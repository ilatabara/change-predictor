id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fironic~master~I9d569b84f1c6e5ae1354ba2668c334e8cb01a450,openstack/ironic,master,I9d569b84f1c6e5ae1354ba2668c334e8cb01a450,Add documentation to create in RegionOne,MERGED,2014-12-07 01:53:34.000000000,2015-01-08 18:23:31.000000000,2015-01-08 18:23:30.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-07 01:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/09833ce61bed966adba706ef78b6c89e90f960f5', 'message': 'Add documentation to create in RegionOne\n\nThe default development documentation does not work with the\npython-ironicclient.  It prints out an error about not finding the\nregion ""regionOne"".  Force the creation in the documentation to ""RegionOne""\nto match the rest of the openstack projects.\n\nChange-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450\n'}, {'number': 2, 'created': '2015-01-07 16:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/13bd54d7f5c7901de7e4224b2e6aa4dc4aff6e75', 'message': 'Add documentation to create in RegionOne\n\nThe default development documentation does not work with the\npython-ironicclient.  It prints out an error about not finding the\nregion ""regionOne"".  Force the creation in the documentation to ""RegionOne""\nto match the rest of the openstack projects.\n\nChange-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450\n'}, {'number': 3, 'created': '2015-01-07 17:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7098cfefbaaf9e452a4bec4d466a2506db60d436', 'message': 'Add documentation to create in RegionOne\n\nThe default development documentation does not work with the\npython-ironicclient.  It prints out an error about not finding the\nregion ""regionOne"".  Force the creation in the documentation to ""RegionOne""\nto match the rest of the openstack projects.\n\nChange-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450\n'}, {'number': 4, 'created': '2015-01-08 03:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/40fb4dca5a505fe9e825edeb39083730014ae166', 'message': 'Add documentation to create in RegionOne\n\nThe default development documentation does not work with the\npython-ironicclient.  It prints out an error about not finding the\nregion ""regionOne"".  Force the creation in the documentation to ""RegionOne""\nto match the rest of the openstack projects.\n\nChange-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450\n'}, {'number': 5, 'created': '2015-01-08 14:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ac0a78cf9789c82f20864624601894ec1239a3e9', 'message': 'Add documentation to create in RegionOne\n\nThe default development documentation may not work with the\npython-ironicclient.  It might print out an error about not finding the\nregion ""regionOne"" (eg if being used in conjunction with some other OpenStack projects). Updated the documentation with a note on how to\naddress this -- by creating in ""RegionOne"".\n\nChange-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450\n'}, {'number': 6, 'created': '2015-01-08 14:06:16.000000000', 'files': ['doc/source/deploy/install-guide.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e8e4ee6d1caa84ddeb504a2239a1bdd29a54bcda', 'message': 'Add documentation to create in RegionOne\n\nThe default development documentation may not work with the\npython-ironicclient.  It might print out an error about not\nfinding the region ""regionOne"" (eg if being used in\nconjunction with some other OpenStack projects). Updated the\ndocumentation with a note on how to address this -- by creating\nin ""RegionOne"".\n\nChange-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450\n'}]",12,139842,e8e4ee6d1caa84ddeb504a2239a1bdd29a54bcda,49,6,6,2834,,,0,"Add documentation to create in RegionOne

The default development documentation may not work with the
python-ironicclient.  It might print out an error about not
finding the region ""regionOne"" (eg if being used in
conjunction with some other OpenStack projects). Updated the
documentation with a note on how to address this -- by creating
in ""RegionOne"".

Change-Id: I9d569b84f1c6e5ae1354ba2668c334e8cb01a450
",git fetch https://review.opendev.org/openstack/ironic refs/changes/42/139842/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploy/install-guide.rst'],1,09833ce61bed966adba706ef78b6c89e90f960f5,, --adminurl=http://IRONIC_NODE:6385 \ --region=RegionOne, --adminurl=http://IRONIC_NODE:6385,2,1
openstack%2Ftempest~master~Ie0cd54242ac2a9531e94854db61d702f118b02bd,openstack/tempest,master,Ie0cd54242ac2a9531e94854db61d702f118b02bd,Floating IP Negative Tests,MERGED,2014-07-25 09:33:30.000000000,2015-01-08 18:22:40.000000000,2015-01-08 18:22:38.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6983}, {'_account_id': 7249}, {'_account_id': 7350}, {'_account_id': 8576}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10969}, {'_account_id': 11671}]","[{'number': 1, 'created': '2014-07-25 09:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0b0753530c76b986da66cf99b448983d377157de', 'message': 'Floating IP Negative Tests\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a network,subnet\n      Create a router and add the interface to the subnet\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a network,subnet\n       Create a router with the external gateway set\n       Add the router interface to the subnet\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a network,subnet\n       Create a router\n       Add the router interface to the subnet\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 2, 'created': '2014-08-07 13:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b07f915f5876838f48ad66504fac41473f39357b', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 3, 'created': '2014-08-18 11:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/da33a337e8c26fa9d05e1e86ddd5248f24a8cda0', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 4, 'created': '2014-08-20 14:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cde4977ce61e903ff70c69fa851ff73382b9a71c', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 5, 'created': '2014-08-20 18:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ebe91ed8ef8361b9fc85bc50798bd986f81a58af', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 6, 'created': '2014-08-20 18:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e70f6f2ff6da596c77e06b9f3155b341ca3e4914', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 7, 'created': '2014-11-12 05:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ac5d9c99948f696aec5a493c2a5af5cde391aae0', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 8, 'created': '2014-11-17 14:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/92387ce823b9071181818c37c00567f4ca820ac0', 'message': 'Floating IP Negative Tests\n\n   Add funtion to create network subnet and router\n      Create a network\n      Create a Subnet\n      Create a Router\n      Create router interface with a subnet\n        -returns: network, subnet, router\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 9, 'created': '2014-11-17 17:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2dadfe0238460e0fa363e775cf28637591ff98f4', 'message': 'Floating IP Negative Tests\n\n   Add funtion to find out fixed ips\n        -returns: Fixed ips list\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 10, 'created': '2014-11-18 08:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/72227b46aed9b1daf1e646a24c122332c86415e9', 'message': 'Floating IP Negative Tests\n\n   Add funtion to find out fixed ips\n        -returns: Fixed ips list\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 11, 'created': '2014-11-18 13:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e449f58c2428b7dfc8ac68565b914da900bfff69', 'message': 'Floating IP Negative Tests\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a port that is not reachable to external network\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a port with a fixed ip\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 12, 'created': '2014-12-02 12:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7f1e58588775612fb0ca2c760ffeb6bc62185ae3', 'message': 'Floating IP Negative Tests\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 13, 'created': '2014-12-18 05:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a88c0bf8e814948496aeb4e7ce7d4fb892a3d549', 'message': 'Floating IP Negative Tests\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}, {'number': 14, 'created': '2015-01-06 06:27:35.000000000', 'files': ['tempest/api/network/test_floating_ips_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec9238353903a215b6d953d59b8acccc98498dfb', 'message': 'Floating IP Negative Tests\n\n   Add test create floating ip with port not reachable\n   to external network returns 404\n      Create a floating ip passing the port\n      Validate te proper error response 404 is return\n\n   Add test create floating ip with private network returns 400\n       Create a floating ip passing the private(tenant) network\n       Validate proper error response 400 is return\n\n   Add test associate floating ip with port not reachable\n   to external network returns 400\n       Create a floating ip passing the external network\n       Update a floating ip by associating the port that is not reachable to floating ip\n       Validate proper error response 400 is return\n\nChange-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd\n'}]",57,109529,ec9238353903a215b6d953d59b8acccc98498dfb,114,14,14,11671,,,0,"Floating IP Negative Tests

   Add test create floating ip with port not reachable
   to external network returns 404
      Create a floating ip passing the port
      Validate te proper error response 404 is return

   Add test create floating ip with private network returns 400
       Create a floating ip passing the private(tenant) network
       Validate proper error response 400 is return

   Add test associate floating ip with port not reachable
   to external network returns 400
       Create a floating ip passing the external network
       Update a floating ip by associating the port that is not reachable to floating ip
       Validate proper error response 400 is return

Change-Id: Ie0cd54242ac2a9531e94854db61d702f118b02bd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/29/109529/14 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_floating_ips_negative.py'],1,0b0753530c76b986da66cf99b448983d377157de,Test_Floatinip_Negative_API,"# Copyright 2014 Hewlett-Packard Development Company, L.P. # Copyright 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr from tempest.api.network import base from tempest.common.utils import data_utils from tempest import config from tempest import exceptions from tempest import test CONF = config.CONF class FloatingIPTestJSON(base.BaseNetworkTest): _interface = 'json' """""" Test the following negative operations for floating ips: Create floatingip with a port that is unreachable to external network Create floatingip in private network Associate floatingip with port that is unreachable to external network """""" @classmethod @test.safe_setup def setUpClass(cls): super(FloatingIPTestJSON, cls).setUpClass() if not test.is_extension_enabled('router', 'network'): msg = ""router extension not enabled."" raise cls.skipException(msg) cls.ext_net_id = CONF.network.public_network_id @test.attr(type=['negative', 'smoke']) def test_create_floatingip_with_port_ext_net_unreachable_returns_404(self): # Create network, subnet self.network = self.create_network() self.subnet = self.create_subnet(self.network) self.router = self.create_router(data_utils.rand_name('router')) self.create_router_interface(self.router['id'], self.subnet['id']) # Find out ips that can be used for tests ips = list(netaddr.IPNetwork(self.subnet['cidr'])) list_ips = [str(ip) for ip in ips[-3:-1]] fixed_ips = [{'ip_address': list_ips[0]}, {'ip_address': list_ips[1]}] # Create port resp, body = self.client.create_port(network_id=self.network['id'], fixed_ips=fixed_ips) self.assertEqual('201', resp['status']) port = body['port'] self.addCleanup(self.client.delete_port, port['id']) self.assertRaises(exceptions.NotFound, self.client.create_floatingip, floating_network_id=self.ext_net_id, port_id=port['id'], fixed_ip_address=list_ips[0]) @test.attr(type=['negative', 'smoke']) def test_create_floatingip_in_private_network_returns_400(self): # Create network, subnet self.network = self.create_network() self.subnet = self.create_subnet(self.network) self.router = self.create_router(data_utils.rand_name('router'), external_network_id=self.ext_net_id) self.create_router_interface(self.router['id'], self.subnet['id']) # Find out ips that can be used for tests ips = list(netaddr.IPNetwork(self.subnet['cidr'])) list_ips = [str(ip) for ip in ips[-3:-1]] fixed_ips = [{'ip_address': list_ips[0]}, {'ip_address': list_ips[1]}] # Create port resp, body = self.client.create_port(network_id=self.network['id'], fixed_ips=fixed_ips) self.assertEqual('201', resp['status']) port = body['port'] self.addCleanup(self.client.delete_port, port['id']) self.assertRaises(exceptions.BadRequest, self.client.create_floatingip, floating_network_id=self.network['id'], port_id=port['id'], fixed_ip_address=list_ips[0]) @test.attr(type=['negative', 'smoke']) def test_associate_floatingip_port_ext_net_unreachable_returns_404(self): # Create network, subnet self.network = self.create_network() self.subnet = self.create_subnet(self.network) self.router = self.create_router(data_utils.rand_name('router')) self.create_router_interface(self.router['id'], self.subnet['id']) # Find out ips that can be used for tests ips = list(netaddr.IPNetwork(self.subnet['cidr'])) list_ips = [str(ip) for ip in ips[-3:-1]] fixed_ips = [{'ip_address': list_ips[0]}, {'ip_address': list_ips[1]}] # Create port resp, body = self.client.create_port(network_id=self.network['id'], fixed_ips=fixed_ips) self.assertEqual('201', resp['status']) port = body['port'] self.addCleanup(self.client.delete_port, port['id']) # Create floating ip resp, body = self.client.create_floatingip( floating_network_id=self.ext_net_id) self.assertEqual('201', resp['status']) floating_ip = body['floatingip'] self.addCleanup(self.client.delete_floatingip, floating_ip['id']) # Associate floating IP to the other port self.assertRaises(exceptions.NotFound, self.client.update_floatingip, floating_ip['id'], port_id=port['id'], fixed_ip_address=list_ips[0]) class FloatingIPTestXML(FloatingIPTestJSON): _interface = 'xml' ",,120,0
openstack%2Fmonasca-common~master~Ie5545775573e7f628d777f247529ea154739341a,openstack/monasca-common,master,Ie5545775573e7f628d777f247529ea154739341a,Make MetricDefinition extend AbstractEntity for pagination,MERGED,2015-01-07 22:42:56.000000000,2015-01-08 18:14:45.000000000,2015-01-08 18:14:45.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}]","[{'number': 1, 'created': '2015-01-07 22:42:56.000000000', 'files': ['java/monasca-common-model/src/main/java/monasca/common/model/metric/MetricDefinition.java'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/6c1fd1911c13f8fc1a434c7d555867ad7e0370af', 'message': 'Make MetricDefinition extend AbstractEntity for pagination\n\nChange-Id: Ie5545775573e7f628d777f247529ea154739341a\n'}]",0,145616,6c1fd1911c13f8fc1a434c7d555867ad7e0370af,7,3,1,12512,,,0,"Make MetricDefinition extend AbstractEntity for pagination

Change-Id: Ie5545775573e7f628d777f247529ea154739341a
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/16/145616/1 && git format-patch -1 --stdout FETCH_HEAD,['java/monasca-common-model/src/main/java/monasca/common/model/metric/MetricDefinition.java'],1,6c1fd1911c13f8fc1a434c7d555867ad7e0370af,,import monasca.common.model.domain.common.AbstractEntity; public class MetricDefinition extends AbstractEntity implements Serializable { public void setId(String id) { this.id = id; } ,public class MetricDefinition implements Serializable {,8,1
openstack%2Ftripleo-image-elements~master~I54ad550fde90a772e476de78fead25ceab3eb7a9,openstack/tripleo-image-elements,master,I54ad550fde90a772e476de78fead25ceab3eb7a9,Try removing pxe_ilo driver,ABANDONED,2015-01-08 17:31:06.000000000,2015-01-08 18:13:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-08 17:31:06.000000000', 'files': ['elements/ironic/os-apply-config/etc/ironic/ironic.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a58f74e21beec20e661f2da67add6529515904b7', 'message': 'Try removing pxe_ilo driver\n\nJust want to see if the pxe_ilo driver is actually the problem or\nif this is just a red herring because it happens to be last in\nthe list.\n\nChange-Id: I54ad550fde90a772e476de78fead25ceab3eb7a9\n'}]",0,145846,a58f74e21beec20e661f2da67add6529515904b7,4,1,1,6928,,,0,"Try removing pxe_ilo driver

Just want to see if the pxe_ilo driver is actually the problem or
if this is just a red herring because it happens to be last in
the list.

Change-Id: I54ad550fde90a772e476de78fead25ceab3eb7a9
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/46/145846/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ironic/os-apply-config/etc/ironic/ironic.conf'],1,a58f74e21beec20e661f2da67add6529515904b7,test-ilo,"enabled_drivers = pxe_ssh,pxe_ipmitool","enabled_drivers = pxe_ssh,pxe_ipmitool,pxe_ilo",1,1
openstack%2Ftempest~master~Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f,openstack/tempest,master,Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f,Change image client methods to return one value,MERGED,2015-01-06 18:47:11.000000000,2015-01-08 18:09:39.000000000,2015-01-08 18:09:38.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-06 18:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/10b212201c2b8e06a31a73c1c07d5d3f7b5223e7', 'message': 'Change image client methods to return one value\n\nTests were updated along with verify_tempest, cleanup, javelin.\nThere were two methods in the clients where the body is a string. Since\nstrings are immutable a more complicated way would have to be created to\nreturn a single value that could be used transparently by clients. So\nthese methods continue to return (response, body).\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f\n'}, {'number': 2, 'created': '2015-01-06 20:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d72d86cc98f3ba5335eba67871c099edfdd351b2', 'message': 'Change image client methods to return one value\n\nTests were updated along with verify_tempest, cleanup, javelin.\nThere were two methods in the clients where the body is a string. Since\nstrings are immutable a more complicated way would have to be created to\nreturn a single value that could be used transparently by clients. So\nthese methods continue to return (response, body).\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f\n'}, {'number': 3, 'created': '2015-01-06 22:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/be98a7d78cf71edbaba275e2775574ed5f76d750', 'message': 'Change image client methods to return one value\n\nTests were updated along with verify_tempest, cleanup, javelin.\nThere were two methods in the clients where the body is a string. Since\nstrings are immutable a more complicated way would have to be created to\nreturn a single value that could be used transparently by clients. So\nthese methods continue to return (response, body).\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f\n'}, {'number': 4, 'created': '2015-01-06 22:22:47.000000000', 'files': ['tempest/api/compute/test_authorization.py', 'tempest/cmd/cleanup_service.py', 'tempest/api/image/v2/test_images.py', 'tempest/scenario/manager.py', 'tempest/api/image/base.py', 'tempest/cmd/verify_tempest_config.py', 'tempest/api/image/v1/test_images.py', 'tempest/api/image/v2/test_images_tags.py', 'tempest/api/compute/images/test_image_metadata.py', 'tempest/api/image/v1/test_image_members.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/image/v2/test_images_member.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/api/image/v2/test_images_member_negative.py', 'tempest/cmd/javelin.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/tests/cmd/test_verify_tempest_config.py', 'tempest/api/image/v2/test_images_negative.py', 'tempest/api/image/v2/test_images_tags_negative.py', 'tempest/api/orchestration/base.py', 'tempest/services/image/v1/json/image_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/34f18782fa8102bd1f6f5519011cc7243207cdf7', 'message': 'Change image client methods to return one value\n\nTests were updated along with verify_tempest, cleanup, javelin.\nThere were two methods in the clients where the body is a string. Since\nstrings are immutable a more complicated way would have to be created to\nreturn a single value that could be used transparently by clients. So\nthese methods continue to return (response, body).\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f\n'}]",1,145295,34f18782fa8102bd1f6f5519011cc7243207cdf7,22,7,4,1192,,,0,"Change image client methods to return one value

Tests were updated along with verify_tempest, cleanup, javelin.
There were two methods in the clients where the body is a string. Since
strings are immutable a more complicated way would have to be created to
return a single value that could be used transparently by clients. So
these methods continue to return (response, body).

Partially implements: blueprint clients-return-one-value

Change-Id: Id6a728d1ea1cf233ae580fdcd305dc42a4f3610f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/95/145295/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cmd/cleanup_service.py', 'tempest/api/image/v2/test_images.py', 'tempest/scenario/manager.py', 'tempest/api/image/base.py', 'tempest/cmd/verify_tempest_config.py', 'tempest/api/image/v1/test_images.py', 'tempest/api/image/v2/test_images_tags.py', 'tempest/api/image/v1/test_image_members.py', 'tempest/api/image/v2/test_images_member.py', 'tempest/api/image/v2/test_images_member_negative.py', 'tempest/cmd/javelin.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/tests/cmd/test_verify_tempest_config.py', 'tempest/api/image/v2/test_images_negative.py', 'tempest/api/image/v2/test_images_tags_negative.py', 'tempest/services/image/v1/json/image_client.py']",16,10b212201c2b8e06a31a73c1c07d5d3f7b5223e7,bp/clients-return-one-value," return rest_client.ResponseBody(resp, body['image']) return rest_client.ResponseBody(resp, body['image']) return rest_client.ResponseBody(resp, body['image']) return rest_client.ResponseBody(resp, body['image']) return rest_client.ResponseBody(resp, body) return rest_client.ResponseBodyList(resp, body['images']) return rest_client.ResponseBodyList(resp, body['images']) return rest_client.ResponseBody(resp, body) # We can't return a ResponseBody because the body is a string return rest_client.ResponseBody(resp, body) return rest_client.ResponseBody(resp, body) return rest_client.ResponseBody(resp) return rest_client.ResponseBody(resp) meta = self.get_image_meta(image_id)"," return resp, body['image'] return resp, body['image'] return resp, body['image'] return resp, body['image'] return resp, body return resp, body['images'] return resp, body['images'] return resp, body return resp, body return resp, body return resp return resp resp, meta = self.get_image_meta(image_id)",158,156
openstack%2Fpuppet-keystone~master~Id973dbfd617b2bf748e2477e96fe5a4b4ceb3229,openstack/puppet-keystone,master,Id973dbfd617b2bf748e2477e96fe5a4b4ceb3229,Use openstackclient for keystone_endpoint,ABANDONED,2015-01-08 17:43:54.000000000,2015-01-08 17:52:45.000000000,,"[{'_account_id': 3}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:43:54.000000000', 'files': ['spec/unit/provider/keystone_endpoint/openstack_spec.rb', 'lib/puppet/provider/keystone_endpoint/openstack.rb', 'spec/unit/provider/keystone_endpoint/keystone_spec.rb', 'lib/puppet/type/keystone_endpoint.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cf16aea9c19bd48037dd58db5e859dbe1101190b', 'message': 'Use openstackclient for keystone_endpoint\n\nblueprint use-openstackclient-in-module-resources\n\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n(cherry picked from commit 0696d02d8b5ac3a1088d6f5e2543d749d07816e6)\n\nChange-Id: Id973dbfd617b2bf748e2477e96fe5a4b4ceb3229\n'}]",0,145856,cf16aea9c19bd48037dd58db5e859dbe1101190b,3,2,1,9983,,,0,"Use openstackclient for keystone_endpoint

blueprint use-openstackclient-in-module-resources

Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
(cherry picked from commit 0696d02d8b5ac3a1088d6f5e2543d749d07816e6)

Change-Id: Id973dbfd617b2bf748e2477e96fe5a4b4ceb3229
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/56/145856/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_endpoint/openstack_spec.rb', 'lib/puppet/provider/keystone_endpoint/openstack.rb', 'spec/unit/provider/keystone_endpoint/keystone_spec.rb', 'lib/puppet/type/keystone_endpoint.rb']",4,cf16aea9c19bd48037dd58db5e859dbe1101190b,bp/use-openstackclient-in-module-resources,"require 'puppet/util/openstack' desc 'Type for managing keystone endpoints.' auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_openstack_type_methods(self, auth_param_doc)", desc <<-EOT This is currently used to model the management of keystone endpoint. EOT # TODO I should do some url validation,233,79
openstack%2Fpuppet-keystone~master~I4d260e7f7910eb86a28e14feca7f9757d984328a,openstack/puppet-keystone,master,I4d260e7f7910eb86a28e14feca7f9757d984328a,Use openstackclient for keystone_user_role,ABANDONED,2015-01-08 17:43:47.000000000,2015-01-08 17:52:38.000000000,,"[{'_account_id': 3}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:43:47.000000000', 'files': ['spec/unit/provider/keystone_user_role/keystone_spec.rb', 'lib/puppet/provider/keystone_user_role/keystone.rb', 'lib/puppet/provider/keystone_user_role/openstack.rb', 'lib/puppet/type/keystone_user_role.rb', 'spec/unit/provider/keystone_user_role/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/1f998cfca608e5d53f207cdf19bbaa1ba5602b06', 'message': 'Use openstackclient for keystone_user_role\n\nblueprint use-openstackclient-in-module-resources\n\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n(cherry picked from commit 80ab6d86a5e286e087e9352231b13f7fab41d7bd)\n\nChange-Id: I4d260e7f7910eb86a28e14feca7f9757d984328a\n'}]",0,145855,1f998cfca608e5d53f207cdf19bbaa1ba5602b06,3,2,1,9983,,,0,"Use openstackclient for keystone_user_role

blueprint use-openstackclient-in-module-resources

Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
(cherry picked from commit 80ab6d86a5e286e087e9352231b13f7fab41d7bd)

Change-Id: I4d260e7f7910eb86a28e14feca7f9757d984328a
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/55/145855/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user_role/keystone_spec.rb', 'lib/puppet/provider/keystone_user_role/keystone.rb', 'lib/puppet/provider/keystone_user_role/openstack.rb', 'lib/puppet/type/keystone_user_role.rb', 'spec/unit/provider/keystone_user_role/openstack_spec.rb']",5,1f998cfca608e5d53f207cdf19bbaa1ba5602b06,bp/use-openstackclient-in-module-resources,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_user_role/openstack' provider_class = Puppet::Type.type(:keystone_user_role).provider(:openstack) describe provider_class do describe 'when updating a user\'s role' do let(:user_role_attrs) do { :name => 'foo@example.com@foo', :ensure => 'present', :roles => ['foo', 'bar'], :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_user_role.new(user_role_attrs) end let(:provider) do provider_class.new(resource) end before(:each) do provider.class.stubs(:openstack) .with('user', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo@example.com"" ') provider.class.stubs(:openstack) .with('project', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') end describe '#create' do it 'adds all the roles to the user' do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo@example.com"" ""1cb05cfed7c24279be884ba4f6520263"",""bar"",""foo"",""foo@example.com"" ') provider.class.stubs(:openstack) .with('role', 'add', [['foo', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.class.stubs(:openstack) .with('role', 'add', [['bar', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'removes all the roles from a user' do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User""') provider.class.stubs(:openstack) .with('role', 'remove', [['foo', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.class.stubs(:openstack) .with('role', 'remove', [['bar', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do subject(:response) do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User"" ""1cb05ed7c24279be884ba4f6520262"",""foo"",""foo"",""foo@example.com"" ""1cb05ed7c24279be884ba4f6520262"",""bar"",""foo"",""foo@example.com"" ') response = provider.exists? end it { is_expected.to be_truthy } end end end ",,255,288
openstack%2Fpuppet-keystone~master~Iea4f946c81752bf894f16e67695886bb6b660a4b,openstack/puppet-keystone,master,Iea4f946c81752bf894f16e67695886bb6b660a4b,Use openstackclient for keystone_user,ABANDONED,2015-01-08 17:43:39.000000000,2015-01-08 17:52:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:43:39.000000000', 'files': ['spec/unit/provider/keystone_user/openstack_spec.rb', 'spec/unit/provider/keystone_user/keystone_spec.rb', 'lib/puppet/provider/keystone_user/openstack.rb', 'lib/puppet/provider/keystone_user/keystone.rb', 'lib/puppet/type/keystone_user.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/89c9a665ffca44bf7cc4cc707bf8bcb40220aea3', 'message': 'Use openstackclient for keystone_user\n\nblueprint use-openstackclient-in-module-resources\n\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n(cherry picked from commit 6af8ac6320c8e93a8dae73aa286350d98d3972f1)\n\nChange-Id: Iea4f946c81752bf894f16e67695886bb6b660a4b\n'}]",0,145854,89c9a665ffca44bf7cc4cc707bf8bcb40220aea3,3,2,1,9983,,,0,"Use openstackclient for keystone_user

blueprint use-openstackclient-in-module-resources

Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
(cherry picked from commit 6af8ac6320c8e93a8dae73aa286350d98d3972f1)

Change-Id: Iea4f946c81752bf894f16e67695886bb6b660a4b
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/54/145854/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user/openstack_spec.rb', 'spec/unit/provider/keystone_user/keystone_spec.rb', 'lib/puppet/provider/keystone_user/openstack.rb', 'lib/puppet/provider/keystone_user/keystone.rb', 'lib/puppet/type/keystone_user.rb']",5,89c9a665ffca44bf7cc4cc707bf8bcb40220aea3,bp/use-openstackclient-in-module-resources,"require 'puppet/util/openstack' desc 'Type for managing keystone users.' newvalues(/(t|T)rue/, /(f|F)alse/, true, false) defaultto(true) value.to_s.downcase.to_sym auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_openstack_type_methods(self, auth_param_doc)"," desc <<-EOT This is currently used to model the creation of keystone users. It currently requires that both the password as well as the tenant are specified. EOT # TODO support description?? newvalues(/(t|T)rue/, /(f|F)alse/) defaultto('True') value.to_s.capitalize",276,224
openstack%2Fpuppet-keystone~master~I4468487c45ead5be7a0e379220420211380bb108,openstack/puppet-keystone,master,I4468487c45ead5be7a0e379220420211380bb108,Use openstackclient for keystone_role,ABANDONED,2015-01-08 17:42:42.000000000,2015-01-08 17:52:23.000000000,,"[{'_account_id': 3}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:42:42.000000000', 'files': ['lib/puppet/provider/keystone_role/keystone.rb', 'lib/puppet/provider/keystone_role/openstack.rb', 'lib/puppet/type/keystone_role.rb', 'spec/unit/provider/keystone_role/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ecee44c3c2a3a98725e492441c2901cd61c1f5de', 'message': 'Use openstackclient for keystone_role\n\nblueprint use-openstackclient-in-module-resources\n\n(cherry picked from commit 4b4850473a940f3d7782dba008697444a942572b)\n\nChange-Id: I4468487c45ead5be7a0e379220420211380bb108\n'}]",0,145853,ecee44c3c2a3a98725e492441c2901cd61c1f5de,3,2,1,9983,,,0,"Use openstackclient for keystone_role

blueprint use-openstackclient-in-module-resources

(cherry picked from commit 4b4850473a940f3d7782dba008697444a942572b)

Change-Id: I4468487c45ead5be7a0e379220420211380bb108
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/53/145853/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_role/keystone.rb', 'lib/puppet/provider/keystone_role/openstack.rb', 'lib/puppet/type/keystone_role.rb', 'spec/unit/provider/keystone_role/openstack_spec.rb']",4,ecee44c3c2a3a98725e492441c2901cd61c1f5de,bp/use-openstackclient-in-module-resources,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_role/openstack' provider_class = Puppet::Type.type(:keystone_role).provider(:openstack) describe provider_class do describe 'when creating a role' do let(:role_attrs) do { :name => 'foo', :ensure => 'present', :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_role.new(role_attrs) end let(:provider) do provider_class.new(resource) end describe '#create' do it 'creates a role' do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') provider.class.stubs(:openstack) .with('role', 'create', [['foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'destroys a role' do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name""') provider.class.stubs(:openstack) .with('role', 'delete', [['foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do context 'when role exists' do subject(:response) do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') response = provider.exists? end it { is_expected.to be_truthy } end context 'when role does not exist' do subject(:response) do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name""') response = provider.exists? end it { is_expected.to be_falsey } end end describe '#instances' do it 'finds every role' do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') instances = provider.instances expect(instances.count).to eq(1) end end end end ",,158,65
openstack%2Fpuppet-keystone~master~I2a136f8a4e84a55fc699d9a56e493d4c0d700935,openstack/puppet-keystone,master,I2a136f8a4e84a55fc699d9a56e493d4c0d700935,Use openstackclient for keystone_service,ABANDONED,2015-01-08 17:41:41.000000000,2015-01-08 17:52:15.000000000,,"[{'_account_id': 3}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:41:41.000000000', 'files': ['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb', 'lib/puppet/provider/keystone_service/keystone.rb', 'spec/unit/provider/keystone_service/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a24210b0bcfd56c222feca66beb86a4d90bf4c8e', 'message': 'Use openstackclient for keystone_service\n\nblueprint use-openstackclient-in-module-resources\n\n(cherry picked from commit 72a02aa70880bb5cb07d0a2b1e828fffbae5d0ed)\n\nChange-Id: I2a136f8a4e84a55fc699d9a56e493d4c0d700935\n'}]",0,145851,a24210b0bcfd56c222feca66beb86a4d90bf4c8e,3,2,1,9983,,,0,"Use openstackclient for keystone_service

blueprint use-openstackclient-in-module-resources

(cherry picked from commit 72a02aa70880bb5cb07d0a2b1e828fffbae5d0ed)

Change-Id: I2a136f8a4e84a55fc699d9a56e493d4c0d700935
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/51/145851/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb', 'lib/puppet/provider/keystone_service/keystone.rb', 'spec/unit/provider/keystone_service/openstack_spec.rb']",4,a24210b0bcfd56c222feca66beb86a4d90bf4c8e,bp/use-openstackclient-in-module-resources,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_service/openstack' provider_class = Puppet::Type.type(:keystone_service).provider(:openstack) describe provider_class do describe 'when creating a service' do let(:service_attrs) do { :name => 'foo', :description => 'foo', :ensure => 'present', :type => 'foo', :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_service.new(service_attrs) end let(:provider) do provider_class.new(resource) end describe '#create' do it 'creates a service' do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo"" ') provider.class.stubs(:openstack) .with('service', 'create', [['foo', '--description', 'foo', '--type', 'foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'destroys a service' do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description""') provider.class.stubs(:openstack) .with('service', 'delete', [['foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do context 'when service exists' do subject(:response) do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo"" ') response = provider.exists? end it { is_expected.to be_truthy } end context 'when service does not exist' do subject(:response) do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description""') response = provider.exists? end it { is_expected.to be_falsey } end end describe '#instances' do it 'finds every service' do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo"" ') instances = provider.instances expect(instances.count).to eq(1) end end end end ",,218,102
openstack%2Fpuppet-keystone~master~I7c210de68dfd5512510e1aef104af017a07766c5,openstack/puppet-keystone,master,I7c210de68dfd5512510e1aef104af017a07766c5,Use openstackclient for keystone_tenant,ABANDONED,2015-01-08 17:41:02.000000000,2015-01-08 17:51:47.000000000,,"[{'_account_id': 3}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:41:02.000000000', 'files': ['spec/unit/provider/keystone_spec.rb', 'spec/unit/provider/keystone_tenant/keystone_spec.rb', 'manifests/init.pp', 'lib/puppet/provider/keystone_tenant/openstack.rb', 'lib/puppet/provider/keystone.rb', 'lib/puppet/provider/keystone_tenant/keystone.rb', 'lib/puppet/util/openstack.rb', 'spec/spec_helper.rb', 'spec/unit/provider/keystone_tenant/openstack_spec.rb', 'spec/unit/provider/openstack_spec.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/provider/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a1f5fa29a7e5ee68d26ed7f6944278d5db560e32', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nblueprint use-openstackclient-in-module-resources\n\n(cherry picked from commit acf3dc6f06b6dcc5af876517c8511a5225e5e3f6)\n\nChange-Id: I7c210de68dfd5512510e1aef104af017a07766c5\n'}]",0,145848,a1f5fa29a7e5ee68d26ed7f6944278d5db560e32,3,2,1,9983,,,0,"Use openstackclient for keystone_tenant

This patch migrates the keystone_tenant provider to use the universal
openstack client instead of the keystone client. It uses the openstack
parent provider in openstacklib to handle multiple authenticating
methods. The keystone_tenant type uses the openstacklib openstack
utility to add a new auth parameter to the keystone_tenant type.

This patch also moves functionality for parsing keystone.conf for the
service token back to the keystone module from openstacklib. It creates
three tiers of inheritance: Keystone_tenant < Keystone < Openstack, so
that keystone-specific functionality can stay in keystone.

It also adds a flush method which should help improve performance.

blueprint use-openstackclient-in-module-resources

(cherry picked from commit acf3dc6f06b6dcc5af876517c8511a5225e5e3f6)

Change-Id: I7c210de68dfd5512510e1aef104af017a07766c5
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/48/145848/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_spec.rb', 'spec/unit/provider/keystone_tenant/keystone_spec.rb', 'manifests/init.pp', 'lib/puppet/provider/keystone_tenant/openstack.rb', 'lib/puppet/provider/keystone.rb', 'lib/puppet/provider/keystone_tenant/keystone.rb', 'lib/puppet/util/openstack.rb', 'spec/spec_helper.rb', 'spec/unit/provider/keystone_tenant/openstack_spec.rb', 'spec/unit/provider/openstack_spec.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/provider/openstack.rb']",12,a1f5fa29a7e5ee68d26ed7f6944278d5db560e32,bp/use-openstackclient-in-module-resources,"# TODO: This needs to be extracted out into openstacklib in the Kilo cycle require 'csv' require 'puppet' class Puppet::Error::OpenstackAuthInputError < Puppet::Error end class Puppet::Error::OpenstackUnauthorizedError < Puppet::Error end class Puppet::Provider::Openstack < Puppet::Provider initvars # so commands will work commands :openstack => 'openstack' def request(service, action, object, credentials, *properties) if password_credentials_set?(credentials) auth_args = password_auth_args(credentials) elsif openrc_set?(credentials) credentials = get_credentials_from_openrc(credentials['openrc']) auth_args = password_auth_args(credentials) elsif service_credentials_set?(credentials) auth_args = token_auth_args(credentials) elsif env_vars_set? # noop; auth needs no extra arguments auth_args = nil else # All authentication efforts failed raise(Puppet::Error::OpenstackAuthInputError, 'No credentials provided.') end args = [object, properties, auth_args].flatten.compact authenticate_request(service, action, args) end def self.request(service, action, object, *properties) if env_vars_set? # noop; auth needs no extra arguments auth_args = nil else # All authentication efforts failed raise(Puppet::Error::OpenstackAuthInputError, 'No credentials provided.') end args = [object, properties, auth_args].flatten.compact authenticate_request(service, action, args) end # Returns an array of hashes, where the keys are the downcased CSV headers # with underscores instead of spaces def self.authenticate_request(service, action, *args) begin if(action == 'list') response = openstack(service, action, '--quiet', '--format', 'csv', args) response = CSV.parse(response.to_s) keys = response.delete_at(0) # ID,Name,Description,Enabled response.collect do |line| hash = {} keys.each_index do |index| key = keys[index].downcase.gsub(/ /, '_').to_sym hash[key] = line[index] end hash end else openstack(service, action, args) end rescue Puppet::ExecutionFailure => e if e.message =~ /HTTP 401/ raise(Puppet::Error::OpenstackUnauthorizedError, 'Could not authenticate.') else raise e end end end def authenticate_request(service, action, *args) self.class.authenticate_request(service, action, *args) end private def password_credentials_set?(auth_params) auth_params && auth_params['username'] && auth_params['password'] && auth_params['tenant_name'] && auth_params['auth_url'] end def openrc_set?(auth_params) auth_params && auth_params['openrc'] end def service_credentials_set?(auth_params) auth_params && auth_params['token'] && auth_params['auth_url'] end def self.env_vars_set? ENV['OS_USERNAME'] && ENV['OS_PASSWORD'] && ENV['OS_TENANT_NAME'] && ENV['OS_AUTH_URL'] end def env_vars_set? self.class.env_vars_set? end def self.password_auth_args(credentials) ['--os-username', credentials['username'], '--os-password', credentials['password'], '--os-tenant-name', credentials['tenant_name'], '--os-auth-url', credentials['auth_url']] end def password_auth_args(credentials) self.class.password_auth_args(credentials) end def self.token_auth_args(credentials) ['--os-token', credentials['token'], '--os-url', credentials['auth_url']] end def token_auth_args(credentials) self.class.token_auth_args(credentials) end def get_credentials_from_openrc(file) creds = {} File.open(file).readlines.delete_if{|l| l=~ /^#/}.each do |line| key, value = line.split('=') key = key.split(' ').last.downcase.sub(/^os_/, '') value = value.chomp.gsub(/'/, '') creds[key] = value end return creds end def self.get_credentials_from_env env = ENV.to_hash.dup.delete_if { |key, _| ! (key =~ /^OS_/) } credentials = {} env.each do |name, value| credentials[name.downcase.sub(/^os_/, '')] = value end credentials end def get_credentials_from_env self.class.get_credentials_from_env end end ",,707,214
openstack%2Fnova~master~Idb27a5d2c4a58f2bb70817006dec219ca702e4dd,openstack/nova,master,Idb27a5d2c4a58f2bb70817006dec219ca702e4dd,initialize objects with context in Instance object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-08 17:42:46.000000000,2015-01-08 06:13:31.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1dddc538d2c401bce7570364819fe683b4091874', 'message': ""initialize objects with context in Instance object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Idb27a5d2c4a58f2bb70817006dec219ca702e4dd\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': ['nova/tests/unit/objects/test_instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/704dab3550502f5244ff42ee3f8c04abae654102', 'message': ""initialize objects with context in Instance object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Idb27a5d2c4a58f2bb70817006dec219ca702e4dd\n""}]",0,142278,704dab3550502f5244ff42ee3f8c04abae654102,22,9,2,4690,,,0,"initialize objects with context in Instance object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: Idb27a5d2c4a58f2bb70817006dec219ca702e4dd
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/142278/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_instance.py'],1,1dddc538d2c401bce7570364819fe683b4091874,bp/kilo-objects," inst = instance.Instance(context=self.context, host='foo-host', memory_mb=128, inst.create() inst = instance.Instance(context=self.context) inst.create() inst1 = instance.Instance(context=self.context, user_id=self.context.user_id, inst1.create() inst = instance.Instance(context=self.context, uuid=self.fake_instance['uuid'], inst.create() inst = instance.Instance(context=self.context, user_id=self.context.user_id, inst.create() inst = instance.Instance(context=self.context, host='foo-host', security_groups=secgroups, inst.create() inst = instance.Instance(context=self.context, id=1, uuid='fake-uuid', host='foo') inst.destroy() inst = instance.Instance(context=self.context, id=db_inst['id'], uuid=db_inst['uuid']) inst.destroy()"," inst = instance.Instance(host='foo-host', memory_mb=128, inst.create(self.context) inst = instance.Instance() inst.create(self.context) inst1 = instance.Instance(user_id=self.context.user_id, inst1.create(self.context) inst = instance.Instance(uuid=self.fake_instance['uuid'], inst.create(self.context) inst = instance.Instance(user_id=self.context.user_id, inst.create(self.context) inst = instance.Instance(host='foo-host', security_groups=secgroups, inst.create(self.context) inst = instance.Instance(id=1, uuid='fake-uuid', host='foo') inst.destroy(self.context) inst = instance.Instance(id=db_inst['id'], uuid=db_inst['uuid']) inst.destroy(self.context)",23,16
openstack%2Fsolum~master~I7afa65db0c8a4b76a6d6f18c0f42d1996a0a097f,openstack/solum,master,I7afa65db0c8a4b76a6d6f18c0f42d1996a0a097f,Include region argument in functest client init,MERGED,2015-01-07 18:32:17.000000000,2015-01-08 17:39:41.000000000,2015-01-08 17:39:41.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 7784}]","[{'number': 1, 'created': '2015-01-07 18:32:17.000000000', 'files': ['functionaltests/api/base.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/64dee4b0779b673897aa61e81695f7985e43f474', 'message': ""Include region argument in functest client init\n\nDefaulting to RegionOne for now; if that's not suitable\nwe can consume the config files to find the real region.\n\nChange-Id: I7afa65db0c8a4b76a6d6f18c0f42d1996a0a097f\n""}]",0,145553,64dee4b0779b673897aa61e81695f7985e43f474,10,4,1,1375,,,0,"Include region argument in functest client init

Defaulting to RegionOne for now; if that's not suitable
we can consume the config files to find the real region.

Change-Id: I7afa65db0c8a4b76a6d6f18c0f42d1996a0a097f
",git fetch https://review.opendev.org/openstack/solum refs/changes/53/145553/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/api/base.py'],1,64dee4b0779b673897aa61e81695f7985e43f474,add-region-to-functest-client," def __init__(self, auth_provider, service='application_deployment', region='RegionOne'): super(SolumClient, self).__init__(auth_provider, service, region)"," def __init__(self, auth_provider, service='application_deployment'): super(SolumClient, self).__init__(auth_provider, service)",3,2
openstack%2Fopenstack-ansible~master~I784e3dd752369de122bb364e02749779a4f6350a,openstack/openstack-ansible,master,I784e3dd752369de122bb364e02749779a4f6350a,Add proper RBAC to Glance's policy.json,MERGED,2015-01-07 18:14:30.000000000,2015-01-08 17:32:05.000000000,2015-01-08 17:32:05.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 9884}, {'_account_id': 12000}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 18:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/81d02ee5d2b221252e6d5987cd5658886d9871d9', 'message': ""Add proper RBAC to Glance's policy.json\n\nCreate a user_is_owner rule to check if the user is the image owner or a\nmember of the tenant.\n\nDocImpact\n\nChange-Id: I784e3dd752369de122bb364e02749779a4f6350a\nPartial-bug: 1408363\n""}, {'number': 2, 'created': '2015-01-08 15:23:56.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8f190b9121715cc90c1d3269f146f1161623d271', 'message': ""Add proper RBAC to Glance's policy.json\n\nCreate a user_is_owner rule to check if the user is the image owner or\na member of the tenant.\n\nDocImpact\n\nChange-Id: I784e3dd752369de122bb364e02749779a4f6350a\nPartial-bug: 1408363\n""}]",0,145550,8f190b9121715cc90c1d3269f146f1161623d271,20,6,2,12000,,,0,"Add proper RBAC to Glance's policy.json

Create a user_is_owner rule to check if the user is the image owner or
a member of the tenant.

DocImpact

Change-Id: I784e3dd752369de122bb364e02749779a4f6350a
Partial-bug: 1408363
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/50/145550/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,81d02ee5d2b221252e6d5987cd5658886d9871d9,bug/1408363," ""user_is_owner"": ""user:%(target.image.owner) OR tenant:%(target.image.owner.tenant)"", ""delete_image"": ""role:admin OR rule:user_is_owner"", ""modify_image"": ""role:admin OR rule:user_is_owner"", ""publicize_image"": ""role:admin OR rule:user_is_owner"", ""add_member"": ""role:admin OR rule:user_is_owner"", ""delete_member"": ""role:admin OR rule:user_is_owner"", ""modify_member"": ""role:admin OR rule:user_is_owner"","," ""delete_image"": """", ""modify_image"": """", ""publicize_image"": """", ""add_member"": """", ""delete_member"": """", ""modify_member"": """",",7,6
openstack%2Fbarbican~master~Ib6bf8fdcceedd6f67f9d7b047f330538b5002289,openstack/barbican,master,Ib6bf8fdcceedd6f67f9d7b047f330538b5002289,Adding error handling to help debug devstack issue,MERGED,2015-01-07 21:14:36.000000000,2015-01-08 17:28:17.000000000,2015-01-08 17:28:16.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-01-07 21:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/80cf517ad6d56cbbd05a255585ff37c92a6fe672', 'message': 'Adding error handling to help debug devstack issue\n\nWe keep running into sporadic JSONDecodeError exceptions being\nraised on our functional tests. Adding a little error handling\nto give us more information and gracefully handle the exception.\n\nChange-Id: Ib6bf8fdcceedd6f67f9d7b047f330538b5002289\nRelated-Bug: #1407767\n'}, {'number': 2, 'created': '2015-01-07 21:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/12e29dd15e683dce5acfeb0ffb41a35818b1f3e8', 'message': 'Adding error handling to help debug devstack issue\n\nWe keep running into sporadic JSONDecodeError exceptions being\nraised on our functional tests. Adding a little error handling\nto give us more information and gracefully handle the exception.\n\nChange-Id: Ib6bf8fdcceedd6f67f9d7b047f330538b5002289\nRelated-Bug: #1407767\n'}, {'number': 3, 'created': '2015-01-07 21:41:23.000000000', 'files': ['functionaltests/api/v1/behaviors/secret_behaviors.py', 'functionaltests/api/v1/behaviors/consumer_behaviors.py', 'functionaltests/api/v1/behaviors/order_behaviors.py', 'functionaltests/api/v1/behaviors/base_behaviors.py', 'functionaltests/api/v1/behaviors/container_behaviors.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/2e2e9077ba4ea8a9debabd3914194255d168d7b4', 'message': 'Adding error handling to help debug devstack issue\n\nWe keep running into sporadic JSONDecodeError exceptions being\nraised on our functional tests. Adding a little error handling\nto give us more information and gracefully handle the exception.\n\nChange-Id: Ib6bf8fdcceedd6f67f9d7b047f330538b5002289\nRelated-Bug: #1407767\n'}]",5,145591,2e2e9077ba4ea8a9debabd3914194255d168d7b4,18,7,3,7262,,,0,"Adding error handling to help debug devstack issue

We keep running into sporadic JSONDecodeError exceptions being
raised on our functional tests. Adding a little error handling
to give us more information and gracefully handle the exception.

Change-Id: Ib6bf8fdcceedd6f67f9d7b047f330538b5002289
Related-Bug: #1407767
",git fetch https://review.opendev.org/openstack/barbican refs/changes/91/145591/1 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/api/v1/behaviors/secret_behaviors.py', 'functionaltests/api/v1/behaviors/consumer_behaviors.py', 'functionaltests/api/v1/behaviors/base_behaviors.py', 'functionaltests/api/v1/behaviors/order_behaviors.py', 'functionaltests/api/v1/behaviors/container_behaviors.py']",5,80cf517ad6d56cbbd05a255585ff37c92a6fe672,bug/1407767, returned_data = self.get_json(resp) container_list = self.get_json(resp), returned_data = resp.json() container_list = resp.json(),23,9
openstack%2Ftripleo-ci~master~Ia3a5946bd2fecdefd45919cd23b5fda7d67ccd86,openstack/tripleo-ci,master,Ia3a5946bd2fecdefd45919cd23b5fda7d67ccd86,Temprevert 13aee6165a21751105aa87dc6e6aecb4cb89b0e6 in ironic,ABANDONED,2015-01-08 16:43:56.000000000,2015-01-08 17:24:05.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-08 16:43:56.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e924dba14d7e1ad0bd6d0b5786d1ad016d3a5a44', 'message': 'Temprevert 13aee6165a21751105aa87dc6e6aecb4cb89b0e6 in ironic\n\nIronic-conductor is having issues starting in our CI jobs right now,\nand this seems like a possible candidate for why.\n\nChange-Id: Ia3a5946bd2fecdefd45919cd23b5fda7d67ccd86\n'}]",0,145833,e924dba14d7e1ad0bd6d0b5786d1ad016d3a5a44,4,1,1,6928,,,0,"Temprevert 13aee6165a21751105aa87dc6e6aecb4cb89b0e6 in ironic

Ironic-conductor is having issues starting in our CI jobs right now,
and this seems like a possible candidate for why.

Change-Id: Ia3a5946bd2fecdefd45919cd23b5fda7d67ccd86
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/33/145833/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,e924dba14d7e1ad0bd6d0b5786d1ad016d3a5a44,,temprevert ironic 13aee6165a21751105aa87dc6e6aecb4cb89b0e6 1408701,,1,0
openstack%2Fneutron~master~Iea700bdd121bbc56a3489a63e2a5391867fad0d6,openstack/neutron,master,Iea700bdd121bbc56a3489a63e2a5391867fad0d6,Correct l3-agent iptables rule for metadata proxy,MERGED,2014-12-11 13:18:33.000000000,2015-01-08 17:23:55.000000000,2015-01-08 17:23:53.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 11114}, {'_account_id': 11126}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 13:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6befb534c93f19b0ba6af4b019edbac26d629f9', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 2, 'created': '2014-12-13 12:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eac4bcd3795434cdfbc482e35e4bcdadf4e2c613', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 3, 'created': '2014-12-16 23:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc3ef660f333924bee88b87ffc7b2c6473963548', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 4, 'created': '2014-12-16 23:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/039e1bf1ca1c812d6d54fc43aab02d08e0fa7f4c', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 5, 'created': '2014-12-17 21:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/468449e63a1a21d733759145d243264fe59ea599', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 6, 'created': '2014-12-18 21:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c291f8aff8bac2de8f7ddebf3294c79b7f04ed4e', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 7, 'created': '2014-12-18 23:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8cefff51a258f89be3febde5a6b50c80670280df', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 8, 'created': '2014-12-22 09:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c64597dc78a9a5aec666a7c8a83a66407856d5ff', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 9, 'created': '2014-12-22 11:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f07a966e75967ce73882fb722ac611010f3177a', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}, {'number': 10, 'created': '2015-01-07 21:10:01.000000000', 'files': ['neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d9d77747d2a16a1bf944e15bf5a7b6fc5e3fe08', 'message': 'Correct l3-agent iptables rule for metadata proxy\n\n2 iptables rules are defined to ensure the metadata proxy is reachable\nfrom vms on 169.254.169.254:80:\n* REDIRECT 169.254.169.254:80 packets to the router on port 9697\n* ACCEPT traffic to 127.0.0.1 on port 9697\n\nThe REDIRECT rule replaces destination ip by:\n * 127.0.0.1 if the packet is local,\n * router ip (the one on the input interface, metadata proxy case).\n\nSo ACCEPT rule filter is not matched ... the metadata proxy is only\nreachable because INPUT policy is ACCEPT.\n\nThis change removes the destination constraint in the ACCEPT rule.\n\nChange-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6\nCloses-Bug: #1399462\n'}]",2,141045,2d9d77747d2a16a1bf944e15bf5a7b6fc5e3fe08,181,31,10,8124,,,0,"Correct l3-agent iptables rule for metadata proxy

2 iptables rules are defined to ensure the metadata proxy is reachable
from vms on 169.254.169.254:80:
* REDIRECT 169.254.169.254:80 packets to the router on port 9697
* ACCEPT traffic to 127.0.0.1 on port 9697

The REDIRECT rule replaces destination ip by:
 * 127.0.0.1 if the packet is local,
 * router ip (the one on the input interface, metadata proxy case).

So ACCEPT rule filter is not matched ... the metadata proxy is only
reachable because INPUT policy is ACCEPT.

This change removes the destination constraint in the ACCEPT rule.

Change-Id: Iea700bdd121bbc56a3489a63e2a5391867fad0d6
Closes-Bug: #1399462
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/141045/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/tests/unit/test_l3_agent.py']",2,d6befb534c93f19b0ba6af4b019edbac26d629f9,bug/1399462," rules = ('INPUT', '-s 0.0.0.0/0 -p tcp -m tcp --dport 8775 -j ACCEPT')"," rules = ('INPUT', '-s 0.0.0.0/0 -d 127.0.0.1 ' '-p tcp -m tcp --dport 8775 -j ACCEPT')",2,4
openstack%2Fmonasca-api~master~I958512ab2d324fc6a98bc65abaa92d02daa87f75,openstack/monasca-api,master,I958512ab2d324fc6a98bc65abaa92d02daa87f75,Check alarm description for NoneType,MERGED,2015-01-08 16:31:38.000000000,2015-01-08 17:05:07.000000000,2015-01-08 17:05:06.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2015-01-08 16:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/12524c8b4cd731ae402755bef1b5ed8d8eecee88', 'message': 'Check alarm description for NoneType\n\nChange-Id: I958512ab2d324fc6a98bc65abaa92d02daa87f75\n'}, {'number': 2, 'created': '2015-01-08 16:35:06.000000000', 'files': ['monasca/v2/reference/alarm_definitions.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/a092308cd4c45fbcb734ff0a7168035b53117244', 'message': 'Check alarm description for NoneType\n\nChange-Id: I958512ab2d324fc6a98bc65abaa92d02daa87f75\n'}]",0,145827,a092308cd4c45fbcb734ff0a7168035b53117244,7,2,2,12512,,,0,"Check alarm description for NoneType

Change-Id: I958512ab2d324fc6a98bc65abaa92d02daa87f75
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/27/145827/2 && git format-patch -1 --stdout FETCH_HEAD,['monasca/v2/reference/alarm_definitions.py'],1,12524c8b4cd731ae402755bef1b5ed8d8eecee88,," 'utf8') if alarm_definition_row['description'] else '',"," 'utf8'),",1,1
openstack%2Ftripleo-specs~master~I86762e3df6322b4c02998b529af827053baa91bb,openstack/tripleo-specs,master,I86762e3df6322b4c02998b529af827053baa91bb,Custom names,ABANDONED,2014-11-11 17:13:14.000000000,2015-01-08 16:49:25.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 7471}, {'_account_id': 8688}, {'_account_id': 9453}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-11-11 17:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f38792f08379530e2ab34e71d3a281b5aaa6445e', 'message': 'Custom names\n\nUsers want to be able to specify instance names. Specifically, 3PAR\nprovides two use-cases: instance names (and hence hostnames) need to be\n<32 characters; and hostname aliases are required for registration in\nDNS.\n\nChange-Id: I86762e3df6322b4c02998b529af827053baa91bb\nCo-Authored-By: nicholas.randon@hp.com\n'}, {'number': 2, 'created': '2014-11-13 15:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d95383f3ae57e9f57a5346df9c789ab7cb2eff3e', 'message': 'Custom names\n\nUsers want to be able to specify instance names. Specifically, 3PAR\nprovides two use-cases: instance names (and hence hostnames) need to be\n<32 characters; and hostname aliases are required for registration in\nDNS.\n\nChange-Id: I86762e3df6322b4c02998b529af827053baa91bb\nCo-Authored-By: nicholas.randon@hp.com\n'}, {'number': 3, 'created': '2014-12-10 10:40:51.000000000', 'files': ['specs/kilo/custom-names.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d45088b63748b98c5191a1e2582bf544572acea7', 'message': 'Custom names\n\nUsers want to be able to specify instance names. Specifically, 3PAR\nprovides two use-cases: instance names (and hence hostnames) need to be\n<32 characters; and hostname aliases are required for registration in\nDNS.\n\nChange-Id: I86762e3df6322b4c02998b529af827053baa91bb\nCo-Authored-By: nicholas.randon@hp.com\n'}]",6,133762,d45088b63748b98c5191a1e2582bf544572acea7,16,6,3,8688,,,0,"Custom names

Users want to be able to specify instance names. Specifically, 3PAR
provides two use-cases: instance names (and hence hostnames) need to be
<32 characters; and hostname aliases are required for registration in
DNS.

Change-Id: I86762e3df6322b4c02998b529af827053baa91bb
Co-Authored-By: nicholas.randon@hp.com
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/62/133762/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/custom-names.rst'],1,f38792f08379530e2ab34e71d3a281b5aaa6445e,bp/custom-names,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============ Custom names ============ https://blueprints.launchpad.net/tripleo/kilo-custom-names Users want to be able to specify instance names. Specifically, 3PAR provides two use-cases: instance names (and hence hostnames) need to be <32 characters; and hostname aliases are required for registration in DNS. Problem Description =================== Overview -------- Background ~~~~~~~~~~ An Ironic instance has at least two names - the instance name and the hostname. At present these always match. It may also have host aliases, registered in external DNS, which should be locally recognised. There's no way to add these right now. 3PAR hostname length ~~~~~~~~~~~~~~~~~~~~ At present, TripleO instance names are auto-generated by Heat. They are composed of the stack name, the node deployment role and a random string. When a long stack name is used, the total length can exceed the maximum hostname length accepted by 3PAR (31 characters). This limit is present in the 3PAR firmware and so cannot easily be patched. Physical location ~~~~~~~~~~~~~~~~~ Another situation where a deployer may want to set the instance name is to include the node's physical location. For example, to have ""rack1node3"" instead of ""cloud-novacompute0-45csd6"". End-user names ~~~~~~~~~~~~~~ However, this is less interesting to an end-user, who is likely to want a name meaningful to them like ""www"". We need to be able to support both the deployer and end-user's requirements. Multi-layer ~~~~~~~~~~~ The final solution should not depend on Heat. That is, you should be able to customise the instance name and add host aliases when creating a node from the Nova CLI. *[we can do this already...]* Proposed Change =============== * Ironic: * If an instance name is not specified, use one from metadata * If there isn't one in the metadata, fail * Nova CLI: * Allow instances to be created without a name * Provide a way to supply Ironic metadata *[may already exist?]* * Heat: * Only autogenerate an instance name if Ironic doesn't have one *[layer violation?]* Alternatives ------------ Patch [1]_ shows how to set instance names from Heat. Self-evidently, this requires Heat. It also has trouble if the instance name should depend on the physical location - this is soluble but messy. Security Impact --------------- * Does this change touch sensitive data such as tokens, keys, or user data? * No. * Does this change involve cryptography or hashing? * No. * Does this change require the use of sudo or any elevated privileges? * Yes, to add hostname aliases. I don't think this is a serious security issue. * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Yes, hostnames. We can fail if a hostname contains characters like spaces or punctuation which are not allowed in hostnames. * Can this change enable a resource exhaustion attack? * No. Other End User Impact --------------------- Users will be able to specify instance names and host aliases by providing Ironic metadata. Instructions for doing so should be provided. Performance Impact ------------------ * Heat must make an additional call to Ironic to determine if Heat needs to autogenerate an instance name. This is not expected to have a significant performance impact. Other Deployer Impact --------------------- * What config options are being added? * None. * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * Immediate. * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. * No impact. Developer Impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: nicholas-randon Other contributors: lxsli Work Items ---------- TBD Dependencies ============ None. Testing ======= TBD *[Is this untestable in CI given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc).]* Documentation Impact ==================== Users will be able to specify instance names and host aliases by providing Ironic metadata. Instructions for doing so should be provided. References ========== .. [1] https://review.openstack.org/#/c/132301/ ",,193,0
openstack%2Ftripleo-image-elements~master~I5e3429ec9f1935fcc6c3201412f8c57ec46408ab,openstack/tripleo-image-elements,master,I5e3429ec9f1935fcc6c3201412f8c57ec46408ab,Send multiple signals,ABANDONED,2014-10-20 16:12:07.000000000,2015-01-08 16:48:51.000000000,,"[{'_account_id': 3}, {'_account_id': 7579}, {'_account_id': 8449}, {'_account_id': 8688}, {'_account_id': 10035}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-10-20 16:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/428c944fb223c01a1affba15765bd08e6ed59a2a', 'message': 'Send multiple signals\n\nAllow ""completion-signal"" and ""completion-handle"" to be lists. If they\nare, curl each URL in each list.\n\nChange-Id: I5e3429ec9f1935fcc6c3201412f8c57ec46408ab\nDepends-On: I406cbd2d974544ed5948e137359629184d8ee156\n'}, {'number': 2, 'created': '2014-10-20 17:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/47d46fe043bfbf9bde2fc2bdebea8a386bc8a67a', 'message': 'Send multiple signals\n\nAllow ""completion-signal"" and ""completion-handle"" to be lists. If they\nare, curl each URL in each list.\n\nChange-Id: I5e3429ec9f1935fcc6c3201412f8c57ec46408ab\nDepends-On: I406cbd2d974544ed5948e137359629184d8ee156\n'}, {'number': 3, 'created': '2014-10-22 16:48:55.000000000', 'files': ['elements/os-refresh-config/os-refresh-config/post-configure.d/99-refresh-completed'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b64ef1d4ae31ea97960dbad6f06b343d0a780311', 'message': 'Send multiple signals\n\nAllow ""completion-signal"" and ""completion-handle"" to be lists. If they\nare, curl each URL in each list. All URLs will be called (in series)\neven if some return non-200 status, this provides a modicum of resiliency.\n\nChange-Id: I5e3429ec9f1935fcc6c3201412f8c57ec46408ab\nDepends-On: I406cbd2d974544ed5948e137359629184d8ee156\n'}]",3,129658,b64ef1d4ae31ea97960dbad6f06b343d0a780311,17,6,3,8688,,,0,"Send multiple signals

Allow ""completion-signal"" and ""completion-handle"" to be lists. If they
are, curl each URL in each list. All URLs will be called (in series)
even if some return non-200 status, this provides a modicum of resiliency.

Change-Id: I5e3429ec9f1935fcc6c3201412f8c57ec46408ab
Depends-On: I406cbd2d974544ed5948e137359629184d8ee156
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/58/129658/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/os-refresh-config/os-refresh-config/post-configure.d/99-refresh-completed'],1,428c944fb223c01a1affba15765bd08e6ed59a2a,,"set -eu status=$(curl -s -w %{http_code} -X $method -H 'Content-Type:' -o $output \ --data-binary ""{\""Status\"" : \""SUCCESS\"",\""Reason\"" : \""Configuration Complete\"",\""UniqueId\"" : \""$ID\"",\""Data\"" : \""Finished os-refresh-config.\""}"" $url)try_signal() { local method=$1 local key=$2 local url=$(os-apply-config --key ""$key"" --type raw --key-default """") if [ -n ""$url"" ]; then echo call_curl ""$method"" ""$url"" else return 1 fi } signal_loop() { local method=$1 local key_part=$2 local key_stem=""completion-${key_part}"" local index=0 while true; do if ! try_signal ""$method"" ""${key_stem}.${index}""; then break fi index=$(($index + 1)) done if [ $index -eq 0 ]; then try_signal ""$method"" ""${key_stem}"" fi } signal_loop PUT handle signal_loop POST signal","set -eux HANDLE=$(os-apply-config --key completion-handle --type raw --key-default """") SIGNAL=$(os-apply-config --key completion-signal --type raw --key-default """") status=$(curl -s -w %{http_code} -X $method -H 'Content-Type:' -o $output --data-binary ""{\""Status\"" : \""SUCCESS\"",\""Reason\"" : \""Configuration Complete\"",\""UniqueId\"" : \""$ID\"",\""Data\"" : \""Finished os-refresh-config.\""}"" $url)# Signals use POST, wait handles use PUT if [ -n ""$HANDLE"" ]; then call_curl PUT $HANDLE fi if [ -n ""$SIGNAL"" ]; then call_curl POST $SIGNAL fi",35,11
openstack%2Ftripleo-incubator~master~I329818ccaf0aba6ba80f21774c1278e6473f5447,openstack/tripleo-incubator,master,I329818ccaf0aba6ba80f21774c1278e6473f5447,Promote HEAT_ENV over env vars,ABANDONED,2014-05-23 10:17:58.000000000,2015-01-08 16:48:34.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 7144}, {'_account_id': 8688}, {'_account_id': 9453}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-05-23 10:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/939fc3546ca597a2a614fcd3d365f359e9c850ac', 'message': 'Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, env vars should\nbe relegated to providing defaults. IE the env values will only be used\nif the corresponding key is absent from the HEAT_ENV file.\n\nFurthers blueprint promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n'}, {'number': 2, 'created': '2014-07-29 09:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9f1ad3a84d2f5dd4ebbf250f06a6783627c2627a', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}, {'number': 3, 'created': '2014-07-29 09:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/5182381d4e6f40a7d3a540a976a0cde3009899cb', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}, {'number': 4, 'created': '2014-07-30 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/a50a92133b9975413f80df64db83363c60354aed', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}, {'number': 5, 'created': '2014-07-30 20:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/1162016d3c833dd06f2a7a461bf19143363b47ed', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}, {'number': 6, 'created': '2014-07-31 06:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/20478d6432494cdf12ce39bce55ad379b35dc66b', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint tripleo-juno-promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}, {'number': 7, 'created': '2014-07-31 07:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/0147dfd7095f3f83a18ef212e24f74a42d2dced2', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint tripleo-juno-promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}, {'number': 8, 'created': '2014-07-31 09:18:29.000000000', 'files': ['scripts/devtest_undercloud.sh', 'scripts/devtest_overcloud.sh', 'scripts/write-tripleorc'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/94642fbde60c7f3ce6d216d8fdfddcfbd95e3f98', 'message': ""Promote HEAT_ENV over env vars\n\nCurrently, if you have a number of environment variables set, those\nvalues will override anything set in the HEAT_ENV file. To transition to\nthat file being the source of truth for configuration, these env vars\nmust be ignored.\n\n  * Add USER_HEAT_ENV to both scripts.\n  * Don't set ENV_JSON from old env vars.\n  * Add default values to ENV_JSON.\n  * Add ignored variables warning to both scripts.\n  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.\n\nFurthers blueprint tripleo-juno-promote-heat-env\n\nSpec: Idb49477f4b37474aac11c680a837be17b696a18d\nChange-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447\n""}]",7,95130,94642fbde60c7f3ce6d216d8fdfddcfbd95e3f98,48,6,8,8688,,,0,"Promote HEAT_ENV over env vars

Currently, if you have a number of environment variables set, those
values will override anything set in the HEAT_ENV file. To transition to
that file being the source of truth for configuration, these env vars
must be ignored.

  * Add USER_HEAT_ENV to both scripts.
  * Don't set ENV_JSON from old env vars.
  * Add default values to ENV_JSON.
  * Add ignored variables warning to both scripts.
  * Remove OVERCLOUD_LIBVIRT_TYPE from write-tripleorc.

Furthers blueprint tripleo-juno-promote-heat-env

Spec: Idb49477f4b37474aac11c680a837be17b696a18d
Change-Id: I329818ccaf0aba6ba80f21774c1278e6473f5447
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/30/95130/8 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,939fc3546ca597a2a614fcd3d365f359e9c850ac,90983,"## #. We need an environment file to store the parameters we're going to give ""MysqlInnodbBufferPoolSize"": 100, } + .parameters' <<< $ENV_JSON) ""ControlVirtualInterface"": ""'${OVERCLOUD_VIRTUAL_INTERFACE}'"", } + .parameters' <<< $ENV_JSON)","## #. We need an environment file to store the parameters we're gonig to give ""MysqlInnodbBufferPoolSize"": 100 } + .parameters + { }' <<< $ENV_JSON) ""ControlVirtualInterface"": ""'${OVERCLOUD_VIRTUAL_INTERFACE}'"" } + .parameters + { }' <<< $ENV_JSON)",5,7
openstack%2Ftripleo-heat-templates~master~Iac68ed93c616f8348f644e1121eba2c217489060,openstack/tripleo-heat-templates,master,Iac68ed93c616f8348f644e1121eba2c217489060,Split allNodesConfig,ABANDONED,2014-09-30 12:44:15.000000000,2015-01-08 16:48:21.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 8688}, {'_account_id': 10035}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-09-30 12:44:15.000000000', 'files': ['nova-compute-instance.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ccea0606ecc02c7bcf037a667018046d4e051f2c', 'message': ""Split allNodesConfig\n\nCurrently, allNodesConfig contains info on both controller and compute\nnodes. The controllers don't really need to know where the compute nodes\nare and vice versa. Separate allNodesConfig into\nnovaComputeAllNodesConfig and controllerAllNodesConfig.\n\nThis will reduce the number of metadata pushes to controllers and thus\nreduce the chance of racy service restarts colliding. Not to mention\nmaking it easier to see what's going on.\n\nChange-Id: Iac68ed93c616f8348f644e1121eba2c217489060\n""}]",0,125025,ccea0606ecc02c7bcf037a667018046d4e051f2c,10,5,1,8688,,,0,"Split allNodesConfig

Currently, allNodesConfig contains info on both controller and compute
nodes. The controllers don't really need to know where the compute nodes
are and vice versa. Separate allNodesConfig into
novaComputeAllNodesConfig and controllerAllNodesConfig.

This will reduce the number of metadata pushes to controllers and thus
reduce the chance of racy service restarts colliding. Not to mention
making it easier to see what's going on.

Change-Id: Iac68ed93c616f8348f644e1121eba2c217489060
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/125025/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova-compute-instance.yaml', 'overcloud-source.yaml']",2,ccea0606ecc02c7bcf037a667018046d4e051f2c,," novaComputeAllNodesConfig: type: OS::Heat::StructuredConfig properties: config: completion-signal: {get_input: deploy_signal_id} hosts: Fn::Join: - ""\n"" - - Fn::Join: - ""\n"" - Merge::Map: NovaCompute0: Fn::Join: - ' ' - - {get_attr: [NovaCompute0, networks, ctlplane, 0]} - {get_attr: [NovaCompute0, name]} - Fn::Join: - '.' - - {get_attr: [NovaCompute0, name]} - 'novalocal' NovaComputeAllNodesConfig: {get_resource: novaComputeAllNodesConfig} config: {get_resource: controllerAllNodesConfig} controllerAllNodesConfig:"," AllNodesConfig: {get_resource: allNodesConfig} config: {get_resource: allNodesConfig} allNodesConfig: NovaCompute0: Fn::Join: - ' ' - - {get_attr: [NovaCompute0, networks, ctlplane, 0]} - {get_attr: [NovaCompute0, name]} - Fn::Join: - '.' - - {get_attr: [NovaCompute0, name]} - 'novalocal' - Fn::Join: - ""\n"" - Merge::Map:",25,17
openstack%2Fpuppet-neutron~stable%2Ficehouse~Iac73b475bfc8ac7f9f97a858ab836a4d07afac5f,openstack/puppet-neutron,stable/icehouse,Iac73b475bfc8ac7f9f97a858ab836a4d07afac5f,/etc/default/neutron-server file is only on Ubuntu packages,MERGED,2015-01-06 10:31:11.000000000,2015-01-08 16:44:37.000000000,2015-01-08 16:44:37.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-06 10:31:11.000000000', 'files': ['spec/classes/neutron_plugins_ml2_spec.rb', 'spec/classes/neutron_plugins_linuxbridge_spec.rb', 'manifests/plugins/cisco.pp', 'manifests/plugins/ml2.pp', 'manifests/plugins/linuxbridge.pp', 'spec/classes/neutron_plugins_cisco_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f864f50a61b547ba7f4cf7cfe788a54eb30727e4', 'message': ""/etc/default/neutron-server file is only on Ubuntu packages\n\nThe /etc/default/neutron-server file is only present in Ubuntu packages,\nnot in Debian.\nLet's change the fact to detect Ubuntu instead of Debian operating\nsystem.\n\nChange-Id: Iac73b475bfc8ac7f9f97a858ab836a4d07afac5f\n(cherry picked from commit ef3ca7f93c29ebe6fbf40788cc4d4bc72182e2a2)\n""}]",0,145191,f864f50a61b547ba7f4cf7cfe788a54eb30727e4,10,4,1,7888,,,0,"/etc/default/neutron-server file is only on Ubuntu packages

The /etc/default/neutron-server file is only present in Ubuntu packages,
not in Debian.
Let's change the fact to detect Ubuntu instead of Debian operating
system.

Change-Id: Iac73b475bfc8ac7f9f97a858ab836a4d07afac5f
(cherry picked from commit ef3ca7f93c29ebe6fbf40788cc4d4bc72182e2a2)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/91/145191/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_spec.rb', 'spec/classes/neutron_plugins_linuxbridge_spec.rb', 'manifests/plugins/cisco.pp', 'manifests/plugins/ml2.pp', 'manifests/plugins/linuxbridge.pp', 'spec/classes/neutron_plugins_cisco_spec.rb']",6,f864f50a61b547ba7f4cf7cfe788a54eb30727e4,," context 'on Ubuntu operating systems' do before do facts.merge!({:operatingsystem => 'Ubuntu'}) end it 'configures /etc/default/neutron-server' do should contain_file_line('/etc/default/neutron-server:NEUTRON_PLUGIN_CONFIG').with( :path => '/etc/default/neutron-server', :match => '^NEUTRON_PLUGIN_CONFIG=(.*)$', :line => 'NEUTRON_PLUGIN_CONFIG=/etc/neutron/plugins/cisco/cisco_plugins.ini', :require => ['Package[neutron-server]', 'Package[neutron-plugin-cisco]'], :notify => 'Service[neutron-server]' ) end it_configures 'default cisco plugin' end context 'on Debian operating systems' do before do facts.merge!({:operatingsystem => 'Debian'}) end it_configures 'default cisco plugin'"," it_configures 'default cisco plugin' it 'configures /etc/default/neutron-server' do should contain_file_line('/etc/default/neutron-server:NEUTRON_PLUGIN_CONFIG').with( :line => 'NEUTRON_PLUGIN_CONFIG=/etc/neutron/plugins/cisco/cisco_plugins.ini', :require => ['Package[neutron-server]', 'Package[neutron-plugin-cisco]'] )",64,26
openstack%2Fpuppet-glance~master~I7aa1918c481e842bc7d555f87dda7eb78b003483,openstack/puppet-glance,master,I7aa1918c481e842bc7d555f87dda7eb78b003483,Fix typo,MERGED,2015-01-07 13:01:01.000000000,2015-01-08 16:43:37.000000000,2015-01-08 16:43:37.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-07 13:01:01.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/81f58412602466db083c29ca5a768761590a7a0e', 'message': 'Fix typo\n\nChange-Id: I7aa1918c481e842bc7d555f87dda7eb78b003483\n'}]",0,145490,81f58412602466db083c29ca5a768761590a7a0e,12,3,1,10540,,,0,"Fix typo

Change-Id: I7aa1918c481e842bc7d555f87dda7eb78b003483
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/90/145490/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,81f58412602466db083c29ca5a768761590a7a0e,fix-typo,# base glance config.,# base glacne config.,1,1
openstack%2Fkeystone-specs~master~I952c953eda5e8c27ee0aa2008a382715f9e256c3,openstack/keystone-specs,master,I952c953eda5e8c27ee0aa2008a382715f9e256c3,Standardize federated scoping process.,MERGED,2015-01-06 11:34:04.000000000,2015-01-08 16:40:13.000000000,2015-01-08 16:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 1228}, {'_account_id': 1916}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8978}, {'_account_id': 13478}]","[{'number': 1, 'created': '2015-01-06 11:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/5dd8be26d45025a2561b1e9ef5e457f05c1bea87', 'message': 'Standardize federated scoping process.\n\nFor a greater standardization and better compatibility federated tokens\nscoping should be carried out with use of ``token`` authentication\nmethod.\n\nChange-Id: I952c953eda5e8c27ee0aa2008a382715f9e256c3\nImplements: blueprint federation-token-scoping\n'}, {'number': 2, 'created': '2015-01-07 00:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/af7d2a0ebdeed6d685b1aa5845b5e8cfdb09ac2c', 'message': 'Standardize federated scoping process.\n\nFor a authentication process standardization and consistency, federated tokens\nscoping step should be carried out with use of ``token`` authentication\nmethod.\n\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\n\nChange-Id: I952c953eda5e8c27ee0aa2008a382715f9e256c3\nImplements: blueprint federation-token-scoping\n'}, {'number': 3, 'created': '2015-01-07 15:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/335c1aabd8cd075cd2ea0456aa38ae99794fd374', 'message': 'Standardize federated scoping process.\n\nFor authentication process standardization and consistency, the\nfederated tokens scoping step should be carried out with the use of the\n``token`` authentication method.\n\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\n\nChange-Id: I952c953eda5e8c27ee0aa2008a382715f9e256c3\nImplements: blueprint federation-token-scoping\n'}, {'number': 4, 'created': '2015-01-08 08:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/45b7934243a7a4c9444629d372544db4336e3a3d', 'message': 'Standardize federated scoping process.\n\nFor authentication process standardization and consistency, the\nfederated tokens scoping step should be carried out with the use of the\n``token`` authentication method.\n\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\n\nChange-Id: I952c953eda5e8c27ee0aa2008a382715f9e256c3\nImplements: blueprint federation-token-scoping\n'}, {'number': 5, 'created': '2015-01-08 15:39:01.000000000', 'files': ['specs/kilo/federation-token-scoping.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/dce94fedc48722813a29376b2cd7639a892ebf85', 'message': 'Standardize federated scoping process.\n\nFor authentication process standardization and consistency, the\nfederated tokens scoping step should be carried out with the use of the\n``token`` authentication method.\n\nCo-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>\n\nChange-Id: I952c953eda5e8c27ee0aa2008a382715f9e256c3\nImplements: blueprint federation-token-scoping\n'}]",40,145204,dce94fedc48722813a29376b2cd7639a892ebf85,34,9,5,8978,,,0,"Standardize federated scoping process.

For authentication process standardization and consistency, the
federated tokens scoping step should be carried out with the use of the
``token`` authentication method.

Co-Authored-By: Steve Martinelli <stevemar@ca.ibm.com>

Change-Id: I952c953eda5e8c27ee0aa2008a382715f9e256c3
Implements: blueprint federation-token-scoping
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/04/145204/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/federation-token-scoping.rst'],1,5dd8be26d45025a2561b1e9ef5e457f05c1bea87,bp/federation-token-scoping,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Scope federation tokens with ``token`` authentication method ============================================================ `bp federation-token-scoping <https://blueprints.launchpad.net/keystone/+spec/federation-token-scoping>`_ For a better compatilibity scoping unscoped *federated* tokens should be carried out with use of standar ``token`` authentication method. Problem Description =================== Curently unscoped federated tokens must be scoped with use of dedicated authentication method - ``saml2`` (or more generic - ``mapped``). This can be unified with a classic scoping workflow, hence authentication method ``token`` should also be used. Proposed Change =============== The proposed solution is two fold: * Mark authentication methods ``mapped`` and ``saml2`` as deprecated. * Properly handle scoping federated tokens via ``token`` authentication method. Alternatives ------------ None Security Impact --------------- * Does this change touch sensitive data such as tokens, keys, or user data? Yes, but the change doesn't change any established security mechanisms. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? No. * Does this change involve cryptography or hashing? Yes, but doesn't working and established behaviours present in OpenStack. * Does this change require the use of sudo or any elevated privileges? No. * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. Yes, but doesn't working and established behaviours present in OpenStack. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. No. Notifications Impact -------------------- None. Other End User Impact --------------------- All the clients will need to be changed so the new authentication method is utilized. This also included relevant changes in ``python-keystoneclient``. Performance Impact ------------------ No performance changes. Other Deployer Impact --------------------- None. Developer Impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Marek Denis <marek.denis> Work Items ---------- * Deprecate default authentication method of federated tokens * Implement requred change in Keystone * Update documentation Dependencies ============ None Documentation Impact ==================== Documentation must be updated. References ========== Keystone change proposal: https://review.openstack.org/#/c/130593 ",,129,0
openstack%2Fironic~master~I3a0c899b322dbdab467bb825b7a3435fe5ad7ebf,openstack/ironic,master,I3a0c899b322dbdab467bb825b7a3435fe5ad7ebf,Updated from global requirements,MERGED,2015-01-08 02:29:18.000000000,2015-01-08 16:10:24.000000000,2015-01-08 16:10:23.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-08 02:29:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e7844592385feb86dd420ad77975a2527e7cf3b8', 'message': 'Updated from global requirements\n\nChange-Id: I3a0c899b322dbdab467bb825b7a3435fe5ad7ebf\n'}]",0,145665,e7844592385feb86dd420ad77975a2527e7cf3b8,10,4,1,11131,,,0,"Updated from global requirements

Change-Id: I3a0c899b322dbdab467bb825b7a3435fe5ad7ebf
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/145665/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e7844592385feb86dd420ad77975a2527e7cf3b8,openstack/requirements,oslo.db>=1.3.0 # Apache-2.0,oslo.db>=1.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~I84601e21c89b6f2354853b9c8c4b2efe694c7489,openstack/openstack-manuals,master,I84601e21c89b6f2354853b9c8c4b2efe694c7489,Adding Network layers information,MERGED,2014-12-23 18:33:17.000000000,2015-01-08 16:09:15.000000000,2015-01-08 16:09:13.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 4656}, {'_account_id': 6547}, {'_account_id': 7244}, {'_account_id': 9382}, {'_account_id': 14396}]","[{'number': 1, 'created': '2014-12-23 18:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eef7383416d3af672ae794f2f7e0fff9d18b576a', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 2, 'created': '2014-12-23 20:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fb049478148df8bbf091f2269d5d41e7bd23b344', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 3, 'created': '2014-12-23 21:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d2b8aac4dd1ea6b9c285c875b2ac91d1f048e7e0', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 4, 'created': '2014-12-23 22:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fa508ad8a414e58b73f048e0bec6e01f76f334c4', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 5, 'created': '2014-12-23 22:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/91138218d654016e4fa90bbf0a8c1bcacb0d0869', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 6, 'created': '2014-12-24 17:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c570b92c35f736d43b9fc00ccc03d17fd98a2ecc', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 7, 'created': '2014-12-24 17:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/829881d69d072467429123c2dc93c8b1cb24740f', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 8, 'created': '2015-01-02 15:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6b89c8f9a662945045a3d6fda72178d30bf52686', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 9, 'created': '2015-01-02 18:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/18a850462d46587625c45d4bfc90bb7042a596f6', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 10, 'created': '2015-01-07 20:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c1ba18cf75c6d77f31538a9690b25f2d68ee91c3', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}, {'number': 11, 'created': '2015-01-07 20:50:54.000000000', 'files': ['doc/networking-guide/section_intro-layers.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/59910692478858e6382b5ee057303dd66f3051c6', 'message': 'Adding Network layers information\n\nAdding OSI model information to network docs\n\nChange-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489\nCloses-Bug:1405244\n'}]",7,143710,59910692478858e6382b5ee057303dd66f3051c6,38,8,11,7244,,,0,"Adding Network layers information

Adding OSI model information to network docs

Change-Id: I84601e21c89b6f2354853b9c8c4b2efe694c7489
Closes-Bug:1405244
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/10/143710/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/section_intro-layers.xml'],1,eef7383416d3af672ae794f2f7e0fff9d18b576a,bug/1405244," <para>The application layer is the OSI layer closest to the end user, which means both the OSI application layer and the user interact directly with the software application.</para> <para>The presentation layer establishes context between application-layer entities, in which the application-layer entities may use different syntax and semantics if the presentation service provides a big mapping between them. If a mapping is available, presentation service data units are encapsulated into session protocol data units, and passed down the protocol stack.</para> <para>This layer provides independence from data representation (e.g., encryption) by translating between application and network formats. The presentation layer transforms data into the form that the application accepts. This layer formats and encrypts data to be sent across a network. It is sometimes called the syntax layer.</para> <para>The original presentation structure used the Basic Encoding Rules of Abstract Syntax Notation One (ASN.1), with capabilities such as converting an EBCDIC-coded text file to an ASCII-coded file, or serialization of objects and other data structures from and to XML.</para> <para>The session layer controls the dialogues (connections) between computers. It establishes, manages and terminates the connections between the local and remote application. It provides for full-duplex, half-duplex, or simplex operation, and establishes checkpointing, adjournment, termination, and restart procedures. The OSI model made this layer responsible for graceful close of sessions, which is a property of the Transmission Control Protocol, and also for session checkpointing and recovery, which is not usually used in the Internet Protocol Suite. The session layer is commonly implemented explicitly in application environments that use remote procedure calls.</para> <para>The transport layer provides the functional and procedural means of transferring variable-length data sequences from a source to a destination host via one or more networks, while maintaining the quality of service functions. An example of a transport-layer protocol in the standard Internet stack is Transmission Control Protocol (TCP), usually built on top of the Internet Protocol (IP).</para> <para>The network layer provides the functional and procedural means of transferring variable length data sequences (called datagrams) from one node to another connected to the same network. A network is a medium to which many nodes can be connected, on which every node has an address and which permits nodes connected to it to transfer messages to other nodes connected to it by merely providing the content of a message and the address of the destination node and letting the network find the way to deliver (""route"") the message to the destination node. In addition to message routing, the network may (or may not) implement message delivery by splitting the message into several fragments, delivering each fragment by a separate route and reassembling the fragments, report delivery errors, etc.</para> <para>Datagram delivery at the network layer is not guaranteed to be reliable.</para> <para>A number of layer-management protocols, a function defined in the management annex, ISO 7498/4, belong to the network layer. These include routing protocols, multicast group management, network-layer information and error, and network-layer address assignment. It is the function of the payload that makes these belong to the network layer, not the protocol that carries them.</para> <para>The data link layer provides a reliable link between two directly connected nodes, by detecting and possibly correcting errors that may occur in the physical layer. The data link layer is divided into two sublayers: * Media Access Control (MAC) layer - responsible for controlling how computers in the network gain access to data and permission to transmit it. * Logical Link Control (LLC) layer - controls error checking and packet synchronization. The Point-to-Point Protocol (PPP) is an example of a data link layer in the TCP/IP protocol stack.</para> <para>Defines the electrical and physical specifications of the data connection. It defines the relationship between a device and a physical transmission medium (e.g., a copper or fiber optical cable). This includes the layout of pins, voltages, line impedance, cable specifications, signal timing, hubs, repeaters, network adapters, host bus adapters (HBA used in storage area networks) and more.The physical layer of Parallel SCSI operates in this layer, as do the physical layers of Ethernet and other local-area networks, such as Token Ring, FDDI, ITU-T G.hn, and IEEE 802.11 (Wi-Fi), as well as personal area networks such as Bluetooth and IEEE 802.15.4.</para>", <para>FIXME</para> <para>FIXME</para> <para>FIXME</para> <para>FIXME</para> <para>FIXME</para> <para>FIXME</para> <para>FIXME</para>,63,7
openstack%2Fopenstack-ansible~master~Ib0aea22df13d5717e81aaf829bb298f80b600909,openstack/openstack-ansible,master,Ib0aea22df13d5717e81aaf829bb298f80b600909,Restrict publicizing images to admin role,MERGED,2015-01-07 17:01:01.000000000,2015-01-08 16:04:38.000000000,2015-01-08 16:04:37.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 9884}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-01-07 17:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/120ae97175cdc658abbd11c61f0a49974e2de150', 'message': 'Restrict publicizing images to admin role\n\nAllowing users to publicize images could lead to a security hole where a\nuser could upload a malicious image (one that houses rootkits or other\nmalware).\n\nChange-Id: Ib0aea22df13d5717e81aaf829bb298f80b600909\nCloses-Bug: #1408363\n'}, {'number': 2, 'created': '2015-01-07 17:18:43.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ba10a9b6fedebbfd38a53274b2bf7186dc4b79d8', 'message': 'Restrict publicizing images to admin role\n\nAllowing users to publicize images could lead to a security hole where a\nuser could upload a malicious image (one that houses rootkits or other\nmalware).\n\nChange-Id: Ib0aea22df13d5717e81aaf829bb298f80b600909\nPartial-Bug: #1408363\n'}]",0,145542,ba10a9b6fedebbfd38a53274b2bf7186dc4b79d8,11,5,2,12892,,,0,"Restrict publicizing images to admin role

Allowing users to publicize images could lead to a security hole where a
user could upload a malicious image (one that houses rootkits or other
malware).

Change-Id: Ib0aea22df13d5717e81aaf829bb298f80b600909
Partial-Bug: #1408363
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/42/145542/2 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,120ae97175cdc658abbd11c61f0a49974e2de150,bug/1408363," ""publicize_image"": ""role:admin"","," ""publicize_image"": """",",1,1
openstack%2Fironic-inspector~master~Ie40fb585c11083c4d8943fd6edc9f5c999206c47,openstack/ironic-inspector,master,Ie40fb585c11083c4d8943fd6edc9f5c999206c47,Disable setting IPMI credentials by default,MERGED,2015-01-08 13:12:37.000000000,2015-01-08 16:00:37.000000000,2015-01-08 16:00:37.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-01-08 13:12:37.000000000', 'files': ['ironic_discoverd/test/test_discover.py', 'README.rst', 'ironic_discoverd/discover.py', 'ironic_discoverd/conf.py', 'example.conf'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/3e67296d41c62d080cba4693684e95ee81c12d6a', 'message': ""Disable setting IPMI credentials by default\n\nIt's unlikely we're going to have proper testing for this feature\nin 1.0.0 timeline, so let us not enable it by default.\n\nAlso updated release notes and example.conf to explicitly state\nexperimental nature of this feature.\n\nChange-Id: Ie40fb585c11083c4d8943fd6edc9f5c999206c47\nImplements: blueprint setup-ipmi-credentials\n""}]",0,145776,3e67296d41c62d080cba4693684e95ee81c12d6a,7,3,1,10239,,,0,"Disable setting IPMI credentials by default

It's unlikely we're going to have proper testing for this feature
in 1.0.0 timeline, so let us not enable it by default.

Also updated release notes and example.conf to explicitly state
experimental nature of this feature.

Change-Id: Ie40fb585c11083c4d8943fd6edc9f5c999206c47
Implements: blueprint setup-ipmi-credentials
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/76/145776/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test/test_discover.py', 'README.rst', 'ironic_discoverd/discover.py', 'ironic_discoverd/conf.py', 'example.conf']",5,3e67296d41c62d080cba4693684e95ee81c12d6a,bp/setup-ipmi-credentials,"; Whether to enable setting IPMI credentials during discovery. This is an ; experimental and not well tested feature, use at your own risk. ;enable_setting_ipmi_credentials = false",,31,3
openstack%2Fnova~master~Id8d8866baaf64721fda2b6b2e8358db18920c8ba,openstack/nova,master,Id8d8866baaf64721fda2b6b2e8358db18920c8ba,Add WarningsFixture to only emit DeprecationWarning once in a test run,MERGED,2015-01-07 22:28:28.000000000,2015-01-08 15:57:50.000000000,2015-01-08 09:13:47.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-07 22:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/570a5098df7174dd3e7013e3a8ec04bd1b9f737a', 'message': ""Add WarningsFixture to only emit DeprecationWarning once in a test run\n\nThe nova unit test console output can be flooded with deprecation\nwarnings from dependent libraries, this change makes it so they are only\nlogged once.\n\nIt's worth noting that Keystone has an alternative implementation where\nthey filter deprecation warnings and only error out if they are coming\nfrom Keystone code. See commit 9ae6ffe8a.\n\nPartial-Bug: #1407736\n\nCo-authoried-by: Sean Dauge <sean@dague.net>\n\nChange-Id: Id8d8866baaf64721fda2b6b2e8358db18920c8ba\n""}, {'number': 2, 'created': '2015-01-07 22:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69c9a5e496d0c515b1dd293b485b25a31283c42b', 'message': ""Add WarningsFixture to only emit DeprecationWarning once in a test run\n\nThe nova unit test console output can be flooded with deprecation\nwarnings from dependent libraries, this change makes it so they are only\nlogged once.\n\nIt's worth noting that Keystone has an alternative implementation where\nthey filter deprecation warnings and only error out if they are coming\nfrom Keystone code. See commit 9ae6ffe8a.\n\nPartial-Bug: #1407736\n\nCo-authoried-by: Sean Dague <sean@dague.net>\n\nChange-Id: Id8d8866baaf64721fda2b6b2e8358db18920c8ba\n""}, {'number': 3, 'created': '2015-01-07 22:36:41.000000000', 'files': ['nova/tests/fixtures.py', 'nova/test.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b718b52feba694bfe832021dbfbb2f8de5bffaab', 'message': ""Add WarningsFixture to only emit DeprecationWarning once in a test run\n\nThe nova unit test console output can be flooded with deprecation\nwarnings from dependent libraries, this change makes it so they are only\nlogged once.\n\nIt's worth noting that Keystone has an alternative implementation where\nthey filter deprecation warnings and only error out if they are coming\nfrom Keystone code. See commit 9ae6ffe8a.\n\nPartial-Bug: #1407736\n\nCo-authored-by: Sean Dague <sean@dague.net>\n\nChange-Id: Id8d8866baaf64721fda2b6b2e8358db18920c8ba\n""}]",0,145611,b718b52feba694bfe832021dbfbb2f8de5bffaab,16,10,3,6873,,,0,"Add WarningsFixture to only emit DeprecationWarning once in a test run

The nova unit test console output can be flooded with deprecation
warnings from dependent libraries, this change makes it so they are only
logged once.

It's worth noting that Keystone has an alternative implementation where
they filter deprecation warnings and only error out if they are coming
from Keystone code. See commit 9ae6ffe8a.

Partial-Bug: #1407736

Co-authored-by: Sean Dague <sean@dague.net>

Change-Id: Id8d8866baaf64721fda2b6b2e8358db18920c8ba
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/145611/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fixtures.py', 'nova/test.py']",2,570a5098df7174dd3e7013e3a8ec04bd1b9f737a,bug/1407736, self.useFixture(nova_fixtures.WarningsFixture()),,14,0
openstack%2Fironic-inspector~master~I048f1a1b3a70b7f44e4310e7c88d4522c475db55,openstack/ironic-inspector,master,I048f1a1b3a70b7f44e4310e7c88d4522c475db55,Add 'default' argument to conf.get* functions,MERGED,2015-01-07 16:36:19.000000000,2015-01-08 15:57:39.000000000,2015-01-08 15:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-01-07 16:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/cac180a5bdacb52d5cd01cf31e9a5afd4757066d', 'message': ""Add 'default' argument to conf.get* functions\n\nChange-Id: I048f1a1b3a70b7f44e4310e7c88d4522c475db55\nCloses-Bug: #1408352\n""}, {'number': 2, 'created': '2015-01-08 09:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/874d79f4a0bb04888ca5a9268e4449d63796c7bf', 'message': ""Add 'default' argument to conf.get* functions\n\nChange-Id: I048f1a1b3a70b7f44e4310e7c88d4522c475db55\nCloses-Bug: #1408352\n""}, {'number': 3, 'created': '2015-01-08 09:39:17.000000000', 'files': ['ironic_discoverd/conf.py', 'ironic_discoverd/node_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/f698bb2f09d1a45d1cb7d9d9b01914bfaa425f1a', 'message': ""Add 'default' argument to conf.get* functions\n\nChange-Id: I048f1a1b3a70b7f44e4310e7c88d4522c475db55\nCloses-Bug: #1408352\n""}]",2,145536,f698bb2f09d1a45d1cb7d9d9b01914bfaa425f1a,13,4,3,10239,,,0,"Add 'default' argument to conf.get* functions

Change-Id: I048f1a1b3a70b7f44e4310e7c88d4522c475db55
Closes-Bug: #1408352
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/36/145536/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/conf.py', 'ironic_discoverd/node_cache.py']",2,cac180a5bdacb52d5cd01cf31e9a5afd4757066d,bug/1408352," _DB_NAME = conf.get('discoverd', 'database', default='').strip()"," _DB_NAME = conf.get('discoverd', 'database').strip()",22,5
openstack%2Fironic-inspector~master~I1716697f2d04947143445ac6badf61453d0d6b17,openstack/ironic-inspector,master,I1716697f2d04947143445ac6badf61453d0d6b17,Remaining changes from making database a required option,MERGED,2015-01-08 09:37:21.000000000,2015-01-08 15:55:09.000000000,2015-01-08 15:55:09.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-01-08 09:37:21.000000000', 'files': ['example.conf', 'ironic_discoverd/test/test_node_cache.py', 'ironic_discoverd/node_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/d014d9f060c69adf2fa6c97af56bc18e9c7b6f89', 'message': 'Remaining changes from making database a required option\n\n* Update example.conf\n* Write missing test\n\nChange-Id: I1716697f2d04947143445ac6badf61453d0d6b17\n'}]",0,145732,d014d9f060c69adf2fa6c97af56bc18e9c7b6f89,7,3,1,10239,,,0,"Remaining changes from making database a required option

* Update example.conf
* Write missing test

Change-Id: I1716697f2d04947143445ac6badf61453d0d6b17
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/32/145732/1 && git format-patch -1 --stdout FETCH_HEAD,"['example.conf', 'ironic_discoverd/node_cache.py', 'ironic_discoverd/test/test_node_cache.py']",3,d014d9f060c69adf2fa6c97af56bc18e9c7b6f89,,"import tempfileimport unittest class TestInit(unittest.TestCase): def setUp(self): super(TestInit, self).setUp() conf.init_conf() conf.CONF.add_section('discoverd') node_cache._DB_NAME = None def test_ok(self): with tempfile.NamedTemporaryFile() as db_file: conf.CONF.set('discoverd', 'database', db_file.name) node_cache.init() self.assertIsNotNone(node_cache._DB_NAME) # Verify that table exists node_cache._db().execute(""select * from nodes"") def test_no_database(self): self.assertRaises(SystemExit, node_cache.init)",,25,3
openstack%2Ftripleo-image-elements~master~I9a31dc4af12f2f6657fd52ee2c73210884b70abe,openstack/tripleo-image-elements,master,I9a31dc4af12f2f6657fd52ee2c73210884b70abe,add ipv6 radvd package to neutron-router,MERGED,2014-12-24 08:25:27.000000000,2015-01-08 15:45:23.000000000,2015-01-08 15:45:23.000000000,"[{'_account_id': 3}, {'_account_id': 6671}, {'_account_id': 6928}, {'_account_id': 8449}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-24 08:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ef808d9c65819c5ecbcba7270bae267b1d244678', 'message': 'add ipv6 radvd package to neutron-router\n\nwith ipv6 radvd introduced in neutron l3 agent, radvd executable\nis needed to spawn a daemon to broadcast ip prefix and other\ninfo.\n\nChange-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe\nCloses-bug: #1404085\n'}, {'number': 2, 'created': '2015-01-04 07:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/15d59a837110cc58c1365efcfcc8f1931fb1e0be', 'message': 'add ipv6 radvd package to neutron-router\n\nwith ipv6 radvd introduced in neutron l3 agent, radvd executable\nis needed to spawn a daemon to broadcast ip prefix and other\ninfo.\n\nChange-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe\nCloses-bug: #1404085\n'}, {'number': 3, 'created': '2015-01-05 14:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c54aeccc4f975b907196f595786dc8f1d663c1e7', 'message': 'add ipv6 radvd package to neutron-router\n\nwith ipv6 radvd introduced in neutron l3 agent, radvd executable\nis needed to spawn a daemon to broadcast ip prefix and other\ninfo.\n\nChange-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe\nCloses-bug: #1404085\n'}, {'number': 4, 'created': '2015-01-05 14:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1e674511e947e550a6f3e77940a2239cb9e1efcf', 'message': 'add ipv6 radvd package to neutron-router\n\nwith ipv6 radvd introduced in neutron l3 agent, radvd executable\nis needed to spawn a daemon to broadcast ip prefix and other\ninfo.\n\nChange-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe\nCloses-bug: #1404085\n'}, {'number': 5, 'created': '2015-01-05 15:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/048a995d10b01766db032ef115e5842ad7299afd', 'message': 'add ipv6 radvd package to neutron-router\n\nwith ipv6 radvd introduced in neutron l3 agent, radvd executable\nis needed to spawn a daemon to broadcast ip prefix and other\ninfo.\n\nChange-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe\nCloses-bug: #1404085\n'}, {'number': 6, 'created': '2015-01-05 16:20:43.000000000', 'files': ['elements/neutron-router/pkg-map', 'elements/neutron-router/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/69d7f6c5f13eb61df1694498625f952f6d95e883', 'message': 'add ipv6 radvd package to neutron-router\n\nwith ipv6 radvd introduced in neutron l3 agent, radvd executable\nis needed to spawn a daemon to broadcast ip prefix and other\ninfo.\n\nChange-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe\nCloses-bug: #1404085\n'}]",0,143796,69d7f6c5f13eb61df1694498625f952f6d95e883,31,5,6,6671,,,0,"add ipv6 radvd package to neutron-router

with ipv6 radvd introduced in neutron l3 agent, radvd executable
is needed to spawn a daemon to broadcast ip prefix and other
info.

Change-Id: I9a31dc4af12f2f6657fd52ee2c73210884b70abe
Closes-bug: #1404085
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/96/143796/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/neutron-router/install.d/neutron-package-install/package-installs-neutron-router', 'elements/neutron-router/install.d/neutron-source-install/80-radvd', 'elements/neutron-router/element-deps']",3,ef808d9c65819c5ecbcba7270bae267b1d244678,bug/1404085,package-installs,,6,0
openstack%2Fironic-specs~master~I5882e2ef4d0d63e8dcc01e9c06d7343bf35473a3,openstack/ironic-specs,master,I5882e2ef4d0d63e8dcc01e9c06d7343bf35473a3,"Correct the diagram for the ""current"" state machine",MERGED,2015-01-07 20:16:02.000000000,2015-01-08 15:35:20.000000000,2015-01-08 15:35:20.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-01-07 20:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c0b60b94edbcd38b587d36a8a90ef59c81d99ab4', 'message': 'Correct the diagram for the ""current"" state machine\n\nAfter working on a formal model of the current state machine,\nit became apparent that the diagram in this spec did not match\nthe behavior in the Juno release.\n\nThis patch is simply a new diagram, based on the actual behavior\nin the Juno release.\n\nChange-Id: I5882e2ef4d0d63e8dcc01e9c06d7343bf35473a3\n'}, {'number': 2, 'created': '2015-01-07 21:37:12.000000000', 'files': ['specs/kilo/new-ironic-state-machine.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0469a1b3796e8a1d3c9c7875e5f0af7d1acc200e', 'message': 'Correct the diagram for the ""current"" state machine\n\nAfter working on a formal model of the current state machine, it became\napparent that the diagram in this spec did not match the behavior in the\nJuno release. The representation of ""momentary"" states is misleading --\nthese were never saved in or written to the node.provision_state field,\nand were instead just return values from function calls.\n\nAs the diagram was thus misleading, this patch replaces the diagram\nbased on the actual behavior in the Juno release.\n\nChange-Id: I5882e2ef4d0d63e8dcc01e9c06d7343bf35473a3\n'}]",2,145569,0469a1b3796e8a1d3c9c7875e5f0af7d1acc200e,16,8,2,2889,,,0,"Correct the diagram for the ""current"" state machine

After working on a formal model of the current state machine, it became
apparent that the diagram in this spec did not match the behavior in the
Juno release. The representation of ""momentary"" states is misleading --
these were never saved in or written to the node.provision_state field,
and were instead just return values from function calls.

As the diagram was thus misleading, this patch replaces the diagram
based on the actual behavior in the Juno release.

Change-Id: I5882e2ef4d0d63e8dcc01e9c06d7343bf35473a3
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/69/145569/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/new-ironic-state-machine.rst'],1,c0b60b94edbcd38b587d36a8a90ef59c81d99ab4,correct-current-state-machine-reference, NOSTATE//NONE +----------+------+\ [DEPLOYWAIT//DEPLOYDONE] ^ R:active + ^ | | | + v v [DELETING//DELETED] +--->[DEPLOYING//DEPLOYDONE] + ^ | + + | | R:rebuild| | | v | | | v ERROR//NONE | | | DEPLOYFAIL//NONE | | v | +---+ACTIVE//NONE | R:deleted + +---------------------------+ , NOSTATE//NONE -------------------\ ^ R:active | | | + | (DELETED//DELETED) | ^ v + +--->[DEPLOYING//DEPLOYDONE]---->DEPLOYFAIL//NONE [DELETING//DELETED] | + ^ | v | R:rebuild| (DEPLOYDONE//DEPLOYDONE) | | + | | v | +---+ACTIVE//NONE |R:deleted + | | +---------------------------+,14,16
openstack%2Fironic-inspector~master~I28f478acb6e0abd6fa38131aea18b392313b1264,openstack/ironic-inspector,master,I28f478acb6e0abd6fa38131aea18b392313b1264,Add configdrive plugin,ABANDONED,2015-01-02 16:07:52.000000000,2015-01-08 15:33:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-01-02 16:07:52.000000000', 'files': ['ironic_discoverd/utils.py', 'ironic_discoverd/plugins/configdrive.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/0086f95963965bd9ca69a0e03cd0bf7da70457a9', 'message': 'Add configdrive plugin\n\nChange-Id: I28f478acb6e0abd6fa38131aea18b392313b1264\n'}]",9,144769,0086f95963965bd9ca69a0e03cd0bf7da70457a9,6,3,1,6773,,,0,"Add configdrive plugin

Change-Id: I28f478acb6e0abd6fa38131aea18b392313b1264
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/69/144769/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/plugins/configdrive.py', 'ironic_discoverd/utils.py']",2,0086f95963965bd9ca69a0e03cd0bf7da70457a9,bp/configdrive,"import contextlibimport shutil import tempfile@contextlib.contextmanager def tempdir(**kwargs): tmpdir = tempfile.mkdtemp(**kwargs) try: yield tmpdir finally: try: shutil.rmtree(tmpdir) except OSError as e: LOG.error(_LE('Could not remove tmpdir: %s'), e) ",,110,0
openstack%2Ftripleo-heat-templates~master~If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8,openstack/tripleo-heat-templates,master,If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8,Puppet: overcloud controller config,MERGED,2014-12-20 02:53:43.000000000,2015-01-08 15:30:14.000000000,2015-01-08 14:54:58.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7585}]","[{'number': 1, 'created': '2014-12-20 02:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a53fa22f97a6ef2279ff570ab78e4f3f71fa72d8', 'message': ""Puppet: overcloud controller config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Controller::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud controller instance\nwhich has the controller node configured via Puppet\nstackforge modules. Initially this includes only the\nfollowing services:\n\n  MySQL\n  RabbitMQ\n  Keepalived/HAProxy (HA is not yet fully supported however)\n  Nova\n  Neutron\n  Keystone\n  Glance (file backend)\n  Cinder\n\nUsing these services it is possible to run devtest_overcloud.sh\nto completion. The idea is that we can quickly add more\nservices once we have CI in place.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n   os-net-config\n   heat-config-puppet\n   puppet-modules\n   hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron\nelements were NOT used to build the controller image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova) etc.\n\nChange-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8\n""}, {'number': 2, 'created': '2014-12-23 03:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/234bba0ac26391348245c8fb493b9231300da47a', 'message': ""Puppet: overcloud controller config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Controller::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud controller instance\nwhich has the controller node configured via Puppet\nstackforge modules. Initially this includes only the\nfollowing services:\n\n  MySQL\n  RabbitMQ\n  Keepalived/HAProxy (HA is not yet fully supported however)\n  Nova\n  Neutron\n  Keystone\n  Glance (file backend)\n  Cinder\n\nUsing these services it is possible to run devtest_overcloud.sh\nto completion. The idea is that we can quickly add more\nservices once we have CI in place.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n   os-net-config\n   heat-config-puppet\n   puppet-modules\n   hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron\nelements were NOT used to build the controller image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova) etc.\n\nChange-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8\n""}, {'number': 3, 'created': '2014-12-23 17:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4c500f9c7deb1f4b1caf84db591b03131c6ede10', 'message': ""Puppet: overcloud controller config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Controller::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud controller instance\nwhich has the controller node configured via Puppet\nstackforge modules. Initially this includes only the\nfollowing services:\n\n  MySQL\n  RabbitMQ\n  Keepalived/HAProxy (HA is not yet fully supported however)\n  Nova\n  Neutron\n  Keystone\n  Glance (file backend)\n  Cinder\n\nUsing these services it is possible to run devtest_overcloud.sh\nto completion. The idea is that we can quickly add more\nservices once we have CI in place.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n   os-net-config\n   heat-config-puppet\n   puppet-modules\n   hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron\nelements were NOT used to build the controller image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova) etc.\n\nChange-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8\n""}, {'number': 4, 'created': '2015-01-05 17:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1eda6b8dbeb5bc1b8aaaeb23a5bcd156cc29367c', 'message': ""Puppet: overcloud controller config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Controller::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud controller instance\nwhich has the controller node configured via Puppet\nstackforge modules. Initially this includes only the\nfollowing services:\n\n  MySQL\n  RabbitMQ\n  Keepalived/HAProxy (HA is not yet fully supported however)\n  Nova\n  Neutron\n  Keystone\n  Glance (file backend)\n  Cinder\n\nUsing these services it is possible to run devtest_overcloud.sh\nto completion. The idea is that we can quickly add more\nservices once we have CI in place.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n   os-net-config\n   heat-config-puppet\n   puppet-modules\n   hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron\nelements were NOT used to build the controller image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova) etc.\n\nChange-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8\n""}, {'number': 5, 'created': '2015-01-05 19:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4bb5882a4d86dbb32b049cb2bc6c4376078d970', 'message': ""Puppet: overcloud controller config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Controller::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud controller instance\nwhich has the controller node configured via Puppet\nstackforge modules. Initially this includes only the\nfollowing services:\n\n  MySQL\n  RabbitMQ\n  Keepalived/HAProxy (HA is not yet fully supported however)\n  Nova\n  Neutron\n  Keystone\n  Glance (file backend)\n  Cinder\n\nUsing these services it is possible to run devtest_overcloud.sh\nto completion. The idea is that we can quickly add more\nservices once we have CI in place.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n   os-net-config\n   heat-config-puppet\n   puppet-modules\n   hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron\nelements were NOT used to build the controller image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova) etc.\n\nChange-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8\n""}, {'number': 6, 'created': '2015-01-08 14:53:57.000000000', 'files': ['overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/overcloud_controller.pp', 'controller-config-puppet.yaml', 'puppet/hieradata/controller.yaml', 'puppet/loadbalancer.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9cf11371ac3a99648e21518059bfa310655769e0', 'message': ""Puppet: overcloud controller config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Controller::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud controller instance\nwhich has the controller node configured via Puppet\nstackforge modules. Initially this includes only the\nfollowing services:\n\n  MySQL\n  RabbitMQ\n  Keepalived/HAProxy (HA is not yet fully supported however)\n  Nova\n  Neutron\n  Keystone\n  Glance (file backend)\n  Cinder\n\nUsing these services it is possible to run devtest_overcloud.sh\nto completion. The idea is that we can quickly add more\nservices once we have CI in place.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n   os-net-config\n   heat-config-puppet\n   puppet-modules\n   hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron\nelements were NOT used to build the controller image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova) etc.\n\nChange-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8\n""}]",4,143244,9cf11371ac3a99648e21518059bfa310655769e0,38,7,6,360,,,0,"Puppet: overcloud controller config

This patch provides an alternate implementation of
the OS::TripleO::Controller::SoftwareConfig which uses Puppet
to drive the configuration. Using this it is possible
to create a fully functional overcloud controller instance
which has the controller node configured via Puppet
stackforge modules. Initially this includes only the
following services:

  MySQL
  RabbitMQ
  Keepalived/HAProxy (HA is not yet fully supported however)
  Nova
  Neutron
  Keystone
  Glance (file backend)
  Cinder

Using these services it is possible to run devtest_overcloud.sh
to completion. The idea is that we can quickly add more
services once we have CI in place.

In order to test this you'll want to build your images
with these elements:

   os-net-config
   heat-config-puppet
   puppet-modules
   hiera

None of the OpenStack specific TripleO elements
should be used with this approach (the nova/neutron
elements were NOT used to build the controller image).

Also, rather than use neutron-openvswitch-agent to configure
low level networking it is recommended that os-net-config
by configured directly via heat modeling rather than
parameter passing to init-neutron-ovs. This allows us to
configure the physical network while avoiding the coupling to
the neutron-openvswitch-element that our standard
parameter driven networking currently uses. (We still need
to move init-neutron-ovs so that it isn't coupled and/or deprecate
its use entirely because the heat drive stuff is more flexible.)

Packages may optionally be pre-installed via DIB using the
-p option (-p openstack-neutron,openstack-nova) etc.

Change-Id: If8462e4eacb08eced61a8b03fd7c3c4257e0b5b8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/143244/4 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry.yaml', 'overcloud-resource-registry-puppet.yaml', 'puppet/overcloud_controller.pp', 'controller-config-puppet.yaml', 'puppet/hieradata/controller.yaml', 'puppet/loadbalancer.pp']",6,a53fa22f97a6ef2279ff570ab78e4f3f71fa72d8,puppet,"# Copyright 2014 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class tripleo::loadbalancer ( $keystone_admin = false, $keystone_public = false, $neutron = false, $cinder = false, $glance_api = false, $glance_registry = false, $nova_ec2 = false, $nova_osapi = false, $nova_metadata = false, $nova_novncproxy = false, $ceilometer = false, $swift_proxy_server = false, $heat_api = false, $heat_cloudwatch = false, $heat_cfn = false, $horizon = false, $mysql = false, $rabbitmq = false, ) { case $::osfamily { 'RedHat': { $keepalived_name_is_process = false $keepalived_vrrp_script = 'systemctl status haproxy.service' } # RedHat 'Debian': { $keepalived_name_is_process = true $keepalived_vrrp_script = undef } } class { keepalived: } keepalived::vrrp_script { 'haproxy': name_is_process => $keepalived_name_is_process, script => $keepalived_vrrp_script, } # KEEPALIVE INSTANCE CONTROL keepalived::instance { '51': interface => hiera('control_virtual_interface'), virtual_ips => [join([hiera('controller_virtual_ip'), "" dev "", hiera('control_virtual_interface')])], state => 'MASTER', track_script => ['haproxy'], priority => 101, } # KEEPALIVE INSTANCE PUBLIC keepalived::instance { '52': interface => hiera('public_virtual_interface'), virtual_ips => [join([hiera('public_virtual_ip'), "" dev "", hiera('public_virtual_interface')])], state => 'MASTER', track_script => ['haproxy'], priority => 101, } sysctl::value { 'net.ipv4.ip_nonlocal_bind': value => '1' } class { 'haproxy': global_options => { 'log' => '/dev/log local0', 'pidfile' => '/var/run/haproxy.pid', 'user' => 'haproxy', 'group' => 'haproxy', 'daemon' => '', 'maxconn' => '4000', }, defaults_options => { 'mode' => 'tcp', 'log' => 'global', 'retries' => '3', 'maxconn' => '150', 'option' => [ 'tcpka', 'tcplog' ], 'timeout' => [ 'http-request 10s', 'queue 1m', 'connect 10s', 'client 1m', 'server 1m', 'check 10s' ], }, } haproxy::listen { 'haproxy.stats': ipaddress => '*', ports => '1993', mode => 'http', options => { 'stats' => 'enable', }, collect_exported => false, } if $keystone_admin { haproxy::listen { 'keystone_admin': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 35357, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'keystone_admin': listening_service => 'keystone_admin', ports => '35357', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $keystone_public { haproxy::listen { 'keystone_public': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 5000, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'keystone_public': listening_service => 'keystone_public', ports => '5000', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $neutron { haproxy::listen { 'neutron': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 9696, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'neutron': listening_service => 'neutron', ports => '9696', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $cinder { haproxy::listen { 'cinder': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8776, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'cinder': listening_service => 'cinder', ports => '8776', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $glance_api { haproxy::listen { 'glance_api': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 9292, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'glance_api': listening_service => 'glance_api', ports => '9292', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $glance_registry { haproxy::listen { 'glance_registry': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 9191, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'glance_registry': listening_service => 'glance_registry', ports => '9191', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $nova_ec2 { haproxy::listen { 'nova_ec2': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8773, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'nova_ec2': listening_service => 'nova_ec2', ports => '8773', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $nova_osapi { haproxy::listen { 'nova_osapi': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8774, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'nova_osapi': listening_service => 'nova_osapi', ports => '8774', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $nova_metadata { haproxy::listen { 'nova_metadata': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8775, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'nova_metadata': listening_service => 'nova_metadata', ports => '8775', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $nova_novncproxy { haproxy::listen { 'nova_novncproxy': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 6080, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'nova_novncproxy': listening_service => 'nova_novncproxy', ports => '6080', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $ceilometer { haproxy::listen { 'ceilometer': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8777, collect_exported => false, } haproxy::balancermember { 'ceilometer': listening_service => 'ceilometer', ports => '8777', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $swift_proxy_server { haproxy::listen { 'swift_proxy_server': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8080, options => { 'option' => [ ""httpchk GET /info"" ] }, collect_exported => false, } haproxy::balancermember { 'swift_proxy_server': listening_service => 'swift_proxy_server', ports => '8080', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $heat_api { haproxy::listen { 'heat_api': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8004, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'heat_api': listening_service => 'heat_api', ports => '8004', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $heat_cloudwatch { haproxy::listen { 'heat_cloudwatch': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8003, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'heat_cloudwatch': listening_service => 'heat_cloudwatch', ports => '8003', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $heat_cfn { haproxy::listen { 'heat_cfn': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 8000, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'heat_cfn': listening_service => 'heat_cfn', ports => '8000', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $horizon { haproxy::listen { 'horizon': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 80, options => { 'option' => [ ""httpchk GET /"" ] }, collect_exported => false, } haproxy::balancermember { 'horizon': listening_service => 'horizon', ports => '80', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $mysql { haproxy::listen { 'mysql': ipaddress => [hiera('controller_virtual_ip')], ports => 3306, options => { 'timeout' => [ ""client 0"", ""server 0"" ] }, collect_exported => false, } haproxy::balancermember { 'mysql': listening_service => 'mysql', ports => '3306', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } if $rabbitmq { haproxy::listen { 'rabbitmq': ipaddress => [hiera('controller_virtual_ip'), hiera('public_virtual_ip')], ports => 5672, options => { 'timeout' => [ ""client 0"", ""server 0"" ] }, collect_exported => false, } haproxy::balancermember { 'rabbitmq': listening_service => 'rabbitmq', ports => '5672', ipaddresses => hiera('controller_host'), options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } } } include ::tripleo::loadbalancer ",,865,1
openstack%2Fdocs-specs~master~I0c1f63bef3ace46c76ddf2b61014c95f40422064,openstack/docs-specs,master,I0c1f63bef3ace46c76ddf2b61014c95f40422064,Adds detailed specification for migrating to new web design,MERGED,2014-12-04 19:00:31.000000000,2015-01-08 15:27:50.000000000,2015-01-08 15:27:49.000000000,"[{'_account_id': 3}, {'_account_id': 287}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 9162}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-04 19:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/f5c2beaa7feb3c68017db1674a60e55d85a1bd31', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}, {'number': 2, 'created': '2014-12-04 21:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/5b4679c9f0f623ed4cbe261959a4f4e758efed17', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}, {'number': 3, 'created': '2014-12-12 19:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/6cf63daf6108a2554395804cd725f4d9ad9f56d0', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}, {'number': 4, 'created': '2014-12-12 23:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/d341e9baedad3b422a995af642e0f86a965c470b', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}, {'number': 5, 'created': '2014-12-18 16:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/fc4a70b900c6b18f2362384b3b31580d8c6a9b88', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}, {'number': 6, 'created': '2014-12-18 16:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/d4eb21be95077671a1b2053fcda68315ab4cfb39', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}, {'number': 7, 'created': '2015-01-07 16:38:16.000000000', 'files': ['doc/source/index.rst', 'specs/template.rst', 'specs/kilo/migrate-to-new-web-design.rst'], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/36465bdb0c0513a8cea6ff86949652f0254b0139', 'message': 'Adds detailed specification for migrating to new web design\n\n- Also includes minor typo fix in template.rst file.\n\nChange-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064\n'}]",14,139154,36465bdb0c0513a8cea6ff86949652f0254b0139,33,8,7,964,,,0,"Adds detailed specification for migrating to new web design

- Also includes minor typo fix in template.rst file.

Change-Id: I0c1f63bef3ace46c76ddf2b61014c95f40422064
",git fetch https://review.opendev.org/openstack/docs-specs refs/changes/54/139154/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/template.rst', 'specs/kilo/migrate-to-new-web-design.rst']",2,f5c2beaa7feb3c68017db1674a60e55d85a1bd31,migration,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================== Migration to New Web Design =========================== https://blueprints.launchpad.net/openstack-manuals/+spec/redesign-docs-site We have a new web design that we've reviewed and vetted within the documentation team. Here are the example pages: * `Main page <http://openstack-homepage.bitballoon.com/docs>`_ * `Content view <http://openstack-homepage.bitballoon.com/docs/book>`_ * `Search results <http://openstack-homepage.bitballoon.com/docs/search>`_ * `Example language landing page <http://openstack-homepage.bitballoon.com/docs/ja>`_ We need to do some template and content migration work to get many docs onto this new web design. Problem description =================== The problems with our current design for docs.openstack.org can be found in the `Docs.OpenStack.org Redesign Project Brief <https://docs.google.com/document/d/1GGKTKHDMc8A0jerdv-K3ql0udnxMr-j4DlhL2Cj6kcw/edit?usp=sharing>`_ The problem to solve with this blueprint specifically is getting the design into Sphinx/jinja templates for use with RST source, as well as getting RST source files from certain Docbook source files. This is a phased approach to try to get many but not all docs migrated in the Kilo release time frame. Proposed change =============== The User Guide, Admin User Guide, Cloud Administrator Guide, High Availability Guide, API Quick Start Guide, and Virtual Machine Image Guide can all go to the new design. This new design will not apply to content that may remain as a book primarily, and to limit the migration's scope to complete it in a timely way, this new design would not apply to all deliverables. Examples of documents that will not be migrated in the Kilo timeframe include the Install Guides, the Operations Guide, the Security Guide, and the Architecture Design Guide. Those deliverables will remain in Docbook and use the Maven plugin for builds for the Kilo release. Alternatives ------------ Rather than use RST/Sphinx for the new design, we could migrate to markdown/Jekyll which is what the prototype design is already using. The OpenStack ecosystem currently supports Python systems like Sphinx and oslosphinx is available with a theme already. We could get rid of Docbook completely for all books rather than the phased approach. I don't think that we have the time to do that in a six-month release, so I'm advocating for a phased approach. Implementation ============== Assignee(s) ----------- Primary assignee: annegentle Other contributors: jagerandi loquacities klevenstein dhellman Work Items ---------- Create jinja2 templates from Jekyll designs: - landing page - search page - content page Test templates across browsers to ensure parity with design: * Chrome on Ubuntu, Fedora, Mac, Windows * Firefox on Ubuntu, Fedora, Mac, Windows Update oslosphinx to have new openstack-docs theme: Currently the theme name is ""openstack."" Reviewing the plan with Doug Hellman, we can either keep the openstack theme and start one named ""openstack-doc"" or update the openstack theme to be the new design. I prefer to name a new one ""openstack-doc"" so that the current openstack theme which can indicate when a project's doc is incubated remains. Replace static www jinja templates in openstack-manuals with new design Migrate Docbook to RST for these books in this priority order: End User Guide Admin User Guide Cloud Administrator Guide Virtual Machine Image Guide High Availability Guide API Quick Start Guide Once migrated, apply new oslosphinx template to these repos and deliverables: openstack-manuals: * End User Guide * Admin User Guide * Cloud Administrator Guide * Virtual Machine Image Guide api-site: * API Quick Start Guide ha-guide: * High Availability Guide Remind projects to update their theme for /developer/ docs for: * nova * neutron * glance * keystone * ceilometer * cinder * heat * horizon * ironic * sahara * swift * trove Create a taxonomy for suggested tags as part of the Conventions wiki page (klevenstein, loquacities) Investigate using index.rst collections across repos for new deliverable assembly. This is not a required task for the migration, but will certainly help with information architecture going forward towards ""every page is page one"" rather than book-like deliverables. (jaegerandi) Dependencies ============ * Foundation web developers hand-off of current design HTML and CSS files. * Core olsosphinx reviewers helping with theme creation and reviews. Testing ======= We need to test the new design on these browsers/operating systems as a priority: * Chrome on Ubuntu, Fedora, Mac, Windows * Firefox on Ubuntu, Fedora, Mac, Windows References ========== * https://docs.google.com/document/d/1GGKTKHDMc8A0jerdv-K3ql0udnxMr-j4DlhL2Cj6kcw/edit?usp=sharing * https://etherpad.openstack.org/p/docstopicsparissummit ",,134,1
openstack%2Fcinder~master~I993acb47de6a2ef33a287691b7706735c6f956bc,openstack/cinder,master,I993acb47de6a2ef33a287691b7706735c6f956bc,Handle ISCSIConnector.get_initiator() OSError,ABANDONED,2015-01-06 21:10:45.000000000,2015-01-08 15:21:25.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 11805}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12779}, {'_account_id': 14259}]","[{'number': 1, 'created': '2015-01-06 21:10:45.000000000', 'files': ['cinder/brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ccdb8233ad9f5531f616df0ef9e1092ac7bb4154', 'message': ""Handle ISCSIConnector.get_initiator() OSError\n\nHandle ISCSIConnector.get_initiator() OSError exception (errno=ENOENT)\nwhen /etc/iscsi/initiatorname.iscsi doesn't exist.\n\nChange-Id: I993acb47de6a2ef33a287691b7706735c6f956bc\nCloses-Bug: 1408087\n""}]",2,145342,ccdb8233ad9f5531f616df0ef9e1092ac7bb4154,20,14,1,11805,,,0,"Handle ISCSIConnector.get_initiator() OSError

Handle ISCSIConnector.get_initiator() OSError exception (errno=ENOENT)
when /etc/iscsi/initiatorname.iscsi doesn't exist.

Change-Id: I993acb47de6a2ef33a287691b7706735c6f956bc
Closes-Bug: 1408087
",git fetch https://review.opendev.org/openstack/cinder refs/changes/42/145342/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/initiator/connector.py'],1,ccdb8233ad9f5531f616df0ef9e1092ac7bb4154,bug/1408087,"import errno except (putils.ProcessExecutionError, OSError) as err: if isinstance(err, OSError) and err.errno != errno.ENOENT: raise", except putils.ProcessExecutionError:,4,1
openstack%2Fapi-site~master~I840c053def8ef1c9d5469438f7e4c5318833dca7,openstack/api-site,master,I840c053def8ef1c9d5469438f7e4c5318833dca7,"Changes type of image from BASE, SERVER, or ALL to snapshot or backup",MERGED,2015-01-06 18:44:50.000000000,2015-01-08 15:21:14.000000000,2015-01-08 15:21:13.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2015-01-06 18:44:50.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/2656c9c90132bcceac04a116528414a09b8e0916', 'message': 'Changes type of image from BASE, SERVER, or ALL to snapshot or backup\n\nChange-Id: I840c053def8ef1c9d5469438f7e4c5318833dca7\nCloses-bug: 1157274\n'}]",0,145293,2656c9c90132bcceac04a116528414a09b8e0916,7,3,1,964,,,0,"Changes type of image from BASE, SERVER, or ALL to snapshot or backup

Change-Id: I840c053def8ef1c9d5469438f7e4c5318833dca7
Closes-bug: 1157274
",git fetch https://review.opendev.org/openstack/api-site refs/changes/93/145293/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2/common.ent'],1,2656c9c90132bcceac04a116528414a09b8e0916,bug/1157274," <para>Value of the type of image, such as snapshot or backup.</para></wadl:doc> <option value=""snapshot""/> <option value=""backup""/>"," <para>Value of the type of image, such as BASE, SERVER, or ALL.</para></wadl:doc> <option value=""BASE""/> <option value=""SERVER""/> <option value=""ALL""/>",4,5
openstack%2Fmagnum~master~I97fbe4e47c444969ff77adb600b4fd7203eeb194,openstack/magnum,master,I97fbe4e47c444969ff77adb600b4fd7203eeb194,Implement service creation,MERGED,2015-01-08 07:40:43.000000000,2015-01-08 15:10:48.000000000,2015-01-08 15:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-08 07:40:43.000000000', 'files': ['magnum/objects/service.py', 'magnum/tests/conductor/handlers/test_kube.py', 'magnum/api/controllers/v1/service.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/bdabe2e592effd549d12e3e20d4b577da10eb692', 'message': 'Implement service creation\n\nService creation is working from magnum api now.\n\nChange-Id: I97fbe4e47c444969ff77adb600b4fd7203eeb194\n'}]",1,145709,bdabe2e592effd549d12e3e20d4b577da10eb692,9,5,1,12385,,,0,"Implement service creation

Service creation is working from magnum api now.

Change-Id: I97fbe4e47c444969ff77adb600b4fd7203eeb194
",git fetch https://review.opendev.org/openstack/magnum refs/changes/09/145709/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/objects/service.py', 'magnum/tests/conductor/handlers/test_kube.py', 'magnum/api/controllers/v1/service.py', 'magnum/conductor/handlers/kube.py']",4,bdabe2e592effd549d12e3e20d4b577da10eb692,impl-pod-create," k8s_master_url = _retrive_k8s_master_url(ctxt, service) status = self.kube_cli.service_create(k8s_master_url, service)", status = self.kube_cli.service_create(service),28,1
openstack%2Fopenstack-ansible~stable%2Ficehouse~I6169a2c72f2e477a8fa751ee9f8de0ecac3c5988,openstack/openstack-ansible,stable/icehouse,I6169a2c72f2e477a8fa751ee9f8de0ecac3c5988,NFS client configuration for cinder,ABANDONED,2015-01-07 23:48:31.000000000,2015-01-08 15:02:55.000000000,,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-07 23:48:31.000000000', 'files': ['rpc_deployment/roles/cinder_common/templates/cinder.conf', 'rpc_deployment/roles/nfs_client/tasks/main.yml', 'rpc_deployment/vars/repo_packages/cinder.yml', 'rpc_deployment/playbooks/openstack/cinder-volume.yml', 'rpc_deployment/roles/nfs_client/templates/nfs_shares.j2', 'etc/rpc_deploy/rpc_user_config.yml.example'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d6897e3c42edf615e167f0a5e62d5fde5c878564', 'message': 'NFS client configuration for cinder\n\nThis change adds the NFS client configuration in the cinder_volume hosts,\nnecessary when using a netapp backend over NFS. (Cherry-picked from\ncommit ed15550a141813b85cd75c8774439a250871fa62)\n\nChange-Id: I6169a2c72f2e477a8fa751ee9f8de0ecac3c5988\n'}]",0,145636,d6897e3c42edf615e167f0a5e62d5fde5c878564,5,3,1,12606,,,0,"NFS client configuration for cinder

This change adds the NFS client configuration in the cinder_volume hosts,
necessary when using a netapp backend over NFS. (Cherry-picked from
commit ed15550a141813b85cd75c8774439a250871fa62)

Change-Id: I6169a2c72f2e477a8fa751ee9f8de0ecac3c5988
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/36/145636/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/roles/cinder_common/templates/cinder.conf', 'rpc_deployment/roles/nfs_client/tasks/main.yml', 'rpc_deployment/vars/repo_packages/cinder.yml', 'rpc_deployment/playbooks/openstack/cinder-volume.yml', 'rpc_deployment/roles/nfs_client/templates/nfs_shares.j2', 'etc/rpc_deploy/rpc_user_config.yml.example']",6,d6897e3c42edf615e167f0a5e62d5fde5c878564,," nfs_client: nfs_shares_config: /etc/cinder/nfs_shares shares: - { ip: ""{{ cinder_netapp_hostname }}"", share: ""/vol/cinder"" }",,33,0
openstack%2Fopenstack-ansible~stable%2Ficehouse~I0ca27f1306a61b8898cd2f59b869b80eb44fad56,openstack/openstack-ansible,stable/icehouse,I0ca27f1306a61b8898cd2f59b869b80eb44fad56,Add gitreview config with correct default branch,ABANDONED,2015-01-07 20:44:03.000000000,2015-01-08 15:02:36.000000000,,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12000}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 20:44:03.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/76717c0eeef2a39b645613aaaf87b2fd42476850', 'message': 'Add gitreview config with correct default branch\n\nChange-Id: I0ca27f1306a61b8898cd2f59b869b80eb44fad56\n(cherry picked from commit b66cfef898ccab534ee3a335ce8900e6d8393eae)\n'}]",0,145581,76717c0eeef2a39b645613aaaf87b2fd42476850,7,5,1,12000,,,0,"Add gitreview config with correct default branch

Change-Id: I0ca27f1306a61b8898cd2f59b869b80eb44fad56
(cherry picked from commit b66cfef898ccab534ee3a335ce8900e6d8393eae)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/145581/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,76717c0eeef2a39b645613aaaf87b2fd42476850,,[gerrit] host=review.openstack.org port=29418 project=stackforge/os-ansible-deployment.git defaultbranch=icehouse ,,5,0
openstack%2Foperations-guide~master~If14712e69f72fc72a19fd9c057401152559fd351,openstack/operations-guide,master,If14712e69f72fc72a19fd9c057401152559fd351,Added content for upgrading Icehouse to Juno,MERGED,2014-12-31 20:29:32.000000000,2015-01-08 15:02:01.000000000,2015-01-08 15:02:00.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 9162}, {'_account_id': 9515}, {'_account_id': 10705}, {'_account_id': 14046}]","[{'number': 1, 'created': '2014-12-31 20:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/137703b9bf8d03b3e3b2cfa57103837f0abd6575', 'message': 'Added content for upgrading Icehouse to Juno\n\nI added content for upgrading Icehouse to Juno. This patch also\nattempts to address the following issues:\n\n1) Verify the neutron database version prior to updating it.\n2) Reduce content duplication by removing syntax specific to\n   certain Linux distributions. For example, operators\n   performing upgrades should know which services to restart\n   and how to restart them.\n\nChange-Id: If14712e69f72fc72a19fd9c057401152559fd351\nCloses-Bug: #1391328\nPartial-Bug: #1337399\n'}, {'number': 2, 'created': '2015-01-02 14:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/2bf3cd6de576ab37055ff79d28b3ec4e71d22da4', 'message': 'Added content for upgrading Icehouse to Juno\n\nI added content for upgrading Icehouse to Juno. This patch also\nattempts to address the following issues:\n\n1) Verify the neutron database version prior to updating it.\n2) Reduce content duplication by removing syntax specific to\n   certain Linux distributions. For example, operators\n   performing upgrades should know which services to restart\n   and how to restart them.\n\nChange-Id: If14712e69f72fc72a19fd9c057401152559fd351\nCloses-Bug: #1391328\nPartial-Bug: #1337399\n'}, {'number': 3, 'created': '2015-01-05 16:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/867231eca0ec450efa1708b3cff59acf43edd139', 'message': 'Added content for upgrading Icehouse to Juno\n\nI added content for upgrading Icehouse to Juno. This patch also\nattempts to address the following issues:\n\n1) Verify the neutron database version prior to updating it.\n2) Reduce content duplication by removing syntax specific to\n   certain Linux distributions. For example, operators\n   performing upgrades should know which services to restart\n   and how to restart them.\n\nChange-Id: If14712e69f72fc72a19fd9c057401152559fd351\nCloses-Bug: #1391328\nPartial-Bug: #1337399\n'}, {'number': 4, 'created': '2015-01-06 19:14:45.000000000', 'files': ['doc/openstack-ops/ch_ops_upgrades.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ae8d4b91c2f60d427bdde57acc3f1b769cca393f', 'message': 'Added content for upgrading Icehouse to Juno\n\nI added content for upgrading Icehouse to Juno. This patch also\nattempts to address the following issues:\n\n1) Verify the neutron database version prior to updating it.\n2) Reduce content duplication by removing syntax specific to\n   certain Linux distributions. For example, operators\n   performing upgrades should know which services to restart\n   and how to restart them.\n\nChange-Id: If14712e69f72fc72a19fd9c057401152559fd351\nCloses-Bug: #1391328\nPartial-Bug: #1337399\n'}]",24,144660,ae8d4b91c2f60d427bdde57acc3f1b769cca393f,31,9,4,9515,,,0,"Added content for upgrading Icehouse to Juno

I added content for upgrading Icehouse to Juno. This patch also
attempts to address the following issues:

1) Verify the neutron database version prior to updating it.
2) Reduce content duplication by removing syntax specific to
   certain Linux distributions. For example, operators
   performing upgrades should know which services to restart
   and how to restart them.

Change-Id: If14712e69f72fc72a19fd9c057401152559fd351
Closes-Bug: #1391328
Partial-Bug: #1337399
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/60/144660/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_upgrades.xml'],1,137703b9bf8d03b3e3b2cfa57103837f0abd6575,bug/1391328," <section xml:id=""upgrade-icehouse-juno""> <title>Upgrading from Icehouse to Juno</title> <?dbhtml stop-chunking?> <para>This procedure covers upgrading a basic operational deployment of the following services: Identity (keystone), Image Service (glance), Compute (nova), Networking (neutron), dashboard (horizon), Block Storage (cinder), Orchestration (heat), and Telemetry (ceilometer). This procedure references the basic three-node architecture in the <link xlink:href=""http://docs.openstack.org/icehouse/install-guide/install/apt/content/"" ><citetitle>OpenStack Installation Guide</citetitle></link>. All nodes should run a supported distribution of Linux with a recent kernel and latest Icehouse packages.</para> <section xml:id=""upgrade-icehouse-juno-considerations""> <title>Considerations</title> <itemizedlist> <listitem> <para>The upgrade process interrupts management of your environment including the dashboard. If you properly prepare for the upgrade, existing instances, networking, and storage should continue to operate. However, instances might experience intermittent network interruptions.</para> </listitem> <listitem> <para>Review the <link xlink:href=""http://wiki.openstack.org/wiki/ReleaseNotes/Juno"" >release notes</link> before upgrading to learn about new, updated, and deprecated features.</para> </listitem> <listitem> <para>Consider adopting structure and options from Juno service configuration files and merging them with existing configuration files. The <link xlink:href=""http://docs.openstack.org/juno/config-reference/content/"" ><citetitle>OpenStack Configuration Reference</citetitle></link> contains new, updated, and deprecated options for most services.</para> </listitem> <listitem> <para>For environments using the OpenStack Networking (neutron) service, verify the Icehouse version of the database:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""neutron-db-manage --config-file /etc/neutron/neutron.conf \ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini current"" neutron</userinput> <computeroutput>INFO [alembic.migration] Context impl MySQLImpl. INFO [alembic.migration] Will assume non-transactional DDL. Current revision for mysql://neutron:XXXXX@controller/neutron: 5ac1c354a051 -> icehouse (head), icehouse</computeroutput></screen> </listitem> </itemizedlist> </section> <section xml:id=""upgrade-icehouse-juno-backup""> <title>Perform a backup</title> <procedure> <step> <para>Save the configuration files on all nodes:</para> <screen><prompt>#</prompt> <userinput>for i in keystone glance nova neutron openstack-dashboard cinder heat ceilometer; \ do mkdir $i-icehouse; \ done</userinput> <prompt>#</prompt> <userinput>for i in keystone glance nova neutron openstack-dashboard cinder heat ceilometer; \ do cp -r /etc/$i/* $i-icehouse/; \ done</userinput></screen> <note> <para>You can modify this example script on each node to handle different services.</para> </note> </step> <step> <para>Back up all databases on the controller:</para> <screen><prompt>#</prompt> <userinput>mysqldump -u root -p --opt --add-drop-database --all-databases &gt; icehouse-db-backup.sql</userinput></screen> <note> <para>Consider updating your SQL server configuration as described in the <link xlink:href=""http://docs.openstack.org/juno/install-guide/install/apt/content/"" >OpenStack Installation Guide</link>.</para> </note> </step> </procedure> </section> <section xml:id=""upgrade-icehouse-juno-repos""> <title>Manage repositories</title> <procedure> <para>Complete the following steps on all nodes.</para> <step> <para>Remove the repository for Icehouse packages.</para> </step> <step> <para>On Ubuntu, follow these steps:</para> <substeps> <step> <para>Add the repository for Juno packages:</para> <screen><prompt>#</prompt> <userinput>echo ""deb http://ubuntu-cloud.archive.canonical.com/ubuntu"" \ ""trusty-updates/juno main"" > /etc/apt/sources.list.d/cloudarchive-juno.list</userinput></screen> <note> <para>Remove any Ubuntu Cloud archive repositories for Icehouse packages. You might also need to install or update the <literal>ubuntu-cloud-keyring</literal> package.</para> </note> </step> <step> <para>Update the repository database.</para> </step> </substeps> </step> <step> <para>On Red Hat Enterprise Linux (RHEL), CentOS, and Fedora, follow these steps:</para> <substeps> <step> <para>Remove the repository for Icehouse packages:</para> <screen><prompt>#</prompt> <userinput>yum erase rdo-release-icehouse</userinput></screen> </step> <step> <para>Add the repository for Juno packages:</para> <screen><prompt>#</prompt> <userinput>yum install http://rdo.fedorapeople.org/openstack-juno/rdo-release-juno.rpm</userinput></screen> </step> <step> <para>Update the repository database.</para> </step> </substeps> </step> </procedure> </section> <section xml:id=""upgrade-icehouse-juno-controller""> <title>Controller nodes</title> <section xml:id=""upgrade-icehouse-juno-controller-packages""> <title>Upgrade packages</title> <para>Upgrade packages to Juno.</para> <note> <para>Depending on your specific configuration, upgrading all packages might restart or break services supplemental to your OpenStack environment. For example, if you use the TGT iSCSI framework for Block Storage volumes and the upgrade includes new packages for it, the package manager might restart the TGT iSCSI services and impact connectivity to volumes.</para> </note> <note> <para>If the package manager prompts you to update configuration files, reject the changes. The package manager will append a suffix to newer versions of configuration files. Consider reviewing and adopting content from these files.</para> </note> </section> <section xml:id=""upgrade-icehouse-juno-controller-services""> <title>Update services</title> <para>Updating a service generally requires modifying one or more configuration files, stopping the service, synchronizing the database schema, and starting the service. Some services require different steps. We recommend verifying operation of each service before proceeding to the next service.</para> <procedure> <title>All services</title> <para>These configuration changes apply to all services.</para> <step> <para>In any file containing the <literal>[keystone_authtoken]</literal> section, modify Identity service access to use the <option>identity_uri</option> option:</para> <programlisting language=""ini"">[keystone_authtoken] ... identity_uri = http://<replaceable>controller</replaceable>:35357</programlisting> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> option replaces them.</para> </step> <step> <para>In any file containing the <option>auth_uri</option> option, modify it to explicitly use version 2.0:</para> <programlisting language=""ini"">auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0</programlisting> </step> </procedure> <procedure> <title>Identity service</title> <step> <para>Edit the <filename>/etc/keystone/keystone.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[token]</literal> section, configure the UUID token provider and SQL driver:</para> <programlisting language=""ini"">[token] ... provider = keystone.token.providers.uuid.Provider driver = keystone.token.persistence.backends.sql.Token</programlisting> </step> </substeps> </step> <step> <para>Stop the service.</para> </step> <step> <para>Clear expired tokens:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""keystone-manage token_flush"" keystone</userinput></screen> </step> <step> <para>Synchronize the database schema:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""keystone-manage db_sync"" keystone</userinput></screen> </step> <step> <para>Start the service.</para> </step> </procedure> <procedure> <title>Image Service</title> <step> <para>Edit the <filename>/etc/glance/glance-api.conf</filename> file:</para> <substeps> <step> <para>Move the following options from the <literal>[DEFAULT]</literal> section to the <literal>[glance_store]</literal> section:</para> <itemizedlist> <listitem> <para><option>default_store</option></para> </listitem> <listitem> <para><option>filesystem_store_datadir</option></para> </listitem> </itemizedlist> <note> <para>These options must contain values.</para> </note> </step> </substeps> </step> <step> <para>Stop the services.</para> </step> <step> <para>Synchronize the database schema:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""glance-manage db_sync"" glance</userinput></screen> </step> <step> <para>Start the services.</para> </step> </procedure> <procedure> <title>Compute service</title> <step> <para>Edit the <filename>/etc/nova/nova.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, rename the <option>glance_host</option> option to <option>host</option> and move it to the <literal>[glance]</literal> section.</para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, rename the following options and move them to the <literal>[neutron]</literal> section:</para> <itemizedlist> <listitem> <para><option>neutron_url</option> becomes <option>url</option></para> </listitem> <listitem> <para><option>neutron_auth_strategy</option> becomes <option>auth_strategy</option></para> </listitem> <listitem> <para><option>neutron_admin_tenant_name</option> becomes <option>admin_tenant_name</option></para> </listitem> <listitem> <para><option>neutron_admin_username</option> becomes <option>admin_username</option></para> </listitem> <listitem> <para><option>neutron_admin_password</option> becomes <option>admin_password</option></para> </listitem> <listitem> <para><option>neutron_admin_auth_url</option> becomes <option>admin_auth_url</option></para> </listitem> <listitem> <para><option>service_neutron_metadata_proxy</option> becomes <option>service_metadata_proxy</option></para> </listitem> <listitem> <para><option>neutron_metadata_proxy_shared_secret</option> becomes <option>metadata_proxy_shared_secret</option></para> </listitem> </itemizedlist> </step> </substeps> </step> <step> <para>Stop the services.</para> </step> <step> <para>Synchronize the database schema:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""nova-manage db sync"" nova</userinput></screen> </step> <step> <para>Start the services.</para> </step> </procedure> <procedure> <title>Networking service</title> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>rpc_backend</option> option:</para> <para> <literal>neutron.openstack.common.rpc.impl_kombu</literal> becomes <literal>rabbit</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>core_plugin</option> option:</para> <para> <literal>neutron.plugins.ml2.plugin.Ml2Plugin</literal> becomes <literal>ml2</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value or values of the <option>service_plugins</option> option to use short names. For example:</para> <para> <literal>neutron.services.l3_router.l3_router_plugin.L3RouterPlugin</literal> becomes <literal>router</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, explicitly define a value for the <option>nova_region_name</option> option. For example:</para> <programlisting language=""ini"">[DEFAULT] ... nova_region_name = regionOne</programlisting> </step> </substeps> </step> <step> <para>Stop the services.</para> </step> <step> <para>Synchronize the database schema:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""neutron-db-manage --config-file /etc/neutron/neutron.conf \ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade juno"" neutron</userinput></screen> </step> <step> <para>Start the services.</para> </step> </procedure> <procedure> <title>Dashboard</title> <para>In typical environments, updating the dashboard only requires restarting the services.</para> <step> <para>Restart the services.</para> </step> </procedure> <procedure> <title>Block Storage service</title> <step> <para>Edit the <filename>/etc/cinder/cinder.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, add the following option:</para> <programlisting language=""ini"">my_ip = <replaceable>controller</replaceable></programlisting> </step> </substeps> </step> <step> <para>Stop the services.</para> </step> <step> <para>Synchronize the database schema:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""cinder-manage db sync"" cinder</userinput></screen> </step> <step> <para>Start the services.</para> </step> </procedure> <procedure> <title>Orchestration service</title> <step> <para>Create the <literal>heat_stack_owner</literal> role if it does not exist:</para> <screen><prompt>#</prompt> <userinput>keystone role-create --name heat_stack_owner</userinput></screen> </step> <step> <para>Edit the <filename>/etc/heat/heat.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>rpc_backend</option> option:</para> <para> <literal>heat.openstack.common.rpc.impl_kombu</literal> becomes <literal>rabbit</literal></para> </step> </substeps> </step> <step> <para>Stop the services.</para> </step> <step> <para>Synchronize the database schema:</para> <screen><prompt>#</prompt> <userinput>su -s /bin/sh -c ""heat-manage db_sync"" heat</userinput></screen> </step> <step> <para>Start the services.</para> </step> </procedure> <procedure> <title>Telemetry service</title> <para>In typical environments, updating the Telemetry service only requires restarting the services.</para> <step> <para>Restart the services.</para> </step> </procedure> </section> </section> <section xml:id=""upgrade-icehouse-juno-network""> <title>Network nodes</title> <section xml:id=""upgrade-icehouse-juno-network-packages""> <title>Upgrade packages</title> <para>Upgrade packages to Juno.</para> <note> <para>Explicitly install the <literal>ipset</literal> package if your distribution does not install it as a dependency.</para> </note> <note> <para>Depending on your specific configuration, upgrading all packages might restart or break services supplemental to your OpenStack environment. For example, if you use the TGT iSCSI framework for Block Storage volumes and the upgrade includes new packages for it, the package manager might restart the TGT iSCSI services and impact connectivity to volumes.</para> </note> <note> <para>If the package manager prompts you to update configuration files, reject the changes. The package manager will append a suffix to newer versions of configuration files. Consider reviewing and adopting content from these files.</para> </note> </section> <section xml:id=""upgrade-icehouse-juno-network-services""> <title>Update services</title> <para>Updating a service generally requires modifying one or more configuration files, stopping the service, synchronizing the database schema, and starting the service. Some services require different steps. We recommend verifying operation of each service before proceeding to the next service.</para> <procedure> <title>All services</title> <para>These configuration changes apply to all services.</para> <step> <para>In any file containing the <literal>[keystone_authtoken]</literal> section, modify Identity service access to use the <option>identity_uri</option> option:</para> <programlisting language=""ini"">[keystone_authtoken] ... identity_uri = http://<replaceable>controller</replaceable>:35357</programlisting> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> option replaces them.</para> </step> <step> <para>In any file containing the <option>auth_uri</option> option, modify it to explicitly use version 2.0:</para> <programlisting language=""ini"">auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0</programlisting> </step> </procedure> <procedure> <title>Networking service</title> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>rpc_backend</option> option:</para> <para> <literal>neutron.openstack.common.rpc.impl_kombu</literal> becomes <literal>rabbit</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>core_plugin</option> option:</para> <para> <literal>neutron.plugins.ml2.plugin.Ml2Plugin</literal> becomes <literal>ml2</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value or values of the <option>service_plugins</option> option to use short names. For example:</para> <para> <literal>neutron.services.l3_router.l3_router_plugin.L3RouterPlugin</literal> becomes <literal>router</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, explicitly define a value for the <option>nova_region_name</option> option. For example:</para> <programlisting language=""ini"">[DEFAULT] ... nova_region_name = regionOne</programlisting> </step> <step> <para>In the <literal>[database]</literal> section, remove any <option>connection</option> options because the Networking service uses the message queue instead of direct access to the database.</para> </step> </substeps> </step> <step> <para>Restart the services.</para> </step> </procedure> </section> </section> <section xml:id=""upgrade-icehouse-juno-compute""> <title>Compute nodes</title> <section xml:id=""upgrade-icehouse-juno-compute-packages""> <title>Upgrade packages</title> <para>Upgrade packages to Juno.</para> <note> <para>Explicitly install the <literal>ipset</literal> package if your distribution does not install it as a dependency.</para> </note> <note> <para>Depending on your specific configuration, upgrading all packages might restart or break services supplemental to your OpenStack environment. For example, if you use the TGT iSCSI framework for Block Storage volumes and the upgrade includes new packages for it, the package manager might restart the TGT iSCSI services and impact connectivity to volumes.</para> </note> <note> <para>If the package manager prompts you to update configuration files, reject the changes. The package manager will append a suffix to newer versions of configuration files. Consider reviewing and adopting content from these files.</para> </note> </section> <section xml:id=""upgrade-icehouse-juno-compute-services""> <title>Update services</title> <para>Updating a service generally requires modifying one or more configuration files, stopping the service, synchronizing the database schema, and starting the service. Some services require different steps. We recommend verifying operation of each service before proceeding to the next service.</para> <procedure> <title>All services</title> <para>These configuration changes apply to all services.</para> <step> <para>In any file containing the <literal>[keystone_authtoken]</literal> section, modify Identity service access to use the <option>identity_uri</option> option:</para> <programlisting language=""ini"">[keystone_authtoken] ... identity_uri = http://<replaceable>controller</replaceable>:35357</programlisting> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> option replaces them.</para> </step> <step> <para>In any file containing the <option>auth_uri</option> option, modify it to explicitly use version 2.0:</para> <programlisting language=""ini"">auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0</programlisting> </step> </procedure> <procedure> <title>Compute service</title> <step> <para>Edit the <filename>/etc/nova/nova.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, rename the <option>glance_host</option> option to <option>host</option> and move it to the <literal>[glance]</literal> section.</para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, rename the following options and move them to the <literal>[neutron]</literal> section:</para> <itemizedlist> <listitem> <para><option>neutron_url</option> becomes <option>url</option></para> </listitem> <listitem> <para><option>neutron_auth_strategy</option> becomes <option>auth_strategy</option></para> </listitem> <listitem> <para><option>neutron_admin_tenant_name</option> becomes <option>admin_tenant_name</option></para> </listitem> <listitem> <para><option>neutron_admin_username</option> becomes <option>admin_username</option></para> </listitem> <listitem> <para><option>neutron_admin_password</option> becomes <option>admin_password</option></para> </listitem> <listitem> <para><option>neutron_admin_auth_url</option> becomes <option>admin_auth_url</option></para> </listitem> <listitem> <para><option>service_neutron_metadata_proxy</option> becomes <option>service_metadata_proxy</option></para> </listitem> <listitem> <para><option>neutron_metadata_proxy_shared_secret</option> becomes <option>metadata_proxy_shared_secret</option></para> </listitem> </itemizedlist> </step> <step> <para>In the <literal>[database]</literal> section, remove any <option>connection</option> options because the Compute service uses the message queue instead of direct access to the database.</para> </step> </substeps> </step> <step> <para>Restart the services.</para> </step> </procedure> <procedure> <title>Networking service</title> <step> <para>Edit the <filename>/etc/neutron/neutron.conf</filename> file:</para> <substeps> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>rpc_backend</option> option:</para> <para> <literal>neutron.openstack.common.rpc.impl_kombu</literal> becomes <literal>rabbit</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value of the <option>core_plugin</option> option:</para> <para> <literal>neutron.plugins.ml2.plugin.Ml2Plugin</literal> becomes <literal>ml2</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, change the value or values of the <option>service_plugins</option> option to use short names. For example:</para> <para> <literal>neutron.services.l3_router.l3_router_plugin.L3RouterPlugin</literal> becomes <literal>router</literal></para> </step> <step> <para>In the <literal>[DEFAULT]</literal> section, explicitly define a value for the <option>nova_region_name</option> option. For example:</para> <programlisting language=""ini"">[DEFAULT] ... nova_region_name = regionOne</programlisting> </step> <step> <para>In the <literal>[database]</literal> section, remove any <option>connection</option> options because the Networking service uses the message queue instead of direct access to the database.</para> </step> </substeps> </step> <step> <para>Restart the services.</para> </step> </procedure> </section> </section> <section xml:id=""upgrade-icehouse-juno-storage""> <title>Storage nodes</title> <section xml:id=""upgrade-icehouse-juno-storage-packages""> <title>Upgrade packages</title> <para>Upgrade packages to Juno.</para> <note> <para>Depending on your specific configuration, upgrading all packages might restart or break services supplemental to your OpenStack environment. For example, if you use the TGT iSCSI framework for Block Storage volumes and the upgrade includes new packages for it, the package manager might restart the TGT iSCSI services and impact connectivity to volumes.</para> </note> <note> <para>If the package manager prompts you to update configuration files, reject the changes. The package manager will append a suffix to newer versions of configuration files. Consider reviewing and adopting content from these files.</para> </note> </section> <section xml:id=""upgrade-icehouse-juno-storage-services""> <title>Update services</title> <para>Updating a service generally requires modifying one or more configuration files, stopping the service, synchronizing the database schema, and starting the service. Some services require different steps. We recommend verifying operation of each service before proceeding to the next service.</para> <procedure> <title>All services</title> <para>These configuration changes apply to all services.</para> <step> <para>In any file containing the <literal>[keystone_authtoken]</literal> section, modify Identity service access to use the <option>identity_uri</option> option:</para> <programlisting language=""ini"">[keystone_authtoken] ... identity_uri = http://<replaceable>controller</replaceable>:35357</programlisting> <para>Comment out any <literal>auth_host</literal>, <literal>auth_port</literal>, and <literal>auth_protocol</literal> options because the <literal>identity_uri</literal> option replaces them.</para> </step> <step> <para>In any file containing the <option>auth_uri</option> option, modify it to explicitly use version 2.0:</para> <programlisting language=""ini"">auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0</programlisting> </step> </procedure> <procedure> <title>Block Storage service</title> <para>In typical environments, updating the Block Storage service only requires restarting the services.</para> <step> <para>Restart the services.</para> </step> </procedure> </section> </section> </section> ",,756,0
openstack%2Fproject-config~master~I35e13bce6d6d973879225a21b1ca6e0c9811bcd5,openstack/project-config,master,I35e13bce6d6d973879225a21b1ca6e0c9811bcd5,Don't run Python 2.6 tests on openstack/tuskar-ui in Kilo,MERGED,2015-01-08 09:16:22.000000000,2015-01-08 15:00:16.000000000,2015-01-08 15:00:16.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-08 09:16:22.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e00a14afe7fed85aea58129e208450eca5dbc269', 'message': ""Don't run Python 2.6 tests on openstack/tuskar-ui in Kilo\n\nSince Horizon dropped support for Python 2.6 in Kilo, and the\nTuskar-UI project depends on Horizon, we have to drop support\ntoo and stop running the Python 2.6 tests.\n\nChange-Id: I35e13bce6d6d973879225a21b1ca6e0c9811bcd5\n""}]",0,145729,e00a14afe7fed85aea58129e208450eca5dbc269,8,4,1,8648,,,0,"Don't run Python 2.6 tests on openstack/tuskar-ui in Kilo

Since Horizon dropped support for Python 2.6 in Kilo, and the
Tuskar-UI project depends on Horizon, we have to drop support
too and stop running the Python 2.6 tests.

Change-Id: I35e13bce6d6d973879225a21b1ca6e0c9811bcd5
",git fetch https://review.opendev.org/openstack/project-config refs/changes/29/145729/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,e00a14afe7fed85aea58129e208450eca5dbc269,, - name: gate-tuskar-ui-python26 branch: ^stable/(icehouse|juno)$,,2,0
openstack%2Ffuel-main~master~Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd,openstack/fuel-main,master,Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd,Add wait for nodes to get online state after upgrade,MERGED,2015-01-08 12:01:14.000000000,2015-01-08 14:59:22.000000000,2015-01-08 13:36:05.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}, {'_account_id': 12867}]","[{'number': 1, 'created': '2015-01-08 12:01:14.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/de1434ba7810e024afb47610a4a2c57dc47d52cb', 'message': 'Add wait for nodes to get online state after upgrade\n\n- Add wait for nodes to get online state after upgrade\nto prevent OSTF failure\n\nChange-Id: Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd\nCloses-Bug: #1398825\n'}]",0,145756,de1434ba7810e024afb47610a4a2c57dc47d52cb,12,8,1,10136,,,0,"Add wait for nodes to get online state after upgrade

- Add wait for nodes to get online state after upgrade
to prevent OSTF failure

Change-Id: Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd
Closes-Bug: #1398825
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/56/145756/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,de1434ba7810e024afb47610a4a2c57dc47d52cb,addWaitNodesOnline, self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:5]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]),,4,0
openstack%2Fpython-glanceclient~master~Ie02c4e75ca1ab995102aa55bbff39b2161218b2d,openstack/python-glanceclient,master,Ie02c4e75ca1ab995102aa55bbff39b2161218b2d,Curl statements to include globoff for IPv6 URLs,MERGED,2014-11-21 13:07:20.000000000,2015-01-08 14:58:42.000000000,2015-01-08 14:58:41.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 10257}, {'_account_id': 11391}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-11-21 13:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/df36073e96bbd08b4dc136ace83d9425a4a41ca3', 'message': 'Curl statements to include globoff for IPv6 URLs\n\npython-glanceclient displays curl statements for debugging/troubleshooting\npurposes. For IPv6 URLs, curl requires --globoff to be passed in the\narguments. Since glanceclient does not use curl directly, this patch\ndisplays the curl commands with globoff option which works for both\nIPv4 and IPv6 URLs.\nFix adapted from python-novaclient Ib7099e8e3bbc15f29bbaa1db37ef21e78a74e7bc\n\nCloses-Bug: #1228744\nChange-Id: Ie02c4e75ca1ab995102aa55bbff39b2161218b2d\n'}, {'number': 2, 'created': '2014-11-24 06:57:20.000000000', 'files': ['glanceclient/common/http.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/465c5cef8d23dcd5400fdfb1aae6d7155c0d44a6', 'message': 'Curl statements to include globoff for IPv6 URLs\n\npython-glanceclient displays curl statements for debugging/troubleshooting\npurposes. For IPv6 URLs, curl requires --globoff to be passed in the\narguments. Since glanceclient does not use curl directly, this patch\ndisplays the curl commands with globoff option which works for both\nIPv4 and IPv6 URLs.\nFix adapted from python-novaclient Ib7099e8e3bbc15f29bbaa1db37ef21e78a74e7bc\n\nCloses-Bug: #1228744\nChange-Id: Ie02c4e75ca1ab995102aa55bbff39b2161218b2d\n'}]",0,136329,465c5cef8d23dcd5400fdfb1aae6d7155c0d44a6,18,6,2,10257,,,0,"Curl statements to include globoff for IPv6 URLs

python-glanceclient displays curl statements for debugging/troubleshooting
purposes. For IPv6 URLs, curl requires --globoff to be passed in the
arguments. Since glanceclient does not use curl directly, this patch
displays the curl commands with globoff option which works for both
IPv4 and IPv6 URLs.
Fix adapted from python-novaclient Ib7099e8e3bbc15f29bbaa1db37ef21e78a74e7bc

Closes-Bug: #1228744
Change-Id: Ie02c4e75ca1ab995102aa55bbff39b2161218b2d
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/29/136329/2 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/common/http.py', 'glanceclient/openstack/common/apiclient/client.py']",2,df36073e96bbd08b4dc136ace83d9425a4a41ca3,bug/1228744," ""curl -g -i"","," ""curl -i"",",2,2
openstack%2Fopenstack-ansible~juno~I45dc082cbce2ad3df267387f76579937ab1130f1,openstack/openstack-ansible,juno,I45dc082cbce2ad3df267387f76579937ab1130f1,pin mariadb to version 5.5.41,MERGED,2015-01-08 11:48:16.000000000,2015-01-08 14:55:37.000000000,2015-01-08 13:31:40.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-08 11:48:16.000000000', 'files': ['rpc_deployment/vars/repo_packages/all_common.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/59edbe9eda007dfd5876441d6e1b4d4d17054b79', 'message': ""pin mariadb to version 5.5.41\n\nIn order to pin to a specific version, you need to point at a repo that\nonly contains that version, as opposed to a main repo that contains all\nthe versions.\n\nThis pinning is to prevent issues when new versions of mariadb are\nreleased (the release of 5.5.41 broke the deployment, and we want to prevent\nthis happenening again now we've fixed that particular issue - 1408138)\n\nWe also bring in the change to the mirror since jmu.edu was unreliable\n\nChange-Id: I45dc082cbce2ad3df267387f76579937ab1130f1\nCloses-Bug: 1408608\n(cherry picked from commit b37140a14d36b712d4ec465ecd6407b7c164f2d2)\n""}]",0,145753,59edbe9eda007dfd5876441d6e1b4d4d17054b79,8,4,1,425,,,0,"pin mariadb to version 5.5.41

In order to pin to a specific version, you need to point at a repo that
only contains that version, as opposed to a main repo that contains all
the versions.

This pinning is to prevent issues when new versions of mariadb are
released (the release of 5.5.41 broke the deployment, and we want to prevent
this happenening again now we've fixed that particular issue - 1408138)

We also bring in the change to the mirror since jmu.edu was unreliable

Change-Id: I45dc082cbce2ad3df267387f76579937ab1130f1
Closes-Bug: 1408608
(cherry picked from commit b37140a14d36b712d4ec465ecd6407b7c164f2d2)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/53/145753/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/vars/repo_packages/all_common.yml'],1,59edbe9eda007dfd5876441d6e1b4d4d17054b79,bug/1408608," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/mariadb-5.5.41/repo/ubuntu/ {{ ansible_distribution_release }} main"", state: ""present"" }"," - { repo: ""deb http://mirror.jmu.edu/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }",1,1
openstack%2Fironic-specs~master~I8d865a91ba78184f2920a33988be7a94f4380a32,openstack/ironic-specs,master,I8d865a91ba78184f2920a33988be7a94f4380a32,Add support for VirtualBox WebService.,MERGED,2014-11-30 05:50:01.000000000,2015-01-08 14:54:38.000000000,2015-01-06 23:02:05.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 9315}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 12356}, {'_account_id': 12952}, {'_account_id': 14046}]","[{'number': 1, 'created': '2014-11-30 05:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7e1b097a8b42f9488717a31436b1f21db799fe38', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nThis is the stage 1 of proposing a spec for Kilo, in this stage we\nshould determine whether the idea is in the scope and in alignment with\nproject direction.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 2, 'created': '2014-12-01 15:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/18ade04ab747b2eef6669d9678cbaeff1c2c9c1e', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nThis is the stage 1 of proposing a spec for Kilo, in this stage we\nshould determine whether the idea is in the scope and in alignment with\nproject direction.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 3, 'created': '2014-12-01 15:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e16a98b3ac8640b4b435c81cd30f192518d12bca', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nThis is the stage 1 of proposing a spec for Kilo, in this stage we\nshould determine whether the idea is in the scope and in alignment with\nproject direction.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 4, 'created': '2014-12-09 09:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c6983d150d86ad4866c84c4d0084abc98929eda3', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 5, 'created': '2014-12-09 09:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/69ef5040be83a4ddc7a2dda88c1fc2bea4ebd718', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 6, 'created': '2014-12-22 11:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/046ff8f727532331aa28f7049677bd67404f94db', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 7, 'created': '2014-12-23 09:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/f01526e308dc168c3f24915a7a2fc92a58959674', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 8, 'created': '2014-12-31 08:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/fca05960dbdfcbaa9fc5d4854e3dd1e83c7b5750', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}, {'number': 9, 'created': '2015-01-05 14:43:14.000000000', 'files': ['specs/kilo/ironic-virtualbox-webservice-support.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ac85d5b8057213ea1db27e8c807d6c281ac22edb', 'message': 'Add support for VirtualBox WebService.\n\nThis change proposed to add support for using VirtualBox VMs\nas bare metal nodes managing them with VirtualBox WebService.\n\nChange-Id: I8d865a91ba78184f2920a33988be7a94f4380a32\n'}]",23,137926,ac85d5b8057213ea1db27e8c807d6c281ac22edb,52,10,9,9315,,,0,"Add support for VirtualBox WebService.

This change proposed to add support for using VirtualBox VMs
as bare metal nodes managing them with VirtualBox WebService.

Change-Id: I8d865a91ba78184f2920a33988be7a94f4380a32
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/26/137926/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/vbox-ws-support.rst'],1,7e1b097a8b42f9488717a31436b1f21db799fe38,vbox_power,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Add support for VirtualBox through WebService ============================================= This change proposes to add ``PowerInterface`` and ``ManagementInterface`` of VirtualBox for testing purposes through VirtualBox WebService. Problem description =================== Some developers are forced to run Windows on their office laptop. Such developers may use a linux VM running in VirtualBox as their cloud controller. There is no way for the developer's to do testing of Ironic on their laptop using VMs in the same VirtualBox Windows host (with hardware-assisted virtualization) as bare metal nodes. Developers may choose to run kvm/qemu inside their VirtualBox VM but nested virtualization is really slow (as there is no hardware assistance). Currently Ironic has support for using a VirtualBox VM as a bare metal and do provisioning on it. It works by doing SSH into the VirtualBox host and running commands using VBoxManage. This works well if you have VirtualBox installed on a Linux box. But when VirtualBox is installed on a Windows box, configuring and getting SSH to work with VBoxManage is a difficult (if not impossible) due to following reasons: * Windows doesn't come with native SSH support and one needs to use some third-party software to enable SSH support on Windows. * Even after configuring SSH, VBoxManage doesn't work remotely due to how Windows manages user accounts - the native Windows user account is different from the corresponding SSH user account, and VBoxManage doesn't work properly when done with SSH user account. * Even after tweaking policies of VirtualBox application, the remote VBoxManage and VBoxSvc don't sync each other properly and often results in a crash. Proposed change =============== VirtualBox comes with a very friendly WebService to manage the VMs remotely. This works by talking to a WebService running on the VirtualBox host using SOAP. VirtualBox already provides a very easy-to-use python binding over this SOAP API and it available as VirtualBox SDK[1]. We can write a new implementation of ``PowerInterface`` and ``ManagementInterface`` using this python binding of the VirtualBox WebService SOAP API. Using this, developers forced to run Windows on their laptop can do the following with VirtualBox installed on their Windows box: * Create a VirtualBox VM and use it as cloud controller. Configure two networks - one NAT enabled and one private network ``intnet``. * Create a VirtualBox VM and use it as test machine. Connect it only to ``intnet``. This can be used as Ironic bare metal node for the above cloud controller. [1] http://download.virtualbox.org/virtualbox/vboxsdkdownload.html ",,60,0
openstack%2Fneutron~master~I0e887b1401daec991f2244fb897a4b1dd206bf35,openstack/neutron,master,I0e887b1401daec991f2244fb897a4b1dd206bf35,NSX: separate DB & backend ops for floating IPs,ABANDONED,2014-12-01 14:36:39.000000000,2015-01-08 14:53:33.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10354}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-01 14:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f94d9dab82b034fbdf047ff7d15ffa4ecbdbb13', 'message': ""NSX: oversee IP allocation on external network\n\nWith this patch, the NSX plugin will pick an IP address for a\nrouter gateway or floating IP port rather than having Neutron's\nDB IPAM logic choose one.\n\nThe aim of this patch is to work around the 'lock wait' timeout\nissues arising from locking queries issued for generating an IP.\n\nA retry mechanism for repeating the operation in case of IP\nallocation clashes is provided as well. To this aim the code\npertaining DB operations for creating a port has been moved to a\nnew method.\n\nUnit test coverage has been added for the changes in the nsx\nplugin database routines module. The changes in the plugin module,\nmostly being a refactor of existing code, are already covered by\nexisting unit tests.\n\nChange-Id: I0e887b1401daec991f2244fb897a4b1dd206bf35\nCloses-Bug: #TBD\n""}, {'number': 2, 'created': '2014-12-01 16:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8e0d75d67b67d9d819994bb6721afb9866b941c', 'message': ""NSX: oversee IP allocation on external network\n\nWith this patch, the NSX plugin will pick an IP address for a\nrouter gateway or floating IP port rather than having Neutron's\nDB IPAM logic choose one.\n\nThe aim of this patch is to work around the 'lock wait' timeout\nissues arising from locking queries issued for generating an IP.\n\nA retry mechanism for repeating the operation in case of IP\nallocation clashes is provided as well. To this aim the code\npertaining DB operations for creating a port has been moved to a\nnew method.\n\nUnit test coverage has been added for the changes in the nsx\nplugin database routines module. The changes in the plugin module,\nmostly being a refactor of existing code, are already covered by\nexisting unit tests.\n\nChange-Id: I0e887b1401daec991f2244fb897a4b1dd206bf35\nCloses-Bug: #TBD\n""}, {'number': 3, 'created': '2014-12-05 14:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8db4da33934c6a31cffa4076d8915d625a1e8105', 'message': 'NSX: separate DB & backend ops for floating IPs\n\nThis patch changes the logic of the NSX plugin in order to prevent\nbackend operations to be performed within a DB transaction.\nDoing so increases the chances of triggering deadlocks due to\neventlet yielding in the middle of a transaction.\n\nFor floating IPs the risk is higher because they allocate IP\naddresses on external networks, where the level of contention is\nmuch higher than internal ones.\n\nThe logic of the floating IP operations has been changed to not\nrely anymore on _update_fip_assoc to implement the floating IP\nrules on the backend. Once the DB operation completes successfully,\nthe rules are implemented on the backend. In case of backend\nfailure the floating IP is put in error status, with the exception\nof the case where the floating IP has just been created, in which\ninstead the DB operation is reverted by deleting the floating IP.\n\nCloses-Bug: #TBD\n\nChange-Id: I0e887b1401daec991f2244fb897a4b1dd206bf35\n'}, {'number': 4, 'created': '2014-12-05 18:20:01.000000000', 'files': ['neutron/plugins/vmware/plugins/base.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/plugins/vmware/common/nsx_utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bbcb55f2c89ffb3d40d1dceb8cc47c7bb838a677', 'message': 'NSX: separate DB & backend ops for floating IPs\n\nThis patch changes the logic of the NSX plugin in order to prevent\nbackend operations to be performed within a DB transaction.\nDoing so increases the chances of triggering deadlocks due to\neventlet yielding in the middle of a transaction.\n\nFor floating IPs the risk is higher because they allocate IP\naddresses on external networks, where the level of contention is\nmuch higher than internal ones.\n\nThe logic of the floating IP operations has been changed to not\nrely anymore on _update_fip_assoc to implement the floating IP\nrules on the backend. Once the DB operation completes successfully,\nthe rules are implemented on the backend. In case of backend\nfailure the floating IP is put in error status, with the exception\nof the case where the floating IP has just been created, in which\ninstead the DB operation is reverted by deleting the floating IP.\n\nCloses-Bug: #TBD\n\nChange-Id: I0e887b1401daec991f2244fb897a4b1dd206bf35\n'}]",0,138078,bbcb55f2c89ffb3d40d1dceb8cc47c7bb838a677,95,25,4,261,,,0,"NSX: separate DB & backend ops for floating IPs

This patch changes the logic of the NSX plugin in order to prevent
backend operations to be performed within a DB transaction.
Doing so increases the chances of triggering deadlocks due to
eventlet yielding in the middle of a transaction.

For floating IPs the risk is higher because they allocate IP
addresses on external networks, where the level of contention is
much higher than internal ones.

The logic of the floating IP operations has been changed to not
rely anymore on _update_fip_assoc to implement the floating IP
rules on the backend. Once the DB operation completes successfully,
the rules are implemented on the backend. In case of backend
failure the floating IP is put in error status, with the exception
of the case where the floating IP has just been created, in which
instead the DB operation is reverted by deleting the floating IP.

Closes-Bug: #TBD

Change-Id: I0e887b1401daec991f2244fb897a4b1dd206bf35
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/138078/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/vmware/plugins/base.py', 'neutron/tests/unit/vmware/db/test_nsx_db.py', 'neutron/plugins/vmware/common/utils.py', 'neutron/plugins/vmware/dbexts/db.py']",4,3f94d9dab82b034fbdf047ff7d15ffa4ecbdbb13,for_fulljob_skae,"import random import netaddrfrom neutron.db import models_v2from neutron.openstack.common import uuidutilsdef find_available_ip(session, subnet_id, subnet_cidr): random.seed(uuidutils.generate_uuid()) allocations = (session.query(models_v2.IPAllocation). filter_by(subnet_id=subnet_id)) allocated_ipset = netaddr.IPSet([allocation['ip_address'] for allocation in allocations]) subnet = netaddr.IPNetwork(subnet_cidr) available_ipset = (netaddr.IPSet(subnet) - allocated_ipset - netaddr.IPSet([subnet.network, subnet.broadcast])) # pick a random address from the first available contiguous range for ip_range in available_ipset.iter_ipranges(): return str(ip_range[random.randint(0, len(ip_range) - 1)]) ",,163,21
openstack%2Fmanila~master~Ie2a9c551eb85c8754bd512bdef6cf4a2fee8f6c0,openstack/manila,master,Ie2a9c551eb85c8754bd512bdef6cf4a2fee8f6c0,Updated from global requirements,MERGED,2015-01-08 02:29:37.000000000,2015-01-08 14:42:35.000000000,2015-01-08 14:42:35.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 7102}, {'_account_id': 8851}]","[{'number': 1, 'created': '2015-01-08 02:29:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/8ee1adcf5ce9f8adb6703b895ee53d94958d42c3', 'message': 'Updated from global requirements\n\nChange-Id: Ie2a9c551eb85c8754bd512bdef6cf4a2fee8f6c0\n'}]",0,145667,8ee1adcf5ce9f8adb6703b895ee53d94958d42c3,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ie2a9c551eb85c8754bd512bdef6cf4a2fee8f6c0
",git fetch https://review.opendev.org/openstack/manila refs/changes/67/145667/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8ee1adcf5ce9f8adb6703b895ee53d94958d42c3,openstack/requirements,oslo.db>=1.3.0 # Apache-2.0,oslo.db>=1.1.0 # Apache-2.0,1,1
openstack%2Frequirements~master~Ie529d0704d4fb7b3acf2458643791c438f8344a0,openstack/requirements,master,Ie529d0704d4fb7b3acf2458643791c438f8344a0,Update oslo.utils to 1.2.0,ABANDONED,2015-01-08 14:41:32.000000000,2015-01-08 14:42:12.000000000,,[],"[{'number': 1, 'created': '2015-01-08 14:41:32.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/baba3c17192117bf44f1242e216be8b44b53deb4', 'message': ""Update oslo.utils to 1.2.0\n\nThere's a big performance improvement when masking passwords\nand we have the namespace changes as well. So let's please\nupdate the oslo.utils to 1.2.0\n\nChange-Id: Ie529d0704d4fb7b3acf2458643791c438f8344a0\n""}]",0,145797,baba3c17192117bf44f1242e216be8b44b53deb4,2,0,1,5638,,,0,"Update oslo.utils to 1.2.0

There's a big performance improvement when masking passwords
and we have the namespace changes as well. So let's please
update the oslo.utils to 1.2.0

Change-Id: Ie529d0704d4fb7b3acf2458643791c438f8344a0
",git fetch https://review.opendev.org/openstack/requirements refs/changes/97/145797/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,baba3c17192117bf44f1242e216be8b44b53deb4,,oslo.utils>=1.2.0 # Apache-2.0,oslo.utils>=1.1.0 # Apache-2.0,1,1
openstack%2Fglance~master~I7215e35534fd9a77730d39b96f9ba3bf6c3ea065,openstack/glance,master,I7215e35534fd9a77730d39b96f9ba3bf6c3ea065,Move default_store option in glance-api.conf,MERGED,2014-12-23 05:44:04.000000000,2015-01-08 14:39:33.000000000,2014-12-24 08:10:18.000000000,"[{'_account_id': 3}, {'_account_id': 6549}, {'_account_id': 9126}, {'_account_id': 10705}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-23 05:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bae6225dd76bee67b40e7388facb6a225a2bda62', 'message': 'Move default_store option in glance-api.conf\n\n[DEFAULT] default_store was deprecated in Juno and moved into the\n[glance_store] section. Yet it remains in the old place in the sample\nglance-api.conf. Additionally, some comments still refer to the\nknown_stores option, which is now simply stores.\n\nChange-Id: I7215e35534fd9a77730d39b96f9ba3bf6c3ea065\n'}, {'number': 2, 'created': '2014-12-23 22:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b009413deb5920c2f20f7d8409def5e10c752c98', 'message': 'Move default_store option in glance-api.conf\n\n[DEFAULT] default_store was deprecated in Juno and moved into the\n[glance_store] section. Yet it remains in the old place in the sample\nglance-api.conf. Additionally, some comments still refer to the\nknown_stores option, which is now simply stores.\n\nChange-Id: I7215e35534fd9a77730d39b96f9ba3bf6c3ea065\n'}, {'number': 3, 'created': '2014-12-24 06:10:06.000000000', 'files': ['etc/glance-api.conf', 'doc/source/configuring.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/99124f627f2d8506a652b8d09740658215ef6674', 'message': 'Move default_store option in glance-api.conf\n\n[DEFAULT] default_store was deprecated in Juno and moved into the\n[glance_store] section. Yet it remains in the old place in the sample\nglance-api.conf. Additionally, some comments still refer to the\nknown_stores option, which is now simply stores.\n\nDocImpact\n\nChange-Id: I7215e35534fd9a77730d39b96f9ba3bf6c3ea065\n'}]",2,143599,99124f627f2d8506a652b8d09740658215ef6674,17,5,3,9126,,,0,"Move default_store option in glance-api.conf

[DEFAULT] default_store was deprecated in Juno and moved into the
[glance_store] section. Yet it remains in the old place in the sample
glance-api.conf. Additionally, some comments still refer to the
known_stores option, which is now simply stores.

DocImpact

Change-Id: I7215e35534fd9a77730d39b96f9ba3bf6c3ea065
",git fetch https://review.opendev.org/openstack/glance refs/changes/99/143599/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/glance-api.conf'],1,bae6225dd76bee67b40e7388facb6a225a2bda62,mv-default_store-api_conf,# registered by one of the stores defined by the 'stores' config option.# Which backend scheme should Glance use by default is not specified # in a request to add a new image to Glance? Known schemes are determined # by the stores option. # Default: 'file' default_store = file ,# Which backend scheme should Glance use by default is not specified # in a request to add a new image to Glance? Known schemes are determined # by the known_stores option below. # Default: 'file' default_store = file # registered by one of the stores defined by the 'known_stores' config option.,7,7
openstack%2Ftripleo-heat-templates~master~Ifba60454ee11222173a9762882e767a836a4545c,openstack/tripleo-heat-templates,master,Ifba60454ee11222173a9762882e767a836a4545c,Controller: Drive os-net-config via software conf,MERGED,2014-12-20 02:53:43.000000000,2015-01-08 14:39:31.000000000,2015-01-08 14:39:31.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-12-20 02:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1c3fef638f30f0154f685e2b69b3fcaa66fad3d', 'message': 'Controller: Drive os-net-config via software conf\n\nThis example extends the controller software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar.\n\nThe default is to use net-config-noop.yaml which\nwill pass no config metadata into the os-net-config\nelement which will essentially disable it in favor\nof using parameters w/ init-neutron-ovs.\n\nChange-Id: Ifba60454ee11222173a9762882e767a836a4545c\n'}, {'number': 2, 'created': '2015-01-05 19:09:49.000000000', 'files': ['controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/84bdcb23d171d3511688d0f54f0bf62479544376', 'message': 'Controller: Drive os-net-config via software conf\n\nThis example extends the controller software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar.\n\nThe default is to use net-config-noop.yaml which\nwill pass no config metadata into the os-net-config\nelement which will essentially disable it in favor\nof using parameters w/ init-neutron-ovs.\n\nChange-Id: Ifba60454ee11222173a9762882e767a836a4545c\n'}]",0,143243,84bdcb23d171d3511688d0f54f0bf62479544376,12,4,2,360,,,0,"Controller: Drive os-net-config via software conf

This example extends the controller software configuration
so that heat metadata is used to model the os-net-config
YAML (ultimately JSON) directly. The existing
os-net-config element already supports this format.

Configuring the physical network layer in this manner
would supplant the ever growing list of Heat parameters
that we have and is something that could be automatically
generated via tuskar.

The default is to use net-config-noop.yaml which
will pass no config metadata into the os-net-config
element which will essentially disable it in favor
of using parameters w/ init-neutron-ovs.

Change-Id: Ifba60454ee11222173a9762882e767a836a4545c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/143243/1 && git format-patch -1 --stdout FETCH_HEAD,['controller.yaml'],1,b1c3fef638f30f0154f685e2b69b3fcaa66fad3d,puppet," NetworkConfig: type: OS::TripleO::Net::SoftwareConfig NetworkDeployment: type: OS::TripleO::SoftwareDeployment properties: signal_transport: NO_SIGNAL config: {get_attr: [NetworkConfig, config_id]} server: {get_resource: Controller} input_values: bridge_name: br-ex interface_name: {get_param: NeutronPublicInterface} ",,13,0
openstack%2Ftripleo-heat-templates~master~I228216a0b55ff2d384b281d9ad2a61b93d58dab9,openstack/tripleo-heat-templates,master,I228216a0b55ff2d384b281d9ad2a61b93d58dab9,Controller: Split out software config,MERGED,2014-10-28 22:01:31.000000000,2015-01-08 14:39:24.000000000,2015-01-08 14:39:23.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-10-28 22:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e8a060eeb83e7fa6267a3d08348500f15721ac05', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 2, 'created': '2014-10-31 16:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9c9503a00d588efd8c9e773179001cdf13a378d3', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 3, 'created': '2014-11-14 17:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/edd13c3f7f2043a7b9728ac25a63eb40e1169000', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 4, 'created': '2014-12-08 14:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cb14ad845c00ea4183b8e49ba433ab6663e35e14', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 5, 'created': '2014-12-09 12:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/63ab42cca80e45da858dab6e47fb2e9e2f2f5ea0', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 6, 'created': '2014-12-09 13:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03ac0d621f72725909758d24271e2f9c308149f8', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 7, 'created': '2014-12-09 18:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4ac6eb35533760906256cf3948da414f36d402aa', 'message': 'Split out controller software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 8, 'created': '2014-12-20 02:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7ebc98c022b4d4c48292b569891b307c87d6773e', 'message': 'Controller: Split out software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}, {'number': 9, 'created': '2015-01-05 19:09:49.000000000', 'files': ['overcloud-resource-registry.yaml', 'controller.yaml', 'controller-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f567ba6dea9ef6147ba9214606f9a4d434e99eb1', 'message': 'Controller: Split out software config\n\nThis is a step towards supporting pluggable software configurations\nin the heat templates. By moving controller-config out of controller.yaml\nwe make it possible to define alternate implementations by\nchanging the OS::TripleO::ControllerConfig value in the\novercloud-resource-registry.yaml heat environment file.\n\nChange-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9\n'}]",1,131583,f567ba6dea9ef6147ba9214606f9a4d434e99eb1,68,10,9,360,,,0,"Controller: Split out software config

This is a step towards supporting pluggable software configurations
in the heat templates. By moving controller-config out of controller.yaml
we make it possible to define alternate implementations by
changing the OS::TripleO::ControllerConfig value in the
overcloud-resource-registry.yaml heat environment file.

Change-Id: I228216a0b55ff2d384b281d9ad2a61b93d58dab9
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/131583/6 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry.yaml', 'controller.yaml', 'controller-config.yaml']",3,e8a060eeb83e7fa6267a3d08348500f15721ac05,puppet,"heat_template_version: 2014-10-16 description: > Controller Config for Controller. resources: ControllerConfigImpl: type: OS::Heat::StructuredConfig properties: group: os-apply-config config: admin-password: {get_param: AdminPassword} admin-token: {get_param: AdminToken} bootstack: public_interface_ip: {get_param: NeutronPublicInterfaceIP} bootstrap_host: nodeid: {get_input: bootstack_nodeid} database: host: &database_host {get_param: VirtualIP} cinder: db: list_join: - '' - - mysql://cinder:unset@ - *database_host - /cinder debug: {get_param: Debug} volume_size_mb: {get_param: CinderLVMLoopDeviceSize} service-password: {get_param: CinderPassword} iscsi-helper: {get_param: CinderISCSIHelper} controller-address: {get_input: controller_host} corosync: bindnetaddr: {get_input: controller_host} mcastport: 5577 pacemaker: stonith_enabled : false recheck_interval : 5 quorum_policy : ignore db-password: unset glance: registry: host: {get_input: controller_virtual_ip} backend: swift db: list_join: - '' - - mysql://glance:unset@ - *database_host - /glance debug: {get_param: Debug} host: {get_input: controller_virtual_ip} port: {get_param: GlancePort} protocol: {get_param: GlanceProtocol} service-password: {get_param: GlancePassword} swift-store-user: service:glance swift-store-key: {get_param: GlancePassword} notifier-strategy: {get_param: GlanceNotifierStrategy} log-file: {get_param: GlanceLogFile} heat: admin_password: {get_param: HeatPassword} admin_tenant_name: service admin_user: heat auth_encryption_key: unset___________ db: list_join: - '' - - mysql://heat:unset@ - *database_host - /heat debug: {get_param: Debug} stack_domain_admin_password: {get_param: HeatStackDomainAdminPassword} watch_server_url: {get_input: heat.watch_server_url} metadata_server_url: {get_input: heat.metadata_server_url} waitcondition_server_url: {get_input: heat.waitcondition_server_url} keystone: db: list_join: - '' - - mysql://keystone:unset@ - *database_host - /keystone debug: {get_param: Debug} host: {get_input: controller_virtual_ip} ca_certificate: {get_param: KeystoneCACertificate} signing_key: {get_param: KeystoneSigningKey} signing_certificate: {get_param: KeystoneSigningCertificate} mysql: innodb_buffer_pool_size: {get_param: MysqlInnodbBufferPoolSize} local_bind: true root-password: {get_param: MysqlRootPassword} cluster_name: str_replace: template: tripleo-CLUSTER params: CLUSTER: {get_param: MysqlClusterUniquePart} neutron: debug: {get_param: Debug} flat-networks: {get_param: NeutronFlatNetworks} host: {get_input: controller_virtual_ip} metadata_proxy_shared_secret: unset ovs: enable_tunneling: {get_input: neutron_enable_tunneling} local_ip: {get_input: controller_host} network_vlan_ranges: {get_param: NeutronNetworkVLANRanges} bridge_mappings: {get_param: NeutronBridgeMappings} public_interface: {get_param: NeutronPublicInterface} public_interface_raw_device: {get_param: NeutronPublicInterfaceRawDevice} public_interface_route: {get_param: NeutronPublicInterfaceDefaultRoute} public_interface_tag: {get_param: NeutronPublicInterfaceTag} physical_bridge: br-ex tenant_network_type: {get_param: NeutronNetworkType} tunnel_types: {get_param: NeutronTunnelTypes} ovs_db: list_join: - '' - - mysql://neutron:unset@ - *database_host - /ovs_neutron?charset=utf8 service-password: {get_param: NeutronPassword} dnsmasq-options: {get_param: NeutronDnsmasqOptions} ceilometer: db: list_join: - '' - - mysql://ceilometer:unset@ - *database_host - /ceilometer debug: {get_param: Debug} metering_secret: {get_param: CeilometerMeteringSecret} service-password: {get_param: CeilometerPassword} snmpd: export_MIB: UCD-SNMP-MIB readonly_user_name: {get_param: SnmpdReadonlyUserName} readonly_user_password: {get_param: SnmpdReadonlyUserPassword} nova: compute_driver: libvirt.LibvirtDriver db: list_join: - '' - - mysql://nova:unset@ - *database_host - /nova default_floating_pool: ext-net host: {get_input: controller_virtual_ip} metadata-proxy: true service-password: {get_param: NovaPassword} rabbit: host: {get_input: controller_virtual_ip} username: {get_param: RabbitUserName} password: {get_param: RabbitPassword} cookie: {get_param: RabbitCookie} ntp: servers: - {server: {get_param: NtpServer}, fudge: ""stratum 0""} virtual_interfaces: instances: - vrrp_instance_name: VI_CONTROL virtual_router_id: 51 keepalive_interface: {get_param: ControlVirtualInterface} priority: 101 virtual_ips: - ip: {get_param: VirtualIP} interface: {get_param: ControlVirtualInterface} - vrrp_instance_name: VI_PUBLIC virtual_router_id: 52 keepalive_interface: {get_param: PublicVirtualInterface} priority: 101 virtual_ips: - ip: {get_param: PublicVirtualIP} interface: {get_param: PublicVirtualInterface} vrrp_sync_groups: - name: VG1 members: - VI_CONTROL - VI_PUBLIC keepalived: keepalive_interface: {get_param: PublicVirtualInterface} priority: 101 virtual_ips: - ip: {get_param: VirtualIP} interface: {get_param: ControlVirtualInterface} - ip: {get_param: PublicVirtualIP} interface: {get_param: PublicVirtualInterface} haproxy: net_binds: - ip: {get_param: VirtualIP} services: - name: keystone_admin port: 35357 net_binds: &public_binds - ip: {get_param: VirtualIP} - ip: {get_param: PublicVirtualIP} - name: keystone_public port: 5000 net_binds: *public_binds - name: horizon port: 80 net_binds: *public_binds - name: neutron port: 9696 net_binds: *public_binds - name: cinder port: 8776 net_binds: *public_binds - name: glance_api port: 9292 net_binds: *public_binds - name: glance_registry port: 9191 net_binds: *public_binds - name: heat_api port: 8004 net_binds: *public_binds - name: heat_cloudwatch port: 8003 net_binds: *public_binds - name: heat_cfn port: 8000 net_binds: *public_binds - name: mysql port: 3306 extra_server_params: - backup options: - timeout client 0 - timeout server 0 - name: nova_ec2 port: 8773 - name: nova_osapi port: 8774 net_binds: *public_binds - name: nova_metadata port: 8775 net_binds: *public_binds - name: ceilometer port: 8777 net_binds: *public_binds - name: swift_proxy_server port: 8080 net_binds: *public_binds - name: rabbitmq port: 5672 options: - timeout client 0 - timeout server 0 ",,251,242
openstack%2Fanchor~master~I7b585a1e30c473df089ba508099af159e432cc78,openstack/anchor,master,I7b585a1e30c473df089ba508099af159e432cc78,Bringing Anchor project setup inline with OpenStack,MERGED,2014-12-17 16:28:46.000000000,2015-01-08 14:39:15.000000000,2015-01-08 14:39:14.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-12-17 16:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/4cbc3b5064b5108fdb91bdb94ce9de5544b312c8', 'message': 'Bringing Anchor project setup inline with OpenStack\n\n- Adding scaffolding for testing (PEP8 mostly disabled for now)\n- Adding requirments lists\n\nChange-Id: I7b585a1e30c473df089ba508099af159e432cc78\n'}, {'number': 2, 'created': '2015-01-07 13:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/b5a11245ee5d2da46242803790830d8ed85b269a', 'message': 'Bringing Anchor project setup inline with OpenStack\n\n- Adding scaffolding for testing (PEP8 mostly disabled for now)\n- Adding requirments lists\n\nChange-Id: I7b585a1e30c473df089ba508099af159e432cc78\n'}, {'number': 3, 'created': '2015-01-08 13:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/66440a366ede5077b3c47314f6369e15b1aa53d2', 'message': 'Bringing Anchor project setup inline with OpenStack\n\n- Adding scaffolding for testing (PEP8 mostly disabled for now)\n- Adding requirments lists\n\nChange-Id: I7b585a1e30c473df089ba508099af159e432cc78\n'}, {'number': 4, 'created': '2015-01-08 13:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/f8b32ba23454883995bea9e92f93c5f96c02858c', 'message': 'Bringing Anchor project setup inline with OpenStack\n\n- Adding scaffolding for testing (PEP8 mostly disabled for now)\n- Adding requirments lists\n\nChange-Id: I7b585a1e30c473df089ba508099af159e432cc78\n'}, {'number': 5, 'created': '2015-01-08 14:20:53.000000000', 'files': ['requirements.txt', '.gitignore', 'test-requirements.txt', '.testr.conf', 'setup.py', 'tests/test_basic.py', 'setup.cfg', 'tox.ini', 'tests/__init__.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/anchor/commit/9eada1323e2e269ed4e85c33da68fd32daa43db3', 'message': 'Bringing Anchor project setup inline with OpenStack\n\n- Adding scaffolding for testing (PEP8 mostly disabled for now)\n- Adding requirments lists\n\nChange-Id: I7b585a1e30c473df089ba508099af159e432cc78\n'}]",3,142486,9eada1323e2e269ed4e85c33da68fd32daa43db3,21,4,5,11716,,,0,"Bringing Anchor project setup inline with OpenStack

- Adding scaffolding for testing (PEP8 mostly disabled for now)
- Adding requirments lists

Change-Id: I7b585a1e30c473df089ba508099af159e432cc78
",git fetch https://review.opendev.org/openstack/anchor refs/changes/86/142486/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitignore', 'test-requirements.txt', '.testr.conf', 'setup.py', 'tests/test_basic.py', 'setup.cfg', 'tox.ini', 'tests/__init__.py']",9,4cbc3b5064b5108fdb91bdb94ce9de5544b312c8,anchor-infra,"#!/usr/bin/env python # Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. ",,153,31
openstack%2Fheat-translator~master~I30a9e18ec2f3026bc9ae88183042c9e845bc5188,openstack/heat-translator,master,I30a9e18ec2f3026bc9ae88183042c9e845bc5188,Minor tweaks,MERGED,2014-12-04 01:12:29.000000000,2015-01-08 14:09:20.000000000,2015-01-08 14:09:18.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 8246}, {'_account_id': 9591}]","[{'number': 1, 'created': '2014-12-04 01:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/3c8003815b062847c7caa33b8555514daa85ad93', 'message': 'Minor tweaks\n\nAdd yaml dump formatting for correct printing of the HOT template.\nChange the sequence of the life cycle operation to work for the\nmonitoring use case.  We still need to generalize the life cycle\nsequence to cover all scenarios.\n\nChange-Id: I30a9e18ec2f3026bc9ae88183042c9e845bc5188\n'}, {'number': 2, 'created': '2014-12-05 19:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/b7dac8be8dd4bfb6e90047973db5873dff6fb791', 'message': 'Minor tweaks\n\nAdd yaml dump formatting for correct printing of the HOT template.\nChange the sequence of the life cycle operation to work for the\nmonitoring use case.  We still need to generalize the life cycle\nsequence to cover all scenarios.\n\nChange-Id: I30a9e18ec2f3026bc9ae88183042c9e845bc5188\n'}, {'number': 3, 'created': '2014-12-06 07:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/61b8b674adf4e53b6b4aa64e087dfee8e3ea56b1', 'message': 'Minor tweaks\n\nAdd yaml dump formatting for correct printing of the HOT template.\nChange the sequence of the life cycle operation to work for the\nmonitoring use case.  We still need to generalize the life cycle\nsequence to cover all scenarios.\n\nChange-Id: I30a9e18ec2f3026bc9ae88183042c9e845bc5188\n'}, {'number': 4, 'created': '2014-12-10 23:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/030653c30bf23f68b8a03fedad742cef78ad551d', 'message': 'Minor tweaks\n\nAdd yaml dump formatting for correct printing of the HOT template.\nChange the sequence of the life cycle operation to work for the\nmonitoring use case.  We still need to generalize the life cycle\nsequence to cover all scenarios.\n\nChange-Id: I30a9e18ec2f3026bc9ae88183042c9e845bc5188\n'}, {'number': 5, 'created': '2015-01-06 23:20:16.000000000', 'files': ['translator/hot/syntax/hot_template.py', 'translator/hot/syntax/hot_resource.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/397ac68baaa20fb22b2459b282b6ef036036a390', 'message': 'Minor tweaks\n\nAdd yaml dump formatting for correct printing of the HOT template.\nChange the sequence of the life cycle operation to work for the\nmonitoring use case.  We still need to generalize the life cycle\nsequence to cover all scenarios.\n\nChange-Id: I30a9e18ec2f3026bc9ae88183042c9e845bc5188\n'}]",17,138928,397ac68baaa20fb22b2459b282b6ef036036a390,24,5,5,9591,,,0,"Minor tweaks

Add yaml dump formatting for correct printing of the HOT template.
Change the sequence of the life cycle operation to work for the
monitoring use case.  We still need to generalize the life cycle
sequence to cover all scenarios.

Change-Id: I30a9e18ec2f3026bc9ae88183042c9e845bc5188
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/28/138928/5 && git format-patch -1 --stdout FETCH_HEAD,"['translator/hot/syntax/hot_template.py', 'translator/hot/syntax/hot_resource.py']",2,3c8003815b062847c7caa33b8555514daa85ad93,bp/heat-translator-tosca,"from translator.toscalib.nodetemplate import NodeTemplate def __init__(self, nodetemplate, name=None, type=None, properties={}, # TODO(anyone): sequence for life cycle needs to cover different # scenarios and cannot be fixed or hard coded here # interfaces_deploy_sequence = ['create', 'start', 'configure'] interfaces_deploy_sequence = ['create', 'configure', 'start'] hosting_server = None if self.nodetemplate.requirements is not None: hosting_server = self._get_hosting_server() {'config': {'get_resource': config_name}, 'server': {'get_resource': hosting_server.name}}) lifecycle_inputs = self._get_lifecycle_inputs(interface) if lifecycle_inputs: deploy_resource.properties['input_values'] = \ lifecycle_inputs # If type is NodeTemplate, look up corresponding HotResrouce host_server = self.properties.get('server')['get_resource'] if host_server is None: raise Exception('Internal Error: expecting host \ in software deployment') elif isinstance(host_server, NodeTemplate): self.properties['server']['get_resource'] = host_server.name def _get_lifecycle_inputs(self, interface): # check if this lifecycle operation has input values specified # extract and convert to HOT format if isinstance(interface.value, str): # the interface has a static string return {} else: # the interface is a dict {'implemenation': xxx, 'input': yyy} inputs = interface.value.get('input') deploy_inputs = {} if inputs: for name, value in inputs.iteritems(): deploy_inputs[name] = value return deploy_inputs def _get_hosting_server(self): # find the server that hosts this software by checking the # requirements for requirement in self.nodetemplate.requirements: for requirement_name, node_name in requirement.iteritems(): for check_node in self.nodetemplate.related_nodes: # check if the capability is Container if node_name == check_node.name: if self._is_container_type(requirement_name, check_node): return check_node return None def _is_container_type(self, requirement_name, node): # capability is a list of dict # For now just check if it's type tosca.nodes.Compute # TODO(anyone): match up requirement and capability if node.type == 'tosca.nodes.Compute': return True else: return False def _get_hot_attribute(self, args): attr = {} # check the HOT resource type to call the appropriate # attribute handler # args[0] should be the target node of the function call attr['get_attr'] = [args[0], 'networks', '""private""', 0] return attr"," def __init__(self, nodetemplate, name=None, type=None, properties=None, interfaces_deploy_sequence = ['create', 'start', 'configure'] {'config': {'get_resource': config_name}}) host_server = self.properties.get('server') if host_server is None: host_server = self.bottom_of_chain().\ properties['server']['get_resource'] self.properties['server'] = {'get_resource': host_server}",69,8
openstack%2Frelease-tools~master~Id07126394ed9679bd65e1cd334261d9d5ca1618d,openstack/release-tools,master,Id07126394ed9679bd65e1cd334261d9d5ca1618d,ossa-to-wiki script,ABANDONED,2014-09-29 00:25:56.000000000,2015-01-08 14:08:21.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 308}, {'_account_id': 1955}, {'_account_id': 7473}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-09-29 00:25:56.000000000', 'files': ['ossa-to-wiki.py', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/889b216bb60036d9cd7adbd050a155f24d92c97e', 'message': 'ossa-to-wiki script\n\nExtract OSSAs from openstack-announce archive\nand output in wiki format for stable point releases at\nhttps://wiki.openstack.org/wiki/ReleaseNotes/2014.1.2\nand\nhttps://wiki.openstack.org/wiki/SecurityAdvisories/Icehouse\n\nChange-Id: Id07126394ed9679bd65e1cd334261d9d5ca1618d\n'}]",0,124653,889b216bb60036d9cd7adbd050a155f24d92c97e,5,6,1,1955,,,0,"ossa-to-wiki script

Extract OSSAs from openstack-announce archive
and output in wiki format for stable point releases at
https://wiki.openstack.org/wiki/ReleaseNotes/2014.1.2
and
https://wiki.openstack.org/wiki/SecurityAdvisories/Icehouse

Change-Id: Id07126394ed9679bd65e1cd334261d9d5ca1618d
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/53/124653/1 && git format-patch -1 --stdout FETCH_HEAD,"['ossa-to-wiki.py', 'requirements.txt']",2,889b216bb60036d9cd7adbd050a155f24d92c97e,,requests>=2.3.0 CacheControl,requests>=1.1,179,1
openstack%2Foslo.db~master~I3acdc0fb30327f56a76ee299cc6bade7c5a7e312,openstack/oslo.db,master,I3acdc0fb30327f56a76ee299cc6bade7c5a7e312,Ensure mysql_sql_mode is set for MySQLOpportunisticTests,MERGED,2015-01-07 23:10:30.000000000,2015-01-08 14:07:06.000000000,2015-01-08 14:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2015-01-07 23:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/fb1a29e1d97e9542e82aec8796354369bc1e594d', 'message': 'Ensure mysql_sql_mode is set for MySQLOpportunisticTests\n\nThe default setting for oslo.db is TRADITIONAL for mysql_sql_mode;\nthis is set up in oslo_db/options.py as well as\nin EngineFacade; however, the provisioning system currently does not\nuse these options or EngineFacade, and the default for\nmysql_sql_mode in the base session.create_engine() is None.\nFor a MySQL/MariaDB database where this is not established in my.cnf,\ntests will run without TRADITIONAL SQL mode and some tests will fail,\nincluding some Nova migration tests that rely upon this.\n\nThis patch resolves that as well as the warning we see\nin tests regarding the empty SQL mode.\n\nChange-Id: I3acdc0fb30327f56a76ee299cc6bade7c5a7e312\n'}, {'number': 2, 'created': '2015-01-08 10:02:26.000000000', 'files': ['oslo_db/sqlalchemy/provision.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/tests/old_import_api/sqlalchemy/test_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/cfbe5c56340c0e4a3b18902d7e55bb18a45857ec', 'message': 'Ensure mysql_sql_mode is set for MySQLOpportunisticTests\n\nThe default setting for oslo.db is TRADITIONAL for mysql_sql_mode;\nthis is set up in oslo_db/options.py as well as\nin EngineFacade; however, the provisioning system currently does not\nuse these options or EngineFacade, and the default for\nmysql_sql_mode in the base session.create_engine() is None.\nFor a MySQL/MariaDB database where this is not established in my.cnf,\ntests will run without TRADITIONAL SQL mode and some tests will fail,\nincluding some Nova migration tests that rely upon this.\n\nThis patch resolves that as well as the warning we see\nin tests regarding the empty SQL mode.\n\nChange-Id: I3acdc0fb30327f56a76ee299cc6bade7c5a7e312\n'}]",1,145622,cfbe5c56340c0e4a3b18902d7e55bb18a45857ec,13,3,2,11816,,,0,"Ensure mysql_sql_mode is set for MySQLOpportunisticTests

The default setting for oslo.db is TRADITIONAL for mysql_sql_mode;
this is set up in oslo_db/options.py as well as
in EngineFacade; however, the provisioning system currently does not
use these options or EngineFacade, and the default for
mysql_sql_mode in the base session.create_engine() is None.
For a MySQL/MariaDB database where this is not established in my.cnf,
tests will run without TRADITIONAL SQL mode and some tests will fail,
including some Nova migration tests that rely upon this.

This patch resolves that as well as the warning we see
in tests regarding the empty SQL mode.

Change-Id: I3acdc0fb30327f56a76ee299cc6bade7c5a7e312
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/22/145622/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/provision.py', 'oslo_db/tests/sqlalchemy/test_sqlalchemy.py', 'oslo_db/tests/old_import_api/sqlalchemy/test_sqlalchemy.py']",3,fb1a29e1d97e9542e82aec8796354369bc1e594d,ensure_sql_mode_set_in_tests," # get the GLOBAL sql_mode, not the @@SESSION, so that # we get what is configured for the MySQL database, as opposed # to what our own session.create_engine() has set it to. ""SELECT @@GLOBAL.sql_mode"").scalar()"," ""SHOW VARIABLES LIKE 'sql_mode'"").fetchone()[1]",24,3
openstack%2Fheat-translator~master~Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3,openstack/heat-translator,master,Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3,Main translation code to handle parameters,MERGED,2014-12-04 01:12:29.000000000,2015-01-08 14:05:35.000000000,2015-01-08 14:05:34.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 9591}]","[{'number': 1, 'created': '2014-12-04 01:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/cbc995d176918a8b1208c20a0bcda838bc412598', 'message': 'Main translation code to handle parameters\n\nChanges to the backend Heat generator to process the parameters\nfrom the TOSCA input section, which would be passed in from the\nCLI or accept the default value.  Thi also handles the similar\nget_attribute function in the output section.\nAdd handler for the nodejs type, needed for the monitoring use\ncase.  Fix the test_blockstorage unit test to match the new\nexpected generator output, due to a change in the Heat Nova\nserver resource type.\n\nChange-Id: Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3\n'}, {'number': 2, 'created': '2014-12-05 19:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/3cee7d7e9e763434f3703fc88b072a84b7789fde', 'message': 'Main translation code to handle parameters\n\nChanges to the backend Heat generator to process the parameters\nfrom the TOSCA input section, which would be passed in from the\nCLI or accept the default value.  Thi also handles the similar\nget_attribute function in the output section.\nAdd handler for the nodejs type, needed for the monitoring use\ncase.  Fix the test_blockstorage unit test to match the new\nexpected generator output, due to a change in the Heat Nova\nserver resource type.\n\nChange-Id: Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3\n'}, {'number': 3, 'created': '2014-12-06 07:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/51fbd2b4d4e8ee6718207403b33fdde14bb690c6', 'message': 'Main translation code to handle parameters\n\nChanges to the backend Heat generator to process the parameters\nfrom the TOSCA input section, which would be passed in from the\nCLI or accept the default value.  Thi also handles the similar\nget_attribute function in the output section.\nAdd handler for the nodejs type, needed for the monitoring use\ncase.  Fix the test_blockstorage unit test to match the new\nexpected generator output, due to a change in the Heat Nova\nserver resource type.\n\nChange-Id: Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3\n'}, {'number': 4, 'created': '2014-12-10 23:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/9a60ad2c393a21c089734e6c3cb145878809bcc0', 'message': 'Main translation code to handle parameters\n\nChanges to the backend Heat generator to process the parameters\nfrom the TOSCA input section, which would be passed in from the\nCLI or accept the default value.  Thi also handles the similar\nget_attribute function in the output section.\nAdd handler for the nodejs type, needed for the monitoring use\ncase.  Fix the test_blockstorage unit test to match the new\nexpected generator output, due to a change in the Heat Nova\nserver resource type.\n\nChange-Id: Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3\n'}, {'number': 5, 'created': '2015-01-06 23:20:16.000000000', 'files': ['translator/tests/test_blockstorage.py', 'translator/hot/translate_node_templates.py', 'translator/hot/translate_outputs.py', 'translator/hot/translate_inputs.py', 'translator/hot/tosca/tosca_nodejs.py', 'translator/hot/tosca_translator.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/314fb8f2ed76b8e872808840d4612147c6c34bde', 'message': 'Main translation code to handle parameters\n\nChanges to the backend Heat generator to process the parameters\nfrom the TOSCA input section, which would be passed in from the\nCLI or accept the default value.  Thi also handles the similar\nget_attribute function in the output section.\nAdd handler for the nodejs type, needed for the monitoring use\ncase.  Fix the test_blockstorage unit test to match the new\nexpected generator output, due to a change in the Heat Nova\nserver resource type.\n\nChange-Id: Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3\n'}]",2,138927,314fb8f2ed76b8e872808840d4612147c6c34bde,19,4,5,9591,,,0,"Main translation code to handle parameters

Changes to the backend Heat generator to process the parameters
from the TOSCA input section, which would be passed in from the
CLI or accept the default value.  Thi also handles the similar
get_attribute function in the output section.
Add handler for the nodejs type, needed for the monitoring use
case.  Fix the test_blockstorage unit test to match the new
expected generator output, due to a change in the Heat Nova
server resource type.

Change-Id: Id73aba9ebaa6828c676a7a2afdee7ec6ef2579d3
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/27/138927/5 && git format-patch -1 --stdout FETCH_HEAD,"['translator/tests/test_blockstorage.py', 'translator/hot/translate_node_templates.py', 'translator/hot/translate_outputs.py', 'translator/hot/translate_inputs.py', 'translator/hot/tosca/tosca_nodejs.py', 'translator/hot/tosca_translator.py']",6,cbc995d176918a8b1208c20a0bcda838bc412598,bp/heat-translator-tosca," self.hot_resources = [] output = translator.translate() # save the list of HOT resource for reference in the output generation self.hot_resources = translator.hot_resources return output translator = TranslateOutputs(self.tosca.outputs, self.hot_resources)", return translator.translate() translator = TranslateOutputs(self.tosca.outputs),114,49
openstack%2Fopenstack-ansible~master~I45dc082cbce2ad3df267387f76579937ab1130f1,openstack/openstack-ansible,master,I45dc082cbce2ad3df267387f76579937ab1130f1,pin mariadb to version 5.5.41,MERGED,2015-01-08 11:38:07.000000000,2015-01-08 14:00:54.000000000,2015-01-08 13:35:30.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-08 11:38:07.000000000', 'files': ['rpc_deployment/vars/repo_packages/all_common.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b37140a14d36b712d4ec465ecd6407b7c164f2d2', 'message': ""pin mariadb to version 5.5.41\n\nIn order to pin to a specific version, you need to point at a repo that\nonly contains that version, as opposed to a main repo that contains all\nthe versions.\n\nThis pinning is to prevent issues when new versions of mariadb are\nreleased (the release of 5.5.41 broke the deployment, and we want to prevent\nthis happenening again now we've fixed that particular issue - 1408138)\n\nChange-Id: I45dc082cbce2ad3df267387f76579937ab1130f1\nCloses-Bug: 1408608\n""}]",0,145751,b37140a14d36b712d4ec465ecd6407b7c164f2d2,8,4,1,425,,,0,"pin mariadb to version 5.5.41

In order to pin to a specific version, you need to point at a repo that
only contains that version, as opposed to a main repo that contains all
the versions.

This pinning is to prevent issues when new versions of mariadb are
released (the release of 5.5.41 broke the deployment, and we want to prevent
this happenening again now we've fixed that particular issue - 1408138)

Change-Id: I45dc082cbce2ad3df267387f76579937ab1130f1
Closes-Bug: 1408608
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/51/145751/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/vars/repo_packages/all_common.yml'],1,b37140a14d36b712d4ec465ecd6407b7c164f2d2,bug/1408608," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/mariadb-5.5.41/repo/ubuntu/ {{ ansible_distribution_release }} main"", state: ""present"" }"," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }",1,1
openstack%2Fopenstack-ansible~icehouse~I45dc082cbce2ad3df267387f76579937ab1130f1,openstack/openstack-ansible,icehouse,I45dc082cbce2ad3df267387f76579937ab1130f1,pin mariadb to version 5.5.41,MERGED,2015-01-08 11:49:37.000000000,2015-01-08 13:58:38.000000000,2015-01-08 13:31:26.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-08 11:49:37.000000000', 'files': ['rpc_deployment/vars/repo_packages/all_common.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/40a186ce6feb7bc57195728b8ba836623f348573', 'message': ""pin mariadb to version 5.5.41\n\nIn order to pin to a specific version, you need to point at a repo that\nonly contains that version, as opposed to a main repo that contains all\nthe versions.\n\nThis pinning is to prevent issues when new versions of mariadb are\nreleased (the release of 5.5.41 broke the deployment, and we want to prevent\nthis happenening again now we've fixed that particular issue - 1408138)\n\nChange-Id: I45dc082cbce2ad3df267387f76579937ab1130f1\nCloses-Bug: 1408608\n(cherry picked from commit b37140a14d36b712d4ec465ecd6407b7c164f2d2)\n""}]",0,145754,40a186ce6feb7bc57195728b8ba836623f348573,8,4,1,425,,,0,"pin mariadb to version 5.5.41

In order to pin to a specific version, you need to point at a repo that
only contains that version, as opposed to a main repo that contains all
the versions.

This pinning is to prevent issues when new versions of mariadb are
released (the release of 5.5.41 broke the deployment, and we want to prevent
this happenening again now we've fixed that particular issue - 1408138)

Change-Id: I45dc082cbce2ad3df267387f76579937ab1130f1
Closes-Bug: 1408608
(cherry picked from commit b37140a14d36b712d4ec465ecd6407b7c164f2d2)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/54/145754/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/vars/repo_packages/all_common.yml'],1,40a186ce6feb7bc57195728b8ba836623f348573,bug/1408608," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/mariadb-5.5.41/repo/ubuntu/ {{ ansible_distribution_release }} main"", state: ""present"" }"," - { repo: ""deb http://ftp.osuosl.org/pub/mariadb/repo/5.5/ubuntu {{ ansible_distribution_release }} main"", state: ""present"" }",1,1
openstack%2Fgnocchi~master~Ie897c7ffd8a64f055d69176d5cc319593a949555,openstack/gnocchi,master,Ie897c7ffd8a64f055d69176d5cc319593a949555,storage: switch default driver to file,MERGED,2014-12-19 15:41:16.000000000,2015-01-08 13:48:32.000000000,2015-01-08 13:48:31.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-19 15:41:16.000000000', 'files': ['gnocchi/storage/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a432b50006e216979c12f7e265b2759a56a9c0e6', 'message': 'storage: switch default driver to file\n\nAt least this one will work by default.\n\nChange-Id: Ie897c7ffd8a64f055d69176d5cc319593a949555\n'}]",0,143117,a432b50006e216979c12f7e265b2759a56a9c0e6,11,4,1,1669,,,0,"storage: switch default driver to file

At least this one will work by default.

Change-Id: Ie897c7ffd8a64f055d69176d5cc319593a949555
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/17/143117/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/__init__.py'],1,a432b50006e216979c12f7e265b2759a56a9c0e6,jd/graph," default='file',"," default='swift',",1,1
openstack%2Fopenstack-ansible~juno~I869b88cfe1bb8237f24d1e058ee7aac64806e230,openstack/openstack-ansible,juno,I869b88cfe1bb8237f24d1e058ee7aac64806e230,Prevent user from accessing privileged files,MERGED,2015-01-07 20:34:48.000000000,2015-01-08 13:40:49.000000000,2015-01-08 11:53:32.000000000,"[{'_account_id': 3}, {'_account_id': 6549}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 20:34:48.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b726fca969e88a4ab703a99b353b815ba01cc9b0', 'message': 'Prevent user from accessing privileged files\n\nCloses-bug: 1400966\nRelated to OSSA-2014-041\nCVE-2014-9493\n\nChange-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230\n(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)\n'}]",0,145576,b726fca969e88a4ab703a99b353b815ba01cc9b0,12,6,1,12000,,,0,"Prevent user from accessing privileged files

Closes-bug: 1400966
Related to OSSA-2014-041
CVE-2014-9493

Change-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230
(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/76/145576/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,b726fca969e88a4ab703a99b353b815ba01cc9b0,bug/1400966," ""delete_image_location"": ""role:admin"", ""set_image_location"": ""role:admin"","," ""delete_image_location"": """", ""set_image_location"": """",",2,2
openstack%2Foslo.messaging~master~I7f4cb3075f776c63aa7dc497173677f92b68c16d,openstack/oslo.messaging,master,I7f4cb3075f776c63aa7dc497173677f92b68c16d,rabbit: fix timeout timer when duration is None,MERGED,2015-01-07 14:52:01.000000000,2015-01-08 13:35:45.000000000,2015-01-08 13:35:45.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 8415}]","[{'number': 1, 'created': '2015-01-07 14:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f6fe6a02ec2ec865f72dcc5c08acc0ac1b1e5df1', 'message': 'rabbit: fix timeout timer when duration is None\n\nWhen the duration of the timeout timer used in the rabbit driver.is\nNone and we want that the timer return a maximum of N secs it return None\n(infinite) instead of N.\n\nThis change fixes that.\n\nChange-Id: I7f4cb3075f776c63aa7dc497173677f92b68c16d\n'}, {'number': 2, 'created': '2015-01-07 14:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4cd0d25d617817fcd341d078e54c469b3a15e526', 'message': 'rabbit: fix timeout timer when duration is None\n\nWhen the duration of the timeout timer used in the rabbit driver.is\nNone and we want that the timer return a maximum of N secs it return None\n(infinite) instead of N.\n\nThis change fixes that.\n\nChange-Id: I7f4cb3075f776c63aa7dc497173677f92b68c16d\n'}, {'number': 3, 'created': '2015-01-07 17:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7163ca81c7399d26a88c586e3bd8c2007caaf455', 'message': 'rabbit: fix timeout timer when duration is None\n\nWhen the duration of the timeout timer used in the rabbit driver.is\nNone and we want that the timer return a maximum of N secs it return None\n(infinite) instead of N.\n\nThis change fixes that.\n\nCloses-bug: #1408370\n\nChange-Id: I7f4cb3075f776c63aa7dc497173677f92b68c16d\n'}, {'number': 4, 'created': '2015-01-07 21:30:01.000000000', 'files': ['oslo/messaging/_drivers/common.py', 'tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/44132d4344902f98007e6e58ea3bee56c701b400', 'message': 'rabbit: fix timeout timer when duration is None\n\nWhen the duration of the timeout timer used in the rabbit driver.is\nNone and we want that the timer return a maximum of N secs it return None\n(infinite) instead of N.\n\nThis change fixes that.\n\nCloses-bug: #1408370\n\nChange-Id: I7f4cb3075f776c63aa7dc497173677f92b68c16d\n'}]",0,145521,44132d4344902f98007e6e58ea3bee56c701b400,14,5,4,2813,,,0,"rabbit: fix timeout timer when duration is None

When the duration of the timeout timer used in the rabbit driver.is
None and we want that the timer return a maximum of N secs it return None
(infinite) instead of N.

This change fixes that.

Closes-bug: #1408370

Change-Id: I7f4cb3075f776c63aa7dc497173677f92b68c16d
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/21/145521/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/common.py'],1,f6fe6a02ec2ec865f72dcc5c08acc0ac1b1e5df1,bug/1408370," maximum = kwargs.pop('maximum', None) if self._duration is None: return None if maximum is None else maximum"," if self._duration is None: return None maximum = kwargs.pop('maximum', None)",2,2
openstack%2Fheat~master~I32e4e7df5bfa98f281fd9a4ee72969b6fd233475,openstack/heat,master,I32e4e7df5bfa98f281fd9a4ee72969b6fd233475,Remove useless create router code from create VPC,ABANDONED,2015-01-08 11:23:22.000000000,2015-01-08 13:27:56.000000000,,"[{'_account_id': 3}, {'_account_id': 9631}]","[{'number': 1, 'created': '2015-01-08 11:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c11680cac99700254dea60c7186f95198c05932d', 'message': 'Remove useless create router code from create VPC\n\nChange-Id: I32e4e7df5bfa98f281fd9a4ee72969b6fd233475\nCloses-Bug:1408618\n'}, {'number': 2, 'created': '2015-01-08 12:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/305ad70f5cf9e769319aa7714e10309f29682e79', 'message': 'Remove useless create router code from create VPC\n\nChange-Id: I32e4e7df5bfa98f281fd9a4ee72969b6fd233475\nCloses-Bug:1408618\n'}, {'number': 3, 'created': '2015-01-08 12:57:53.000000000', 'files': ['heat/engine/resources/vpc.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/617182f1413968a488104391db35e2d262449aff', 'message': 'Remove useless create router code from create VPC\n\nChange-Id: I32e4e7df5bfa98f281fd9a4ee72969b6fd233475\nCloses-Bug:1408618\n'}]",0,145749,617182f1413968a488104391db35e2d262449aff,8,2,3,9631,,,0,"Remove useless create router code from create VPC

Change-Id: I32e4e7df5bfa98f281fd9a4ee72969b6fd233475
Closes-Bug:1408618
",git fetch https://review.opendev.org/openstack/heat refs/changes/49/145749/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/vpc.py'],1,c11680cac99700254dea60c7186f95198c05932d,bug/1408618,, client.create_router({'router': router_props})['router'],0,1
openstack%2Fheat~master~Iffae1b10e81b12ca8455139eae609ddca5e8dd09,openstack/heat,master,Iffae1b10e81b12ca8455139eae609ddca5e8dd09,Enable E265 style check,MERGED,2015-01-02 14:33:29.000000000,2015-01-08 13:13:15.000000000,2015-01-08 13:13:14.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-02 14:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b36aca37eef6adcfa71512362ad76c0c4ed7392', 'message': ""Enable E265 style check\n\nblock comment should start with '# '\n\nChange-Id: Iffae1b10e81b12ca8455139eae609ddca5e8dd09\n""}, {'number': 2, 'created': '2015-01-02 15:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/05fdae171543e770fc6cbe548e97dbf05ecdda1e', 'message': ""Enable E265 style check\n\nblock comment should start with '# '\n\nChange-Id: Iffae1b10e81b12ca8455139eae609ddca5e8dd09\n""}, {'number': 3, 'created': '2015-01-05 10:11:25.000000000', 'files': ['heat/engine/resources/route_table.py', 'heat/tests/test_parser.py', 'heat/common/wsgi.py', 'heat/engine/resources/sahara_templates.py', 'heat/tests/test_security_group.py', 'contrib/rackspace/rackspace/resources/cloud_dns.py', 'heat/tests/test_loguserdata.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/engine/parameter_groups.py', 'heat/engine/cfn/functions.py', 'heat/tests/__init__.py', 'heat/tests/db/test_migrations.py', 'heat/api/openstack/v1/views/stacks_view.py', 'contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'heat/engine/hot/template.py', 'heat/tests/test_provider_template.py', 'heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_cw_alarm.py', 'heat/tests/test_hot.py', 'heat/cloudinit/part_handler.py', 'heat/common/exception.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'heat/tests/test_software_component.py', 'contrib/heat_keystoneclient_v2/heat_keystoneclient_v2/client.py', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_server.py', 'heat/engine/resources/sahara_cluster.py', 'heat/tests/test_sqlalchemy_api.py', 'tox.ini', 'heat/tests/test_ceilometer_alarm.py', 'heat/tests/test_lifecycle_plugin_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/8415baf6cc41156d1800fbedf26122ac354eeaa1', 'message': ""Enable E265 style check\n\nblock comment should start with '# '\n\nChange-Id: Iffae1b10e81b12ca8455139eae609ddca5e8dd09\n""}]",0,144752,8415baf6cc41156d1800fbedf26122ac354eeaa1,18,4,3,9542,,,0,"Enable E265 style check

block comment should start with '# '

Change-Id: Iffae1b10e81b12ca8455139eae609ddca5e8dd09
",git fetch https://review.opendev.org/openstack/heat refs/changes/52/144752/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/route_table.py', 'heat/tests/test_parser.py', 'heat/common/wsgi.py', 'heat/engine/resources/sahara_templates.py', 'heat/tests/test_security_group.py', 'contrib/rackspace/rackspace/resources/cloud_dns.py', 'heat/tests/test_loguserdata.py', 'heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py', 'heat/engine/parameter_groups.py', 'heat/engine/cfn/functions.py', 'heat/tests/__init__.py', 'heat/tests/db/test_migrations.py', 'heat/api/openstack/v1/views/stacks_view.py', 'contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'heat/engine/hot/template.py', 'heat/tests/test_provider_template.py', 'heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_cw_alarm.py', 'heat/tests/test_hot.py', 'heat/cloudinit/part_handler.py', 'heat/common/exception.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'heat/tests/test_software_component.py', 'contrib/heat_keystoneclient_v2/heat_keystoneclient_v2/client.py', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_server.py', 'heat/engine/resources/sahara_cluster.py', 'heat/tests/test_sqlalchemy_api.py', 'tox.ini', 'heat/tests/test_ceilometer_alarm.py', 'heat/tests/test_lifecycle_plugin_utils.py']",32,2b36aca37eef6adcfa71512362ad76c0c4ed7392,new-hacking, # special case string # Test for iterabilityy, #special case string #Test for iterabilityy,97,98
openstack%2Fdiskimage-builder~master~Iad202650a2344031f7e39b6dd5a517926a7e9866,openstack/diskimage-builder,master,Iad202650a2344031f7e39b6dd5a517926a7e9866,Map nagios-plugins-basic to nagios-plugins for redhat-common,ABANDONED,2015-01-08 11:17:35.000000000,2015-01-08 13:03:08.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2015-01-08 11:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7a09a9dad67029b6b1c79e98521a41339bc85fe2', 'message': 'Map nagios-plugins-basic to nagios-plugis for redhat-common\n\nInstalling all nagios plugins seems wrong here, we just need the\nbasic ones.\n\nChange-Id: Iad202650a2344031f7e39b6dd5a517926a7e9866\n'}, {'number': 2, 'created': '2015-01-08 12:20:35.000000000', 'files': ['elements/redhat-common/bin/map-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/12188fe33a08226c49917af931db7f7243bb7d7b', 'message': 'Map nagios-plugins-basic to nagios-plugins for redhat-common\n\nInstalling all nagios plugins was unneeded here, we just need the\nbasic ones.\n\nChange-Id: Iad202650a2344031f7e39b6dd5a517926a7e9866\n'}]",0,145747,12188fe33a08226c49917af931db7f7243bb7d7b,4,3,2,6796,,,0,"Map nagios-plugins-basic to nagios-plugins for redhat-common

Installing all nagios plugins was unneeded here, we just need the
basic ones.

Change-Id: Iad202650a2344031f7e39b6dd5a517926a7e9866
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/47/145747/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/redhat-common/bin/map-packages'],1,7a09a9dad67029b6b1c79e98521a41339bc85fe2,nagios_plugins_mapping," 'nagios-plugins-basic': 'nagios-plugins',"," 'nagios-plugins-basic': 'nagios-plugins-all',",1,1
openstack%2Fheat~master~I368728e486bc7b05c0768df17123a0efad078efb,openstack/heat,master,I368728e486bc7b05c0768df17123a0efad078efb,Cleanup heat/openstack/common,MERGED,2015-01-02 11:58:41.000000000,2015-01-08 12:56:24.000000000,2015-01-08 12:40:14.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 7491}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-02 11:58:41.000000000', 'files': ['heat/openstack/common/timeutils.py', 'heat_integrationtests/common/test.py', 'heat/openstack/common/jsonutils.py', 'heat/openstack/common/strutils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ffa61cca63e698d9d5ae3a953a1ab9014daa026d', 'message': 'Cleanup heat/openstack/common\n\nRemove jsonutils, strutils and timeutils modules.\nThey are not tracked in openstack-common.conf.\nFirst two were not used anywhere, and single usage of timeutils is fixed\nto use oslo.utils.\n\nChange-Id: I368728e486bc7b05c0768df17123a0efad078efb\n'}]",0,144738,ffa61cca63e698d9d5ae3a953a1ab9014daa026d,24,6,1,9542,,,0,"Cleanup heat/openstack/common

Remove jsonutils, strutils and timeutils modules.
They are not tracked in openstack-common.conf.
First two were not used anywhere, and single usage of timeutils is fixed
to use oslo.utils.

Change-Id: I368728e486bc7b05c0768df17123a0efad078efb
",git fetch https://review.opendev.org/openstack/heat refs/changes/38/144738/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/timeutils.py', 'heat_integrationtests/common/test.py', 'heat/openstack/common/jsonutils.py', 'heat/openstack/common/strutils.py']",4,ffa61cca63e698d9d5ae3a953a1ab9014daa026d,oslo,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" System-level utilities and helper functions. """""" import math import re import sys import unicodedata import six from heat.openstack.common.gettextutils import _ UNIT_PREFIX_EXPONENT = { 'k': 1, 'K': 1, 'Ki': 1, 'M': 2, 'Mi': 2, 'G': 3, 'Gi': 3, 'T': 4, 'Ti': 4, } UNIT_SYSTEM_INFO = { 'IEC': (1024, re.compile(r'(^[-+]?\d*\.?\d+)([KMGT]i?)?(b|bit|B)$')), 'SI': (1000, re.compile(r'(^[-+]?\d*\.?\d+)([kMGT])?(b|bit|B)$')), } TRUE_STRINGS = ('1', 't', 'true', 'on', 'y', 'yes') FALSE_STRINGS = ('0', 'f', 'false', 'off', 'n', 'no') SLUGIFY_STRIP_RE = re.compile(r""[^\w\s-]"") SLUGIFY_HYPHENATE_RE = re.compile(r""[-\s]+"") def int_from_bool_as_string(subject): """"""Interpret a string as a boolean and return either 1 or 0. Any string value in: ('True', 'true', 'On', 'on', '1') is interpreted as a boolean True. Useful for JSON-decoded stuff and config file parsing """""" return bool_from_string(subject) and 1 or 0 def bool_from_string(subject, strict=False, default=False): """"""Interpret a string as a boolean. A case-insensitive match is performed such that strings matching 't', 'true', 'on', 'y', 'yes', or '1' are considered True and, when `strict=False`, anything else returns the value specified by 'default'. Useful for JSON-decoded stuff and config file parsing. If `strict=True`, unrecognized values, including None, will raise a ValueError which is useful when parsing values passed in from an API call. Strings yielding False are 'f', 'false', 'off', 'n', 'no', or '0'. """""" if not isinstance(subject, six.string_types): subject = six.text_type(subject) lowered = subject.strip().lower() if lowered in TRUE_STRINGS: return True elif lowered in FALSE_STRINGS: return False elif strict: acceptable = ', '.join( ""'%s'"" % s for s in sorted(TRUE_STRINGS + FALSE_STRINGS)) msg = _(""Unrecognized value '%(val)s', acceptable values are:"" "" %(acceptable)s"") % {'val': subject, 'acceptable': acceptable} raise ValueError(msg) else: return default def safe_decode(text, incoming=None, errors='strict'): """"""Decodes incoming text/bytes string using `incoming` if they're not already unicode. :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a unicode `incoming` encoded representation of it. :raises TypeError: If text is not an instance of str """""" if not isinstance(text, (six.string_types, six.binary_type)): raise TypeError(""%s can't be decoded"" % type(text)) if isinstance(text, six.text_type): return text if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) try: return text.decode(incoming, errors) except UnicodeDecodeError: # Note(flaper87) If we get here, it means that # sys.stdin.encoding / sys.getdefaultencoding # didn't return a suitable encoding to decode # text. This happens mostly when global LANG # var is not set correctly and there's no # default encoding. In this case, most likely # python will use ASCII or ANSI encoders as # default encodings but they won't be capable # of decoding non-ASCII characters. # # Also, UTF-8 is being used since it's an ASCII # extension. return text.decode('utf-8', errors) def safe_encode(text, incoming=None, encoding='utf-8', errors='strict'): """"""Encodes incoming text/bytes string using `encoding`. If incoming is not specified, text is expected to be encoded with current python's default encoding. (`sys.getdefaultencoding`) :param incoming: Text's current encoding :param encoding: Expected encoding for text (Default UTF-8) :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a bytestring `encoding` encoded representation of it. :raises TypeError: If text is not an instance of str """""" if not isinstance(text, (six.string_types, six.binary_type)): raise TypeError(""%s can't be encoded"" % type(text)) if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) if isinstance(text, six.text_type): return text.encode(encoding, errors) elif text and encoding != incoming: # Decode text before encoding it with `encoding` text = safe_decode(text, incoming, errors) return text.encode(encoding, errors) else: return text def string_to_bytes(text, unit_system='IEC', return_int=False): """"""Converts a string into an float representation of bytes. The units supported for IEC :: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it) KB, KiB, MB, MiB, GB, GiB, TB, TiB The units supported for SI :: kb(it), Mb(it), Gb(it), Tb(it) kB, MB, GB, TB Note that the SI unit system does not support capital letter 'K' :param text: String input for bytes size conversion. :param unit_system: Unit system for byte size conversion. :param return_int: If True, returns integer representation of text in bytes. (default: decimal) :returns: Numerical representation of text in bytes. :raises ValueError: If text has an invalid value. """""" try: base, reg_ex = UNIT_SYSTEM_INFO[unit_system] except KeyError: msg = _('Invalid unit system: ""%s""') % unit_system raise ValueError(msg) match = reg_ex.match(text) if match: magnitude = float(match.group(1)) unit_prefix = match.group(2) if match.group(3) in ['b', 'bit']: magnitude /= 8 else: msg = _('Invalid string format: %s') % text raise ValueError(msg) if not unit_prefix: res = magnitude else: res = magnitude * pow(base, UNIT_PREFIX_EXPONENT[unit_prefix]) if return_int: return int(math.ceil(res)) return res def to_slug(value, incoming=None, errors=""strict""): """"""Normalize string. Convert to lowercase, remove non-word characters, and convert spaces to hyphens. Inspired by Django's `slugify` filter. :param value: Text to slugify :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: slugified unicode representation of `value` :raises TypeError: If text is not an instance of str """""" value = safe_decode(value, incoming, errors) # NOTE(aababilov): no need to use safe_(encode|decode) here: # encodings are always ""ascii"", error handling is always ""ignore"" # and types are always known (first: unicode; second: str) value = unicodedata.normalize(""NFKD"", value).encode( ""ascii"", ""ignore"").decode(""ascii"") value = SLUGIFY_STRIP_RE.sub("""", value).strip().lower() return SLUGIFY_HYPHENATE_RE.sub(""-"", value) ",1,636
openstack%2Ffuel-main~master~Id25ab5f77023d33883ae3dabf5f55c3a51f48eb0,openstack/fuel-main,master,Id25ab5f77023d33883ae3dabf5f55c3a51f48eb0,fuel-devops version bump,MERGED,2015-01-08 12:11:53.000000000,2015-01-08 12:28:35.000000000,2015-01-08 12:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 9977}, {'_account_id': 11081}, {'_account_id': 13505}]","[{'number': 1, 'created': '2015-01-08 12:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2c6780d448c42b51f40829dd3ad1df8daa591644', 'message': 'fuel-devops version bump\n\nChange-Id: Id25ab5f77023d33883ae3dabf5f55c3a51f48eb0\n'}, {'number': 2, 'created': '2015-01-08 12:26:15.000000000', 'files': ['fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/dd6687ab58eda12415b151d21195bfa338b57f29', 'message': 'fuel-devops version bump\n\nRelated-Bug: #1396488\nChange-Id: Id25ab5f77023d33883ae3dabf5f55c3a51f48eb0\n'}]",2,145758,dd6687ab58eda12415b151d21195bfa338b57f29,16,9,2,8965,,,0,"fuel-devops version bump

Related-Bug: #1396488
Change-Id: Id25ab5f77023d33883ae3dabf5f55c3a51f48eb0
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/58/145758/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/requirements.txt'],1,2c6780d448c42b51f40829dd3ad1df8daa591644,,git+git://github.com/stackforge/fuel-devops.git@2.5.3,git+git://github.com/stackforge/fuel-devops.git@2.5.2,1,1
openstack%2Fnova~master~I1ed2fea9ff3d8194628b722684492f8ba7a3cabb,openstack/nova,master,I1ed2fea9ff3d8194628b722684492f8ba7a3cabb,Switch to tempest-lib's packaged subunit-trace,MERGED,2015-01-06 21:05:39.000000000,2015-01-08 12:25:47.000000000,2015-01-08 02:12:15.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5196}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-06 21:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c0ed6c506df97d3c4076f6d355c7c99b4d870e1', 'message': ""Sewitch to tempest-lib's packaged subunit-trace\n\nThis commit removes the local copy of subunit-trace in nova and uses\nthe packaged version of the utility in tempest-lib.\n\nChange-Id: I1ed2fea9ff3d8194628b722684492f8ba7a3cabb\n""}, {'number': 2, 'created': '2015-01-06 21:25:56.000000000', 'files': ['tools/subunit-trace.py', 'test-requirements.txt', 'tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a543bcec8a5ff0b461e2a1d1ae7a853bbb02db2', 'message': ""Switch to tempest-lib's packaged subunit-trace\n\nThis commit removes the local copy of subunit-trace in nova and uses\nthe packaged version of the utility in tempest-lib.\n\nChange-Id: I1ed2fea9ff3d8194628b722684492f8ba7a3cabb\n""}]",1,145340,7a543bcec8a5ff0b461e2a1d1ae7a853bbb02db2,18,9,2,5196,,,0,"Switch to tempest-lib's packaged subunit-trace

This commit removes the local copy of subunit-trace in nova and uses
the packaged version of the utility in tempest-lib.

Change-Id: I1ed2fea9ff3d8194628b722684492f8ba7a3cabb
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/145340/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/subunit-trace.py', 'test-requirements.txt', 'tools/pretty_tox.sh']",3,8c0ed6c506df97d3c4076f6d355c7c99b4d870e1,kill-local-subunit-trace,"python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | subunit-trace -f","python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | $(dirname $0)/subunit-trace.py -f",2,308
openstack%2Ffuel-ostf~master~I94ce611015e6d33675f94a04082da2aa6878074a,openstack/fuel-ostf,master,I94ce611015e6d33675f94a04082da2aa6878074a,Reorganized and cleaned unit tests,MERGED,2015-01-05 11:10:13.000000000,2015-01-08 12:18:29.000000000,2015-01-08 12:18:28.000000000,"[{'_account_id': 3}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-01-05 11:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/47203fa63b4bd0cb0a7ff192acc7ce08c3b2bf94', 'message': 'Reorganized and cleaned unit tests\n\nNow all tests in \'unit\' directory can be easily run\n * http requests are mocked\n * do not require access to /var/log\n * do not require db access\n * ""integration"" tests are in separate directory\n * tox -epy26 -- fuel_plugin/testing/tests/unit/ allows\n   to run tests for now (will be added to run_tests.sh in the\n   future)\nIntroduced requests-mock to mock requests calls\nMoved ""base.py"" from unitests dir to better place.\n\nChange-Id: I94ce611015e6d33675f94a04082da2aa6878074a\nPartial-Bug: #1404892\n'}, {'number': 2, 'created': '2015-01-08 07:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/bfd222192365d90c0db5b9dfd30a34739f7a560c', 'message': 'Reorganized and cleaned unit tests\n\nNow all tests in \'unit\' directory can be easily run\n * http requests are mocked\n * do not require access to /var/log\n * do not require db access\n * ""integration"" tests are in separate directory\n * tox -epy26 -- fuel_plugin/testing/tests/unit/ allows\n   to run tests for now (will be added to run_tests.sh in the\n   future)\nIntroduced requests-mock to mock requests calls\nMoved ""base.py"" from unitests dir to better place.\n\nChange-Id: I94ce611015e6d33675f94a04082da2aa6878074a\nPartial-Bug: #1404892\n'}, {'number': 3, 'created': '2015-01-08 08:28:00.000000000', 'files': ['fuel_plugin/testing/tests/integration/__init__.py', 'fuel_plugin/testing/tests/unit/test_nose_discovery.py', 'fuel_plugin/testing/tests/unit/test_support_utilities.py', 'test-requirements.txt', 'fuel_plugin/testing/tests/base.py', 'fuel_plugin/testing/tests/integration/tests_wsgi_interface.py', 'fuel_plugin/testing/tests/unit/test_results_logger.py', 'fuel_plugin/testing/tests/integration/test_wsgi_controllers.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/bac8730db5c1f2db004c276a4d5c09deafe88806', 'message': 'Reorganized and cleaned unit tests\n\nNow all tests in \'unit\' directory can be easily run\n * http requests are mocked\n * do not require access to /var/log\n * do not require db access\n * ""integration"" tests are in separate directory\n * tox -epy26 -- fuel_plugin/testing/tests/unit/ allows\n   to run tests for now (will be added to run_tests.sh in the\n   future)\nIntroduced requests-mock to mock requests calls\nMoved ""base.py"" from unitests dir to better place.\n\nChange-Id: I94ce611015e6d33675f94a04082da2aa6878074a\nPartial-Bug: #1404892\n'}]",2,144966,bac8730db5c1f2db004c276a4d5c09deafe88806,24,9,3,12200,,,0,"Reorganized and cleaned unit tests

Now all tests in 'unit' directory can be easily run
 * http requests are mocked
 * do not require access to /var/log
 * do not require db access
 * ""integration"" tests are in separate directory
 * tox -epy26 -- fuel_plugin/testing/tests/unit/ allows
   to run tests for now (will be added to run_tests.sh in the
   future)
Introduced requests-mock to mock requests calls
Moved ""base.py"" from unitests dir to better place.

Change-Id: I94ce611015e6d33675f94a04082da2aa6878074a
Partial-Bug: #1404892
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/66/144966/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin/testing/tests/integration/__init__.py', 'fuel_plugin/testing/tests/unit/test_nose_discovery.py', 'fuel_plugin/testing/tests/unit/test_support_utilities.py', 'test-requirements.txt', 'fuel_plugin/testing/tests/base.py', 'fuel_plugin/testing/tests/integration/tests_wsgi_interface.py', 'fuel_plugin/testing/tests/unit/test_results_logger.py', 'fuel_plugin/testing/tests/integration/test_wsgi_controllers.py']",8,47203fa63b4bd0cb0a7ff192acc7ce08c3b2bf94,bug/1404892,from fuel_plugin.testing.tests import base,from fuel_plugin.testing.tests.unit import base,123,18
openstack%2Ffuel-ostf~master~I74c9b7f7bd137b6284e4e3dd5c131f348b564d78,openstack/fuel-ostf,master,I74c9b7f7bd137b6284e4e3dd5c131f348b564d78,Improved tox configuration,MERGED,2015-01-05 08:44:46.000000000,2015-01-08 12:17:53.000000000,2015-01-08 12:17:53.000000000,"[{'_account_id': 3}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-01-05 08:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/23b1441f0de51b5f24e3e81a441e0f662f8cda52', 'message': ""Improved tox configuration\n\ntox.ini is now similar to the one from Nailgun's code:\n * renamed 'pep8' env\n * added 'venv' env to run any command\n * replaced pep8 script with flake8\n * flake8 conf inside tox.ini\n * updated requirements for new tox.ini\n\nChange-Id: I74c9b7f7bd137b6284e4e3dd5c131f348b564d78\nPartial-Bug: #1404892\n""}, {'number': 2, 'created': '2015-01-07 10:16:41.000000000', 'files': ['run_tests.sh', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/7c9a83539c085180cf83f8bf9da25a91330c5898', 'message': ""Improved tox configuration\n\ntox.ini is now similar to the one from Nailgun's code:\n * renamed 'pep8' env\n * added 'venv' env to run any command\n * replaced pep8 script with flake8\n * flake8 conf inside tox.ini\n * updated requirements for new tox.ini\n\nChange-Id: I74c9b7f7bd137b6284e4e3dd5c131f348b564d78\nPartial-Bug: #1404892\n""}]",10,144950,7c9a83539c085180cf83f8bf9da25a91330c5898,22,8,2,12200,,,0,"Improved tox configuration

tox.ini is now similar to the one from Nailgun's code:
 * renamed 'pep8' env
 * added 'venv' env to run any command
 * replaced pep8 script with flake8
 * flake8 conf inside tox.ini
 * updated requirements for new tox.ini

Change-Id: I74c9b7f7bd137b6284e4e3dd5c131f348b564d78
Partial-Bug: #1404892
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/50/144950/2 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'test-requirements.txt', 'tox.ini']",3,23b1441f0de51b5f24e3e81a441e0f662f8cda52,bug/1404892,"envlist = pep8usedevelop = True install_command = pip install {packages} setenv = VIRTUAL_ENV={envdir}commands = nosetests {posargs:fuel_plugin/testing/tests} [testenv:venv] deps = -r{toxinidir}/requirements.txt commands = {posargs:} [testenv:pep8] usedevelop = False commands = flake8 {posargs} [flake8] exclude = .venv,.git,.tox,dist,doc,*lib/python*,*egg,build,tools,__init__.py,docs show-pep8 = True show-source = True count = True",envlist = flake8[flake8] show-source = True exclude = .tox commands = nosetests fuel_plugin/testing/tests/unit fuel_plugin/testing/tests/functional/tests.py:AdapterTests [testenv:flake8] deps = flake8 commands = flake8,24,13
openstack%2Fopenstack-ansible~icehouse~I869b88cfe1bb8237f24d1e058ee7aac64806e230,openstack/openstack-ansible,icehouse,I869b88cfe1bb8237f24d1e058ee7aac64806e230,Prevent user from accessing privileged files,MERGED,2015-01-07 20:35:06.000000000,2015-01-08 11:53:56.000000000,2015-01-08 11:53:56.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 20:35:06.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0e42c95ff016dfc0bf76f7ee8bae5cd72a9f4c9d', 'message': 'Prevent user from accessing privileged files\n\nCloses-bug: 1400966\nRelated to OSSA-2014-041\nCVE-2014-9493\n\nChange-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230\n(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)\n'}]",0,145577,0e42c95ff016dfc0bf76f7ee8bae5cd72a9f4c9d,11,5,1,12000,,,0,"Prevent user from accessing privileged files

Closes-bug: 1400966
Related to OSSA-2014-041
CVE-2014-9493

Change-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230
(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/77/145577/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,0e42c95ff016dfc0bf76f7ee8bae5cd72a9f4c9d,bug/1400966," ""delete_image_location"": ""role:admin"", ""set_image_location"": ""role:admin"","," ""delete_image_location"": """", ""set_image_location"": """",",2,2
openstack%2Ftricircle~master~I4d22e8261b06667f1f6abbd085e98a62a26ce375,openstack/tricircle,master,I4d22e8261b06667f1f6abbd085e98a62a26ce375,fresh cinder proxy,MERGED,2015-01-08 11:43:04.000000000,2015-01-08 11:44:45.000000000,2015-01-08 11:44:45.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2015-01-08 11:43:04.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/8796babed2ebdd6398aa78076bcc69fcaf25b2e3', 'message': 'fresh cinder proxy\n\nChange-Id: I4d22e8261b06667f1f6abbd085e98a62a26ce375\n'}]",0,145752,8796babed2ebdd6398aa78076bcc69fcaf25b2e3,6,2,1,13924,,,0,"fresh cinder proxy

Change-Id: I4d22e8261b06667f1f6abbd085e98a62a26ce375
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/52/145752/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,8796babed2ebdd6398aa78076bcc69fcaf25b2e3,master," metadata = volume_properties.get('metadata', {}) metadata['logicalVolumeId'] = volume_id if 'logicalVolumeId' in metadata: metadata.pop('logicalVolumeId')"," metadata = volume_properties.get('metadata', {}) metadata['logicalVolumeId'] = volume_id ",5,3
openstack%2Fheat~master~I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d,openstack/heat,master,I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d,Add missing template resource member list test,MERGED,2014-12-31 10:28:32.000000000,2015-01-08 11:40:53.000000000,2015-01-08 11:40:52.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-31 10:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b864525429da74c352424748a952d1417262439', 'message': 'Add missing template resource member list test\n\nChange-Id: I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d\n'}, {'number': 2, 'created': '2015-01-05 05:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9dd670fdfcaa09751bf4ca30bdd4a8c3216092a0', 'message': 'Add missing template resource member list test\n\nChange-Id: I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d\n'}, {'number': 3, 'created': '2015-01-06 13:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d0afffc26409f5274777ac83e9a79621250775fd', 'message': 'Add missing template resource member list test\n\nChange-Id: I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d\n'}, {'number': 4, 'created': '2015-01-07 06:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aaac32b6f0dadce6c66668222b02bb5bcdbbfada', 'message': 'Add missing template resource member list test\n\nChange-Id: I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d\n'}, {'number': 5, 'created': '2015-01-08 06:16:27.000000000', 'files': ['heat/tests/test_provider_template.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c0a7bdb895f6d25fe38a3692cbd483a0f62da803', 'message': 'Add missing template resource member list test\n\nChange-Id: I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d\n'}]",0,144623,c0a7bdb895f6d25fe38a3692cbd483a0f62da803,24,5,5,4715,,,0,"Add missing template resource member list test

Change-Id: I49a5d374fbcf4bb3afb617f7b390c52fa1faae7d
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/144623/5 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_provider_template.py'],1,0b864525429da74c352424748a952d1417262439,bp/decouple-nested," 'MemList': {'Type': 'CommaDelimitedList'}, ""MemList"": {""Type"": ""List""}, ""MemList"": [{""key"": ""name"", ""value"": ""three""}, {""key"": ""name"", ""value"": ""four""}], # verify Member List conversion mem_exp = '.member.0.key=name,.member.0.value=three,' \ '.member.1.key=name,.member.1.value=four' self.assertEqual(mem_exp, converted_params.get(""MemList""))",,8,0
openstack%2Fheat~master~Ie535b8aa67403fb05e536af34d7bacfe3f08ce99,openstack/heat,master,Ie535b8aa67403fb05e536af34d7bacfe3f08ce99,Enable H101 style check,MERGED,2015-01-02 14:33:29.000000000,2015-01-08 11:31:22.000000000,2015-01-08 10:54:18.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-02 14:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/280c71ffc9535c98b3a0bda1eaba3d5ffb0f5045', 'message': 'Enable H101 style check\n\nTODO must contain a name in parentheses\n\nChange-Id: Ie535b8aa67403fb05e536af34d7bacfe3f08ce99\n'}, {'number': 2, 'created': '2015-01-02 15:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/75d3995fba5d39111c46da4bb2d5c26b281e8760', 'message': 'Enable H101 style check\n\nTODO must contain a name in parentheses\n\nChange-Id: Ie535b8aa67403fb05e536af34d7bacfe3f08ce99\n'}, {'number': 3, 'created': '2015-01-05 10:11:25.000000000', 'files': ['heat/engine/api.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/8f801e29c8e244306c87c7234fa3c449c8574fa1', 'message': 'Enable H101 style check\n\nTODO must contain a name in parentheses\n\nChange-Id: Ie535b8aa67403fb05e536af34d7bacfe3f08ce99\n'}]",0,144751,8f801e29c8e244306c87c7234fa3c449c8574fa1,18,4,3,9542,,,0,"Enable H101 style check

TODO must contain a name in parentheses

Change-Id: Ie535b8aa67403fb05e536af34d7bacfe3f08ce99
",git fetch https://review.opendev.org/openstack/heat refs/changes/51/144751/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/api.py', 'tox.ini']",2,280c71ffc9535c98b3a0bda1eaba3d5ffb0f5045,new-hacking,"ignore = E251,E265,F402,F812,H202,H233,H305,H307,H402,H404,H405,H803,H904","# H101 Use TODO(NAME)ignore = E251,E265,F402,F812,H101,H202,H233,H305,H307,H402,H404,H405,H803,H904",3,4
openstack%2Ffuel-ostf~master~Ia8e27f0f274946b4374d3fa8c06e4b3766c2b6da,openstack/fuel-ostf,master,Ia8e27f0f274946b4374d3fa8c06e4b3766c2b6da,Get version of Fuel from release data,MERGED,2015-01-05 13:54:31.000000000,2015-01-08 11:14:49.000000000,2015-01-08 11:14:49.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8392}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2015-01-05 13:54:31.000000000', 'files': ['fuel_health/tests/platform_tests/test_platform_murano_linux.py', 'fuel_health/config.py', 'fuel_health/tests/platform_tests/test_platform_sahara.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b5764ec7216845f1b9fefab812c3671396056faf', 'message': 'Get version of Fuel from release data\n\nAdd fuel version to change link to the doc autamatically:\n\n* Add Fuel group to the ConfigOpt\n* Add fuel version and get it from api/clusters/id\n* Add usage of fuel_veersion to the platform tests\n\nChange-Id: Ia8e27f0f274946b4374d3fa8c06e4b3766c2b6da\nCloses-Bug:#1398812\nRelated-Bug: #1398393\n'}]",0,144986,b5764ec7216845f1b9fefab812c3671396056faf,10,7,1,6719,,,0,"Get version of Fuel from release data

Add fuel version to change link to the doc autamatically:

* Add Fuel group to the ConfigOpt
* Add fuel version and get it from api/clusters/id
* Add usage of fuel_veersion to the platform tests

Change-Id: Ia8e27f0f274946b4374d3fa8c06e4b3766c2b6da
Closes-Bug:#1398812
Related-Bug: #1398393
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/86/144986/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/platform_tests/test_platform_murano_linux.py', 'fuel_health/config.py', 'fuel_health/tests/platform_tests/test_platform_sahara.py']",3,b5764ec7216845f1b9fefab812c3671396056faf,bug/1398812, 'fuel-{0}/user-guide.html#platform-tests' '-description'.format(self.config.fuel.fuel_version)), 'fuel-6.0/user-guide.html#platform-tests-description'),25,3
openstack%2Fcookbook-openstack-compute~master~I4830974846cd11e8a3883665f17ff9217610f34e,openstack/cookbook-openstack-compute,master,I4830974846cd11e8a3883665f17ff9217610f34e,Add setting for compatible with older rpc API,ABANDONED,2015-01-08 11:07:23.000000000,2015-01-08 11:08:37.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2015-01-08 11:07:23.000000000', 'files': ['attributes/default.rb', 'spec/nova-common_spec.rb', 'templates/default/nova.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/3ad22f1696e3c0b672b8bd106a43b2661292cf3c', 'message': 'Add setting for compatible with older rpc API\n\nSet [upgrade_levels] compute=[version name] in\nnova.conf, such as add compute=juno to enable\nkilo rpc API compatible with juno compute, for\nkilo controller can manage the juno compute node.\nAccording to\nhttps://review.openstack.org/#/c/53944/\n\nChange-Id: I4830974846cd11e8a3883665f17ff9217610f34e\n'}]",0,145745,3ad22f1696e3c0b672b8bd106a43b2661292cf3c,3,1,1,14564,,,0,"Add setting for compatible with older rpc API

Set [upgrade_levels] compute=[version name] in
nova.conf, such as add compute=juno to enable
kilo rpc API compatible with juno compute, for
kilo controller can manage the juno compute node.
According to
https://review.openstack.org/#/c/53944/

Change-Id: I4830974846cd11e8a3883665f17ff9217610f34e
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/45/145745/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/nova-common_spec.rb', 'templates/default/nova.conf.erb']",3,3ad22f1696e3c0b672b8bd106a43b2661292cf3c,, <% unless node['openstack']['compute']['upgrade_levels']['compute'].nil? -%> [upgrade_levels] compute = <%= node['openstack']['compute']['upgrade_levels']['compute'] %> <% end -%>,,13,0
openstack%2Fpuppet-keystone~master~I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13,openstack/puppet-keystone,master,I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13,Add lib directories to $LOAD_PATH if not present,MERGED,2015-01-08 03:08:51.000000000,2015-01-08 11:01:21.000000000,2015-01-08 11:01:21.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}]","[{'number': 1, 'created': '2015-01-08 03:08:51.000000000', 'files': ['lib/puppet/type/keystone_service.rb', 'lib/puppet/type/keystone_user_role.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/type/keystone_role.rb', 'lib/puppet/type/keystone_user.rb', 'lib/puppet/type/keystone_endpoint.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/031300546a104377623a96506b5d1b8eabc5b4c9', 'message': 'Add lib directories to $LOAD_PATH if not present\n\nA combination of issues with puppet and rspec-puppet make it impossible\nfor rspec-puppet to properly load puppet/util/openstack when other\nmodules run tests against puppet-keystone. This patch works around the\nissue by adding all directories in lib/puppet to the $LOAD_PATH prior\nto attempting to use them.\n\nChange-Id: I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13\nCloses-bug: 1408531\n'}]",0,145677,031300546a104377623a96506b5d1b8eabc5b4c9,7,5,1,8482,,,0,"Add lib directories to $LOAD_PATH if not present

A combination of issues with puppet and rspec-puppet make it impossible
for rspec-puppet to properly load puppet/util/openstack when other
modules run tests against puppet-keystone. This patch works around the
issue by adding all directories in lib/puppet to the $LOAD_PATH prior
to attempting to use them.

Change-Id: I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13
Closes-bug: 1408531
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/77/145677/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/type/keystone_service.rb', 'lib/puppet/type/keystone_user_role.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/type/keystone_role.rb', 'lib/puppet/type/keystone_user.rb', 'lib/puppet/type/keystone_endpoint.rb']",6,031300546a104377623a96506b5d1b8eabc5b4c9,bug/1408531,"# LP#1408531 File.expand_path('../..', File.dirname(__FILE__)).tap { |dir| $LOAD_PATH.unshift(dir) unless $LOAD_PATH.include?(dir) }",,12,0
openstack%2Frally~master~I917412e954e57ca5f03df0bb739b7806d38a12a5,openstack/rally,master,I917412e954e57ca5f03df0bb739b7806d38a12a5,Don't hard set keystone endpoint,MERGED,2014-12-29 21:21:38.000000000,2015-01-08 10:52:29.000000000,2015-01-08 10:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6589}, {'_account_id': 8367}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-29 21:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a42061da94a9ac77a5d0f7a38380b563698e39d5', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}, {'number': 2, 'created': '2014-12-29 22:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a2a159241eda08c3d611c123dc9713878b214d1', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}, {'number': 3, 'created': '2015-01-05 23:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a665adf4b8fa32e039070ed8cb59faefd4753da', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nA warning will be issued if a deployment defines an admin_port, however\nthe admin_port itself will be ignored. This provides some backwards\ncompatibility with existing deployments.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}, {'number': 4, 'created': '2015-01-05 23:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f0e8ccb5dd219ef0734b465e6155efdc35fd8110', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nA warning will be issued if a deployment defines an admin_port, however\nthe admin_port itself will be ignored. This provides some backwards\ncompatibility with existing deployments.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}, {'number': 5, 'created': '2015-01-06 15:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fca21103051a202801629c2b471444b03b1dd955', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nA warning will be issued if a deployment defines an admin_port, however\nthe admin_port itself will be ignored. This provides some backwards\ncompatibility with existing deployments.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}, {'number': 6, 'created': '2015-01-06 19:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ead989e048101c87370c11a0610fb2e3a8a4e148', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nA warning will be issued if a deployment defines an admin_port, however\nthe admin_port itself will be ignored. This provides some backwards\ncompatibility with existing deployments.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}, {'number': 7, 'created': '2015-01-07 18:56:53.000000000', 'files': ['rally/deploy/engines/existing.py', 'tests/unit/test_api.py', 'doc/source/deploy_engines.rst', 'doc/samples/deployments/existing-keystone-v3.json', 'doc/samples/deployments/existing.json', 'rally/osclients.py', 'rally/objects/endpoint.py', 'tests/unit/objects/test_endpoint.py', 'tests/unit/deploy/engines/test_existing.py', 'rally/cmd/commands/deployment.py', 'tests/unit/test_osclients.py', 'tests/unit/cmd/commands/test_deployment.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8e8dcf9360b287b194b724d0e902188a133137dd', 'message': ""Don't hard set keystone endpoint\n\nKeystone client utilizes the auth_url provided to it in order to\ndiscover the appropriate end point for the action. It will either use\nthe publicURL or the adminURL it gets in the service catalog for the\nidentity service. UNLESS caller to the keystone client hard sets the\nendpoint key, in which case keystone will blindly use it instead of\nlooking in the catalog. Because rally was setting it, rally also had to\nset it differently when doing admin level stuff, but rally doesn't have\nto do that at all. Rally can rely on the service catalog and let\nkeystone sort it out.\n\nThis change removes manually setting endpoint and just passes along the\nauth_url to keystone. This obviates the need to define an admin_port in\na deployment configuration, and reduces the number of tests that need to\nbe ran.\n\nA warning will be issued if a deployment defines an admin_port, however\nthe admin_port itself will be ignored. This provides some backwards\ncompatibility with existing deployments.\n\nChange-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5\nRelated-Bug: 1398375\n""}]",6,144366,8e8dcf9360b287b194b724d0e902188a133137dd,58,6,7,6589,,,0,"Don't hard set keystone endpoint

Keystone client utilizes the auth_url provided to it in order to
discover the appropriate end point for the action. It will either use
the publicURL or the adminURL it gets in the service catalog for the
identity service. UNLESS caller to the keystone client hard sets the
endpoint key, in which case keystone will blindly use it instead of
looking in the catalog. Because rally was setting it, rally also had to
set it differently when doing admin level stuff, but rally doesn't have
to do that at all. Rally can rely on the service catalog and let
keystone sort it out.

This change removes manually setting endpoint and just passes along the
auth_url to keystone. This obviates the need to define an admin_port in
a deployment configuration, and reduces the number of tests that need to
be ran.

A warning will be issued if a deployment defines an admin_port, however
the admin_port itself will be ignored. This provides some backwards
compatibility with existing deployments.

Change-Id: I917412e954e57ca5f03df0bb739b7806d38a12a5
Related-Bug: 1398375
",git fetch https://review.opendev.org/openstack/rally refs/changes/66/144366/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/deploy/engines/existing.py', 'tests/unit/test_api.py', 'doc/source/deploy_engines.rst', 'doc/samples/deployments/existing-keystone-v3.json', 'doc/samples/deployments/existing.json', 'rally/osclients.py', 'rally/objects/endpoint.py', 'tests/unit/objects/test_endpoint.py', 'tests/unit/deploy/engines/test_existing.py', 'rally/cmd/commands/deployment.py', 'tests/unit/test_osclients.py', 'tests/unit/cmd/commands/test_deployment.py']",12,a42061da94a9ac77a5d0f7a38380b563698e39d5,bug/1398375," ""endpoint_type"": consts.EndpointType.INTERNAL ""region_name"", ""endpoint_type""] fake_data = [""url"", ""u"", ""p"", ""t"", ""r"", consts.EndpointType.INTERNAL]"," ""endpoint_type"": consts.EndpointType.INTERNAL, ""admin_port"": ""ap"" ""region_name"", ""endpoint_type"", ""admin_port""] fake_data = [""url"", ""u"", ""p"", ""t"", ""r"", consts.EndpointType.INTERNAL, ""ap""]",7,58
openstack%2Fneutron~master~I1c45c29617d692cc05b44f7f2c4ec1e5252be303,openstack/neutron,master,I1c45c29617d692cc05b44f7f2c4ec1e5252be303,Add a constant for router interface device owners,MERGED,2014-10-28 20:01:02.000000000,2015-01-08 10:40:30.000000000,2014-12-31 16:23:18.000000000,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-28 20:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d4964d2240746f6c58d5b3459b27262b0d542ef', 'message': 'Add a constant for router interface device owners\n\nIn the absense of a port object that includes a check for whether a\ngiven port is implementing a router interface, this change adds the\nROUTER_INTERFACES tuple containing the relevant DEVICE_OWNER_*\nconstants.\n\nThis change was suggested by https://review.openstack.org/#/c/129865/\n\nChange-Id: I1c45c29617d692cc05b44f7f2c4ec1e5252be303\n'}, {'number': 2, 'created': '2014-10-28 20:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e7f01847d3b978d8fce02621dea49db618abec9c', 'message': 'Add a constant for router interface device owners\n\nIn the absense of a port object that includes a check for whether a\ngiven port is implementing a router interface, this change adds the\nROUTER_INTERFACES tuple containing the relevant DEVICE_OWNER_*\nconstants.\n\nThis change was suggested by https://review.openstack.org/#/c/129865/\n\nChange-Id: I1c45c29617d692cc05b44f7f2c4ec1e5252be303\n'}, {'number': 3, 'created': '2014-12-31 02:17:28.000000000', 'files': ['neutron/common/constants.py', 'neutron/agent/l3/agent.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/agent/metadata/agent.py', 'neutron/tests/unit/test_metadata_agent.py', 'neutron/agent/linux/dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2bdf7d67a7e20cc688f292155ae2b29af785b920', 'message': 'Add a constant for router interface device owners\n\nIn the absense of a port object that includes a check for whether a\ngiven port is implementing a router interface, this change adds the\nROUTER_INTERFACE_OWNERS tuple containing the relevant DEVICE_OWNER_*\nconstants.\n\nThis change was suggested by https://review.openstack.org/#/c/129865/\n\nChange-Id: I1c45c29617d692cc05b44f7f2c4ec1e5252be303\n'}]",2,131551,2bdf7d67a7e20cc688f292155ae2b29af785b920,64,33,3,2035,,,0,"Add a constant for router interface device owners

In the absense of a port object that includes a check for whether a
given port is implementing a router interface, this change adds the
ROUTER_INTERFACE_OWNERS tuple containing the relevant DEVICE_OWNER_*
constants.

This change was suggested by https://review.openstack.org/#/c/129865/

Change-Id: I1c45c29617d692cc05b44f7f2c4ec1e5252be303
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/131551/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/db/l3_dvr_db.py', 'neutron/agent/metadata/agent.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/test_metadata_agent.py', 'neutron/agent/linux/dhcp.py']",6,6d4964d2240746f6c58d5b3459b27262b0d542ef,131551, if port['device_owner'] not in constants.ROUTER_INTERFACES:," if port.device_owner not in (constants.DEVICE_OWNER_ROUTER_INTF, constants.DEVICE_OWNER_DVR_INTERFACE):",11,22
openstack%2Ffuel-web~master~I6f23da3ea7a4f692d02dcb84175540e64f34df89,openstack/fuel-web,master,I6f23da3ea7a4f692d02dcb84175540e64f34df89,Deployment graph configuration storage in nailgun,MERGED,2014-12-16 12:15:28.000000000,2015-01-08 10:20:52.000000000,2015-01-08 10:20:51.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-16 12:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ae696c683bae2be1703fa792e1fee19d7cb80b65', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_graph\nRelease.deployemtn_graph\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_graph\nGET/PUT cluster/<cluster_id>/deployment_graph\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 2, 'created': '2014-12-16 15:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fc51968834fd90312c0189118f6e81770ee36cda', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_graph\nRelease.deployemtn_graph\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_graph\nGET/PUT cluster/<cluster_id>/deployment_graph\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 3, 'created': '2014-12-16 17:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1977f726cb06878d46d46260c648067d11d69732', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 4, 'created': '2014-12-17 10:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/945e00ce36951571352ac39420c3d126ca1ede01', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 5, 'created': '2014-12-18 15:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ebaf314a24cf6e74ef322cf561197de52fa4660d', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 6, 'created': '2014-12-23 08:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/43b5c53744ccb20362bfec51ae4baa3fe10db933', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 7, 'created': '2014-12-23 10:18:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9153010a5c42d6b32fb13b3875d7e1f72ec2f921', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 8, 'created': '2014-12-29 15:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c70c2128169404934451f67fa0f5f08441ca625e', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 9, 'created': '2014-12-31 12:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/de95e0e6636adc76a8eb07d199a4ed6d790e916e', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}, {'number': 10, 'created': '2014-12-31 13:35:07.000000000', 'files': ['nailgun/nailgun/db/sqlalchemy/models/release.py', 'nailgun/nailgun/api/v1/handlers/cluster.py', 'nailgun/nailgun/api/v1/validators/graph.py', 'nailgun/nailgun/api/v1/handlers/release.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_graph_related_handlers.py', 'nailgun/nailgun/api/v1/urls.py', 'nailgun/nailgun/api/v1/validators/json_schema/tasks.py', 'nailgun/nailgun/db/sqlalchemy/models/cluster.py', 'nailgun/nailgun/orchestrator/deployment_graph.py', 'nailgun/nailgun/api/v1/validators/cluster.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_6_1.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py', 'nailgun/nailgun/api/v1/handlers/base.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/064fb1e9f7bbf35b9fdbb51c0bdb3abc5b2d831b', 'message': 'Deployment graph configuration storage in nailgun\n\nWe have several requirements for graph storages, that will\nsatisfy all parties:\n\n- Store graph definition externally to nailgun, in fuel-library,\n  because fuel-library devs should be able to modify graph configuration,\n  based on changes in puppet modules\n- Validate any data that nailgun will store, and validation should\n  happen at the time data is received by nailgun\n- It should be possible to migrate data to required format, on upgrade,\n  if we will decide that it is necessary\n- It should be possible to modify graph per cluster, and per release,\n  for flexibility of debugging and development, also it may\n  help with maintenance tasks\n\nTo solve this issues 2 db fields was added:\n\nCluster.deployment_tasks\nRelease.deployemtn_tasks\n\nIt will be possible to read/modify both of this fields by next api request:\n\nGET/PUT release/<rel_id>/deployment_tasks\nGET/PUT cluster/<cluster_id>/deployment_tasks\n\nAlso note that deployment configuration for old release will be stored in\nnailgun code in orchestrator/graph_configuration.py module\n\nimplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89\n'}]",15,142086,064fb1e9f7bbf35b9fdbb51c0bdb3abc5b2d831b,65,10,10,8907,,,0,"Deployment graph configuration storage in nailgun

We have several requirements for graph storages, that will
satisfy all parties:

- Store graph definition externally to nailgun, in fuel-library,
  because fuel-library devs should be able to modify graph configuration,
  based on changes in puppet modules
- Validate any data that nailgun will store, and validation should
  happen at the time data is received by nailgun
- It should be possible to migrate data to required format, on upgrade,
  if we will decide that it is necessary
- It should be possible to modify graph per cluster, and per release,
  for flexibility of debugging and development, also it may
  help with maintenance tasks

To solve this issues 2 db fields was added:

Cluster.deployment_tasks
Release.deployemtn_tasks

It will be possible to read/modify both of this fields by next api request:

GET/PUT release/<rel_id>/deployment_tasks
GET/PUT cluster/<cluster_id>/deployment_tasks

Also note that deployment configuration for old release will be stored in
nailgun code in orchestrator/graph_configuration.py module

implements blueprint granular-deployment-based-on-tasks

Change-Id: I6f23da3ea7a4f692d02dcb84175540e64f34df89
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/86/142086/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/orchestrator/deployment_graph.py', 'nailgun/nailgun/db/sqlalchemy/models/release.py', 'nailgun/nailgun/api/v1/handlers/cluster.py', 'nailgun/nailgun/api/v1/validators/cluster.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/api/v1/handlers/release.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_6_1.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/api/v1/urls.py', 'nailgun/nailgun/api/v1/validators/release.py', 'nailgun/nailgun/db/sqlalchemy/models/cluster.py']",11,ae696c683bae2be1703fa792e1fee19d7cb80b65,bp/granular-deployment-based-on-tasks," deployment_graph = Column(JSON, default=[])",,184,13
openstack%2Fdiskimage-builder~master~Ib7801597400d6d87146181935922c8832baf5aaa,openstack/diskimage-builder,master,Ib7801597400d6d87146181935922c8832baf5aaa,Continue past dependency ordering diffs.,MERGED,2014-11-26 20:24:09.000000000,2015-01-08 10:20:17.000000000,2015-01-08 10:20:16.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 8399}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-11-26 20:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/2cc935c38bc9a9af2d90d5c6f32c0ab8cb6b5e66', 'message': 'Continue past dependency ordering diffs.\n\nWe now guard against diff returning non-zero (which it does when it\ndiscovers changes). This allows dib-lint runs to continue past the point\nof displaying a dependency ordering nit.\n\nChange-Id: Ib7801597400d6d87146181935922c8832baf5aaa\n'}, {'number': 2, 'created': '2014-12-12 18:37:08.000000000', 'files': ['bin/dib-lint'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f4a2eb6ef3a7e65d23527842eb31f45daeb007c6', 'message': 'Continue past dependency ordering diffs.\n\nWe now guard against diff returning non-zero (which it does when it\ndiscovers changes). This allows dib-lint runs to continue past the point\nof displaying a dependency ordering nit.\n\nChange-Id: Ib7801597400d6d87146181935922c8832baf5aaa\n'}]",4,137465,f4a2eb6ef3a7e65d23527842eb31f45daeb007c6,36,7,2,6449,,,0,"Continue past dependency ordering diffs.

We now guard against diff returning non-zero (which it does when it
discovers changes). This allows dib-lint runs to continue past the point
of displaying a dependency ordering nit.

Change-Id: Ib7801597400d6d87146181935922c8832baf5aaa
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/65/137465/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/dib-lint'],1,2cc935c38bc9a9af2d90d5c6f32c0ab8cb6b5e66,137465, diff -c ${UNSORTED} ${SORTED} || true, diff -c ${UNSORTED} ${SORTED},1,1
openstack%2Fswift~master~I14828cfc2ae644dbd9ead8c20613b19cea8607f1,openstack/swift,master,I14828cfc2ae644dbd9ead8c20613b19cea8607f1,Add tests for unavailability of `tee` and `splice` in `libc`,MERGED,2014-12-18 16:35:46.000000000,2015-01-08 10:19:16.000000000,2015-01-08 10:19:14.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8542}, {'_account_id': 13052}, {'_account_id': 13777}]","[{'number': 1, 'created': '2014-12-18 16:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/92580cb3aba8d0203f91bdeab1cb858525f82d35', 'message': ""Add tests for unavailability of `tee` and `splice` in `libc`\n\nAs suggested by Paul Luse in review 135319 (for 2a0a8ae00f2), this\nbrings test coverage of the `swift.common.splice` module up to 100%.\n\nThe mechanism used to check whether the functions are looked up on `libc`\nis somewhat ugly, but using a `PropertyMock` raising an `AttributeError`\nas `side_effect` doesn't work: it results in `mock` creating a `Mock`\ninstance and returning it.\n\nChange-Id: I14828cfc2ae644dbd9ead8c20613b19cea8607f1\nSee: https://review.openstack.org/#/c/135319/4/swift/common/splice.py,cm\nSee: 2a0a8ae00f2d3b7db255b0905b063e930f824f3d\n""}, {'number': 2, 'created': '2014-12-21 14:24:54.000000000', 'files': ['test/unit/common/test_splice.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bf4c78bc25303264d661ae144a46217e39007219', 'message': ""Add tests for unavailability of `tee` and `splice` in `libc`\n\nAs suggested by Paul Luse in review 135319 (for 2a0a8ae00f2), this\nbrings test coverage of the `swift.common.splice` module up to 100%.\n\nThe mechanism used to check whether the functions are looked up on `libc`\nis somewhat ugly, but using a `PropertyMock` raising an `AttributeError`\nas `side_effect` doesn't work: it results in `mock` creating a `Mock`\ninstance and returning it.\n\nChange-Id: I14828cfc2ae644dbd9ead8c20613b19cea8607f1\nSee: https://review.openstack.org/#/c/135319/4/swift/common/splice.py,cm\nSee: 2a0a8ae00f2d3b7db255b0905b063e930f824f3d\n""}]",2,142836,bf4c78bc25303264d661ae144a46217e39007219,14,8,2,13777,,,0,"Add tests for unavailability of `tee` and `splice` in `libc`

As suggested by Paul Luse in review 135319 (for 2a0a8ae00f2), this
brings test coverage of the `swift.common.splice` module up to 100%.

The mechanism used to check whether the functions are looked up on `libc`
is somewhat ugly, but using a `PropertyMock` raising an `AttributeError`
as `side_effect` doesn't work: it results in `mock` creating a `Mock`
instance and returning it.

Change-Id: I14828cfc2ae644dbd9ead8c20613b19cea8607f1
See: https://review.openstack.org/#/c/135319/4/swift/common/splice.py,cm
See: 2a0a8ae00f2d3b7db255b0905b063e930f824f3d
",git fetch https://review.opendev.org/openstack/swift refs/changes/36/142836/2 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/test_splice.py'],1,92580cb3aba8d0203f91bdeab1cb858525f82d35,splice-coverage,"import mock def test_unavailable_in_libc(self): '''Test `available` attribute when `libc` has no `splice` support''' class LibC(object): '''A fake `libc` object tracking `splice` attribute access''' def __init__(self): self.splice_retrieved = False @property def splice(self): self.splice_retrieved = True raise AttributeError libc = LibC() mock_cdll = mock.Mock(return_value=libc) with mock.patch('ctypes.CDLL', new=mock_cdll): # Force re-construction of a `Splice` instance # Something you're not supposed to do in actual code new_splice = type(splice)() self.assertFalse(new_splice.available) libc_name = ctypes.util.find_library('c') mock_cdll.assert_called_once_with(libc_name, use_errno=True) self.assertTrue(libc.splice_retrieved) def test_unavailable_in_libc(self): '''Test `available` attribute when `libc` has no `tee` support''' class LibC(object): '''A fake `libc` object tracking `tee` attribute access''' def __init__(self): self.tee_retrieved = False @property def tee(self): self.tee_retrieved = True raise AttributeError libc = LibC() mock_cdll = mock.Mock(return_value=libc) with mock.patch('ctypes.CDLL', new=mock_cdll): # Force re-construction of a `Tee` instance # Something you're not supposed to do in actual code new_tee = type(tee)() self.assertFalse(new_tee.available) libc_name = ctypes.util.find_library('c') mock_cdll.assert_called_once_with(libc_name, use_errno=True) self.assertTrue(libc.tee_retrieved)",,57,0
openstack%2Fceilometer~master~I8e047acbc3c55184dcac99f8e73e3060ecd02507,openstack/ceilometer,master,I8e047acbc3c55184dcac99f8e73e3060ecd02507,Check to skip to poll and publish when no resource,MERGED,2014-12-19 13:50:53.000000000,2015-01-08 10:18:49.000000000,2015-01-08 10:18:47.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-19 13:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/816c0acaa8d96c754688ae44b431ec74801000f0', 'message': 'Check to skip to poll and publish when no resource\n\nThis fix checks is pollster must have resources or not.\nCurrently only ipmi pollsters been found, that not require resources.\n\nChange-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507\nCloses-bug: 1403505\n'}, {'number': 2, 'created': '2014-12-19 14:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/816e8f43bda938e327eb111dd565b1e7840f34f8', 'message': 'Check to skip to poll and publish when no resources found\n\nThis fix checks is pollster must have resources or not.\nCurrently only ipmi pollsters been found, that not require resources.\n\nChange-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507\nCloses-bug: 1403505'}, {'number': 3, 'created': '2014-12-24 09:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f88256c7ff976e47ae05bef5e8a8d352cbf94b01', 'message': 'Check to skip to poll and publish when no resource\n\nThis fix checks is pollster must have resources or not.\nCurrently only ipmi pollsters been found, that not require resources.\n\nChange-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507\nCloses-bug: 1403505\n'}, {'number': 4, 'created': '2014-12-24 10:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9a0dadbe309282fe4ec0e626fa26e44d1b3d172f', 'message': 'Check to skip to poll and publish when no resource\n\nThis fix checks is pollster must have resources or not.\nCurrently only ipmi pollsters been found, that not require resources.\n\nChange-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507\nCloses-bug: 1403505\n'}, {'number': 5, 'created': '2014-12-24 10:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ac4fca8bb1bfb924cba67ffe1bb16e212c76b112', 'message': 'Check to skip to poll and publish when no resource\n\nThis fix checks is pollster must have resources or not.\nCurrently only ipmi pollsters been found, that not require resources.\n\nChange-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507\nCloses-bug: 1403505\n'}, {'number': 6, 'created': '2014-12-25 07:50:36.000000000', 'files': ['ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/tests/agent/agentbase.py', 'ceilometer/agent/base.py', 'ceilometer/ipmi/pollsters/node.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2518c6e97d744a34d268684e45f4371e416f4f2a', 'message': 'Check to skip to poll and publish when no resource\n\nThis fix checks if pollster must have resources or not.\nCurrently only ipmi pollsters do not require resources.\n\nChange-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507\nCloses-bug: 1403505\n'}]",10,143092,2518c6e97d744a34d268684e45f4371e416f4f2a,30,9,6,13273,,,0,"Check to skip to poll and publish when no resource

This fix checks if pollster must have resources or not.
Currently only ipmi pollsters do not require resources.

Change-Id: I8e047acbc3c55184dcac99f8e73e3060ecd02507
Closes-bug: 1403505
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/92/143092/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/tests/agent/agentbase.py', 'ceilometer/agent/base.py', 'ceilometer/ipmi/pollsters/node.py']",4,816c0acaa8d96c754688ae44b431ec74801000f0,bug/1403505, no_resources = True ,,30,0
openstack%2Fironic~master~Id953a79b7db56b4014727d402104a9e998e55255,openstack/ironic,master,Id953a79b7db56b4014727d402104a9e998e55255,display error logging should be improved,MERGED,2015-01-02 16:15:19.000000000,2015-01-08 10:18:22.000000000,2015-01-08 10:18:21.000000000,"[{'_account_id': 3}, {'_account_id': 7244}, {'_account_id': 8106}, {'_account_id': 9315}, {'_account_id': 10343}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-02 16:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc1955cb846e2fb1861ef113c10959742450015c', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}, {'number': 2, 'created': '2015-01-05 16:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ff4a85ead2564ed4605d382b5967a5aded5ca7a', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}, {'number': 3, 'created': '2015-01-05 16:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5178781977edf0f88c86c9003d5b330f953ee77d', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}, {'number': 4, 'created': '2015-01-05 18:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/51ddf8a56b4897e8ea92d1ec27a2dd4c2fd7b14a', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}, {'number': 5, 'created': '2015-01-06 20:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0f5ea2cd5d1e6ad3bc75779af3dbc106f861f565', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}, {'number': 6, 'created': '2015-01-07 19:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b63635892bf26c74acaf293aa315ff9a19fd101d', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}, {'number': 7, 'created': '2015-01-07 20:58:34.000000000', 'files': ['ironic/common/glance_service/base_image_service.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d1f7eddb9e0100f849500589a2675e03350ff67d', 'message': 'display error logging should be improved\n\nRemoved duplicate error logging\n\nChange-Id: Id953a79b7db56b4014727d402104a9e998e55255\nCloses-Bug: 1286374\n'}]",2,144771,d1f7eddb9e0100f849500589a2675e03350ff67d,43,6,7,7244,,,0,"display error logging should be improved

Removed duplicate error logging

Change-Id: Id953a79b7db56b4014727d402104a9e998e55255
Closes-Bug: 1286374
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/144771/5 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/glance_service/base_image_service.py'],1,bc1955cb846e2fb1861ef113c10959742450015c,bug/1286374,," LOG.exception(error_msg, {'host': host, 'port': port, 'num_attempts': num_attempts, 'method': method, 'extra': extra})",0,5
openstack%2Fpython-neutronclient~master~Ib22c48ce091916c7c874db91c8c16ebfc7846411,openstack/python-neutronclient,master,Ib22c48ce091916c7c874db91c8c16ebfc7846411,Add Python 3 classifiers,MERGED,2015-01-07 08:47:50.000000000,2015-01-08 10:11:12.000000000,2015-01-08 10:11:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-01-07 08:47:50.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d6e40b566e059d3a3a352c371955077e128356a8', 'message': 'Add Python 3 classifiers\n\nChange-Id: Ib22c48ce091916c7c874db91c8c16ebfc7846411\n'}]",0,145431,d6e40b566e059d3a3a352c371955077e128356a8,12,4,1,8122,,,0,"Add Python 3 classifiers

Change-Id: Ib22c48ce091916c7c874db91c8c16ebfc7846411
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/31/145431/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,d6e40b566e059d3a3a352c371955077e128356a8,py3-classifiers, Programming Language :: Python :: 3 Programming Language :: Python :: 3.3 Programming Language :: Python :: 3.4,,3,0
openstack%2Fneutron~master~Ie215f33818cc5c16e570ace4c750df5371d27e09,openstack/neutron,master,Ie215f33818cc5c16e570ace4c750df5371d27e09,ovs_dvr: Use lazy logging interpolation,MERGED,2014-12-22 04:43:01.000000000,2015-01-08 10:03:20.000000000,2014-12-31 05:39:23.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8279}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-22 04:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5743b3b84ee67c3ff0c79e7f81dcef3db984fc1d', 'message': 'ovs_dvr: Use lazy logging interpolation\n\nThere are a small number of examples of ""eager"" interpolation in\nneutron:\n  logging.debug(""foo %s"" % arg)\n\nThese should be converted to perform the interpolation lazily within\nthe logging function, since if the severity is below the logging level\nthen the interpolation can be skipped entirely.\n\nThis change addresses all such examples found in ovs agent via a pylint\ntest.  Other occurrences are addressed elsewhere.\n\nChange-Id: Ie215f33818cc5c16e570ace4c750df5371d27e09\nPartial-Bug: #1404788\n'}, {'number': 2, 'created': '2014-12-22 23:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/522535d74f48231bd6641f4e7d8ee33207db09ee', 'message': 'ovs_dvr: Use lazy logging interpolation\n\nThere are a small number of examples of ""eager"" interpolation in\nneutron:\n  logging.debug(""foo %s"" % arg)\n\nThese should be converted to perform the interpolation lazily within\nthe logging function, since if the severity is below the logging level\nthen the interpolation can be skipped entirely.\n\nThis change addresses all such examples found in ovs agent via a pylint\ntest.  Other occurrences are addressed elsewhere.\n\nChange-Id: Ie215f33818cc5c16e570ace4c750df5371d27e09\nPartial-Bug: #1404788\n'}, {'number': 3, 'created': '2014-12-31 03:26:53.000000000', 'files': ['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff03b268f78693c781c83aec575777381f5bcb95', 'message': 'ovs_dvr: Use lazy logging interpolation\n\nThere are a small number of examples of ""eager"" interpolation in\nneutron:\n  logging.debug(""foo %s"" % arg)\n\nThese should be converted to perform the interpolation lazily within\nthe logging function, since if the severity is below the logging level\nthen the interpolation can be skipped entirely.\n\nThis change addresses all such examples found in ovs agent via a pylint\ntest.  Other occurrences are addressed elsewhere.\n\nChange-Id: Ie215f33818cc5c16e570ace4c750df5371d27e09\nPartial-Bug: #1404788\n'}]",2,143359,ff03b268f78693c781c83aec575777381f5bcb95,88,24,3,11279,,,0,"ovs_dvr: Use lazy logging interpolation

There are a small number of examples of ""eager"" interpolation in
neutron:
  logging.debug(""foo %s"" % arg)

These should be converted to perform the interpolation lazily within
the logging function, since if the severity is below the logging level
then the interpolation can be skipped entirely.

This change addresses all such examples found in ovs agent via a pylint
test.  Other occurrences are addressed elsewhere.

Change-Id: Ie215f33818cc5c16e570ace4c750df5371d27e09
Partial-Bug: #1404788
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/143359/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py'],1,5743b3b84ee67c3ff0c79e7f81dcef3db984fc1d,bug/1404788," LOG.debug(""get_subnet_for_dvr for subnet %s returned with %s"", subnet_uuid, subnet_info)"," LOG.debug(""get_subnet_for_dvr for subnet %s returned with %s"" % (subnet_uuid, subnet_info))",2,2
openstack%2Ffuel-web~master~Ieada040739116227f53f70558cead5bcb4d5bb48,openstack/fuel-web,master,Ieada040739116227f53f70558cead5bcb4d5bb48,fuelclient: use keystone v2.0 client explicitly,MERGED,2014-12-26 14:24:44.000000000,2015-01-08 10:00:52.000000000,2015-01-08 10:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-26 14:24:44.000000000', 'files': ['fuelclient/fuelclient/client.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/df4f1d9bcc6c9755fefb2654a13e817cf50ab7bd', 'message': 'fuelclient: use keystone v2.0 client explicitly\n\nCurrently, we\'re using a Keystone client which actually performs\nauto discovering and returns one of available client. In theory\nall works fine, but unfortunately the ""auth_url"" will be replaced\nby Keystone with a keystone endpoint. The issue is that this\nendpoint may be unavailable if we\'re working through some\nproxy/tunnel and don\'t have direct access to the fuel master node.\n\nAs workaround, we can explicitly create a keystone client for v2.0,\nand none of discovering will be performed and the endpoint will not\nbe replaced implicitly by keystone client.\n\nChange-Id: Ieada040739116227f53f70558cead5bcb4d5bb48\nCloses-Bug: #1405190\n'}]",0,144146,df4f1d9bcc6c9755fefb2654a13e817cf50ab7bd,21,10,1,10391,,,0,"fuelclient: use keystone v2.0 client explicitly

Currently, we're using a Keystone client which actually performs
auto discovering and returns one of available client. In theory
all works fine, but unfortunately the ""auth_url"" will be replaced
by Keystone with a keystone endpoint. The issue is that this
endpoint may be unavailable if we're working through some
proxy/tunnel and don't have direct access to the fuel master node.

As workaround, we can explicitly create a keystone client for v2.0,
and none of discovering will be performed and the endpoint will not
be replaced implicitly by keystone client.

Change-Id: Ieada040739116227f53f70558cead5bcb4d5bb48
Closes-Bug: #1405190
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/46/144146/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelclient/fuelclient/client.py'],1,df4f1d9bcc6c9755fefb2654a13e817cf50ab7bd,bug/1405190,from keystoneclient.v2_0 import client as auth_client,from keystoneclient import client as auth_client,1,1
openstack%2Ftripleo-image-elements~master~I02091fbaa811ef94bb1738aa09cc5d65acce0724,openstack/tripleo-image-elements,master,I02091fbaa811ef94bb1738aa09cc5d65acce0724,Split RabbitMQ actions out of startup script,MERGED,2014-11-13 15:30:19.000000000,2015-01-08 09:59:33.000000000,2015-01-08 09:59:32.000000000,"[{'_account_id': 3}, {'_account_id': 1865}, {'_account_id': 1872}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 6969}, {'_account_id': 7579}, {'_account_id': 7582}, {'_account_id': 8688}, {'_account_id': 9453}, {'_account_id': 10373}, {'_account_id': 11650}, {'_account_id': 11655}, {'_account_id': 14123}]","[{'number': 1, 'created': '2014-11-13 15:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e6fbe432392f5820eabcfac48b2a77ccf1d5a56c', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 2, 'created': '2014-11-13 19:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7d5f06f7160b627d0b4ec37bf602621d97b83f85', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 3, 'created': '2014-11-13 19:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5314aad2a90b0518b8fb0f303ad4340ebc7aad3c', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 4, 'created': '2014-11-13 19:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8de56f09964923e0a6d3a06262871edd31bb6c8b', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 5, 'created': '2014-11-13 19:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/11bd17e4071f04ab82540a07f2d535fa92360332', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 6, 'created': '2014-11-14 16:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fa01da0ec3f80ef002a1782759698577351154c0', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 7, 'created': '2014-11-14 18:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ef2979e3ff4a2a65dc8ee09072fe8e71c9f80288', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 8, 'created': '2014-11-17 15:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2afeb28ea7480d65ae4fe26e4cf61c02c5633aca', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 9, 'created': '2014-11-20 15:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5aff624adc15f5a3116d01ff5228e28fb658c58a', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 10, 'created': '2014-11-20 16:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/aa56b78691af3036e426cefb68650fcddefabe32', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 11, 'created': '2014-11-20 16:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6b3ac8fe19e03e9559942c70f88cbf63579eea39', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 12, 'created': '2014-11-24 09:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9b4cd5f48a306ea41e712762191c4944a1b6e7a3', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 13, 'created': '2014-11-25 13:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/624c71da76028b4260b654826f08195a6db5a208', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_leave_cluster\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 14, 'created': '2014-11-26 15:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/446c9729836b6eeaa49789863478f2058cfc0c04', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 15, 'created': '2014-11-26 18:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ac547d17faec905eec94d9bb5b283dcede2e231d', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 16, 'created': '2014-11-27 17:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/da11b97d566c3800faf9a9ff4a683e83ff83ad45', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 17, 'created': '2014-11-27 18:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/04d00906b691c9255d57fef9494184904eb0dc5b', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 18, 'created': '2014-11-27 18:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/31d370e82a157f4d6d91eaa5197ba08c5fe2971e', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 19, 'created': '2014-11-28 08:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9635e41b68c65076ffcd64808b4e3f55fb8e0709', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 20, 'created': '2014-12-02 10:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dce80668b0edff054721fad853b09d5c60161410', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 21, 'created': '2014-12-11 19:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8510dd2c72f4733890af532b00bc77b66ed9f337', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}, {'number': 22, 'created': '2014-12-15 11:52:54.000000000', 'files': ['elements/rabbitmq-server/bin/rabbitmq_join_cluster', 'elements/rabbitmq-server/bin/rabbitmq_reset_node', 'elements/rabbitmq-server/bin/rabbitmq_size_of_cluster', 'elements/rabbitmq-server/bin/rabbitmq_is_in_cluster', 'elements/rabbitmq-server/os-refresh-config/post-configure.d/51-rabbitmq'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9892ef30de884d59c3c8dd5a0d779dd18f339551', 'message': ""Split RabbitMQ actions out of startup script\n\nThis patch adds the following utilities which may be used to control and\ninspect Rabbit's clustering state:\n\n   bin/rabbitmq_is_in_cluster\n   bin/rabbitmq_join_cluster\n   bin/rabbitmq_reset_node\n   bin/rabbitmq_size_of_cluster\n\nThese have been factored out of os-refresh-config/post-configure.d/51-rabbitmq\nas requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.\n\nRelates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766\nChange-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724\n""}]",38,134249,9892ef30de884d59c3c8dd5a0d779dd18f339551,131,14,22,10373,,,0,"Split RabbitMQ actions out of startup script

This patch adds the following utilities which may be used to control and
inspect Rabbit's clustering state:

   bin/rabbitmq_is_in_cluster
   bin/rabbitmq_join_cluster
   bin/rabbitmq_reset_node
   bin/rabbitmq_size_of_cluster

These have been factored out of os-refresh-config/post-configure.d/51-rabbitmq
as requested on Ic758256481fdd31d10f4e4a341ae93cb372a0766.

Relates-To: Ic758256481fdd31d10f4e4a341ae93cb372a0766
Change-Id: I02091fbaa811ef94bb1738aa09cc5d65acce0724
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/49/134249/16 && git format-patch -1 --stdout FETCH_HEAD,"['elements/rabbitmq-server/bin/rabbitmq_join_cluster', 'elements/rabbitmq-server/bin/rabbitmq_leave_cluster', 'elements/rabbitmq-server/bin/rabbitmq_size_of_cluster', 'elements/rabbitmq-server/bin/rabbitmq_is_in_cluster', 'elements/rabbitmq-server/os-refresh-config/post-configure.d/51-rabbitmq']",5,e6fbe432392f5820eabcfac48b2a77ccf1d5a56c,improve_join,"while rabbitmq_is_in_cluster; do NODES_IN_CLUSTER=$(rabbitmq_size_of_cluster --remote-host ""${BOOTSTRAP_NODE}"") timeout 300 rabbitmq_leave_cluster || { rabbitmqctl start_app && exit 1; } while ! rabbitmq_is_in_cluster; do rabbitmq_join_cluster --remote-host ""${NODES[${COUNT}]}"" || true while [[ $(rabbitmq_size_of_cluster) -ne ${TOTAL_NODES} ]]; do while [[ $(rabbitmq_size_of_cluster --remote-host ""${BOOTSTRAP_NODE}"") -lt 2 ]]; do rabbitmq_join_cluster --remote-host ""${BOOTSTRAP_NODE}""","## Cluster configuration set-up. ## function is_in_cluster() { # Returns true if the list following ""running_nodes"" in rabbitmqctl # cluster_status contains at least two nodes. rabbitmqctl cluster_status 2>/dev/null | grep -q ""running_nodes,\[[^]]\+,"" } # Number of nodes in the cluster according to remote node $1. # If $1 isn't in a cluster or it's in a cluster by itself, then this will # return 0. function cluster_size() { local remote_node=""${1}"" rabbitmqctl -n ""rabbit@${remote_node}"" cluster_status 2>/dev/null | sed -n '/{running_nodes,\[[^]]\+,/,/\]\},/p' | wc -l } function leave_cluster() { rabbitmqctl stop_app # This syncs all data into the cluster, then removes this node, cleaning local mnesia. rabbitmqctl reset } export -f leave_cluster function join_cluster_with() { local remote_node=""${1}"" local local_node=""${2}"" rabbitmqctl stop_app rabbitmqctl join_cluster ""rabbit@${remote_node}"" 2>/dev/null || true rabbitmqctl start_app if ! is_in_cluster; then echo ""Failed to join node [${local_node}] with [${remote_node}]..."" return 1 fi } while is_in_cluster; do NODES_IN_CLUSTER=$(cluster_size ""${BOOTSTRAP_NODE}"") timeout 300 bash -c leave_cluster || { rabbitmqctl start_app && exit 1; } while ! is_in_cluster; do join_cluster_with ""${NODES[${COUNT}]}"" ""${LOCAL_RABBIT_HOST}"" || true while [[ $(cluster_size ""${LOCAL_RABBIT_HOST}"") -ne ${TOTAL_NODES} ]]; do while [[ $(cluster_size ""${BOOTSTRAP_NODE}"") -lt 2 ]]; do is_in_cluster || join_cluster_with ""${BOOTSTRAP_NODE}"" ""${LOCAL_RABBIT_HOST}""",195,46
openstack%2Fopenstack-ansible~icehouse~I0ca27f1306a61b8898cd2f59b869b80eb44fad56,openstack/openstack-ansible,icehouse,I0ca27f1306a61b8898cd2f59b869b80eb44fad56,Add gitreview config with correct default branch,MERGED,2015-01-07 20:42:59.000000000,2015-01-08 09:43:31.000000000,2015-01-08 09:43:31.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 20:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b66cfef898ccab534ee3a335ce8900e6d8393eae', 'message': 'Add gitreview config with correct default branch\n\nChange-Id: I0ca27f1306a61b8898cd2f59b869b80eb44fad56\n'}, {'number': 2, 'created': '2015-01-07 20:43:32.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1654c4365ef4a782ed2dfa1e7bc7178230cbec2f', 'message': 'Add gitreview config with correct default branch\n\nChange-Id: I0ca27f1306a61b8898cd2f59b869b80eb44fad56\n(cherry picked from commit b66cfef898ccab534ee3a335ce8900e6d8393eae)\n'}]",0,145580,1654c4365ef4a782ed2dfa1e7bc7178230cbec2f,12,5,2,12000,,,0,"Add gitreview config with correct default branch

Change-Id: I0ca27f1306a61b8898cd2f59b869b80eb44fad56
(cherry picked from commit b66cfef898ccab534ee3a335ce8900e6d8393eae)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/80/145580/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,b66cfef898ccab534ee3a335ce8900e6d8393eae,stable/icehouse,[gerrit] host=review.openstack.org port=29418 project=stackforge/os-ansible-deployment.git defaultbranch=icehouse ,,5,0
openstack%2Fbarbican~master~If1f9f822d4bd6649676f2b9244ef60ab4047d6df,openstack/barbican,master,If1f9f822d4bd6649676f2b9244ef60ab4047d6df,Replace and remove native asserts,MERGED,2015-01-07 19:37:47.000000000,2015-01-08 09:43:17.000000000,2015-01-08 09:43:16.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-01-07 19:37:47.000000000', 'files': ['barbican/tests/plugin/test_kmip.py', 'barbican/tests/plugin/test_dogtag.py', 'barbican/queue/__init__.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/61e28b9959a26ad85d69251c5fd3cdef381b6607', 'message': 'Replace and remove native asserts\n\nIn some test cases, native python asserts were being used instead of\nthe assert methods that come with the test framework. They were\nchanged since the framework asserts give more relevant information if\nthe test hits a bug.\n\nOn the other hand, some asserts in the queue initialization code were\nnot really necessary, so they were removed.\n\nChange-Id: If1f9f822d4bd6649676f2b9244ef60ab4047d6df\n'}]",1,145563,61e28b9959a26ad85d69251c5fd3cdef381b6607,17,14,1,10873,,,0,"Replace and remove native asserts

In some test cases, native python asserts were being used instead of
the assert methods that come with the test framework. They were
changed since the framework asserts give more relevant information if
the test hits a bug.

On the other hand, some asserts in the queue initialization code were
not really necessary, so they were removed.

Change-Id: If1f9f822d4bd6649676f2b9244ef60ab4047d6df
",git fetch https://review.opendev.org/openstack/barbican refs/changes/63/145563/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/plugin/test_kmip.py', 'barbican/tests/plugin/test_dogtag.py', 'barbican/queue/__init__.py', 'barbican/tests/api/test_resources.py']",4,61e28b9959a26ad85d69251c5fd3cdef381b6607,replace_asserts," self.assertEqual(resp.status_int, 400)", assert resp.status_int == 400,18,20
openstack%2Fopenstack-ansible~juno~I9525bb55ed5eeb36fadf0c69be8f743450880bf4,openstack/openstack-ansible,juno,I9525bb55ed5eeb36fadf0c69be8f743450880bf4,Add gitreview config with correct default branch,MERGED,2015-01-07 20:53:54.000000000,2015-01-08 09:40:41.000000000,2015-01-08 09:40:41.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-01-07 20:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f03e38021d37949ff658987c8f1fb6b66419848d', 'message': 'Add gitreview config with correct default branch\n\nChange-Id: I9525bb55ed5eeb36fadf0c69be8f743450880bf4\n'}, {'number': 2, 'created': '2015-01-07 20:54:36.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d148fdf50474612b8971858a5b56373637730512', 'message': 'Add gitreview config with correct default branch\n\nChange-Id: I9525bb55ed5eeb36fadf0c69be8f743450880bf4\n(cherry picked from commit f03e38021d37949ff658987c8f1fb6b66419848d)\n'}]",0,145585,d148fdf50474612b8971858a5b56373637730512,13,6,2,12892,,,0,"Add gitreview config with correct default branch

Change-Id: I9525bb55ed5eeb36fadf0c69be8f743450880bf4
(cherry picked from commit f03e38021d37949ff658987c8f1fb6b66419848d)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/85/145585/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,f03e38021d37949ff658987c8f1fb6b66419848d,,defaultbranch=juno,,1,0
openstack%2Fopenstack-ansible~master~Icc06e4c8e00b44df7540bb8d33f0d0afba20e4f6,openstack/openstack-ansible,master,Icc06e4c8e00b44df7540bb8d33f0d0afba20e4f6,add remote maas check for ssl cert expiry,MERGED,2015-01-07 15:30:38.000000000,2015-01-08 09:40:32.000000000,2015-01-08 09:40:32.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12000}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 15:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/34b3aecdb7ca7cf525b2fe6deebb72fa594c2ae7', 'message': 'add remote maas check for ssl cert expiry\n\nif setting up your external endpoints to be behind an ssl cert on your\nload balancer, it might be quite useful to get an alert when the\ncert is due to expire.  This commit adds that check in a new\nplaybook that would need to be run manually if you are setting up\nthis way.\n\nCloses-Bug: 1408335\n\nChange-Id: Icc06e4c8e00b44df7540bb8d33f0d0afba20e4f6\n'}, {'number': 2, 'created': '2015-01-07 16:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2483d8f481bd90dc26db8ab619e214002ca71cce', 'message': 'add remote maas check for ssl cert expiry\n\nif setting up your external endpoints to be behind an ssl cert on your\nload balancer, it might be quite useful to get an alert when the\ncert is due to expire.  This commit adds that check in a new\nplaybook that would need to be run manually if you are setting up\nthis way.\n\nCloses-Bug: 1408335\n\nChange-Id: Icc06e4c8e00b44df7540bb8d33f0d0afba20e4f6\n'}, {'number': 3, 'created': '2015-01-07 17:04:54.000000000', 'files': ['rpc_deployment/playbooks/monitoring/maas_ssl_check.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6276950833189f227431181fb6a1d39b5e428fde', 'message': 'add remote maas check for ssl cert expiry\n\nif setting up your external endpoints to be behind an ssl cert on your\nload balancer, it might be quite useful to get an alert when the\ncert is due to expire.  This commit adds that check in a new\nplaybook that would need to be run manually if you are setting up\nthis way.\n\nCloses-Bug: 1408335\n\nChange-Id: Icc06e4c8e00b44df7540bb8d33f0d0afba20e4f6\n'}]",2,145527,6276950833189f227431181fb6a1d39b5e428fde,20,6,3,425,,,0,"add remote maas check for ssl cert expiry

if setting up your external endpoints to be behind an ssl cert on your
load balancer, it might be quite useful to get an alert when the
cert is due to expire.  This commit adds that check in a new
playbook that would need to be run manually if you are setting up
this way.

Closes-Bug: 1408335

Change-Id: Icc06e4c8e00b44df7540bb8d33f0d0afba20e4f6
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/27/145527/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/playbooks/monitoring/maas_ssl_check.yml'],1,34b3aecdb7ca7cf525b2fe6deebb72fa594c2ae7,bug/1408335,"# Copyright 2014, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # - hosts: utility[0] user: root roles: - maas_remote vars: entity_name: ""{{ lb_name }}"" target_alias: ""{{ maas_target_alias }}"" check_type: remote.http check_name: lb_ssl_cert_expiry_check check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" monitoring_zones: ""{{ maas_monitoring_zones }}"" notification_plan: ""{{ maas_notification_plan }}"" scheme: ""https"" ip_address: ""{{ external_vip_address }}"" port: ""443"" path: """" url: ""{{ scheme }}://{{ ip_address }}:{{ port }}{{ path }}"" alarm_name: lb_ssl_cert_expiry_alarm criteria: ""if (metric['cert_end_in'] < 604800) {return new AlarmStatus(CRITICAL, 'Cert expiring in less than 604800 seconds.');}if (metric['cert_end_in'] < 2628288) {return new AlarmStatus(WARNING, 'Cert expiring in less than 2628288 seconds.');}return new AlarmStatus(OK, 'HTTP certificate doesn\'t expire soon.');"" ",,35,0
openstack%2Ftricircle~master~I18ab0bbaff168aa5f0260206208bdcd17a4e1415,openstack/tricircle,master,I18ab0bbaff168aa5f0260206208bdcd17a4e1415,recovery mapping_uuid in cinder-proxy volume metadata,MERGED,2015-01-08 09:36:00.000000000,2015-01-08 09:37:20.000000000,2015-01-08 09:37:20.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2015-01-08 09:36:00.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/2ccb6a723c26f651f12093350c99428d24a91eb8', 'message': 'recovery mapping_uuid in cinder-proxy volume metadata\n\nb/c this is useful for nova-proxy to attach volume\n\nChange-Id: I18ab0bbaff168aa5f0260206208bdcd17a4e1415\n'}]",0,145731,2ccb6a723c26f651f12093350c99428d24a91eb8,6,2,1,13924,,,0,"recovery mapping_uuid in cinder-proxy volume metadata

b/c this is useful for nova-proxy to attach volume

Change-Id: I18ab0bbaff168aa5f0260206208bdcd17a4e1415
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/31/145731/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,2ccb6a723c26f651f12093350c99428d24a91eb8,master," metadata['mapping_uuid'] = bodyResponse._info['id'] self.db.volume_metadata_update(context, volume_id, metadata, True)",,4,0
openstack%2Fcinder~master~Ic42836e995bbdaad92e355b94cb2d7b45d8fdb60,openstack/cinder,master,Ic42836e995bbdaad92e355b94cb2d7b45d8fdb60,LVM: Add terminate_connection call for Target Objects,MERGED,2015-01-07 23:12:46.000000000,2015-01-08 09:18:42.000000000,2015-01-08 09:18:41.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 9176}, {'_account_id': 10115}, {'_account_id': 10622}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}]","[{'number': 1, 'created': '2015-01-07 23:12:46.000000000', 'files': ['cinder/volume/targets/driver.py', 'cinder/tests/targets/test_base_iscsi_driver.py', 'cinder/volume/targets/fake.py', 'cinder/volume/targets/iet.py', 'cinder/volume/targets/lio.py', 'cinder/volume/targets/iscsi.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/00b03b90cc460215c2e9f2aac107e362955320e2', 'message': 'LVM: Add terminate_connection call for Target Objects\n\nterminate_connection should be redirected from LVM driver to targets\nobject. Especially this is required in LioAdm to remove an initiator\nfrom a target. This also fixes some mismatch of method arguments and\nremove unused methods in target objects.\n\nChange-Id: Ic42836e995bbdaad92e355b94cb2d7b45d8fdb60\nPartial-Bug: #1408443\n'}]",0,145627,00b03b90cc460215c2e9f2aac107e362955320e2,16,10,1,9176,,,0,"LVM: Add terminate_connection call for Target Objects

terminate_connection should be redirected from LVM driver to targets
object. Especially this is required in LioAdm to remove an initiator
from a target. This also fixes some mismatch of method arguments and
remove unused methods in target objects.

Change-Id: Ic42836e995bbdaad92e355b94cb2d7b45d8fdb60
Partial-Bug: #1408443
",git fetch https://review.opendev.org/openstack/cinder refs/changes/27/145627/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/targets/driver.py', 'cinder/tests/targets/test_base_iscsi_driver.py', 'cinder/volume/targets/fake.py', 'cinder/volume/targets/iet.py', 'cinder/volume/targets/lio.py', 'cinder/volume/targets/iscsi.py', 'cinder/volume/drivers/lvm.py']",7,00b03b90cc460215c2e9f2aac107e362955320e2,bug/1408443," return self.target_driver.terminate_connection(volume, connector, **kwargs)", pass,10,35
openstack%2Fhorizon~master~Ied17f1e6f58947161ac6c241446f8eac5a9383c2,openstack/horizon,master,Ied17f1e6f58947161ac6c241446f8eac5a9383c2,Updated from global requirements,MERGED,2015-01-08 02:15:25.000000000,2015-01-08 09:16:59.000000000,2015-01-08 09:16:58.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 7665}, {'_account_id': 8648}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-01-08 02:15:25.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/55a5dccd9e03bffbd1491b945a6fa3ace039f72a', 'message': 'Updated from global requirements\n\nChange-Id: Ied17f1e6f58947161ac6c241446f8eac5a9383c2\n'}]",0,145656,55a5dccd9e03bffbd1491b945a6fa3ace039f72a,8,6,1,11131,,,0,"Updated from global requirements

Change-Id: Ied17f1e6f58947161ac6c241446f8eac5a9383c2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/145656/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,55a5dccd9e03bffbd1491b945a6fa3ace039f72a,openstack/requirements,XStatic-Angular>=1.3.7 # MIT License,XStatic-Angular>=1.2.1.1 # MIT License,1,1
openstack%2Fcinder~master~I33b605fecf1709efa6124312ba58cd29ed885178,openstack/cinder,master,I33b605fecf1709efa6124312ba58cd29ed885178,Fix drbd driver to load without 3'rd party libs,MERGED,2015-01-08 00:25:05.000000000,2015-01-08 09:13:37.000000000,2015-01-08 09:13:36.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 10622}, {'_account_id': 10677}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 14339}]","[{'number': 1, 'created': '2015-01-08 00:25:05.000000000', 'files': ['cinder/volume/drivers/drbdmanagedrv.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ef58aff5d8b141b73baddda727ee273c30814c39', 'message': ""Fix drbd driver to load without 3'rd party libs\n\nThe new drbd driver has a couple needed 3'rd party libs\nthat aren't in the global requirements.  That means that\nany time there's an attempt to import the driver things\nblow up due to import errors.\n\nThe great thing is that the author took care of things in\nunit tests by creating mocks, but we still have the problem\nof the driver itself, and this causes us to be unable to do\nthings like genconfig.\n\nThis patch just wraps the 3'rd party libs into a try/catch\nblock, sets them to None if they're not on the system.\n\nAlso, move the global dbus.array variable into init and\nmake it a member variable.\n\nChange-Id: I33b605fecf1709efa6124312ba58cd29ed885178\nCloses-Bug: #1408483\n""}]",1,145644,ef58aff5d8b141b73baddda727ee273c30814c39,13,10,1,2243,,,0,"Fix drbd driver to load without 3'rd party libs

The new drbd driver has a couple needed 3'rd party libs
that aren't in the global requirements.  That means that
any time there's an attempt to import the driver things
blow up due to import errors.

The great thing is that the author took care of things in
unit tests by creating mocks, but we still have the problem
of the driver itself, and this causes us to be unable to do
things like genconfig.

This patch just wraps the 3'rd party libs into a try/catch
block, sets them to None if they're not on the system.

Also, move the global dbus.array variable into init and
make it a member variable.

Change-Id: I33b605fecf1709efa6124312ba58cd29ed885178
Closes-Bug: #1408483
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/145644/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/drbdmanagedrv.py'],1,ef58aff5d8b141b73baddda727ee273c30814c39,bug/1408483,"try: import dbus import drbdmanage.consts as dm_const import drbdmanage.exceptions as dm_exc import drbdmanage.utils as dm_utils except ImportError: dbus = None dm_const = None dm_exc = None dm_utils = None self.empty_list = dbus.Array([], signature=""a(ss)"") self.empty_list, self.empty_list) self.empty_list, self.empty_list, self.empty_list) self.empty_list) r_props = self.empty_list self.empty_list, self.empty_list, self.empty_list)","import dbus import drbdmanage.consts as dm_const import drbdmanage.exceptions as dm_exc import drbdmanage.utils as dm_utilsEMPTY_LIST = dbus.Array([], signature=""a(ss)"") EMPTY_LIST, EMPTY_LIST) EMPTY_LIST, EMPTY_LIST, EMPTY_LIST) EMPTY_LIST) r_props = EMPTY_LIST EMPTY_LIST, EMPTY_LIST, EMPTY_LIST)",22,15
openstack%2Fheat~master~Ie75a3c5b4e61cbc4c5478e24f7ac41df0fdc2aba,openstack/heat,master,Ie75a3c5b4e61cbc4c5478e24f7ac41df0fdc2aba,Updated from global requirements,MERGED,2015-01-08 02:28:49.000000000,2015-01-08 09:13:27.000000000,2015-01-08 09:13:26.000000000,"[{'_account_id': 3}, {'_account_id': 4715}]","[{'number': 1, 'created': '2015-01-08 02:28:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/b02e13262422d7bef9c1a143b7c91a316987293b', 'message': 'Updated from global requirements\n\nChange-Id: Ie75a3c5b4e61cbc4c5478e24f7ac41df0fdc2aba\n'}]",0,145663,b02e13262422d7bef9c1a143b7c91a316987293b,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ie75a3c5b4e61cbc4c5478e24f7ac41df0fdc2aba
",git fetch https://review.opendev.org/openstack/heat refs/changes/63/145663/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b02e13262422d7bef9c1a143b7c91a316987293b,openstack/requirements,oslo.db>=1.3.0 # Apache-2.0,oslo.db>=1.1.0 # Apache-2.0,1,1
openstack%2Fec2-api~master~I8f613b083f5e6042fd76177e500986596d00f689,openstack/ec2-api,master,I8f613b083f5e6042fd76177e500986596d00f689,add volumes' tests,MERGED,2014-12-30 13:23:45.000000000,2015-01-08 09:05:33.000000000,2015-01-08 09:05:32.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-30 13:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c39934f243ccb1231be2e8a07ee5029fe2e25922', 'message': ""add volumes' tests\n\nChange-Id: I8f613b083f5e6042fd76177e500986596d00f689\n""}, {'number': 2, 'created': '2015-01-03 20:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/b9c01ddfa3d3f08a4643c28e7d6b7deabfb7fe5b', 'message': ""add volumes' tests\n\nChange-Id: I8f613b083f5e6042fd76177e500986596d00f689\n""}, {'number': 3, 'created': '2015-01-05 18:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/33af319af3fba454f797a2448fc5b8ffed122c4d', 'message': ""add volumes' tests\n\nChange-Id: I8f613b083f5e6042fd76177e500986596d00f689\n""}, {'number': 4, 'created': '2015-01-08 08:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2ba722a86dc18e6cad585eff387e5b6d3cdfdcf0', 'message': ""add volumes' tests\n\nChange-Id: I8f613b083f5e6042fd76177e500986596d00f689\n""}, {'number': 5, 'created': '2015-01-08 08:51:23.000000000', 'files': ['ec2api/api/volume.py', 'ec2api/api/cloud.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py', 'ec2api/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/4706689b21a242ef068dd05e461c795dea19c055', 'message': ""add volumes' tests\n\nChange-Id: I8f613b083f5e6042fd76177e500986596d00f689\n""}]",5,144453,4706689b21a242ef068dd05e461c795dea19c055,18,4,5,10234,,,0,"add volumes' tests

Change-Id: I8f613b083f5e6042fd76177e500986596d00f689
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/53/144453/5 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/volume.py', 'ec2api/api/cloud.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py', 'ec2api/tests/test_volume.py']",5,c39934f243ccb1231be2e8a07ee5029fe2e25922,master-2,"# Copyright 2014 # The Cloudscaling Group, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import mock from ec2api.tests import base from ec2api.tests import fakes from ec2api.tests import matchers from ec2api.tests import tools class VolumeTestCase(base.ApiTestCase): def test_create_volume(self): self.cinder_volumes.create.return_value = ( fakes.CinderVolume(fakes.OS_VOLUME_1)) self.db_api.add_item.side_effect = ( fakes.get_db_api_add_item(fakes.ID_EC2_VOLUME_1)) resp = self.execute( 'CreateVolume', {'AvailabilityZone': 'fake_zone'}) self.assertEqual(200, resp['status']) self.assertThat(fakes.EC2_VOLUME_1, matchers.DictMatches( tools.purge_dict(resp, {'status'}))) self.cinder_volumes.create.assert_called_once(mock.ANY) self.db_api.add_item.assert_called_once_with( mock.ANY, 'vol', tools.purge_dict(fakes.DB_VOLUME_1, ('id',))) ",,125,13
openstack%2Ffuel-web~master~I78416f525060b68902478c97e42cb38f7479c2b8,openstack/fuel-web,master,I78416f525060b68902478c97e42cb38f7479c2b8,Fix for nailgun_performance_test job (#1407027),ABANDONED,2015-01-04 20:57:21.000000000,2015-01-08 08:50:22.000000000,,"[{'_account_id': 3}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-01-04 20:57:21.000000000', 'files': ['nailgun/tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3d2558123682661c6e4b9abbab8dd7d2d22d0085', 'message': ""Fix for nailgun_performance_test job (#1407027)\n\n- added new 'perf' env.\n\nChange-Id: I78416f525060b68902478c97e42cb38f7479c2b8\n""}]",3,144897,3d2558123682661c6e4b9abbab8dd7d2d22d0085,10,8,1,14372,,,0,"Fix for nailgun_performance_test job (#1407027)

- added new 'perf' env.

Change-Id: I78416f525060b68902478c97e42cb38f7479c2b8
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/97/144897/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/tox.ini'],1,3d2558123682661c6e4b9abbab8dd7d2d22d0085,nailgun_performance_tests, [testenv:perf] install_command = pip install {packages} deps = -r{toxinidir}/test-requirements.txt setenv = VIRTUAL_ENV={envdir} commands = nosetests {posargs:test/performance},,7,0
openstack%2Ftripleo-heat-templates~master~I96144ee2f4ca33bd7467f09ad960ea268c1250bf,openstack/tripleo-heat-templates,master,I96144ee2f4ca33bd7467f09ad960ea268c1250bf,Bring back (abandoned) support for Cinder/NFS,MERGED,2014-11-21 11:13:53.000000000,2015-01-08 08:50:15.000000000,2015-01-08 08:50:15.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 6488}, {'_account_id': 6796}, {'_account_id': 7585}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-11-21 11:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/692660e79c061f07cb976ba22e8b477a206ba1e6', 'message': 'Fix overcloud-with-block-storage-nfs target\n\nThis change updates nfs-server-source, drops (stale) block-storage-nfs\nYAML files and finally realigns overcloud-with-block-storage-nfs make\ntarget deps with regular overcloud target.\n\nChange-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf\n'}, {'number': 2, 'created': '2014-11-21 11:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b2a6318d71a92e0fed1db8d040cdce9e70a77be2', 'message': 'Fix overcloud-with-block-storage-nfs target\n\nThis change updates nfs-server-source, drops (stale) block-storage-nfs\nYAML files and finally realigns overcloud-with-block-storage-nfs make\ntarget deps with regular overcloud target.\n\nChange-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf\n'}, {'number': 3, 'created': '2014-11-21 11:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/efa433f281381923e00e9cbdf67569ed908dd696', 'message': 'Fix overcloud-with-block-storage-nfs target\n\nThis change updates nfs-server-source, drops (stale) block-storage-nfs\nYAML files and finally realigns overcloud-with-block-storage-nfs make\ntarget deps with regular overcloud target.\n\nChange-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf\n'}, {'number': 4, 'created': '2014-12-10 10:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/614316209fae61d0df7e03a7c140d30b4de300af', 'message': 'Fix nfs-server-source.yaml template and remove hidden make target\n\nThis change updates (and renames) nfs-server-source non-working as\nunmaintained; also drops (stale) block-storage-nfs YAML file and the\nhidden block-storage-with-nfs target as well, adding a comment on\nwith sample usage of nfs-source.yaml\n\nChange-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf\n'}, {'number': 5, 'created': '2014-12-10 23:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/094e9e5b478e807cfe8b5873cd1ec580bc40e7f1', 'message': 'Bring back working support for Cinder/NFS\n\nWe used to have a YAML file providing a test config of Cinder/NFS\nwhich could be used via a special Makefile target; this was not\nused in CI though so overtime things broke.\n\nThis change aims at bringing that back and also make it easier to\nuse it via a few changes:\n\n* deletes unmaintained nfs-server-source (not working due to\n  changes in the elements)\n* rops (unneeded) block-storage-nfs\n* removes the hidden block-storage-with-nfs target from Makefile\n* provides a working YAML (updated to support newer elements and\n  newer template language as well)\n* improves existing comments in Makefile on how to use it\n\nChange-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf\n'}, {'number': 6, 'created': '2014-12-10 23:22:17.000000000', 'files': ['Makefile', 'block-storage-nfs.yaml', 'nfs-source.yaml', 'nfs-server-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6674c39d80b2418aa573d7f8bbbb9c92648f90c5', 'message': 'Bring back (abandoned) support for Cinder/NFS\n\nWe used to have a YAML file providing a test setup for Cinder/NFS\nwhich could be used via a special Makefile target; this was not\nused in CI anymore though and overtime things broke.\n\nThis change aims at bringing that functionality back and also\nmake it easier to use it via a number of changes:\n\n* delete unmaintained nfs-server-source (not working due to\n  changes in the elements)\n* delete (unneeded) block-storage-nfs\n* remove the hidden block-storage-with-nfs target from Makefile\n* add a some nfs-source which supports newer elements and\n  newer template language as well\n* improve existing comments in Makefile documeting how to use it\n\nChange-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf\n'}]",7,136303,6674c39d80b2418aa573d7f8bbbb9c92648f90c5,45,6,6,6796,,,0,"Bring back (abandoned) support for Cinder/NFS

We used to have a YAML file providing a test setup for Cinder/NFS
which could be used via a special Makefile target; this was not
used in CI anymore though and overtime things broke.

This change aims at bringing that functionality back and also
make it easier to use it via a number of changes:

* delete unmaintained nfs-server-source (not working due to
  changes in the elements)
* delete (unneeded) block-storage-nfs
* remove the hidden block-storage-with-nfs target from Makefile
* add a some nfs-source which supports newer elements and
  newer template language as well
* improve existing comments in Makefile documeting how to use it

Change-Id: I96144ee2f4ca33bd7467f09ad960ea268c1250bf
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/136303/5 && git format-patch -1 --stdout FETCH_HEAD,"['Makefile', 'block-storage-nfs.yaml', 'nfs-server-source.yaml']",3,692660e79c061f07cb976ba22e8b477a206ba1e6,nfs_ci,"resources: controllerNfsServerConfig: type: OS::Heat::StructuredConfig properties: group: os-apply-config config: nfs_server: shares: - name: cinder clients: - machine: 192.0.2.0/24 options: rw,async,no_root_squash controllerCinderNfsConfig: type: OS::Heat::StructuredConfig properties: group: os-apply-config config: cinder: include_nfs_backend: true nfs_share: Fn::Join: - ':' - - {get_attr: [controller0, networks, ctlplane, 0]} - /mnt/state/var/lib/nfs/cinder controllerNfsServerDeployment: type: OS::Heat::StructuredDeployment properties: config: {get_resource: controllerNfsServerConfig} server: {get_resource: controller0} signal_transport: NO_SIGNAL controller0CinderNfsDeployment: type: OS::Heat::StructuredDeployment properties: config: {get_resource: controllerCinderNfsConfig} server: {get_resource: controller0} signal_transport: NO_SIGNAL",description: 'NFS server share configuration for testing' resources: controller0Config: type: AWS::AutoScaling::LaunchConfiguration metadata: nfs_server: shares: Merge::Map: NovaCompute0: Fn::Join: - ' ' - - get_attr: - NovaCompute0 - networks - ctlplane - 0 BlockStorage0: Fn::Join: - ' ' - - get_attr: - BlockStorage0 - networks - ctlplane - 0,37,93
openstack%2Fopenstack-manuals~master~I6db7bb513dde5cb163e5f0aa94cbfc6beae45591,openstack/openstack-manuals,master,I6db7bb513dde5cb163e5f0aa94cbfc6beae45591,Publish the French Image Guide,MERGED,2015-01-06 10:12:46.000000000,2015-01-08 08:49:39.000000000,2015-01-08 08:49:38.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-06 10:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/834a03fd3c0ca79ad4891742fe1016f8b68b22bb', 'message': 'Try publishing French Image Guide\n\nTranslation of the Image Guide into French is almost complete.\n\nThis patch makes the necessary changes to publish it.\n\nChange-Id: I6db7bb513dde5cb163e5f0aa94cbfc6beae45591\n'}, {'number': 2, 'created': '2015-01-07 04:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/93f8993e2d9b7cc34240cb6254b54d43645d5672', 'message': 'Try publishing French Image Guide\n\nTranslation of the Image Guide into French is almost complete.\n\nThis patch makes the necessary changes to publish it.\n\nChange-Id: I6db7bb513dde5cb163e5f0aa94cbfc6beae45591\n'}, {'number': 3, 'created': '2015-01-08 08:01:57.000000000', 'files': ['www/draft-i18n-manuals.html', 'doc-tools-check-languages.conf'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3b4a75e1b754ade947d9dc2fd05ea8490a3e4c66', 'message': 'Publish the French Image Guide\n\nTranslation of the Image Guide into French is almost complete.\n\nThis patch makes the necessary changes to publish it.\n\nChange-Id: I6db7bb513dde5cb163e5f0aa94cbfc6beae45591\n'}]",1,145186,3b4a75e1b754ade947d9dc2fd05ea8490a3e4c66,28,4,3,612,,,0,"Publish the French Image Guide

Translation of the Image Guide into French is almost complete.

This patch makes the necessary changes to publish it.

Change-Id: I6db7bb513dde5cb163e5f0aa94cbfc6beae45591
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/86/145186/3 && git format-patch -1 --stdout FETCH_HEAD,['doc-tools-check-languages.conf'],1,834a03fd3c0ca79ad4891742fe1016f8b68b22bb,publish-fr-image-guide," [""fr""]=""common glossary user-guide image-guide"" [""fr""]=""user-guide image-guide"""," [""fr""]=""common glossary user-guide"" [""fr""]=""user-guide""",2,2
openstack%2Fneutron~stable%2Fjuno~I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd,openstack/neutron,stable/juno,I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd,ipv6: set OtherConfig flag for DHCPv6 stateless subnets,MERGED,2014-12-22 15:07:31.000000000,2015-01-08 08:26:10.000000000,2015-01-07 18:10:54.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 979}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-12-22 15:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b5a763575981930ba3cd6400669bde5b967a2ee', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nSince radvd configuration file becomes quite complex, migrated its\ngeneration to Jinja2.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nNo more unit tests seem to be needed: conditional prefix generation is\nalready covered in test_l3_agent, and other statements are common for\nall ipv6_ra_modes.\n\nConflicts:\n\tneutron/tests/unit/test_l3_agent.py\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n(cherry picked from commit 4f3a9135acb561172f7af45bc82739d6dc49f23c)\n""}, {'number': 2, 'created': '2015-01-05 11:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/51447507dbc28172024390f952a1a319ad86bb48', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nSince radvd configuration file becomes quite complex, migrated its\ngeneration to Jinja2.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nNo more unit tests seem to be needed: conditional prefix generation is\nalready covered in test_l3_agent, and other statements are common for\nall ipv6_ra_modes.\n\nConflicts:\n\tneutron/tests/unit/test_l3_agent.py\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n(cherry picked from commit 4f3a9135acb561172f7af45bc82739d6dc49f23c)\n""}, {'number': 3, 'created': '2015-01-06 10:03:26.000000000', 'files': ['neutron/agent/linux/ra.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/327e32519d3314f3bc9709a5901aff375fd8c011', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nSince radvd configuration file becomes quite complex, migrated its\ngeneration to Jinja2.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nNo more unit tests seem to be needed: conditional prefix generation is\nalready covered in test_l3_agent, and other statements are common for\nall ipv6_ra_modes.\n\nConflicts:\n\tneutron/tests/unit/test_l3_agent.py\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n(cherry picked from commit 4f3a9135acb561172f7af45bc82739d6dc49f23c)\n""}]",0,143461,327e32519d3314f3bc9709a5901aff375fd8c011,59,17,3,9656,,,0,"ipv6: set OtherConfig flag for DHCPv6 stateless subnets

In case of DHCPv6 stateless subnets, we should inform DHCP clients about
other configuration values available from DHCP server. This is done by
setting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag
setting in radvd case.

Since radvd configuration file becomes quite complex, migrated its
generation to Jinja2.

Added a basic unit test that checks that flag is set for stateless mode
and not SLAAC. For stateful, it doesn't really matter whether other flag
is set, so no need to expect any value of it.

No more unit tests seem to be needed: conditional prefix generation is
already covered in test_l3_agent, and other statements are common for
all ipv6_ra_modes.

Conflicts:
	neutron/tests/unit/test_l3_agent.py

Change-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd
Closes-Bug: #1397022
(cherry picked from commit 4f3a9135acb561172f7af45bc82739d6dc49f23c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/143461/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ra.py', 'neutron/tests/unit/test_l3_agent.py']",2,2b5a763575981930ba3cd6400669bde5b967a2ee,bug/1397022,"from neutron.agent.linux import ra def test_generate_radvd_conf_other_flag(self): # we don't check other flag for stateful since it's redundant # for this mode and can be ignored by clients, as per RFC4861 expected = {l3_constants.IPV6_SLAAC: False, l3_constants.DHCPV6_STATELESS: True} for ra_mode, flag_set in expected.iteritems(): router = prepare_router_data() ri = self._process_router_ipv6_interface_added(router, ra_mode=ra_mode) ra._generate_radvd_conf(ri.router['id'], router[l3_constants.INTERFACE_KEY], mock.Mock()) asserter = self.assertIn if flag_set else self.assertNotIn asserter('AdvOtherConfigFlag on;', self.utils_replace_file.call_args[0][1]) ",,38,23
openstack%2Ftripleo-heat-templates~master~Ia2579ed39a16d2b9826ce8406cb97fc116e3d595,openstack/tripleo-heat-templates,master,Ia2579ed39a16d2b9826ce8406cb97fc116e3d595,Allow setting Neutron tunnel type in no mergepy,MERGED,2015-01-06 18:48:55.000000000,2015-01-08 08:23:50.000000000,2015-01-08 08:23:50.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7585}]","[{'number': 1, 'created': '2015-01-06 18:48:55.000000000', 'files': ['overcloud-without-mergepy.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e137dd54d371f5830162ba19cb6fdf018f12e6e7', 'message': 'Allow setting Neutron tunnel type in no mergepy\n\nThe Neutron tunnel type settings were missing from the Controller\nsection of the without-mergepy template, which made it impossible\nto configure any tunnel other than gre.\n\nChange-Id: Ia2579ed39a16d2b9826ce8406cb97fc116e3d595\n'}]",0,145296,e137dd54d371f5830162ba19cb6fdf018f12e6e7,8,3,1,6928,,,0,"Allow setting Neutron tunnel type in no mergepy

The Neutron tunnel type settings were missing from the Controller
section of the without-mergepy template, which made it impossible
to configure any tunnel other than gre.

Change-Id: Ia2579ed39a16d2b9826ce8406cb97fc116e3d595
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/145296/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-without-mergepy.yaml'],1,e137dd54d371f5830162ba19cb6fdf018f12e6e7,neutron-tunnels-nomergepy, NeutronNetworkType: {get_param: NeutronNetworkType} NeutronTunnelTypes: {get_param: NeutronTunnelTypes},,2,0
openstack%2Ftripleo-heat-templates~master~I421ce4fca87ac87dd65ab8bbb20e7ea9be8d9c5d,openstack/tripleo-heat-templates,master,I421ce4fca87ac87dd65ab8bbb20e7ea9be8d9c5d,Don't store Ceilo DB credentials on compute node,MERGED,2014-12-07 20:10:16.000000000,2015-01-08 08:22:56.000000000,2015-01-08 08:22:55.000000000,"[{'_account_id': 3}, {'_account_id': 4220}, {'_account_id': 4328}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7585}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-07 20:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3152fc58a9275f7b60ac7f1e6057c068db60d151', 'message': ""Don't store Ceilo DB credentials on compute node\n\nThis patch removes all references to the Ceilometer DSN parameter\nin the overcloud compute templates. These credentials\nare not required in order to run the required Ceilometer\nservice/agents.\n\nChange-Id: I421ce4fca87ac87dd65ab8bbb20e7ea9be8d9c5d\n""}, {'number': 2, 'created': '2014-12-08 13:35:38.000000000', 'files': ['overcloud-without-mergepy.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'compute.yaml', 'compute-config.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/84c7b32c41cca4e52e52e144550d5e718bbe62f3', 'message': ""Don't store Ceilo DB credentials on compute node\n\nThis patch removes all references to the Ceilometer DSN parameter\nin the overcloud compute templates. These credentials\nare not required in order to run the required Ceilometer\nservice/agents.\n\nChange-Id: I421ce4fca87ac87dd65ab8bbb20e7ea9be8d9c5d\n""}]",0,139876,84c7b32c41cca4e52e52e144550d5e718bbe62f3,18,7,2,360,,,0,"Don't store Ceilo DB credentials on compute node

This patch removes all references to the Ceilometer DSN parameter
in the overcloud compute templates. These credentials
are not required in order to run the required Ceilometer
service/agents.

Change-Id: I421ce4fca87ac87dd65ab8bbb20e7ea9be8d9c5d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/76/139876/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'compute.yaml', 'compute-config.yaml', 'overcloud-source.yaml']",6,3152fc58a9275f7b60ac7f1e6057c068db60d151,no_compute_dsn,," CeilometerDSN: Fn::Join: - '' - - mysql://ceilometer:unset@ - &compute_database_host {get_attr: [ControlVirtualIP, fixed_ips, 0, ip_address]} - /ceilometer",0,20
openstack%2Ftripleo-heat-templates~master~Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7,openstack/tripleo-heat-templates,master,Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7,Puppet: overcloud compute config,MERGED,2014-10-22 18:30:11.000000000,2015-01-08 08:17:23.000000000,2015-01-08 08:17:23.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4190}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 6554}, {'_account_id': 6928}, {'_account_id': 6969}, {'_account_id': 7144}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 9453}, {'_account_id': 11491}]","[{'number': 1, 'created': '2014-10-22 18:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06f31da7e5f0ceaa330d8530bdd1a7c7b1a53221', 'message': ""Implement a Puppet overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::NovaComputeConfig which uses Puppet\nto drive the configuration. Using this I was able\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-collect-config\n heat-config\n heat-config-puppet (not yet landed)\n puppet-modules (not yet landed)\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking I've started using os-net-config\ndirectly via heat.\n\nI'm also using upstream packages built via Delorean.\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 2, 'created': '2014-10-22 18:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d76654d69133305b7397a213f19f3d332d1d4cfd', 'message': ""Implement a Puppet overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::NovaComputeConfig which uses Puppet\nto drive the configuration. Using this I was able\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-collect-config\n heat-config\n heat-config-puppet\n puppet-modules (not yet landed)\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking I've started using os-net-config\ndirectly via heat.\n\nI'm also using upstream packages built via Delorean.\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7""}, {'number': 3, 'created': '2014-10-23 19:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/778f030d8b07511289779b8eafafcd58227049f9', 'message': ""Implement a Puppet overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::NovaComputeConfig which uses Puppet\nto drive the configuration. Using this I was able\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-collect-config\n heat-config\n heat-config-puppet\n puppet-modules (not yet landed)\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking I've started using os-net-config\ndirectly via heat.\n\nI'm also using upstream packages built via Delorean.\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 4, 'created': '2014-10-28 13:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aa0a9f84f37c9fbf69ba8653f44b66cd00a654d5', 'message': ""Implement a Puppet overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::NovaComputeConfig which uses Puppet\nto drive the configuration. Using this I was able\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-collect-config\n heat-config\n heat-config-puppet\n puppet-modules (not yet landed)\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking I've started using os-net-config\ndirectly via heat.\n\nI'm also using upstream packages built via Delorean.\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 5, 'created': '2014-11-14 17:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/83e615068ae36fab13b3595dc81a7f041c42697e', 'message': ""Implement a Puppet overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this I was able\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-collect-config\n heat-config\n heat-config-puppet\n puppet-modules\n os-net-config\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova and neutron\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking I've started using os-net-config\ndirectly via heat. This allows us to configure the\nphysical networking while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (Need\nto move init-neutron-ovs and/or deprecate its\nuse entirely because the heat drive stuff is\nway more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 6, 'created': '2014-11-25 18:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0cebe20e824a950ce02c902608b000d6e2d8ebe', 'message': ""Implement a Puppet overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this I was able\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-collect-config\n heat-config\n heat-config-puppet\n puppet-modules\n os-net-config\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the TIE nova and neutron\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking I've started using os-net-config\ndirectly via heat. This allows us to configure the\nphysical networking while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (Need\nto move init-neutron-ovs and/or deprecate its\nuse entirely because the heat drive stuff is\nway more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 7, 'created': '2014-12-06 00:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ef6d82ebad23d3476c8339836e524aefec924c58', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the TIE nova and neutron\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs and/or deprecate its use entirely\nbecause the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 8, 'created': '2014-12-06 02:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8ca7d2bb86dc91d446f2cd137b1359ecc630e058', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional (non-HA) overcloud\nwhich had the compute node configured via Puppet\nstackforge modules.  This includes all the Nova and\nNeutron configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the TIE nova and neutron\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs and/or deprecate its use entirely\nbecause the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 9, 'created': '2014-12-06 14:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9095ea708817951ae63ab846daa5266543cdeecf', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs and/or deprecate its use entirely\nbecause the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 10, 'created': '2014-12-07 23:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8fcabb1966e53fdf3af83343e09b6cf1981673bb', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 11, 'created': '2014-12-08 02:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06b5d8a8544d962dba1c92952e3c284fc2e130b1', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 12, 'created': '2014-12-08 03:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cf2910a7e21d7b06f6ca81fef35a7db395b22a5b', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 13, 'created': '2014-12-10 14:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a0d3656f63252be7bb552ede5bdf52fbd5b68b0', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 14, 'created': '2014-12-20 02:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/519de0838c2fd18bac89e3e69f004ba2dc3a42a1', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}, {'number': 15, 'created': '2015-01-05 19:09:49.000000000', 'files': ['overcloud-resource-registry-puppet.yaml', 'compute.yaml', 'puppet/hieradata/compute.yaml', 'compute-config.yaml', 'puppet/hieradata/common.yaml', 'compute-config-puppet.yaml', 'puppet/overcloud_compute.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6812f6f644914da6d4b1c62230517cdd29b1e5f9', 'message': ""Puppet: overcloud compute config\n\nThis patch provides an alternate implementation of\nthe OS::TripleO::Compute::SoftwareConfig which uses Puppet\nto drive the configuration. Using this it is possible\nto create a fully functional overcloud compute instance\nwhich has the compute node configured via Puppet\nstackforge modules.  This includes all the Nova, Neutron,\nand Ceilometer configuration required to make things work.\n\nIn order to test this you'll want to build your images\nwith these elements:\n\n os-net-config\n heat-config-puppet\n puppet-modules\n hiera\n\nNone of the OpenStack specific TripleO elements\nshould be used with this approach (the nova/neutron/ceilometer\nelements were NOT used to build the compute image).\n\nAlso, rather than use neutron-openvswitch-agent to configure\nlow level networking it is recommended that os-net-config\nby configured directly via heat modeling rather than\nparameter passing to init-neutron-ovs. This allows us to\nconfigure the physical network while avoiding the coupling to\nthe neutron-openvswitch-element that our standard\nparameter driven networking currently uses. (We still need\nto move init-neutron-ovs so that it isn't coupled and/or deprecate\nits use entirely because the heat drive stuff is more flexible.)\n\nPackages may optionally be pre-installed via DIB using the\n-p option (-p openstack-neutron,openstack-nova).\n\nChange-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7\n""}]",25,130304,6812f6f644914da6d4b1c62230517cdd29b1e5f9,103,16,15,360,,,0,"Puppet: overcloud compute config

This patch provides an alternate implementation of
the OS::TripleO::Compute::SoftwareConfig which uses Puppet
to drive the configuration. Using this it is possible
to create a fully functional overcloud compute instance
which has the compute node configured via Puppet
stackforge modules.  This includes all the Nova, Neutron,
and Ceilometer configuration required to make things work.

In order to test this you'll want to build your images
with these elements:

 os-net-config
 heat-config-puppet
 puppet-modules
 hiera

None of the OpenStack specific TripleO elements
should be used with this approach (the nova/neutron/ceilometer
elements were NOT used to build the compute image).

Also, rather than use neutron-openvswitch-agent to configure
low level networking it is recommended that os-net-config
by configured directly via heat modeling rather than
parameter passing to init-neutron-ovs. This allows us to
configure the physical network while avoiding the coupling to
the neutron-openvswitch-element that our standard
parameter driven networking currently uses. (We still need
to move init-neutron-ovs so that it isn't coupled and/or deprecate
its use entirely because the heat drive stuff is more flexible.)

Packages may optionally be pre-installed via DIB using the
-p option (-p openstack-neutron,openstack-nova).

Change-Id: Ic36be25d70f0a94ca07ffda6e0005669b81c1ac7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/04/130304/15 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-resource-registry-puppet.yaml', 'puppet_manifests/overcloud_compute.pp', 'compute-config-puppet.yaml']",3,06f31da7e5f0ceaa330d8530bdd1a7c7b1a53221,puppet,heat_template_version: 2014-10-16 description: > Puppet Software Config for Nova Compute. resources: NovaComputeConfigImpl: type: OS::Heat::SoftwareConfig properties: group: puppet inputs: - name: debug - name: nova_compute_driver - name: nova_compute_libvirt_type - name: nova_dsn - name: nova_api_host - name: nova_public_ip - name: nova_password - name: ceilometer_dsn - name: ceilometer_metering_secret - name: ceilometer_password - name: ceilometer_compute_agent - name: snmpd_readonly_user_name - name: snmpd_readonly_user_password - name: glance_host - name: glance_port - name: glance_protocol - name: keystone_host - name: neutron_flat_networks - name: neutron_host - name: neutron_dsn - name: neutron_local_ip - name: neutron_tenant_network_type - name: neutron_tunnel_types - name: neutron_network_vlan_ranges - name: neutron_bridge_mappings - name: neutron_enable_tunneling - name: neutron_physical_bridge - name: neutron_public_interface - name: neutron_password - name: admin_password - name: rabbit_host - name: rabbit_username - name: rabbit_password - name: live_update_host - name: live_update_username - name: live_update_password - name: live_update_tenant_name - name: nova_image - name: live_update_compute_image - name: ntp_server outputs: - name: result config: get_file: puppet_manifests/overcloud_compute.pp outputs: config_id: description: The ID of the NovaComputeConfigImpl resource. value: {get_resource: NovaComputeConfigImpl} ,,186,0
openstack%2Ftripleo-image-elements~master~I4a7bd068991e9241074985cc46a695db50c5961f,openstack/tripleo-image-elements,master,I4a7bd068991e9241074985cc46a695db50c5961f,Add support for pxe_ilo driver,MERGED,2014-12-04 14:36:26.000000000,2015-01-08 08:05:13.000000000,2015-01-08 08:05:12.000000000,"[{'_account_id': 3}, {'_account_id': 1706}, {'_account_id': 1872}, {'_account_id': 6488}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-12-04 14:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3b4dc98c9a8e9cd9c37ae511e743ec77d028937f', 'message': ""Add support for pxe_ilo driver\n\nThis adds pxe_ilo to the list of enabled drivers in ironic.conf.\npxe_ilo requires proliantutils which is not in ironic's requirements.txt\nas its conditionally loaded.\n\nChange-Id: I4a7bd068991e9241074985cc46a695db50c5961f\n""}, {'number': 2, 'created': '2014-12-09 16:43:05.000000000', 'files': ['elements/ironic/install.d/ironic-source-install/68-ironic', 'elements/ironic/os-apply-config/etc/ironic/ironic.conf', 'elements/ironic/install.d/ironic-package-install/package-installs-ironic'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/26df595990576c68b2343c2758808cb02de0d642', 'message': ""Add support for pxe_ilo driver\n\nThis adds pxe_ilo to the list of enabled drivers in ironic.conf.\npxe_ilo requires proliantutils which is not in ironic's requirements.txt\nas its conditionally loaded.\n\nChange-Id: I4a7bd068991e9241074985cc46a695db50c5961f\n""}]",2,139070,26df595990576c68b2343c2758808cb02de0d642,26,5,2,1706,,,0,"Add support for pxe_ilo driver

This adds pxe_ilo to the list of enabled drivers in ironic.conf.
pxe_ilo requires proliantutils which is not in ironic's requirements.txt
as its conditionally loaded.

Change-Id: I4a7bd068991e9241074985cc46a695db50c5961f
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/70/139070/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/ironic/install.d/ironic-source-install/68-ironic', 'elements/ironic/os-apply-config/etc/ironic/ironic.conf']",2,3b4dc98c9a8e9cd9c37ae511e743ec77d028937f,os_add_pxe_ilo,"enabled_drivers = pxe_ssh,pxe_ipmitool,pxe_ilo","enabled_drivers = pxe_ssh,pxe_ipmitool",2,1
openstack%2Fheat-templates~master~I7bf54c32fda7a9da862f93a491ceca1d3743e964,openstack/heat-templates,master,I7bf54c32fda7a9da862f93a491ceca1d3743e964,Correct unresolved reference 'true' and 'false',MERGED,2015-01-07 07:43:33.000000000,2015-01-08 08:04:30.000000000,2015-01-08 08:04:29.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 8246}]","[{'number': 1, 'created': '2015-01-07 07:43:33.000000000', 'files': ['hot/software-config/elements/heat-config/os-refresh-config/configure.d/55-heat-config'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/4da7ae65971150b6e75db7807fb87763bd74dd83', 'message': ""Correct unresolved reference 'true' and 'false'\n\nCorrect unresolved references, set boolean value\nto True/False instead of true/false.\n\nChange-Id: I7bf54c32fda7a9da862f93a491ceca1d3743e964\n""}]",0,145424,4da7ae65971150b6e75db7807fb87763bd74dd83,8,5,1,8289,,,0,"Correct unresolved reference 'true' and 'false'

Correct unresolved references, set boolean value
to True/False instead of true/false.

Change-Id: I7bf54c32fda7a9da862f93a491ceca1d3743e964
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/24/145424/1 && git format-patch -1 --stdout FETCH_HEAD,['hot/software-config/elements/heat-config/os-refresh-config/configure.d/55-heat-config'],1,4da7ae65971150b6e75db7807fb87763bd74dd83,correct_true_and_false, found = False found = True, found = false found = true,2,2
openstack%2Fheat~master~Iea32ef7dddb5f75681aa4992d8270391e038a1c8,openstack/heat,master,Iea32ef7dddb5f75681aa4992d8270391e038a1c8,"Enable E122, E126 and E128 style checks",MERGED,2015-01-02 14:33:29.000000000,2015-01-08 07:58:04.000000000,2015-01-08 07:58:03.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 8289}]","[{'number': 1, 'created': '2015-01-02 14:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22ead3f327da3da5f764b28d34e7874175e292bc', 'message': 'Enable E122, E126 and E128 style checks\n\nImproper indent of continued lines.\n\nChange-Id: Iea32ef7dddb5f75681aa4992d8270391e038a1c8\n'}, {'number': 2, 'created': '2015-01-02 15:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fb147a4835973fea72b1a58405740be85d2ba2a9', 'message': 'Enable E122, E126 and E128 style checks\n\nImproper indent of continued lines.\n\nChange-Id: Iea32ef7dddb5f75681aa4992d8270391e038a1c8\n'}, {'number': 3, 'created': '2015-01-05 10:11:25.000000000', 'files': ['heat/tests/test_structured_config.py', 'heat/tests/test_parser.py', 'heat/tests/v1_1/fakes.py', 'heat/tests/test_api_openstack_v1.py', 'heat/engine/resources/template_resource.py', 'heat/tests/test_engine_service.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'heat/tests/test_notifications.py', 'heat/tests/test_software_component.py', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_identifier.py', 'heat/tests/test_server.py', 'heat/tests/test_resource_group.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/9b70d303866e2ed451ce4c3fea5f81b4a88abf5c', 'message': 'Enable E122, E126 and E128 style checks\n\nImproper indent of continued lines.\n\nChange-Id: Iea32ef7dddb5f75681aa4992d8270391e038a1c8\n'}]",0,144750,9b70d303866e2ed451ce4c3fea5f81b4a88abf5c,14,4,3,9542,,,0,"Enable E122, E126 and E128 style checks

Improper indent of continued lines.

Change-Id: Iea32ef7dddb5f75681aa4992d8270391e038a1c8
",git fetch https://review.opendev.org/openstack/heat refs/changes/50/144750/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_structured_config.py', 'heat/tests/test_parser.py', 'heat/tests/v1_1/fakes.py', 'heat/tests/test_api_openstack_v1.py', 'heat/engine/resources/template_resource.py', 'heat/tests/test_engine_service.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'heat/tests/test_notifications.py', 'heat/tests/test_software_component.py', 'heat/common/heat_keystoneclient.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_identifier.py', 'heat/tests/test_server.py', 'heat/tests/test_resource_group.py', 'tox.ini']",15,22ead3f327da3da5f764b28d34e7874175e292bc,new-hacking,"ignore = E251,E265,F402,F812,H101,H202,H233,H305,H307,H402,H404,H405,H803,H904","# E122 continuation line missing indentation or outdented # E126 continuation line over-indented for hanging indent # E128 continuation line under-indented for visual indentignore = E122,E126,E128,E251,E265,F402,F812,H101,H202,H233,H305,H307,H402,H404,H405,H803,H904",219,222
openstack%2Fheat~master~Ib40011ff8748e92d27134c10b1423d02ac438a2e,openstack/heat,master,Ib40011ff8748e92d27134c10b1423d02ac438a2e,Add 'shared' property for OS::Neutron::Firewall,MERGED,2014-12-29 03:58:07.000000000,2015-01-08 07:57:01.000000000,2015-01-08 07:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-29 03:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d16bca0b5d168c9670d114093fb0a35778b66ac0', 'message': ""Add 'shared' property for OS::Neutron::Firewall\n\nAdd 'shared' property and out attribute for\nOS::Neutron::Firewall resource.\n\nChange-Id: Ib40011ff8748e92d27134c10b1423d02ac438a2e\nCloses-Bug: #1406174\n""}, {'number': 2, 'created': '2014-12-30 01:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4ba09b84bd6e461be708b949b298f7a79574bb2b', 'message': ""Add 'shared' property for OS::Neutron::Firewall\n\nAdd 'shared' property and out attribute for\nOS::Neutron::Firewall resource.\n\nChange-Id: Ib40011ff8748e92d27134c10b1423d02ac438a2e\n""}, {'number': 3, 'created': '2015-01-08 01:08:32.000000000', 'files': ['heat/tests/test_neutron_firewall.py', 'heat/engine/resources/neutron/firewall.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/eb75e5a5a1878d6b483b4091efe4ef8070371c8c', 'message': ""Add 'shared' property for OS::Neutron::Firewall\n\nAdd 'shared' property and out attribute for\nOS::Neutron::Firewall resource.\n\nChange-Id: Ib40011ff8748e92d27134c10b1423d02ac438a2e\n""}]",4,144249,eb75e5a5a1878d6b483b4091efe4ef8070371c8c,19,8,3,8289,,,0,"Add 'shared' property for OS::Neutron::Firewall

Add 'shared' property and out attribute for
OS::Neutron::Firewall resource.

Change-Id: Ib40011ff8748e92d27134c10b1423d02ac438a2e
",git fetch https://review.opendev.org/openstack/heat refs/changes/49/144249/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/firewall.py', 'heat/tests/test_neutron_firewall.py']",2,d16bca0b5d168c9670d114093fb0a35778b66ac0,add-shared-property-for-firewall," ""shared"": True, 'firewall_policy_id': 'policy-id', 'shared': True}} 'firewall_policy_id': 'policy-id', 'shared': True}} 'firewall_policy_id': 'policy-id', 'shared': True}}) self.assertIs(True, rsrc.FnGetAtt('shared'))", 'firewall_policy_id': 'policy-id'}} 'firewall_policy_id': 'policy-id'}} 'firewall_policy_id': 'policy-id'}}),19,5
openstack%2Fglance~master~I83e84fcb1a3e26346435f5a56d255a73863a96ec,openstack/glance,master,I83e84fcb1a3e26346435f5a56d255a73863a96ec,Fix rendering of readme document,MERGED,2015-01-07 11:11:03.000000000,2015-01-08 07:45:28.000000000,2015-01-08 07:45:28.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 9096}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-01-07 11:11:03.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/a734a2096dc2cda18d73ef196474b527a2386fe4', 'message': ""Fix rendering of readme document\n\nPreviously, the bullet points didn't bullet.\n\nChange-Id: I83e84fcb1a3e26346435f5a56d255a73863a96ec\n""}]",0,145468,a734a2096dc2cda18d73ef196474b527a2386fe4,17,5,1,11356,,,0,"Fix rendering of readme document

Previously, the bullet points didn't bullet.

Change-Id: I83e84fcb1a3e26346435f5a56d255a73863a96ec
",git fetch https://review.opendev.org/openstack/glance refs/changes/68/145468/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a734a2096dc2cda18d73ef196474b527a2386fe4,readme-formatting,retrieving and storing virtual machine images. Use the following resources to learn more: ,retrieving and storing virtual machine images. Use the following resources to learn more:,4,2
openstack%2Fcinder~master~I0faf4d49b2d3e631b08ec1dff4361ff2376e3308,openstack/cinder,master,I0faf4d49b2d3e631b08ec1dff4361ff2376e3308,Deal with tgt already exists errors,MERGED,2015-01-07 22:10:27.000000000,2015-01-08 07:44:49.000000000,2015-01-08 07:44:48.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 7198}, {'_account_id': 10622}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}]","[{'number': 1, 'created': '2015-01-07 22:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d207928c217451fecd75cc8f9f0c5498cf812f57', 'message': ""Deal with tgt already exists errors\n\nSo there's a major problem in the iscsi code (and has been\nfor quite some time).  The tgt show command sometimes seems\nto be corrupt and the issued command is actually a tgt create.\nThe result is that we already have a tgt and the call raises\nwhich then causes the operation to fail.\n\nAn example of the issue:\n  Stdout: Unexpected error while running command.Command:\n  sudo cinder-rootwrap /etc/cinder/rootwrap.conf tgt-admin\n  --update iqn.2010-10.org.openstack:volume-f055d3c5-db7a-\n  484e-9d0d-b98495439413\n  Exit code: 22\n  Stdout:\n  Command:tgtadm -C 0 --lld iscsi --op new --mode target\n  --tid 1 -T iqn.2010-10.org.openstack:volume-f055d3c5-db7a-\n  484e-9d0d-b98495439413\n  exited with code: 22.\n  Stderr: u'tgtadm: this target already exists\n\nWhat's disturbing however is that in that section of code\nwe're sending a --op show!!  Could be something we're\ndoing with our member executor?  Or maybe something to\ndo with the new oslo concurrency code?\n\nRegardless, his patch intends to provide a clear marker for\nER in the case that create export fails due to the\ntarget entry already existing.\n\nAlso this patch will enable us to go ahead and just use\nthe existing target rather than bomb out and fail everything.\nRoot cause of why we're getting a second create is still\nunknown and needs addressed, but this might help in getting\nmore info as well as keeping things stable until we address\nthe root issue.\n\nChange-Id: I0faf4d49b2d3e631b08ec1dff4361ff2376e3308\nPartial-Bug: #1398078\n""}, {'number': 2, 'created': '2015-01-08 00:40:34.000000000', 'files': ['cinder/volume/targets/tgt.py', 'cinder/tests/targets/test_tgt_driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/941e5f761be165accaabbdeec1608189b04ab67e', 'message': ""Deal with tgt already exists errors\n\nSo there's a major problem in the iscsi code (and has been\nfor quite some time).  The tgt show command sometimes seems\nto be corrupt and the issued command is actually a tgt create.\nThe result is that we already have a tgt and the call raises\nwhich then causes the operation to fail.\n\nAn example of the issue:\n  Stdout: Unexpected error while running command.Command:\n  sudo cinder-rootwrap /etc/cinder/rootwrap.conf tgt-admin\n  --update iqn.2010-10.org.openstack:volume-f055d3c5-db7a-\n  484e-9d0d-b98495439413\n  Exit code: 22\n  Stdout:\n  Command:tgtadm -C 0 --lld iscsi --op new --mode target\n  --tid 1 -T iqn.2010-10.org.openstack:volume-f055d3c5-db7a-\n  484e-9d0d-b98495439413\n  exited with code: 22.\n  Stderr: u'tgtadm: this target already exists\n\nWhat's disturbing however is that in that section of code\nwe're sending a --op show!!  Could be something we're\ndoing with our member executor?  Or maybe something to\ndo with the new oslo concurrency code?\n\nRegardless, his patch intends to provide a clear marker for\nER in the case that create export fails due to the\ntarget entry already existing.\n\nAlso this patch will enable us to go ahead and just use\nthe existing target rather than bomb out and fail everything.\nRoot cause of why we're getting a second create is still\nunknown and needs addressed, but this might help in getting\nmore info as well as keeping things stable until we address\nthe root issue.\n\nChange-Id: I0faf4d49b2d3e631b08ec1dff4361ff2376e3308\nPartial-Bug: #1398078\n""}]",1,145608,941e5f761be165accaabbdeec1608189b04ab67e,18,8,2,2243,,,0,"Deal with tgt already exists errors

So there's a major problem in the iscsi code (and has been
for quite some time).  The tgt show command sometimes seems
to be corrupt and the issued command is actually a tgt create.
The result is that we already have a tgt and the call raises
which then causes the operation to fail.

An example of the issue:
  Stdout: Unexpected error while running command.Command:
  sudo cinder-rootwrap /etc/cinder/rootwrap.conf tgt-admin
  --update iqn.2010-10.org.openstack:volume-f055d3c5-db7a-
  484e-9d0d-b98495439413
  Exit code: 22
  Stdout:
  Command:tgtadm -C 0 --lld iscsi --op new --mode target
  --tid 1 -T iqn.2010-10.org.openstack:volume-f055d3c5-db7a-
  484e-9d0d-b98495439413
  exited with code: 22.
  Stderr: u'tgtadm: this target already exists

What's disturbing however is that in that section of code
we're sending a --op show!!  Could be something we're
doing with our member executor?  Or maybe something to
do with the new oslo concurrency code?

Regardless, his patch intends to provide a clear marker for
ER in the case that create export fails due to the
target entry already existing.

Also this patch will enable us to go ahead and just use
the existing target rather than bomb out and fail everything.
Root cause of why we're getting a second create is still
unknown and needs addressed, but this might help in getting
more info as well as keeping things stable until we address
the root issue.

Change-Id: I0faf4d49b2d3e631b08ec1dff4361ff2376e3308
Partial-Bug: #1398078
",git fetch https://review.opendev.org/openstack/cinder refs/changes/08/145608/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/targets/tgt.py', 'cinder/tests/targets/test_tgt_driver.py']",2,d207928c217451fecd75cc8f9f0c5498cf812f57,bug/1398078,"from oslo_concurrency import processutils as putils def test_create_iscsi_target_already_exists(self): def _fake_execute(*args, **kwargs): raise putils.ProcessExecutionError( exit_code=1, stdout='', stderr='target already exists', cmd='tgtad --lld iscsi --op show --mode target') self.stubs.Set(self.target, '_execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.assertEqual( 1, self.target.create_iscsi_target( test_vol, 1, 0, self.fake_volumes_dir)) ",,49,6
openstack%2Ftrove~master~I55e81693866cb15b3b06ee2ad1700f144023cc60,openstack/trove,master,I55e81693866cb15b3b06ee2ad1700f144023cc60,Obsolete oslo-incubator modules - exception,MERGED,2014-11-06 14:27:47.000000000,2015-01-08 07:44:30.000000000,2015-01-08 07:44:29.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6268}, {'_account_id': 6413}, {'_account_id': 7796}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9746}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10266}, {'_account_id': 10295}, {'_account_id': 10725}, {'_account_id': 12673}, {'_account_id': 13355}]","[{'number': 1, 'created': '2014-11-06 14:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f7785d15615057e3c733972322f5d7d49d0d309a', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 2, 'created': '2014-11-06 14:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e4fb80fabab517a19a945f40c1e3a6b561a32476', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 3, 'created': '2014-11-07 08:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0a2b1608821444345cc340441c0214c8ad46e55a', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 4, 'created': '2014-11-07 10:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/56a98b6b6b254fee766a1849a2ca03c4ff67b3a6', 'message': 'Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 5, 'created': '2014-11-07 10:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8e287d16fd3c749e57cb090787ba89926c17f36b', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n""}, {'number': 6, 'created': '2014-11-18 20:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f4f8cdc1e2f315b150b43119e47b08e4f6e182ef', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n""}, {'number': 7, 'created': '2014-12-04 16:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/437ee9e72d40e018ab7357dd7185260e308697a3', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n""}, {'number': 8, 'created': '2014-12-10 20:06:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/11cd1e54198604198214fd32bde0867dca7625d9', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nThis change has been rebased on https://review.openstack.org/#/c/129714/\n\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\n""}, {'number': 9, 'created': '2014-12-11 20:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9e3f7daf9d3a5be29398bc673ca0f24ed89c2b7b', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nThis change has been rebased on https://review.openstack.org/#/c/129714/\n\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\n""}, {'number': 10, 'created': '2014-12-11 21:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0d86c1c71134bf12224fdecdcc2fd9484c851927', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nThis change has been rebased on https://review.openstack.org/#/c/129714/\n\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\n""}, {'number': 11, 'created': '2014-12-16 19:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b6d5685675ff094b255971560c20ed178cf381d6', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nThis change has been rebased on https://review.openstack.org/#/c/129714/\n\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\n""}, {'number': 12, 'created': '2014-12-25 15:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c47018f47126e7b2620226170c97c4dacb9008f3', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nThis change has been rebased on https://review.openstack.org/#/c/129714/\n\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\n""}, {'number': 13, 'created': '2015-01-06 18:43:23.000000000', 'files': ['trove/common/exception.py', 'trove/common/extensions.py', 'trove/common/base_exception.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/trove/commit/fb83a84e62489e822ae44bbef74faa467e443632', 'message': ""Obsolete oslo-incubator modules - exception\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This change relates to the exception module\nthat is now obsolete. The change here is to delete the file from\nopenstack-common.conf and handle the change as it ripples into the\nmodules that used to include exception.\n\nThe change is modeled on the change that was implemented in\noslo-incubator when this module was deprecated. See review\nhttps://review.openstack.org/#/c/39314\n\nwsgi.py will be deprecated in another change so the only change being\nmade here is (effectively) to extensions.py\n\nWe can't delete the file in openstack/common because there is still a\ndependency within oslo-incubator.\n\nThis change has been rebased on https://review.openstack.org/#/c/129714/\n\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\nChange-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60\n""}]",6,133051,fb83a84e62489e822ae44bbef74faa467e443632,58,21,13,9664,,,0,"Obsolete oslo-incubator modules - exception

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules. This change relates to the exception module
that is now obsolete. The change here is to delete the file from
openstack-common.conf and handle the change as it ripples into the
modules that used to include exception.

The change is modeled on the change that was implemented in
oslo-incubator when this module was deprecated. See review
https://review.openstack.org/#/c/39314

wsgi.py will be deprecated in another change so the only change being
made here is (effectively) to extensions.py

We can't delete the file in openstack/common because there is still a
dependency within oslo-incubator.

This change has been rebased on https://review.openstack.org/#/c/129714/

Blueprint: retire-unused-trove-modules
Partial-Bug: #1380789
Change-Id: I55e81693866cb15b3b06ee2ad1700f144023cc60
",git fetch https://review.opendev.org/openstack/trove refs/changes/51/133051/10 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/extensions.py', 'trove/openstack/common/wsgi.py', 'trove/openstack/common/exception.py']",3,f7785d15615057e3c733972322f5d7d49d0d309a,bugs/bug-1380789-exception,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exceptions common to OpenStack projects """""" import logging from trove.openstack.common.gettextutils import _ _FATAL_EXCEPTION_FORMAT_ERRORS = False class Error(Exception): def __init__(self, message=None): super(Error, self).__init__(message) class ApiError(Error): def __init__(self, message='Unknown', code='Unknown'): self.message = message self.code = code super(ApiError, self).__init__('%s: %s' % (code, message)) class NotFound(Error): pass class UnknownScheme(Error): msg = ""Unknown scheme '%s' found in URI"" def __init__(self, scheme): msg = self.__class__.msg % scheme super(UnknownScheme, self).__init__(msg) class BadStoreUri(Error): msg = ""The Store URI %s was malformed. Reason: %s"" def __init__(self, uri, reason): msg = self.__class__.msg % (uri, reason) super(BadStoreUri, self).__init__(msg) class Duplicate(Error): pass class NotAuthorized(Error): pass class NotEmpty(Error): pass class Invalid(Error): pass class BadInputError(Exception): """"""Error resulting from a client sending bad input to a server"""""" pass class MissingArgumentError(Error): pass class DatabaseMigrationError(Error): pass class ClientConnectionError(Exception): """"""Error resulting from a client connecting to a server"""""" pass def wrap_exception(f): def _wrap(*args, **kw): try: return f(*args, **kw) except Exception as e: if not isinstance(e, Error): #exc_type, exc_value, exc_traceback = sys.exc_info() logging.exception(_('Uncaught exception')) #logging.error(traceback.extract_stack(exc_traceback)) raise Error(str(e)) raise _wrap.func_name = f.func_name return _wrap class OpenstackException(Exception): """""" Base Exception To correctly use this class, inherit from it and define a 'message' property. That message will get printf'd with the keyword arguments provided to the constructor. """""" message = ""An unknown exception occurred"" def __init__(self, **kwargs): try: self._error_string = self.message % kwargs except Exception as e: if _FATAL_EXCEPTION_FORMAT_ERRORS: raise e else: # at least get the core message out if something happened self._error_string = self.message def __str__(self): return self._error_string class MalformedRequestBody(OpenstackException): message = ""Malformed message body: %(reason)s"" class InvalidContentType(OpenstackException): message = ""Invalid content type %(content_type)s"" ",25,153
openstack%2Fnova~master~If5258c851b60cc4360f357a531610e4e52f9b26c,openstack/nova,master,If5258c851b60cc4360f357a531610e4e52f9b26c,Remove no need LOG.exception on attach_interface,MERGED,2015-01-07 14:25:37.000000000,2015-01-08 07:41:17.000000000,2015-01-07 18:11:41.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-07 14:25:37.000000000', 'files': ['nova/api/openstack/compute/contrib/attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/644c89d175370cbb6b269cb2914ba26bc481e63b', 'message': 'Remove no need LOG.exception on attach_interface\n\nWhen attach_interface, this LOG.exception will be reported\nif InterfaceAttachFailed is raised from compute layer\nactually, there already are LOG.error and API layer also\nreported this exception, so there is no need to\nraise exception here.\n\nChange-Id: If5258c851b60cc4360f357a531610e4e52f9b26c\n'}]",3,145515,644c89d175370cbb6b269cb2914ba26bc481e63b,15,10,1,6062,,,0,"Remove no need LOG.exception on attach_interface

When attach_interface, this LOG.exception will be reported
if InterfaceAttachFailed is raised from compute layer
actually, there already are LOG.error and API layer also
reported this exception, so there is no need to
raise exception here.

Change-Id: If5258c851b60cc4360f357a531610e4e52f9b26c
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/145515/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/attach_interfaces.py'],1,644c89d175370cbb6b269cb2914ba26bc481e63b,remove_log_exception_attach_interface,, LOG.exception(e),0,1
openstack%2Fneutron~master~Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3,openstack/neutron,master,Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3,Remove locking from network and subnet delete op,MERGED,2014-08-19 17:52:35.000000000,2015-01-08 07:27:09.000000000,2014-12-18 00:59:02.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1923}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6635}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 8124}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9093}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10354}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10624}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-08-19 17:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/731b432f69a500fb3930e17ec5deebaf336f5e55', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet instead of using SELECT FOR UPDATE deletes\nthe IPAllocations that can be auto-deleted straight away.\nAn Exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network tries to delete all ports and subnet before\nperforming the network deletiong. No lock is needed here,\nif some other process modifies the Port or Subnet table,\nadding new items,the network deletion will fail because\nof a violation of a foreign key contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 2, 'created': '2014-08-20 15:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3451ec44308af25eaaea0598a16181944a765346', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet instead of using SELECT FOR UPDATE deletes\nthe IPAllocations that can be auto-deleted straight away.\nAn Exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network tries to delete all ports and subnets before\nperforming the network deletion. No lock is needed here,\nif some other process modifies the Port or Subnet table,\nadding new items,the network deletion will fail because\nof a violation of a foreign key contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 3, 'created': '2014-09-01 10:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/80a901bd1488894712ad87d329f039ba7682e29b', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet instead of using SELECT FOR UPDATE deletes\nthe IPAllocations that can be auto-deleted straight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network tries to delete all ports and subnets before\nperforming the network deletion. No lock is needed here -\nif some other process modifies the Port or Subnet table,\nadding new items, the network deletion will fail because\nof a violation of a foreign key contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 4, 'created': '2014-09-01 14:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f1741f9043dc58a1918efa0b6dc8a26bb4356ec', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet instead of using SELECT FOR UPDATE deletes\nthe IPAllocations that can be auto-deleted straight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network tries to delete all ports and subnets before\nperforming the network deletion. No lock is needed here -\nif some other process modifies the Port or Subnet table,\nadding new items, the network deletion will fail because\nof a violation of a foreign key contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 5, 'created': '2014-09-03 10:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/59a9c04d3252ba556e731a4a0faff56d0a94e5d1', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet instead of using SELECT FOR UPDATE deletes\nthe IPAllocations that can be auto-deleted straight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network tries to delete all ports and subnets before\nperforming the network deletion. No lock is needed here -\nif some other process modifies the Port or Subnet table,\nadding new items, the network deletion will fail because\nof a violation of a foreign key contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 6, 'created': '2014-09-05 14:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/477e08a28994157850b998decb7ab06c7259e20e', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 7, 'created': '2014-09-08 15:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09db897f2fda2721cbebb7696b08007d62b4d51d', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 8, 'created': '2014-09-15 14:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0aae65a70f3e92eca0fcd7d822a2924c2c8f29ff', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 9, 'created': '2014-10-01 14:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd95499bc0b913706030f2dac6da880433a0cf00', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 10, 'created': '2014-11-20 18:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/46fef429bd5cfb15768e8f6e3f1230c6aabf55b9', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 11, 'created': '2014-11-21 18:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d368731b9dd3c8b57678dbd22e69c886ac17a31e', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 12, 'created': '2014-11-24 18:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8169c4c3fc5a1a7f12c597d4bb1075e5892735ab', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 13, 'created': '2014-11-28 17:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/417d883251be3c0263492816e8ff6760a5754d18', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 14, 'created': '2014-12-03 19:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ede41d77e7a8940a29aeb8f0248fca9af827352e', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 15, 'created': '2014-12-15 16:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/81f2789365d8c455d5880118a887562fb38cb619', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 16, 'created': '2014-12-16 09:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce9231dd5e56bd6add98523a2403248d184cb09a', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}, {'number': 17, 'created': '2014-12-16 13:51:02.000000000', 'files': ['neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/532cd91fa79f6061399a1bf326a49c5e6f5ece6b', 'message': 'Remove locking from network and subnet delete op\n\ndelete_subnet in Ml2 plugin instead of using SELECT FOR\nUPDATE deletes the IPAllocations that can be auto-deleted\nstraight away.\nAn exception is raised if there are ports that cannot be\nautodeleted.\n\ndelete_network in ML2 plugin tries to delete all ports\nand subnets before performing the network deletion.\nNo lock is needed here - if some other process modifies\nthe Port or Subnet table, adding new items, the network\ndeletion will fail because of a violation of a foreign\nkey contraint.\nIn that case the operation will be retried.\n\nChange-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3\nCloses-bug: #1332917\n'}]",55,115360,532cd91fa79f6061399a1bf326a49c5e6f5ece6b,449,48,17,6788,,,0,"Remove locking from network and subnet delete op

delete_subnet in Ml2 plugin instead of using SELECT FOR
UPDATE deletes the IPAllocations that can be auto-deleted
straight away.
An exception is raised if there are ports that cannot be
autodeleted.

delete_network in ML2 plugin tries to delete all ports
and subnets before performing the network deletion.
No lock is needed here - if some other process modifies
the Port or Subnet table, adding new items, the network
deletion will fail because of a violation of a foreign
key contraint.
In that case the operation will be retried.

Change-Id: Ib4e9441a95d6c80b92a43d55fdeb18d7b51a1cf3
Closes-bug: #1332917
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/115360/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,731b432f69a500fb3930e17ec5deebaf336f5e55,lock-db," # No need of locking the Port of the Subnet table here. # If these tables are modified by another process, the # deletion of the network from the DB will fail because of # a foreign key constraint violation. The DBException will # be caught and the loop retried. with session.begin(subtransactions=True): filter_by(network_id=id).all()) filter_by(network_id=id).all()) # delete_subnet will delete the IPAllocation and call update_port. # the DHCP agent will delete the ports asynchronously with session.begin(subtransactions=True): filter_by( device_owner=const.DEVICE_OWNER_DHCP). all()) if allocated: map(session.delete, allocated) # Check if there are tenant owned ports tenant_ports = (session.query(models_v2.IPAllocation). filter_by(subnet_id=id). join(models_v2.Port). filter_by(network_id=subnet['network_id']). all()) if tenant_ports:"," # REVISIT(rkukura): Its not clear that # with_lockmode('update') is really needed in this # transaction, and if not, the semaphore can also be # removed. # # REVISIT: Serialize this operation with a semaphore # to prevent deadlock waiting to acquire a DB lock # held by another thread in the same process, leading # to 'lock wait timeout' errors. with contextlib.nested(lockutils.lock('db-access'), session.begin(subtransactions=True)): filter_by(network_id=id). with_lockmode('update').all()) filter_by(network_id=id). with_lockmode('update').all()) for port in ports: try: self.delete_port(context, port.id) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_(""Exception auto-deleting port %s""), port.id) # REVISIT: Serialize this operation with a semaphore to # prevent deadlock waiting to acquire a DB lock held by # another thread in the same process, leading to 'lock # wait timeout' errors. with contextlib.nested(lockutils.lock('db-access'), session.begin(subtransactions=True)): with_lockmode('update').all()) only_auto_del = all(not a.port_id or a.ports.device_owner in db_base_plugin_v2. AUTO_DELETE_PORT_OWNERS for a in allocated) if not only_auto_del: session.delete(a)",24,37
openstack%2Fopenstack-manuals~master~I4355d25cfa85f32403983b58aa3f0b3cd1925c6a,openstack/openstack-manuals,master,I4355d25cfa85f32403983b58aa3f0b3cd1925c6a,change to section_user_requirements_general_purpose,MERGED,2015-01-07 20:50:14.000000000,2015-01-08 07:25:47.000000000,2015-01-08 07:25:46.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-07 20:50:14.000000000', 'files': ['doc/arch-design/generalpurpose/section_user_requirements_general_purpose.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/922f8b059dcd13105431b35648f1b7e12e533a1b', 'message': 'change to section_user_requirements_general_purpose\n\nchanged to general purpose clouds\nadded “a” private cloud and removed “the”\n\nChange-Id: I4355d25cfa85f32403983b58aa3f0b3cd1925c6a\n'}]",0,145583,922f8b059dcd13105431b35648f1b7e12e533a1b,7,3,1,9382,,,0,"change to section_user_requirements_general_purpose

changed to general purpose clouds
added “a” private cloud and removed “the”

Change-Id: I4355d25cfa85f32403983b58aa3f0b3cd1925c6a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/83/145583/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/generalpurpose/section_user_requirements_general_purpose.xml'],1,922f8b059dcd13105431b35648f1b7e12e533a1b,section_user_req_gen," derive. General purpose clouds do not always provide create their own clouds internally. Using a private cloud, architectural and cloud components.</para> security, a general purpose cloud is not considered an"," derive. General purpose cloud do not always provide create their own clouds internally. Using private cloud, the architectural and cloud components.</para> security, general purpose cloud is not considered an",4,4
openstack%2Fopenstack-manuals~master~I85e593a5cf8bfff1c8e093df35a8924c8cb61332,openstack/openstack-manuals,master,I85e593a5cf8bfff1c8e093df35a8924c8cb61332,Fix 3PAR host persona mapping to match WSAPI,MERGED,2015-01-07 22:37:04.000000000,2015-01-08 07:25:39.000000000,2015-01-08 07:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-07 22:37:04.000000000', 'files': ['doc/config-reference/block-storage/drivers/hp-3par-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/edd3b9e23610718697110fbfeb8b5f8be98d5c32', 'message': 'Fix 3PAR host persona mapping to match WSAPI\n\nAligns the 3PAR host personas to match the WSAPI and 3PAR\ncinder driver code that was merged in the following review:\nhttps://review.openstack.org/142894\n\nChange-Id: I85e593a5cf8bfff1c8e093df35a8924c8cb61332\nCloses-Bug: 1406841\n'}]",0,145612,edd3b9e23610718697110fbfeb8b5f8be98d5c32,7,3,1,6043,,,0,"Fix 3PAR host persona mapping to match WSAPI

Aligns the 3PAR host personas to match the WSAPI and 3PAR
cinder driver code that was merged in the following review:
https://review.openstack.org/142894

Change-Id: I85e593a5cf8bfff1c8e093df35a8924c8cb61332
Closes-Bug: 1406841
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/12/145612/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/hp-3par-driver.xml'],1,edd3b9e23610718697110fbfeb8b5f8be98d5c32,bug/1406841," <literal>3 - Generic-legacy</literal>, <literal>4 - HPUX-legacy</literal>, <literal>5 - AIX-legacy</literal>, <literal>6 - EGENERA</literal>, <literal>7 - ONTAP-legacy</literal>, <literal>8 - VMware</literal>, <literal>9 - OpenVMS</literal>, <literal>10 - HPUX</literal>, and <literal>11 - WindowsServer</literal>.</para>"," <literal>6 - Generic-legacy</literal>, <literal>7 - HPUX-legacy</literal>, <literal>8 - AIX-legacy</literal>, <literal>9 - EGENERA</literal>, <literal>10 - ONTAP-legacy</literal>, <literal>11 - VMware</literal>, <literal>12 - OpenVMS</literal>, <literal>13 - HPUX</literal>, and <literal>15 - WindowsServer</literal>.</para>",8,8
openstack%2Fapi-site~master~I80bd6a0cbbc798f6ad5c069feff21c665f07f35d,openstack/api-site,master,I80bd6a0cbbc798f6ad5c069feff21c665f07f35d,"Fix required attributes of ""ip_version"" for subnet-create.",MERGED,2015-01-08 06:04:05.000000000,2015-01-08 07:24:13.000000000,2015-01-08 07:24:13.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-08 06:04:05.000000000', 'files': ['api-ref/src/wadls/netconn-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/a612d805bdd4c0e1dfd733d212a5576b768f8a42', 'message': 'Fix required attributes of ""ip_version"" for subnet-create.\n\nChange the required attribute from ""false"" to ""true"".\n\nChange-Id: I80bd6a0cbbc798f6ad5c069feff21c665f07f35d\nCloses-Bug: #1408218\n'}]",0,145691,a612d805bdd4c0e1dfd733d212a5576b768f8a42,7,3,1,13702,,,0,"Fix required attributes of ""ip_version"" for subnet-create.

Change the required attribute from ""false"" to ""true"".

Change-Id: I80bd6a0cbbc798f6ad5c069feff21c665f07f35d
Closes-Bug: #1408218
",git fetch https://review.opendev.org/openstack/api-site refs/changes/91/145691/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/netconn-api/src/common.ent'],1,a612d805bdd4c0e1dfd733d212a5576b768f8a42,bug/1408218," <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"""," <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""false""",1,1
openstack%2Fopenstack-manuals~master~Ie1b3b0dd9c23463de5911c241633a1158e825492,openstack/openstack-manuals,master,Ie1b3b0dd9c23463de5911c241633a1158e825492,few corrections to hello_world_rst,MERGED,2015-01-08 01:59:43.000000000,2015-01-08 07:16:22.000000000,2015-01-08 07:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-01-08 01:59:43.000000000', 'files': ['doc/hot-guide/source/hello_world.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/72abf4a681f2efa21a684b467d31a92a5f467af4', 'message': 'few corrections to hello_world_rst\n\nchanged hidding to hiding\ncorrected contraints to constraints\n\nChange-Id: Ie1b3b0dd9c23463de5911c241633a1158e825492\n'}]",0,145653,72abf4a681f2efa21a684b467d31a92a5f467af4,7,3,1,9382,,,0,"few corrections to hello_world_rst

changed hidding to hiding
corrected contraints to constraints

Change-Id: Ie1b3b0dd9c23463de5911c241633a1158e825492
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/53/145653/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/hot-guide/source/hello_world.rst'],1,72abf4a681f2efa21a684b467d31a92a5f467af4,hello_world_rst,Hiding parameters valuesThe following example defines multiple constraints for a password definition:,Hidding parameters valuesThe following example defines multiple contraints for a password definition:,2,2
openstack%2Fopenstack-manuals~master~I0ddc025366367af9a9eaa928eeae83d4decb576f,openstack/openstack-manuals,master,I0ddc025366367af9a9eaa928eeae83d4decb576f,cleaned up hot_spec.rst file,MERGED,2015-01-08 02:09:24.000000000,2015-01-08 07:16:14.000000000,2015-01-08 07:16:13.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-01-08 02:09:24.000000000', 'files': ['doc/hot-guide/source/hot_spec.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c1e9dde0fc86bc904caf393080122bf4d3bfa858', 'message': 'cleaned up hot_spec.rst file\n\ncorrected and changed contrainsts in two places\nomitted should be omitted - changed\ncorrected dictionnary - typo\ncorrected Orchestration - typo\ncorrected provdes - typo\n\nChange-Id: I0ddc025366367af9a9eaa928eeae83d4decb576f\n'}]",0,145655,c1e9dde0fc86bc904caf393080122bf4d3bfa858,7,3,1,9382,,,0,"cleaned up hot_spec.rst file

corrected and changed contrainsts in two places
omitted should be omitted - changed
corrected dictionnary - typo
corrected Orchestration - typo
corrected provdes - typo

Change-Id: I0ddc025366367af9a9eaa928eeae83d4decb576f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/55/145655/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/hot-guide/source/hot_spec.rst'],1,c1e9dde0fc86bc904caf393080122bf4d3bfa858,hot_spec,"constraints at instantiation time. The constraints are defined as a list with If omitted, a default validation message is presented to the user.dictionary with the actual content of fetched paths and URLs. Theto the absolute URLs required by the Orchestration API.A provider template provides a custom definition of a resource, called its","contrainsts at instantiation time. The contrainsts are defined as a list with If ommitted, a default validation message is presented to the user.dictionnary with the actual content of fetched paths and URLs. Theto the absolute URLs required by the Orcestration API.A provider template provdes a custom definition of a resource, called its",5,5
openstack%2Fopenstack-manuals~master~Ifd1ab697efdaafea1aa990132c85c35930658933,openstack/openstack-manuals,master,Ifd1ab697efdaafea1aa990132c85c35930658933,made change to section_tech_considerations,MERGED,2015-01-07 21:40:20.000000000,2015-01-08 07:16:06.000000000,2015-01-08 07:16:05.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 4656}, {'_account_id': 6547}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-01-07 21:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0c9de6e4e90fcba65fefe30557d5150994c72f45', 'message': 'made change to section_tech_considerations\n\nremoved an - “will become essential”\nadded the before port density\n\nChange-Id: Ifd1ab697efdaafea1aa990132c85c35930658933\n'}, {'number': 2, 'created': '2015-01-07 23:55:56.000000000', 'files': ['doc/arch-design/network_focus/section_tech_considerations_network_focus.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dbadc966783227b978d8fba98778ea29be110d0d', 'message': 'made change to section_tech_considerations\n\nremoved an - “will become essential”\nadded the before port density\nchanged largest to greatest\n\nChange-Id: Ifd1ab697efdaafea1aa990132c85c35930658933\n'}]",1,145597,dbadc966783227b978d8fba98778ea29be110d0d,12,5,2,9382,,,0,"made change to section_tech_considerations

removed an - “will become essential”
added the before port density
changed largest to greatest

Change-Id: Ifd1ab697efdaafea1aa990132c85c35930658933
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/145597/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/network_focus/section_tech_considerations_network_focus.xml'],1,0c9de6e4e90fcba65fefe30557d5150994c72f45,section_tech_consid, become essential for network focused applications in the decision based on the largest port density often comes with a, become an essential for network focused applications in the decision based on largest port density often comes with a,2,2
openstack%2Fopenstack-manuals~master~Iadfb78ee9f47313e723db96c4f45c10e160c3ffa,openstack/openstack-manuals,master,Iadfb78ee9f47313e723db96c4f45c10e160c3ffa,fixed a typo in software_deployment.rst,MERGED,2015-01-08 02:19:32.000000000,2015-01-08 07:15:58.000000000,2015-01-08 07:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-08 02:19:32.000000000', 'files': ['doc/hot-guide/source/software_deployment.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f69bb74a3f37079588776bf8540f5ecab569655f', 'message': 'fixed a typo in software_deployment.rst\n\nmade change to overrite - typo\n\nChange-Id: Iadfb78ee9f47313e723db96c4f45c10e160c3ffa\n'}]",0,145658,f69bb74a3f37079588776bf8540f5ecab569655f,7,3,1,9382,,,0,"fixed a typo in software_deployment.rst

made change to overrite - typo

Change-Id: Iadfb78ee9f47313e723db96c4f45c10e160c3ffa
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/58/145658/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/hot-guide/source/software_deployment.rst'],1,f69bb74a3f37079588776bf8540f5ecab569655f,sw_deployment, # signals to overwrite each other. The following two calls, # signals to overrite each other. The following two calls,1,1
openstack%2Fopenstack-manuals~master~Iedb92395452ef60c2aca7d72c1a8f4b445a4d342,openstack/openstack-manuals,master,Iedb92395452ef60c2aca7d72c1a8f4b445a4d342,fixing typo on section_intro-layers,MERGED,2015-01-08 04:19:29.000000000,2015-01-08 07:10:49.000000000,2015-01-08 07:10:48.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-08 04:19:29.000000000', 'files': ['doc/networking-guide/section_intro-layers.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/27fb0ca11d4286c5a7fb81fe80b0d37f4a006e62', 'message': 'fixing typo on section_intro-layers\n\nProtocal should be protocol\n\nChange-Id: Iedb92395452ef60c2aca7d72c1a8f4b445a4d342\n'}]",0,145683,27fb0ca11d4286c5a7fb81fe80b0d37f4a006e62,7,3,1,9382,,,0,"fixing typo on section_intro-layers

Protocal should be protocol

Change-Id: Iedb92395452ef60c2aca7d72c1a8f4b445a4d342
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/83/145683/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/section_intro-layers.xml'],1,27fb0ca11d4286c5a7fb81fe80b0d37f4a006e62,section-intro_layers," <para>Layer-3 protocols include the Internet Protocol Suite, which includes"," <para>Layer-3 protocols include the Internet Protocal Suite, which includes",1,1
openstack%2Fopenstack-manuals~master~I5153b59ac89638d3765ef325867e56c5e2d82f99,openstack/openstack-manuals,master,I5153b59ac89638d3765ef325867e56c5e2d82f99,Adds auto-extract archive file info to End User Guide,MERGED,2015-01-06 21:20:29.000000000,2015-01-08 07:07:27.000000000,2015-01-08 07:07:26.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-06 21:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3a3738fc5d56928511f99643fd08ae2e8b639898', 'message': 'Adds auto-extract archive file info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I5153b59ac89638d3765ef325867e56c5e2d82f99\nPartial-bug: 1392382\n'}, {'number': 2, 'created': '2015-01-06 22:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e442ef5183fff9bbc726efffe98e20bc91102550', 'message': 'Adds auto-extract archive file info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I5153b59ac89638d3765ef325867e56c5e2d82f99\nPartial-bug: 1392382\n'}, {'number': 3, 'created': '2015-01-06 23:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b3be82238d23f715fb406fdd95e077b37a94d541', 'message': 'Adds auto-extract archive file info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I5153b59ac89638d3765ef325867e56c5e2d82f99\nPartial-bug: 1392382\n'}, {'number': 4, 'created': '2015-01-07 19:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b2cdaa3546b9b16356a28c0da0326b6eb3ae5db8', 'message': 'Adds auto-extract archive file info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I5153b59ac89638d3765ef325867e56c5e2d82f99\nPartial-bug: 1392382\n'}, {'number': 5, 'created': '2015-01-07 20:16:47.000000000', 'files': ['doc/user-guide/section_cli_swift_howto.xml', 'doc/user-guide/section_object-api-archive-auto-extract.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/daf73d3ac215139fbd33c82fba8753b07dcab812', 'message': 'Adds auto-extract archive file info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I5153b59ac89638d3765ef325867e56c5e2d82f99\nPartial-bug: 1392382\n'}]",8,145344,daf73d3ac215139fbd33c82fba8753b07dcab812,18,5,5,12454,,,0,"Adds auto-extract archive file info to End User Guide

With the moving of the Object Storage API content from a
long-form dev guide to a specification, some topics needed
To be added to the End User Guide.

Change-Id: I5153b59ac89638d3765ef325867e56c5e2d82f99
Partial-bug: 1392382
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/44/145344/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/section_cli_swift_howto.xml', 'doc/user-guide/section_object-api-archive-auto-extract.xml']",2,3a3738fc5d56928511f99643fd08ae2e8b639898,bug/1392382,"<?xml version=""1.0"" encoding=""UTF-8""?> <!DOCTYPE section [ <!ENTITY % openstack SYSTEM ""../common/entities/openstack.ent""> %openstack; ]> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""archive-auto-extract""> <?dbhtml stop-chunking?> <title>Auto-extract archive files</title> <para>Use the auto-extract archive feature to upload a tar(1) archive file.</para> <para>The Object Storage system extracts files from the archive file and creates an object.</para> <section xml:id=""archive-auto-extract-put""> <title>Auto-extract archive request</title> <para>To upload an archive file, make a &PUT; request. Add the <parameter>extract-archive=<replaceable>format</replaceable></parameter> query parameter to indicate that you are uploading a tar(1) archive file instead of normal content.</para> <para>Valid values for the <replaceable>format</replaceable> variable are <literal>tar</literal>, <literal>tar.gz</literal>, or <literal>tar.bz2</literal>.</para> <para>The path you specify in the &PUT; request is used for the location of the object and the prefix for the resulting object names.</para> <para>In the &PUT; request, you can specify the path for:</para> <itemizedlist> <listitem> <para>An account</para> </listitem> <listitem> <para>Optionally, a specific container</para> </listitem> <listitem> <para>Optionally, a specific object prefix</para> </listitem> </itemizedlist> <para>For example, if the first object in the tar(1) archive is <filename>/home/file1.txt</filename> and you specify the <filename>/v1/12345678912345/mybackup/castor/</filename> path, the operation creates the <filename>castor/home/file1.txt</filename> object in the <literal>mybackup</literal> container in the <literal>12345678912345</literal> account.</para> </section> <section xml:id=""archive-auto-extract-create""> <title>Create an archive for auto-extract</title> <para>You must use the tar(1) utility to create the tar(1) archive file.</para> <para>You can upload regular files but you cannot upload other items (for example, empty directories or symbolic links).</para> <para>You must UTF-8-encode the member names.</para> <para>The archive auto-extract feature supports these formats:</para> <itemizedlist> <listitem> <para>The POSIX.1-1988 Ustar format.</para> </listitem> <listitem> <para>The GNU tar format. Includes the long name, long link, and sparse extensions.</para> </listitem> <listitem> <para>The POSIX.1-2001 pax format.</para> <para>Use gzip(1) or bzip2(1) to compress the archive.</para> <para>Use the <parameter>extract-archive</parameter> query parameter to specify the format. Valid values for this parameter are <literal>tar</literal>, <literal>tar.gz</literal>, or <literal>tar.bz2</literal>.</para> </listitem> </itemizedlist> </section> <section xml:id=""archive-auto-extract-response""> <title>Auto-extract archive response</title> <para>When Object Storage processes the request, it performs multiple sub-operations. Even if all sub-operations fail, the operation returns a <returnvalue>201</returnvalue> <literal>Created</literal> status. Some sub-operations might succeed while others fail: Examine the response body to determine the results of each auto-extract archive sub-operation.</para> <para>You can set the <literal>Accept</literal> request header to one of these values to define the response format:</para> <variablelist> <varlistentry> <term><literal>text/plain</literal></term> <listitem> <para>Formats response as plain text. If you omit the <literal>Accept</literal> header, <literal>text/plain</literal> is the default.</para> </listitem> </varlistentry> </variablelist> <variablelist> <varlistentry> <term><literal>application/json</literal></term> <listitem> <para>Formats response as JSON.</para> </listitem> </varlistentry> <varlistentry> <term><literal>application/xml</literal></term> <listitem> <para>Formats response as XML.</para> </listitem> </varlistentry> </variablelist> <variablelist> <varlistentry> <term><literal>text/xml</literal></term> <listitem> <para>Formats response as XML.</para> </listitem> </varlistentry> </variablelist> <para>The following auto-extract archive files example shows a <literal>text/plain</literal> response body where no failures occurred:</para> <screen><computeroutput>Number Files Created: 10 Errors:</computeroutput></screen> <para>The following auto-extract archive files example shows a <literal>text/plain</literal> response where some failures occurred. In this example, the Object Storage system is configured to reject certain character strings so that the <errorcode>400</errorcode> <errortext>Bad Request</errortext> error occurs for any objects that use the restricted strings.</para> <screen><computeroutput>Number Files Created: 8 Errors: /v1/12345678912345/mycontainer/home/xx%3Cyy, 400 Bad Request /v1/12345678912345/mycontainer/../image.gif, 400 Bad Request</computeroutput></screen> <para>The following example shows the failure response in <literal>application/json</literal> format.</para> <programlisting language=""json"">{ ""Number Files Created"":1, ""Errors"":[ [ ""/v1/12345678912345/mycontainer/home/xx%3Cyy"", ""400 Bad Request"" ], [ ""/v1/12345678912345/mycontainer/../image.gif"", ""400 Bad Request"" ] ] }</programlisting> </section> </section> ",,160,1
openstack%2Fopenstack-manuals~master~Ifbd8ca417b32716fc97aefa7034f6a26a332257d,openstack/openstack-manuals,master,Ifbd8ca417b32716fc97aefa7034f6a26a332257d,Imported Translations from Transifex,MERGED,2015-01-08 06:15:53.000000000,2015-01-08 07:05:18.000000000,2015-01-08 07:05:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-08 06:15:53.000000000', 'files': ['doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/image-guide/locale/fr.po', 'doc/user-guide/locale/user-guide.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df29463e575e7a6b16f27c2084db0475c70228d9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifbd8ca417b32716fc97aefa7034f6a26a332257d\n'}]",0,145693,df29463e575e7a6b16f27c2084db0475c70228d9,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ifbd8ca417b32716fc97aefa7034f6a26a332257d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/93/145693/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/image-guide/locale/fr.po', 'doc/user-guide/locale/user-guide.pot']",4,df29463e575e7a6b16f27c2084db0475c70228d9,transifex/translations,"""POT-Creation-Date: 2015-01-08 06:15+0000\n""msgid ""The command generates a key pair with the name that you specify for <replaceable>KEY_NAME</replaceable>, writes the private key to the <filename>.pem</filename> file that you specify, and registers the public key at the Nova database.""#: ./doc/user-guide/section_object-api-large-lists.xml:7(title) msgid ""Page through large lists of containers or objects"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:8(para) msgid ""If you have a large number of containers or objects, you can use the <parameter>marker</parameter>, <parameter>limit</parameter>, and <parameter>end_marker</parameter> parameters to control how many items are returned in a list and where the list starts or ends."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:16(parameter) msgid ""marker"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:18(para) msgid ""When you request a list of containers or objects, Object Storage returns a maximum of 10,000 names for each request. To get subsequent names, you must make another request with the <parameter>marker</parameter> parameter. Set the <literal>marker</literal> parameter to the name of the last item returned in the previous list. You must URL-encode the <parameter>marker</parameter> value before you send the HTTP request. Object Storage returns a maximum of 10,000 names starting after the last item returned."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:33(parameter) msgid ""limit"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:35(para) msgid ""To return fewer than 10,000 names, use the <parameter>limit</parameter> parameter. If the number of names returned equals the specified <parameter>limit</parameter> (or 10,000 if you omit the <parameter>limit</parameter> parameter), you can assume there are more names to list. If the number of names in the list is exactly divisible by the <parameter>limit</parameter> value, the last request has no content."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:47(parameter) msgid ""end_marker"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:49(para) msgid ""Limits the result set to names that are less than the <parameter>end_marker</parameter> parameter value. You must URL-encode the <parameter>end_marker</parameter> value before you send the HTTP request."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:58(title) msgid ""To page through a large list of containers"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:59(para) msgid ""Assume the following list of container names:"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:66(para) msgid ""Use a <parameter>limit</parameter> of two:"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:70(para) msgid ""Because two container names are returned, there are more names to list."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:74(para) msgid ""Make another request with a <parameter>marker</parameter> parameter set to the name of the last item returned:"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:80(para) msgid ""Again, two items are returned, and there might be more."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:84(para) msgid ""Make another request with a <parameter>marker</parameter> of the last item returned:"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:89(para) msgid ""You receive a one-item response, which is fewer than the <parameter>limit</parameter> number of names. This indicates that this is the end of the list."" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:94(para) msgid ""Use the <parameter>end_marker</parameter> parameter to limit the result set to object names that are less than the <parameter>end_marker</parameter> parameter value:"" msgstr """" #: ./doc/user-guide/section_object-api-large-lists.xml:102(para) msgid ""You receive a result set of all container names before the <parameter>end-marker</parameter> value."" msgstr """" ","""POT-Creation-Date: 2015-01-05 06:11+0000\n""msgid ""The command generates a key pair with the name that you specify fir <replaceable>KEY_NAME</replaceable>, writes the private key to the <filename>.pem</filename> file that you specify, and registers the public key at the Nova database.""",301,17
openstack%2Fproject-config~master~I73551b1b45f72075a26474dfd73b313eed2751d2,openstack/project-config,master,I73551b1b45f72075a26474dfd73b313eed2751d2,Remove python 2.6 jobs for IPA,MERGED,2015-01-07 23:01:20.000000000,2015-01-08 07:03:11.000000000,2015-01-08 07:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 10380}]","[{'number': 1, 'created': '2015-01-07 23:01:20.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/52ca485b483e3528ea5b82fdf16dab918fe0835a', 'message': ""Remove python 2.6 jobs for IPA\n\nNo former or current IPA ramdisk required python 2.6 support. These\ntests are completely unneeded and waste effort. Once removed here, I'll\nremove py26 environment from tox.ini in IPA itself.\n\nChange-Id: I73551b1b45f72075a26474dfd73b313eed2751d2\n""}]",0,145621,52ca485b483e3528ea5b82fdf16dab918fe0835a,8,4,1,10342,,,0,"Remove python 2.6 jobs for IPA

No former or current IPA ramdisk required python 2.6 support. These
tests are completely unneeded and waste effort. Once removed here, I'll
remove py26 environment from tox.ini in IPA itself.

Change-Id: I73551b1b45f72075a26474dfd73b313eed2751d2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/145621/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,52ca485b483e3528ea5b82fdf16dab918fe0835a,remove-py26-ipa,, - name: python26-jobs,0,1
openstack%2Fneutron~master~I2f7dba6e3f8ea4ddebe7638d908b2ae42997225a,openstack/neutron,master,I2f7dba6e3f8ea4ddebe7638d908b2ae42997225a,Bump minimal dnsmasq version to 2.67,MERGED,2015-01-07 12:29:01.000000000,2015-01-08 06:49:42.000000000,2015-01-07 18:10:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-07 12:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dcdf17bacfa74f61032f6d7797e1ca2bcdbe3e45', 'message': 'Bump minimal dnsmasq version to 2.67\n\nVersions prior to 2.67 did not support MAC address matching for IPv6 clients.\nQuoting dnsmasq CHANGELOG:\n\n""\nversion 2.67\n[...]\n    Support identification of clients by MAC address in\n    DHCPv6. When using a relay, the relay must support RFC\n    6939 for this to work. It always works for directly\n    connected clients. Thanks to Vladislav Grishenko\n    for prompting this feature.\n""\n\nChange-Id: I2f7dba6e3f8ea4ddebe7638d908b2ae42997225a\nCloses-Bug: #1408297\n'}, {'number': 2, 'created': '2015-01-07 15:08:23.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/012ffe86752416cd55269924d6236cdfac6b7434', 'message': 'Bump minimal dnsmasq version to 2.67\n\nVersions prior to 2.67 did not support MAC address matching for IPv6 clients.\nQuoting dnsmasq CHANGELOG:\n\n""\nversion 2.67\n[...]\n    Support identification of clients by MAC address in\n    DHCPv6. When using a relay, the relay must support RFC\n    6939 for this to work. It always works for directly\n    connected clients. Thanks to Vladislav Grishenko\n    for prompting this feature.\n""\n\nChange-Id: I2f7dba6e3f8ea4ddebe7638d908b2ae42997225a\nCloses-Bug: #1408297\n'}]",0,145482,012ffe86752416cd55269924d6236cdfac6b7434,43,21,2,9656,,,0,"Bump minimal dnsmasq version to 2.67

Versions prior to 2.67 did not support MAC address matching for IPv6 clients.
Quoting dnsmasq CHANGELOG:

""
version 2.67
[...]
    Support identification of clients by MAC address in
    DHCPv6. When using a relay, the relay must support RFC
    6939 for this to work. It always works for directly
    connected clients. Thanks to Vladislav Grishenko
    for prompting this feature.
""

Change-Id: I2f7dba6e3f8ea4ddebe7638d908b2ae42997225a
Closes-Bug: #1408297
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/145482/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/dhcp.py'],1,dcdf17bacfa74f61032f6d7797e1ca2bcdbe3e45,bug/1408297, MINIMUM_VERSION = 2.67, MINIMUM_VERSION = 2.63,1,1
openstack%2Fnova~master~I09cbb376df2ce81e618c99e5db36ddf7809f6f3d,openstack/nova,master,I09cbb376df2ce81e618c99e5db36ddf7809f6f3d,Doc:  Adds python-tox to Ubuntu dependencies,MERGED,2014-11-25 13:34:27.000000000,2015-01-08 06:47:39.000000000,2015-01-07 16:09:03.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 8412}, {'_account_id': 9420}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11647}, {'_account_id': 13692}]","[{'number': 1, 'created': '2014-11-25 13:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/055b6a4853351a378e135d421b11883f0f2593e7', 'message': ""Doc:  Adds python-tox to Ubuntu dependencies\n\nThe development.environment instructions were almost completely copy/pastable\nto get started on a new machine. Almost. This doc patch just adds python-tox to\nthe list of things to be fetched with apt-get, so no it's really simple to get\nstarted on a brand-new machine or cloud instance.\n\nChange-Id: I09cbb376df2ce81e618c99e5db36ddf7809f6f3d\n""}, {'number': 2, 'created': '2014-11-25 13:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/986756663aa590247035d82f3b210d506e65327c', 'message': ""Doc:  Adds python-tox to Ubuntu dependencies\n\nThe development.environment instructions were almost completely copy/pastable\nto get started on a new machine. Almost. This doc patch just adds python-tox to\nthe list of things to be fetched with apt-get, so now it's really *really* simple to get\nstarted on a brand-new machine or cloud instance.\n\nChange-Id: I09cbb376df2ce81e618c99e5db36ddf7809f6f3d\n""}, {'number': 3, 'created': '2014-12-09 10:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a58349888b4625389293df0188d58464e3a1978d', 'message': ""Doc:  Adds python-tox to Ubuntu dependencies\n\nThe development.environment instructions were almost completely copy/pastable\nto get started on a new machine. Almost. This doc patch just adds python-tox to\nthe list of things to be fetched with apt-get, so now it's really *really* simple to get\nstarted on a brand-new machine or cloud instance.\n\nChange-Id: I09cbb376df2ce81e618c99e5db36ddf7809f6f3d\n""}, {'number': 4, 'created': '2014-12-22 14:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/20604781d9d06185bbc22900da11e7dab0a8bf88', 'message': ""Doc:  Adds python-tox to Ubuntu dependencies\n\nThe development.environment instructions were almost completely copy/pastable\nto get started on a new machine. Almost. This doc patch just adds python-tox to\nthe list of things to be fetched with apt-get, so now it's really *really* simple to get\nstarted on a brand-new machine or cloud instance.\n\nChange-Id: I09cbb376df2ce81e618c99e5db36ddf7809f6f3d\n""}, {'number': 5, 'created': '2015-01-07 13:51:04.000000000', 'files': ['doc/source/devref/development.environment.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/e2c5aef5301688e6f135955e17ac65fdcec34022', 'message': ""Doc:  Adds python-tox to Ubuntu dependencies\n\nThe development.environment instructions were almost completely copy/pastable\nto get started on a new machine. Almost. This doc patch just adds python-tox to\nthe list of things to be fetched with apt-get, so now it's really *really* simple to get\nstarted on a brand-new machine or cloud instance.\n\nChange-Id: I09cbb376df2ce81e618c99e5db36ddf7809f6f3d\n""}]",0,137060,e2c5aef5301688e6f135955e17ac65fdcec34022,40,15,5,9420,,,0,"Doc:  Adds python-tox to Ubuntu dependencies

The development.environment instructions were almost completely copy/pastable
to get started on a new machine. Almost. This doc patch just adds python-tox to
the list of things to be fetched with apt-get, so now it's really *really* simple to get
started on a brand-new machine or cloud instance.

Change-Id: I09cbb376df2ce81e618c99e5db36ddf7809f6f3d
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/137060/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/development.environment.rst'],1,055b6a4853351a378e135d421b11883f0f2593e7,devref_updates, sudo apt-get install python-dev libssl-dev python-pip git-core libxml2-dev libxslt-dev pkg-config libffi-dev libpq-dev libmysqlclient-dev libvirt-dev graphviz libsqlite3-dev python-tox, sudo apt-get install python-dev libssl-dev python-pip git-core libxml2-dev libxslt-dev pkg-config libffi-dev libpq-dev libmysqlclient-dev libvirt-dev graphviz libsqlite3-dev,1,1
openstack%2Fhorizon~master~Ia0161831b3c1f2770da518bef3cf4b14d633118e,openstack/horizon,master,Ia0161831b3c1f2770da518bef3cf4b14d633118e,Fixed Eye icon on Login Page,ABANDONED,2015-01-08 03:46:21.000000000,2015-01-08 06:39:55.000000000,,"[{'_account_id': 3}, {'_account_id': 10442}]","[{'number': 1, 'created': '2015-01-08 03:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/226a579555fee254e9e24f406ef1b4352750cb15', 'message': ""Fixed Eye icon on Login Page\n\nEye icon will only appear in password field on Login Page if i use\nhttp://localhost/auth/login/,But Eye icon missing in password field on Login\nPage if i use (without /auth/login/)\nhttp://localhost/\nCheck the code, the way with 'http://localhost' use splash.html, but it is\nmissing some js. So I think it can delete the splash.html, all request\nredirect to auth/login\n\nChange-Id: Ia0161831b3c1f2770da518bef3cf4b14d633118e\ncloses-bug: #1408383\n""}, {'number': 2, 'created': '2015-01-08 05:16:38.000000000', 'files': ['openstack_dashboard/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b11ad3ae5510e35e2e36c1e01397ebf2dec59dc7', 'message': ""Fixed Eye icon on Login Page\n\nEye icon will only appear in password field on Login Page if i use\nhttp://localhost/auth/login/,But Eye icon missing in password field on Login\nPage if i use (without /auth/login/)\nhttp://localhost/\nCheck the code, the way with 'http://localhost' use splash.html, but it is\nmissing some js. So I think it can delete the splash.html, all request\nredirect to auth/login\n\nChange-Id: Ia0161831b3c1f2770da518bef3cf4b14d633118e\ncloses-bug: #1408383\n""}]",0,145680,b11ad3ae5510e35e2e36c1e01397ebf2dec59dc7,5,2,2,9337,,,0,"Fixed Eye icon on Login Page

Eye icon will only appear in password field on Login Page if i use
http://localhost/auth/login/,But Eye icon missing in password field on Login
Page if i use (without /auth/login/)
http://localhost/
Check the code, the way with 'http://localhost' use splash.html, but it is
missing some js. So I think it can delete the splash.html, all request
redirect to auth/login

Change-Id: Ia0161831b3c1f2770da518bef3cf4b14d633118e
closes-bug: #1408383
",git fetch https://review.opendev.org/openstack/horizon refs/changes/80/145680/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/views.py'],1,226a579555fee254e9e24f406ef1b4352750cb15,bug/1408383, response = shortcuts.redirect(horizon.get_user_home(request.user))," if request.user.is_authenticated(): response = shortcuts.redirect(horizon.get_user_home(request.user)) else: form = forms.Login(request) response = shortcuts.render(request, 'splash.html', {'form': form})",1,5
openstack%2Fpython-ceilometerclient~master~Ibcf90a394c78bdd38235a0214ac07cfd4f38f927,openstack/python-ceilometerclient,master,Ibcf90a394c78bdd38235a0214ac07cfd4f38f927,Add apiclient to openstack-common.conf,MERGED,2014-12-26 10:28:19.000000000,2015-01-08 05:05:39.000000000,2015-01-08 05:05:38.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}]","[{'number': 1, 'created': '2014-12-26 10:28:19.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/e294ab33db2b0ee33d2c36460a30582d3dd7f644', 'message': ""Add apiclient to openstack-common.conf\n\nNo matter what we do with apiclient in future, we should\ninclude it in openstack-common.conf file since we're using it.\n\nChange-Id: Ibcf90a394c78bdd38235a0214ac07cfd4f38f927\n""}]",0,144111,e294ab33db2b0ee33d2c36460a30582d3dd7f644,23,5,1,6676,,,0,"Add apiclient to openstack-common.conf

No matter what we do with apiclient in future, we should
include it in openstack-common.conf file since we're using it.

Change-Id: Ibcf90a394c78bdd38235a0214ac07cfd4f38f927
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/11/144111/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,e294ab33db2b0ee33d2c36460a30582d3dd7f644,bug/1354470,module=apiclient,,1,0
openstack%2Fmagnum~master~Id522322a461bcbed50970c22dceecbc87cab1c39,openstack/magnum,master,Id522322a461bcbed50970c22dceecbc87cab1c39,Fix dbapi method _add_baymodels_filters,MERGED,2015-01-07 17:47:53.000000000,2015-01-08 04:58:17.000000000,2015-01-08 04:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 11536}]","[{'number': 1, 'created': '2015-01-07 17:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/dcc820434954aab9bd925803cbe88d8ac680ebc1', 'message': 'Fix dbapi method _add_baymodels_filters\n\nChange-Id: Id522322a461bcbed50970c22dceecbc87cab1c39\n'}, {'number': 2, 'created': '2015-01-07 20:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3e6f736d69084dff4d729af46623dc72dddf0cb2', 'message': 'Fix dbapi method _add_baymodels_filters\n\nChange-Id: Id522322a461bcbed50970c22dceecbc87cab1c39\n'}, {'number': 3, 'created': '2015-01-08 03:29:39.000000000', 'files': ['magnum/db/sqlalchemy/api.py', 'magnum/tests/db/test_baymodels.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9ab299d69a5c9f107db30f4db3f33caee1c3f9ca', 'message': 'Fix dbapi method _add_baymodels_filters\n\nChange-Id: Id522322a461bcbed50970c22dceecbc87cab1c39\n'}]",0,145548,9ab299d69a5c9f107db30f4db3f33caee1c3f9ca,16,5,3,11536,,,0,"Fix dbapi method _add_baymodels_filters

Change-Id: Id522322a461bcbed50970c22dceecbc87cab1c39
",git fetch https://review.opendev.org/openstack/magnum refs/changes/48/145548/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/db/sqlalchemy/api.py', 'magnum/tests/db/test_baymodels.py']",2,dcc820434954aab9bd925803cbe88d8ac680ebc1,dbapi," def test_get_baymodel_list_with_filters(self): bm1 = self._create_test_baymodel(id=1, name='bm-one', uuid=magnum_utils.generate_uuid(), image_id='image1') bm2 = self._create_test_baymodel(id=2, name='bm-two', uuid=magnum_utils.generate_uuid(), image_id='image2') res = self.dbapi.get_baymodel_list(filters={'name': 'bm-one'}) self.assertEqual([bm1['id']], [r.id for r in res]) res = self.dbapi.get_baymodel_list(filters={'name': 'bad-name'}) self.assertEqual([], [r.id for r in res]) res = self.dbapi.get_baymodel_list(filters={'image_id': 'image1'}) self.assertEqual([bm1['id']], [r.id for r in res]) res = self.dbapi.get_baymodel_list(filters={'image_id': 'image2'}) self.assertEqual([bm2['id']], [r.id for r in res]) def test_get_baymodelinfo_list_defaults(self): bm_id_list = [] for i in range(1, 6): bm = self._create_test_baymodel(id=i, uuid=magnum_utils.generate_uuid()) bm_id_list.append(bm['id']) res = [i[0] for i in self.dbapi.get_baymodelinfo_list()] self.assertEqual(sorted(res), sorted(bm_id_list)) def test_get_baymodelinfo_list_with_cols(self): uuids = {} names = {} for i in range(1, 6): uuid = magnum_utils.generate_uuid() name = ""node"" + str(i) bm = self._create_test_baymodel(id=i, name=name, uuid=uuid) uuids[bm['id']] = uuid names[bm['id']] = name res = self.dbapi.get_baymodelinfo_list(columns=['id', 'name', 'uuid']) self.assertEqual(names, dict((r[0], r[1]) for r in res)) self.assertEqual(uuids, dict((r[0], r[2]) for r in res)) ",,55,22
openstack%2Fmagnum~master~Ic3c4c38b290e9000d8f3838839b8690bf16335bb,openstack/magnum,master,Ic3c4c38b290e9000d8f3838839b8690bf16335bb,Raise on deleting a referenced baymodel,MERGED,2015-01-07 17:47:53.000000000,2015-01-08 04:56:54.000000000,2015-01-08 04:56:53.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-07 17:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/75030ab2ab5d301bcc1fd8a3c43f4baf6b4df585', 'message': 'Raise an exception on deleting non-empty baymodel\n\nChange-Id: Ic3c4c38b290e9000d8f3838839b8690bf16335bb\n'}, {'number': 2, 'created': '2015-01-07 20:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9b2cc4b361b3c443d9e2a0831c89f6457b854dd8', 'message': 'Raise on deleting a referenced baymodel\n\nChange-Id: Ic3c4c38b290e9000d8f3838839b8690bf16335bb\n'}, {'number': 3, 'created': '2015-01-08 03:22:51.000000000', 'files': ['magnum/db/sqlalchemy/api.py', 'magnum/tests/db/test_baymodels.py', 'magnum/tests/common/test_exception.py', 'magnum/common/exception.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/decfb9c747ae32d2e180fa62fe12648fe286e697', 'message': 'Raise on deleting a referenced baymodel\n\nChange-Id: Ic3c4c38b290e9000d8f3838839b8690bf16335bb\n'}]",8,145547,decfb9c747ae32d2e180fa62fe12648fe286e697,19,6,3,11536,,,0,"Raise on deleting a referenced baymodel

Change-Id: Ic3c4c38b290e9000d8f3838839b8690bf16335bb
",git fetch https://review.opendev.org/openstack/magnum refs/changes/47/145547/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/db/sqlalchemy/api.py', 'magnum/tests/db/test_baymodels.py', 'magnum/tests/common/test_exception.py', 'magnum/common/exception.py']",4,75030ab2ab5d301bcc1fd8a3c43f4baf6b4df585,dbapi,"class BayModelNotEmpty(Invalid): message = _(""Baymodel %(baymodel)s is not empty."") ",,39,3
openstack%2Fdevstack-gate~master~I0c8cf8f5627d1c00f278827ab0cee708f7741e89,openstack/devstack-gate,master,I0c8cf8f5627d1c00f278827ab0cee708f7741e89,Use private addresses everywhere with aiopcpu,MERGED,2014-11-17 20:36:43.000000000,2015-01-08 04:48:36.000000000,2015-01-08 04:48:35.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5803}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-11-17 20:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/bd1fadcc62cdc5517473cc816e3fbaaa73b0c0b5', 'message': ""Set HOST_IP to the private interface\n\nWe are trying to use the private addresses everywhere. By default\ndevstack picks the interface with the default route (usually the public\ninterface). This is breaking migrate/move in aiopcpu since we are adding the\nssh host keys for the private interfaces and not the public ones. So\nwhen nova tries to move an instance across nodes it tries to ssh over\nthe public interface which doesn't have its host key in the known hosts\nfile.\n\nChange-Id: I0c8cf8f5627d1c00f278827ab0cee708f7741e89\n""}, {'number': 2, 'created': '2014-11-17 22:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8d558317d1d6d45e6fbbfbfdd6b447a19bf8a977', 'message': ""Set HOST_IP to the private interface\n\nWe are trying to use the private addresses everywhere. By default\ndevstack picks the interface with the default route (usually the public\ninterface). This is breaking migrate/move in aiopcpu since we are adding the\nssh host keys for the private interfaces and not the public ones. So\nwhen nova tries to move an instance across nodes it tries to ssh over\nthe public interface which doesn't have its host key in the known hosts\nfile.\n\nChange-Id: I0c8cf8f5627d1c00f278827ab0cee708f7741e89\n""}, {'number': 3, 'created': '2014-11-17 22:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/545fd2137255bf3c304dd78f77772e9109425df0', 'message': ""Use private addresses everywhere with aiopcpu\n\nFor consistency of debugging issues like nova instance resize and\nmigrations it helps a lot to use a single set of IPs for OpenStack\nservices. We can't use the public IP for everything (for reasons) but\ncan use the private addresses everywhere so use them.\n\nThis requires setting HOST_IP explicitly in localrc as devstack will\npick the public IPs on nodes that have them by default.\n\nChange-Id: I0c8cf8f5627d1c00f278827ab0cee708f7741e89\n""}, {'number': 4, 'created': '2014-11-17 23:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f7468deb3d25a0fce7bc35caa3bdf81c54de44bf', 'message': ""Use private addresses everywhere with aiopcpu\n\nFor consistency of debugging issues like nova instance resize and\nmigrations it helps a lot to use a single set of IPs for OpenStack\nservices. We can't use the public IP for everything (for reasons) but\ncan use the private addresses everywhere so use them.\n\nThis requires setting HOST_IP explicitly in localrc as devstack will\npick the public IPs on nodes that have them by default.\n\nChange-Id: I0c8cf8f5627d1c00f278827ab0cee708f7741e89\n""}, {'number': 5, 'created': '2014-11-17 23:58:30.000000000', 'files': ['devstack-vm-gate.sh', 'devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/3e635eb5f27e78eff6adbded1b5cddd373cbcf94', 'message': ""Use private addresses everywhere with aiopcpu\n\nFor consistency of debugging issues like nova instance resize and\nmigrations it helps a lot to use a single set of IPs for OpenStack\nservices. We can't use the public IP for everything (for reasons) but\ncan use the private addresses everywhere so use them.\n\nThis requires setting HOST_IP explicitly in localrc as devstack will\npick the public IPs on nodes that have them by default.\n\nChange-Id: I0c8cf8f5627d1c00f278827ab0cee708f7741e89\n""}]",0,135070,3e635eb5f27e78eff6adbded1b5cddd373cbcf94,19,8,5,1849,,,0,"Use private addresses everywhere with aiopcpu

For consistency of debugging issues like nova instance resize and
migrations it helps a lot to use a single set of IPs for OpenStack
services. We can't use the public IP for everything (for reasons) but
can use the private addresses everywhere so use them.

This requires setting HOST_IP explicitly in localrc as devstack will
pick the public IPs on nodes that have them by default.

Change-Id: I0c8cf8f5627d1c00f278827ab0cee708f7741e89
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/70/135070/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,bd1fadcc62cdc5517473cc816e3fbaaa73b0c0b5,multi," # For now assume only one subnode local sub_node=`head -1 /etc/nodepool/primary_node_private` echo ""HOST_IP=$sub_node"" >>""$localrc_file"" else echo ""HOST_IP=$primary_node"" >>""$localrc_file""",,5,0
openstack%2Fheat~master~I22942d20d31f993ad74fbf6a72e5be45928dbc7e,openstack/heat,master,I22942d20d31f993ad74fbf6a72e5be45928dbc7e,Remove duplicate autoscaling adjustment tests,MERGED,2014-12-17 00:15:40.000000000,2015-01-08 04:47:39.000000000,2015-01-08 04:47:38.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 7256}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-17 00:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/201cea979a11b4a5c7ae14761455a249524c1f34', 'message': 'Remove duplicate autoscaling adjustment tests\n\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\nNote: these are done in tests/autoscaling/test_new_capacity.py\n'}, {'number': 2, 'created': '2014-12-19 04:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0d1f2bcb09966750445af66e4fcb08dd91fa6531', 'message': 'Remove duplicate autoscaling adjustment tests\n\nNote: these are done in tests/autoscaling/test_new_capacity.py\n\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\n'}, {'number': 3, 'created': '2014-12-22 03:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/136cc0a961015bba2bf4dd8b7f3f7c8483b87b0b', 'message': 'Remove duplicate autoscaling adjustment tests\n\nNote: these are done in tests/autoscaling/test_new_capacity.py\n\nPart of blueprint decouple-nested\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\n'}, {'number': 4, 'created': '2014-12-31 10:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/62b641f9ec63d02993a105653c31dfc410ada55c', 'message': 'Remove duplicate autoscaling adjustment tests\n\nNote: these are done in tests/autoscaling/test_new_capacity.py\n\nPart of blueprint decouple-nested\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\n'}, {'number': 5, 'created': '2015-01-05 05:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/506058ba8f9b9ec81c6128ee4507a2f8c9959855', 'message': 'Remove duplicate autoscaling adjustment tests\n\nNote: these are done in tests/autoscaling/test_new_capacity.py\n\nPart of blueprint decouple-nested\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\n'}, {'number': 6, 'created': '2015-01-06 13:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/59206ac5274c5db107ec43745d73a9dd63e60157', 'message': 'Remove duplicate autoscaling adjustment tests\n\nNote: these are done in tests/autoscaling/test_new_capacity.py\n\nPart of blueprint decouple-nested\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\n'}, {'number': 7, 'created': '2015-01-07 06:18:45.000000000', 'files': ['heat/tests/test_heat_autoscaling_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/425ce355aad0db74536c7d72a665d26c7a8e46a0', 'message': 'Remove duplicate autoscaling adjustment tests\n\nNote: these are done in tests/autoscaling/test_new_capacity.py\n\nPart of blueprint decouple-nested\nChange-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e\n'}]",2,142265,425ce355aad0db74536c7d72a665d26c7a8e46a0,47,10,7,4715,,,0,"Remove duplicate autoscaling adjustment tests

Note: these are done in tests/autoscaling/test_new_capacity.py

Part of blueprint decouple-nested
Change-Id: I22942d20d31f993ad74fbf6a72e5be45928dbc7e
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/142265/5 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_heat_autoscaling_group.py'],1,201cea979a11b4a5c7ae14761455a249524c1f34,cleaner-series,," def test_scaling_group_truncate_adjustment(self): # Create initial group, 2 instances properties = self.parsed['resources']['my-group']['properties'] properties['desired_capacity'] = 2 rsrc = self.create_stack(self.parsed)['my-group'] self.assertEqual(2, grouputils.get_size(rsrc)) rsrc.adjust(4) self.assertEqual(5, grouputils.get_size(rsrc)) rsrc.adjust(-5) self.assertEqual(1, grouputils.get_size(rsrc)) rsrc.adjust(0) self.assertEqual(1, grouputils.get_size(rsrc)) def _do_test_scaling_group_percent(self, decrease, lowest, increase, create, highest): # Create initial group, 2 instances properties = self.parsed['resources']['my-group']['properties'] properties['desired_capacity'] = 2 rsrc = self.create_stack(self.parsed)['my-group'] self.assertEqual(2, grouputils.get_size(rsrc)) # reduce by decrease % rsrc.adjust(decrease, 'percentage_change_in_capacity') self.assertEqual(lowest, grouputils.get_size(rsrc)) # raise by increase % rsrc.adjust(increase, 'percentage_change_in_capacity') self.assertEqual(highest, grouputils.get_size(rsrc)) def test_scaling_group_percent(self): self._do_test_scaling_group_percent(-50, 1, 200, 2, 3) def test_scaling_group_percent_round_up(self): self._do_test_scaling_group_percent(-33, 1, 33, 1, 2) def test_scaling_group_percent_round_down(self): self._do_test_scaling_group_percent(-66, 1, 225, 2, 3) ",0,41
openstack%2Fglance~master~I2e36bac15878ccd5a4285462af8689c7d188ac7b,openstack/glance,master,I2e36bac15878ccd5a4285462af8689c7d188ac7b,Fix spelling typo,MERGED,2015-01-07 22:27:03.000000000,2015-01-08 04:47:30.000000000,2015-01-08 04:47:29.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-01-07 22:27:03.000000000', 'files': ['doc/source/configuring.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/1b2c1b1a1b8212712b408d94c20cadc69503c304', 'message': 'Fix spelling typo\n\nFixing a typo in documentation\n\nChange-Id: I2e36bac15878ccd5a4285462af8689c7d188ac7b\n'}]",0,145610,1b2c1b1a1b8212712b408d94c20cadc69503c304,7,3,1,12807,,,0,"Fix spelling typo

Fixing a typo in documentation

Change-Id: I2e36bac15878ccd5a4285462af8689c7d188ac7b
",git fetch https://review.opendev.org/openstack/glance refs/changes/10/145610/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuring.rst'],1,1b2c1b1a1b8212712b408d94c20cadc69503c304,typo,"When Glance API service is ran behind a proxy, operator probably need to","When Glance API service is ran dehind a proxy, operator probably need to",1,1
openstack%2Fceilometer~master~Ic6c0b19d6662332ae17a286702e202abe6f9c67a,openstack/ceilometer,master,Ic6c0b19d6662332ae17a286702e202abe6f9c67a,Imported Translations from Transifex,MERGED,2014-12-05 06:10:33.000000000,2015-01-08 04:47:06.000000000,2015-01-08 04:47:05.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-05 06:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/75510c749a57eda226a836da7bea90c8bcfb6003', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 2, 'created': '2014-12-06 06:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/680bbb4df616b5ba044af186f075ff0f2990df29', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 3, 'created': '2014-12-07 06:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c68432ce24ba3c906e40054564ba8653c1ae945d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 4, 'created': '2014-12-08 06:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8dbad7fc8ac55f97c624d8ee55f644de2b5a87db', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 5, 'created': '2014-12-09 06:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5e6f35a2173072868ba789b93ab327e4ba98eb76', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 6, 'created': '2014-12-10 06:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e43f7d61030184ad7ce572eaec19cd82f5999948', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 7, 'created': '2014-12-11 06:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c0a67234ea0e1cc116e7145815d5658e0155a416', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 8, 'created': '2014-12-12 06:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f75fda165de176f52ddc411ae66646e50a067de8', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 9, 'created': '2014-12-13 06:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fac95e54a7d0aaaf4c24f8c62267a8060ada5c0b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 10, 'created': '2014-12-14 06:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c58671aa46c0bf8929710a9ddb0b8651cb6ecfa6', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 11, 'created': '2014-12-15 06:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/72e94f9d00380914fa9fce4a137b4cc498fb0086', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 12, 'created': '2014-12-16 06:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/84471fc44bb8a1b3820995f3fc724549925f4bcc', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 13, 'created': '2014-12-17 06:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1b58be56ecb5a9c9e927143df72c22cd62c45e57', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 14, 'created': '2014-12-18 06:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7e036e6165cac3aac1e2b1fe7c7b8ffd7e1feafa', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 15, 'created': '2014-12-19 06:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0af824518d2c658b681e6c664d2afe225e5ca635', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 16, 'created': '2014-12-20 06:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/afd601d88363a86ee2db5ea206a0f2e82d54c117', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 17, 'created': '2014-12-21 06:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0a4d9d0532ce4808863a3e058981f7e846d6b3a5', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 18, 'created': '2014-12-22 06:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/adfe5af6fd5d2a79fae68f30abc598ba46673c8a', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 19, 'created': '2014-12-23 06:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/58ee5628ad11dbc1b308a1073a10d60df691b20d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 20, 'created': '2014-12-24 06:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4e9759755dbee8a1b290d198811ba3971e50ecc7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 21, 'created': '2014-12-25 06:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/216b31ef50c520f21c3d82b8a27fd2dfa0b01965', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 22, 'created': '2014-12-26 06:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f6038a10ed49db794a1f4c0b77a3993501d1560b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 23, 'created': '2014-12-27 06:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/026d29bf7d6962b6878d92dffe930bdd1aeffa7d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 24, 'created': '2014-12-28 06:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fdfacc715313808bd49a013423883c6923aab99f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 25, 'created': '2014-12-29 06:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5fd7a1667a3439ed06b32b9e3700e7aa837b31a2', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 26, 'created': '2014-12-30 06:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c3dfb78c653f85c0ce79a9cdb4050012226c93d8', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 27, 'created': '2014-12-31 06:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d958c47cbf090f8dbd37f7084296ce5e8a92f05', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 28, 'created': '2015-01-01 06:07:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2096d527c933d60f5718ab14467522c9553b3827', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 29, 'created': '2015-01-02 06:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4de147b18e089dfd1b9a1cfc74bf2d1caf8b4f70', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 30, 'created': '2015-01-03 06:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f73eb035c5b128ba67d10e10f66a4afc1a651257', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 31, 'created': '2015-01-04 06:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d724c5907336af9cd492556617e437e497841322', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 32, 'created': '2015-01-05 06:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9da68bac684d1b866bed814bcb9ff9e9d610fd04', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 33, 'created': '2015-01-06 06:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2c8f8b2dbafc947a9e946657ce3635e3833894ec', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}, {'number': 34, 'created': '2015-01-07 06:11:39.000000000', 'files': ['ceilometer/locale/ceilometer-log-warning.pot', 'ceilometer/locale/it/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/zh_CN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/ceilometer-log-info.pot', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/te_IN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_AU/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/es/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ceilometer.pot'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fa994396b41c491e3e1ff78993f6685c48bbd47e', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a\n'}]",0,139527,fa994396b41c491e3e1ff78993f6685c48bbd47e,147,12,34,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ic6c0b19d6662332ae17a286702e202abe6f9c67a
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/27/139527/34 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/ceilometer-log-warning.pot', 'ceilometer/locale/it/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/zh_CN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/ceilometer-log-info.pot', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/te_IN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_AU/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/es/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ceilometer.pot']",18,75510c749a57eda226a836da7bea90c8bcfb6003,transifex/translations,"""Project-Id-Version: ceilometer 2015.1.dev244.g31e5435\n""""POT-Creation-Date: 2014-12-05 06:10+0000\n""#: ceilometer/compute/pollsters/cpu.py:37#: ceilometer/compute/pollsters/cpu.py:51 #: ceilometer/compute/pollsters/cpu.py:82 #: ceilometer/compute/pollsters/disk.py:121 #: ceilometer/compute/pollsters/disk.py:326#: ceilometer/compute/pollsters/net.py:109#: ceilometer/compute/pollsters/cpu.py:54#: ceilometer/compute/pollsters/cpu.py:57#: ceilometer/compute/pollsters/cpu.py:66#: ceilometer/compute/pollsters/cpu.py:70#: ceilometer/compute/pollsters/cpu.py:85#: ceilometer/compute/pollsters/cpu.py:88#: ceilometer/compute/pollsters/disk.py:124 #: ceilometer/compute/pollsters/disk.py:329 #: ceilometer/compute/pollsters/net.py:112#: ceilometer/compute/pollsters/disk.py:129 #: ceilometer/compute/pollsters/disk.py:335 #: ceilometer/compute/pollsters/net.py:117#: ceilometer/compute/pollsters/net.py:95#: ceilometer/compute/virt/libvirt/inspector.py:135""Failed to inspect vnics of instance Name %(instance_name)s UUID "" ""%(instance_uuid)s, domain is in state of SHUTOFF""#: ceilometer/compute/virt/libvirt/inspector.py:173""Failed to inspect disks of instance Name %(instance_name)s UUID "" ""%(instance_uuid)s, domain is in state of SHUTOFF""#: ceilometer/compute/virt/libvirt/inspector.py:198""Failed to inspect memory usage of instance Name %(instance_name)s UUID "" ""%(instance_uuid)s, domain is in state of SHUTOFF""#: ceilometer/compute/virt/libvirt/inspector.py:216""Failed to inspect memory usage of instance Name %(instance_name)s UUID "" ""%(instance_uuid)s, can not get info from libvirt""#: ceilometer/compute/virt/libvirt/inspector.py:225""Failed to inspect memory usage of %(instance_uuid)s, can not get info ""#: ceilometer/openstack/common/log.py:298#: ceilometer/openstack/common/log.py:406#: ceilometer/openstack/common/log.py:467#: ceilometer/openstack/common/log.py:715#: ceilometer/openstack/common/policy.py:98#: ceilometer/openstack/common/policy.py:101#: ceilometer/openstack/common/policy.py:105 msgid """" ""Directories where policy configuration files are stored. They can be "" ""relative to any directory in the search path defined by the config_dir "" ""option, or absolute paths. The file defined by policy_file must exist for"" "" these directories to be searched.""#: ceilometer/openstack/common/policy.py:129#: ceilometer/openstack/common/policy.py:226#: ceilometer/storage/__init__.py:111#: ceilometer/storage/impl_mongodb.py:552#: ceilometer/storage/mongo/utils.py:246#: ceilometer/storage/mongo/utils.py:265#: ceilometer/storage/mongo/utils.py:402#: ceilometer/storage/mongo/utils.py:406","""Project-Id-Version: ceilometer 2015.1.dev230.gcde8916\n""""POT-Creation-Date: 2014-12-04 06:08+0000\n""#: ceilometer/compute/pollsters/cpu.py:38#: ceilometer/compute/pollsters/cpu.py:52 #: ceilometer/compute/pollsters/cpu.py:83 #: ceilometer/compute/pollsters/disk.py:122 #: ceilometer/compute/pollsters/disk.py:327#: ceilometer/compute/pollsters/net.py:111#: ceilometer/compute/pollsters/cpu.py:55#: ceilometer/compute/pollsters/cpu.py:58#: ceilometer/compute/pollsters/cpu.py:67#: ceilometer/compute/pollsters/cpu.py:71#: ceilometer/compute/pollsters/cpu.py:86#: ceilometer/compute/pollsters/cpu.py:89#: ceilometer/compute/pollsters/disk.py:125 #: ceilometer/compute/pollsters/disk.py:330 #: ceilometer/compute/pollsters/net.py:114#: ceilometer/compute/pollsters/disk.py:130 #: ceilometer/compute/pollsters/disk.py:336 #: ceilometer/compute/pollsters/net.py:119#: ceilometer/compute/pollsters/net.py:97#: ceilometer/compute/virt/libvirt/inspector.py:131""Failed to inspect vnics of %(instance_name)s, domain is in state of "" ""SHUTOFF""#: ceilometer/compute/virt/libvirt/inspector.py:166""Failed to inspect disks of %(instance_name)s, domain is in state of "" ""SHUTOFF""#: ceilometer/compute/virt/libvirt/inspector.py:189""Failed to inspect memory usage of %(instance_name)s, domain is in state "" ""of SHUTOFF""#: ceilometer/compute/virt/libvirt/inspector.py:205""Failed to inspect memory usage of %(instance_name)s, can not get info "" ""from libvirt""#: ceilometer/compute/virt/libvirt/inspector.py:212""Failed to inspect memory usage of %(instance_name)s, can not get info ""#: ceilometer/openstack/common/log.py:287#: ceilometer/openstack/common/log.py:395#: ceilometer/openstack/common/log.py:456#: ceilometer/openstack/common/log.py:707#: ceilometer/openstack/common/policy.py:97#: ceilometer/openstack/common/policy.py:100#: ceilometer/openstack/common/policy.py:104 msgid ""The directories of policy configuration files is stored""#: ceilometer/openstack/common/policy.py:119#: ceilometer/openstack/common/policy.py:213#: ceilometer/storage/__init__.py:106#: ceilometer/storage/impl_mongodb.py:549#: ceilometer/storage/mongo/utils.py:174#: ceilometer/storage/mongo/utils.py:193#: ceilometer/storage/mongo/utils.py:330#: ceilometer/storage/mongo/utils.py:334",224,180
openstack%2Fdiskimage-builder~master~Ia8d7b210369fe7eb7ab239cbdb7f96841104a35d,openstack/diskimage-builder,master,Ia8d7b210369fe7eb7ab239cbdb7f96841104a35d,dracut-ramdisk: fix support for elements with ramdisk-install.d,MERGED,2014-12-16 16:07:40.000000000,2015-01-08 04:22:36.000000000,2015-01-08 04:22:34.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7419}, {'_account_id': 7623}]","[{'number': 1, 'created': '2014-12-16 16:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/8e9ceb8f286460d51d71fc36b30e97ea9b80a9c9', 'message': 'dracut-ramdisk: fix support for elements with ramdisk-install.d\n\nChange-Id: Ia8d7b210369fe7eb7ab239cbdb7f96841104a35d\nCloses-Bug: 1403121\n'}, {'number': 2, 'created': '2014-12-17 18:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/84b47c09cf0682e01f960e7be6e4632ae4337ac1', 'message': ""dracut-ramdisk: fix support for elements with ramdisk-install.d\n\nCopy all of TMP_MOUNT_PATH into the ramdisk so that\nramdisk-install.d actions are respected.\n\nIncludes a workaround for a bug in Dracut that caused the copy\nto fail.\n\nAlso moves init instead of copying it so we don't conflict with\nthe Dracut init.\n\nChange-Id: Ia8d7b210369fe7eb7ab239cbdb7f96841104a35d\nCloses-Bug: 1403121\n""}, {'number': 3, 'created': '2014-12-18 10:49:44.000000000', 'files': ['elements/dracut-ramdisk/post-install.d/99-build-dracut-ramdisk'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/75b34baa981267a3283033eac241d7d7943514dd', 'message': ""dracut-ramdisk: fix support for elements with ramdisk-install.d\n\nCopy all of TMP_MOUNT_PATH into the ramdisk so that\nramdisk-install.d actions are respected.\n\nIncludes a workaround for a bug in Dracut that caused the copy\nto fail.\n\nAlso moves init instead of copying it so we don't conflict with\nthe Dracut init.\n\nChange-Id: Ia8d7b210369fe7eb7ab239cbdb7f96841104a35d\nCloses-Bug: 1403121\n""}]",1,142141,75b34baa981267a3283033eac241d7d7943514dd,24,5,3,6645,,,0,"dracut-ramdisk: fix support for elements with ramdisk-install.d

Copy all of TMP_MOUNT_PATH into the ramdisk so that
ramdisk-install.d actions are respected.

Includes a workaround for a bug in Dracut that caused the copy
to fail.

Also moves init instead of copying it so we don't conflict with
the Dracut init.

Change-Id: Ia8d7b210369fe7eb7ab239cbdb7f96841104a35d
Closes-Bug: 1403121
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/41/142141/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/dracut-ramdisk/post-install.d/99-build-dracut-ramdisk'],1,8e9ceb8f286460d51d71fc36b30e97ea9b80a9c9,bug/1403121," --include ""$TMP_MOUNT_PATH/"" / \"," --include ""$TMP_MOUNT_PATH/init-func"" /init-func \",1,2
openstack%2Fneutron~master~Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43,openstack/neutron,master,Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43,Fix DVR flow problems for IPv6 subnet,MERGED,2014-12-03 07:08:30.000000000,2015-01-08 03:50:21.000000000,2015-01-08 03:50:19.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6620}, {'_account_id': 6685}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8172}, {'_account_id': 9077}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-03 07:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11157c98e50ed635be6e38be1496f82b081ad199', 'message': ""Fix DVR openflow problems for IPv6 subnet\n\nThis code fixes DVR openflow problems by changing proto='ip' to\nproto='ipv6' and changing nw_dst to ipv6_dst.\n\nWhen DVR is enabled, RADVD is spawned by l3 agent on each compute\nnode. This code also prevent IPv6 Router Advertisement from\nsending to other compute nodes.\n\nChange-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43\nCloses-Bug: 1398244\nCloses-Bug: 1398627\nPartial-Bug: 1376325\n""}, {'number': 2, 'created': '2014-12-05 07:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3a688cc6bc62159ee9706b2c15d1cb7c5fb4ffb', 'message': ""Fix DVR openflow problems for IPv6 subnet\n\nThis code fixes DVR openflow problems by changing proto='ip' to\nproto='ipv6' and changing nw_dst to ipv6_dst.\n\nWhen DVR is enabled, RADVD is spawned by l3 agent on each compute\nnode. This code also prevent IPv6 Router Advertisement from\nsending to other compute nodes.\n\nChange-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43\nCloses-Bug: 1398244\nCloses-Bug: 1398627\nPartial-Bug: 1376325\n""}, {'number': 3, 'created': '2014-12-05 07:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ed0749f2db29a03065e0baf0be6bb73a94ddf51', 'message': ""Fix DVR flow problems for IPv6 subnet\n\nThis code fixes DVR flow problems by changing proto='ip' to\nproto='ipv6' and changing nw_dst to ipv6_dst.\n\nWhen DVR is enabled, RADVD is spawned by l3 agent on each compute\nnode. This code also prevent IPv6 Router Advertisement from\nsending to other compute nodes.\n\nChange-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43\nCloses-Bug: 1398244\nCloses-Bug: 1398627\nPartial-Bug: 1376325\n""}, {'number': 4, 'created': '2014-12-09 08:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bdceaa5b2269e2b134c4750891f9e1bb51d17dc6', 'message': ""Fix DVR flow problems for IPv6 subnet\n\nThis code fixes DVR flow problems by changing proto='ip' to\nproto='ipv6' and changing nw_dst to ipv6_dst.\n\nWhen DVR is enabled, RADVD is spawned by l3 agent on each compute\nnode. This code also prevent IPv6 Router Advertisement from\nsending to other compute nodes.\n\nChange-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43\nCloses-Bug: 1398244\nCloses-Bug: 1398627\nPartial-Bug: 1376325\n""}, {'number': 5, 'created': '2014-12-10 06:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d42fac3bde99cb772ee0ff63af66964b49f2b944', 'message': ""Fix DVR flow problems for IPv6 subnet\n\nThis code fixes DVR flow problems by changing proto='ip' to\nproto='ipv6' and changing nw_dst to ipv6_dst.\n\nWhen DVR is enabled, RADVD is spawned by l3 agent on each compute\nnode. This code also prevent IPv6 Router Advertisement from\nsending to other compute nodes.\n\nChange-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43\nCloses-Bug: 1398244\nCloses-Bug: 1398627\nPartial-Bug: 1376325\n""}, {'number': 6, 'created': '2014-12-26 03:38:12.000000000', 'files': ['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/727417e71ed155c7d356b27518896026338f79c3', 'message': ""Fix DVR flow problems for IPv6 subnet\n\nThis code fixes DVR flow problems by changing proto='ip' to\nproto='ipv6' and changing nw_dst to ipv6_dst.\n\nWhen DVR is enabled, RADVD is spawned by l3 agent on each compute\nnode. This code also prevent IPv6 Router Advertisement from\nsending to other compute nodes.\n\nChange-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43\nCloses-Bug: 1398244\nCloses-Bug: 1398627\nPartial-Bug: 1376325\n""}]",15,138654,727417e71ed155c7d356b27518896026338f79c3,132,32,6,7183,,,0,"Fix DVR flow problems for IPv6 subnet

This code fixes DVR flow problems by changing proto='ip' to
proto='ipv6' and changing nw_dst to ipv6_dst.

When DVR is enabled, RADVD is spawned by l3 agent on each compute
node. This code also prevent IPv6 Router Advertisement from
sending to other compute nodes.

Change-Id: Id94acd85ea124eff6cfdfbfc546f5dd4ca81ef43
Closes-Bug: 1398244
Closes-Bug: 1398627
Partial-Bug: 1376325
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/138654/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py']",2,11157c98e50ed635be6e38be1496f82b081ad199,bug/1398244," 'ip_version': 4, 'ip_version': 4, 'ip_version': 4, 'ip_version': 4, 'ip_version': 4, 'ip_version': 4,",,198,74
openstack%2Foslo.middleware~master~I87bc7714cd8df7457f535caf29cdee8b055cd8b0,openstack/oslo.middleware,master,I87bc7714cd8df7457f535caf29cdee8b055cd8b0,Fix bug tracker link in readme,MERGED,2015-01-07 20:40:25.000000000,2015-01-08 03:49:41.000000000,2015-01-08 03:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6537}]","[{'number': 1, 'created': '2015-01-07 20:40:25.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/020fd92f2d789828cd7de06928c65233f4e6b87f', 'message': 'Fix bug tracker link in readme\n\nPoint to the right bug tracker in README.rst.\n\nChange-Id: I87bc7714cd8df7457f535caf29cdee8b055cd8b0\n'}]",0,145578,020fd92f2d789828cd7de06928c65233f4e6b87f,14,3,1,2472,,,0,"Fix bug tracker link in readme

Point to the right bug tracker in README.rst.

Change-Id: I87bc7714cd8df7457f535caf29cdee8b055cd8b0
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/78/145578/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,020fd92f2d789828cd7de06928c65233f4e6b87f,fix-readme-links,* Bugs: http://bugs.launchpad.net/oslo.middleware ,* Bugs: http://bugs.launchpad.net/oslo,1,1
openstack%2Fpython-ceilometerclient~master~I90c5ff10309ff7ad3fb634274e16c26ec8e6a1a2,openstack/python-ceilometerclient,master,I90c5ff10309ff7ad3fb634274e16c26ec8e6a1a2,Add client property for common.base.Manager,MERGED,2014-12-19 03:18:39.000000000,2015-01-08 03:41:25.000000000,2015-01-08 03:41:23.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 9382}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-19 03:18:39.000000000', 'files': ['ceilometerclient/common/base.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/dc74ae7c14af89b8371bf737b4e24468caaba198', 'message': 'Add client property for common.base.Manager\n\nThe latest oslo-incubator.apiclient code assumes resource manager has\nproperty named client, but ceilometerclient has named that property\nto api, which will cause problem when we sync with oslo-incubator.\n\nThis patch simply uses client as an alias of api.\n\nChange-Id: I90c5ff10309ff7ad3fb634274e16c26ec8e6a1a2\n'}]",0,142966,dc74ae7c14af89b8371bf737b4e24468caaba198,12,7,1,6676,,,0,"Add client property for common.base.Manager

The latest oslo-incubator.apiclient code assumes resource manager has
property named client, but ceilometerclient has named that property
to api, which will cause problem when we sync with oslo-incubator.

This patch simply uses client as an alias of api.

Change-Id: I90c5ff10309ff7ad3fb634274e16c26ec8e6a1a2
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/66/142966/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/common/base.py'],1,dc74ae7c14af89b8371bf737b4e24468caaba198,compat-with-apiclient," @property def client(self): """"""Compatible with latest oslo-incubator.apiclient code."""""" return self.api ",,5,0
openstack%2Fgrenade~master~I582ddc6024bca9b9f369c544c03848ea7d23c275,openstack/grenade,master,I582ddc6024bca9b9f369c544c03848ea7d23c275,upgrade-ironic: Do not source lib/baremetal,MERGED,2015-01-07 21:18:59.000000000,2015-01-08 03:41:15.000000000,2015-01-08 03:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}]","[{'number': 1, 'created': '2015-01-07 21:18:59.000000000', 'files': ['upgrade-ironic'], 'web_link': 'https://opendev.org/openstack/grenade/commit/f3553a56543d95367567a74c12316843f2f0b9b4', 'message': 'upgrade-ironic: Do not source lib/baremetal\n\nnova-baremetal support was dropped from devstack, this removes\na reference that is blocking ironic pullup testing.\n\nChange-Id: I582ddc6024bca9b9f369c544c03848ea7d23c275\n'}]",0,145592,f3553a56543d95367567a74c12316843f2f0b9b4,8,3,1,1420,,,0,"upgrade-ironic: Do not source lib/baremetal

nova-baremetal support was dropped from devstack, this removes
a reference that is blocking ironic pullup testing.

Change-Id: I582ddc6024bca9b9f369c544c03848ea7d23c275
",git fetch https://review.opendev.org/openstack/grenade refs/changes/92/145592/1 && git format-patch -1 --stdout FETCH_HEAD,['upgrade-ironic'],1,f3553a56543d95367567a74c12316843f2f0b9b4,,,source $TARGET_DEVSTACK_DIR/lib/baremetal,0,1
openstack%2Fpython-heatclient~master~Ia489df4749f76f37af2d6b7e76c1705f4ffd4715,openstack/python-heatclient,master,Ia489df4749f76f37af2d6b7e76c1705f4ffd4715,Replace httpretty with requests-mock,MERGED,2015-01-06 06:59:30.000000000,2015-01-08 03:40:12.000000000,2015-01-08 03:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7191}]","[{'number': 1, 'created': '2015-01-06 06:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ef0293c2176e8bf503530fb57c3f59f8858949f6', 'message': 'Replace httpretty with requests-mock\n\nRemove all references to httpretty in favour of requests-mock. It is\neasier to work with and seems to have less side effects.\n\nChange-Id: Ia489df4749f76f37af2d6b7e76c1705f4ffd4715\n'}, {'number': 2, 'created': '2015-01-07 21:44:58.000000000', 'files': ['heatclient/tests/test_shell.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/8b92973e1a74c784d6f0d344e1ec0570e1f6b890', 'message': 'Replace httpretty with requests-mock\n\nRemove all references to httpretty in favour of requests-mock. It is\neasier to work with and seems to have less side effects.\n\nChange-Id: Ia489df4749f76f37af2d6b7e76c1705f4ffd4715\n'}]",0,145149,8b92973e1a74c784d6f0d344e1ec0570e1f6b890,11,4,2,7191,,,0,"Replace httpretty with requests-mock

Remove all references to httpretty in favour of requests-mock. It is
easier to work with and seems to have less side effects.

Change-Id: Ia489df4749f76f37af2d6b7e76c1705f4ffd4715
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/49/145149/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'test-requirements.txt']",2,ef0293c2176e8bf503530fb57c3f59f8858949f6,tests,requests-mock>=0.5.1 # Apache-2.0,"httpretty>=0.8.0,!=0.8.1,!=0.8.2,!=0.8.3",25,107
openstack%2Fneutron~master~I884c61ba10cd42011204c3c79e89aa79f1b97f13,openstack/neutron,master,I884c61ba10cd42011204c3c79e89aa79f1b97f13,global requirements: Update oslo.db to 1.1.3,ABANDONED,2015-01-07 12:32:47.000000000,2015-01-08 03:37:53.000000000,,"[{'_account_id': 5170}, {'_account_id': 6962}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}]","[{'number': 1, 'created': '2015-01-07 12:32:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c368daa20c21ad11bebae77aa0b364265b7ddacd', 'message': ""global requirements: Update oslo.db to 1.1.3\n\nWith current Neutron master (commit: 98c53d5), and oslo.db 1.1.0,\nDevStack setup fails with:\n\n[. . .]\ncontext(dependent_req)\\npkg_resources.ContextualVersionConflict: (SQLAlchemy 0.9.8 (/usr/lib64/python2.7/site-packages), Requirement.parse(\\'SQLAlchem\ny<=0.8.99,<=0.9.99,>=0.8.4,>=0.9.7\\'), set([\\'oslo.db\\']))\\n'\n2015-01-07 06:48:11.110 CRITICAL neutron [-] RuntimeError:\nCommand: ['sudo', '/usr/bin/neutron-rootwrap', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=10', '--', 'set-fail-mode', 'br-int', 'secure']\nExit code: 1\nStdout: ''\n[. . .]\n\nA manual 'pip uninstall oslo.db && pip install oslo.db' fixes this\nissue.\n\nSo, update oslo.db version in requirements.txt to that effect.\n\nChange-Id: I884c61ba10cd42011204c3c79e89aa79f1b97f13\n""}]",0,145484,c368daa20c21ad11bebae77aa0b364265b7ddacd,10,8,1,6962,,,0,"global requirements: Update oslo.db to 1.1.3

With current Neutron master (commit: 98c53d5), and oslo.db 1.1.0,
DevStack setup fails with:

[. . .]
context(dependent_req)\npkg_resources.ContextualVersionConflict: (SQLAlchemy 0.9.8 (/usr/lib64/python2.7/site-packages), Requirement.parse(\'SQLAlchem
y<=0.8.99,<=0.9.99,>=0.8.4,>=0.9.7\'), set([\'oslo.db\']))\n'
2015-01-07 06:48:11.110 CRITICAL neutron [-] RuntimeError:
Command: ['sudo', '/usr/bin/neutron-rootwrap', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=10', '--', 'set-fail-mode', 'br-int', 'secure']
Exit code: 1
Stdout: ''
[. . .]

A manual 'pip uninstall oslo.db && pip install oslo.db' fixes this
issue.

So, update oslo.db version in requirements.txt to that effect.

Change-Id: I884c61ba10cd42011204c3c79e89aa79f1b97f13
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/145484/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c368daa20c21ad11bebae77aa0b364265b7ddacd,,oslo.db>=1.3.0 # Apache-2.0,oslo.db>=1.1.0 # Apache-2.0,1,1
openstack%2Fheat-templates~master~I856268053eb755f585183c6a6047eea6c569f9c2,openstack/heat-templates,master,I856268053eb755f585183c6a6047eea6c569f9c2,Write docker operations log to deploy_stdout/stderr,MERGED,2014-11-20 22:15:13.000000000,2015-01-08 03:23:53.000000000,2015-01-08 03:23:53.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 8833}]","[{'number': 1, 'created': '2014-11-20 22:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/bb0337eaea448bc56ed416011b041fd12d3f54a6', 'message': 'Write docker operations log to deploy_stdout/stderr\n\nPreviously deploy_stdout contained a dictionary of container info,\nwhich is not a stdout stream, nor does it give the user any feedback\non what docker operations were performed.\n\nThe container info dict can be added back as a special output.\n\nChange-Id: I856268053eb755f585183c6a6047eea6c569f9c2\n'}, {'number': 2, 'created': '2014-12-29 04:58:42.000000000', 'files': ['hot/software-config/elements/heat-config-docker/install.d/hook-docker.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/5c188939b6c8546b59dc012f55489dbb067ff471', 'message': 'Write docker operations log to deploy_stdout/stderr\n\nPreviously deploy_stdout contained a dictionary of container info,\nwhich is not a stdout stream, nor does it give the user any feedback\non what docker operations were performed.\n\nThe container info dict can be added back as a special output.\n\nChange-Id: I856268053eb755f585183c6a6047eea6c569f9c2\n'}]",9,136144,5c188939b6c8546b59dc012f55489dbb067ff471,15,5,2,4571,,,0,"Write docker operations log to deploy_stdout/stderr

Previously deploy_stdout contained a dictionary of container info,
which is not a stdout stream, nor does it give the user any feedback
on what docker operations were performed.

The container info dict can be added back as a special output.

Change-Id: I856268053eb755f585183c6a6047eea6c569f9c2
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/44/136144/2 && git format-patch -1 --stdout FETCH_HEAD,['hot/software-config/elements/heat-config-docker/install.d/hook-docker.py'],1,bb0337eaea448bc56ed416011b041fd12d3f54a6,heat-config-kubelet,"import cStringIOdef remove_all_containers_for_pod(client, log, pod_name): log.debug('Removing all containers from %s' % pod_name) log.debug('Removing container %s' % x['Id']) log.debug('Inspecting image %s' % image) log.debug('Pulling image %s' % image)def get_client(log): log.debug('Connecting to %s' % DOCKER_BASE_URL) log.debug('Connected to version %s' % client._version)def mount_external_volumes(log, volumes): log.debug('Creating mount path %s' % vol_path)def configure_logging(): formatter = logging.Formatter( '[%(asctime)s] (%(name)s) [%(levelname)s] %(message)s') # debug log to stderr handler = logging.StreamHandler(sys.stderr) handler.setFormatter(formatter) log.addHandler(handler) deploy_stdout = cStringIO.StringIO() handler = logging.StreamHandler(deploy_stdout) handler.setFormatter(formatter) handler.setLevel('DEBUG') log.addHandler(handler) deploy_stderr = cStringIO.StringIO() handler = logging.StreamHandler(deploy_stderr) handler.setFormatter(formatter) handler.setLevel('DEBUG') return log, deploy_stdout, deploy_stderr def main(argv=sys.argv): (log, deploy_stdout, deploy_stderr) = configure_logging() client = get_client(log) remove_all_containers_for_pod(client, log, pod_name) 'deploy_stdout': deploy_stdout.getvalue(), 'deploy_stderr': deploy_stderr.getvalue(), mount_external_volumes(log, volumes) log.debug('Making volume bindings') log.debug('Creating container with image %s' % image) log.debug('Building volume mounts') log.debug('Started container %s.' % container_id) container_info = get_container_info(client, container_id) remove_all_containers_for_pod(client, log, pod_name) 'deploy_stdout': deploy_stdout.getvalue(), 'deploy_stderr': deploy_stderr.getvalue(),","def remove_all_containers_for_pod(client, pod_name):def get_client():def mount_external_volumes(volumes):def main(argv=sys.argv): handler = logging.StreamHandler(sys.stderr) handler.setFormatter( logging.Formatter( '[%(asctime)s] (%(name)s) [%(levelname)s] %(message)s')) log.addHandler(handler) client = get_client() log.debug('Received Config %s' % config) remove_all_containers_for_pod(client, pod_name) 'deploy_stdout': stdout, 'deploy_stderr': stderr, mount_external_volumes(volumes) log.debug('Pulling docker image %s.' % image) log.debug('Making volume bindings.') log.debug('Building volume mounts.') log.debug('Started Container %s.' % container_id) stdout[container_id] = get_container_info(client, container_id) if container_id: stderr[container_id] = ex else: stderr[image] = ex remove_all_containers_for_pod(client, pod_name) 'deploy_stdout': stdout, 'deploy_stderr': stderr,",49,27
openstack%2Fdevstack~stable%2Ficehouse~I229e2d5f07070a9236ec612d4032c94c4361a9f6,openstack/devstack,stable/icehouse,I229e2d5f07070a9236ec612d4032c94c4361a9f6,XenAPI: workaround for unsupp. associative arrays,MERGED,2014-12-17 19:12:32.000000000,2015-01-08 03:00:45.000000000,2015-01-08 03:00:44.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5044}, {'_account_id': 7118}]","[{'number': 1, 'created': '2014-12-17 19:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/961defa22f8cd570c96be2827ad0917436c3b808', 'message': ""XenAPI: workaround for unsupp. associative arrays\n\nDom0's bash does not support associative arrays, however we source\n`functions` and therefore our scripts fail. This change breaks the\ndependency of dom0 tools on domU functions.\n\nFixes bug: 1379804\n\nChange-Id: I229e2d5f07070a9236ec612d4032c94c4361a9f6\n""}, {'number': 2, 'created': '2014-12-17 19:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ba9c34964e92f6c04d1b094c0d9456a7493fd4d6', 'message': ""DNM: XenAPI: workaround for unsupp. associative arrays\n\nDom0's bash does not support associative arrays, however we source\n`functions` and therefore our scripts fail. This change breaks the\ndependency of dom0 tools on domU functions.\n\nBackport is work in progress - do not merge.\n\nFixes bug: 1379804\n\nChange-Id: I229e2d5f07070a9236ec612d4032c94c4361a9f6\n""}, {'number': 3, 'created': '2014-12-21 21:36:17.000000000', 'files': ['tools/xen/install_os_domU.sh', 'tools/xen/xenrc', 'tools/xen/prepare_guest_template.sh', 'tools/xen/build_xva.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fa145efdc7e559b9353525b9b4ff5085aafaddb8', 'message': ""XenAPI: workaround for unsupp. associative arrays\n\nDom0's bash does not support associative arrays, however we source\n`functions` and therefore our scripts fail. This change breaks the\ndependency of dom0 tools on domU functions.\n\nThe associative arrays change was backported to Icehouse, breaking\nXenAPI.  This fixes that breakage\n\nFixes bug: 1379804\n\nChange-Id: I229e2d5f07070a9236ec612d4032c94c4361a9f6\n""}]",0,142543,fa145efdc7e559b9353525b9b4ff5085aafaddb8,11,4,3,6735,,,0,"XenAPI: workaround for unsupp. associative arrays

Dom0's bash does not support associative arrays, however we source
`functions` and therefore our scripts fail. This change breaks the
dependency of dom0 tools on domU functions.

The associative arrays change was backported to Icehouse, breaking
XenAPI.  This fixes that breakage

Fixes bug: 1379804

Change-Id: I229e2d5f07070a9236ec612d4032c94c4361a9f6
",git fetch https://review.opendev.org/openstack/devstack refs/changes/43/142543/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/xen/install_os_domU.sh', 'tools/xen/xenrc', 'tools/xen/prepare_guest_template.sh', 'tools/xen/build_xva.sh']",4,961defa22f8cd570c96be2827ad0917436c3b808,icehouse,,# Source lower level functions . $TOP_DIR/../../functions # Determine what system we are running on. # Might not be XenServer if we're using xenserver-core GetDistro ,19,23
openstack%2Fkeystone~master~Ib4e077398467e9cafb450f2171c3e8d1024ca4e2,openstack/keystone,master,Ib4e077398467e9cafb450f2171c3e8d1024ca4e2,Remove requirements not needed by oslo-incubator modules anymore,MERGED,2014-11-25 01:33:32.000000000,2015-01-08 03:00:35.000000000,2015-01-08 03:00:34.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 9142}]","[{'number': 1, 'created': '2014-11-25 01:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5edfcebffdfd724eab5046d8bae2c36567ee6477', 'message': ""Remove requirements not needed by oslo-incubator modules anymore\n\nSince a lot of code was removed from oslo-incubator, some packages\ndon't have to be listed in test-requirements anymore.\n\nChange-Id: Ib4e077398467e9cafb450f2171c3e8d1024ca4e2\n""}, {'number': 2, 'created': '2015-01-07 19:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/65b156d693335860fabe2de708dff66fed6c8734', 'message': ""Remove requirements not needed by oslo-incubator modules anymore\n\nSince a lot of code was removed from oslo-incubator, some packages\ndon't have to be listed in test-requirements anymore.\n\nPartial-Bug: #1408423\n\nChange-Id: Ib4e077398467e9cafb450f2171c3e8d1024ca4e2\n""}, {'number': 3, 'created': '2015-01-07 20:28:44.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'requirements-py3.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/511dd9c78df4008cd78c48372c262d50e279c00c', 'message': ""Remove requirements not needed by oslo-incubator modules anymore\n\nSince a lot of code was removed from oslo-incubator, some packages\ndon't have to be listed in test-requirements anymore.\n\nPartial-Bug: #1408423\nChange-Id: Ib4e077398467e9cafb450f2171c3e8d1024ca4e2\n""}]",0,136941,511dd9c78df4008cd78c48372c262d50e279c00c,19,6,3,6486,,,0,"Remove requirements not needed by oslo-incubator modules anymore

Since a lot of code was removed from oslo-incubator, some packages
don't have to be listed in test-requirements anymore.

Partial-Bug: #1408423
Change-Id: Ib4e077398467e9cafb450f2171c3e8d1024ca4e2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/41/136941/3 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'test-requirements-py3.txt']",2,5edfcebffdfd724eab5046d8bae2c36567ee6477,bug/1408423,,# Used only by oslo kombu>=2.5.0 lockfile>=0.8,0,6
openstack%2Fdevstack~master~I86e02ea5a5eace92397bc18e08c494c6fd009880,openstack/devstack,master,I86e02ea5a5eace92397bc18e08c494c6fd009880,Actually run all the Cinder cert tests.,MERGED,2014-12-19 09:35:05.000000000,2015-01-08 03:00:30.000000000,2015-01-08 03:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 10385}, {'_account_id': 11444}, {'_account_id': 12988}]","[{'number': 1, 'created': '2014-12-19 09:35:05.000000000', 'files': ['driver_certs/cinder_driver_cert.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5107556a7985b35a22904c57fd4a6f851cef0024', 'message': 'Actually run all the Cinder cert tests.\n\nChange the tests to run on the tox invocation line, too, not just in\nthe message logged.\n\nChange-Id: I86e02ea5a5eace92397bc18e08c494c6fd009880\n'}]",0,143022,5107556a7985b35a22904c57fd4a6f851cef0024,12,9,1,12988,,,0,"Actually run all the Cinder cert tests.

Change the tests to run on the tox invocation line, too, not just in
the message logged.

Change-Id: I86e02ea5a5eace92397bc18e08c494c6fd009880
",git fetch https://review.opendev.org/openstack/devstack refs/changes/22/143022/1 && git format-patch -1 --stdout FETCH_HEAD,['driver_certs/cinder_driver_cert.sh'],1,5107556a7985b35a22904c57fd4a6f851cef0024,update_cinder_cert_to_include_all_volume_tests,./tools/pretty_tox.sh volume 2>&1 | tee -a $TEMPFILE,./tools/pretty_tox.sh api.volume 2>&1 | tee -a $TEMPFILE,1,1
openstack%2Fdevstack~master~Ic6b1f70ec2d2c06002eb6877a747b7b84213c710,openstack/devstack,master,Ic6b1f70ec2d2c06002eb6877a747b7b84213c710,Adding installation Heat package after cloning,MERGED,2014-12-16 09:36:46.000000000,2015-01-08 03:00:23.000000000,2015-01-08 03:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 8074}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 09:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/76999f69453b8b60eb752f4dc516ef8b5c02ed2c', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 2, 'created': '2014-12-18 19:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6940007462b9189cc44f08fd2ed6694b60dbe37f', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 3, 'created': '2014-12-19 07:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6535b55cc715809c4bdef2a5249970f61b08d738', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 4, 'created': '2014-12-22 08:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c4687ce7182627901c61d9bff0f022692c5b1cf5', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 5, 'created': '2014-12-22 08:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c021c2e7228a48d91c81f5f85337800a8045eb9c', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 6, 'created': '2014-12-24 08:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e835188eb341ad2c8f396b39eb8f932fd8ce2129', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 7, 'created': '2014-12-29 08:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2ca7c54689140b80b16335efcc227c6e2f1bbf23', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}, {'number': 8, 'created': '2014-12-30 09:25:09.000000000', 'files': ['lib/heat'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a38bc5b3c2b97230896948073401153b0c3d157f', 'message': 'Adding installation Heat package after cloning\n\nThere are two important reasons for this change:\n - Other OpenStack components contain this code already.\n - Heat store references on client/constraint/version plugins in\n   setup.cfg and and stevedore uses these references, so we should\n   install Heat after changing this part of code. As example look patch\n   https://review.openstack.org/#/c/86978/ for grenade job, where\n   heat-engine can not find two constrainsts due to changing their code\n   place between releases.\n\nChange-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710\nCloses-Bug: #1402985\n'}]",0,142045,a38bc5b3c2b97230896948073401153b0c3d157f,55,10,8,6577,,,0,"Adding installation Heat package after cloning

There are two important reasons for this change:
 - Other OpenStack components contain this code already.
 - Heat store references on client/constraint/version plugins in
   setup.cfg and and stevedore uses these references, so we should
   install Heat after changing this part of code. As example look patch
   https://review.openstack.org/#/c/86978/ for grenade job, where
   heat-engine can not find two constrainsts due to changing their code
   place between releases.

Change-Id: Ic6b1f70ec2d2c06002eb6877a747b7b84213c710
Closes-Bug: #1402985
",git fetch https://review.opendev.org/openstack/devstack refs/changes/45/142045/6 && git format-patch -1 --stdout FETCH_HEAD,['lib/heat'],1,76999f69453b8b60eb752f4dc516ef8b5c02ed2c,bug/1402985, setup_develop $HEAT_DIR,,1,0
openstack%2Fdevstack~master~Iec6bf74c9321082c35465d332aba7f5fa240cc1a,openstack/devstack,master,Iec6bf74c9321082c35465d332aba7f5fa240cc1a,Trove configure authtoken via conf file,MERGED,2014-12-23 01:09:00.000000000,2015-01-08 03:00:14.000000000,2015-01-08 03:00:13.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6486}, {'_account_id': 7118}, {'_account_id': 7191}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-23 01:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c684d2cfe7bff896b4198023a2ed620ebe0c06b5', 'message': 'Trove configure authtoken via conf file\n\nConfigure auth_token middleware in trove via the conf file rather than\nthe paste pipeline. This is the standard and expected mechanism.\n\nChange-Id: Iec6bf74c9321082c35465d332aba7f5fa240cc1a\n'}, {'number': 2, 'created': '2015-01-05 00:12:14.000000000', 'files': ['lib/trove'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2de47465bdc33e7cc7bd6626a91374eccbf014f1', 'message': 'Trove configure authtoken via conf file\n\nConfigure auth_token middleware in trove via the conf file rather than\nthe paste pipeline. This is the standard and expected mechanism.\n\nChange-Id: Iec6bf74c9321082c35465d332aba7f5fa240cc1a\n'}]",0,143579,2de47465bdc33e7cc7bd6626a91374eccbf014f1,17,6,2,7191,,,0,"Trove configure authtoken via conf file

Configure auth_token middleware in trove via the conf file rather than
the paste pipeline. This is the standard and expected mechanism.

Change-Id: Iec6bf74c9321082c35465d332aba7f5fa240cc1a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/79/143579/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/trove'],1,c684d2cfe7bff896b4198023a2ed620ebe0c06b5,trove-authtoken, configure_auth_token_middleware $TOVE_CONF_DIR/trove.conf trove $TROVE_AUTH_CACHE_DIR , configure_auth_token_middleware $TROVE_API_PASTE_INI trove $TROVE_AUTH_CACHE_DIR filter:authtoken ,2,2
openstack%2Ffuel-docs~stable%2F6.0~I06899c7c7546e993f26a01fc4533986c479fca94,openstack/fuel-docs,stable/6.0,I06899c7c7546e993f26a01fc4533986c479fca94,Fix pacemaker settings documentation,MERGED,2015-01-08 02:28:51.000000000,2015-01-08 02:31:23.000000000,2015-01-08 02:31:23.000000000,"[{'_account_id': 3}, {'_account_id': 7604}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-01-08 02:28:51.000000000', 'files': ['pages/reference-architecture/ha-notes/0120-pacemaker-settings.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/475f8b74cdd03b1f5946e569b6c6c2403d05aad3', 'message': 'Fix pacemaker settings documentation\n\nNeutron L3 agents are cloned over controller nodes, so\npacemaker settings description should be changed\n\nChange-Id: I06899c7c7546e993f26a01fc4533986c479fca94\n(cherry picked from commit 4e7c97c76113ba38411cc3bf201fce8a8c0cd903)\n'}]",0,145664,475f8b74cdd03b1f5946e569b6c6c2403d05aad3,7,4,1,8787,,,0,"Fix pacemaker settings documentation

Neutron L3 agents are cloned over controller nodes, so
pacemaker settings description should be changed

Change-Id: I06899c7c7546e993f26a01fc4533986c479fca94
(cherry picked from commit 4e7c97c76113ba38411cc3bf201fce8a8c0cd903)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/64/145664/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/reference-architecture/ha-notes/0120-pacemaker-settings.rst'],1,475f8b74cdd03b1f5946e569b6c6c2403d05aad3,,"Open vSwitch, metadata and L3 agents are started as Pacemaker clones on all the nodes, then a single instance of the dhcp agent is started.","Then Open vSwitch and metadata agents are cloned on all the nodes. Then dhcp and L3 agents are started and tied together by use of Pacemaker constraints called ""colocation"".",2,3
openstack%2Ffuel-docs~master~I06899c7c7546e993f26a01fc4533986c479fca94,openstack/fuel-docs,master,I06899c7c7546e993f26a01fc4533986c479fca94,Fix pacemaker settings documentation,MERGED,2014-12-25 12:01:18.000000000,2015-01-08 02:28:51.000000000,2015-01-08 02:28:41.000000000,"[{'_account_id': 3}, {'_account_id': 7604}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-25 12:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/fb12ea3cf8adec64441aa73f2e1659a27c75428d', 'message': 'Fix pacemaker settings documentation\n\nNeutron L3 agents are cloned over controller nodes, so\npacemaker settings description should be changed\n\nChange-Id: I06899c7c7546e993f26a01fc4533986c479fca94\n'}, {'number': 2, 'created': '2015-01-04 10:40:13.000000000', 'files': ['pages/reference-architecture/ha-notes/0120-pacemaker-settings.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4e7c97c76113ba38411cc3bf201fce8a8c0cd903', 'message': 'Fix pacemaker settings documentation\n\nNeutron L3 agents are cloned over controller nodes, so\npacemaker settings description should be changed\n\nChange-Id: I06899c7c7546e993f26a01fc4533986c479fca94\n'}]",2,143965,4e7c97c76113ba38411cc3bf201fce8a8c0cd903,17,6,2,7604,,,0,"Fix pacemaker settings documentation

Neutron L3 agents are cloned over controller nodes, so
pacemaker settings description should be changed

Change-Id: I06899c7c7546e993f26a01fc4533986c479fca94
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/65/143965/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/reference-architecture/ha-notes/0120-pacemaker-settings.rst'],1,fb12ea3cf8adec64441aa73f2e1659a27c75428d,master,"Then Open vSwitch, metadata and L3 agents are cloned on all the nodes. Then dhcp agents is started.","Then Open vSwitch and metadata agents are cloned on all the nodes. Then dhcp and L3 agents are started and tied together by use of Pacemaker constraints called ""colocation"".",2,3
openstack%2Ffuel-docs~stable%2F6.0~Iaa435e3b2bde4156c023c86b8cacc9b466080400,openstack/fuel-docs,stable/6.0,Iaa435e3b2bde4156c023c86b8cacc9b466080400,RN-6.0 - Fix PDF build issue,MERGED,2015-01-08 02:23:24.000000000,2015-01-08 02:27:43.000000000,2015-01-08 02:27:43.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2015-01-08 02:23:24.000000000', 'files': ['pages/release-notes/v6-0/9010-vmware-tech.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4a44b408e63171457c3214da6941ead386ae0ca3', 'message': 'RN-6.0 - Fix PDF build issue\n\nChange-Id: Iaa435e3b2bde4156c023c86b8cacc9b466080400\n(cherry picked from commit 03dfc8ce1af51a674c281d97522a49a4e9c9dcab)\n'}]",0,145659,4a44b408e63171457c3214da6941ead386ae0ca3,7,4,1,8787,,,0,"RN-6.0 - Fix PDF build issue

Change-Id: Iaa435e3b2bde4156c023c86b8cacc9b466080400
(cherry picked from commit 03dfc8ce1af51a674c281d97522a49a4e9c9dcab)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/59/145659/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/9010-vmware-tech.rst'],1,4a44b408e63171457c3214da6941ead386ae0ca3,,.. include:: /pages/release-notes/v6-0/vmware/9020-nsx.rst,.. include:: pages/release-notes/v6-0/vmware/9020-nsx.rst,1,1
openstack%2Frequirements~master~I590a5049e0b4b6cbe0bfcdff472bbef5d7505bdb,openstack/requirements,master,I590a5049e0b4b6cbe0bfcdff472bbef5d7505bdb,global-requirements: Update oslo.db to 1.3.0,MERGED,2015-01-07 12:49:06.000000000,2015-01-08 02:25:15.000000000,2015-01-08 02:25:14.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 8655}, {'_account_id': 9317}]","[{'number': 1, 'created': '2015-01-07 12:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/801ac5251a2474147ef20e0b43f4f465793f6c84', 'message': ""global-requirements: Update oslo.db to 1.1.3\n\nWith current Neutron master (commit: 98c53d5), and oslo.db 1.1.0,\nDevStack setup fails with:\n\n[. . .]\ncontext(dependent_req)\\npkg_resources.ContextualVersionConflict: (SQLAlchemy 0.9.8 (/usr/lib64/python2.7/site-packages), Requirement.parse(\\'SQLAlchem\ny<=0.8.99,<=0.9.99,>=0.8.4,>=0.9.7\\'), set([\\'oslo.db\\']))\\n'\n2015-01-07 06:48:11.110 CRITICAL neutron [-] RuntimeError:\nCommand: ['sudo', '/usr/bin/neutron-rootwrap', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=10', '--', 'set-fail-mode', 'br-int', 'secure']\nExit code: 1\nStdout: ''\n[. . .]\n\nA manual 'pip uninstall oslo.db && pip install oslo.db' fetches 1.1.3,\nfixing this issue.\n\nSo, update oslo.db version to 1.1.3 in global-requirements.txt.\n\nChange-Id: I590a5049e0b4b6cbe0bfcdff472bbef5d7505bdb\n""}, {'number': 2, 'created': '2015-01-07 13:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d9625a67aeefce8657b4bf53ae992e4ddcc0f590', 'message': ""global-requirements: Update oslo.db to 1.1.3\n\noslo.db 1.1.0 doesn't fulfil requirements for SQLAlchemy -- with current\nNeutron git master (commit: 98c53d5), and oslo.db 1.1.0, DevStack\ninvocation fails with version conflicts. Updating oslo.db to 1.1.3 fixes\nit.\n\nSo, update oslo.db version to 1.1.3 in global-requirements.txt.\n\nChange-Id: I590a5049e0b4b6cbe0bfcdff472bbef5d7505bdb\n""}, {'number': 3, 'created': '2015-01-07 14:00:50.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/dbd1c74770570128192d10c2a1d58ed5b93d5cda', 'message': ""global-requirements: Update oslo.db to 1.3.0\n\noslo.db 1.1.0 doesn't fulfil requirements for SQLAlchemy -- with current\nNeutron git master (commit: 98c53d5) and oslo.db 1.1.0, DevStack\ninvocation fails with version conflicts. Updating oslo.db to 1.3.0 fixes\nit.\n\nSo, update oslo.db version to 1.3.0 in global-requirements.txt.\n\nChange-Id: I590a5049e0b4b6cbe0bfcdff472bbef5d7505bdb\n""}]",0,145489,dbd1c74770570128192d10c2a1d58ed5b93d5cda,14,5,3,6962,,,0,"global-requirements: Update oslo.db to 1.3.0

oslo.db 1.1.0 doesn't fulfil requirements for SQLAlchemy -- with current
Neutron git master (commit: 98c53d5) and oslo.db 1.1.0, DevStack
invocation fails with version conflicts. Updating oslo.db to 1.3.0 fixes
it.

So, update oslo.db version to 1.3.0 in global-requirements.txt.

Change-Id: I590a5049e0b4b6cbe0bfcdff472bbef5d7505bdb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/89/145489/3 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,801ac5251a2474147ef20e0b43f4f465793f6c84,,oslo.db>=1.3.0 # Apache-2.0,oslo.db>=1.1.0 # Apache-2.0,1,1
openstack%2Fdevstack~master~I47e158abce9d090eb839c6e97d9191dc99ccfe55,openstack/devstack,master,I47e158abce9d090eb839c6e97d9191dc99ccfe55,"uuidgen binary is needed by lib/{neutron,ceph}",MERGED,2014-12-20 16:11:07.000000000,2015-01-08 02:25:07.000000000,2015-01-08 02:25:06.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6984}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-12-20 16:11:07.000000000', 'files': ['files/debs/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/95d1a43f1feef36ee50b0f53a6da258a4a646244', 'message': 'uuidgen binary is needed by lib/{neutron,ceph}\n\nWhen using unstack.sh script on Debian Wheezy, i saw a failing call on\nuuidgen binary:\n\n    $ ./unstack.sh\n    /home/stack/devstack/lib/neutron: line 83: uuidgen: command not found\n    Site keystone disabled.\n    [...]\n\nChange-Id: I47e158abce9d090eb839c6e97d9191dc99ccfe55\n'}]",0,143275,95d1a43f1feef36ee50b0f53a6da258a4a646244,10,6,1,14404,,,0,"uuidgen binary is needed by lib/{neutron,ceph}

When using unstack.sh script on Debian Wheezy, i saw a failing call on
uuidgen binary:

    $ ./unstack.sh
    /home/stack/devstack/lib/neutron: line 83: uuidgen: command not found
    Site keystone disabled.
    [...]

Change-Id: I47e158abce9d090eb839c6e97d9191dc99ccfe55
",git fetch https://review.opendev.org/openstack/devstack refs/changes/75/143275/1 && git format-patch -1 --stdout FETCH_HEAD,['files/debs/neutron'],1,95d1a43f1feef36ee50b0f53a6da258a4a646244,,uuid-runtime,,1,0
openstack%2Fdevstack~stable%2Ficehouse~I8655a955ebb322516d92bee418b93d4cc23bdc5c,openstack/devstack,stable/icehouse,I8655a955ebb322516d92bee418b93d4cc23bdc5c,Do not modify rsyslog files if rsyslog is not used.,MERGED,2015-01-07 07:06:18.000000000,2015-01-08 02:24:59.000000000,2015-01-08 02:24:57.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4220}, {'_account_id': 5803}, {'_account_id': 7118}, {'_account_id': 8674}]","[{'number': 1, 'created': '2015-01-07 07:06:18.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/afd4ba425d4aa544dd6732955456c3f4ed6190db', 'message': 'Do not modify rsyslog files if rsyslog is not used.\n\nSwift was missing an \'if [[ $SYSLOG != ""False"" ]]\' statement which is used\nby other services, and therefor failed with a \'No such file or directory\'\nerror when \'SYSLOG=False\' was set in localrc.\n\nCloses-Bug: 1308461\n\nChange-Id: I8655a955ebb322516d92bee418b93d4cc23bdc5c\n(cherry picked from commit f894c2ab805f9dfc0dfdd3668ccd3a83ee4eb9f2)\n'}]",0,145420,afd4ba425d4aa544dd6732955456c3f4ed6190db,9,6,1,5803,,,0,"Do not modify rsyslog files if rsyslog is not used.

Swift was missing an 'if [[ $SYSLOG != ""False"" ]]' statement which is used
by other services, and therefor failed with a 'No such file or directory'
error when 'SYSLOG=False' was set in localrc.

Closes-Bug: 1308461

Change-Id: I8655a955ebb322516d92bee418b93d4cc23bdc5c
(cherry picked from commit f894c2ab805f9dfc0dfdd3668ccd3a83ee4eb9f2)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/20/145420/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,afd4ba425d4aa544dd6732955456c3f4ed6190db,," if [[ $SYSLOG != ""False"" ]]; then sed ""s,%SWIFT_LOGDIR%,${swift_log_dir},"" $FILES/swift/rsyslog.conf | sudo \ tee /etc/rsyslog.d/10-swift.conf # restart syslog to take the changes sudo killall -HUP rsyslogd fi"," sed ""s,%SWIFT_LOGDIR%,${swift_log_dir},"" $FILES/swift/rsyslog.conf | sudo \ tee /etc/rsyslog.d/10-swift.conf # restart syslog to take the changes sudo killall -HUP rsyslogd",7,4
openstack%2Fglance~master~I3c8e08f71022e8771fc184f9049c25dde4a6ed69,openstack/glance,master,I3c8e08f71022e8771fc184f9049c25dde4a6ed69,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:41:18.000000000,2015-01-08 02:24:49.000000000,2015-01-08 02:24:48.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6484}, {'_account_id': 7665}, {'_account_id': 8158}, {'_account_id': 8959}, {'_account_id': 9096}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-12-05 03:41:18.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/050bc0c45e7d27f4d2461f9ad992e4f8e29871f7', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I3c8e08f71022e8771fc184f9049c25dde4a6ed69\n'}]",0,139322,050bc0c45e7d27f4d2461f9ad992e4f8e29871f7,14,10,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I3c8e08f71022e8771fc184f9049c25dde4a6ed69
",git fetch https://review.opendev.org/openstack/glance refs/changes/22/139322/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,050bc0c45e7d27f4d2461f9ad992e4f8e29871f7,infra-manual, http://docs.openstack.org/infra/manual/developers.html#development-workflow http://docs.openstack.org/infra/manual/developers.html#development-workflow, http://wiki.openstack.org/HowToContribute#If_you.27re_a_developer http://wiki.openstack.org/GerritWorkflow,2,2
openstack%2Fkeystone~master~I30e9a0fecb1c6af67e9704b777e5822797d1b7f5,openstack/keystone,master,I30e9a0fecb1c6af67e9704b777e5822797d1b7f5,let endpoint_filter sql backend return dict data,MERGED,2014-12-26 06:31:29.000000000,2015-01-08 02:24:03.000000000,2015-01-08 02:24:02.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 9101}, {'_account_id': 11022}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-12-26 06:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0d7796908f3c3eb5db3ec54952c647a87e61ec82', 'message': 'let endpoint_filter sql backend return dict data\n\nManager or controller should adapt different backends. This requires\nall backends return the same data structure(keystone uses dict). But,\ncurrently, some list methods in contrib/endpoint_filter/backends/sql.py\nreturn db object.\n\nChange-Id: I30e9a0fecb1c6af67e9704b777e5822797d1b7f5\nCloses-Bug: #1405710\n'}, {'number': 2, 'created': '2014-12-27 03:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/34cd7b800e9e2881ab208bf2758969befee76683', 'message': 'let endpoint_filter sql backend return dict data\n\nManager or controller should adapt different backends. This requires\nall backends return the same data structure(keystone uses dict). But,\ncurrently, some list methods in contrib/endpoint_filter/backends/sql.py\nreturn db object.\n\nChange-Id: I30e9a0fecb1c6af67e9704b777e5822797d1b7f5\nCloses-Bug: #1405710\n'}, {'number': 3, 'created': '2015-01-05 04:54:01.000000000', 'files': ['keystone/contrib/endpoint_filter/backends/sql.py', 'keystone/contrib/endpoint_filter/controllers.py', 'keystone/contrib/endpoint_filter/backends/catalog_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1faf9f15c96997de89550ce60de3ce8b4e7851d2', 'message': 'let endpoint_filter sql backend return dict data\n\nManager or controller should adapt different backends. This requires\nall backends return the same data structure(keystone uses dict). But,\ncurrently, some list methods in contrib/endpoint_filter/backends/sql.py\nreturn db object.\n\nChange-Id: I30e9a0fecb1c6af67e9704b777e5822797d1b7f5\nCloses-Bug: #1405710\n'}]",1,144084,1faf9f15c96997de89550ce60de3ce8b4e7851d2,19,6,3,9101,,,0,"let endpoint_filter sql backend return dict data

Manager or controller should adapt different backends. This requires
all backends return the same data structure(keystone uses dict). But,
currently, some list methods in contrib/endpoint_filter/backends/sql.py
return db object.

Change-Id: I30e9a0fecb1c6af67e9704b777e5822797d1b7f5
Closes-Bug: #1405710
",git fetch https://review.opendev.org/openstack/keystone refs/changes/84/144084/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/contrib/endpoint_filter/backends/sql.py', 'keystone/contrib/endpoint_filter/backends/catalog_sql.py', 'keystone/contrib/endpoint_filter/controllers.py']",3,0d7796908f3c3eb5db3ec54952c647a87e61ec82,bug/1405574," ref['endpoint_group_id']) for ref in refs] (ref['endpoint_id'], self.catalog_api.get_endpoint( ref['endpoint_id'])) for ref in refs) ref['project_id']) for ref in refs] endpoint_group_ref['project_id'])"," ref.endpoint_group_id) for ref in refs] (ref.endpoint_id, self.catalog_api.get_endpoint( ref.endpoint_id)) for ref in refs) ref.project_id) for ref in refs] endpoint_group_ref.project_id)",12,13
openstack%2Ftrove-integration~master~If98ec4ee8816f715c3b3146aba0ada989b841674,openstack/trove-integration,master,If98ec4ee8816f715c3b3146aba0ada989b841674,Install additional oslo modules in guest image,MERGED,2015-01-07 17:46:04.000000000,2015-01-08 02:23:54.000000000,2015-01-08 02:23:54.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 8214}, {'_account_id': 9664}, {'_account_id': 10215}]","[{'number': 1, 'created': '2015-01-07 17:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/7acddcdebbd596ffbf97530fa00d37710deb5fc7', 'message': 'Install additional oslo modules in guest image\n\nThe change (https://review.openstack.org/#/c/141081/) moves trove from\nusing processutils.py (oslo-incubator) to oslo.concurrency. This must\nbe reflected in the guest image.\n\nChange-Id: If98ec4ee8816f715c3b3146aba0ada989b841674\nPartial-Bug: #1380789\n'}, {'number': 2, 'created': '2015-01-07 17:48:48.000000000', 'files': ['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/209ffd30a021a541aa7aeb0643ac667e2181975d', 'message': 'Install additional oslo modules in guest image\n\nThe change (https://review.openstack.org/#/c/141081/) moves trove from\nusing processutils.py (oslo-incubator) to oslo.concurrency. This must\nbe reflected in the guest image.\n\nChange 141081 depends on this change.\n\nChange-Id: If98ec4ee8816f715c3b3146aba0ada989b841674\nPartial-Bug: #1380789\n'}]",0,145546,209ffd30a021a541aa7aeb0643ac667e2181975d,12,6,2,9664,,,0,"Install additional oslo modules in guest image

The change (https://review.openstack.org/#/c/141081/) moves trove from
using processutils.py (oslo-incubator) to oslo.concurrency. This must
be reflected in the guest image.

Change 141081 depends on this change.

Change-Id: If98ec4ee8816f715c3b3146aba0ada989b841674
Partial-Bug: #1380789
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/46/145546/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep']",2,7acddcdebbd596ffbf97530fa00d37710deb5fc7,bugs/bug-1380789, osprofiler>=0.3.0 oslo.concurrency>=0.3.0, osprofiler>=0.3.0,2,2
openstack%2Ffuel-docs~master~Iaa435e3b2bde4156c023c86b8cacc9b466080400,openstack/fuel-docs,master,Iaa435e3b2bde4156c023c86b8cacc9b466080400,RN-6.0 - Fix PDF build issue,MERGED,2015-01-03 16:48:25.000000000,2015-01-08 02:23:24.000000000,2015-01-08 02:23:15.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-01-03 16:48:25.000000000', 'files': ['pages/release-notes/v6-0/9010-vmware-tech.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/03dfc8ce1af51a674c281d97522a49a4e9c9dcab', 'message': 'RN-6.0 - Fix PDF build issue\n\nChange-Id: Iaa435e3b2bde4156c023c86b8cacc9b466080400\n'}]",0,144840,03dfc8ce1af51a674c281d97522a49a4e9c9dcab,10,5,1,10014,,,0,"RN-6.0 - Fix PDF build issue

Change-Id: Iaa435e3b2bde4156c023c86b8cacc9b466080400
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/40/144840/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/9010-vmware-tech.rst'],1,03dfc8ce1af51a674c281d97522a49a4e9c9dcab,rn-nsx-build,.. include:: /pages/release-notes/v6-0/vmware/9020-nsx.rst,.. include:: pages/release-notes/v6-0/vmware/9020-nsx.rst,1,1
openstack%2Fglance~master~I49d3ad246e4f3b6f814545f01c1039158dbb902d,openstack/glance,master,I49d3ad246e4f3b6f814545f01c1039158dbb902d,Imported Translations from Transifex,MERGED,2014-12-19 06:05:47.000000000,2015-01-08 02:11:32.000000000,2015-01-08 02:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-12-19 06:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/83d8df051c9dca2fcac2ff35ed8d71a420c781d0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 2, 'created': '2014-12-20 06:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f62aa98279af1b7bce7467174154ddd6c729025f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 3, 'created': '2014-12-21 06:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8190d0e3964ace7b9ec29475252ce064b80fe44b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 4, 'created': '2014-12-22 06:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c461c681c5405f0336e5500e1b54bb4d8505a53d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 5, 'created': '2014-12-23 06:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7d9fbc3669d8d6a9172f720bc64790c6800b1abd', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 6, 'created': '2014-12-24 06:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7f96205f243ebfe7571b62a71c6e2e44e96987ec', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 7, 'created': '2014-12-25 06:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/20df3d22e3b7567b8e40df9ddb92347fe51478ab', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 8, 'created': '2014-12-26 06:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b1bdd5d8872b98a32b6a75f830142eecd6fae6a6', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 9, 'created': '2014-12-27 06:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9e296d348a2df62bd2f20d50223ac037073be8c7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 10, 'created': '2014-12-28 06:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4b319b669d0e0620973a273c6713932cf43c6e1e', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 11, 'created': '2014-12-29 06:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e24a92d8fa96274e2a016ab6d00934681300eca0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 12, 'created': '2014-12-30 06:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e607bde1a7bb06af03bc7a402c401a0893df1793', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 13, 'created': '2014-12-31 06:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b9a66ef0be5627291a15b60dfa9eb6e661a719f0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 14, 'created': '2015-01-01 06:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b8dd16bb4d1d95327552b69763d4b9d97702fba7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 15, 'created': '2015-01-02 06:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/10d6e995cf8b945e84e918eba6f4e12e7c35b8ee', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 16, 'created': '2015-01-03 06:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dc4ad94740f88b75921e8a401df4fe3e3ee662b9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 17, 'created': '2015-01-04 06:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/57950cbe58569d3c6d29ac4149fbd265e410e55d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 18, 'created': '2015-01-05 06:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/29a60ceeedb93838abcee59eea48ed2fd164ff11', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 19, 'created': '2015-01-06 06:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4400368e8b9fe3ead5c2400c745c1a44bfb40a18', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}, {'number': 20, 'created': '2015-01-07 06:03:41.000000000', 'files': ['glance/locale/en_US/LC_MESSAGES/glance.po', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-info.po', 'glance/locale/fr/LC_MESSAGES/glance-log-error.po', 'glance/locale/glance-log-error.pot', 'glance/locale/ko_KR/LC_MESSAGES/glance-log-error.po', 'glance/locale/glance-log-info.pot', 'glance/locale/en_GB/LC_MESSAGES/glance-log-warning.po', 'glance/locale/glance-log-warning.pot', 'glance/locale/glance.pot', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-warning.po', 'glance/locale/en_GB/LC_MESSAGES/glance-log-info.po'], 'web_link': 'https://opendev.org/openstack/glance/commit/5b371594bf1d1d8082221113cb640b1df9cc835e', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d\n'}]",0,142988,5b371594bf1d1d8082221113cb640b1df9cc835e,44,3,20,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I49d3ad246e4f3b6f814545f01c1039158dbb902d
",git fetch https://review.opendev.org/openstack/glance refs/changes/88/142988/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/locale/en_US/LC_MESSAGES/glance.po', 'glance/locale/fr/LC_MESSAGES/glance-log-error.po', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-info.po', 'glance/locale/glance-log-error.pot', 'glance/locale/ko_KR/LC_MESSAGES/glance-log-error.po', 'glance/locale/glance-log-info.pot', 'glance/locale/en_GB/LC_MESSAGES/glance-log-warning.po', 'glance/locale/glance-log-warning.pot', 'glance/locale/glance.pot', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-warning.po', 'glance/locale/en_GB/LC_MESSAGES/glance-log-info.po']",11,83d8df051c9dca2fcac2ff35ed8d71a420c781d0,transifex/translations,"""POT-Creation-Date: 2014-12-19 06:05+0000\n"" ""PO-Revision-Date: 2014-12-18 21:31+0000\n""#: glance/db/simple/api.py:55#: glance/db/simple/api.py:61#: glance/db/sqlalchemy/metadata.py:170#: glance/db/sqlalchemy/metadata.py:242#: glance/db/sqlalchemy/metadata.py:244#: glance/db/sqlalchemy/metadata.py:256#: glance/db/sqlalchemy/metadata.py:347","""POT-Creation-Date: 2014-12-18 06:06+0000\n"" ""PO-Revision-Date: 2014-12-10 14:35+0000\n""#: glance/db/simple/api.py:54#: glance/db/simple/api.py:60#: glance/db/sqlalchemy/metadata.py:157#: glance/db/sqlalchemy/metadata.py:219#: glance/db/sqlalchemy/metadata.py:221#: glance/db/sqlalchemy/metadata.py:232#: glance/db/sqlalchemy/metadata.py:312#: glance/openstack/common/lockutils.py:82 #, python-format msgid ""Created lock path: %s"" msgstr ""Created lock path: %s"" #: glance/openstack/common/lockutils.py:194 #, python-format msgid ""Failed to remove file %(file)s"" msgstr ""Failed to remove file %(file)s"" ",523,517
openstack%2Fswift~master~I32711fd10dfb1b84cbea9d05638b9ee002588104,openstack/swift,master,I32711fd10dfb1b84cbea9d05638b9ee002588104,Substituted object storage paragraph with simple definition,MERGED,2015-01-06 18:45:41.000000000,2015-01-08 02:11:01.000000000,2015-01-08 02:11:00.000000000,"[{'_account_id': 3}, {'_account_id': 860}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 9625}]","[{'number': 1, 'created': '2015-01-06 18:45:41.000000000', 'files': ['doc/source/api/object_api_v1_overview.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/5b99ba1c8a78fe8cc1c5ad2ca554289188881919', 'message': 'Substituted object storage paragraph with simple definition\n\nChange-Id: I32711fd10dfb1b84cbea9d05638b9ee002588104\nCloses-bug: #1373925\n'}]",0,145294,5b99ba1c8a78fe8cc1c5ad2ca554289188881919,9,5,1,14474,,,0,"Substituted object storage paragraph with simple definition

Change-Id: I32711fd10dfb1b84cbea9d05638b9ee002588104
Closes-bug: #1373925
",git fetch https://review.opendev.org/openstack/swift refs/changes/94/145294/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api/object_api_v1_overview.rst'],1,5b99ba1c8a78fe8cc1c5ad2ca554289188881919,bug/1373925,"OpenStack Object Storage is a highly available, distributed, eventually consistent object/blob store. You create, modify, and get objects and object metadata. ","OpenStack Object Storage is an object-based storage system that stores content and metadata as objects. You create, modify, and get objects and object metadata.",3,3
openstack%2Fnova~master~I0aed6e19446febd3350b15f63a2855604dd9d5c3,openstack/nova,master,I0aed6e19446febd3350b15f63a2855604dd9d5c3,Add obj_as_admin() to NovaPersistentObject,MERGED,2014-12-04 23:18:31.000000000,2015-01-08 02:07:56.000000000,2015-01-08 02:07:53.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-04 23:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19e3929c52fc1381518309594cfcbcb5799623f5', 'message': ""Add obj_as_admin() to NovaPersistentObject\n\nSince this is a nova-ism, I'm adding this to our subclass of NovaObject,\nwhich we use for almost everything, and at least everything that will care\nabout this. Later, we should probably generalize a layer between the base\nand NovaPersistentObject classes for things like this.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3\n""}, {'number': 2, 'created': '2014-12-05 00:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c0501b645d5e9c6a6f2b25e6cfca715759654de', 'message': ""Add obj_as_admin() to NovaPersistentObject\n\nSince this is a nova-ism, I'm adding this to our subclass of NovaObject,\nwhich we use for almost everything, and at least everything that will care\nabout this. Later, we should probably generalize a layer between the base\nand NovaPersistentObject classes for things like this.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3\n""}, {'number': 3, 'created': '2014-12-05 16:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7a32a084bee727b6549e3782b0ccc95e61e66cd', 'message': ""Add obj_as_admin() to NovaPersistentObject\n\nSince this is a nova-ism, I'm adding this to our subclass of NovaObject,\nwhich we use for almost everything, and at least everything that will care\nabout this. Later, we should probably generalize a layer between the base\nand NovaPersistentObject classes for things like this.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3\n""}, {'number': 4, 'created': '2014-12-09 06:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fedc1023a38b1d71d7c1571c56042c6ca86b820', 'message': ""Add obj_as_admin() to NovaPersistentObject\n\nSince this is a nova-ism, I'm adding this to our subclass of NovaObject,\nwhich we use for almost everything, and at least everything that will care\nabout this. Later, we should probably generalize a layer between the base\nand NovaPersistentObject classes for things like this.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3\n""}, {'number': 5, 'created': '2014-12-09 06:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2415b9f5e34231e1f73dca8e418a7f7ea3ef3f6', 'message': ""Add obj_as_admin() to NovaPersistentObject\n\nSince this is a nova-ism, I'm adding this to our subclass of NovaObject,\nwhich we use for almost everything, and at least everything that will care\nabout this. Later, we should probably generalize a layer between the base\nand NovaPersistentObject classes for things like this.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3\n""}, {'number': 6, 'created': '2014-12-10 18:58:02.000000000', 'files': ['nova/objects/base.py', 'nova/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/58b006de8dd4564fe4003eb6ce5e8fe552544131', 'message': ""Add obj_as_admin() to NovaPersistentObject\n\nSince this is a nova-ism, I'm adding this to our subclass of NovaObject,\nwhich we use for almost everything, and at least everything that will care\nabout this. Later, we should probably generalize a layer between the base\nand NovaPersistentObject classes for things like this.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3\n""}]",8,139261,58b006de8dd4564fe4003eb6ce5e8fe552544131,57,13,6,4393,,,0,"Add obj_as_admin() to NovaPersistentObject

Since this is a nova-ism, I'm adding this to our subclass of NovaObject,
which we use for almost everything, and at least everything that will care
about this. Later, we should probably generalize a layer between the base
and NovaPersistentObject classes for things like this.

Related to blueprint kilo-objects

Change-Id: I0aed6e19446febd3350b15f63a2855604dd9d5c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/139261/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/tests/unit/objects/test_objects.py']",2,19e3929c52fc1381518309594cfcbcb5799623f5,bp/kilo-objects," def test_obj_as_admin(self): obj = MyObj(context=self.context) def fake(*args, **kwargs): self.assertTrue(obj._context.is_admin) with mock.patch.object(obj, 'obj_reset_changes') as mock_fn: mock_fn.side_effect = fake with obj.obj_as_admin(): obj.save() self.assertTrue(mock_fn.called) self.assertFalse(obj._context.is_admin) ",,34,0
openstack%2Frequirements~master~Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e,openstack/requirements,master,Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e,Angular xstatic for Version 1.3.7,MERGED,2014-12-18 18:30:49.000000000,2015-01-08 02:07:41.000000000,2015-01-08 02:07:40.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1941}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6786}, {'_account_id': 7665}, {'_account_id': 8512}, {'_account_id': 8648}, {'_account_id': 9576}, {'_account_id': 9659}, {'_account_id': 10063}, {'_account_id': 11902}, {'_account_id': 12071}, {'_account_id': 13805}]","[{'number': 1, 'created': '2014-12-18 18:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/85dda4abd72761f8f136e6b11eb315160f0340dd', 'message': 'Angular xstatic for Version 1.3.7\n\nAdding version 1.3.7\n1.3.x angular is needed for Horizon launch instance work.\n\nThis is dependent on the following merging:\nhttps://review.openstack.org/#/c/142520/\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e\n'}, {'number': 2, 'created': '2015-01-05 17:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/50500dd727b9b869af5f389d2b1d2ba5a3918d0c', 'message': 'Angular xstatic for Version 1.3.7\n\nAdding version 1.3.7\n1.3.x angular is needed for Horizon launch instance work.\n\nThis is dependent on the following merging:\nhttps://review.openstack.org/#/c/142520/\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e\n'}, {'number': 3, 'created': '2015-01-05 22:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9aac569fcdc603e7486c9d6d053ba0ea7c47de4b', 'message': 'Angular xstatic for Version 1.3.7\n\nAdding version 1.3.7\n1.3.x angular is needed for Horizon launch instance work.\n\nThis was dependent on the following (done):\nhttps://review.openstack.org/#/c/142520/\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e\n'}, {'number': 4, 'created': '2015-01-06 00:14:24.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6493a66714f395a3a7816e5620dd30b23a8a3382', 'message': ""Angular xstatic for Version 1.3.7\n\nAdding version 1.3.7\n1.3.x angular is needed for Horizon launch instance work.\n\nThis was dependent on the following (done):\nhttps://review.openstack.org/#/c/142520/\n\nXstatic-Angular 1.3.7 includes the following packages:\n\nXStatic-Angular-Cookies\nXStatic-Angular-Mock\n\nThey can be removed, but this apparently needs to be done\nin a multi-step process. The interdependency chain,\n(horizon has dependency on the old packages) causes\nan integration test to fail. So, if we follow the normal\nprocess, then we have to do it in the following order.\n\n1) The newer pakage has to be added to global requirements\n2) a) The new dependency has to be added to Horizon\n   b) Old dependencies must be removed from Horizon\n3) The older packages must be removed from global requirements\n   - change 145096\n\nAt least this what I can tell how to make it all\nwork following processes since I can't modify the\nrequirements across projects in the same patch set.\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e\n""}]",2,142869,6493a66714f395a3a7816e5620dd30b23a8a3382,39,16,4,7665,,,0,"Angular xstatic for Version 1.3.7

Adding version 1.3.7
1.3.x angular is needed for Horizon launch instance work.

This was dependent on the following (done):
https://review.openstack.org/#/c/142520/

Xstatic-Angular 1.3.7 includes the following packages:

XStatic-Angular-Cookies
XStatic-Angular-Mock

They can be removed, but this apparently needs to be done
in a multi-step process. The interdependency chain,
(horizon has dependency on the old packages) causes
an integration test to fail. So, if we follow the normal
process, then we have to do it in the following order.

1) The newer pakage has to be added to global requirements
2) a) The new dependency has to be added to Horizon
   b) Old dependencies must be removed from Horizon
3) The older packages must be removed from global requirements
   - change 145096

At least this what I can tell how to make it all
work following processes since I can't modify the
requirements across projects in the same patch set.

Partially Implements: blueprint launch-instance-redesign

Change-Id: Ibd171723c6b7ba672c90daf35ae88f672e8d5f4e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/69/142869/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,85dda4abd72761f8f136e6b11eb315160f0340dd,bp/launch-instance-redesign,XStatic-Angular>=1.3.7 # MIT License,XStatic-Angular>=1.2.1.1 # MIT License XStatic-Angular-Cookies>=1.2.1.1 # MIT License XStatic-Angular-Mock>=1.2.1.1 # MIT License,1,3
openstack%2Fsahara~master~I4b8edf26187b3c23d08f9efbee42086652efea5a,openstack/sahara,master,I4b8edf26187b3c23d08f9efbee42086652efea5a,Cleaned up config generator settings,MERGED,2015-01-06 20:21:43.000000000,2015-01-08 02:07:38.000000000,2015-01-08 02:07:37.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-06 20:21:43.000000000', 'files': ['tools/config/config-generator.sahara.conf', 'etc/sahara/sahara.conf.sample', 'sahara/config.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7282251ee2e04213af6f9dbe04304468c6c51d64', 'message': 'Cleaned up config generator settings\n\n1. Sahara opts are listed once\n2. Oslo incubator opts are listed separately\n3. Groups are referenced by variables\n\nStill things to improve:\n1. opt-group mapping is listed twice now (in reg and in list)\n2. registering spread across the project (should be in one place)\n3. dependancies are not managed (it should be one place with CONF)\n\nChange-Id: I4b8edf26187b3c23d08f9efbee42086652efea5a\nCloses-Bug: #1407834\n'}]",0,145325,7282251ee2e04213af6f9dbe04304468c6c51d64,9,5,1,8411,,,0,"Cleaned up config generator settings

1. Sahara opts are listed once
2. Oslo incubator opts are listed separately
3. Groups are referenced by variables

Still things to improve:
1. opt-group mapping is listed twice now (in reg and in list)
2. registering spread across the project (should be in one place)
3. dependancies are not managed (it should be one place with CONF)

Change-Id: I4b8edf26187b3c23d08f9efbee42086652efea5a
Closes-Bug: #1407834
",git fetch https://review.opendev.org/openstack/sahara refs/changes/25/145325/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/config/config-generator.sahara.conf', 'etc/sahara/sahara.conf.sample', 'sahara/config.py', 'setup.cfg']",4,7282251ee2e04213af6f9dbe04304468c6c51d64,bug/1407834, sahara.config = sahara.config:list_opts log.config = sahara.openstack.common.log:list_opts periodic.config = sahara.openstack.common.periodic_task:list_opts policy.config = sahara.openstack.common.policy:list_opts, sahara = sahara.config:list_opts sahara_main = sahara.config:main_opts,147,138
openstack%2Fneutron~master~I58874512965ae0754caa8db38372f21f2b829e74,openstack/neutron,master,I58874512965ae0754caa8db38372f21f2b829e74,Add coverage to AttributeError in RPC code for DVR,ABANDONED,2014-12-24 06:32:29.000000000,2015-01-08 02:04:17.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-24 06:32:29.000000000', 'files': ['neutron/tests/unit/api/rpc/handlers/__init__.py', 'neutron/tests/unit/api/rpc/handlers/test_dvr_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5d0921e59e8c8101e7f4673485c764a9858eac8', 'message': 'Add coverage to AttributeError in RPC code for DVR\n\nCommit eff0b350 did not include tests for this error. This patch\ncompletes the efforts.\n\nCloses-bug: #1394848\n\nChange-Id: I58874512965ae0754caa8db38372f21f2b829e74\n'}]",2,143778,c5d0921e59e8c8101e7f4673485c764a9858eac8,43,20,1,748,,,0,"Add coverage to AttributeError in RPC code for DVR

Commit eff0b350 did not include tests for this error. This patch
completes the efforts.

Closes-bug: #1394848

Change-Id: I58874512965ae0754caa8db38372f21f2b829e74
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/143778/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/rpc/handlers/__init__.py', 'neutron/tests/unit/api/rpc/handlers/test_dvr_rpc.py']",2,c5d0921e59e8c8101e7f4673485c764a9858eac8,bug/1394848,"# Copyright (c) 2014 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from neutron.api.rpc.handlers import dvr_rpc from neutron.tests import base class DVRServerRpcApiMixinTestCase(base.BaseTestCase): def setUp(self): self.mixin = dvr_rpc.DVRServerRpcApiMixin() self.mixin.client = mock.Mock() self.ctxt = mock.ANY self.mock_cctxt = mock.Mock() self.mixin.client.prepare.return_value = self.mock_cctxt super(DVRServerRpcApiMixinTestCase, self).setUp() def test_get_dvr_mac_address_by_host(self): self.mixin.get_dvr_mac_address_by_host(self.ctxt, 'foo_host') self.mock_cctxt.call.assert_called_with( self.ctxt, 'get_dvr_mac_address_by_host', host='foo_host') def test_get_dvr_mac_address_list(self): self.mixin.get_dvr_mac_address_list(self.ctxt) self.mock_cctxt.call.assert_called_with( self.ctxt, 'get_dvr_mac_address_list') def test_get_ports_on_host_by_subnet(self): self.mixin.get_ports_on_host_by_subnet( self.ctxt, 'foo_host', 'foo_subnet') self.mock_cctxt.call.assert_called_with( self.ctxt, 'get_ports_on_host_by_subnet', host='foo_host', subnet='foo_subnet') def test_get_subnet_for_dvr(self): self.mixin.get_subnet_for_dvr(self.ctxt, 'foo_subnet') self.mock_cctxt.call.assert_called_with( self.ctxt, 'get_subnet_for_dvr', subnet='foo_subnet') ",,53,0
openstack%2Fsahara~master~I58940e9606d736412c2c653ddb4ad4d09e6edcea,openstack/sahara,master,I58940e9606d736412c2c653ddb4ad4d09e6edcea,Extracted config check from pep8 to separate env,MERGED,2015-01-06 19:00:29.000000000,2015-01-08 02:02:50.000000000,2015-01-08 02:02:49.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-06 19:00:29.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ba24c7afd9f7781df6a7a8f9542a29182d50418c', 'message': 'Extracted config check from pep8 to separate env\n\nPep8 is broken after each oslo update. Extracted config check to\na separate env. Next step - add this env to Jenkins (or sahara-ci)\nas non-voting job once it is merged.\n\nChange-Id: I58940e9606d736412c2c653ddb4ad4d09e6edcea\nCloses-Bug: #1408053\n'}]",0,145300,ba24c7afd9f7781df6a7a8f9542a29182d50418c,9,5,1,8411,,,0,"Extracted config check from pep8 to separate env

Pep8 is broken after each oslo update. Extracted config check to
a separate env. Next step - add this env to Jenkins (or sahara-ci)
as non-voting job once it is merged.

Change-Id: I58940e9606d736412c2c653ddb4ad4d09e6edcea
Closes-Bug: #1408053
",git fetch https://review.opendev.org/openstack/sahara refs/changes/00/145300/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ba24c7afd9f7781df6a7a8f9542a29182d50418c,bug/1408053,[testenv:checkconfig] commands = {toxinidir}/tools/config/check_uptodate.sh, {toxinidir}/tools/config/check_uptodate.sh,3,1
openstack%2Fcongress~master~I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d,openstack/congress,master,I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d,Use schema instead of hard coded index,MERGED,2015-01-06 20:00:25.000000000,2015-01-08 01:51:07.000000000,2015-01-08 01:51:07.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-06 20:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4b4b341b203800a3248a2cde426627ee46750494', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 2, 'created': '2015-01-06 21:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6df36858b1e9b94ae6cfbb95ef5d843f80789f57', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 3, 'created': '2015-01-06 21:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0d202a656116d8cb6ba00e594cad1ffad0ce4adb', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 4, 'created': '2015-01-06 22:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e618528e39c530df60cc6117269c66012d7f538f', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 5, 'created': '2015-01-06 23:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d9967d5cd626f1a38d7b002ebb2bf0b7c812de53', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 6, 'created': '2015-01-07 00:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a938fe0aecad2fd10a8d47f52f75b13a969dd6cc', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 7, 'created': '2015-01-07 00:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/17441350d94f56a73a1ba9163be4b6b786da1c98', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 8, 'created': '2015-01-07 18:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/898448f24cb33a536b83d4d0203f6077af860ad4', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}, {'number': 9, 'created': '2015-01-07 21:00:20.000000000', 'files': ['contrib/tempest/tempest/scenario/congress_datasources/test_glancev2.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_ceilometer.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_nova.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/335e09d77f3281fbc05efe00250aed0ca48dc317', 'message': 'Use schema instead of hard coded index\n\nThe previous version of these tempest tests uses a hard coded index to pick\nthe ID field from the congress table which is fragile.  This change uses the\nschema and the column name to determine the index.\n\nChange-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d\n'}]",4,145319,335e09d77f3281fbc05efe00250aed0ca48dc317,45,5,9,12875,,,0,"Use schema instead of hard coded index

The previous version of these tempest tests uses a hard coded index to pick
the ID field from the congress table which is fragile.  This change uses the
schema and the column name to determine the index.

Change-Id: I5ed04db0cec3d3132fd6bfdce2d6dbc658f0638d
",git fetch https://review.opendev.org/openstack/congress refs/changes/19/145319/3 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/tempest/tempest/scenario/congress_datasources/test_glancev2.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_ceilometer.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_cinder.py']",4,4b4b341b203800a3248a2cde426627ee46750494,master-indexing2," volume_id_col = [i for i, c in enumerate(volume_schema) if c['name'] == 'id'] volume_row = volumes_map[row['data'][volume_id_col]]", volume_row = volumes_map[row['data'][0]],18,6
openstack%2Fcongress~master~Icd5341ddd3a868edd1814c0ef9436cafba6bdd22,openstack/congress,master,Icd5341ddd3a868edd1814c0ef9436cafba6bdd22,Make indexing work for joins,MERGED,2014-12-18 18:42:42.000000000,2015-01-08 01:51:01.000000000,2015-01-08 01:51:00.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-18 18:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cb6e6a72c30cd60b4d7468b5475c0ff4cc7994b0', 'message': 'Make indexing work for joins\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 2, 'created': '2014-12-19 23:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e4096491f4d9a58e9dbfd148e9a45f6a68ce12bc', 'message': 'Make indexing work for joins\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 3, 'created': '2014-12-19 23:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/fc67908361d2947d617b97b9a0d8eb80dc06ea89', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 4, 'created': '2014-12-19 23:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/97ed6d9544e30f67a1759a9b0c9591cba4e81339', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 5, 'created': '2014-12-19 23:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/63e7e39ec4a3b4a4256b66e42f01d6839c1154c8', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 6, 'created': '2015-01-05 19:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cb0166f924e07ad1263f90fd588f2267e4a19fca', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 7, 'created': '2015-01-06 01:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/32ad40a8d255cf77b7d034d437082a192684e0b0', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 8, 'created': '2015-01-06 02:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6943e50f80fa188f8be54a5be94f334e91c6ca14', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 9, 'created': '2015-01-06 19:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0d2b690b730d7be3990b77eebdb4c61f480c950f', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 10, 'created': '2015-01-07 18:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4d27ccac673dfbda164521e7dabf2a2d5bc231ec', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}, {'number': 11, 'created': '2015-01-07 21:00:20.000000000', 'files': ['congress/tests/policy/test_nonrecur.py', 'congress/policy/ruleset.py', 'congress/tests/helper.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/67e1c187deae9a7c97652b99dd08522151d0aae0', 'message': 'Make indexing work for joins\n\nThis speeds up evaluation from a linear search O(n) to a hash table lookup\nO(1).  This speedup can be quite large when dealing with large datasets.\n\nChange-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22\n'}]",6,142874,67e1c187deae9a7c97652b99dd08522151d0aae0,48,5,11,12875,,,0,"Make indexing work for joins

This speeds up evaluation from a linear search O(n) to a hash table lookup
O(1).  This speedup can be quite large when dealing with large datasets.

Change-Id: Icd5341ddd3a868edd1814c0ef9436cafba6bdd22
",git fetch https://review.opendev.org/openstack/congress refs/changes/74/142874/4 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy/test_nonrecur.py', 'congress/policy/ruleset.py', 'congress/tests/helper.py', 'congress/policy/runtime.py']",4,cb6e6a72c30cd60b4d7468b5475c0ff4cc7994b0,master-indexing2," for rule in self.head_index(lit.table, lit.plug(context.binding)): # for rule in self.head_index(lit.table, None): def head_index(self, table, match_literal=None): """"""This routine must return all the formulas pertinent for top-down evaluation when a literal with TABLE is at the top of the stack. If match_literal is given, return just the rules that match the match_literal. return self.rules.get_rules(table, match_literal) def head_index(self, table, match_literal=None):"," # ALEX: Here is where the runtime iterates to find a match. We need # to use lit and context.binding to limit the number of iterations. # print(""LIT %s"" % lit) # print(""BINDING %s"" % context.binding) # print(""PLUG %s"" % lit.plug(context.binding)) for rule in self.head_index(lit.table): def head_index(self, table): """"""This routine must return all the formulas pertinent for top-down evaluation when a literal with TABLE is at the top of the stack. return self.rules.get_rules(table) def head_index(self, table):",142,34
openstack%2Ftripleo-image-elements~master~I0593597beb616af2d4949a1b28307a9e1a5eebbe,openstack/tripleo-image-elements,master,I0593597beb616af2d4949a1b28307a9e1a5eebbe,Update iptables to support variable Horizon port,MERGED,2014-12-22 22:09:29.000000000,2015-01-08 01:50:30.000000000,2015-01-08 01:50:29.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6896}, {'_account_id': 7144}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-12-22 22:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4a09822990d166278b47469d4aadc07eec45e2fb', 'message': 'EEIN-214 Add rules to iptables for Horizon HTTPS port 443\n\nWhen SSL is enabled, iptables must allow traffic on port\n443 for HTTPS access to the Horizon UI.\n\nWhen SSL is disabled, iptables should continue to open\nport 80 for traditional HTTP access.\n\nChange-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe\n'}, {'number': 2, 'created': '2014-12-22 22:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f9fbc4a4bf56e2cf33ac34a16f93dc32915bcf69', 'message': 'EEIN-214 Add rules to iptables for Horizon HTTPS port 443\n\nWhen SSL is enabled, iptables must allow traffic on port\n443 for HTTPS access to the Horizon UI.\n\nWhen SSL is disabled, iptables should continue to open\nport 80 for traditional HTTP access.\n\nChange-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe\n'}, {'number': 3, 'created': '2014-12-23 17:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/55e75166542d85014e09805ebdbeb3446d66cfe5', 'message': 'Add rules to iptables for Horizon HTTPS port 443\n\nWhen SSL is enabled, iptables must allow traffic on port\n443 for HTTPS access to the Horizon UI.\n\nWhen SSL is disabled, iptables should continue to open\nport 80 for traditional HTTP access.\n\nChange-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe\n'}, {'number': 4, 'created': '2014-12-23 17:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ca6281aae0cf3a9ba90a774f5ed18f5b965c761a', 'message': 'Add rules to iptables for Horizon HTTPS port 443\n\nWhen SSL is enabled, iptables must allow traffic on port\n443 for HTTPS access to the Horizon UI.\n\nWhen SSL is disabled, iptables should continue to open\nport 80 for traditional HTTP access.\n\nImplementation depends on Iec475a6c245a5bfe8b1d63ff72b6d0299861615c\n\nChange-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe\n'}, {'number': 5, 'created': '2014-12-23 17:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e8edae8858f0b991ec7f3f80a650f0558d488d5d', 'message': 'Update iptables to support variable Horizon port\n\nWhen SSL is enabled, iptables must allow traffic on port\n443 for HTTPS access to the Horizon UI.\n\nWhen SSL is disabled, iptables should continue to open\nport 80 for traditional HTTP access.\n\nImplementation depends on Iec475a6c245a5bfe8b1d63ff72b6d0299861615c\n\nChange-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe\n'}, {'number': 6, 'created': '2014-12-25 14:56:50.000000000', 'files': ['elements/horizon/os-refresh-config/pre-configure.d/97-horizon-fedora-iptables'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dd2bf0518bd1ba369571d6e871cbf1ab3d3a67d9', 'message': 'Update iptables to support variable Horizon port\n\nWhen SSL is enabled, iptables must allow traffic on port\n443 for HTTPS access to the Horizon UI.\n\nWhen SSL is disabled, iptables should continue to open\nport 80 for traditional HTTP access.\n\nImplementation depends on Iec475a6c245a5bfe8b1d63ff72b6d0299861615c\n\nChange-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe\n'}]",1,143550,dd2bf0518bd1ba369571d6e871cbf1ab3d3a67d9,25,6,6,10290,,,0,"Update iptables to support variable Horizon port

When SSL is enabled, iptables must allow traffic on port
443 for HTTPS access to the Horizon UI.

When SSL is disabled, iptables should continue to open
port 80 for traditional HTTP access.

Implementation depends on Iec475a6c245a5bfe8b1d63ff72b6d0299861615c

Change-Id: I0593597beb616af2d4949a1b28307a9e1a5eebbe
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/50/143550/6 && git format-patch -1 --stdout FETCH_HEAD,['elements/horizon/os-refresh-config/pre-configure.d/97-horizon-fedora-iptables'],1,4a09822990d166278b47469d4aadc07eec45e2fb,(detached,"# Open either port 80 or 443, depending on whether stunnel.connect_host contains a value if [ -z ""$(os-apply-config --key 'stunnel.connect_host' --type raw --key-default '') ]; then add-rule INPUT -p tcp --port 80 -j ACCEPT else add-rule INPUT -p tcp --port 443 -j ACCEPT fi",add-rule INPUT -p tcp --dport 80 -j ACCEPT,6,1
openstack%2Fdevstack~master~I52150fef11ba6e3ab2fd0acacaa3c64413c0c0d1,openstack/devstack,master,I52150fef11ba6e3ab2fd0acacaa3c64413c0c0d1,Customizing tempest configuration for libvirt-lxc,MERGED,2015-01-06 16:36:56.000000000,2015-01-08 01:40:26.000000000,2015-01-08 01:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 10385}, {'_account_id': 13215}]","[{'number': 1, 'created': '2015-01-06 16:36:56.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7b47c47308a601839008413d20acacf2c52e3f45', 'message': 'Customizing tempest configuration for libvirt-lxc\n\nIn order to support the continued testing of the libvirt driver\nwith lxc virtualization, certain compute features must be disabled\nincluding rescue, resize, and suspend.\n\nChange-Id: I52150fef11ba6e3ab2fd0acacaa3c64413c0c0d1\n'}]",0,145262,7b47c47308a601839008413d20acacf2c52e3f45,11,6,1,13215,,,0,"Customizing tempest configuration for libvirt-lxc

In order to support the continued testing of the libvirt driver
with lxc virtualization, certain compute features must be disabled
including rescue, resize, and suspend.

Change-Id: I52150fef11ba6e3ab2fd0acacaa3c64413c0c0d1
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/145262/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,7b47c47308a601839008413d20acacf2c52e3f45,libvirt-lxc-tempest-customization," # Libvirt-LXC if [ ""$VIRT_DRIVER"" = ""libvirt"" ] && [ ""$LIBVIRT_TYPE"" = ""lxc"" ]; then iniset $TEMPEST_CONFIG compute-feature-enabled rescue False iniset $TEMPEST_CONFIG compute-feature-enabled resize False iniset $TEMPEST_CONFIG compute-feature-enabled suspend False fi ",,7,0
openstack%2Fcongress~master~I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2,openstack/congress,master,I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2,Refactor to separate RuleSet,MERGED,2014-12-18 18:42:42.000000000,2015-01-08 01:25:43.000000000,2015-01-08 01:25:43.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-18 18:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/ddf8fd0b0fb825d25e4e2b334755e4af6d0b88b1', 'message': 'Refactor to separate RuleSet\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 2, 'created': '2014-12-19 23:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/7894262127f83df978190ce9b3735c822a8d3d50', 'message': 'Refactor to separate RuleSet\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 3, 'created': '2014-12-19 23:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/7c385bdceff42c1eb942f89cb44dde5f81dbf81c', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 4, 'created': '2015-01-05 19:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/c18e53fbf25cdedad308382a50ffc164f9bdd5b8', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 5, 'created': '2015-01-06 01:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/8487cdc2e270a24ae5cf66823ba2757bdd668140', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 6, 'created': '2015-01-06 02:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/080e33dc9fdf1cff935bb092958dfc9baee05904', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 7, 'created': '2015-01-06 19:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/dda25f570a3d276c6932cc99bdd3be5d69725cfc', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 8, 'created': '2015-01-07 18:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2b2de53d325cd791e7b2c38545df86123f980709', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}, {'number': 9, 'created': '2015-01-07 21:00:20.000000000', 'files': ['congress/policy/ruleset.py', 'contrib/horizon/congress.py', 'congress/policy/runtime.py', 'congress/tests/policy/test_ruleset.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/b6c33fe0dd75488a8ea8010769daf4c864b713f0', 'message': 'Refactor to separate RuleSet\n\nThis separates the logic to associate a set of rules with a particular table.\nThis will make it easier to implement indexing for table joins.\n\nChange-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2\n'}]",28,142873,b6c33fe0dd75488a8ea8010769daf4c864b713f0,46,5,9,12875,,,0,"Refactor to separate RuleSet

This separates the logic to associate a set of rules with a particular table.
This will make it easier to implement indexing for table joins.

Change-Id: I338c37df6f9970de56ac4a3c239d9e7f17f1e7a2
",git fetch https://review.opendev.org/openstack/congress refs/changes/73/142873/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy/test_nonrecur.py', 'congress/tests/base.py', 'congress/policy/ruleset.py', 'contrib/tempest/tempest/scenario/manager_congress.py', 'contrib/horizon/congress.py', 'congress/policy/runtime.py']",6,ddf8fd0b0fb825d25e4e2b334755e4af6d0b88b1,master-indexing2,"from congress.policy.ruleset import RuleSet """"""Top-down evaluation for the rules in self.rules."""""" # ALEX: Here is where the runtime iterates to find a match. We need # to use lit and context.binding to limit the number of iterations. # print(""LIT %s"" % lit) # print(""BINDING %s"" % context.binding) # print(""PLUG %s"" % lit.plug(context.binding)) for rule in self.head_index(lit.table): # print(""iterating on rule %s"" % rule) return self.rules.keys() if self.rules.contains_key(table): return self.rules.get_rules(table) return [] self.rules = RuleSet() self.rules.clear() if not self.rules.contains_key(tablename): if len(self.rules.get_rules(tablename)) == 0: return len(list(self.rules.get_rules(tablename))[0].head.arguments) return self.rules.add_rule(rule.head.table, rule) return self.rules.discard_rule(rule.head.table, rule) tablenames = self.rules.keys() if self.rules.contains_key(table): results.extend(self.rules.get_rules(table)) self.rules = RuleSet() self.rules.add_rule(delta.trigger.table, delta) self.rules.discard_rule(delta.trigger.table, delta) return str(self.rules) if self.rules.contains_key(table): return self.rules.get_rules(table) else: return []","from congress.policy import utility """"""Top-down evaluation for the rules in SELF.CONTENTS."""""" for rule in self.head_index(lit.table): return self.contents.keys() if table not in self.contents: return [] return list(self.contents[table]) self.contents = {} self.contents = {} if tablename not in self.contents: if len(self.contents[tablename]) == 0: return len(list(self.contents[tablename])[0].head.arguments) table = rule.head.table if table in self.contents: return self.contents[table].add(rule) else: self.contents[table] = utility.OrderedSet([rule]) return True table = rule.head.table if table in self.contents: return self.contents[table].discard(rule) return False tablenames = self.contents.keys() if table in self.contents: results.extend(self.contents[table]) self.contents = {} if delta.trigger.table not in self.contents: self.contents[delta.trigger.table] = [delta] else: self.contents[delta.trigger.table].append(delta) if delta.trigger.table not in self.contents: return self.contents[delta.trigger.table].remove(delta) return str(self.contents) if table not in self.contents: return [] else: return self.contents[table]",101,39
openstack%2Fneutron~master~I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f,openstack/neutron,master,I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f,Add Process class helper to manage processes with namespace,MERGED,2014-09-17 17:11:53.000000000,2015-01-08 01:20:46.000000000,2015-01-07 22:29:15.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 642}, {'_account_id': 704}, {'_account_id': 2035}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11126}, {'_account_id': 11698}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 13051}, {'_account_id': 13538}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-09-17 17:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c45fdcfe5773001d6b9598637976a942a40dc9d4', 'message': 'Add Process class to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 2, 'created': '2014-09-19 15:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8d20a37ec4e7bbfef05c45d62233a1cb90709f0', 'message': 'Add Process class to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 3, 'created': '2014-09-22 15:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2cdecf0553aee23808743c4afd05b440ea82f73', 'message': 'Add Process class to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 4, 'created': '2014-09-23 14:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/873032b0d20ea97cfab914c9c6ab2c6f0d16d149', 'message': 'Add Process class to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 5, 'created': '2014-09-24 16:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6198233a1dac83c454696395e0ea7ce9dd3b132c', 'message': 'Add Process class to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 6, 'created': '2014-09-25 06:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ee58af4b91c0ced5dee0509712bc39b893d482d', 'message': 'Add Process class to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 7, 'created': '2014-10-03 16:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a133e7a6ab010b7e7e7b47a56927c04366d0a977', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 8, 'created': '2014-10-06 08:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb1332296c93d3c95316e80e139e3a22392794e9', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 9, 'created': '2014-10-15 13:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70e8be17c33f1524e6b15a4c6b065b70836ae83a', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 10, 'created': '2014-10-15 15:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/75a8c83fccb7bc0c6d4e3ab2e782bc0498d79f8e', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 11, 'created': '2014-10-16 12:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bfe13c5e9a1aa91792c87f5df3632c4fa2f0545b', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 12, 'created': '2014-10-20 15:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7d66998053d1160153fac8049280c19a39b7538', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 13, 'created': '2014-11-12 15:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c24b76a6e8fb7b248649257d6099dca18e88a52b', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 14, 'created': '2014-11-13 08:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca80280ed7d734456bc576a14f16f30c8c710d85', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 15, 'created': '2014-11-21 13:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b17aa36475350c25ecfd22dc9d1706637816b99', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 16, 'created': '2014-11-21 14:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fd6e4998819e273a7614a80df5f9f9624e84fe9', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 17, 'created': '2014-11-21 14:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6354e1e026a310ec25a19ca30a2b5dc6414273c6', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 18, 'created': '2014-11-27 12:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70b323dd919029662623cf254eb35aa1e6f26058', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 19, 'created': '2014-11-28 12:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4496c7660eadf8340166c01e33941467d5bcd4a', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 20, 'created': '2014-11-28 13:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a292275029366944475da7e3a398f788fb06b6a3', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 21, 'created': '2014-12-12 17:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/afaeeee309a1eb3665b378367db494423dc3b04a', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 22, 'created': '2014-12-15 11:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/200f4e6b7b27e1279c2daa36e368cc5280c2df59', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 23, 'created': '2014-12-15 12:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/adcd3d8945dd890510d7630b3c4872f7d2adceba', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 24, 'created': '2014-12-16 09:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/29862337eddb6e007a4dde84c33920754280ded7', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 25, 'created': '2014-12-17 16:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e4a4a2446a8ce36ace6e07d6cf300bdd3de3fcd', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 26, 'created': '2015-01-05 16:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a330a6cb0498da5ba26e6f0fb6f10b1a60f1c2b', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}, {'number': 27, 'created': '2015-01-07 10:20:44.000000000', 'files': ['neutron/tests/unit/test_agent_linux_utils.py', 'neutron/tests/unit/agent/linux/test_async_process.py', 'neutron/tests/functional/agent/linux/test_ovsdb_monitor.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/agent/linux/async_process.py', 'neutron/tests/functional/agent/linux/test_helpers.py', 'neutron/agent/linux/utils.py', 'neutron/tests/contrib/filters.template', 'neutron/tests/functional/agent/linux/helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/374a612241ff9f15bcdcccb6c60d6d0847706766', 'message': 'Add Process class helper to manage processes with namespace\n\nThis class extends Popen class with usage of namespace and root-helper.\nBecause of usage of root wrapper, this class re-uses get_child_pid() for\nkilling the child process. get_child_pid() is taken out of AsyncProcess\nas a part of this patch.\n\nChange-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f\nRelated-Bug: 1243216\n'}]",153,122207,374a612241ff9f15bcdcccb6c60d6d0847706766,611,45,27,8655,,,0,"Add Process class helper to manage processes with namespace

This class extends Popen class with usage of namespace and root-helper.
Because of usage of root wrapper, this class re-uses get_child_pid() for
killing the child process. get_child_pid() is taken out of AsyncProcess
as a part of this patch.

Change-Id: I856b3ec75f347ecccaf4a1c6fd17b28a33ee1a3f
Related-Bug: 1243216
",git fetch https://review.opendev.org/openstack/neutron refs/changes/07/122207/25 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_agent_linux_utils.py', 'neutron/tests/unit/agent/linux/test_async_process.py', 'neutron/tests/functional/agent/linux/test_ovsdb_monitor.py', 'neutron/agent/linux/external_process.py', 'neutron/tests/unit/test_linux_external_process.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/agent/linux/async_process.py', 'neutron/agent/linux/utils.py']",8,c45fdcfe5773001d6b9598637976a942a40dc9d4,bug/1243216," raw_pids = execute(['ps', '--ppid', pid, '-o', 'pid='], log_fail_as_error=False) no_children_found = 'Exit code: 1' in e.message def get_child_pid(pid, root_helper=None): # If root helper was used, two or more processes will be created: # # - a root helper process (e.g. sudo myscript) # - possibly a rootwrap script (e.g. neutron-rootwrap) # - a child process (e.g. myscript) # # Killing the root helper process will leave the child process # running, re-parented to init, so the only way to ensure that both # die is to target the child process directly. if root_helper is not None: try: pid = find_child_pids(pid)[0] except IndexError: # Process is already dead return None while True: try: # We shouldn't have more than one child per process # so keep getting the children of the first one pid = find_child_pids(pid)[0] except IndexError: # Last process in the tree, return it break return pid"," raw_pids = execute(['ps', '--ppid', pid, '-o', 'pid=']) no_children_found = 'Exit code: 1' in str(e)",239,75
openstack%2Fmanila~master~Id054857f320d9eda02bc0b82e5512c0595342290,openstack/manila,master,Id054857f320d9eda02bc0b82e5512c0595342290,py3: use six.moves.range instead of xrange,MERGED,2014-12-27 10:47:26.000000000,2015-01-08 01:01:02.000000000,2015-01-08 01:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-27 10:47:26.000000000', 'files': ['doc/ext/manila_todo.py', 'manila/tests/api/v1/test_limits.py', 'manila/tests/scheduler/test_host_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/346b7c468a87b4d539898949a63f025aaf38dd98', 'message': ""py3: use six.moves.range instead of xrange\n\nsix is the canonical compatibility library for supporting\nPython 2 and 3 in a single codebase.\n\nThe xrange module  was removed in Python 3 and we should\nuse 'six.moves.range' instead of 'xrange' to make\ncode compatible with py 2 and 3 as well.\n\nPartially-implements blueprint py3-compatibility\n\nChange-Id: Id054857f320d9eda02bc0b82e5512c0595342290\n""}]",0,144208,346b7c468a87b4d539898949a63f025aaf38dd98,16,6,1,6116,,,0,"py3: use six.moves.range instead of xrange

six is the canonical compatibility library for supporting
Python 2 and 3 in a single codebase.

The xrange module  was removed in Python 3 and we should
use 'six.moves.range' instead of 'xrange' to make
code compatible with py 2 and 3 as well.

Partially-implements blueprint py3-compatibility

Change-Id: Id054857f320d9eda02bc0b82e5512c0595342290
",git fetch https://review.opendev.org/openstack/manila refs/changes/08/144208/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ext/manila_todo.py', 'manila/tests/api/v1/test_limits.py', 'manila/tests/scheduler/test_host_manager.py']",3,346b7c468a87b4d539898949a63f025aaf38dd98,bp/py3-compatibility,"from six import moves for x in moves.range(1, 5)] for i in moves.range(4):"," for x in xrange(1, 5)] for i in xrange(4):",7,4
openstack%2Fcongress~master~Ie5e6c82ae2777921d1c6367e5297351455f69683,openstack/congress,master,Ie5e6c82ae2777921d1c6367e5297351455f69683,Fix a transient test failure in tempest tests,MERGED,2015-01-05 23:16:14.000000000,2015-01-08 00:23:03.000000000,2015-01-08 00:12:14.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-05 23:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cbabeaf2d7ea77bb27294e8843ad1ee51cdbf135', 'message': 'Experiment with Temptest Test Failure\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}, {'number': 2, 'created': '2015-01-05 23:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2f9769d0bbf6c862f63fbc8758564c6ef609e90d', 'message': 'Experiment with Temptest Test Failure\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}, {'number': 3, 'created': '2015-01-06 00:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d9237ddd0d353877e6545d1155864f8507b2788f', 'message': 'Experiment with Temptest Test Failure\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}, {'number': 4, 'created': '2015-01-06 01:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/bc0367a009caa66f1a2f561a3b22ebedaec7bd64', 'message': 'Fix a transient test failure in test_keystonev2\n\nThis test fetches data directly from keystone and congress and compares them.\nHowever, the test is not synchronized with whatever inserts data into\nkeystone, so when the test starts, keystone might not have all the data.\nWhile the test is running, keystone gets more data and gives the data to\ncongress.  This causes the test to think congress has users that keystone does\nnot, leading to a KeyError.\n\nThis changes makes the test fetch data from keystone and congress each time\nthe test tries to compare the two.  This ensures that eventually, the two\ndatasets converge.  It also avoids the KeyError when the congress data has\nsomething keystone does not.\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}, {'number': 5, 'created': '2015-01-06 19:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5579cca677cca739bd66668014b8b5112d45e49f', 'message': 'Fix a transient test failure in tempest tests\n\nThe previous version of these tests fetch data directly from the data service\nand from congress and compares the two responses.  However, the test is not\nsynchronized with whatever inserts data into the data service, so when the\ntest starts, the data service might not have all the data.  While the test is\nrunning, the data service can get more data and give the data to congress.\nThis causes the test to think congress has data that the data service does\nnot, leading to a KeyError.\n\nThis changes makes the test fetch data from the data service and congress each\ntime the test tries to compare the two.  This ensures that eventually, the two\ndatasets converge.  It also avoids the KeyError when the congress data has\nsomething the data service does not.\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}, {'number': 6, 'created': '2015-01-07 18:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/571bdf4355469c070ce582b4f58f9ac98095639b', 'message': 'Fix a transient test failure in tempest tests\n\nThe previous version of these tests fetch data directly from the data service\nand from congress and compares the two responses.  However, the test is not\nsynchronized with whatever inserts data into the data service, so when the\ntest starts, the data service might not have all the data.  While the test is\nrunning, the data service can get more data and give the data to congress.\nThis causes the test to think congress has data that the data service does\nnot, leading to a KeyError.\n\nThis changes makes the test fetch data from the data service and congress each\ntime the test tries to compare the two.  This ensures that eventually, the two\ndatasets converge.  It also avoids the KeyError when the congress data has\nsomething the data service does not.\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}, {'number': 7, 'created': '2015-01-07 21:00:20.000000000', 'files': ['contrib/tempest/tempest/scenario/congress_datasources/test_glancev2.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_ceilometer.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_nova.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py', 'contrib/tempest/tempest/scenario/congress_datasources/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/732c072e0330460defe951202a8ac3fbdf13ff5b', 'message': 'Fix a transient test failure in tempest tests\n\nThe previous version of these tests fetch data directly from the data service\nand from congress and compares the two responses.  However, the test is not\nsynchronized with whatever inserts data into the data service, so when the\ntest starts, the data service might not have all the data.  While the test is\nrunning, the data service can get more data and give the data to congress.\nThis causes the test to think congress has data that the data service does\nnot, leading to a KeyError.\n\nThis changes makes the test fetch data from the data service and congress each\ntime the test tries to compare the two.  This ensures that eventually, the two\ndatasets converge.  It also avoids the KeyError when the congress data has\nsomething the data service does not.\n\nChange-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683\n'}]",14,145089,732c072e0330460defe951202a8ac3fbdf13ff5b,41,5,7,12875,,,0,"Fix a transient test failure in tempest tests

The previous version of these tests fetch data directly from the data service
and from congress and compares the two responses.  However, the test is not
synchronized with whatever inserts data into the data service, so when the
test starts, the data service might not have all the data.  While the test is
running, the data service can get more data and give the data to congress.
This causes the test to think congress has data that the data service does
not, leading to a KeyError.

This changes makes the test fetch data from the data service and congress each
time the test tries to compare the two.  This ensures that eventually, the two
datasets converge.  It also avoids the KeyError when the congress data has
something the data service does not.

Change-Id: Ie5e6c82ae2777921d1c6367e5297351455f69683
",git fetch https://review.opendev.org/openstack/congress refs/changes/89/145089/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py'],1,cbabeaf2d7ea77bb27294e8843ad1ee51cdbf135,master-indexing2," try: user_row = user_map[row['data'][4]] except KeyError: assert False, ""Could not find key %s in %s"" % (str(row), str(user_map)) ", user_row = user_map[row['data'][4]],5,1
openstack%2Fpuppet-keystone~master~I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5,openstack/puppet-keystone,master,I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5,Use openstackclient for keystone_endpoint,MERGED,2014-12-22 07:32:00.000000000,2015-01-08 00:20:50.000000000,2015-01-08 00:20:49.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-12-22 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/de4e5b58f97c55dd5db62e3a87eeed3d103ccba1', 'message': 'Use openstackclient for keystone_endpoint\n\nChange-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 2, 'created': '2014-12-23 18:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ea92cdb8a2f2b25503777b6320ea736512a78ae7', 'message': 'Use openstackclient for keystone_endpoint\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 3, 'created': '2015-01-05 19:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/d3b1d410620cb01a2a7ff10f78d6e77dc0d72e70', 'message': 'Use openstackclient for keystone_endpoint\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 4, 'created': '2015-01-07 22:47:45.000000000', 'files': ['spec/unit/provider/keystone_endpoint/openstack_spec.rb', 'lib/puppet/provider/keystone_endpoint/openstack.rb', 'spec/unit/provider/keystone_endpoint/keystone_spec.rb', 'lib/puppet/type/keystone_endpoint.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/0696d02d8b5ac3a1088d6f5e2543d749d07816e6', 'message': 'Use openstackclient for keystone_endpoint\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}]",0,143385,0696d02d8b5ac3a1088d6f5e2543d749d07816e6,28,5,4,8482,,,0,"Use openstackclient for keystone_endpoint

blueprint use-openstackclient-in-module-resources

Change-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5
Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/85/143385/3 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_endpoint/openstack_spec.rb', 'lib/puppet/provider/keystone_endpoint/openstack.rb', 'spec/unit/provider/keystone_endpoint/keystone_spec.rb', 'lib/puppet/type/keystone_endpoint.rb']",4,de4e5b58f97c55dd5db62e3a87eeed3d103ccba1,openstackclient,"require 'puppet/util/openstack' desc 'Type for managing keystone endpoints.' auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_aviator_params(self, auth_param_doc)", desc <<-EOT This is currently used to model the management of keystone endpoint. EOT # TODO I should do some url validation,233,79
openstack%2Fopenstack-manuals~master~Ie498dca57cf262c8b3e61e210e2f89c6a7d5e0fb,openstack/openstack-manuals,master,Ie498dca57cf262c8b3e61e210e2f89c6a7d5e0fb,Change Python2 to Python2.7,MERGED,2015-01-06 21:56:48.000000000,2015-01-08 00:15:42.000000000,2015-01-08 00:15:41.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 4656}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-01-06 21:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/afc783f8a385608183036abc0ddb0329e30cef26', 'message': 'Revert ""Make sure that tox uses python2 by default""\n\nPython2 is not a binary installed on all systems - we should find a\nbetter way to run only python2.7 by setting it in the envlist\n\nThis reverts commit 3936226d945755933505a3627a5d55cbacb4330f.\n\nChange-Id: Ie498dca57cf262c8b3e61e210e2f89c6a7d5e0fb\n'}, {'number': 2, 'created': '2015-01-07 19:58:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/82aed2c350c757a779a1e1d23d81b2e1fba959b7', 'message': 'Change Python2 to Python2.7\n\n""Python2"" is not a binary installed on all systems.\n\nChange-Id: Ie498dca57cf262c8b3e61e210e2f89c6a7d5e0fb\n'}]",0,145355,82aed2c350c757a779a1e1d23d81b2e1fba959b7,13,6,2,4656,,,0,"Change Python2 to Python2.7

""Python2"" is not a binary installed on all systems.

Change-Id: Ie498dca57cf262c8b3e61e210e2f89c6a7d5e0fb
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/55/145355/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,afc783f8a385608183036abc0ddb0329e30cef26,python_2,,basepython = python2,0,1
openstack%2Fhorizon~master~I4dbf5a2be2ba7a52f2ae80dda62b7d2fd90db39d,openstack/horizon,master,I4dbf5a2be2ba7a52f2ae80dda62b7d2fd90db39d,changes to settings.rst file in dev docs,ABANDONED,2014-12-09 18:28:13.000000000,2015-01-08 00:07:48.000000000,,"[{'_account_id': 3}, {'_account_id': 9622}, {'_account_id': 13785}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-12-09 18:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9c514f026177278d0c595ea84033c117f9d4b854', 'message': 'changes to settings.rst file in dev docs\n\nadded ""the"" in a few places that were needed\nremoved a few spaces\n\nChange-Id: I4dbf5a2be2ba7a52f2ae80dda62b7d2fd90db39d\n'}, {'number': 2, 'created': '2014-12-10 03:41:53.000000000', 'files': ['doc/source/topics/settings.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/129ad9efcd6c73aae70c8ccd7c520c4c6f381129', 'message': 'changes to settings.rst file in dev docs\n\nadded ""the"" in a few places that were needed\nremoved a few spaces\n\nChange-Id: I4dbf5a2be2ba7a52f2ae80dda62b7d2fd90db39d\n'}]",7,140425,129ad9efcd6c73aae70c8ccd7c520c4c6f381129,10,4,2,9382,,,0,"changes to settings.rst file in dev docs

added ""the"" in a few places that were needed
removed a few spaces

Change-Id: I4dbf5a2be2ba7a52f2ae80dda62b7d2fd90db39d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/25/140425/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/topics/settings.rst'],1,9c514f026177278d0c595ea84033c117f9d4b854,settings_rst," In the OpenStack Dashboard configuration, we suggest **NOT** to use this setting. Please specify the order of the dashboard using the This is the default in the OpenStack Dashboard. In the OpenStack Dashboard configuration, we suggest **NOT** to use this setting. Please specify the order of the dashboard using theThis can either be a literal URL path (such as the default), or Python'sYou can customize the sort order by: id, name, ram, disk and vCPUs.This example sorts flavors by vCPUs in descending order::connections to OpenStack services when making API calls.Specifies where service based policy files are located. These are used to"," In OpenStack Dashboard configuration, we suggest **NOT** to use this setting. Please specify the order of dashboard using the This is the default way in OpenStack Dashboard. In OpenStack Dashboard configuration, we suggest **NOT** to use this setting. Please specify the order of dashboard using theThis can be either a literal URL path (such as the default), or Python'sYou can customize the sort order by: id, name, ram, disk and vcpus.This example sorts flavors by vcpus in descending order::connections to openstack services when making API calls.Specifies where service based policy files are located. These are used to",10,10
openstack%2Fopenstack-manuals~master~I0d7d57e0525012273149c235b910d8515d474386,openstack/openstack-manuals,master,I0d7d57e0525012273149c235b910d8515d474386,made change to section_dashboard_launch_instances_from_image,ABANDONED,2014-12-12 07:23:05.000000000,2015-01-08 00:07:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 10497}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-12-12 07:23:05.000000000', 'files': ['doc/user-guide/section_dashboard_launch_instances_from_image.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/68b9105100b0c5e62e0cf7b16394300d57aae6f5', 'message': 'made change to section_dashboard_launch_instances_from_image\n\nremoved to from sentence didn’t make sense\nadded a dash\n\nChange-Id: I0d7d57e0525012273149c235b910d8515d474386\n'}]",1,141287,68b9105100b0c5e62e0cf7b16394300d57aae6f5,6,4,1,9382,,,0,"made change to section_dashboard_launch_instances_from_image

removed to from sentence didn’t make sense
added a dash

Change-Id: I0d7d57e0525012273149c235b910d8515d474386
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/141287/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/section_dashboard_launch_instances_from_image.xml'],1,68b9105100b0c5e62e0cf7b16394300d57aae6f5,," <para>Select the volume from which to launch. Launch an you select does not boot, instead, it is replaced by the image comment and include this note when the bug is back-ported"," <para>To select the volume to from which to launch, launch an you select does not boot. Instead, it is replaced by the image comment and include this note when the bug is backported",3,3
openstack%2Fswift~master~If6fa78ae1abbeff8aaaf274bc9545d51a2c8e3ee,openstack/swift,master,If6fa78ae1abbeff8aaaf274bc9545d51a2c8e3ee,corrected a number of typos and mistypes,ABANDONED,2014-11-22 20:58:06.000000000,2015-01-08 00:06:51.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-11-22 20:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b28acad6e2fff65788f2341bb410214904b32561', 'message': 'corrected a number of typos and mistypes\n\nexamples: mechanism, override, entry points, extensions, request\nremoved spaces as well\n\nChange-Id: If6fa78ae1abbeff8aaaf274bc9545d51a2c8e3ee\n'}, {'number': 2, 'created': '2014-11-22 23:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5b4501411579a6252791391123817ebc2b3c0d0b', 'message': 'corrected a number of typos and mistypes\n\nexamples: mechanism, override, entry points, extensions, request\nremoved spaces as well\n\nChange-Id: If6fa78ae1abbeff8aaaf274bc9545d51a2c8e3ee\n'}, {'number': 3, 'created': '2014-11-24 16:14:56.000000000', 'files': ['doc/source/development_middleware.rst', 'doc/source/deployment_guide.rst', 'doc/source/development_auth.rst', 'doc/source/development_ondisk_backends.rst', 'doc/source/cors.rst', 'doc/source/logs.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/b9595ea5ea0c39dd75b2f74024df79e0f7633297', 'message': 'corrected a number of typos and mistypes\n\nexamples: mechanism, override, entry points, extensions, request\nremoved spaces as well\n\nChange-Id: If6fa78ae1abbeff8aaaf274bc9545d51a2c8e3ee\n'}]",4,136587,b9595ea5ea0c39dd75b2f74024df79e0f7633297,14,5,3,9382,,,0,"corrected a number of typos and mistypes

examples: mechanism, override, entry points, extensions, request
removed spaces as well

Change-Id: If6fa78ae1abbeff8aaaf274bc9545d51a2c8e3ee
",git fetch https://review.opendev.org/openstack/swift refs/changes/87/136587/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/development_middleware.rst', 'doc/source/deployment_guide.rst', 'doc/source/development_auth.rst', 'doc/source/development_ondisk_backends.rst', 'doc/source/cors.rst', 'doc/source/logs.rst']",6,b28acad6e2fff65788f2341bb410214904b32561,auth_de,"source The ""source"" of the request. This may be set for requests","source The ""source"" of the reuqest. This may be set for requests",16,16
openstack%2Fneutron-specs~master~I6e9aba3c1a93bee21f2718fa7a96a10ce11cfe01,openstack/neutron-specs,master,I6e9aba3c1a93bee21f2718fa7a96a10ce11cfe01,Implements opencontrail extension support,ABANDONED,2015-01-06 10:07:33.000000000,2015-01-07 23:50:13.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 7002}]","[{'number': 1, 'created': '2015-01-06 10:07:33.000000000', 'files': ['specs/kilo/opencontrail-add-extension-support.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/270e8ef1b3f27b8fe15d12d3b51cf512f0b55ce9', 'message': 'Implements opencontrail extension support\n\nThis blueprint is pre-requisite to support opencontrail extension\nIPAM, Policy and route-table.\n\nChange-Id: I6e9aba3c1a93bee21f2718fa7a96a10ce11cfe01\nImplements: blueprint opencontrail-add-extension-support\n'}]",0,145183,270e8ef1b3f27b8fe15d12d3b51cf512f0b55ce9,6,3,1,7002,,,0,"Implements opencontrail extension support

This blueprint is pre-requisite to support opencontrail extension
IPAM, Policy and route-table.

Change-Id: I6e9aba3c1a93bee21f2718fa7a96a10ce11cfe01
Implements: blueprint opencontrail-add-extension-support
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/83/145183/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/opencontrail-add-extension-support.rst'],1,270e8ef1b3f27b8fe15d12d3b51cf512f0b55ce9,bp/is,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Opencontrail add extension support ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/opencontrail-add-extension-support This blueprint is pre-requisite to support opencontrail extensions, IPAM, Policy and route-table. This blueprint will load the extension from .ini file. Problem Description =================== Currently, opencontrail plugin support core neutron features. This blueprint will going to add base code to load the opencontrail extensions via ContrailPlugin.ini file. Proposed Change =============== This spec will act as a base for the opencontrail extension blueprint named ipam, policy and route-table. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None Other End User Impact --------------------- None. Performance Impact ------------------ None. IPv6 Impact ----------- None. Other Deployer Impact --------------------- None. Developer Impact ---------------- None. Community Impact ---------------- None. Alternatives ------------ None. Implementation ============== Assignee(s) ----------- Primary assignee: yatinkumbhare-c Work Items ---------- Opencontrail extension support will have base code to load the .ini file. This blueprint is a dependant blueprint for opencontrail extension work. Dependencies ============ None. Testing ======= Unit and integration Tests will be added to cover the necessary. Tempest Tests ------------- None. Functional Tests ---------------- None. API Tests --------- No new API tests are planned as no APIs are changed or introduced as part of this blueprint. Documentation Impact ==================== None. User Documentation ------------------ Opencontrail specific documentation will be updated. Developer Documentation ----------------------- None. References ========== None. ",,153,0
openstack%2Fneutron~master~I883c67c93e85668cd9d90b0486e448d906fdf8ed,openstack/neutron,master,I883c67c93e85668cd9d90b0486e448d906fdf8ed,Make lb mechanism driver use enable_security_group flag,MERGED,2014-12-03 22:00:51.000000000,2015-01-07 23:45:06.000000000,2015-01-07 13:57:48.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 13961}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-12-03 22:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/996638a0db1890cf27c71fc0ddd13e0ebb1a8d97', 'message': 'Make lb mechanism driver use enable_security_group flag\n\nThis patch allows Neutron security groups to be enabled or\ndisabled with the enable_security_group flag when using the\nlinuxbridge ml2 mechanism driver.\n\nCloses-Bug: #1398996\nChange-Id: I883c67c93e85668cd9d90b0486e448d906fdf8ed\n'}, {'number': 2, 'created': '2015-01-07 09:46:01.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_linuxbridge.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cddf3388993539aad450de017070d7902d8ee29f', 'message': 'Make lb mechanism driver use enable_security_group flag\n\nThis patch allows Neutron security groups to be enabled or\ndisabled with the enable_security_group flag when using the\nlinuxbridge ml2 mechanism driver.\n\nCloses-Bug: #1398996\nChange-Id: I883c67c93e85668cd9d90b0486e448d906fdf8ed\n'}]",0,138874,cddf3388993539aad450de017070d7902d8ee29f,52,28,2,2733,,,0,"Make lb mechanism driver use enable_security_group flag

This patch allows Neutron security groups to be enabled or
disabled with the enable_security_group flag when using the
linuxbridge ml2 mechanism driver.

Closes-Bug: #1398996
Change-Id: I883c67c93e85668cd9d90b0486e448d906fdf8ed
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/138874/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/mech_linuxbridge.py'],1,996638a0db1890cf27c71fc0ddd13e0ebb1a8d97,bug/1398996,from neutron.agent import securitygroups_rpc sg_enabled = securitygroups_rpc.is_firewall_enabled() {portbindings.CAP_PORT_FILTER: sg_enabled}), {portbindings.CAP_PORT_FILTER: True}),3,1
openstack%2Fpuppet-keystone~master~I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39,openstack/puppet-keystone,master,I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39,Use openstackclient for keystone_tenant,MERGED,2014-11-17 01:48:29.000000000,2015-01-07 23:43:08.000000000,2015-01-07 14:04:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-11-17 01:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/89e8007d192b0e1b0c27d99eda9d75c29f2f6b92', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 2, 'created': '2014-11-20 19:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/e617ad8d8d3abde0f5d3d195ecc1c6a8e80448df', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 3, 'created': '2014-11-24 19:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/288c649d7bd9aefa1f5dfc101454c95df8a069aa', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 4, 'created': '2014-11-25 00:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/3e8d06547c21685c20ccadf683856fdd88a7c67e', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 5, 'created': '2014-11-25 01:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cbff4311d0dfb2ddfae2b7382d3ca134fb4e26b1', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 6, 'created': '2014-11-26 17:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/215ba0e7e5ba823b48afac014034cde8d7590bcc', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 7, 'created': '2014-12-02 18:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/34fb2bc8d719e779b1811e9b927296b36f8686cd', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 8, 'created': '2014-12-16 22:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/6fbeac162fb3f24f78f4908944c83c465f1ec73b', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 9, 'created': '2014-12-16 23:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/d875268a31ac034e8162fb1937ea6f15d8fb5564', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 10, 'created': '2014-12-16 23:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/e675299c52455b7f503751b07fcb8455e2957f42', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 11, 'created': '2014-12-17 01:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/161342fe5b5f201c2dc1966e7932d39ee601e3d9', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 12, 'created': '2014-12-17 02:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/02026b2b6c2c9bffd9f3eaa5933b5c9a26c090fd', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nThis is a proof of concept, and it should probably not be merged until\nall the providers in the keystone module are similarly migrated.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 13, 'created': '2014-12-17 17:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/e712a6dc5c38de4fec167bf138b92c3ae2ab73fb', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 14, 'created': '2014-12-17 17:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/b7943b4f46ab3a210c77a77ecc0931a11e82ff5e', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 15, 'created': '2014-12-17 18:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/4e255d1b366bc5a92eca045ae710dfac84f8fd51', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 16, 'created': '2014-12-17 23:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/9d24b07f790d0754f0beb337430cde450fb4fd08', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 17, 'created': '2014-12-17 23:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/93f1b3987cd748fbe30152328f5db320aecc6588', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 18, 'created': '2014-12-18 00:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/0563d3e0cc20522022356ad1671157f11dade4ed', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 19, 'created': '2014-12-18 00:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/202953b3a807e7689d3301b9052a18b4bbbc4490', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 20, 'created': '2014-12-18 17:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/3c924f6f6df787cdf7f3294797ba33010ce5443b', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 21, 'created': '2014-12-22 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7e25fe4a4a903f657c29865885c563b03117a862', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 22, 'created': '2014-12-23 18:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cbfb803b89d641e3cd5e4b4fc07cccd3d26a215c', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}, {'number': 23, 'created': '2015-01-05 19:13:17.000000000', 'files': ['spec/unit/provider/keystone_spec.rb', 'spec/unit/provider/keystone_tenant/keystone_spec.rb', 'manifests/init.pp', 'lib/puppet/provider/keystone_tenant/openstack.rb', 'lib/puppet/provider/keystone.rb', 'lib/puppet/provider/keystone_tenant/keystone.rb', 'lib/puppet/util/openstack.rb', 'spec/spec_helper.rb', 'spec/unit/provider/keystone_tenant/openstack_spec.rb', 'spec/unit/provider/openstack_spec.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/provider/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/acf3dc6f06b6dcc5af876517c8511a5225e5e3f6', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n'}]",8,134844,acf3dc6f06b6dcc5af876517c8511a5225e5e3f6,66,5,23,8482,,,0,"Use openstackclient for keystone_tenant

This patch migrates the keystone_tenant provider to use the universal
openstack client instead of the keystone client. It uses the openstack
parent provider in openstacklib to handle multiple authenticating
methods. The keystone_tenant type uses the openstacklib openstack
utility to add a new auth parameter to the keystone_tenant type.

This patch also moves functionality for parsing keystone.conf for the
service token back to the keystone module from openstacklib. It creates
three tiers of inheritance: Keystone_tenant < Keystone < Openstack, so
that keystone-specific functionality can stay in keystone.

It also adds a flush method which should help improve performance.

blueprint use-openstackclient-in-module-resources

Change-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/44/134844/14 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone.rb', 'lib/puppet/provider/keystone_tenant/keystone.rb', 'spec/unit/provider/keystone_tenant/keystone_spec.rb', 'spec/unit/provider/keystone_tenant/openstack_spec.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/provider/keystone_tenant/openstack.rb']",6,89e8007d192b0e1b0c27d99eda9d75c29f2f6b92,openstackclient,"$LOAD_PATH.push(File.join(File.dirname(__FILE__), '..', '..', '..')) require 'json' require 'puppet/provider/keystone' Puppet::Type.type(:keystone_tenant).provide( :openstack, :parent => Puppet::Provider::Keystone ) do def create properties = [] if resource[:enabled] == :true properties << '--enable' elsif resource[:enabled] == :false properties << '--disable' end if resource[:description] properties << '--description' properties << resource[:description] end request('project', 'create', properties, resource[:name], resource[:auth]) end def exists? ! instance(resource[:name]).empty? end def destroy request('project', 'delete', resource[:name], resource[:auth]) end def enabled=(value) if value == :true request('project', 'set', '--enable', resource[:name], resource[:auth]) else request('project', 'set', '--disable', resource[:name], resource[:auth]) end end def enabled bool_to_sym(instance(resource[:name])['Enabled']) end def description=(value) # There is a --description flag for the set command, but it does not # work if the value is empty request('project', 'set', '--property', ""description=#{value}"", resource[:name], resource[:auth]) end def description instance(resource[:name])['Description'] end def id instance(resource[:name])['id'] end def self.instances list = JSON.parse(request('project', 'list', nil, nil)) list.collect do |project| new( :name => project['Name'], :ensure => :present, :enabled => project['Enabled'], :description => project['Description'], :id => project['ID'], ) end end def instances JSON.parse(request('project', 'list', nil, resource[:auth])) end def instance(name) @instances ||= instances.select { |instance| instance['Name'] == name }.first || {} end private # Helper functions to use on the pre-validated enabled field def bool_to_sym(bool) bool == true ? :true : :false end def sym_to_bool(sym) sym == :true ? true : false end end ",,302,212
openstack%2Fnova~master~I1cdef3ed745149a061dfdfff295da63423855d35,openstack/nova,master,I1cdef3ed745149a061dfdfff295da63423855d35,Remove py26 compatibility code,ABANDONED,2014-10-27 19:10:22.000000000,2015-01-07 23:39:36.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-27 19:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51f0ec91d18319cffd44668967756eb93dc6405d', 'message': 'Remove py26 compatibility code\n\nWork in Progress\n\nResolve any comment about py26\n\nChange-Id: I1cdef3ed745149a061dfdfff295da63423855d35\n'}, {'number': 2, 'created': '2014-10-27 21:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8783175ba351bb5d86f29b37e3a58129a37fc1c4', 'message': ""Remove py26 compatibility code\n\nResolve any comment about py26. Now that we don't support py26 having\ncomments explaining that we do X for py26 can lead to confusion.\n\nChange-Id: I1cdef3ed745149a061dfdfff295da63423855d35\n""}, {'number': 3, 'created': '2014-10-28 21:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b341f26d7f42b5591e0166402a4487b986b7cbb', 'message': ""Remove py26 compatibility code\n\nResolve any comment about py26. Now that we don't support py26 having\ncomments explaining that we do X for py26 can lead to confusion.\n\nChange-Id: I1cdef3ed745149a061dfdfff295da63423855d35\n""}, {'number': 4, 'created': '2014-11-13 19:42:50.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/virt/hyperv/vhdutilsv2.py', 'nova/virt/libvirt/driver.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/unit/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ad82798c1bbb4cdfeeb1405e3fd4148ec404e9e8', 'message': ""Remove py26 compatibility code\n\nResolve any comment about py26. Now that we don't support py26 having\ncomments explaining that we do X for py26 can lead to confusion.\n\nChange-Id: I1cdef3ed745149a061dfdfff295da63423855d35\n""}]",9,131248,ad82798c1bbb4cdfeeb1405e3fd4148ec404e9e8,39,14,4,1849,,,0,"Remove py26 compatibility code

Resolve any comment about py26. Now that we don't support py26 having
comments explaining that we do X for py26 can lead to confusion.

Change-Id: I1cdef3ed745149a061dfdfff295da63423855d35
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/131248/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/virt/hyperv/vhdutilsv2.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/image/test_glance.py']",4,51f0ec91d18319cffd44668967756eb93dc6405d,py26,,"import sys # Python 2.6 can not parse ipv6 address correctly @testtools.skipIf(sys.version_info < (2, 7), ""py27 or greater only"")",3,7
openstack%2Foslo.utils~master~Ic3ed252d181c93b8a0db465db6c8c4a7ca97da42,openstack/oslo.utils,master,Ic3ed252d181c93b8a0db465db6c8c4a7ca97da42,Improve performance of strutils.mask_password,MERGED,2015-01-07 19:32:37.000000000,2015-01-07 23:38:55.000000000,2015-01-07 23:38:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 10396}]","[{'number': 1, 'created': '2015-01-07 19:32:37.000000000', 'files': ['tools/perf_test_mask_password.py', 'oslo_utils/strutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/6e0b86164b955a7930cd39dd3c12574f25f1a14e', 'message': ""Improve performance of strutils.mask_password\n\nOnly apply substitution patterns related to key values that appear in\nthe string.\n\nReplace .*? in patterns with more explicit patterns that don't require\nbacktracing.\n\nAdd a performance test script for future testing work, with references\nto large data files that can be downloaded but that we don't want to\ncheck into the source repository because of their sizes.\n\nChange-Id: Ic3ed252d181c93b8a0db465db6c8c4a7ca97da42\nRelated-bug: #1408362\n""}]",0,145562,6e0b86164b955a7930cd39dd3c12574f25f1a14e,16,8,1,2472,,,0,"Improve performance of strutils.mask_password

Only apply substitution patterns related to key values that appear in
the string.

Replace .*? in patterns with more explicit patterns that don't require
backtracing.

Add a performance test script for future testing work, with references
to large data files that can be downloaded but that we don't want to
check into the source repository because of their sizes.

Change-Id: Ic3ed252d181c93b8a0db465db6c8c4a7ca97da42
Related-bug: #1408362
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/62/145562/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/perf_test_mask_password.py', 'oslo_utils/strutils.py']",2,6e0b86164b955a7930cd39dd3c12574f25f1a14e,bug/1408362,"_SANITIZE_PATTERNS_2 = {} _SANITIZE_PATTERNS_1 = {}_FORMAT_PATTERNS_2 = [r'(%(key)s\s*[=]\s*[\""\'])[^\""\']*([\""\'])', r'(%(key)s\s+[\""\'])[^\""\']*([\""\'])', r'(<%(key)s>)[^<]*(</%(key)s>)', r'([\""\']%(key)s[\""\']\s*:\s*[\""\'])[^\""\']*([\""\'])', r'([\'""][^""\']*%(key)s[\'""]\s*:\s*u?[\'""])[^\""\']*' '([\'""])', r'([\'""][^\'""]*%(key)s[\'""]\s*,\s*\'--?[A-z]+\'\s*,\s*u?' '[\'""])[^\""\']*([\'""])',# NOTE(dhellmann): Keep a separate list of patterns by key so we only # need to apply the substitutions for keys we find using a quick ""in"" # test. for key in _SANITIZE_KEYS: _SANITIZE_PATTERNS_1[key] = [] _SANITIZE_PATTERNS_2[key] = [] _SANITIZE_PATTERNS_2[key].append(reg_ex) _SANITIZE_PATTERNS_1[key].append(reg_ex) substitute1 = r'\g<1>' + secret substitute2 = r'\g<1>' + secret + r'\g<2>' for key in _SANITIZE_KEYS: if key in message: for pattern in _SANITIZE_PATTERNS_2[key]: message = re.sub(pattern, substitute2, message) for pattern in _SANITIZE_PATTERNS_1[key]: message = re.sub(pattern, substitute1, message)","_SANITIZE_PATTERNS_2 = [] _SANITIZE_PATTERNS_1 = []_FORMAT_PATTERNS_2 = [r'(%(key)s\s*[=]\s*[\""\']).*?([\""\'])', r'(%(key)s\s+[\""\']).*?([\""\'])', r'(<%(key)s>).*?(</%(key)s>)', r'([\""\']%(key)s[\""\']\s*:\s*[\""\']).*?([\""\'])', r'([\'""].*?%(key)s[\'""]\s*:\s*u?[\'""]).*?([\'""])', r'([\'""].*?%(key)s[\'""]\s*,\s*\'--?[A-z]+\'\s*,\s*u?' '[\'""]).*?([\'""])',for key in _SANITIZE_KEYS: _SANITIZE_PATTERNS_2.append(reg_ex) _SANITIZE_PATTERNS_1.append(reg_ex) if not any(key in message for key in _SANITIZE_KEYS): return message substitute = r'\g<1>' + secret + r'\g<2>' for pattern in _SANITIZE_PATTERNS_2: message = re.sub(pattern, substitute, message) substitute = r'\g<1>' + secret for pattern in _SANITIZE_PATTERNS_1: message = re.sub(pattern, substitute, message)",79,21
openstack%2Fpython-keystoneclient~master~Id89622f7709923814d7dfab72ab4139fee62f2a8,openstack/python-keystoneclient,master,Id89622f7709923814d7dfab72ab4139fee62f2a8,add clear definition of service list,MERGED,2015-01-04 09:30:57.000000000,2015-01-07 23:26:31.000000000,2015-01-07 23:26:31.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 9101}]","[{'number': 1, 'created': '2015-01-04 09:30:57.000000000', 'files': ['keystoneclient/tests/v3/test_services.py', 'keystoneclient/v3/services.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8f878997b499dad057fc83e15c483ff876f1ec18', 'message': 'add clear definition of service list\n\nChange-Id: Id89622f7709923814d7dfab72ab4139fee62f2a8\n'}]",1,144870,8f878997b499dad057fc83e15c483ff876f1ec18,9,4,1,9101,,,0,"add clear definition of service list

Change-Id: Id89622f7709923814d7dfab72ab4139fee62f2a8
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/70/144870/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/v3/test_services.py', 'keystoneclient/v3/services.py']",2,8f878997b499dad057fc83e15c483ff876f1ec18,service_list," def list(self, name=None, type=None, **kwargs): return super(ServiceManager, self).list( name=name, type=type, **kwargs) @utils.positional(enforcement=utils.positional.WARN)",,19,0
openstack%2Fpython-cinderclient~master~I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57,openstack/python-cinderclient,master,I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57,Client output is not sorted by --sort_key,MERGED,2014-12-16 02:45:38.000000000,2015-01-07 23:15:40.000000000,2015-01-07 23:15:39.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 5538}, {'_account_id': 7198}, {'_account_id': 7634}, {'_account_id': 10559}, {'_account_id': 11600}]","[{'number': 1, 'created': '2014-12-16 02:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/af7198e3bc30d759a0fb7eb6b33ec33160159ee2', 'message': ""Client output is not sorted by --sort_key\n\nThe cinder client supports invoking the volumes REST API with the\nsort_dir and sort_key parameters. However, the client output table\nis always sorted by ID even though the REST API is returning in\nsorted order based on the sort key/direction provided.\n\nFor example, the command below supplies the 'size' sort key but the\noutput table is still sorted by ID:\n\ncinder list --sort_key size --sort_dir desc\n\nThis fix contains:\n* Updates to the print_list utility to prevent any re-ordering so\n  that the current object order is maintained\n* Updates to the shell to disable re-ordering if the user supplies\n  sort parameters\n\nChange-Id: I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57\nCloses-Bug: 1402846\n""}, {'number': 2, 'created': '2014-12-17 14:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/5716b7f5f492074b4a451c8caae8f52f445f2ae5', 'message': ""Client output is not sorted by --sort_key\n\nThe cinder client supports invoking the volumes REST API with the\nsort_dir and sort_key parameters. However, the client output table\nis always sorted by ID even though the REST API is returning in\nsorted order based on the sort key/direction provided.\n\nFor example, the command below supplies the 'size' sort key but the\noutput table is still sorted by ID:\n\ncinder list --sort_key size --sort_dir desc\n\nThis fix contains:\n* Updates to the print_list utility to prevent any re-ordering so\n  that the current object order is maintained\n* Updates to the shell to disable re-ordering if the user supplies\n  sort parameters\n\nChange-Id: I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57\nCloses-Bug: 1402846\n""}, {'number': 3, 'created': '2014-12-19 15:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/08cb91e5621939553520c4cb5307c8831d14b029', 'message': ""Client output is not sorted by --sort_key\n\nThe cinder client supports invoking the volumes REST API with the\nsort_dir and sort_key parameters. However, the client output table\nis always sorted by ID even though the REST API is returning in\nsorted order based on the sort key/direction provided.\n\nFor example, the command below supplies the 'size' sort key but the\noutput table is still sorted by ID:\n\ncinder list --sort_key size --sort_dir desc\n\nThis fix contains:\n* Updates to the print_list utility to prevent any re-ordering so\n  that the current object order is maintained\n* Updates to the shell to disable re-ordering if the user supplies\n  sort parameters\n\nChange-Id: I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57\nCloses-Bug: 1402846\n""}, {'number': 4, 'created': '2014-12-22 02:29:38.000000000', 'files': ['cinderclient/tests/test_utils.py', 'cinderclient/tests/v2/test_shell.py', 'cinderclient/v2/shell.py', 'cinderclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b0e4cc1b63911710524005855aeefadc0850f44b', 'message': ""Client output is not sorted by --sort_key\n\nThe cinder client supports invoking the volumes REST API with the\nsort_dir and sort_key parameters. However, the client output table\nis always sorted by ID even though the REST API is returning in\nsorted order based on the sort key/direction provided.\n\nFor example, the command below supplies the 'size' sort key but the\noutput table is still sorted by ID:\n\ncinder list --sort_key size --sort_dir desc\n\nThis fix contains:\n* Updates to the print_list utility to prevent any re-ordering so\n  that the current object order is maintained\n* Updates to the shell to disable re-ordering if the user supplies\n  sort parameters\n\nChange-Id: I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57\nCloses-Bug: 1402846\n""}]",9,141964,b0e4cc1b63911710524005855aeefadc0850f44b,36,9,4,10559,,,0,"Client output is not sorted by --sort_key

The cinder client supports invoking the volumes REST API with the
sort_dir and sort_key parameters. However, the client output table
is always sorted by ID even though the REST API is returning in
sorted order based on the sort key/direction provided.

For example, the command below supplies the 'size' sort key but the
output table is still sorted by ID:

cinder list --sort_key size --sort_dir desc

This fix contains:
* Updates to the print_list utility to prevent any re-ordering so
  that the current object order is maintained
* Updates to the shell to disable re-ordering if the user supplies
  sort parameters

Change-Id: I4cc111a8bdd2b89158dfc4bb0d16fa6dbf36cc57
Closes-Bug: 1402846
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/64/141964/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/test_utils.py', 'cinderclient/tests/v2/test_shell.py', 'cinderclient/v2/shell.py', 'cinderclient/utils.py']",4,af7198e3bc30d759a0fb7eb6b33ec33160159ee2,bug/1404020,"def print_list(objs, fields, formatters={}, sortby_index=0): '''Prints a list of objects. @param objs: Objects to print @param fields: Fields on each object to be printed @param formatters: Custom field formatters @param sortby_index: Results sorted against the key in the fields list at this index; if None the the object order is not altered ''' if sortby_index is None: order_by = None else: order_by = fields[sortby_index]","def print_list(objs, fields, formatters={}, order_by=None): if order_by is None: order_by = fields[0]",70,5
openstack%2Fdevstack~master~I9633446e78cb5af21f61a26f6fb365a8ed57a85f,openstack/devstack,master,I9633446e78cb5af21f61a26f6fb365a8ed57a85f,Fix proper oslo.messaging object for zeromq driver,MERGED,2014-12-21 08:52:45.000000000,2015-01-07 23:05:22.000000000,2015-01-07 23:05:21.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7805}, {'_account_id': 10385}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-12-21 08:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2f1909951fa12f242c5dfc6f06c60a53af4440d8', 'message': 'Fix proper oslo.messaging object for zeromq driver\n\nCurrently, as almost all the rpc driver of projects\nhas been switched to oslo.messaging, the object should\nbe imported via oslo.messaing rather than its own rpc lib.\n\nChange-Id: I9633446e78cb5af21f61a26f6fb365a8ed57a85f\nImplements: blueprint zeromq\nCloses-Bug: #1395721\n'}, {'number': 2, 'created': '2014-12-21 08:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c30566c1d091d0356ee699d10eeddca217065fdb', 'message': 'Fix proper oslo.messaging object for zeromq driver\n\nCurrently, as almost all the rpc driver of projects\nhave been switched to oslo.messaging, the object should\nbe imported via oslo.messaging rather than its own rpc lib.\n\nChange-Id: I9633446e78cb5af21f61a26f6fb365a8ed57a85f\nImplements: blueprint zeromq\nCloses-Bug: #1395721\n'}, {'number': 3, 'created': '2014-12-22 08:41:23.000000000', 'files': ['lib/rpc_backend'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ce1524d0843894b099c4abd20a64f92acad50c55', 'message': 'Fix proper oslo.messaging object for zeromq driver\n\nCurrently, as almost all the rpc driver of projects\nhave been switched to oslo.messaging, the object should\nbe imported via oslo.messaging rather than its own rpc lib.\n\nChange-Id: I9633446e78cb5af21f61a26f6fb365a8ed57a85f\nPartially-Implements: blueprint zeromq\nCloses-Bug: #1395721\n'}]",0,143293,ce1524d0843894b099c4abd20a64f92acad50c55,17,6,3,7805,,,0,"Fix proper oslo.messaging object for zeromq driver

Currently, as almost all the rpc driver of projects
have been switched to oslo.messaging, the object should
be imported via oslo.messaging rather than its own rpc lib.

Change-Id: I9633446e78cb5af21f61a26f6fb365a8ed57a85f
Partially-Implements: blueprint zeromq
Closes-Bug: #1395721
",git fetch https://review.opendev.org/openstack/devstack refs/changes/93/143293/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/rpc_backend'],1,2f1909951fa12f242c5dfc6f06c60a53af4440d8,bp/zeromq," iniset $file $section rpc_backend ""zmq"" oslo.messaging._drivers.matchmaker_redis.MatchMakerRedis", iniset $file $section rpc_backend ${package}.openstack.common.rpc.impl_zmq ${package}.openstack.common.rpc.matchmaker_redis.MatchMakerRedis,2,2
openstack%2Fglance_store~master~I5b356170ec82d033204e22f79c862201400a0a31,openstack/glance_store,master,I5b356170ec82d033204e22f79c862201400a0a31,Define a new parameter to pass CA cert file,MERGED,2014-10-01 12:20:32.000000000,2015-01-07 23:03:43.000000000,2015-01-07 23:03:41.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 1605}, {'_account_id': 1865}, {'_account_id': 2537}, {'_account_id': 2750}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 11356}, {'_account_id': 12000}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-10-01 12:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/2c872e6e4312c3d2e6e12a5f0bcabb55f2ded4e9', 'message': 'Define a new parameter to pass CA cert file\n\nThis change adds a new parameter for the swift store driver that allows\nto speficy the name of the CA cert file to use in the SSL connections for\nverifying certificates. This parameter is passed to the swiftclient in\nthe creation of the connection.\n\nChange-Id: I5b356170ec82d033204e22f79c862201400a0a31\nCloses-bug: 1375857\n'}, {'number': 2, 'created': '2014-11-10 12:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/42469b0229b5912c90d713abe24be1bc9abadaff', 'message': 'Define a new parameter to pass CA cert file\n\nThis change adds a new parameter for the swift store driver that allows\nto speficy the name of the CA cert file to use in the SSL connections for\nverifying certificates. This parameter is passed to the swiftclient in\nthe creation of the connection.\n\nChange-Id: I5b356170ec82d033204e22f79c862201400a0a31\nCloses-bug: 1375857\n'}, {'number': 3, 'created': '2014-12-02 10:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/85719c4cbf66b8573ed4ff2ee5a8c1812fc2779f', 'message': 'Define a new parameter to pass CA cert file\n\nThis change adds a new parameter for the swift store driver that allows\nto speficy the name of the CA cert file to use in the SSL connections for\nverifying certificates. This parameter is passed to the swiftclient in\nthe creation of the connection.\n\nChange-Id: I5b356170ec82d033204e22f79c862201400a0a31\nCloses-bug: 1375857\n'}, {'number': 4, 'created': '2015-01-06 17:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/f4d254beed5fa1fdcf5b1f5901ea6acb7e5a2378', 'message': 'Define a new parameter to pass CA cert file\n\nThis change adds a new parameter for the swift store driver that allows\nto speficy the name of the CA cert file to use in the SSL connections for\nverifying certificates. This parameter is passed to the swiftclient in\nthe creation of the connection. The parameter is called ""swift_store_cacert"".\n\nChange-Id: I5b356170ec82d033204e22f79c862201400a0a31\nCloses-bug: 1375857\nDocImpact\n'}, {'number': 5, 'created': '2015-01-06 22:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/46a0330b4b5e10f81ed32b15d8e8c2fe66924bae', 'message': 'Define a new parameter to pass CA cert file\n\nThis change adds a new parameter for the swift store driver that allows\nto speficy the name of the CA cert file to use in the SSL connections for\nverifying certificates. This parameter is passed to the swiftclient in\nthe creation of the connection. The parameter is called ""swift_store_cacert"". This change corresponds to change\nI4cbfae3c1ac84d6c85875d34a58dd2a87ae85d6f in glance.\n\nChange-Id: I5b356170ec82d033204e22f79c862201400a0a31\nCloses-bug: 1375857\nDocImpact\n'}, {'number': 6, 'created': '2015-01-06 22:37:21.000000000', 'files': ['glance_store/_drivers/swift/store.py', 'tests/unit/test_swift_store.py', 'tests/unit/test_opts.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/6b2cdbf4e608e38a6471093c77e5dd5792ab8532', 'message': 'Define a new parameter to pass CA cert file\n\nThis change adds a new parameter for the swift store driver that allows\nto speficy the name of the CA cert file to use in the SSL connections for\nverifying certificates. This parameter is passed to the swiftclient in\nthe creation of the connection. The parameter is called ""swift_store_cacert"".\nThis change corresponds to change\nI4cbfae3c1ac84d6c85875d34a58dd2a87ae85d6f in glance.\n\nChange-Id: I5b356170ec82d033204e22f79c862201400a0a31\nCloses-bug: 1375857\nDocImpact\n'}]",2,125338,6b2cdbf4e608e38a6471093c77e5dd5792ab8532,46,12,6,1865,,,0,"Define a new parameter to pass CA cert file

This change adds a new parameter for the swift store driver that allows
to speficy the name of the CA cert file to use in the SSL connections for
verifying certificates. This parameter is passed to the swiftclient in
the creation of the connection. The parameter is called ""swift_store_cacert"".
This change corresponds to change
I4cbfae3c1ac84d6c85875d34a58dd2a87ae85d6f in glance.

Change-Id: I5b356170ec82d033204e22f79c862201400a0a31
Closes-bug: 1375857
DocImpact
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/38/125338/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance_store/_drivers/swift/store.py', 'tests/unit/test_swift_store.py', 'tests/unit/test_opts.py']",3,2c872e6e4312c3d2e6e12a5f0bcabb55f2ded4e9,bug/1375857," 'swift_store_auth_cacert',",,12,3
openstack%2Fcinder~master~Idcd88de9c5e8a096f0ef473e92bff17e6be16814,openstack/cinder,master,Idcd88de9c5e8a096f0ef473e92bff17e6be16814,Fix argument order in assertEqual: tests/test_glusterfs.py,MERGED,2015-01-06 05:49:57.000000000,2015-01-07 22:55:35.000000000,2015-01-07 22:55:34.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12779}, {'_account_id': 13900}]","[{'number': 1, 'created': '2015-01-06 05:49:57.000000000', 'files': ['cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f743605fa3dae8f57003e50fa50c864a89e8c3b2', 'message': 'Fix argument order in assertEqual: tests/test_glusterfs.py\n\nThe assertEqual in cinder/tests/test_glusterfs.py is using\nincorrect argument order (observed, expected), which causes the\nerror message about mismatch to be reversed if the test case fails.\nChange it to (expected, observed).\n\nChange-Id: Idcd88de9c5e8a096f0ef473e92bff17e6be16814\nPartial-Bug: #1259292\n'}]",0,145133,f743605fa3dae8f57003e50fa50c864a89e8c3b2,16,12,1,14428,,,0,"Fix argument order in assertEqual: tests/test_glusterfs.py

The assertEqual in cinder/tests/test_glusterfs.py is using
incorrect argument order (observed, expected), which causes the
error message about mismatch to be reversed if the test case fails.
Change it to (expected, observed).

Change-Id: Idcd88de9c5e8a096f0ef473e92bff17e6be16814
Partial-Bug: #1259292
",git fetch https://review.opendev.org/openstack/cinder refs/changes/33/145133/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_glusterfs.py'],1,f743605fa3dae8f57003e50fa50c864a89e8c3b2,bug/1259292," self.assertEqual(expected, mock_execute.mock_calls) self.assertEqual(expected, mock_execute.mock_calls) self.assertEqual(expected, mock_execute.mock_calls) self.assertEqual(expected, mock_execute.mock_calls) self.assertEqual(hashed_path, result) self.assertEqual((df_avail, df_total_size), result) self.assertEqual(2, len(drv.shares)) self.assertEqual(self.TEST_EXPORT2_OPTIONS, drv.shares[self.TEST_EXPORT2]) self.assertEqual(expected, mock_execute.mock_calls) self.assertEqual('volume-%s' % self.VOLUME_UUID, info[self.VOLUME_UUID]) self.assertEqual(vol_filename_2, item_1['filename']) self.assertEqual(vol_filename_3, item_2['filename']) self.assertEqual(1, len(chain)) self.assertEqual(vol_filename, chain[0]['filename']) self.assertEqual('raw', conn_info['data']['format']) self.assertEqual('glusterfs', conn_info['driver_volume_type']) self.assertEqual(volume['name'], conn_info['data']['name']) self.assertEqual(self.TEST_MNT_POINT_BASE, conn_info['mount_point_base']) self.assertEqual(self.TEST_MNT_POINT_BASE, drv._get_mount_point_base()) self.assertEqual(1, mock_create_temporary_file.call_count)"," self.assertEqual(mock_execute.mock_calls, expected) self.assertEqual(mock_execute.mock_calls, expected) self.assertEqual(mock_execute.mock_calls, expected) self.assertEqual(mock_execute.mock_calls, expected) self.assertEqual(result, hashed_path) self.assertEqual(result, (df_avail, df_total_size)) self.assertEqual(len(drv.shares), 2) self.assertEqual(drv.shares[self.TEST_EXPORT2], self.TEST_EXPORT2_OPTIONS) self.assertEqual(mock_execute.mock_calls, expected) self.assertEqual(info[self.VOLUME_UUID], 'volume-%s' % self.VOLUME_UUID) self.assertEqual(item_1['filename'], vol_filename_2) self.assertEqual(item_2['filename'], vol_filename_3) self.assertEqual(len(chain), 1) self.assertEqual(chain[0]['filename'], vol_filename) self.assertEqual(conn_info['data']['format'], 'raw') self.assertEqual(conn_info['driver_volume_type'], 'glusterfs') self.assertEqual(conn_info['data']['name'], volume['name']) self.assertEqual(conn_info['mount_point_base'], self.TEST_MNT_POINT_BASE) self.assertEqual(drv._get_mount_point_base(), self.TEST_MNT_POINT_BASE) self.assertEqual(mock_create_temporary_file.call_count, 1)",24,24
openstack%2Fmanila~master~I4aa8e84659ae428c5155a81c2ff6aab710a7832e,openstack/manila,master,I4aa8e84659ae428c5155a81c2ff6aab710a7832e,Fix handling of share-networks with single_svm drivers,MERGED,2014-12-29 18:52:25.000000000,2015-01-07 22:53:01.000000000,2015-01-07 22:53:00.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-29 18:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/63b515a1873266bc2adebc1fe1bfdb0c8d16d807', 'message': ""[WIP] Implement single SVM mode for Generic driver\n\nAdd possibility to run Generic driver in single SVM mode. It allows us\nto create shares without share-networks defined on one specific Nova VM.\n\nAdded three (3) new config options that are used only with single SVM mode:\n- 'service_instance_name_or_id' expects string with name or id of Nova VM.\n- 'service_net_name_or_ip' expects name of network that Nova VM is switched to\n  or IP itself. Used for handle operation of share.\n- 'tenant_net_name_or_ip' expects name of network that Nova VM is switched to\n  or IP itself. Used for exporting share to end users.\n\nAll three new config option are required if single SVM mode is enabled.\nIf multi SVM mode is enabled they will be skipped.\n\nSet config opt 'share_driver_mode' within devstack by default because in case\nof Generic driver it becomes required. It is set to 'multi_svm' for\ncompatibility with existing Tempest jobs.\n\nIt is now mandatory to set up config opt 'share_driver_mode' for Generic\ndriver, because it now supports more than one mode.\n\nTODO: add/update unit tests\n\nImplements bp single-svm-mode-for-generic-driver\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\n""}, {'number': 2, 'created': '2015-01-05 18:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/10ddb835f5b1c6e7ab46ed98ca94d4df4212a42a', 'message': ""[WIP] Implement single SVM mode for Generic driver\n\nAdd possibility to run Generic driver in single SVM mode. It allows us\nto create shares without share-networks defined on one specific Nova VM.\n\nAdded three (3) new config options that are used only with single SVM mode:\n- 'service_instance_name_or_id' expects string with name or id of Nova VM.\n- 'service_net_name_or_ip' expects name of network that Nova VM is switched to\n  or IP itself. Used for handle operation of share.\n- 'tenant_net_name_or_ip' expects name of network that Nova VM is switched to\n  or IP itself. Used for exporting share to end users.\n\nAll three new config options are required if single SVM mode is enabled.\nIf multi SVM mode is enabled they will be skipped.\n\nSet config opt 'share_driver_mode' within devstack by default because in case\nof Generic driver it becomes required. It is set to 'multi_svm' for\ncompatibility with existing Tempest jobs.\n\nTODO: add/update unit tests\n\nImplements bp single-svm-mode-for-generic-driver\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\n""}, {'number': 3, 'created': '2015-01-05 19:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cb5a0b178a753d19e1a8476396132413f40a218c', 'message': ""[WIP] Implement single SVM mode for Generic driver\n\nAdd possibility to run Generic driver in single SVM mode. It allows us\nto create shares without share-networks defined on one specific Nova VM.\n\nAdded three (3) new config options that are used only with single SVM mode:\n- 'service_instance_name_or_id' expects string with name or id of Nova VM.\n- 'service_net_name_or_ip' expects name of network that Nova VM is switched to\n  or IP itself. Used for handle operation of share.\n- 'tenant_net_name_or_ip' expects name of network that Nova VM is switched to\n  or IP itself. Used for exporting share to end users.\n\nAll three new config options are required if single SVM mode is enabled.\nIf multi SVM mode is enabled they will be skipped.\n\nSet config opt 'share_driver_mode' within devstack by default because in case\nof Generic driver it becomes required. It is set to 'multi_svm' for\ncompatibility with existing Tempest jobs.\n\nTODO: add/update unit tests\n\nImplements bp single-svm-mode-for-generic-driver\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\n""}, {'number': 4, 'created': '2015-01-06 10:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/caa277ca5ba65c270bd9037e46a02d39cb5de8ac', 'message': 'Fix handling of share-networks with single_svm drivers\n\nIf we create share with share driver that is enabled with ""single_svm"" mode\nand provide share network, entity of ""share server"" will be created and status\n""ACTIVE"" will be set to it, because driver\'s interface of share-server creation\nwill return ""Ok"".\nSo, raise error before share server creation if share network provided using\n""single_svm"" mode with any share driver.\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\nCloses-Bug: #1407923\n'}, {'number': 5, 'created': '2015-01-06 11:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cb411814a2871ee0bf1a07bcbe1fc315aa508038', 'message': 'Fix handling of share-networks with single_svm drivers\n\nIf we create share with share driver that is enabled with ""single_svm"" mode\nand provide share network, entity of ""share server"" will be created and status\n""ACTIVE"" will be set to it, because driver\'s interface of share-server creation\nwill return ""Ok"".\nSo, raise error before share server creation if share network provided using\n""single_svm"" mode with any share driver.\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\nCloses-Bug: #1407923\n'}, {'number': 6, 'created': '2015-01-06 18:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/577e5b788ea5776ea109bc71b588ed308c0b59d2', 'message': 'Fix handling of share-networks with single_svm drivers\n\nIf we create share with share driver that is enabled with ""single_svm"" mode\nand provide share network, entity of ""share server"" will be created and status\n""ACTIVE"" will be set to it, because driver\'s interface of share-server creation\nwill return ""Ok"".\nSo, raise error before share server creation if share network provided using\n""single_svm"" mode with any share driver.\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\nCloses-Bug: #1407923\n'}, {'number': 7, 'created': '2015-01-07 21:15:38.000000000', 'files': ['manila/share/manager.py', 'manila/tests/share/test_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/96ba32011ac5b4d591880cfc87a5737918f68e9e', 'message': 'Fix handling of share-networks with single_svm drivers\n\nIf we create share with share driver that is enabled with ""single_svm"" mode\nand provide share network, entity of ""share server"" will be created and status\n""ACTIVE"" will be set to it, because driver\'s interface of share-server creation\nwill return ""Ok"".\nSo, raise error before share server creation if share network provided using\n""single_svm"" mode with any share driver.\n\nChange-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e\nCloses-Bug: #1407923\n'}]",3,144342,96ba32011ac5b4d591880cfc87a5737918f68e9e,29,9,7,8851,,,0,"Fix handling of share-networks with single_svm drivers

If we create share with share driver that is enabled with ""single_svm"" mode
and provide share network, entity of ""share server"" will be created and status
""ACTIVE"" will be set to it, because driver's interface of share-server creation
will return ""Ok"".
So, raise error before share server creation if share network provided using
""single_svm"" mode with any share driver.

Change-Id: I4aa8e84659ae428c5155a81c2ff6aab710a7832e
Closes-Bug: #1407923
",git fetch https://review.opendev.org/openstack/manila refs/changes/42/144342/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/service_instance.py', 'manila/compute/nova.py', 'manila/share/drivers/generic.py', 'contrib/devstack/lib/manila']",4,63b515a1873266bc2adebc1fe1bfdb0c8d16d807,bug/1407923,MANILA_SHARE_BACKEND1_DRIVER_MODE=${MANILA_SHARE_BACKEND1_DRIVER_MODE=:-multi_svm}MANILA_SHARE_BACKEND2_DRIVER_MODE=${MANILA_SHARE_BACKEND2_DRIVER_MODE=:-multi_svm} iniset $MANILA_CONF $group_name share_driver_mode $MANILA_SHARE_BACKEND1_DRIVER_MODE iniset $MANILA_CONF $group_name share_driver_mode $MANILA_SHARE_BACKEND2_DRIVER_MODE,,157,59
openstack%2Fpuppet-keystone~master~Iba420322e21c2aadeeadc5568ce15e0adcd89f19,openstack/puppet-keystone,master,Iba420322e21c2aadeeadc5568ce15e0adcd89f19,Use openstackclient for keystone_user_role,MERGED,2014-12-22 07:32:00.000000000,2015-01-07 22:46:19.000000000,2015-01-07 22:46:18.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-12-22 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a6e778b09e5100b39160bddaca591bd59dc7cb34', 'message': 'Use openstackclient for keystone_user_role\n\nChange-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 2, 'created': '2014-12-23 18:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/5f13a90618b6debc61a5fba5326cf50e6339643c', 'message': 'Use openstackclient for keystone_user_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 3, 'created': '2015-01-05 19:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c099ca76cf7e3e35e526623324e0cd0f446aad11', 'message': 'Use openstackclient for keystone_user_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 4, 'created': '2015-01-07 21:05:41.000000000', 'files': ['spec/unit/provider/keystone_user_role/keystone_spec.rb', 'lib/puppet/provider/keystone_user_role/keystone.rb', 'lib/puppet/provider/keystone_user_role/openstack.rb', 'lib/puppet/type/keystone_user_role.rb', 'spec/unit/provider/keystone_user_role/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/80ab6d86a5e286e087e9352231b13f7fab41d7bd', 'message': 'Use openstackclient for keystone_user_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}]",0,143384,80ab6d86a5e286e087e9352231b13f7fab41d7bd,25,5,4,8482,,,0,"Use openstackclient for keystone_user_role

blueprint use-openstackclient-in-module-resources

Change-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19
Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/84/143384/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user_role/keystone_spec.rb', 'lib/puppet/provider/keystone_user_role/keystone.rb', 'lib/puppet/provider/keystone_user_role/openstack.rb', 'lib/puppet/type/keystone_user_role.rb', 'spec/unit/provider/keystone_user_role/openstack_spec.rb']",5,a6e778b09e5100b39160bddaca591bd59dc7cb34,openstackclient,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_user_role/openstack' provider_class = Puppet::Type.type(:keystone_user_role).provider(:openstack) describe provider_class do describe 'when updating a user\'s role' do let(:user_role_attrs) do { :name => 'foo@example.com@foo', :ensure => 'present', :roles => ['foo', 'bar'], :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_user_role.new(user_role_attrs) end let(:provider) do provider_class.new(resource) end before(:each) do provider.class.stubs(:openstack) .with('user', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo@example.com"" ') provider.class.stubs(:openstack) .with('project', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') end describe '#create' do it 'adds all the roles to the user' do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo@example.com"" ""1cb05cfed7c24279be884ba4f6520263"",""bar"",""foo"",""foo@example.com"" ') provider.class.stubs(:openstack) .with('role', 'add', [['foo', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.class.stubs(:openstack) .with('role', 'add', [['bar', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'removes all the roles from a user' do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User""') provider.class.stubs(:openstack) .with('role', 'remove', [['foo', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.class.stubs(:openstack) .with('role', 'remove', [['bar', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do subject(:response) do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User"" ""1cb05ed7c24279be884ba4f6520262"",""foo"",""foo"",""foo@example.com"" ""1cb05ed7c24279be884ba4f6520262"",""bar"",""foo"",""foo@example.com"" ') response = provider.exists? end it { is_expected.to be_truthy } end end end ",,255,288
openstack%2Fproject-config~master~Ie713482acbd454eeb58c3481e8b8820049daaab8,openstack/project-config,master,Ie713482acbd454eeb58c3481e8b8820049daaab8,Correct revoke-sudo to actually work,MERGED,2015-01-07 21:47:40.000000000,2015-01-07 22:37:44.000000000,2015-01-07 22:37:43.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2015-01-07 21:47:40.000000000', 'files': ['jenkins/jobs/macros.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/64f23c918b9f43f6ab421dcbfdef4cd055c0f0cc', 'message': 'Correct revoke-sudo to actually work\n\n* jenkins/jobs/macros.yaml(revoke-sudo): Simplify the sudoers\ninclude file deletion to not rely on a conditional check, and then\ntest that it actually worked. Previously, systems where\n/etc/sudoers.d was non-world-readable caused it to be a silent\nno-op.\n\nChange-Id: Ie713482acbd454eeb58c3481e8b8820049daaab8\n'}]",0,145599,64f23c918b9f43f6ab421dcbfdef4cd055c0f0cc,8,4,1,5263,,,0,"Correct revoke-sudo to actually work

* jenkins/jobs/macros.yaml(revoke-sudo): Simplify the sudoers
include file deletion to not rely on a conditional check, and then
test that it actually worked. Previously, systems where
/etc/sudoers.d was non-world-readable caused it to be a silent
no-op.

Change-Id: Ie713482acbd454eeb58c3481e8b8820049daaab8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/99/145599/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/macros.yaml'],1,64f23c918b9f43f6ab421dcbfdef4cd055c0f0cc,revoke-sudo, #!/bin/bash -x sudo rm -f /etc/sudoers.d/jenkins-sudo # Prove that general sudo access is actually revoked ! sudo -n true, #!/bin/bash if [ -f /etc/sudoers.d/jenkins-sudo ] ; then sudo rm /etc/sudoers.d/jenkins-sudo fi,4,4
openstack%2Fopenstack-ansible~stable%2Ficehouse~I869b88cfe1bb8237f24d1e058ee7aac64806e230,openstack/openstack-ansible,stable/icehouse,I869b88cfe1bb8237f24d1e058ee7aac64806e230,Prevent user from accessing privileged files,ABANDONED,2015-01-07 20:28:25.000000000,2015-01-07 22:34:33.000000000,,"[{'_account_id': 3}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 20:28:25.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/69ca3a9acb2afad99b3fc2b53939e4cb52b42d6a', 'message': 'Prevent user from accessing privileged files\n\nCloses-bug: 1400966\nRelated to OSSA-2014-041\nCVE-2014-9493\n\nChange-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230\n(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)\n'}]",0,145573,69ca3a9acb2afad99b3fc2b53939e4cb52b42d6a,5,3,1,12000,,,0,"Prevent user from accessing privileged files

Closes-bug: 1400966
Related to OSSA-2014-041
CVE-2014-9493

Change-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230
(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/73/145573/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,69ca3a9acb2afad99b3fc2b53939e4cb52b42d6a,bug/1400966," ""delete_image_location"": ""role:admin"", ""set_image_location"": ""role:admin"","," ""delete_image_location"": """", ""set_image_location"": """",",2,2
openstack%2Fdevstack~master~If132a94e53545d9134859aa508da7b9819ede2f8,openstack/devstack,master,If132a94e53545d9134859aa508da7b9819ede2f8,Clear multi-line sections before adding lines,MERGED,2014-12-13 19:02:37.000000000,2015-01-07 22:32:16.000000000,2015-01-07 22:32:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 10385}, {'_account_id': 10850}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-13 19:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f34742fc89de117ac37d55fb9bdafa65813d9b10', 'message': 'Clear multi-line sections before adding lines\n\nWith multiline support for local.conf, the first line is created with\niniset, which will set *all* previous lines to the same thing, and then\nsubsequent lines will be added. Modify the multiline support to first\nclear existing lines from the section.\n\nChange-Id: If132a94e53545d9134859aa508da7b9819ede2f8\n'}, {'number': 2, 'created': '2014-12-15 01:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d48a3372358a1560dab1697bc2ac95cdb73a5f76', 'message': 'Clear multi-line sections before adding lines\n\nWith multiline support for local.conf, the first line is created with\niniset, which will set *all* previous lines to the same thing, and then\nsubsequent lines will be added. Modify the multiline support to first\nclear existing lines from the section.\n\nChange-Id: If132a94e53545d9134859aa508da7b9819ede2f8\n'}, {'number': 3, 'created': '2014-12-15 02:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7271caf8d69724a25494ecc372c4d1b1f965fc00', 'message': 'Clear multi-line sections before adding lines\n\nWith multiline support for local.conf, the first line is created with\niniset, which will set *all* previous lines to the same thing, and then\nsubsequent lines will be added. Modify the multiline support to first\nclear existing lines from the section.\n\nThis causes fatal errors with neutron.conf, which defines drivers with a bunch\nof service_provider= options, and the current code ends up with the first\ndriver defined in local.conf being present twice.\n\nChange-Id: If132a94e53545d9134859aa508da7b9819ede2f8\n'}, {'number': 4, 'created': '2014-12-15 03:50:23.000000000', 'files': ['tests/test_ini.sh', 'functions-common', 'lib/config'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1f65fd64ce2f4ed32a706f9bcb28c2ee0cf51e5b', 'message': 'Clear multi-line sections before adding lines\n\nWith multiline support for local.conf, the first line is created with\niniset, which will set *all* previous lines to the same thing, and then\nsubsequent lines will be added. Modify the multiline support to first\nclear existing lines from the section.\n\nThis causes fatal errors with neutron.conf, which defines drivers with a bunch\nof service_provider= options, and the current code ends up with the first\ndriver defined in local.conf being present twice.\n\nChange-Id: If132a94e53545d9134859aa508da7b9819ede2f8\n'}]",0,141573,1f65fd64ce2f4ed32a706f9bcb28c2ee0cf51e5b,24,7,4,10980,,,0,"Clear multi-line sections before adding lines

With multiline support for local.conf, the first line is created with
iniset, which will set *all* previous lines to the same thing, and then
subsequent lines will be added. Modify the multiline support to first
clear existing lines from the section.

This causes fatal errors with neutron.conf, which defines drivers with a bunch
of service_provider= options, and the current code ends up with the first
driver defined in local.conf being present twice.

Change-Id: If132a94e53545d9134859aa508da7b9819ede2f8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/73/141573/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions-common', 'lib/config']",2,f34742fc89de117ac37d55fb9bdafa65813d9b10,," print ""inidelete "" configfile "" "" section "" "" attr",,16,0
openstack%2Fheat~master~I5e25425688481e1c1910278b32caa7d479aeb1f8,openstack/heat,master,I5e25425688481e1c1910278b32caa7d479aeb1f8,Account for nested stack validation in ResourceGroup,ABANDONED,2015-01-07 21:12:09.000000000,2015-01-07 22:31:15.000000000,,"[{'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}]","[{'number': 1, 'created': '2015-01-07 21:12:09.000000000', 'files': ['heat/engine/resources/resource_group.py', 'heat/engine/properties.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/970ec464532217e5635a856f6833416356ddd9c0', 'message': 'Account for nested stack validation in ResourceGroup\n\nDue to the changes in StackResource, no special validation is\nneeded in ResourceGroup anymore given that the parent class\nvalidates the nested template and also therefore accounts for\n0-count groups.\n\nPartial-Bug: #1407100\nChange-Id: I5e25425688481e1c1910278b32caa7d479aeb1f8\n'}]",0,145589,970ec464532217e5635a856f6833416356ddd9c0,2,3,1,7256,,,0,"Account for nested stack validation in ResourceGroup

Due to the changes in StackResource, no special validation is
needed in ResourceGroup anymore given that the parent class
validates the nested template and also therefore accounts for
0-count groups.

Partial-Bug: #1407100
Change-Id: I5e25425688481e1c1910278b32caa7d479aeb1f8
",git fetch https://review.opendev.org/openstack/heat refs/changes/89/145589/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/resource_group.py', 'heat/engine/properties.py']",2,970ec464532217e5635a856f6833416356ddd9c0,bug/1407100, if len(list(deps)) > 0: return True return False, return len(list(deps)) > 0,10,17
openstack%2Fopenstack-ansible~stable%2Fjuno~I869b88cfe1bb8237f24d1e058ee7aac64806e230,openstack/openstack-ansible,stable/juno,I869b88cfe1bb8237f24d1e058ee7aac64806e230,Prevent user from accessing privileged files,ABANDONED,2015-01-07 20:29:16.000000000,2015-01-07 22:09:44.000000000,,"[{'_account_id': 3}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 20:29:16.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/daa161b1f9cef514b602f682b8f7d6341aa57d9f', 'message': 'Prevent user from accessing privileged files\n\nCloses-bug: 1400966\nRelated to OSSA-2014-041\nCVE-2014-9493\n\nChange-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230\n(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)\n'}]",0,145575,daa161b1f9cef514b602f682b8f7d6341aa57d9f,5,3,1,12000,,,0,"Prevent user from accessing privileged files

Closes-bug: 1400966
Related to OSSA-2014-041
CVE-2014-9493

Change-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230
(cherry picked from commit 233a71022e0ee90ddacc05126a0bc7265c1ad166)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/75/145575/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,daa161b1f9cef514b602f682b8f7d6341aa57d9f,bug/1400966," ""delete_image_location"": ""role:admin"", ""set_image_location"": ""role:admin"","," ""delete_image_location"": """", ""set_image_location"": """",",2,2
openstack%2Fmanila~master~I807b64418382d2a6dcc211aee06aaab4c00a681f,openstack/manila,master,I807b64418382d2a6dcc211aee06aaab4c00a681f,Imported Translations from Transifex,MERGED,2015-01-01 06:11:08.000000000,2015-01-07 21:47:12.000000000,2015-01-07 21:47:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-01-01 06:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/eaf0e31a3e819b751df53358587b9798b8dae561', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}, {'number': 2, 'created': '2015-01-02 06:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ee4aa106e098da8a976219e94a6d2791783f55e1', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}, {'number': 3, 'created': '2015-01-03 06:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ee3520457473cb2a04ea59179765f952a62de9b9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}, {'number': 4, 'created': '2015-01-04 06:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ab16b72f31aeca368c8cff5ff59e88b488533873', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}, {'number': 5, 'created': '2015-01-05 06:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/53118c5698b70d01e9b3569c8ce90a0c0437641c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}, {'number': 6, 'created': '2015-01-06 06:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c426e4066849e1c9f4f9ec3a115207f06d39285c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}, {'number': 7, 'created': '2015-01-07 06:12:37.000000000', 'files': ['manila/locale/manila.pot', 'manila/locale/manila-log-info.pot', 'manila/locale/manila-log-warning.pot', 'manila/locale/de/LC_MESSAGES/manila-log-error.po', 'manila/locale/manila-log-error.pot'], 'web_link': 'https://opendev.org/openstack/manila/commit/9e3c025c62302658e3243d9b82ab1dc1d423bbdb', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f\n'}]",0,144674,9e3c025c62302658e3243d9b82ab1dc1d423bbdb,35,5,7,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I807b64418382d2a6dcc211aee06aaab4c00a681f
",git fetch https://review.opendev.org/openstack/manila refs/changes/74/144674/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila/locale/manila.pot', 'manila/locale/manila-log-info.pot', 'manila/locale/manila-log-warning.pot', 'manila/locale/de/LC_MESSAGES/manila-log-error.po', 'manila/locale/manila-log-error.pot']",5,eaf0e31a3e819b751df53358587b9798b8dae561,transifex/translations,"# Copyright (C) 2015 ORGANIZATION# FIRST AUTHOR <EMAIL@ADDRESS>, 2015.""Project-Id-Version: manila 2015.1.dev44\n""""POT-Creation-Date: 2015-01-01 06:11+0000\n""#: manila/share/drivers/emc/plugins/vnx/helper.py:89#: manila/share/drivers/emc/plugins/vnx/helper.py:1159","# Copyright (C) 2014 ORGANIZATION# FIRST AUTHOR <EMAIL@ADDRESS>, 2014.""Project-Id-Version: manila 2015.1.dev9\n""""POT-Creation-Date: 2014-12-20 06:12+0000\n""#: manila/openstack/common/lockutils.py:117 #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr """" #: manila/share/drivers/emc/plugins/vnx/helper.py:90#: manila/share/drivers/emc/plugins/vnx/helper.py:1160",52,91
openstack%2Fmanila~master~Iedff2bad44e9d55d7e0c1cab0eee24ec9ffdccd0,openstack/manila,master,Iedff2bad44e9d55d7e0c1cab0eee24ec9ffdccd0,Fix nit in tempest naming,MERGED,2015-01-02 16:03:32.000000000,2015-01-07 21:47:05.000000000,2015-01-07 21:47:04.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8623}, {'_account_id': 11878}, {'_account_id': 13634}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-01-02 16:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d485be8818ef1cee7741f330aa8f6f3eb9b1d374', 'message': ""Fix nit in tempest naming\n\nReplace 'porject_ip' with 'project_id' in name of Tempest test.\n\nChange-Id: Iedff2bad44e9d55d7e0c1cab0eee24ec9ffdccd0\n""}, {'number': 2, 'created': '2015-01-07 16:34:40.000000000', 'files': ['contrib/tempest/tempest/api/share/admin/test_share_networks.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/930873909958fb6e4114b27f3b5c877001046a91', 'message': ""Fix nit in tempest naming\n\nReplace 'porject_ip' with 'project_id' in name of Tempest test.\n\nChange-Id: Iedff2bad44e9d55d7e0c1cab0eee24ec9ffdccd0\n""}]",0,144768,930873909958fb6e4114b27f3b5c877001046a91,15,9,2,8851,,,0,"Fix nit in tempest naming

Replace 'porject_ip' with 'project_id' in name of Tempest test.

Change-Id: Iedff2bad44e9d55d7e0c1cab0eee24ec9ffdccd0
",git fetch https://review.opendev.org/openstack/manila refs/changes/68/144768/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/admin/test_share_networks.py'],1,d485be8818ef1cee7741f330aa8f6f3eb9b1d374,, def test_list_share_networks_filter_by_project_id(self):, def test_list_share_networks_filter_by_porject_ip(self):,1,1
openstack%2Fmanila~master~I5aa77eb9c45a12e7e4d467eebb90487709cbe197,openstack/manila,master,I5aa77eb9c45a12e7e4d467eebb90487709cbe197,Set pbr 'warnerrors' option for doc build,MERGED,2015-01-07 16:46:58.000000000,2015-01-07 21:46:27.000000000,2015-01-07 21:46:26.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}]","[{'number': 1, 'created': '2015-01-07 16:46:58.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/manila/commit/1d4fb90e10061ce870ac90e8b51611adc11601e6', 'message': ""Set pbr 'warnerrors' option for doc build\n\nBy setting this pbr option in setup.cfg, the doc build will fail in\ncase of any warnings or errors occur during the build process.\n\nChange-Id: I5aa77eb9c45a12e7e4d467eebb90487709cbe197\n""}]",0,145539,1d4fb90e10061ce870ac90e8b51611adc11601e6,11,3,1,7102,,,0,"Set pbr 'warnerrors' option for doc build

By setting this pbr option in setup.cfg, the doc build will fail in
case of any warnings or errors occur during the build process.

Change-Id: I5aa77eb9c45a12e7e4d467eebb90487709cbe197
",git fetch https://review.opendev.org/openstack/manila refs/changes/39/145539/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,1d4fb90e10061ce870ac90e8b51611adc11601e6,144233, [pbr] warnerrors = true,,3,0
openstack%2Foslo.messaging~master~I7ad29b0adcffb138647b06f1e7d760cb3750771f,openstack/oslo.messaging,master,I7ad29b0adcffb138647b06f1e7d760cb3750771f,TEST,ABANDONED,2015-01-07 13:29:08.000000000,2015-01-07 21:29:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-07 13:29:08.000000000', 'files': ['oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/rpc/client.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1de1ade843b0c3c834152d8aa00c714960faf51c', 'message': 'TEST\n\nChange-Id: I7ad29b0adcffb138647b06f1e7d760cb3750771f\n'}]",0,145498,1de1ade843b0c3c834152d8aa00c714960faf51c,3,1,1,2813,,,0,"TEST

Change-Id: I7ad29b0adcffb138647b06f1e7d760cb3750771f
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/98/145498/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/rpc/client.py']",2,1de1ade843b0c3c834152d8aa00c714960faf51c,sileht/timeout-bug," default=120,"," default=60,",4,2
openstack%2Ftripleo-heat-templates~master~If93945a2c3396b07b592d08efb1f66e11d6194dd,openstack/tripleo-heat-templates,master,If93945a2c3396b07b592d08efb1f66e11d6194dd,Drop the MysqlClusterUniquePart validation,MERGED,2015-01-02 13:55:50.000000000,2015-01-07 21:27:55.000000000,2015-01-07 21:27:55.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 6928}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-01-02 13:55:50.000000000', 'files': ['controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/00d305fd40ccfdc8b6b496f166469261414caa26', 'message': 'Drop the MysqlClusterUniquePart validation\n\nTrying to use overcloud-without-mergepy currently fails with\na validation error around MysqlClusterUniquePart. This\nworks around the issue by temporarily dropping the validation.\n\nChange-Id: If93945a2c3396b07b592d08efb1f66e11d6194dd\nPartial-bug: #1405446\n'}]",0,144746,00d305fd40ccfdc8b6b496f166469261414caa26,13,5,1,360,,,0,"Drop the MysqlClusterUniquePart validation

Trying to use overcloud-without-mergepy currently fails with
a validation error around MysqlClusterUniquePart. This
works around the issue by temporarily dropping the validation.

Change-Id: If93945a2c3396b07b592d08efb1f66e11d6194dd
Partial-bug: #1405446
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/144746/1 && git format-patch -1 --stdout FETCH_HEAD,['controller.yaml'],1,00d305fd40ccfdc8b6b496f166469261414caa26,MysqlClusterUniquePart_validation," # Drop the validation: https://bugs.launchpad.net/tripleo/+bug/1405446 # constraints: # - length: {min: 4, max: 10}"," constraints: - length: {min: 4, max: 10}",3,2
openstack%2Fsahara~master~I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906,openstack/sahara,master,I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906,Fix for CDH EDP and CDH Hive process,ABANDONED,2014-12-24 16:52:05.000000000,2015-01-07 21:11:50.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-12-24 16:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ae13ddd646297c1e64444e9e6af48ee411ad16ae', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 2, 'created': '2014-12-24 19:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/70c58eff6d22358a2f034f8e79a0c32cba87a645', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 3, 'created': '2014-12-25 10:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e8fa48b324ba881d1b57b280625167cbe33e1d49', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 4, 'created': '2014-12-25 16:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2e2a7d8afc642c6b52f5f6f55d22f603bf41beb3', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 5, 'created': '2014-12-29 10:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/01f1e9e49d2032e33c6cd322616a437c2a1d7401', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 6, 'created': '2014-12-29 12:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f6982d134da5f08cb002323e785d682d4efef273', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 7, 'created': '2014-12-29 12:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b3131019fd9c47cacaf65ab1bd431fb245939581', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 8, 'created': '2014-12-29 13:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9d7d2423d49fae390663e7753d2b0201ac70b7fe', 'message': '[WIP] Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 9, 'created': '2014-12-29 14:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/05bc6129d1b3133d67e3819f2b2227c12a96b4f2', 'message': 'Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}, {'number': 10, 'created': '2014-12-29 15:49:46.000000000', 'files': ['sahara/plugins/hdfs_utils.py', 'sahara/plugins/hdp/versions/version_1_3_2/edp_engine.py', 'sahara/plugins/cdh/deploy.py', 'sahara/service/edp/oozie/engine.py', 'sahara/plugins/cdh/edp_engine.py', 'sahara/plugins/vanilla/v1_2_1/edp_engine.py', 'sahara/plugins/hdp/versions/version_2_0_6/edp_engine.py', 'sahara/tests/unit/plugins/vanilla/v1_2_1/test_plugin.py', 'sahara/tests/unit/service/edp/oozie/test_oozie.py', 'sahara/plugins/vanilla/hadoop2/edp_engine.py', 'sahara/service/edp/hdfs_helper.py', 'sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/unit/plugins/hdp/test_ambariplugin.py', 'sahara/tests/integration/tests/base.py', 'sahara/tests/unit/plugins/vanilla/hadoop2/test_plugin.py', 'sahara/plugins/cdh/hdfs_utils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/6786b8b35949d009b76d83e7f3bae03a1ffa0c19', 'message': 'Fix for CDH EDP and CDH Hive process\n\nCloses-bug: #1405200\n\nChange-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906\n'}]",0,143877,6786b8b35949d009b76d83e7f3bae03a1ffa0c19,63,8,10,7710,,,0,"Fix for CDH EDP and CDH Hive process

Closes-bug: #1405200

Change-Id: I1f55bdc50b0f8e4fe6ad5f64445f727912cd3906
",git fetch https://review.opendev.org/openstack/sahara refs/changes/77/143877/8 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/hdfs_utils.py', 'sahara/plugins/hdp/versions/version_1_3_2/edp_engine.py', 'sahara/plugins/vanilla/hadoop2/edp_engine.py', 'sahara/service/edp/oozie/engine.py', 'sahara/plugins/cdh/edp_engine.py', 'sahara/service/edp/hdfs_helper.py', 'sahara/plugins/vanilla/v1_2_1/edp_engine.py', 'sahara/plugins/hdp/versions/version_2_0_6/edp_engine.py']",8,ae13ddd646297c1e64444e9e6af48ee411ad16ae,bug/1405200,"from sahara.plugins import hdfs_utils self.fs_helper.mkdir(remote, dir_name, self.get_hdfs_user()) @property def fs_helper(self): return hdfs_utils.HadoopV2DFSUtils()","from sahara.service.edp import hdfs_helper hdfs_helper.create_dir_hadoop2(remote, dir_name, self.get_hdfs_user())",115,46
openstack%2Fpuppet-keystone~master~I127f44178084978fd37281ac2f79f3e65b96897a,openstack/puppet-keystone,master,I127f44178084978fd37281ac2f79f3e65b96897a,Use openstackclient for keystone_user,MERGED,2014-12-22 07:32:00.000000000,2015-01-07 21:04:40.000000000,2015-01-07 21:04:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-12-22 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/537d366fe9ed0555a1afaec801ca786f33ca0642', 'message': 'Use openstackclient for keystone_user\n\nChange-Id: I127f44178084978fd37281ac2f79f3e65b96897a\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 2, 'created': '2014-12-23 18:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/85eb1e0ab2ed95ac011d1f9e66f48afa20daae2d', 'message': 'Use openstackclient for keystone_user\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I127f44178084978fd37281ac2f79f3e65b96897a\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 3, 'created': '2015-01-05 19:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/d094686fea7ffe1b3f67cb110d65884ece385aed', 'message': 'Use openstackclient for keystone_user\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I127f44178084978fd37281ac2f79f3e65b96897a\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}, {'number': 4, 'created': '2015-01-07 20:38:59.000000000', 'files': ['spec/unit/provider/keystone_user/openstack_spec.rb', 'spec/unit/provider/keystone_user/keystone_spec.rb', 'lib/puppet/provider/keystone_user/openstack.rb', 'lib/puppet/provider/keystone_user/keystone.rb', 'lib/puppet/type/keystone_user.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/6af8ac6320c8e93a8dae73aa286350d98d3972f1', 'message': 'Use openstackclient for keystone_user\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I127f44178084978fd37281ac2f79f3e65b96897a\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n'}]",0,143383,6af8ac6320c8e93a8dae73aa286350d98d3972f1,26,5,4,8482,,,0,"Use openstackclient for keystone_user

blueprint use-openstackclient-in-module-resources

Change-Id: I127f44178084978fd37281ac2f79f3e65b96897a
Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/83/143383/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user/openstack_spec.rb', 'spec/unit/provider/keystone_user/keystone_spec.rb', 'lib/puppet/provider/keystone_user/openstack.rb', 'lib/puppet/provider/keystone_user/keystone.rb', 'lib/puppet/type/keystone_user.rb']",5,537d366fe9ed0555a1afaec801ca786f33ca0642,openstackclient,"require 'puppet/util/openstack' desc 'Type for managing keystone users.' newvalues(/(t|T)rue/, /(f|F)alse/, true, false) defaultto(true) value.to_s.downcase.to_sym auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_aviator_params(self, auth_param_doc)"," desc <<-EOT This is currently used to model the creation of keystone users. It currently requires that both the password as well as the tenant are specified. EOT # TODO support description?? newvalues(/(t|T)rue/, /(f|F)alse/) defaultto('True') value.to_s.capitalize",276,224
openstack%2Fproject-config~master~I14332c43cf12d46bd4472312e8edfa5760fc2f68,openstack/project-config,master,I14332c43cf12d46bd4472312e8edfa5760fc2f68,Import shade into openstack-infra,MERGED,2015-01-07 18:18:29.000000000,2015-01-07 20:51:42.000000000,2015-01-07 20:51:42.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-01-07 18:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a21e92c4969fbb74562d678ccf89f38fa4f742cc', 'message': ""Import shade into openstack-infra\n\nShade is a library that contains all the various logic you need to use\nOpenStack with the clouds Infra has encountered. It's currently being\nused as the basis of the next generation of ansible modules and the\nintent is to replace the direct python-*client calls in nodepool and\nlaunch_node.\n\nChange-Id: I14332c43cf12d46bd4472312e8edfa5760fc2f68\n""}, {'number': 2, 'created': '2015-01-07 18:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1b4958a9003c3b4938efa6299082d4b9d17e83ad', 'message': ""Import shade into openstack-infra\n\nShade is a library that contains all the various logic you need to use\nOpenStack with the clouds Infra has encountered. It's currently being\nused as the basis of the next generation of ansible modules and the\nintent is to replace the direct python-*client calls in nodepool and\nlaunch_node.\n\nChange-Id: I14332c43cf12d46bd4472312e8edfa5760fc2f68\n""}, {'number': 3, 'created': '2015-01-07 19:48:05.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack-infra/shade.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/db6c3555823898b5d7659cca5e305bd1ce7fe2d7', 'message': ""Import shade into openstack-infra\n\nShade is a library that contains all the various logic you need to use\nOpenStack with the clouds Infra has encountered. It's currently being\nused as the basis of the next generation of ansible modules and the\nintent is to replace the direct python-*client calls in nodepool and\nlaunch_node.\n\nChange-Id: I14332c43cf12d46bd4472312e8edfa5760fc2f68\n""}]",0,145551,db6c3555823898b5d7659cca5e305bd1ce7fe2d7,14,4,3,2,,,0,"Import shade into openstack-infra

Shade is a library that contains all the various logic you need to use
OpenStack with the clouds Infra has encountered. It's currently being
used as the basis of the next generation of ansible modules and the
intent is to replace the direct python-*client calls in nodepool and
launch_node.

Change-Id: I14332c43cf12d46bd4472312e8edfa5760fc2f68
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/145551/3 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack-infra/shade.config']",4,a21e92c4969fbb74562d678ccf89f38fa4f742cc,,"[access ""refs/for/refs/*""] pushMerge = group infra-core [access ""refs/heads/*""] abandon = group infra-core label-Code-Review = -2..+2 group infra-core label-Workflow = -1..+1 group infra-core [access ""refs/tags/*""] pushSignedTag = group infra-core [receive] requireChangeId = true [submit] mergeContent = true ",,35,0
openstack%2Fos-cloud-config~master~I9fe4f57dc39e709c8f7549913ac3b1ef1eec81b5,openstack/os-cloud-config,master,I9fe4f57dc39e709c8f7549913ac3b1ef1eec81b5,Do not use https for keystone v2 admin,MERGED,2014-12-17 21:09:17.000000000,2015-01-07 20:38:29.000000000,2015-01-07 20:38:28.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 8399}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-12-17 21:09:17.000000000', 'files': ['os_cloud_config/keystone.py'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/80fefcd609ae71c825e95d26e8ade5e60d175697', 'message': 'Do not use https for keystone v2 admin\n\nWhen passing an SSL hostname for keystone v2 admin access, the code\nassumes that v2 admin services will be https. However, that is not the\ncase and usually is avoided. Since v2 is frozen and will be deprecated\nsome day, adding SSL for this piece of it seems like extra work for\nnot much gain. So we just use http.\n\nChange-Id: I9fe4f57dc39e709c8f7549913ac3b1ef1eec81b5\n'}]",0,142580,80fefcd609ae71c825e95d26e8ade5e60d175697,13,4,1,6488,,,0,"Do not use https for keystone v2 admin

When passing an SSL hostname for keystone v2 admin access, the code
assumes that v2 admin services will be https. However, that is not the
case and usually is avoided. Since v2 is frozen and will be deprecated
some day, adding SSL for this piece of it seems like extra work for
not much gain. So we just use http.

Change-Id: I9fe4f57dc39e709c8f7549913ac3b1ef1eec81b5
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/80/142580/1 && git format-patch -1 --stdout FETCH_HEAD,['os_cloud_config/keystone.py'],1,80fefcd609ae71c825e95d26e8ade5e60d175697,, # It may not be readily obvious that admin v2 is never available # via https. The SSL parameter is just the DNS name to use. admin_url = 'http://%s:35357/v2.0' % (ssl or public or host)," admin_url = '%s://%s:35357/v2.0' % ('https' if ssl else 'http', ssl or public or host)",3,2
openstack%2Fcongress-specs~master~I667307f16c3c1371f478436c27080a9c28629dd0,openstack/congress-specs,master,I667307f16c3c1371f478436c27080a9c28629dd0,Indentation and title fixes in Kilo specs,MERGED,2015-01-07 01:26:40.000000000,2015-01-07 20:35:43.000000000,2015-01-07 20:35:42.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2015-01-07 01:26:40.000000000', 'files': ['specs/kilo/vCenter_Driver.rst', 'specs/kilo/heat-datasource-driver.rst', 'specs/kilo/add-in-list-type-for-hdict.rst', 'specs/kilo/parent-key-improvements.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/7813794c3d607d3c9c5c9dde113d282cef76208f', 'message': 'Indentation and title fixes in Kilo specs\n\nChange-Id: I667307f16c3c1371f478436c27080a9c28629dd0\n'}]",0,145390,7813794c3d607d3c9c5c9dde113d282cef76208f,6,2,1,7187,,,0,"Indentation and title fixes in Kilo specs

Change-Id: I667307f16c3c1371f478436c27080a9c28629dd0
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/90/145390/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/kilo/vCenter_Driver.rst', 'specs/kilo/heat-datasource-driver.rst', 'specs/kilo/add-in-list-type-for-hdict.rst', 'specs/kilo/parent-key-improvements.rst']",4,7813794c3d607d3c9c5c9dde113d282cef76208f,,,,40,29
openstack%2Fcongress~master~I54229206e2103106d3e00cab8ab898fefc8df60d,openstack/congress,master,I54229206e2103106d3e00cab8ab898fefc8df60d,Adds runtime.ExperimentalRuntime class,MERGED,2014-12-23 22:49:19.000000000,2015-01-07 20:34:37.000000000,2015-01-07 20:34:37.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}, {'_account_id': 13664}]","[{'number': 1, 'created': '2014-12-23 22:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/053056d3fb9c3c5215d460a93bb97576d1b9403a', 'message': 'Adds runtime.ExperimentalRuntime class\n\nChange-Id: I54229206e2103106d3e00cab8ab898fefc8df60d\nCloses-Bug: #1404977\n'}, {'number': 2, 'created': '2014-12-23 23:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/561cb8ef942436d23a4622486df5f6b86db1deff', 'message': 'Adds runtime.ExperimentalRuntime class\n\nChange-Id: I54229206e2103106d3e00cab8ab898fefc8df60d\nCloses-Bug: #1404977\n'}, {'number': 3, 'created': '2015-01-07 19:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a1cfc2e904d7ca4b07c275f4a1a9cd2dcb29c1f8', 'message': 'Adds runtime.ExperimentalRuntime class\n\nChange-Id: I54229206e2103106d3e00cab8ab898fefc8df60d\nCloses-Bug: #1404977\n'}, {'number': 4, 'created': '2015-01-07 19:46:18.000000000', 'files': ['congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/27260e5c67b65c150a490fc51fcb5a00b232e795', 'message': 'Adds runtime.ExperimentalRuntime class\n\nChange-Id: I54229206e2103106d3e00cab8ab898fefc8df60d\nCloses-Bug: #1404977\n'}]",0,143741,27260e5c67b65c150a490fc51fcb5a00b232e795,22,6,4,13664,,,0,"Adds runtime.ExperimentalRuntime class

Change-Id: I54229206e2103106d3e00cab8ab898fefc8df60d
Closes-Bug: #1404977
",git fetch https://review.opendev.org/openstack/congress refs/changes/41/143741/4 && git format-patch -1 --stdout FETCH_HEAD,['congress/policy/runtime.py'],1,053056d3fb9c3c5215d460a93bb97576d1b9403a,1404977," ############################################################################## # ExperimentalRuntime ############################################################################## class ExperimentalRuntime (Runtime): def explain(self, query, tablenames=None, find_all=False, target=None): """"""Event handler for explanations. Given a ground query and a collection of tablenames that we want the explanation in terms of, return proof(s) that the query is true. If FIND_ALL is True, returns list; otherwise, returns single proof. """""" if isinstance(query, basestring): return self.explain_string( query, tablenames, find_all, self.get_target(target)) elif isinstance(query, tuple): return self.explain_tuple( query, tablenames, find_all, self.get_target(target)) else: return self.explain_obj( query, tablenames, find_all, self.get_target(target)) def remediate(self, formula): """"""Event handler for remediation."""""" if isinstance(formula, basestring): return self.remediate_string(formula) elif isinstance(formula, tuple): return self.remediate_tuple(formula) else: return self.remediate_obj(formula) def execute(self, action_sequence): """"""Event handler for execute: execute a sequence of ground actions in the real world. """""" if isinstance(action_sequence, basestring): return self.execute_string(action_sequence) else: return self.execute_obj(action_sequence) def access_control(self, action, support=''): """"""Event handler for making access_control request. ACTION is an atom describing a proposed action instance. SUPPORT is any data that should be assumed true when posing the query. Returns True iff access is granted. """""" # parse if isinstance(action, basestring): action = self.parse1(action) assert compile.is_atom(action), ""ACTION must be an atom"" if isinstance(support, basestring): support = self.parse(support) # add support to theory newth = NonrecursiveRuleTheory(abbr=""Temp"") newth.tracer.trace('*') for form in support: newth.insert(form) acth = self.theory[self.ACCESSCONTROL_THEORY] acth.includes.append(newth) # check if action is true in theory result = len(acth.select(action, find_all=False)) > 0 # allow new theory to be freed acth.includes.remove(newth) return result"," def explain(self, query, tablenames=None, find_all=False, target=None): """"""Event handler for explanations. Given a ground query and a collection of tablenames that we want the explanation in terms of, return proof(s) that the query is true. If FIND_ALL is True, returns list; otherwise, returns single proof. """""" if isinstance(query, basestring): return self.explain_string( query, tablenames, find_all, self.get_target(target)) elif isinstance(query, tuple): return self.explain_tuple( query, tablenames, find_all, self.get_target(target)) else: return self.explain_obj( query, tablenames, find_all, self.get_target(target)) def remediate(self, formula): """"""Event handler for remediation."""""" if isinstance(formula, basestring): return self.remediate_string(formula) elif isinstance(formula, tuple): return self.remediate_tuple(formula) else: return self.remediate_obj(formula) def execute(self, action_sequence): """"""Event handler for execute: execute a sequence of ground actions in the real world. """""" if isinstance(action_sequence, basestring): return self.execute_string(action_sequence) else: return self.execute_obj(action_sequence) def access_control(self, action, support=''): """"""Event handler for making access_control request. ACTION is an atom describing a proposed action instance. SUPPORT is any data that should be assumed true when posing the query. Returns True iff access is granted. """""" # parse if isinstance(action, basestring): action = self.parse1(action) assert compile.is_atom(action), ""ACTION must be an atom"" if isinstance(support, basestring): support = self.parse(support) # add support to theory newth = NonrecursiveRuleTheory(abbr=""Temp"") newth.tracer.trace('*') for form in support: newth.insert(form) acth = self.theory[self.ACCESSCONTROL_THEORY] acth.includes.append(newth) # check if action is true in theory result = len(acth.select(action, find_all=False)) > 0 # allow new theory to be freed acth.includes.remove(newth) return result ",65,59
openstack%2Fos-cloud-config~master~Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416,openstack/os-cloud-config,master,Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416,Add support for creating Keystone v3 clients,MERGED,2014-11-12 04:50:53.000000000,2015-01-07 20:33:59.000000000,2015-01-07 20:33:58.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 9453}, {'_account_id': 9712}, {'_account_id': 13762}]","[{'number': 1, 'created': '2014-11-12 04:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/ccf98a621cb905bc79709a37238d17cf45389cac', 'message': 'Add support for creating Keystone v3 clients\n\nDue to the Keystone v2 client not supporting domains, we should add\nsupport for using the Keystone v3 client for some operations. This\nbranch does not change any of the existing Keystone callsites, merely\nadds support for creating the client.\n\nDrive-by correcting the method name for the Neutron client tests.\n\nChange-Id: Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416\n'}, {'number': 2, 'created': '2014-11-12 05:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/cec80c3193ec8f1d160e22b38d7e25248260122c', 'message': 'Add support for creating Keystone v3 clients\n\nDue to the Keystone v2 client not supporting domains, we should add\nsupport for using the Keystone v3 client for some operations. This\nbranch does not change any of the existing Keystone callsites, merely\nadds support for creating the client.\n\nDrive-by correcting the method name for the Neutron client tests.\n\nChange-Id: Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416\n'}, {'number': 3, 'created': '2014-11-19 02:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/45d325d762a63915cb7d090a8878d9bfecd660c7', 'message': 'Add support for creating Keystone v3 clients\n\nDue to the Keystone v2 client not supporting domains, we should add\nsupport for using the Keystone v3 client for some operations. This\nbranch does not change any of the existing Keystone callsites, merely\nadds support for creating the client.\n\nDrive-by correcting the method name for the Neutron client tests.\n\nChange-Id: Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416\n'}, {'number': 4, 'created': '2014-12-10 04:46:44.000000000', 'files': ['os_cloud_config/utils/clients.py', 'os_cloud_config/utils/tests/test_clients.py', 'os_cloud_config/cmd/utils/_clients.py', 'os_cloud_config/cmd/utils/tests/test_clients.py'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/f811472c5f7c79a0c0580b8975bc38b93ddd2d1b', 'message': 'Add support for creating Keystone v3 clients\n\nDue to the Keystone v2 client not supporting domains, we should add\nsupport for using the Keystone v3 client for some operations. This\nbranch does not change any of the existing Keystone callsites, merely\nadds support for creating the client.\n\nDrive-by correcting the method name for the Neutron client tests.\n\nChange-Id: Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416\n'}]",1,133885,f811472c5f7c79a0c0580b8975bc38b93ddd2d1b,34,8,4,9369,,,0,"Add support for creating Keystone v3 clients

Due to the Keystone v2 client not supporting domains, we should add
support for using the Keystone v3 client for some operations. This
branch does not change any of the existing Keystone callsites, merely
adds support for creating the client.

Drive-by correcting the method name for the Neutron client tests.

Change-Id: Ifd94b73684df99e3a2ef9ced9b8b4a748ac18416
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/85/133885/4 && git format-patch -1 --stdout FETCH_HEAD,"['os_cloud_config/utils/clients.py', 'os_cloud_config/utils/tests/test_clients.py', 'os_cloud_config/cmd/utils/_clients.py', 'os_cloud_config/cmd/utils/tests/test_clients.py']",4,ccf98a621cb905bc79709a37238d17cf45389cac,add-keystone-v3," @mock.patch('keystoneclient.v3.client.Client') def test_get_keystone_client(self, client_mock, environ): clients.get_keystone_v3_client() client_mock.assert_called_once_with( username=environ[""OS_USERNAME""], password=environ[""OS_PASSWORD""], auth_url=environ[""OS_AUTH_URL""].replace('v2.0', 'v3'), tenant_name=environ[""OS_TENANT_NAME""]) @mock.patch('os.environ') def test_get_neutron_client(self, client_mock, environ):"," def test_get_client(self, client_mock, environ):",39,2
openstack%2Fkeystone~master~Ied54434f13e960b1ec99227e5fd8db95e7dcbad9,openstack/keystone,master,Ied54434f13e960b1ec99227e5fd8db95e7dcbad9,Remove unused requirements,ABANDONED,2015-01-06 01:43:19.000000000,2015-01-07 20:26:25.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 9101}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-01-06 01:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d38176921d360105939689623d0faf9616c7f75f', 'message': 'Remove unused requirements\n\nWith the removal of keystone.openstack.common.gettextutils, Babel\nis no longer used directly by Keystone.\n\nChange-Id: Ied54434f13e960b1ec99227e5fd8db95e7dcbad9\n'}, {'number': 2, 'created': '2015-01-07 19:58:37.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8df8cdf9373e01f682b9ac20b309649cdd2c5e7c', 'message': 'Remove unused requirements\n\nWith the removal of keystone.openstack.common.gettextutils, Babel\nis no longer used directly by Keystone.\n\nPartial-Bug: #1408423\n\nChange-Id: Ied54434f13e960b1ec99227e5fd8db95e7dcbad9\n'}]",0,145110,8df8cdf9373e01f682b9ac20b309649cdd2c5e7c,9,4,2,6486,,,0,"Remove unused requirements

With the removal of keystone.openstack.common.gettextutils, Babel
is no longer used directly by Keystone.

Partial-Bug: #1408423

Change-Id: Ied54434f13e960b1ec99227e5fd8db95e7dcbad9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/10/145110/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,d38176921d360105939689623d0faf9616c7f75f,bug/1408423,,Babel>=1.3,0,2
openstack%2Ftripleo-heat-templates~master~Iec475a6c245a5bfe8b1d63ff72b6d0299861615c,openstack/tripleo-heat-templates,master,Iec475a6c245a5bfe8b1d63ff72b6d0299861615c,Pass Horizon port through to controller nodes,MERGED,2014-12-23 17:34:56.000000000,2015-01-07 20:23:06.000000000,2015-01-07 20:23:05.000000000,"[{'_account_id': 3}, {'_account_id': 6896}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 10290}, {'_account_id': 11650}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-12-23 17:34:56.000000000', 'files': ['overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03037369955f47a2bd5720a614f612b16cbec31c', 'message': 'Pass Horizon port through to controller nodes\n\nThe Horizon port may vary based on SSL enablement, and needs\nto be known by the nodes for the purpose of iptables rules, etc.\n\nChange-Id: Iec475a6c245a5bfe8b1d63ff72b6d0299861615c\n'}]",0,143700,03037369955f47a2bd5720a614f612b16cbec31c,16,7,1,10290,,,0,"Pass Horizon port through to controller nodes

The Horizon port may vary based on SSL enablement, and needs
to be known by the nodes for the purpose of iptables rules, etc.

Change-Id: Iec475a6c245a5bfe8b1d63ff72b6d0299861615c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/00/143700/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-source.yaml'],1,03037369955f47a2bd5720a614f612b16cbec31c,upstream/master, HorizonPort: type: number default: 80 description: Horizon web server port. port: {get_param: HorizonPort},,5,0
openstack%2Foslo.messaging~master~Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a,openstack/oslo.messaging,master,Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a,Don't log each received messages,MERGED,2015-01-07 16:54:04.000000000,2015-01-07 20:21:45.000000000,2015-01-07 20:21:41.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-07 16:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8948ea1f8a4dc4342bfd2a5c54a364b8a0d1b26f', 'message': ""Don't log each received messages.\n\noslo.utils.strutils.mask_password take too much time on\nbig payload (nova-conductor can receive payload ~ 66k in\nlargeops jobs for example).\n\nThis change removes this logging until we make mask_password\nmore efficient or we have a smarted the oslo.messaging logging to\nnot log everything.\n\nChange-Id: Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a\nCloses-bug: #1408362\n""}, {'number': 2, 'created': '2015-01-07 17:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4eee330450502441004d9fd2d5ac4925e67e89da', 'message': ""Don't log each received messages.\n\noslo.utils.strutils.mask_password take too much time on\nbig payload (nova-conductor can receive payload ~ 66k in\nlargeops jobs for example).\n\nThis change removes this logging until we make mask_password\nmore efficient or we have a smarted the oslo.messaging logging to\nnot log everything.\n\nChange-Id: Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a\nCloses-bug: #1408362\n""}, {'number': 3, 'created': '2015-01-07 17:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/42ef575963b8d82be2963f4a455b953ec42d2911', 'message': ""Don't log each received messages.\n\noslo.utils.strutils.mask_password take too much time on\nbig payload (nova-conductor can receive payload ~ 66k in\nlargeops jobs for example).\n\nThis change removes this logging until we make mask_password\nmore efficient or we have a smarted the oslo.messaging logging to\nnot log everything.\n\nChange-Id: Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a\nCloses-bug: #1408362\n""}, {'number': 4, 'created': '2015-01-07 17:27:43.000000000', 'files': ['oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c18f9f7c611df0e4c8e7e8d2067b31406147d264', 'message': ""Don't log each received messages\n\noslo.utils.strutils.mask_password take too much time on\nbig payload (nova-conductor can receive payload ~ 66k in\nlargeops jobs for example).\n\nThis change removes this logging until we make mask_password\nmore efficient or we have a smarted the oslo.messaging logging to\nnot log everything.\n\nChange-Id: Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a\nCloses-bug: #1408362\n""}]",10,145541,c18f9f7c611df0e4c8e7e8d2067b31406147d264,18,4,4,2813,,,0,"Don't log each received messages

oslo.utils.strutils.mask_password take too much time on
big payload (nova-conductor can receive payload ~ 66k in
largeops jobs for example).

This change removes this logging until we make mask_password
more efficient or we have a smarted the oslo.messaging logging to
not log everything.

Change-Id: Ib1f1d70c5cb820e8ff2de10e6064037808ea1f3a
Closes-bug: #1408362
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/41/145541/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/common.py', 'oslo/messaging/_drivers/amqp.py']",3,8948ea1f8a4dc4342bfd2a5c54a364b8a0d1b26f,bug/1408362,"from oslo.utils import strutils LOG.debug('unpacked context: %s', strutils.mask_password(six.u(ctx.to_dict())))"," rpc_common._safe_log(LOG.debug, 'unpacked context: %s', ctx.to_dict())",9,9
openstack%2Fnova~master~I295e3e2b2c2d640684a5416c53fa1fed7e6297e2,openstack/nova,master,I295e3e2b2c2d640684a5416c53fa1fed7e6297e2,Unshelving a volume backed instance doesn't work,MERGED,2014-12-31 06:07:11.000000000,2015-01-07 19:53:38.000000000,2015-01-07 09:20:04.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10300}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-31 06:07:11.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c944babe99657093cc8210478deaae0142c98e96', 'message': ""Unshelving a volume backed instance doesn't work\n\nIn case of volume backed instance, snapshot is not\ntaken when an instance is shelved, so shelve_image_id\nkey is not set to the instance system metadata.\nIf shelve_image_id is None, then it shouldn't raise UnshelveException.\n\nCloses-Bug: #1404801\nChange-Id: I295e3e2b2c2d640684a5416c53fa1fed7e6297e2\n""}]",2,144582,c944babe99657093cc8210478deaae0142c98e96,19,10,1,10300,,,0,"Unshelving a volume backed instance doesn't work

In case of volume backed instance, snapshot is not
taken when an instance is shelved, so shelve_image_id
key is not set to the instance system metadata.
If shelve_image_id is None, then it shouldn't raise UnshelveException.

Closes-Bug: #1404801
Change-Id: I295e3e2b2c2d640684a5416c53fa1fed7e6297e2
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/144582/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",2,c944babe99657093cc8210478deaae0142c98e96,bug/18025," image = None # No need to check for image if image_id is None as # ""shelved_image_id"" key is not set for volume backed # instance during the shelve process if image_id: with compute_utils.EventReporter( context, 'get_image_info', instance.uuid): try: image = safe_image_show(context, image_id) except exception.ImageNotFound: instance.vm_state = vm_states.ERROR instance.save() LOG.error(reason, instance=instance) raise exception.UnshelveException( instance_id=instance.uuid, reason=reason)"," with compute_utils.EventReporter( context, 'get_image_info', instance.uuid): try: image = safe_image_show(context, image_id) except exception.ImageNotFound: instance.vm_state = vm_states.ERROR instance.save() if image_id: else: reason = _('Unshelve attempted but the image_id is ' 'not provided') LOG.error(reason, instance=instance) raise exception.UnshelveException( instance_id=instance.uuid, reason=reason)",28,20
openstack%2Fnova~master~I0ff5990987e94a98825fdfa5200e0bf4a20f99b9,openstack/nova,master,I0ff5990987e94a98825fdfa5200e0bf4a20f99b9,Remove unused directory nova/tests/unit/bundle,MERGED,2014-12-18 02:31:54.000000000,2015-01-07 19:34:40.000000000,2015-01-07 19:34:36.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5638}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-18 02:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e6ce69b2bded6872589084d3edeeaed8809165c', 'message': 'Remove unused directory nova/tests/unit/bundle\n\nSeems like a vestige from some test that was yanked out.\n\nChange-Id: I0ff5990987e94a98825fdfa5200e0bf4a20f99b9\n'}, {'number': 2, 'created': '2014-12-18 02:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/712ccb952544e2aa1bdfa2e1de67fad6df4e6d47', 'message': 'Remove unused directory nova/tests/unit/bundle\n\nSeems like a vestige from some test that was yanked out.\n\nChange-Id: I0ff5990987e94a98825fdfa5200e0bf4a20f99b9\n'}, {'number': 3, 'created': '2014-12-21 02:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ca3d5c8fbce212a3e8b6c99428d3b14c1118fda', 'message': 'Remove unused directory nova/tests/unit/bundle\n\nSeems like a vestige from some test that was yanked out.\n\nChange-Id: I0ff5990987e94a98825fdfa5200e0bf4a20f99b9\n'}, {'number': 4, 'created': '2014-12-28 16:01:33.000000000', 'files': ['nova/tests/unit/bundle/1mb.part.1', 'nova/tests/unit/CA/cacert.pem', 'nova/tests/unit/bundle/1mb.part.0', 'nova/tests/unit/CA/private/cakey.pem', 'nova/tests/unit/bundle/1mb.no_kernel_or_ramdisk.manifest.xml', 'nova/tests/unit/bundle/1mb.manifest.xml'], 'web_link': 'https://opendev.org/openstack/nova/commit/d4df699445f5a62a8aee6584a4186496594c1260', 'message': 'Remove unused directory nova/tests/unit/bundle\n\nSeems like a vestige from some test that was yanked out.\n\nChange-Id: I0ff5990987e94a98825fdfa5200e0bf4a20f99b9\n'}]",0,142647,d4df699445f5a62a8aee6584a4186496594c1260,46,12,4,5638,,,0,"Remove unused directory nova/tests/unit/bundle

Seems like a vestige from some test that was yanked out.

Change-Id: I0ff5990987e94a98825fdfa5200e0bf4a20f99b9
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/142647/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/bundle/1mb.part.1', 'nova/tests/unit/bundle/1mb.part.0', 'nova/tests/unit/bundle/1mb.no_kernel_or_ramdisk.manifest.xml', 'nova/tests/unit/bundle/1mb.manifest.xml']",4,6e6ce69b2bded6872589084d3edeeaed8809165c,,,"<?xml version=""1.0"" ?><manifest><version>2007-10-10</version><bundler><name>euca-tools</name><version>1.2</version><release>31337</release></bundler><machine_configuration><architecture>x86_64</architecture><kernel_id>aki-test</kernel_id><ramdisk_id>ari-test</ramdisk_id></machine_configuration><image><name>1mb</name><user>42</user><type>machine</type><digest algorithm=""SHA1"">da39a3ee5e6b4b0d3255bfef95601890afd80709</digest><size>1048576</size><bundled_size>1136</bundled_size><ec2_encrypted_key algorithm=""AES-128-CBC"">33a2ea00dc64083dd9a10eb5e233635b42a7beb1670ab75452087d9de74c60aba1cd27c136fda56f62beb581de128fb1f10d072b9e556fd25e903107a57827c21f6ee8a93a4ff55b11311fcef217e3eefb07e81f71e88216f43b4b54029c1f2549f2925a839a73947d2d5aeecec4a62ece4af9156d557ae907978298296d9915</ec2_encrypted_key><user_encrypted_key algorithm=""AES-128-CBC"">4c11147fd8caf92447e90ce339928933d7579244c2f8ffb07cc0ea35f8738da8b90eff6c7a49671a84500e993e9462e4c36d5c19c0b3a2b397d035b4c0cce742b58e12552175d81d129b0425e9f71ebacb9aeb539fa9dd2ac36749fb82876f6902e5fb24b6ec19f35ec4c20acd50437fd30966e99c4d9a0647577970a8fa3023</user_encrypted_key><ec2_encrypted_iv>14bd082c9715f071160c69bbfb070f51d2ba1076775f1d988ccde150e515088156b248e4b5a64e46c4fe064feeeedfe14511f7fde478a51acb89f9b2f6c84b60593e5c3f792ba6b01fed9bf2158fdac03086374883b39d13a3ca74497eeaaf579fc3f26effc73bfd9446a2a8c4061f0874bfaca058905180e22d3d8881551cb3</ec2_encrypted_iv><user_encrypted_iv>8f7606f19f00e4e19535dd234b66b31b77e9c7bad3885d9c9efa75c863631fd4f82a009e17d789066d9cc6032a436f05384832f6d9a3283d3e63eab04fa0da5c8c87db9b17e854e842c3fb416507d067a266b44538125ce732e486098e8ebd1ca91fa3079f007fce7d14957a9b7e57282407ead3c6eb68fe975df3d83190021b</user_encrypted_iv><parts count=""2""><part index=""0""><filename>1mb.part.0</filename><digest algorithm=""SHA1"">c4413423cf7a57e71187e19bfd5cd4b514a64283</digest></part><part index=""1""><filename>1mb.part.1</filename><digest algorithm=""SHA1"">9d4262e6589393d09a11a0332af169887bc2e57d</digest></part></parts></image><signature>4e00b5ba28114dda4a9df7eeae94be847ec46117a09a1cbe41e578660642f0660dda1776b39fb3bf826b6cfec019e2a5e9c566728d186b7400ebc989a30670eb1db26ce01e68bd9d3f31290370077a85b81c66b63c1e0d5499bac115c06c17a21a81b6d3a67ebbce6c17019095af7ab07f3796c708cc843e58efc12ddc788c5e</signature></manifest> ",0,2
openstack%2Fproject-config~master~I50e63ad7adf6ad5d2348d7912ce0a99bb81b78d4,openstack/project-config,master,I50e63ad7adf6ad5d2348d7912ce0a99bb81b78d4,Publish files for gate-rally-dsvm-cli job,MERGED,2014-12-24 16:35:37.000000000,2015-01-07 19:34:28.000000000,2015-01-07 19:34:27.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6172}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 9545}, {'_account_id': 11610}]","[{'number': 1, 'created': '2014-12-24 16:35:37.000000000', 'files': ['jenkins/jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/234f7ea25960492a4d3e31666c50348f1b233594', 'message': 'Publish files for gate-rally-dsvm-cli job\n\ngate-rally-dsvm-cli is functional testing gate for Rally CLI.\nIn many case we would like to see ouput of commands. This change\nallow us to do that.\n\nChange-Id: I50e63ad7adf6ad5d2348d7912ce0a99bb81b78d4\n'}]",0,143874,234f7ea25960492a4d3e31666c50348f1b233594,17,9,1,6172,,,0,"Publish files for gate-rally-dsvm-cli job

gate-rally-dsvm-cli is functional testing gate for Rally CLI.
In many case we would like to see ouput of commands. This change
allow us to do that.

Change-Id: I50e63ad7adf6ad5d2348d7912ce0a99bb81b78d4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/74/143874/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/rally.yaml'],1,234f7ea25960492a4d3e31666c50348f1b233594,improve_test_cli, - target: 'logs/$LOG_PATH' source: 'rally-cli-output-files/**' keep-hierarchy: true copy-after-failure: true,,4,0
openstack%2Ftripleo-ci~master~I015143068fbf3f17cda3ac6a2bb87784b84cf127,openstack/tripleo-ci,master,I015143068fbf3f17cda3ac6a2bb87784b84cf127,Lower overcloud wait_for,ABANDONED,2015-01-05 22:33:17.000000000,2015-01-07 19:17:32.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-01-05 22:33:17.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bb8ae0fa17d401e5142754fb6c718b97d5721340', 'message': 'Lower overcloud wait_for\n\nWe are currently waiting for 360 min for the overcloud to time out. This\nis probably an unreasonable default but its also reasonable for us to\nset this value in CI since we have a known timeout window before jenkins\nkills our CI job.\n\nChange-Id: I015143068fbf3f17cda3ac6a2bb87784b84cf127\nCloses-Bug: #140781\n'}]",2,145077,bb8ae0fa17d401e5142754fb6c718b97d5721340,6,3,1,10035,,,0,"Lower overcloud wait_for

We are currently waiting for 360 min for the overcloud to time out. This
is probably an unreasonable default but its also reasonable for us to
set this value in CI since we have a known timeout window before jenkins
kills our CI job.

Change-Id: I015143068fbf3f17cda3ac6a2bb87784b84cf127
Closes-Bug: #140781
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/77/145077/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,bb8ae0fa17d401e5142754fb6c718b97d5721340,fix/set-overcloud-stack-timeout,OVERCLOUD_STACK_TIMEOUT=10,,1,0
openstack%2Fproject-config~master~Ieb1efa910fff124fe30159cf7b5f394e91eff2c4,openstack/project-config,master,Ieb1efa910fff124fe30159cf7b5f394e91eff2c4,Add networking-plumgrid project to StackForge,MERGED,2015-01-02 10:30:03.000000000,2015-01-07 19:15:29.000000000,2015-01-07 19:15:28.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1106}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 8279}, {'_account_id': 11809}]","[{'number': 1, 'created': '2015-01-02 10:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eeee601fef54628b8ceee2d08c541cfb4650cca4', 'message': 'Add networking-plumgrid project to StackForge\n\nThis repo will hold PLUMgrid drivers for Neutron.\nThe need of setting this repo up is inline with spec proposal [1], where core\nelements of the Neutron project are decoupled by the internals of the\ntechnology being supported.\n[1] https://review.openstack.org/#/c/134680/\n\nChange-Id: Ieb1efa910fff124fe30159cf7b5f394e91eff2c4\n'}, {'number': 2, 'created': '2015-01-02 10:35:04.000000000', 'files': ['jenkins/jobs/projects.yaml', 'gerrit/acls/stackforge/networking-plumgrid.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7c49d913fad8d7d6192c8a4cc4a843541acb0997', 'message': 'Add networking-plumgrid project to StackForge\n\nThis repo will hold PLUMgrid drivers for Neutron.\n\nThe need of setting this repo up is inline with spec proposal [1], where core\nelements of the Neutron project are decoupled by the internals of the\ntechnology being supported.\n\n[1] https://review.openstack.org/#/c/134680/\n\nChange-Id: Ieb1efa910fff124fe30159cf7b5f394e91eff2c4\n'}]",3,144730,7c49d913fad8d7d6192c8a4cc4a843541acb0997,27,12,2,8279,,,0,"Add networking-plumgrid project to StackForge

This repo will hold PLUMgrid drivers for Neutron.

The need of setting this repo up is inline with spec proposal [1], where core
elements of the Neutron project are decoupled by the internals of the
technology being supported.

[1] https://review.openstack.org/#/c/134680/

Change-Id: Ieb1efa910fff124fe30159cf7b5f394e91eff2c4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/30/144730/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/acls/stackforge/networking-plumgrid.config', 'gerrit/projects.yaml', 'zuul/layout.yaml']",4,eeee601fef54628b8ceee2d08c541cfb4650cca4,networking-plumgrid, - name: stackforge/networking-plumgrid template: - name: merge-check - name: python-jobs ,,30,0
openstack%2Fopenstack-manuals~master~I0ee8366bc88985ba985518c8c014a03af6bdc05a,openstack/openstack-manuals,master,I0ee8366bc88985ba985518c8c014a03af6bdc05a,Adds retrieving large lists info to End User Guide,MERGED,2014-12-15 22:25:59.000000000,2015-01-07 19:14:08.000000000,2015-01-07 19:14:07.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 9382}]","[{'number': 1, 'created': '2014-12-15 22:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/355c633685592d1be83123aa2e932bf2431727ba', 'message': 'Adds retrieving large lists info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I0ee8366bc88985ba985518c8c014a03af6bdc05a\nPartial-bug: 1392382\n'}, {'number': 2, 'created': '2014-12-18 17:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9d6c9e3606366a14478442f397eee5be34fb136f', 'message': 'Adds retrieving large lists info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I0ee8366bc88985ba985518c8c014a03af6bdc05a\nPartial-bug: 1392382\n'}, {'number': 3, 'created': '2015-01-06 22:50:18.000000000', 'files': ['doc/user-guide/section_cli_swift_howto.xml', 'doc/user-guide/section_object-api-large-lists.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d80560cf95f07ba49bf7207d30e214d09acf7b33', 'message': 'Adds retrieving large lists info to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I0ee8366bc88985ba985518c8c014a03af6bdc05a\nPartial-bug: 1392382\n'}]",4,141922,d80560cf95f07ba49bf7207d30e214d09acf7b33,14,5,3,12454,,,0,"Adds retrieving large lists info to End User Guide

With the moving of the Object Storage API content from a
long-form dev guide to a specification, some topics needed
To be added to the End User Guide.

Change-Id: I0ee8366bc88985ba985518c8c014a03af6bdc05a
Partial-bug: 1392382
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/141922/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/section_cli_swift_howto.xml', 'doc/user-guide/section_object-api-large-lists.xml']",2,355c633685592d1be83123aa2e932bf2431727ba,bug/1392382,"<?xml version=""1.0"" encoding=""UTF-8""?> <!DOCTYPE section [ <!-- Some useful entities borrowed from HTML --> <!ENTITY ndash ""&#x2013;""> <!ENTITY mdash ""&#x2014;""> <!ENTITY hellip ""&#x2026;""> ]> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""large-lists""> <title>Page through large lists of containers or objects</title> <para>If you have a large number of containers or objects, you can use the <parameter>marker</parameter>, <parameter>limit</parameter>, and <parameter>end_marker</parameter> parameters to control how many items are returned in a list and where the list starts or ends.</para> <itemizedlist> <listitem> <para><emphasis role=""bold""><parameter>marker</parameter> parameter</emphasis>. When you request a list of containers or objects, Object Storage returns a maximum of 10,000 names for each request. To get subsequent names, you must make another request with the <parameter>marker</parameter> parameter. Set the <literal>marker</literal> parameter to the name of the last item returned in the previous list. You must URL-encode the <parameter>marker</parameter> value before you send the HTTP request. Object Storage returns a maximum of 10,000 names starting after the last item returned.</para> </listitem> <listitem> <para><emphasis role=""bold""><parameter>limit</parameter> parameter</emphasis>. To return fewer than 10,000 names, use the <parameter>limit</parameter> parameter. If the number of names returned equals the specified <parameter>limit</parameter> (or 10,000 if you omit the <parameter>limit</parameter> parameter), you can assume there are more names to list. If the number of names in the list is exactly divisible by the <parameter>limit</parameter> value, the last request has no content.</para> </listitem> <listitem> <para><emphasis role=""bold"" ><parameter>end_marker</parameter> parameter</emphasis>. Limits the result set to names that are less than the <parameter>end_marker</parameter> parameter value. You must URL-encode the <parameter>end_marker</parameter> value before you send the HTTP request.</para> </listitem> </itemizedlist> <para>For examples of how to page through large lists, see the Object Storage API examples chapter in the <citetitle>OpenStack Object Storage API v1 Reference</citetitle>.</para> </section> ",,62,0
openstack%2Fnova~master~Ibbe91227e98b2ccddd1892ed43e54ac526fe7664,openstack/nova,master,Ibbe91227e98b2ccddd1892ed43e54ac526fe7664,Remove unused function _get_flavor_refs in flavor_access extension,MERGED,2015-01-05 05:56:40.000000000,2015-01-07 19:13:00.000000000,2015-01-07 19:12:57.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2015-01-05 05:56:40.000000000', 'files': ['nova/api/openstack/compute/contrib/flavor_access.py', 'nova/api/openstack/compute/plugins/v3/flavor_access.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9c8d7af26eda8694c94be27d769b4bd6e8c1709d', 'message': 'Remove unused function _get_flavor_refs in flavor_access extension\n\nFunction _get_flavor_refs never be used in any code, this patch is to remove it\nin flavor_access extension for both v2 and v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ibbe91227e98b2ccddd1892ed43e54ac526fe7664\n'}]",0,144930,9c8d7af26eda8694c94be27d769b4bd6e8c1709d,15,11,1,11189,,,0,"Remove unused function _get_flavor_refs in flavor_access extension

Function _get_flavor_refs never be used in any code, this patch is to remove it
in flavor_access extension for both v2 and v2.1 API.

Partially implements blueprint v2-on-v3-api

Change-Id: Ibbe91227e98b2ccddd1892ed43e54ac526fe7664
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/144930/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/flavor_access.py', 'nova/api/openstack/compute/plugins/v3/flavor_access.py']",2,9c8d7af26eda8694c94be27d769b4bd6e8c1709d,bp/v2-on-v3-api,," def _get_flavor_refs(self, context): """"""Return a dictionary mapping flavorid to flavor_ref."""""" flavors = objects.FlavorList.get_all(context) rval = {} for flavor in flavors: rval[flavor.flavorid] = flavor return rval ",0,18
openstack%2Fnova~master~Ied5bc13840e2373f7d23cba784441aa2d02b7236,openstack/nova,master,Ied5bc13840e2373f7d23cba784441aa2d02b7236,VMware: make use of oslo.vmware logout,MERGED,2014-12-29 14:47:49.000000000,2015-01-07 19:04:37.000000000,2015-01-07 19:04:34.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-29 14:47:49.000000000', 'files': ['nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e30ac4cfe79cfc092098eb5bb719a58d56d984ce', 'message': 'VMware: make use of oslo.vmware logout\n\nMake use of the oslo.vmware method for logging out of an active\nsession instead of doing it via the session Vim.\n\nTrivialFix\n\nChange-Id: Ied5bc13840e2373f7d23cba784441aa2d02b7236\n'}]",0,144307,e30ac4cfe79cfc092098eb5bb719a58d56d984ce,30,11,1,1653,,,0,"VMware: make use of oslo.vmware logout

Make use of the oslo.vmware method for logging out of an active
session instead of doing it via the session Vim.

TrivialFix

Change-Id: Ied5bc13840e2373f7d23cba784441aa2d02b7236
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/144307/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py']",2,e30ac4cfe79cfc092098eb5bb719a58d56d984ce,use-oslo-logout,," @mock.patch('nova.virt.vmwareapi.driver.VMwareVCDriver.__init__') def test_cleanup_host_direct(self, mock_init): mock_init.return_value = None vcdriver = driver.VMwareVCDriver(None, False) vcdriver._session = mock.Mock() vcdriver.cleanup_host(""foo"") vcdriver._session.vim.client.service.Logout.assert_called_once_with( vcdriver._session.vim.service_content.sessionManager ) @mock.patch('nova.virt.vmwareapi.driver.VMwareVCDriver.__init__') def test_cleanup_host_direct_with_bad_logout(self, mock_init): mock_init.return_value = None vcdriver = driver.VMwareVCDriver(None, False) vcdriver._session = mock.Mock() fault = suds.WebFault(mock.Mock(), mock.Mock()) vcdriver._session.vim.client.service.Logout.side_effect = fault vcdriver.cleanup_host(""foo"") ",1,29
openstack%2Fnova~stable%2Fjuno~I01df2096ced51eb9ebfd994cf8397f2fa094f6e3,openstack/nova,stable/juno,I01df2096ced51eb9ebfd994cf8397f2fa094f6e3,Return floating_ip['fixed_ip']['instance_uuid'] from neutronv2 API,MERGED,2015-01-06 23:18:28.000000000,2015-01-07 19:04:16.000000000,2015-01-07 19:04:14.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8788}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-01-06 23:18:28.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d9bcfab1e9310d6fa6aa4d060bec59c741e12ca4', 'message': ""Return floating_ip['fixed_ip']['instance_uuid'] from neutronv2 API\n\nThe os-floating-ips extension translates the floating IP information\nfrom the network API for the response but is only checking fields based\non what comes back from nova-network, which is using the FloatingIP\nobject. The neutronv2 API returns a different set of keys for the\ninstance/instance_uuid which the API extension doesn't handle and\ntherefore doesn't show the associated instance id for a given floating\nIP.\n\nThe network APIs should return consistent data formats so this change\nadds the expected key to fix the bug in the API extension (since the API\nextensions shouldn't have to know the implementation details of the\nnetwork API, there are some extensions actually checking if it's the\nneutron API and parsing the result set based on that).\n\nThis change will be used to backport the fix to the stable branches.\n\nThe longer term fix is to convert the neutronv2 get_floating_ip* API\nmethods to use nova objects which will be done as part of blueprint\nkilo-objects in a separate change.\n\nConflicts:\n        nova/tests/unit/network/test_neutronv2.py\n\nNOTE(mriedem): The conflict is due to the test modules being\nmoved in Kilo, otherwise the code is the same.\n\nCloses-Bug: #1380965\n\nChange-Id: I01df2096ced51eb9ebfd994cf8397f2fa094f6e3\n(cherry picked from commit 48c24dbb6bc1e55973dce2b8bc3e74105b0020ce)\n""}]",0,145374,d9bcfab1e9310d6fa6aa4d060bec59c741e12ca4,12,8,1,6873,,,0,"Return floating_ip['fixed_ip']['instance_uuid'] from neutronv2 API

The os-floating-ips extension translates the floating IP information
from the network API for the response but is only checking fields based
on what comes back from nova-network, which is using the FloatingIP
object. The neutronv2 API returns a different set of keys for the
instance/instance_uuid which the API extension doesn't handle and
therefore doesn't show the associated instance id for a given floating
IP.

The network APIs should return consistent data formats so this change
adds the expected key to fix the bug in the API extension (since the API
extensions shouldn't have to know the implementation details of the
network API, there are some extensions actually checking if it's the
neutron API and parsing the result set based on that).

This change will be used to backport the fix to the stable branches.

The longer term fix is to convert the neutronv2 get_floating_ip* API
methods to use nova objects which will be done as part of blueprint
kilo-objects in a separate change.

Conflicts:
        nova/tests/unit/network/test_neutronv2.py

NOTE(mriedem): The conflict is due to the test modules being
moved in Kilo, otherwise the code is the same.

Closes-Bug: #1380965

Change-Id: I01df2096ced51eb9ebfd994cf8397f2fa094f6e3
(cherry picked from commit 48c24dbb6bc1e55973dce2b8bc3e74105b0020ce)
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/145374/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,d9bcfab1e9310d6fa6aa4d060bec59c741e12ca4,bug/1380965-juno, # TODO(mriedem): remove this workaround once the get_floating_ip* # API methods are converted to use nova objects. result['fixed_ip']['instance_uuid'] = instance_uuid,,6,0
openstack%2Foctavia~master~I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e,openstack/octavia,master,I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e,updates the amphora driver interface spec,MERGED,2014-12-17 18:51:37.000000000,2015-01-07 18:58:15.000000000,2014-12-30 18:51:20.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 6951}, {'_account_id': 10477}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-17 18:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e6835f997c39d7e97fd913a949fdf2dd11cb157a', 'message': 'updates the spec with the lastest from\nthe midcycle\n* remove getHealth, getStats\n* add getConfiguration\n* remove some unneeded exceptions\n\nChange-Id: I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e\n'}, {'number': 2, 'created': '2014-12-18 18:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/62407d061bcab3ef92126890347c21dd364b1ec4', 'message': 'updates the spec with the lastest from\nthe midcycle\n* remove getHealth, getStats\n* add getConfiguration\n* remove some unneeded exceptions\n* make several calls return task flow\n  flows\n\nChange-Id: I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e\n'}, {'number': 3, 'created': '2014-12-18 18:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/5d972e76fad039f88e92eb699f8b8869d9037cd1', 'message': 'updates the spec\n\nwith the lastest from the midcycle\n* remove getHealth, getStats\n* add getConfiguration\n* remove some unneeded exceptions\n* make several calls return task flow\n  flows\n\nChange-Id: I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e\n'}, {'number': 4, 'created': '2014-12-18 21:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8f14f6ae5e4bb8c4401b037288ca9e5f093a1306', 'message': 'updates the spec\n\nwith the lastest from the midcycle\n* remove getHealth, getStats\n* add getConfiguration\n* remove some unneeded exceptions\n* make several calls return task flow\n  flows\n\nChange-Id: I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e\n'}, {'number': 5, 'created': '2014-12-22 18:36:25.000000000', 'files': ['specs/version0.5/amphora-driver-interface.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/5281a1b0a56189ca628cb551deeaeb2180da8ad5', 'message': 'updates the amphora driver interface spec\n\nwith the lastest from the midcycle\n* remove getHealth, getStats\n* add getConfiguration\n* remove some unneeded exceptions\n* make several calls return task flow\n  flows\n\nChange-Id: I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e\n'}]",22,142537,5281a1b0a56189ca628cb551deeaeb2180da8ad5,33,9,5,10850,,,0,"updates the amphora driver interface spec

with the lastest from the midcycle
* remove getHealth, getStats
* add getConfiguration
* remove some unneeded exceptions
* make several calls return task flow
  flows

Change-Id: I6a11fac73a696f23f7c4df7410f66ecdd9fcf50e
",git fetch https://review.opendev.org/openstack/octavia refs/changes/37/142537/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/version0.5/amphora-driver-interface.rst'],1,e6835f997c39d7e97fd913a949fdf2dd11cb157a,," # ""packages"":{""ha proxy"":""1.5""}, ""network-interfaces"": {""eth0"":{""ip"":...}} # some information might come from querying the amphora def get_config(self, amphora): #returns the configuration to be inspected by the controller and create missing network interfaces, etc. return amphora #per default just say the DB state matches the real one * ConfigException - gathering configuration information for this amphora failed"," # ""packages"":{""ha proxy"":""1.5""}} #some information might come from querying the amphora def get_metrics(self, amphora): #return ceilometer ready metrics - some amphora might choose to send them #straight to ceilometer others might use the mixin #support metrics to be compatible with Neutron LBaaS raise NotImplementedError def get_health(self, amphora): #returns map: {""amphora-status"":HEALTHY, loadbalancers: {""loadbalancer-id"": {""loadbalancer-status"": HEALTHY, # ""listeners"":{""listener-id"":{""listener-status"":HEALTHY, ""nodes"":{""node-id"":HEALTHY, ...}}, ...}, ...}} raise NotImplementedError * MetricsException - gathering metrics failed * StatisticsException - gathering statistics failed * ArchiveException - couldn't archive the logs * TargetException - the target is not accessible * QuotaException - the target has no space left * UnauthorizedException - unauthorized to write to the target ",6,20
openstack%2Fopenstack-ansible~master~I869b88cfe1bb8237f24d1e058ee7aac64806e230,openstack/openstack-ansible,master,I869b88cfe1bb8237f24d1e058ee7aac64806e230,Prevent user from accessing privileged files,MERGED,2015-01-07 16:40:01.000000000,2015-01-07 18:53:24.000000000,2015-01-07 17:35:47.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 7217}, {'_account_id': 9884}, {'_account_id': 12000}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-01-07 16:40:01.000000000', 'files': ['rpc_deployment/roles/glance_common/templates/policy.json'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/233a71022e0ee90ddacc05126a0bc7265c1ad166', 'message': 'Prevent user from accessing privileged files\n\nCloses-bug: 1400966\nRelated to OSSA-2014-041\nCVE-2014-9493\n\nChange-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230\n'}]",3,145537,233a71022e0ee90ddacc05126a0bc7265c1ad166,11,6,1,12000,,,0,"Prevent user from accessing privileged files

Closes-bug: 1400966
Related to OSSA-2014-041
CVE-2014-9493

Change-Id: I869b88cfe1bb8237f24d1e058ee7aac64806e230
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/37/145537/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/glance_common/templates/policy.json'],1,233a71022e0ee90ddacc05126a0bc7265c1ad166,bug/1400966," ""delete_image_location"": ""role:admin"", ""set_image_location"": ""role:admin"","," ""delete_image_location"": """", ""set_image_location"": """",",2,2
openstack%2Fglance~master~Iacf926fc98d009e580e1a8d83bbd6576685625b4,openstack/glance,master,Iacf926fc98d009e580e1a8d83bbd6576685625b4,use LOG instead of logger as name for the Logger object,ABANDONED,2014-05-27 07:24:30.000000000,2015-01-07 18:44:08.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9126}, {'_account_id': 9751}, {'_account_id': 9910}]","[{'number': 1, 'created': '2014-05-27 07:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/306ad87fbd62d2acd90edd4abc249f46e0b54a33', 'message': 'use LOG instead of logger as name for the Logger object\n\nChange-Id: Iacf926fc98d009e580e1a8d83bbd6576685625b4\n'}, {'number': 2, 'created': '2014-05-27 07:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0940da7505eec9d7b78ff95a9ee1d69ae9325518', 'message': 'use LOG instead of logger as name for the Logger object\n\nChange-Id: Iacf926fc98d009e580e1a8d83bbd6576685625b4\n'}, {'number': 3, 'created': '2014-05-31 09:09:41.000000000', 'files': ['glance/tests/integration/v2/base.py', 'glance/tests/functional/store/test_vmware_datastore.py', 'glance/common/wsgi.py', 'glance/common/config.py', 'glance/tests/functional/__init__.py', 'glance/cmd/replicator.py', 'glance/tests/integration/legacy_functional/base.py', 'glance/tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/131d3f0aca935773c41cf1b08b4d19364a951b96', 'message': ""use LOG instead of logger as name for the Logger object\n\nReplaced all appearances of 'logger' with 'LOG' to unify\nthe name of the Logger object.\n\nAlso replaced all imports of logging with\nglance.openstack.common.log and moved the logger initialization\nin glance/common/config.py into the global scope.\n\nChange-Id: Iacf926fc98d009e580e1a8d83bbd6576685625b4\n""}]",7,95662,131d3f0aca935773c41cf1b08b4d19364a951b96,29,11,3,167,,,0,"use LOG instead of logger as name for the Logger object

Replaced all appearances of 'logger' with 'LOG' to unify
the name of the Logger object.

Also replaced all imports of logging with
glance.openstack.common.log and moved the logger initialization
in glance/common/config.py into the global scope.

Change-Id: Iacf926fc98d009e580e1a8d83bbd6576685625b4
",git fetch https://review.opendev.org/openstack/glance refs/changes/62/95662/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/integration/v2/base.py', 'glance/common/wsgi.py', 'glance/common/config.py', 'glance/tests/functional/__init__.py', 'glance/tests/integration/legacy_functional/base.py', 'glance/tests/__init__.py']",6,306ad87fbd62d2acd90edd4abc249f46e0b54a33,use_log,LOG = logging.getLogger()LOG.addHandler(hdlr) LOG.setLevel(logging.DEBUG),logger = logging.getLogger()logger.addHandler(hdlr) logger.setLevel(logging.DEBUG),23,23
openstack%2Fpython-ceilometerclient~master~I545de167cdf8cfec6b5c67984b74327fb76c513a,openstack/python-ceilometerclient,master,I545de167cdf8cfec6b5c67984b74327fb76c513a,Enable --os-insecure CLI option,MERGED,2014-11-28 16:50:46.000000000,2015-01-07 18:41:02.000000000,2015-01-07 18:41:02.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 10987}, {'_account_id': 12637}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-11-28 16:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/b1d28085d2434544a5bb2cd56237f01a92493dc0', 'message': 'Enable --os-insecure CLI option\n\n--os-insecure is not correctly passed to Keystoneclient because it\nexpects a bool type but we assgin a string value to the insecure\nparameter, this patch fixes it by using oslo.utils.strutils.bool_from_string.\n\n--os-insecure is ignored by Ceilometerclient.v2.client because it\nexpects parameter verify rather than insecure, this patch fixes it\nby convert insecure to verify if that field is not set.\n\nChange-Id: I545de167cdf8cfec6b5c67984b74327fb76c513a\nCloses-Bug: #1394449\n'}, {'number': 2, 'created': '2014-11-28 16:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/f373edba42c426063b08058492f1b36eff7005a7', 'message': 'Enable --os-insecure CLI option\n\n--os-insecure is not correctly passed to Keystoneclient because it\nexpects a bool type but we assgin a string value to the insecure\nparameter, this patch fixes it by using oslo.utils.strutils.bool_from_string.\n\n--os-insecure is ignored by Ceilometerclient.v2.client because it\nexpects parameter verify rather than insecure, this patch fixes it\nby converting insecure to verify if that field is not set.\n\nChange-Id: I545de167cdf8cfec6b5c67984b74327fb76c513a\nCloses-Bug: #1394449\n'}, {'number': 3, 'created': '2014-11-29 06:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/da1e3c064fcb30f1fc2a90f942fb6739a1869f21', 'message': 'Enable --os-insecure CLI option\n\n--os-insecure is not correctly passed to Keystoneclient because it\nexpects a bool type but we assgin a string value to the insecure\nparameter, this patch fixes it by using oslo.utils.strutils.bool_from_string.\n\n--os-insecure is ignored by Ceilometerclient.v2.client because it\nexpects parameter verify rather than insecure, this patch fixes it\nby converting insecure to verify if that field is not set.\n\nChange-Id: I545de167cdf8cfec6b5c67984b74327fb76c513a\nCloses-Bug: #1394449\n'}, {'number': 4, 'created': '2014-12-06 14:01:57.000000000', 'files': ['ceilometerclient/tests/test_shell.py', 'ceilometerclient/client.py', 'ceilometerclient/v2/client.py', 'ceilometerclient/tests/test_client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/3f4b657f7a3dbd79ccad4558a85713a85d51c261', 'message': 'Enable --os-insecure CLI option\n\n--os-insecure is not correctly passed to Keystoneclient because it\nexpects a bool type but we assgin a string value to the insecure\nparameter, this patch fixes it by using oslo.utils.strutils.bool_from_string.\n\n--os-insecure is ignored by Ceilometerclient.v2.client because it\nexpects parameter verify rather than insecure, this patch fixes it\nby converting insecure to verify if that field is not set.\n\nChange-Id: I545de167cdf8cfec6b5c67984b74327fb76c513a\nCloses-Bug: #1394449\n'}]",16,137831,3f4b657f7a3dbd79ccad4558a85713a85d51c261,27,9,4,6676,,,0,"Enable --os-insecure CLI option

--os-insecure is not correctly passed to Keystoneclient because it
expects a bool type but we assgin a string value to the insecure
parameter, this patch fixes it by using oslo.utils.strutils.bool_from_string.

--os-insecure is ignored by Ceilometerclient.v2.client because it
expects parameter verify rather than insecure, this patch fixes it
by converting insecure to verify if that field is not set.

Change-Id: I545de167cdf8cfec6b5c67984b74327fb76c513a
Closes-Bug: #1394449
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/31/137831/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/client.py', 'ceilometerclient/v2/client.py']",2,b1d28085d2434544a5bb2cd56237f01a92493dc0,bug/1394449,"from oslo.utils import strutils insecure = strutils.bool_from_string(kwargs.get('insecure')) verify = kwargs.get('verify', not insecure) verify=verify,"," verify=kwargs.get('verify'),",8,2
openstack%2Fkeystone~stable%2Ficehouse~I3e0f1c2d9a859f276f74cb1d1477f92fe8a7524e,openstack/keystone,stable/icehouse,I3e0f1c2d9a859f276f74cb1d1477f92fe8a7524e,Updated from global requirements,MERGED,2015-01-07 15:20:30.000000000,2015-01-07 18:40:11.000000000,2015-01-07 18:40:10.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-01-07 15:20:30.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/345bd42708399b546fb11eb5a19b3715764811ac', 'message': 'Updated from global requirements\n\nChange-Id: I3e0f1c2d9a859f276f74cb1d1477f92fe8a7524e\n'}]",0,145524,345bd42708399b546fb11eb5a19b3715764811ac,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I3e0f1c2d9a859f276f74cb1d1477f92fe8a7524e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/24/145524/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,345bd42708399b546fb11eb5a19b3715764811ac,openstack/requirements,"keyring>=1.6.1,!=2.0,!=2.0.1,!=2.0.2,!=2.0.3","keyring>=1.6.1,<2.0,>=2.1",1,1
openstack%2Fpython-heatclient~master~Ifd6a64b57f5a2fe901088bceef8cb06ce49845ec,openstack/python-heatclient,master,Ifd6a64b57f5a2fe901088bceef8cb06ce49845ec,Cleanup shell tests,MERGED,2015-01-06 06:59:30.000000000,2015-01-07 18:35:19.000000000,2015-01-07 18:35:18.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}]","[{'number': 1, 'created': '2015-01-06 06:59:30.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/tests/keystone_client_fixtures.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/891d2f3e5bd1f3d372d59806118a040b262d9ab6', 'message': 'Cleanup shell tests\n\nMost of the basic test data that was being copied from keystone was\nunused or available as a fixture. Remove that copied data and use the\nfixture.\n\nI5436e86378db64163c69060feccaf6fa2054c8f4\n\nChange-Id: Ifd6a64b57f5a2fe901088bceef8cb06ce49845ec\n'}]",0,145148,891d2f3e5bd1f3d372d59806118a040b262d9ab6,7,3,1,7191,,,0,"Cleanup shell tests

Most of the basic test data that was being copied from keystone was
unused or available as a fixture. Remove that copied data and use the
fixture.

I5436e86378db64163c69060feccaf6fa2054c8f4

Change-Id: Ifd6a64b57f5a2fe901088bceef8cb06ce49845ec
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/48/145148/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/tests/keystone_client_fixtures.py']",2,891d2f3e5bd1f3d372d59806118a040b262d9ab6,tests,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from oslo.serialization import jsonutils from keystoneclient.fixture import v2 as ks_v2_fixture from keystoneclient.fixture import v3 as ks_v3_fixture # these are copied from python-keystoneclient tests BASE_HOST = 'http://keystone.example.com' BASE_URL = ""%s:5000/"" % BASE_HOST UPDATED = '2013-03-06T00:00:00Z' V2_URL = ""%sv2.0"" % BASE_URL V2_DESCRIBED_BY_HTML = {'href': 'http://docs.openstack.org/api/' 'openstack-identity-service/2.0/content/', 'rel': 'describedby', 'type': 'text/html'} V2_DESCRIBED_BY_PDF = {'href': 'http://docs.openstack.org/api/openstack-ident' 'ity-service/2.0/identity-dev-guide-2.0.pdf', 'rel': 'describedby', 'type': 'application/pdf'} V2_VERSION = {'id': 'v2.0', 'links': [{'href': V2_URL, 'rel': 'self'}, V2_DESCRIBED_BY_HTML, V2_DESCRIBED_BY_PDF], 'status': 'stable', 'updated': UPDATED} V3_URL = ""%sv3"" % BASE_URL V3_MEDIA_TYPES = [{'base': 'application/json', 'type': 'application/vnd.openstack.identity-v3+json'}, {'base': 'application/xml', 'type': 'application/vnd.openstack.identity-v3+xml'}] V3_VERSION = {'id': 'v3.0', 'links': [{'href': V3_URL, 'rel': 'self'}], 'media-types': V3_MEDIA_TYPES, 'status': 'stable', 'updated': UPDATED} TOKENID = uuid.uuid4().hex def _create_version_list(versions): return jsonutils.dumps({'versions': {'values': versions}}) def _create_single_version(version): return jsonutils.dumps({'version': version}) V3_VERSION_LIST = _create_version_list([V3_VERSION, V2_VERSION]) V2_VERSION_LIST = _create_version_list([V2_VERSION]) V3_VERSION_ENTRY = _create_single_version(V3_VERSION) V2_VERSION_ENTRY = _create_single_version(V2_VERSION) HEAT_ENDPOINT = 'http://www.heat.com/v1' def keystone_request_callback(request, uri, headers): response_headers = {""content-type"": ""application/json""} token_id = TOKENID if uri == BASE_URL: return (200, headers, V3_VERSION_LIST) elif uri == BASE_URL + ""/v2.0"": v2_token = ks_v2_fixture.Token(token_id) return (200, response_headers, jsonutils.dumps(v2_token)) elif uri == BASE_URL + ""/v3"": v3_token = ks_v3_fixture.Token() response_headers[""X-Subject-Token""] = token_id return (201, response_headers, jsonutils.dumps(v3_token)) ",24,102
openstack%2Fsahara~master~I4262810026b0d65ef195829549f8c99bdfe94c2f,openstack/sahara,master,I4262810026b0d65ef195829549f8c99bdfe94c2f,Enable more services in CDH plugin,MERGED,2014-12-15 07:02:29.000000000,2015-01-07 18:19:53.000000000,2015-01-07 18:05:11.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13662}]","[{'number': 1, 'created': '2014-12-15 07:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4105647d92c95f171df574cd71022abba6b09420', 'message': 'Enable more services in CDH plugin\n\nWe add more services support in CDH plugin, including Flume, Key-Value\nStore Indexer, Sentry, SOLR, SQOOP, and Impala.\n\nimplements bp:add-cdh-more-services\n\nChange-Id: I4262810026b0d65ef195829549f8c99bdfe94c2f\n'}, {'number': 2, 'created': '2014-12-22 16:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ce7b14c5eb6206ce265f7b6d3b6191722c1f35c7', 'message': 'Enable more services in CDH plugin\n\nWe add more services support in CDH plugin, including Flume, Key-Value\nStore Indexer, Sentry, SOLR, SQOOP, and Impala.\n\nimplements bp:add-cdh-more-services\n\nChange-Id: I4262810026b0d65ef195829549f8c99bdfe94c2f\n'}, {'number': 3, 'created': '2014-12-22 16:29:16.000000000', 'files': ['sahara/plugins/cdh/resources/impala-impalad.json', 'sahara/plugins/cdh/deploy.py', 'sahara/plugins/cdh/resources/impala-llama.json', 'sahara/plugins/cdh/plugin.py', 'sahara/plugins/cdh/resources/impala-catalogserver.json', 'sahara/plugins/cdh/resources/ks_indexer-service.json', 'sahara/plugins/cdh/resources/flume-agent.json', 'sahara/plugins/cdh/db_helper.py', 'sahara/plugins/cdh/resources/sqoop-service.json', 'sahara/plugins/cdh/resources/sqoop-sqoop_server.json', 'sahara/plugins/cdh/resources/impala-service.json', 'sahara/plugins/cdh/resources/cdh_config.py', 'sahara/plugins/cdh/resources/solr-service.json', 'sahara/plugins/cdh/utils.py', 'sahara/plugins/cdh/resources/flume-service.json', 'sahara/plugins/cdh/resources/ks_indexer-hbase_indexer.json', 'sahara/plugins/cdh/resources/solr-solr_server.json', 'sahara/plugins/cdh/validation.py', 'sahara/plugins/cdh/resources/sentry-service.json', 'sahara/plugins/cdh/resources/solr-gateway.json', 'sahara/plugins/cdh/resources/create_sentry_db.sql', 'sahara/plugins/cdh/cloudera_utils.py', 'sahara/plugins/cdh/resources/sentry-sentry_server.json', 'sahara/plugins/cdh/resources/impala-statestore.json', 'sahara/plugins/cdh/config_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1cb8222ee7da08275afb712c2a6e25a6d905fb66', 'message': 'Enable more services in CDH plugin\n\nWe add more services support in CDH plugin, including Flume, Key-Value\nStore Indexer, Sentry, SOLR, SQOOP, and Impala.\n\nimplements bp:add-cdh-more-services\n\nChange-Id: I4262810026b0d65ef195829549f8c99bdfe94c2f\n'}]",0,141735,1cb8222ee7da08275afb712c2a6e25a6d905fb66,80,11,3,13662,,,0,"Enable more services in CDH plugin

We add more services support in CDH plugin, including Flume, Key-Value
Store Indexer, Sentry, SOLR, SQOOP, and Impala.

implements bp:add-cdh-more-services

Change-Id: I4262810026b0d65ef195829549f8c99bdfe94c2f
",git fetch https://review.opendev.org/openstack/sahara refs/changes/35/141735/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/resources/impala-impalad.json', 'sahara/plugins/cdh/deploy.py', 'sahara/plugins/cdh/resources/impala-llama.json', 'sahara/plugins/cdh/plugin.py', 'sahara/plugins/cdh/resources/impala-catalogserver.json', 'sahara/plugins/cdh/resources/ks_indexer-service.json', 'sahara/plugins/cdh/resources/flume-agent.json', 'sahara/plugins/cdh/db_helper.py', 'sahara/plugins/cdh/resources/sqoop-service.json', 'sahara/plugins/cdh/resources/sqoop-sqoop_server.json', 'sahara/plugins/cdh/resources/impala-service.json', 'sahara/plugins/cdh/resources/cdh_config.py', 'sahara/plugins/cdh/resources/solr-service.json', 'sahara/plugins/cdh/utils.py', 'sahara/plugins/cdh/resources/flume-service.json', 'sahara/plugins/cdh/resources/ks_indexer-hbase_indexer.json', 'sahara/plugins/cdh/resources/solr-solr_server.json', 'sahara/plugins/cdh/validation.py', 'sahara/plugins/cdh/resources/sentry-service.json', 'sahara/plugins/cdh/resources/solr-gateway.json', 'sahara/plugins/cdh/resources/create_sentry_db.sql', 'sahara/plugins/cdh/cloudera_utils.py', 'sahara/plugins/cdh/resources/sentry-sentry_server.json', 'sahara/plugins/cdh/resources/impala-statestore.json', 'sahara/plugins/cdh/config_helper.py']",25,4105647d92c95f171df574cd71022abba6b09420,bp/add-cdh-more-services,"zookeeper_server_confs = _load_json(path_to_config + 'zookeeper-server.json')flume_service_confs = _load_json(path_to_config + 'flume-service.json') flume_agent_confs = _load_json(path_to_config + 'flume-agent.json') sentry_service_confs = _load_json(path_to_config + 'sentry-service.json') sentry_server_confs = _load_json(path_to_config + 'sentry-sentry_server.json') solr_service_confs = _load_json(path_to_config + 'solr-service.json') solr_server_confs = _load_json(path_to_config + 'solr-solr_server.json') sqoop_service_confs = _load_json(path_to_config + 'sqoop-service.json') sqoop_server_confs = _load_json(path_to_config + 'sqoop-sqoop_server.json') ks_indexer_service_confs = _load_json(path_to_config + 'ks_indexer-service.json') ks_indexer_role_confs = _load_json(path_to_config + 'ks_indexer-hbase_indexer.json') impala_service_confs = _load_json(path_to_config + 'impala-service.json') impala_catalogserver_confs = _load_json(path_to_config + 'impala-catalogserver.json') impala_impalad_confs = _load_json(path_to_config + 'impala-impalad.json') impala_llama_confs = _load_json(path_to_config + 'impala-llama.json') impala_statestore_confs = _load_json(path_to_config + 'impala-statestore.json') cfg += _init_configs(flume_service_confs, 'FLUME', 'cluster') cfg += _init_configs(flume_agent_confs, 'FLUME', 'node') cfg += _init_configs(sentry_service_confs, 'SENTRY', 'cluster') cfg += _init_configs(sentry_server_confs, 'SENTRY', 'node') cfg += _init_configs(solr_service_confs, 'SOLR', 'cluster') cfg += _init_configs(solr_server_confs, 'SOLR', 'node') cfg += _init_configs(sqoop_service_confs, 'SQOOP', 'cluster') cfg += _init_configs(sqoop_server_confs, 'SQOOP', 'node') cfg += _init_configs(ks_indexer_service_confs, 'KS_INDEXER', 'cluster') cfg += _init_configs(ks_indexer_role_confs, 'KS_INDEXER', 'node') cfg += _init_configs(impala_service_confs, 'IMPALA', 'cluster') cfg += _init_configs(impala_catalogserver_confs, 'CATALOGSERVER', 'node') cfg += _init_configs(impala_impalad_confs, 'IMPALAD', 'node') cfg += _init_configs(impala_statestore_confs, 'STATESTORE', 'node')",zookeeper_server_confs = _load_json(path_to_config + 'zookeeper-server.json'),3500,55
openstack%2Fneutron~stable%2Fjuno~I2287e5348aab82e39cf1b6e2884d08237a09b06d,openstack/neutron,stable/juno,I2287e5348aab82e39cf1b6e2884d08237a09b06d,Fix neutron hang for IPv6 allocation pool update,MERGED,2015-01-06 14:52:53.000000000,2015-01-07 18:12:10.000000000,2015-01-07 18:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 14208}]","[{'number': 1, 'created': '2015-01-06 14:52:53.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/560ef8187275415e4817e2cc78ca161b0a4aa7cf', 'message': 'Fix neutron hang for IPv6 allocation pool update\n\nWhile rebuilding IPAllocationPools, Neutron is using netaddr.iter_iprange\n(a generator that produces IPAddress objects). For an IPv6 subnet, this is\na costly operation and is causing Neutron Server to hang. This patch\naddresses the issue by replacing netaddr.iter_iprange with netaddr.IPRange\nwhich provides the same functionality while calculating the IPSets.\n\nCloses-Bug: #1401751\nChange-Id: I2287e5348aab82e39cf1b6e2884d08237a09b06d\n(cherry picked from commit b38f1bfa7b4f662182f552530b43301b214baa8d)\n'}]",0,145242,560ef8187275415e4817e2cc78ca161b0a4aa7cf,24,13,1,10257,,,0,"Fix neutron hang for IPv6 allocation pool update

While rebuilding IPAllocationPools, Neutron is using netaddr.iter_iprange
(a generator that produces IPAddress objects). For an IPv6 subnet, this is
a costly operation and is causing Neutron Server to hang. This patch
addresses the issue by replacing netaddr.iter_iprange with netaddr.IPRange
which provides the same functionality while calculating the IPSets.

Closes-Bug: #1401751
Change-Id: I2287e5348aab82e39cf1b6e2884d08237a09b06d
(cherry picked from commit b38f1bfa7b4f662182f552530b43301b214baa8d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/145242/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py']",2,560ef8187275415e4817e2cc78ca161b0a4aa7cf,bug/1401751," poolset = netaddr.IPSet(netaddr.IPRange(pool['first_ip'], pool['last_ip']))"," poolset = netaddr.IPSet(netaddr.iter_iprange(pool['first_ip'], pool['last_ip']))",58,22
openstack%2Fdevstack~master~I8e4175313b3cf0b12e981122358b1288a7eb0746,openstack/devstack,master,I8e4175313b3cf0b12e981122358b1288a7eb0746,Implement devstack external plugins,MERGED,2014-12-18 14:45:50.000000000,2015-01-07 18:11:09.000000000,2015-01-07 18:11:07.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-12-18 14:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a09ca5928c28e6c0ebf13aa48a88b361ff1e4d1a', 'message': 'WIP: first pass at plugin infrastructure\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch]\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}, {'number': 2, 'created': '2014-12-18 21:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cb1060511dee631c41c8f1549565f7451322f726', 'message': 'Implement devstack external plugins\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch]\n\nIt implements the devstack specification for this at\nI173dee3d57967b1d2ffd30e4868a2832aeac97ce\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}, {'number': 3, 'created': '2014-12-19 13:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6ad35085aabab70780e248c6813ddde6b7d24ea8', 'message': 'Implement devstack external plugins\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch] [priority]\n\nIt implements the devstack specification for this at\nI173dee3d57967b1d2ffd30e4868a2832aeac97ce\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}, {'number': 4, 'created': '2015-01-05 23:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/679d98b9b7282f67d7d02288de46f6ea69cae83f', 'message': 'Implement devstack external plugins\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch]\n\nIt implements the devstack specification for this at\nI173dee3d57967b1d2ffd30e4868a2832aeac97ce\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}, {'number': 5, 'created': '2015-01-06 13:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7429a10b1c0fb64f18ae5f4a63044260fbd1b07e', 'message': 'Implement devstack external plugins\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch]\n\nIt implements the devstack specification for this at\nI173dee3d57967b1d2ffd30e4868a2832aeac97ce\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}, {'number': 6, 'created': '2015-01-06 14:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e87a9698cd85091187b089285fe167e8a1e675e1', 'message': 'Implement devstack external plugins\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch]\n\nIt implements the devstack specification for this at\nI173dee3d57967b1d2ffd30e4868a2832aeac97ce\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}, {'number': 7, 'created': '2015-01-06 17:30:42.000000000', 'files': ['doc/source/plugins.rst', 'functions-common', 'unstack.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2c65e71ab85a6271818048f79541e9b269566df5', 'message': 'Implement devstack external plugins\n\nThis is an initial pass at plugin infrastructure for devstack which\nallows specifying an external repository via:\n\nenable_plugin <name> <giturl> [branch]\n\nIt implements the devstack specification for this at\nI173dee3d57967b1d2ffd30e4868a2832aeac97ce\n\nChange-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746\n'}]",6,142805,2c65e71ab85a6271818048f79541e9b269566df5,34,7,7,2750,,,0,"Implement devstack external plugins

This is an initial pass at plugin infrastructure for devstack which
allows specifying an external repository via:

enable_plugin <name> <giturl> [branch]

It implements the devstack specification for this at
I173dee3d57967b1d2ffd30e4868a2832aeac97ce

Change-Id: I8e4175313b3cf0b12e981122358b1288a7eb0746
",git fetch https://review.opendev.org/openstack/devstack refs/changes/05/142805/2 && git format-patch -1 --stdout FETCH_HEAD,"['functions-common', 'stack.sh']",2,a09ca5928c28e6c0ebf13aa48a88b361ff1e4d1a,plugins,# Enable Plugins install_all_plugins ,,35,1
openstack%2Fnova~master~Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f,openstack/nova,master,Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f,Move metadata filtering logic to utils.py,MERGED,2014-09-03 06:49:09.000000000,2015-01-07 18:10:25.000000000,2015-01-07 18:10:22.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5538}, {'_account_id': 5638}, {'_account_id': 6773}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11224}, {'_account_id': 11428}, {'_account_id': 12487}]","[{'number': 1, 'created': '2014-09-03 06:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4603d3038ba895f38805a4c34a858999dd998589', 'message': 'Move resource filtering logic to a common place\n\nCloses-Bug: 1364758\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n'}, {'number': 2, 'created': '2014-09-05 09:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b9b659aa1e9f6ff07d819518060dcd4ad689b19', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 3, 'created': '2014-09-05 11:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65cd86066d8c4c08ea0dfb409b386b8c782b903f', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 4, 'created': '2014-09-05 14:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73e9c0f4580e5106ee464c6238a96253c1cd51cc', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 5, 'created': '2014-09-05 16:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f2bec145fc26d7cfd001f5fb44802b62fe74150', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 6, 'created': '2014-09-18 05:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7e54dd02fc824a69e7f69d1971227b14bc0471a', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 7, 'created': '2014-10-08 15:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7feb9dd7adfed9df67dcfb5495ff0bbdf3dd9b56', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 8, 'created': '2014-11-25 08:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d58792c47151786b0ec5d41c503223730890c47a', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 9, 'created': '2014-11-25 12:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a9fa5b043968143036f5a7a23477a823f45ff91', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 10, 'created': '2014-11-26 10:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2fd990666497adb6ab50767a0e7194307eb5757', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with compute\ncode. To make this filtering logic usable for filtering metadata of other\nresources, it is being moved to utils.py file. The filtering metadata logic\nis going to be used for filtering volume and volume snapshot metadata in the\nEC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic. Those\nhave been added too, and in the process of writing unit tests, a bug was found\nand fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 11, 'created': '2014-12-08 05:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fbc08b77ac436df5a1511184d7f75d56bccebd74', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with\ncompute code. To make this filtering logic usable for filtering\nmetadata of other resources, it is being moved to utils.py file. The\nfiltering metadata logic is going to be used for filtering volume and\nvolume snapshot metadata in the EC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic.\nThose have been added too, and in the process of writing unit tests,\na bug was found and fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 12, 'created': '2014-12-08 14:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/390f41e6ca7493d23dbc2aeb04ce6e540cb5022c', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with\ncompute code. To make this filtering logic usable for filtering\nmetadata of other resources, it is being moved to utils.py file. The\nfiltering metadata logic is going to be used for filtering volume and\nvolume snapshot metadata in the EC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic.\nThose have been added too, and in the process of writing unit tests,\na bug was found and fixed too, in this patch.\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 13, 'created': '2014-12-10 12:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c338d3b9bb1c95d11d78c9130358c4753402a41c', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with\ncompute code. To make this filtering logic usable for filtering\nmetadata of other resources, it is being moved to utils.py file. The\nfiltering metadata logic is going to be used for filtering volume and\nvolume snapshot metadata in the EC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic.\nThose have been added too, and in the process of writing unit tests,\na bug was found: a single character value of a resource metadata\n(e.g. 'c') matches when a filter is specified which contains\nthat character as a part of input matching string (e.g.\nall resources which has a metadata value = 'taco')\n\nThe bug has also been fixed, and accompanying testcase added\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 14, 'created': '2014-12-17 18:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abe656e2dd66eea9a94a024f5d1f40fc8ae26b06', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with\ncompute code. To make this filtering logic usable for filtering\nmetadata of other resources, it is being moved to utils.py file. The\nfiltering metadata logic is going to be used for filtering volume and\nvolume snapshot metadata in the EC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic.\nThose have been added too, and in the process of writing unit tests,\na bug was found: a single character value of a resource metadata\n(e.g. 'c') matches when a filter is specified which contains\nthat character as a part of input matching string (e.g.\nall resources which has a metadata value = 'taco')\n\nThe bug has also been fixed, and accompanying testcase added\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 15, 'created': '2014-12-23 11:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c61ba6276eb11c095252d4178b5112ee1cf9bf6a', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with\ncompute code. To make this filtering logic usable for filtering\nmetadata of other resources, it is being moved to utils.py file. The\nfiltering metadata logic is going to be used for filtering volume and\nvolume snapshot metadata in the EC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic.\nThose have been added too, and in the process of writing unit tests,\na bug was found: a single character value of a resource metadata\n(e.g. 'c') matches when a filter is specified which contains\nthat character as a part of input matching string (e.g.\nall resources which has a metadata value = 'taco')\n\nThe bug has also been fixed, and accompanying testcase added\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}, {'number': 16, 'created': '2014-12-27 10:52:27.000000000', 'files': ['nova/tests/unit/test_utils.py', 'nova/utils.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b2759edacae209ae07288fa56d76eaaf2947b0a6', 'message': ""Move metadata filtering logic to utils.py\n\nMetadata filtering logic in it's current form is tightly coupled with\ncompute code. To make this filtering logic usable for filtering\nmetadata of other resources, it is being moved to utils.py file. The\nfiltering metadata logic is going to be used for filtering volume and\nvolume snapshot metadata in the EC2 API, at the very least.\n\nThere were no unit tests present at all to test the filtering logic.\nThose have been added too, and in the process of writing unit tests,\na bug was found: a single character value of a resource metadata\n(e.g. 'c') matches when a filter is specified which contains\nthat character as a part of input matching string (e.g.\nall resources which has a metadata value = 'taco')\n\nThe bug has also been fixed, and accompanying testcase added\n\nCloses-Bug: 1364758\nCloses-Bug: 1365887\nChange-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f\n""}]",31,118554,b2759edacae209ae07288fa56d76eaaf2947b0a6,168,20,16,5538,,,0,"Move metadata filtering logic to utils.py

Metadata filtering logic in it's current form is tightly coupled with
compute code. To make this filtering logic usable for filtering
metadata of other resources, it is being moved to utils.py file. The
filtering metadata logic is going to be used for filtering volume and
volume snapshot metadata in the EC2 API, at the very least.

There were no unit tests present at all to test the filtering logic.
Those have been added too, and in the process of writing unit tests,
a bug was found: a single character value of a resource metadata
(e.g. 'c') matches when a filter is specified which contains
that character as a part of input matching string (e.g.
all resources which has a metadata value = 'taco')

The bug has also been fixed, and accompanying testcase added

Closes-Bug: 1364758
Closes-Bug: 1365887
Change-Id: Ie9dbb50b79c042e49ef7eaba831280e175cc1e7f
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/118554/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/utils.py', 'nova/compute/api.py', 'nova/tests/test_utils.py']",3,4603d3038ba895f38805a4c34a858999dd998589,bp/ec2-volume-and-snapshot-tags," class ResourceFilterTestCase(test.NoDBTestCase): def test_no_filter_specified(self): i1 = { 'uuid': '1', 'metadata': {'k1': 'v1'}, } i2 = { 'uuid': '2', 'metadata': {'k1': 'v2'}, } expected = [ { 'instance_id': '1', 'key': 'k1', 'value': 'v1', }, { 'instance_id': '2', 'key': 'k1', 'value': 'v2', }] actual = utils.get_all_resource_metadata('instance', [i1, i2], search_filts=[], metadata_type='metadata') self.assertEqual(expected, actual)",,98,39
openstack%2Fpython-heatclient~master~Ic497d952ede7500d3787495865440befd0a92c0a,openstack/python-heatclient,master,Ic497d952ede7500d3787495865440befd0a92c0a,Fix passing an object url to the heat CLI,MERGED,2015-01-07 07:28:10.000000000,2015-01-07 18:06:29.000000000,2015-01-07 18:06:29.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 8289}]","[{'number': 1, 'created': '2015-01-07 07:28:10.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/3e54669e994616254316a660c701f7c66707f2ad', 'message': 'Fix passing an object url to the heat CLI\n\nMake a wrapper around the raw_request function so that it correctly\nreturns a string rather than a requests.Response object to match\nthe required API.\n\nCloses-Bug: #1408199\nChange-Id: Ic497d952ede7500d3787495865440befd0a92c0a\n'}]",0,145422,3e54669e994616254316a660c701f7c66707f2ad,8,5,1,7191,,,0,"Fix passing an object url to the heat CLI

Make a wrapper around the raw_request function so that it correctly
returns a string rather than a requests.Response object to match
the required API.

Closes-Bug: #1408199
Change-Id: Ic497d952ede7500d3787495865440befd0a92c0a
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/22/145422/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/v1/shell.py']",2,3e54669e994616254316a660c701f7c66707f2ad,bug/1408199,"def _authenticated_fetcher(hc): """"""A wrapper around the heat client object to fetch a template. """""" def _do(*args, **kwargs): return hc.http_client.raw_request(*args, **kwargs).content return _do _authenticated_fetcher(hc)) _authenticated_fetcher(hc)) _authenticated_fetcher(hc)) _authenticated_fetcher(hc))", hc.http_client.raw_request) hc.http_client.raw_request) hc.http_client.raw_request) hc.http_client.raw_request),21,5
openstack%2Fcinder~master~Id428fa2132c1afed424443083645787ee3cb0399,openstack/cinder,master,Id428fa2132c1afed424443083645787ee3cb0399,Add an instance-locality filter,MERGED,2014-09-02 11:34:33.000000000,2015-01-07 18:05:20.000000000,2015-01-07 18:05:19.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 2792}, {'_account_id': 2861}, {'_account_id': 5538}, {'_account_id': 6094}, {'_account_id': 6491}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7710}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9366}, {'_account_id': 10068}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12561}, {'_account_id': 12778}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13636}, {'_account_id': 13900}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}]","[{'number': 1, 'created': '2014-09-02 11:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/52a1cf26127b6b1655dd535b74b9dcce42d1404b', 'message': ""Add a data locality filter\n\nThe term data locality here refers to having an instance and an attached\nvolume on the same physical host.  This can be desirable in some\nconfigurations, in order to improve disk throughput and reduce latency.\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.\n\nThis change adds a filter to Cinder: InstanceLocalFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 2, 'created': '2014-09-02 12:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f0b0edba7736b35d32b08febce994dfca7d65df', 'message': ""Add a data locality filter\n\nThe term data locality here refers to having an instance and an attached\nvolume on the same physical host.  This can be desirable in some\nconfigurations, in order to improve disk throughput and reduce latency.\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.\n\nThis change adds a filter to Cinder: InstanceLocalFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 3, 'created': '2014-09-02 14:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/14500de5eb3b722e7d4d9c1fe43d3638e002d0d1', 'message': ""Add a data locality filter\n\nThe term data locality here refers to having an instance and an attached\nvolume on the same physical host.  This can be desirable in some\nconfigurations, in order to improve disk throughput and reduce latency.\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.\n\nThis change adds a filter to Cinder: InstanceLocalFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 4, 'created': '2014-09-03 12:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b927cc5466c1f4465b431358dac777111b14aaf', 'message': ""Add a data locality filter\n\nThe term data locality here refers to having an instance and an attached\nvolume on the same physical host.  This can be desirable in some\nconfigurations, in order to improve disk throughput and reduce latency.\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.\n\nThis change adds a filter to Cinder: InstanceLocalFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 5, 'created': '2014-09-03 14:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c20ae2ffd54d005cfaf3694a81a8356bfece74ed', 'message': ""Add a data locality filter\n\nThe term data locality here refers to having an instance and an attached\nvolume on the same physical host.  This can be desirable in some\nconfigurations, in order to improve disk throughput and reduce latency.\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.\n\nThis change adds a filter to Cinder: InstanceLocalFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 6, 'created': '2014-09-08 12:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9d0bfe60ca1f550df2ba433b91b88aca3e17479f', 'message': ""Add an instance locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis change adds a filter to Cinder: InstanceLocalityFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.  In order to work, physical hosts should\nrun both nova-compute and cinder-volume services.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 7, 'created': '2014-09-10 10:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f766d8c8fbde100dd6af2ea5acc1af5d82c787a0', 'message': ""Add an instance locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis change adds a filter to Cinder: InstanceLocalityFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without any knowledge of the underlying\ninfrastructure or back-ends.  In order to work, physical hosts should\nrun both nova-compute and cinder-volume services.\n\nPlease note that this filter can allow multiple Cinder hosts to match,\nsince multiple back-ends can co-exist on the same physical host.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 8, 'created': '2014-09-16 15:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e9fd5090eca84a8734c55871c5ca3e98a3fb4427', 'message': ""Add an instance locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis change adds a filter to Cinder: InstanceLocalityFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without specifying the hypervisor's hostname, and\nwithout any knowledge of the underlying back-ends.\n\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.  Also, this filter relies on Nova's Extended\nServer Attributes extension, so the calling user should have the right\nto use this extension (either being admin or authorized by Nova's policy\nin the 'extended_server_attributes' property).\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 9, 'created': '2014-09-17 08:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3dc1dbc0893f8df177c833c6fbc7427ff51cfeba', 'message': ""Add an instance locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis change adds a filter to Cinder: InstanceLocalityFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without specifying the hypervisor's hostname, and\nwithout any knowledge of the underlying back-ends.\n\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.  Also, this filter relies on Nova's Extended\nServer Attributes extension, so the calling user should have the right\nto use this extension (either being admin or authorized by Nova's policy\nin the 'extended_server_attributes' property).\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 10, 'created': '2014-09-17 10:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fcfdc9558649f65c08fc7a723b378c5dd7f4997f', 'message': ""Add an instance locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis change adds a filter to Cinder: InstanceLocalityFilter.  When using\nthis filter, a user can request the creation of volumes 'local' to a\nspecified instance, without specifying the hypervisor's hostname, and\nwithout any knowledge of the underlying back-ends.\n\nIn order to work, physical hosts should run both nova-compute and\ncinder-volume services.  Also, this filter relies on Nova's Extended\nServer Attributes extension, so the calling user should have the right\nto use this extension (either being admin or authorized by Nova's policy\nin the 'extended_server_attributes' property).\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID SIZE\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 11, 'created': '2014-10-29 13:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a46bfa3e92998f3c702d164a4fd1577dd0ea952', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:hypervisor_hostname'\n  property is returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the property\n  to be returned by Nova. This can be achieved either by changing Nova's\n  policy.json (the 'extended_server_attributes' option), or by setting a\n  Nova admin account in Cinder's conf.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a 42 GB volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID 42\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 12, 'created': '2014-10-30 10:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/38cac9bf9836f7e4ad719617d8d3a8315badd9b7', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:hypervisor_hostname'\n  property is returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the property\n  to be returned by Nova. This can be achieved either by changing Nova's\n  policy.json (the 'extended_server_attributes' option), or by setting a\n  Nova admin account in Cinder's conf.\n\nFor example:\n  Instance identified by INSTANCE-UUID is running in a hypervisor\n  running on the HOST1 physical host.\n\n  To create a 42 GB volume in a back-end hosted by HOST1:\n    cinder create --hint local_to_instance=INSTANCE-UUID 42\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 13, 'created': '2014-11-26 13:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b03103ef88ff47f26ca3e3684c0e477e237e3942', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the property\n  to be returned by Nova. This can be achieved either by changing Nova's\n  policy.json (the 'extended_server_attributes' option), or by setting\n  an account with admin role in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 14, 'created': '2014-11-26 14:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/87c4bde24849cc3fdec360a78e25e1f4ab6841f5', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the property\n  to be returned by Nova. This can be achieved either by changing Nova's\n  policy.json (the 'extended_server_attributes' option), or by setting\n  an account with admin role in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact\n\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 15, 'created': '2014-11-27 10:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5adf9facce99e5ba2a65329c2f348df42ef705c6', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the property\n  to be returned by Nova. This can be achieved either by changing Nova's\n  policy.json (the 'extended_server_attributes' option), or by setting\n  an account with admin role in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 16, 'created': '2014-12-01 18:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0481027a7ac5d8592dd84b9964dea902b67c626e', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto improve disk throughput and reduce latency.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the property\n  to be returned by Nova. This can be achieved either by changing Nova's\n  policy.json (the 'extended_server_attributes' option), or by setting\n  an account with admin role in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 17, 'created': '2014-12-05 15:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77f37cbfd5fdbbc9def0022485a61e02b2bb7e8e', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 18, 'created': '2014-12-05 17:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/faebafa3dba96a610c5e6cf6868e834ca35d3679', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 19, 'created': '2014-12-15 20:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e6cf0fa08507cc117dc70231c14015c44254e22', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 20, 'created': '2014-12-20 10:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b616634c5bb2e2c96c945b4deb7c5523a1039eff', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 21, 'created': '2014-12-27 14:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b1d3d4ac79ab6c261ec339a8a76065fe50ca1479', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 22, 'created': '2015-01-03 15:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7151dc41378fb18241d9c3fb020a6e2d11e48300', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nNote:\n  Currently it is not recommended to allow instance migrations for\n  hypervisors where this hint will be used. In case of instance\n  migration, a previously locally-created volume will not be\n  automatically migrated. Also in case of instance migration during the\n  volume's scheduling, the result is unpredictable.\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 23, 'created': '2015-01-03 15:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d7faf512f06b95a55763b51a4d3df8cfa7e7f39', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nNote:\n  Currently it is not recommended to allow instance migrations for\n  hypervisors where this hint will be used. In case of instance\n  migration, a previously locally-created volume will not be\n  automatically migrated. Also in case of instance migration during the\n  volume's scheduling, the result is unpredictable.\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 24, 'created': '2015-01-03 15:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd351eb9a7270f58d942fc582bfb805e717d98f3', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nNote:\n  Currently it is not recommended to allow instance migrations for\n  hypervisors where this hint will be used. In case of instance\n  migration, a previously locally-created volume will not be\n  automatically migrated. Also in case of instance migration during the\n  volume's scheduling, the result is unpredictable.\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}, {'number': 25, 'created': '2015-01-07 09:47:29.000000000', 'files': ['cinder/tests/scheduler/test_host_filters.py', 'cinder/tests/scheduler/fakes.py', 'cinder/compute/nova.py', 'cinder/exception.py', 'cinder/tests/compute/test_nova.py', 'cinder/scheduler/filters/instance_locality_filter.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0269a26f13ed36b670e55b92f7645fb989cbce86', 'message': ""Add an instance-locality filter\n\nHaving an instance and an attached volume on the same physical host\n(i.e. data locality) can be desirable in some configurations, in order\nto achieve high-performance disk I/O.\n\nThis patch adds an InstanceLocalityFilter filter that allow users to\nrequest creation of volumes 'local' to an existing instance, without\nspecifying the hypervisor's hostname, and without any knowledge of the\nunderlying back-ends.\n\nIn order to work:\n- At least one physical host should run both nova-compute and\n  cinder-volume services.\n- The Extended Server Attributes extension needs to be active in Nova\n  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is\n  returned when requesting instance info.\n- The user making the call needs to have sufficient rights for the\n  property to be returned by Nova. This can be achieved either by\n  changing Nova's policy.json (the 'extended_server_attributes' option),\n  or by setting an account with privileged rights in Cinder conf.\n\nFor example:\n  Instance 01234567-89ab-cdef is running in a hypervisor on the physical\n  host 'my-host'.\n\n  To create a 42 GB volume in a back-end hosted by 'my-host':\n    cinder create --hint local_to_instance=01234567-89ab-cdef 42\n\nNote:\n  Currently it is not recommended to allow instance migrations for\n  hypervisors where this hint will be used. In case of instance\n  migration, a previously locally-created volume will not be\n  automatically migrated. Also in case of instance migration during the\n  volume's scheduling, the result is unpredictable.\n\nDocImpact: New Cinder scheduler filter\nChange-Id: Id428fa2132c1afed424443083645787ee3cb0399\n""}]",58,118310,0269a26f13ed36b670e55b92f7645fb989cbce86,223,36,25,12561,,,0,"Add an instance-locality filter

Having an instance and an attached volume on the same physical host
(i.e. data locality) can be desirable in some configurations, in order
to achieve high-performance disk I/O.

This patch adds an InstanceLocalityFilter filter that allow users to
request creation of volumes 'local' to an existing instance, without
specifying the hypervisor's hostname, and without any knowledge of the
underlying back-ends.

In order to work:
- At least one physical host should run both nova-compute and
  cinder-volume services.
- The Extended Server Attributes extension needs to be active in Nova
  (this is by default), so that the 'OS-EXT-SRV-ATTR:host' property is
  returned when requesting instance info.
- The user making the call needs to have sufficient rights for the
  property to be returned by Nova. This can be achieved either by
  changing Nova's policy.json (the 'extended_server_attributes' option),
  or by setting an account with privileged rights in Cinder conf.

For example:
  Instance 01234567-89ab-cdef is running in a hypervisor on the physical
  host 'my-host'.

  To create a 42 GB volume in a back-end hosted by 'my-host':
    cinder create --hint local_to_instance=01234567-89ab-cdef 42

Note:
  Currently it is not recommended to allow instance migrations for
  hypervisors where this hint will be used. In case of instance
  migration, a previously locally-created volume will not be
  automatically migrated. Also in case of instance migration during the
  volume's scheduling, the result is unpredictable.

DocImpact: New Cinder scheduler filter
Change-Id: Id428fa2132c1afed424443083645787ee3cb0399
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/118310/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/scheduler/test_host_filters.py', 'cinder/tests/scheduler/fakes.py', 'cinder/scheduler/filters/datalocality_filter.py', 'setup.cfg']",4,52a1cf26127b6b1655dd535b74b9dcce42d1404b,instance_locality_filter, InstanceLocalFilter = cinder.scheduler.filters.datalocality_filter:InstanceLocalFilter,,130,0
openstack%2Fpuppet-keystone~master~I9fc83d541266ddd28d697df500f6642208235b86,openstack/puppet-keystone,master,I9fc83d541266ddd28d697df500f6642208235b86,Use openstackclient for keystone_role,MERGED,2014-12-18 00:21:35.000000000,2015-01-07 17:57:32.000000000,2015-01-07 17:41:57.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-12-18 00:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/d445deaa3e58d8d17406e564d3cc11f714ca98c2', 'message': 'Migrate keystone_role to use openstackclient\n\nTodo: add tests\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 2, 'created': '2014-12-18 00:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/3f78a3654af47b06eedf6a6c4de265688092d757', 'message': 'Migrate keystone_role to use openstackclient\n\nTodo: add tests\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 3, 'created': '2014-12-18 00:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/9cef81872a60cf9c7951d285c2818aaa5f27bcd4', 'message': 'Migrate keystone_role to use openstackclient\n\nTodo: add tests\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 4, 'created': '2014-12-18 00:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/afb0e63574d7b3b804f33133c973c46a81cdf267', 'message': 'Migrate keystone_role to use openstackclient\n\nTodo: add tests\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 5, 'created': '2014-12-18 17:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a5fa08efc41bf9c38ce79b49cda11c7607897c5d', 'message': 'Migrate keystone_role to use openstackclient\n\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 6, 'created': '2014-12-22 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/754ccb27766bc068d3d6bd50cddc4c6d7f2847ba', 'message': 'Use openstackclient for keystone_role\n\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 7, 'created': '2014-12-23 18:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/9e52dc23b8e19d2d3b27a65ada6bafe4f78dbf0c', 'message': 'Use openstackclient for keystone_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 8, 'created': '2015-01-05 19:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ecfaf2d083cf5bdf2bfb59c22d808b7e06ebfa80', 'message': 'Use openstackclient for keystone_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}, {'number': 9, 'created': '2015-01-07 17:32:22.000000000', 'files': ['lib/puppet/provider/keystone_role/keystone.rb', 'lib/puppet/provider/keystone_role/openstack.rb', 'lib/puppet/type/keystone_role.rb', 'spec/unit/provider/keystone_role/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/4b4850473a940f3d7782dba008697444a942572b', 'message': 'Use openstackclient for keystone_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n'}]",0,142618,4b4850473a940f3d7782dba008697444a942572b,36,4,9,8482,,,0,"Use openstackclient for keystone_role

blueprint use-openstackclient-in-module-resources

Change-Id: I9fc83d541266ddd28d697df500f6642208235b86
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/18/142618/6 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_role/keystone.rb', 'lib/puppet/provider/keystone_role/openstack.rb', 'lib/puppet/type/keystone_role.rb']",3,d445deaa3e58d8d17406e564d3cc11f714ca98c2,openstackclient,"require 'puppet/util/openstack' auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_aviator_params(self, auth_param_doc)",,59,65
openstack%2Fmanila~master~I3527e6bd37f56e5b1cbae0bdccd64487871ea560,openstack/manila,master,I3527e6bd37f56e5b1cbae0bdccd64487871ea560,Fix documentation build,MERGED,2015-01-07 13:29:42.000000000,2015-01-07 17:57:04.000000000,2015-01-07 17:57:04.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2015-01-07 13:29:42.000000000', 'files': ['doc/source/devref/emc_vnx_driver.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/b2d12a00d1601553af7b261055d9304ba166e621', 'message': 'Fix documentation build\n\nmanila/share/drivers/emc/plugins/registry.py was removed which leads to:\n\nImportError: No module named registry\n\nwhile generating the documentation.\n\nChange-Id: I3527e6bd37f56e5b1cbae0bdccd64487871ea560\n'}]",0,145499,b2d12a00d1601553af7b261055d9304ba166e621,9,5,1,7102,,,0,"Fix documentation build

manila/share/drivers/emc/plugins/registry.py was removed which leads to:

ImportError: No module named registry

while generating the documentation.

Change-Id: I3527e6bd37f56e5b1cbae0bdccd64487871ea560
",git fetch https://review.opendev.org/openstack/manila refs/changes/99/145499/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/emc_vnx_driver.rst'],1,b2d12a00d1601553af7b261055d9304ba166e621,144233,,The :mod:`manila.share.drivers.emc.plugins.registry` Module ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ .. automodule:: manila.share.drivers.emc.plugins.registry :noindex: :members: :undoc-members: :show-inheritance: ,0,9
openstack%2Fpuppet-keystone~master~I2c39a6e682e3cff799b1072609c327bf338616d5,openstack/puppet-keystone,master,I2c39a6e682e3cff799b1072609c327bf338616d5,Updated wsgi file from openstack/keystone.,ABANDONED,2014-06-17 16:07:49.000000000,2015-01-07 17:55:27.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 5538}, {'_account_id': 6554}, {'_account_id': 7155}, {'_account_id': 7822}, {'_account_id': 8318}]","[{'number': 1, 'created': '2014-06-17 16:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a2b9968d36a0f382c71ebec4948d5f37268af0da', 'message': 'Updated wsgi file from openstack/keystone.\n\nThe current wsgi file does not work with\nicehouse. The file has been updated from\nthe openstack keystone repository.\n\nChange-Id: I2c39a6e682e3cff799b1072609c327bf338616d5\n'}, {'number': 2, 'created': '2014-06-18 12:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/e77e5fa0a4d168bcf96a4ed0684cf804a0c90489', 'message': 'Updated wsgi file from openstack/keystone.\n\nThe current wsgi file does not work with\nicehouse. The file has been updated from\nthe openstack keystone repository.\n\nChange-Id: I2c39a6e682e3cff799b1072609c327bf338616d5\n'}, {'number': 3, 'created': '2014-06-18 12:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ff6c3429947b2422efc4b40d52788d07bf012dd1', 'message': 'Updated wsgi file from openstack/keystone.\n\nThe current wsgi file does not work with\nicehouse. The file has been updated from\nthe openstack keystone repository.\n\nChange-Id: I2c39a6e682e3cff799b1072609c327bf338616d5\n'}, {'number': 4, 'created': '2014-11-16 08:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/2b2d8918649f817a0bd36a8b885578d1db42cf14', 'message': 'Updated wsgi file from openstack/keystone.\n\nThe current wsgi file does not work with\nicehouse. The file has been updated from\nthe openstack keystone repository.\n\nChange-Id: I2c39a6e682e3cff799b1072609c327bf338616d5\n'}, {'number': 5, 'created': '2014-11-16 09:07:18.000000000', 'files': ['files/httpd/keystone.py'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/04ce3f30570a9c1f4cca3099468f9f767cfdf42a', 'message': 'Updated wsgi file from openstack/keystone.\n\nThe current wsgi file does not work with\nicehouse. The file has been updated from\nthe openstack keystone repository.\n\nChange-Id: I2c39a6e682e3cff799b1072609c327bf338616d5\n'}]",2,100611,04ce3f30570a9c1f4cca3099468f9f767cfdf42a,36,7,5,8318,,,0,"Updated wsgi file from openstack/keystone.

The current wsgi file does not work with
icehouse. The file has been updated from
the openstack keystone repository.

Change-Id: I2c39a6e682e3cff799b1072609c327bf338616d5
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/11/100611/5 && git format-patch -1 --stdout FETCH_HEAD,['files/httpd/keystone.py'],1,a2b9968d36a0f382c71ebec4948d5f37268af0da,master-wsgi-fix,"# NOTE(dstanek): gettextutils.enable_lazy() must be called before # gettextutils._() is called to ensure it has the desired lazy lookup # behavior. This includes cases, like keystone.exceptions, where # gettextutils._() is called at import time. gettextutils.enable_lazy() from keystone.common import dependencyfrom keystone.common import sqlfrom keystone import service config.configure() sql.initialize() config.set_default_for_default_log_levels() config.setup_logging() drivers = service.load_backends() dependency.resolve_future_dependencies()",# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # This file was copied from https://github.com/openstack/keystone/raw/c3b92295b718a41c3136876eb39297081015a97c/httpd/keystone.py # It's only required for platforms on which it is not packaged yet. # It should be removed when available everywhere in a package. # # NOTE(blk-u): # gettextutils.install() must run to set _ before importing any modules that # contain static translated strings. gettextutils.install('keystone') config.setup_logging(CONF),19,14
openstack%2Fswift~master~I7c751880cb6742db7347f31c4d32b523e33da75b,openstack/swift,master,I7c751880cb6742db7347f31c4d32b523e33da75b,Add undocumented options to keystoneauth sample config,MERGED,2015-01-06 17:01:10.000000000,2015-01-07 17:48:40.000000000,2015-01-07 17:48:39.000000000,"[{'_account_id': 3}, {'_account_id': 860}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 8542}]","[{'number': 1, 'created': '2015-01-06 17:01:10.000000000', 'files': ['etc/proxy-server.conf-sample', 'swift/common/middleware/keystoneauth.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/fd8eb6b280ca15c0cfc9723c056cdac8548b34fd', 'message': 'Add undocumented options to keystoneauth sample config\n\nAdds is_admin and allow_overrides to the keystoneauth section\nof proxy-server.conf.sample and also adds related comments to\nthe keystoneauth docstring.\n\nDocImpact\n\nChange-Id: I7c751880cb6742db7347f31c4d32b523e33da75b\n'}]",0,145266,fd8eb6b280ca15c0cfc9723c056cdac8548b34fd,14,7,1,7847,,,0,"Add undocumented options to keystoneauth sample config

Adds is_admin and allow_overrides to the keystoneauth section
of proxy-server.conf.sample and also adds related comments to
the keystoneauth docstring.

DocImpact

Change-Id: I7c751880cb6742db7347f31c4d32b523e33da75b
",git fetch https://review.opendev.org/openstack/swift refs/changes/66/145266/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/proxy-server.conf-sample', 'swift/common/middleware/keystoneauth.py']",2,fd8eb6b280ca15c0cfc9723c056cdac8548b34fd,p-keystone-options," The authtoken middleware is shipped with keystonemiddleware - it does not have any other dependencies than itself so you can either installing keystonemiddleware. If the ``is_admin`` option is ``true``, a user whose username is the same as the project name and who has any role on the project will have access rights elevated to be the same as if the user had one of the ``operator_roles``. Note that the condition compares names rather than UUIDs. This option is deprecated. It is ``false`` by default. By default, middleware higher in the WSGI pipeline may override auth processing, useful for middleware such as tempurl and formpost. If you know you're not going to use such middleware and you want a bit of extra security you can disable this behaviour by setting the ``allow_overrides`` option to ``false``:: allow_overrides = false ", The authtoken middleware is shipped directly with keystone it does not have any other dependences than itself so you can either installing keystone.,31,3
openstack%2Fsahara~master~I4b0c1fc131baa2cee51aeaac1c450d6fd8c700ba,openstack/sahara,master,I4b0c1fc131baa2cee51aeaac1c450d6fd8c700ba,Add Java type edp test in integration test of CDH plugin,MERGED,2014-12-22 17:10:57.000000000,2015-01-07 17:48:32.000000000,2015-01-07 17:48:32.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-12-22 17:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fabdef629da797d7dd18621f41314827b22521e1', 'message': 'Add Java type edp test in integration test of CDH plugin\n\nChange-Id: I4b0c1fc131baa2cee51aeaac1c450d6fd8c700ba\nCloses-Bug: 1402518\n'}, {'number': 2, 'created': '2014-12-22 17:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f4418e6bb6ec80fafa0a502145f846d81a772589', 'message': 'Add Java type edp test in integration test of CDH plugin\n\nChange-Id: I4b0c1fc131baa2cee51aeaac1c450d6fd8c700ba\nCloses-Bug: 1402518\n'}, {'number': 3, 'created': '2014-12-23 01:09:08.000000000', 'files': ['sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/integration/README.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7570904b875adf1c8fca5704f71a52d42f9157e2', 'message': 'Add Java type edp test in integration test of CDH plugin\n\nChange-Id: I4b0c1fc131baa2cee51aeaac1c450d6fd8c700ba\nCloses-Bug: 1402518\n'}]",1,143499,7570904b875adf1c8fca5704f71a52d42f9157e2,42,8,3,9740,,,0,"Add Java type edp test in integration test of CDH plugin

Change-Id: I4b0c1fc131baa2cee51aeaac1c450d6fd8c700ba
Closes-Bug: 1402518
",git fetch https://review.opendev.org/openstack/sahara refs/changes/99/143499/2 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/integration/README.rst']",2,fabdef629da797d7dd18621f41314827b22521e1,bug/1402518, The CDH plugin has the following checks: ++++++++++++++++++++++++++++++++++++++++ 1. Proper cluster creation. 2. Cinder support. 3. Map Reduce. 4. Elastic Data Processing (EDP). 5. Swift availability. 6. Cluster scaling.,,20,0
openstack%2Fheat~master~I8c00d337de59cbf7b3e6f31967e55c4df4c2bb02,openstack/heat,master,I8c00d337de59cbf7b3e6f31967e55c4df4c2bb02,Remove dependency oslo-incubator.middleware.request_id,ABANDONED,2014-12-25 06:58:07.000000000,2015-01-07 17:30:56.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6676}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-12-25 06:58:07.000000000', 'files': ['heat/openstack/common/middleware/__init__.py', 'heat/openstack/common/versionutils.py', 'openstack-common.conf', 'heat/openstack/common/middleware/request_id.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/53071b5dd07ade91ca0cb81bb8f8c26b01abf976', 'message': 'Remove dependency oslo-incubator.middleware.request_id\n\nNow we are using oslo.middleware, the old code of\nopenstack.common.middleware should be removed.\n\nChange-Id: I8c00d337de59cbf7b3e6f31967e55c4df4c2bb02\n'}]",0,143937,53071b5dd07ade91ca0cb81bb8f8c26b01abf976,13,5,1,6676,,,0,"Remove dependency oslo-incubator.middleware.request_id

Now we are using oslo.middleware, the old code of
openstack.common.middleware should be removed.

Change-Id: I8c00d337de59cbf7b3e6f31967e55c4df4c2bb02
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/143937/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/middleware/__init__.py', 'heat/openstack/common/versionutils.py', 'openstack-common.conf', 'heat/openstack/common/middleware/request_id.py']",4,53071b5dd07ade91ca0cb81bb8f8c26b01abf976,rm-request-id,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Compatibility shim for Kilo, while operators migrate to oslo.middleware."""""" from oslo.middleware import request_id from heat.openstack.common import versionutils ENV_REQUEST_ID = 'openstack.request_id' HTTP_RESP_HEADER_REQUEST_ID = 'x-openstack-request-id' @versionutils.deprecated(as_of=versionutils.deprecated.KILO, in_favor_of='oslo.middleware.RequestId') class RequestIdMiddleware(request_id.RequestId): pass ",0,232
openstack%2Fbarbican-specs~master~I61665b49963d13682665f10c3d31c913207c4773,openstack/barbican-specs,master,I61665b49963d13682665f10c3d31c913207c4773,updated to use oslo.common.quota,ABANDONED,2015-01-07 16:53:34.000000000,2015-01-07 16:59:01.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-07 16:53:34.000000000', 'files': ['specs/kilo/quota-support-for-barbican-resources.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/77ecb8605883fb5b4378c9b88c305d41526045e7', 'message': 'updated to use oslo.common.quota\n\nChange-Id: I61665b49963d13682665f10c3d31c913207c4773\n'}]",0,145540,77ecb8605883fb5b4378c9b88c305d41526045e7,3,1,1,7874,,,0,"updated to use oslo.common.quota

Change-Id: I61665b49963d13682665f10c3d31c913207c4773
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/40/145540/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/quota-support-for-barbican-resources.rst'],1,77ecb8605883fb5b4378c9b88c305d41526045e7,add_quota_support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add quota support for Barbican resources ========================================== https://blueprints.launchpad.net/barbican/+spec/quota-support-on-barbican-resources Barbican REST API doesn't impose any limit on the number of resources allowed per project. This could result in resource explosion. This blueprint proposes a way to specify and enforce quotas with projects. Quotas are operational limits so that cloud resources are optimized. Problem Description =================== The current Barbican REST API for resource creation doesn't impose any limit on the maximum number of resources allowed per project. This could result in a resource explosion. Here are few scenarios that could impact the normal functioning of the Barbican server: * A client could place requests for several thousands of orders to create secrets for a single project. This might overwhelm the Barbican server both in terms of processing time and disk space consumed * If a buggy client script runs amok and attempts to create a generic type container with no associated secret, it could quickly fill-up the Barbican database! This is similar to the quota enforcement done by nova and cinder services. Proposed Change =============== Introduce quotas for all Barbican resources. The quotas should have reasonably high values as defaults. The following resources will have quota support: * secrets * orders * containers * transport_keys *Note:* This proposal is a simpler subset of the quota implemenation done by oslo.common.quota.py. Barbican does not have any reservable resources and so the quotas are much simpler in that there is no usage tracking and reservations. Also, project-user level quota enforcement is not covered by this spec. ***Enforcing quotas:*** Barbican API controllers will be updated with quota logic for the create resource methods. Once implemented, the quota check will work as follows for resource creation requests: 1. Get the quotas for the project from the auth context. If per-project quotas have not been setup, use default quotas 2. Get a count of the resource for the context project 3. If the count equals or exceeds the quotas, reject the request with the following error message: HTTP 403 Forbidden {""error"": ""Quota exceeded for <project-id>. Only <count> <resource>s are allowed"" } 4. Continue with the resource creation Update the Barbican config file to include the following section for quota limits: :: [quotas] enabled = true # number of secrets allowed per project quota_secrets = 100 # number of orders allowed per project quota_orders = 100 # number of containers allowed per project quota_containers = 50 # number of transport_keys allowed per project # Note, a negative value signifies unlimited quota_transport_keys = -1 # default driver to use for quota checks quota_driver = barbican.quota.ConfDriver no_quota_limits_for=<project id1>,<project id2>... A positive number for the quota_<value> indicates the max limit for that resource and a negative value means unlimited. While these generic quotas applies to all projects, there will be also support to enforce quotas per project and quota classes. The priority in which the quotas are enforce is then: [per tenant quotas] => [per class quotas] => [default quotas] The default quotas are stored in the config file (as shown above) but the per-tenant/class quotas are store in db. A REST API for the quota CRUD operations will be implemented as well. The details of this is discussed in a later section below. Alternatives ------------ The quota configuration and logic are derived by looking at quota implementations done by other OpenStack projects like nova, cinder and neutron. Much of this logic (sans db implementation) has been refactored into oslo.common. The implementation of this spec should make use of the oslo common quota implementation to avoid code duplication. Another alternative is an initiative by Kevin Mitchell from Rackspace https://wiki.openstack.org/wiki/Boson. However, the oslo.common implementation is more usable for Barbican. Data model impact ----------------- The following new data models will be added: * Quota Represents a single quota override for a project. If there is no row for a given project id and resource, then the default for the quota class is used. If there is no row for a given quota class and resource, then the default for the deployment is used. If the row is present but the hard limit is Null, then the resource is unlimited. Schema: (table name: **quotas**) * id: Integer, Primary Key * project_id: String(255) * resource: String(255), nullable=False * hard_limit: Integer **Contraints**: project_id + resource should be unique * QuotaClass Represents a single quota override for a quota class. If there is no row for a given quota class and resource, then the default for the deployment is used. If the row is present but the hard limit is Null, then the resource is unlimited. Schema: (table name: **quota_classes**) * id: Integer, Primary Key * class_name: String(255), nullable=False * resource: String(255), nullable=False * hard_limit: Integer **Contraints**: class_name + resource should be unique * ProjectClass Associates a project with a particular class Ideally, the auth middleware (keystone) should supply the class that a project belongs to. This could be removed once keystone supplies that detail. Schema: (table name: **project_class**) * id: Integer, Primary Key * project_id: String(255), nullable=False * class_name: String(255), nullable=False **Contraints**: project_id + class_name should be unique A new Alembic migration version script will be added which will add the models to existing Barbican deployments. * Changes to existing models: No existing models will be impacted by this addition. However, it needs to be investigated if new indexes need to be built to speed up resource consumption lookups. REST API impact --------------- The following new REST API will be implemented to manage quotas CRUD operations: * List quotas * Returns a list of all resource quotas for the project. If there are no project specific quotas, returns the class specific quota. If the project has no associated class, returns the deployment default resource limits. * GET v2/quotas * Normal http response code(s) 200 OK * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * Required request headers X-Auth-Token, if using keystone auth X-Project-Id, if using unauthenticated context * Parameters class=""<class name>"", optional. If specified, lists quotas for the specified class. Requires the caller to have Barbican admin role * JSON schema definition for the body data if allowed None * JSON schema definition for the response data if any common_quota = { 'type': ['integer', 'string'], 'pattern': '^-?[0-9]+$', # -1 is a flag value for unlimited 'minimum': -1 } EXAMPLE:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * Example 1:: A non-admin user checking the resource quotas using a token scoped to a particular project Request: GET /v2/quotas X-Auth-Token:<token> Response: 200 OK Content-Type: application/json { ""quotas"": { ""secrets"": 10, ""orders"": 20, ""containers"": 10, ""transport_keys"": 50 } } * Example 2:: An admin user checking the default resource quotas Request: GET /v2/quotas?class=default X-Auth-Token:<token> Response: 200 OK Content-Type: application/json { ""quotas"": { ""secrets"": 5, ""orders"": 10, ""containers"": 5, ""transport_keys"": 25 } } * List quotas for a specific project (admin only) * Returns a list of all resource quotas for the specified project. If there are no project specific quotas, returns the class specific quota. If the project has no associated class, returns the deployment default resource limits. * GET v2/quotas/{project_id} * Normal http response code(s) 200 OK * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * Required request headers X-Auth-Token, if using keystone auth *Note:* the caller should have barbican admin role X-Project-Id, if using unauthenticated context * JSON schema definition for the body data if allowed None * JSON schema definition for the response data if any common_quota = { 'type': ['integer', 'string'], 'pattern': '^-?[0-9]+$', # -1 is a flag value for unlimited 'minimum': -1 } Example:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * Example:: Request: GET /v2/quotas/1234 X-Auth-Token:<token> Response: 200 OK Content-Type: application/json { ""quotas"": { ""secrets"": 10, ""orders"": 20, ""containers"": 10, ""transport_keys"": 50 } } * Update/Set quotas for a specific project (admin only) * Updates and returns a list of resource quotas for the specified project. It is not required to specify limits for all Barbican resources. If a resource is not specified, the class/default limits are used for that resource. * PATCH v2/quotas/{project_id} * Normal http response code(s) 200 OK * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * 400 Bad Request - If the request payload doesn't confirm to schema * Required request headers X-Auth-Token, if using keystone auth *Note:* the caller should have barbican admin role X-Project-Id, if using unauthenticated context * JSON schema definition for the body data if allowed:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * JSON schema definition for the response data if any common_quota = { 'type': ['integer', 'string'], 'pattern': '^-?[0-9]+$', # -1 is a flag value for unlimited 'minimum': -1 } Example:: { 'type': 'object', 'properties': { 'type': 'object' 'quotas': { 'properties': { 'secrets': common_quota, 'orders': common_quota, 'containers': common_quota, 'transport_keys': common_quota }, 'additionalProperties': False } }, 'additionalProperties': False } * Example:: Request: PATCH /v2/quotas/1234 X-Auth-Token:<token> Body:: { ""quotas"": { ""secrets"": 50, ""transport_keys"": 100 } } Response: 200 OK Content-Type: application/json { ""secrets"": 50, ""orders"": 20, ""containers"": 10, ""transport_keys"": 100 } * Delete quotas for a specific project (admin only) * Deletes project specific resource quotas for the specified project. After this call succeeds, the class/default resource quotas will be returned for subsequent calls to list the project quotas. * DELETE v2/quotas/{project_id} * Normal http response code(s) 204 No Content * Expected error http response code(s) * 401 Unauthorized - If the auth token is not present or invalid * 404 Not Found - If using unauthenticated context and X-Project-Id header is not present in the request * Required request headers X-Auth-Token, if using keystone auth *Note:* the caller should have barbican admin role X-Project-Id, if using unauthenticated context * Parameters None * JSON schema definition for the body data if allowed None * JSON schema definition for the response data if any None * Example:: Request: DELETE /v2/quotas/1234 X-Auth-Token:<token> Response: 204 No Content * Policy changes For all admin-only APIs, the caller is expected to have a barbican admin role. The check for this will be added to the Barbican policy.json Once implemented and enforced, all Barbican resource creation API could return a new error message back to the client if the request exceeded the allowed quota limits. Example:: Request:: POST /v2/secrets X-Auth-Token: <token> Content-Type: application/json { # payload to create secret } Response:: 403 Forbidden Retry-After: 0 Content-Type: application/json { ""error"": ""Quota exceeded for <project-id>. Only <count> <resource>s are allowed"" } Security impact --------------- None Notifications & Audit Impact ---------------------------- None Other end user impact --------------------- The Barbican client (python-barbicanclient) has to be enhanced to consume the Quota REST API mentioned. The following scenarios should be supported. Quota commands that a regular non-admin barbican user can make: * List all quotas barbican quota show Quota commands that only a barbican admin can make * List the default quotas applicable to all new projects barbican quota show --class default * List quotas for a specific project barbican quota show --project_id <project> * Update quotas for a specific project barbican quota update --project_id <project> --secrets 50 --orders 10 * Delete per-project quotas for a project barbican quota delete --project_id <project> Performance Impact ------------------ TBD Other deployer impact --------------------- The new data models introduced will be added by a new Alembic version file. If automatic migration is turned OFF, the db migration tool has to be run manually to effect the changes. Developer impact ---------------- Developers integrating with Barbican API/client now need to handle the case where the server could return a quota violation error Implementation ============== Assignee(s) ----------- Venkat Sundaram (tsv) will be leading the implementation of the code. Primary assignee: <tsv> Other assignees: <meera> Work Items ---------- * Quota db provider source code (tsv) * Data model additions (tsv) * Updated default config file with quota section (tsv) * Alembic migration version file (tsv) * python-barbicanclient enhancements to support quota operations (tsv) * New unit tests to test quota related source changes (tsv) * Update existing resource unit tests to handle quota violation errors (tsv) * Functional tests (meera) Dependencies ============ TBD Testing ======= New functional tests and tempest tests need to be added. Details TBD Documentation Impact ==================== * A new section about Quotas has to be documented * Existing resource API documentation needs to be updated with quota violation specific errors References ========== TBD ",,710,0
openstack%2Ffuel-docs~stable%2F6.0~I24bbbb09355a04d3a88dcbe7deae5e102d60e435,openstack/fuel-docs,stable/6.0,I24bbbb09355a04d3a88dcbe7deae5e102d60e435,Updated link to demo (6.0),MERGED,2015-01-07 12:44:01.000000000,2015-01-07 16:58:18.000000000,2015-01-07 16:58:17.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-01-07 12:44:01.000000000', 'files': ['index.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/75d35431a5e693f8340a195a0a318809e8cdfe74', 'message': 'Updated link to demo (6.0)\n\nChange-Id: I24bbbb09355a04d3a88dcbe7deae5e102d60e435\n'}]",0,145488,75d35431a5e693f8340a195a0a318809e8cdfe74,7,3,1,406,,,0,"Updated link to demo (6.0)

Change-Id: I24bbbb09355a04d3a88dcbe7deae5e102d60e435
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/88/145488/1 && git format-patch -1 --stdout FETCH_HEAD,['index.rst'],1,75d35431a5e693f8340a195a0a318809e8cdfe74,,`Demos and tutorials <https://www.youtube.com/watch?v=ET4hkzb_QRM>`__ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Watch the Mirantis OpenStack demos at https://www.youtube.com/watch?v=ET4hkzb_QRM,`Demos and tutorials <https://vimeo.com/96222550>`__ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Watch the Mirantis OpenStack demos at https://vimeo.com/96222550,3,3
openstack%2Ffuel-docs~master~I24bbbb09355a04d3a88dcbe7deae5e102d60e435,openstack/fuel-docs,master,I24bbbb09355a04d3a88dcbe7deae5e102d60e435,Updated link to demo (6.0),MERGED,2015-01-07 12:39:49.000000000,2015-01-07 16:58:00.000000000,2015-01-07 16:58:00.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-01-07 12:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/fc09908e2e762b620efee9b756938ab80376d399', 'message': 'Updated link to demo (6.0)\n\nChange-Id: I24bbbb09355a04d3a88dcbe7deae5e102d60e435\n'}, {'number': 2, 'created': '2015-01-07 12:42:04.000000000', 'files': ['index.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/822516521dacdc1a475d6e94619b8de4219f25c0', 'message': 'Updated link to demo (6.0)\n\nChange-Id: I24bbbb09355a04d3a88dcbe7deae5e102d60e435\n'}]",0,145486,822516521dacdc1a475d6e94619b8de4219f25c0,13,3,2,406,,,0,"Updated link to demo (6.0)

Change-Id: I24bbbb09355a04d3a88dcbe7deae5e102d60e435
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/86/145486/1 && git format-patch -1 --stdout FETCH_HEAD,['index.rst'],1,fc09908e2e762b620efee9b756938ab80376d399,,`Demos and tutorials <https://www.youtube.com/watch?v=ET4hkzb_QRM>`__Watch the Mirantis OpenStack demos at https://www.youtube.com/watch?v=ET4hkzb_QRM,`Demos and tutorials <https://vimeo.com/96222550>`__Watch the Mirantis OpenStack demos at https://vimeo.com/96222550,2,2
openstack%2Fopenstack-ansible~master~I91a6ab3994be348b17caaf9c9200d84463076d87,openstack/openstack-ansible,master,I91a6ab3994be348b17caaf9c9200d84463076d87,Configure disks for hp cloud instances,MERGED,2015-01-06 14:33:06.000000000,2015-01-07 16:50:39.000000000,2015-01-07 16:50:38.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 14513}]","[{'number': 1, 'created': '2015-01-06 14:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7374ff5f4851033750152bb4f865de617774e3de', 'message': 'Dont Merge, debugging AIO\n\nChange-Id: I91a6ab3994be348b17caaf9c9200d84463076d87\n'}, {'number': 2, 'created': '2015-01-06 15:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d95a91c8460e2c76e98f6b890273b9c333fc438e', 'message': 'Dont Merge, debugging AIO\n\nChange-Id: I91a6ab3994be348b17caaf9c9200d84463076d87\n'}, {'number': 3, 'created': '2015-01-07 10:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2deb6d43c05f9675d3ca90f8114ba7c7f5b44236', 'message': 'Dont Merge, debugging AIO\n\nChange-Id: I91a6ab3994be348b17caaf9c9200d84463076d87\n'}, {'number': 4, 'created': '2015-01-07 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4f1e759761489b9c67dde49e27ec78b7ce7224ea', 'message': 'Dont Merge, debugging AIO\n\nChange-Id: I91a6ab3994be348b17caaf9c9200d84463076d87\n'}, {'number': 5, 'created': '2015-01-07 13:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a3ab7bf60edf891761f76d9f2e1b6250831ed6c7', 'message': 'Configure disks for hp cloud instances\n\nNodepool sometimes provides an hp cloud instance that has the majority\nof space in /dev/vdb which is mounted at /mnt. This patch repurposes\nthat partition as an lvm VG for containers.\n\nAlso:\n * creates an LV for /opt and mounts that.\n * outputs some instance info that may be useful for debugging\n\nCloses-Bug: #1407647\n\nChange-Id: I91a6ab3994be348b17caaf9c9200d84463076d87\n'}, {'number': 6, 'created': '2015-01-07 13:54:29.000000000', 'files': ['scripts/os-ansible-aio-check.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a4785cba7d5d10e06854998b3faa71d2cf0641e2', 'message': 'Configure disks for hp cloud instances\n\nNodepool sometimes provides an hp cloud instance that has the majority\nof space in /dev/vdb which is mounted at /mnt. This patch repurposes\nthat partition as an lvm VG for containers.\n\nAlso:\n * creates an LV for /opt and mounts that.\n * outputs some instance info that may be useful for debugging\n\nCloses-Bug: #1407647\n\nChange-Id: I91a6ab3994be348b17caaf9c9200d84463076d87\n'}]",0,145234,a4785cba7d5d10e06854998b3faa71d2cf0641e2,26,6,6,7217,,,0,"Configure disks for hp cloud instances

Nodepool sometimes provides an hp cloud instance that has the majority
of space in /dev/vdb which is mounted at /mnt. This patch repurposes
that partition as an lvm VG for containers.

Also:
 * creates an LV for /opt and mounts that.
 * outputs some instance info that may be useful for debugging

Closes-Bug: #1407647

Change-Id: I91a6ab3994be348b17caaf9c9200d84463076d87
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/145234/3 && git format-patch -1 --stdout FETCH_HEAD,['scripts/os-ansible-aio-check.sh'],1,7374ff5f4851033750152bb4f865de617774e3de,bug/1407647, successerator ansible-playbook -vvvv -e @/etc/rpc_deploy/user_variables.yml \, successerator ansible-playbook -e @/etc/rpc_deploy/user_variables.yml \,1,1
openstack%2Fdesignate~master~Iabda1f2e0abf726faa74853f6b85e57d15f99a08,openstack/designate,master,Iabda1f2e0abf726faa74853f6b85e57d15f99a08,Zones prematurely marked ACTIVE,ABANDONED,2015-01-05 21:29:20.000000000,2015-01-07 16:48:53.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-05 21:29:20.000000000', 'files': ['designate/central/service.py', 'designate/pool_manager/service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/6cbb10aedb21d5be5ce1b4cd31753d7188c188e8', 'message': ""Zones prematurely marked ACTIVE\n\n*Delays making a choice on zone status until after create_domain\nmethod unless it's certain. A delayed poll or periodic sync will\nmark the zone ACTIVE\n*Adds a couple checks on errors to make sure a zone that never\nsuccessfully transferred is marked ERROR\n\nChange-Id: Iabda1f2e0abf726faa74853f6b85e57d15f99a08\nCloses-Bug: 1404377\n""}]",0,145067,6cbb10aedb21d5be5ce1b4cd31753d7188c188e8,3,1,1,8174,,,0,"Zones prematurely marked ACTIVE

*Delays making a choice on zone status until after create_domain
method unless it's certain. A delayed poll or periodic sync will
mark the zone ACTIVE
*Adds a couple checks on errors to make sure a zone that never
successfully transferred is marked ERROR

Change-Id: Iabda1f2e0abf726faa74853f6b85e57d15f99a08
Closes-Bug: 1404377
",git fetch https://review.opendev.org/openstack/designate refs/changes/67/145067/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/central/service.py', 'designate/pool_manager/service.py']",2,6cbb10aedb21d5be5ce1b4cd31753d7188c188e8,bug/1404377," status = None if self._is_update_consensus(context, domain): status = SUCCESS_STATUS if not self._is_create_consensus(context, domain): status = ERROR_STATUS # If status is None, more time is needed and we stay PENDING if status is not None: self.central_api.update_status( context, domain.id, status, domain.serial) if error_serial > consensus_serial or error_serial == 0: def _is_update_consensus(self, context, domain): return self._is_success_consensus(context, domain, UPDATE_ACTION) "," status = ERROR_STATUS if self._is_create_consensus(context, domain): status = SUCCESS_STATUS self.central_api.update_status( context, domain.id, status, domain.serial) if error_serial > consensus_serial:",15,8
openstack%2Fbarbican~master~If4810b5e96ade5255d7886eb9480157329380b97,openstack/barbican,master,If4810b5e96ade5255d7886eb9480157329380b97,Plugin contract changes for the certificate-order-api,MERGED,2014-12-16 20:27:39.000000000,2015-01-07 16:46:26.000000000,2015-01-07 16:46:24.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 10035}, {'_account_id': 10273}]","[{'number': 1, 'created': '2014-12-16 20:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d5b7729bde7746b579cc94fed7021aa7e01d16e0', 'message': 'Second commit for Common Cert API\n\nThis patch adds the plugin contract changes and code needed\nto pass the new cert request types to the plugins.\n\nNote that this is different from the blueprint - in that we\nnow introduce a provides() method, and we no longer use separate\nAPI calls to distinguish between types.\n\nMissing logic in some functions is expected to be filled in\nin subsequent patches.\n\nChange-Id: If4810b5e96ade5255d7886eb9480157329380b97\n'}, {'number': 2, 'created': '2014-12-17 03:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/2e8f174a1e9cf44b46a22be6fe2cd6ddb85ef060', 'message': 'Second commit for Common Cert API\n\nThis patch adds the plugin contract changes and code needed\nto pass the new cert request types to the plugins.\n\nNote that this is different from the blueprint - in that we\nnow introduce a provides() method, and we no longer use separate\nAPI calls to distinguish between types.\n\nMissing logic in some functions is expected to be filled in\nin subsequent patches.\n\nChange-Id: If4810b5e96ade5255d7886eb9480157329380b97\n'}, {'number': 3, 'created': '2015-01-05 19:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/05fc3ad36b32b02ea5dfc5528b4a915d0e897bb6', 'message': 'Plugin contract changes for the certificate-order-api\n\nThis patch adds the plugin contract changes and code needed\nto pass the new cert request types to the plugins.\n\nNote that this is different from the blueprint - in that we\nnow introduce a provides() method, and we no longer use separate\nAPI calls to distinguish between types.\n\nMissing logic in some functions is expected to be filled in\nin subsequent patches.\n\nChange-Id: If4810b5e96ade5255d7886eb9480157329380b97\n'}, {'number': 4, 'created': '2015-01-05 20:02:32.000000000', 'files': ['barbican/plugin/simple_certificate_manager.py', 'barbican/tests/tasks/test_certificate_resources.py', 'barbican/tests/plugin/interface/test_certificate_manager.py', 'barbican/tasks/certificate_resources.py', 'barbican/tests/plugin/test_simple_certificate_manager.py', 'barbican/plugin/interface/certificate_manager.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e37fe9624ad03c478228c6f7683cf2ffd8b7825b', 'message': 'Plugin contract changes for the certificate-order-api\n\nThis patch adds the plugin contract changes and code needed\nto pass the new cert request types to the plugins.\n\nNote that this is different from the blueprint - in that we\nnow introduce a supported_request_types() method, and we no longer use separate\nAPI calls to distinguish between types.\n\nMissing logic in some functions is expected to be filled in\nin subsequent patches.\n\nChange-Id: If4810b5e96ade5255d7886eb9480157329380b97\nImplements: blueprint certificate-order-api\n'}]",7,142212,e37fe9624ad03c478228c6f7683cf2ffd8b7825b,18,6,4,9914,,,0,"Plugin contract changes for the certificate-order-api

This patch adds the plugin contract changes and code needed
to pass the new cert request types to the plugins.

Note that this is different from the blueprint - in that we
now introduce a supported_request_types() method, and we no longer use separate
API calls to distinguish between types.

Missing logic in some functions is expected to be filled in
in subsequent patches.

Change-Id: If4810b5e96ade5255d7886eb9480157329380b97
Implements: blueprint certificate-order-api
",git fetch https://review.opendev.org/openstack/barbican refs/changes/12/142212/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/plugin/simple_certificate_manager.py', 'barbican/tests/plugin/interface/test_certificate_manager.py', 'barbican/tasks/certificate_resources.py', 'barbican/tests/plugin/test_simple_certificate_manager.py', 'barbican/plugin/interface/certificate_manager.py']",5,d5b7729bde7746b579cc94fed7021aa7e01d16e0,certificate-order-api,"#certificate request types REQUEST_TYPE = ""request_type"" CUSTOM_REQUEST = ""custom"" FULL_CMC_REQUEST = ""full-cmc"" SIMPLE_CMC_REQUEST = ""simple-cmc"" STORED_KEY_REQUEST = ""stored-key"" def provides(self): """"""Returns the capabilities supported by this plugin. :returns: dict containing Barbican-core defined capabilities of this plugin. The current defined capabilities are: REQUEST_TYPE -- which defaults to CUSTOM_REQUEST """""" return {REQUEST_TYPE, [CUSTOM_REQUEST]} request_type = certificate_spec.get(REQUEST_TYPE, CUSTOM_REQUEST) for ext in self.extensions: supported_request_types = ext.obj.provides().get(REQUEST_TYPE) if request_type not in supported_request_types: continue :returns: CertificateEventPluginBase plugin implementation", for ext in self.extensions: :returns: CertficiateEventPluginBase plugin implementation,118,1
openstack%2Fgnocchi~master~I1c0586bdef88c68e045a5a66d14418c710d1f241,openstack/gnocchi,master,I1c0586bdef88c68e045a5a66d14418c710d1f241,storage: change create_metric() to accept ArchivePolicy as argument,MERGED,2015-01-06 17:30:42.000000000,2015-01-07 16:43:51.000000000,2015-01-07 16:43:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2015-01-06 17:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0ff1c465e79ce8b715700a79dab088738658a497', 'message': 'storage: change create_metric() to accept ArchivePolicy as argument\n\nThis should simplify the prototype of create_metric() and allow other\ncomponents than gnocchi.rest to create metric properly.\n\nChange-Id: I1c0586bdef88c68e045a5a66d14418c710d1f241\n'}, {'number': 2, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f45c9a05e2898ea3a45ddadac373fb6765aa7860', 'message': 'storage: change create_metric() to accept ArchivePolicy as argument\n\nThis should simplify the prototype of create_metric() and allow other\ncomponents than gnocchi.rest to create metric properly.\n\nChange-Id: I1c0586bdef88c68e045a5a66d14418c710d1f241\n'}, {'number': 3, 'created': '2015-01-07 13:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d8e6908c7d71121ff5ed3b655e6c9d36d4323b24', 'message': 'storage: change create_metric() to accept ArchivePolicy as argument\n\nThis should simplify the prototype of create_metric() and allow other\ncomponents than gnocchi.rest to create metric properly.\n\nChange-Id: I1c0586bdef88c68e045a5a66d14418c710d1f241\n'}, {'number': 4, 'created': '2015-01-07 15:50:44.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/base.py', 'gnocchi/storage/__init__.py', 'gnocchi/tests/test_aggregates.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py', 'gnocchi/storage/null.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0c1a9673d51f188866f40c6e6a5728855c274731', 'message': 'storage: change create_metric() to accept ArchivePolicy as argument\n\nThis should simplify the prototype of create_metric() and allow other\ncomponents than gnocchi.rest to create metric properly.\n\nChange-Id: I1c0586bdef88c68e045a5a66d14418c710d1f241\n'}]",1,145275,0c1a9673d51f188866f40c6e6a5728855c274731,15,3,4,1669,,,0,"storage: change create_metric() to accept ArchivePolicy as argument

This should simplify the prototype of create_metric() and allow other
components than gnocchi.rest to create metric properly.

Change-Id: I1c0586bdef88c68e045a5a66d14418c710d1f241
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/75/145275/4 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/base.py', 'gnocchi/storage/__init__.py', 'gnocchi/tests/test_aggregates.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/tests/test_storage.py', 'gnocchi/storage/null.py', 'gnocchi/tests/test_rest.py']",8,0ff1c465e79ce8b715700a79dab088738658a497,jd/statsd," self.archive_policies['medium'].to_human_readable_dict(), for name, ap in six.iteritems(self.archive_policies): self.assertIn(ap.to_human_readable_dict(), aps) self.archive_policies['medium'].to_human_readable_dict(), self.archive_policies['medium'].to_human_readable_dict(),"," {""name"": ""medium"", ""back_window"": 0, ""definition"": [ archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() for d in self.archive_policies['medium'] ]}, for name, definition in six.iteritems(self.archive_policies): self.assertIn( {""name"": name, ""back_window"": 0, ""definition"": [ archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() for d in definition ]}, aps) {""name"": ""medium"", ""back_window"": 0, ""definition"": [ archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() for d in self.archive_policies['medium'] ]}, {""name"": ""medium"", ""back_window"": 0, ""definition"": [ archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() for d in self.archive_policies['medium'] ]},",29,58
openstack%2Fmanila~master~If80a31beca54ac4193b7b72b8c49c928b18d356f,openstack/manila,master,If80a31beca54ac4193b7b72b8c49c928b18d356f,Fix TypeError in tempest retry functionality,MERGED,2015-01-06 19:21:57.000000000,2015-01-07 16:43:35.000000000,2015-01-07 16:32:58.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}]","[{'number': 1, 'created': '2015-01-06 19:21:57.000000000', 'files': ['contrib/tempest/tempest/api/share/base.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/acc00e30236ec190df478fcf3f31647b4aaec489', 'message': 'Fix TypeError in tempest retry functionality\n\nWhen we get error with share creation and retry is enabled log message\nis combined. But formatting was with mistake. It expected named/mapped\nformating but got positioned formatting.\n\nChange-Id: If80a31beca54ac4193b7b72b8c49c928b18d356f\nCloses-Bug: #1408069\n'}]",0,145309,acc00e30236ec190df478fcf3f31647b4aaec489,12,6,1,8851,,,0,"Fix TypeError in tempest retry functionality

When we get error with share creation and retry is enabled log message
is combined. But formatting was with mistake. It expected named/mapped
formating but got positioned formatting.

Change-Id: If80a31beca54ac4193b7b72b8c49c928b18d356f
Closes-Bug: #1408069
",git fetch https://review.opendev.org/openstack/manila refs/changes/09/145309/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/base.py'],1,acc00e30236ec190df478fcf3f31647b4aaec489,bug/1408069," msg = (""Share '%s' failed to be built. """," msg = (""Share '%(id)s' failed to be built. """,1,1
openstack%2Ffuel-library~stable%2F5.0~I68c8eda5fa0b527764e2ad65bc0979cc2e5a47d4,openstack/fuel-library,stable/5.0,I68c8eda5fa0b527764e2ad65bc0979cc2e5a47d4,Ensure reliable cleanup of resources,MERGED,2014-09-09 15:43:57.000000000,2015-01-07 16:36:52.000000000,2015-01-07 16:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-09-09 15:43:57.000000000', 'files': ['deployment/puppet/corosync/lib/puppet/provider/service/pacemaker.rb', 'deployment/puppet/corosync/lib/puppet/provider/cs_resource/crm.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b538a2baa1cfc3c345e6f7d52f5ca191abdd2b74', 'message': ""Ensure reliable cleanup of resources\n\nPacemaker for some unknown reasons fails to\ncleanup errors in some conditions and doesn't\nperform required operations.\nThis patch adds duplicate cleanups.\n\nCloses-Bug: 1367340\nChange-Id: I68c8eda5fa0b527764e2ad65bc0979cc2e5a47d4\n""}]",0,120127,b538a2baa1cfc3c345e6f7d52f5ca191abdd2b74,20,7,1,9037,,,0,"Ensure reliable cleanup of resources

Pacemaker for some unknown reasons fails to
cleanup errors in some conditions and doesn't
perform required operations.
This patch adds duplicate cleanups.

Closes-Bug: 1367340
Change-Id: I68c8eda5fa0b527764e2ad65bc0979cc2e5a47d4
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/120127/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/corosync/lib/puppet/provider/service/pacemaker.rb', 'deployment/puppet/corosync/lib/puppet/provider/cs_resource/crm.rb']",2,b538a2baa1cfc3c345e6f7d52f5ca191abdd2b74,bug/1367340," crm('resource', 'cleanup', @resource[:name]) crm('resource', 'manage', @resource[:name])",,9,1
openstack%2Fpython-solumclient~master~I557c56916b13ca58104314e421e4f25fbf47a4a3,openstack/python-solumclient,master,I557c56916b13ca58104314e421e4f25fbf47a4a3,Add created_at and updated_at to assembly,MERGED,2015-01-06 20:54:23.000000000,2015-01-07 16:34:26.000000000,2015-01-07 16:34:25.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 9095}]","[{'number': 1, 'created': '2015-01-06 20:54:23.000000000', 'files': ['solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/f685202f4688d6b6bdc82bcdf09ef2946ae7c0fc', 'message': 'Add created_at and updated_at to assembly\n\nExpose the created_at and updated_at fields of assembly\nobjects, sorting by updated_at field. This puts the oldest\nassemblies on the top of the list due to how cliutils\nprint_list orders rows.\n\nChange-Id: I557c56916b13ca58104314e421e4f25fbf47a4a3\n'}]",0,145337,f685202f4688d6b6bdc82bcdf09ef2946ae7c0fc,9,4,1,1375,,,0,"Add created_at and updated_at to assembly

Expose the created_at and updated_at fields of assembly
objects, sorting by updated_at field. This puts the oldest
assemblies on the top of the list due to how cliutils
print_list orders rows.

Change-Id: I557c56916b13ca58104314e421e4f25fbf47a4a3
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/37/145337/1 && git format-patch -1 --stdout FETCH_HEAD,['solumclient/solum.py'],1,f685202f4688d6b6bdc82bcdf09ef2946ae7c0fc,assembly-dates," fields = ['uuid', 'name', 'description', 'status', 'created_at', 'updated_at'] cliutils.print_list(response, fields, sortby_index=5) 'trigger_uri', 'created_at', 'updated_at']"," fields = ['uuid', 'name', 'description', 'status'] cliutils.print_list(response, fields) 'trigger_uri']",4,3
openstack%2Fmanila~master~I26194e77dfb0c6e303772d5924f0a0f512a48cda,openstack/manila,master,I26194e77dfb0c6e303772d5924f0a0f512a48cda,Fix concurrency problem in getting share network in Tempest,MERGED,2015-01-02 12:16:45.000000000,2015-01-07 16:32:52.000000000,2015-01-07 16:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-01-02 12:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f12833f18d0c3ed3a86394fa77443a2e7b2a997b', 'message': 'Fix concurrency getting share network in Tempest\n\nIn CI Tempest jobs we get error ""share network not found"" from time to time.\nCause for it was in improper usage of networks for isolated creds, that were\ndeleting share networks but did not create/use separate networks.\nSo, concurrent test suites were taken share network that becomes deleted by\nanother test suite within ""cleanup"" operation.\n\nMake isolated creds use separate networks and delete such separate networks\nin cleanup. It will make concurrent test suites with and without isolated creds\nuse different share networks.\n\nChange-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda\nCloses-Bug: #1406655\n'}, {'number': 2, 'created': '2015-01-02 15:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/bdc431dc4ff5342ba6657cf93baf2c497a067272', 'message': 'Fix concurrency getting share network in Tempest\n\nIn CI Tempest jobs we get error ""share network not found"" from time to time.\nCause for it was in improper usage of networks for isolated creds, that were\ndeleting share networks but did not use separate networks.\nSo, concurrent test suites were taken share network that becomes deleted by\nanother test suite within ""cleanup"" operation.\n\nMake isolated creds use separate networks. It will make concurrent test suites\nwith and without isolated creds use different share networks.\n\nRemove usage of external lock for method ""provide_share_network"" for tests\nthat use isolated creds.\n\nChange-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda\nCloses-Bug: #1406655\n'}, {'number': 3, 'created': '2015-01-02 15:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/49d9b08fa887a4ef7baddaff3bcaf80b2b837cb9', 'message': 'Fix concurrency getting share network in Tempest\n\nIn CI Tempest jobs we get error ""share network not found"" from time to time.\nCause for it was in improper usage of networks for isolated creds, that were\ndeleting share networks but did not use separate networks.\nSo, concurrent test suites were taken share network that becomes deleted by\nanother test suite within ""cleanup"" operation.\n\nMake isolated creds use separate networks. It will make concurrent test suites\nwith and without isolated creds use different share networks.\n\nRemove usage of external lock for method ""provide_share_network"" for tests\nthat use isolated creds.\n\nChange-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda\nCloses-Bug: #1406655\n'}, {'number': 4, 'created': '2015-01-02 17:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a16371770ba66f465dafd67bd0e5bc57bbaf975a', 'message': 'Fix concurrency getting share network in Tempest\n\nIn CI Tempest jobs we get error ""share network not found"" from time to time.\nCause for it was in improper usage of networks for isolated creds, that were\ndeleting share networks but did not use separate networks.\nSo, concurrent test suites were taken share network that becomes deleted by\nanother test suite within ""cleanup"" operation.\n\nMake isolated creds use separate networks. It will make concurrent test suites\nwith and without isolated creds use different share networks.\n\nRemove usage of external lock for method ""provide_share_network"" for tests\nthat use isolated creds.\n\nChange-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda\nCloses-Bug: #1406655\n'}, {'number': 5, 'created': '2015-01-02 18:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1753ed2249473f43f3e0019fecbf11dd18313b34', 'message': 'Fix concurrency getting share network in Tempest\n\nIn CI Tempest jobs we get error ""share network not found"" from time to time.\nCause for it was in improper usage of networks for isolated creds, that were\ndeleting share networks but did not use separate networks.\nSo, concurrent test suites were taken share network that becomes deleted by\nanother test suite within ""cleanup"" operation.\n\nMake isolated creds use separate networks. It will make concurrent test suites\nwith and without isolated creds use different share networks.\n\nRemove usage of external lock for method ""provide_share_network"" for tests\nthat use isolated creds.\n\nChange-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda\nCloses-Bug: #1406655\n'}, {'number': 6, 'created': '2015-01-04 07:53:24.000000000', 'files': ['contrib/tempest/tempest/api/share/base.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/28a5debbe21a70eab5d6cf0303605bff46702d39', 'message': 'Fix concurrency problem in getting share network in Tempest\n\nIn CI Tempest jobs we get error ""share network not found"" from time to time.\nCause for it was improper usage of networks for isolated creds, that were\ndeleting share networks but did not use separate networks.\nSo, concurrent test suites were taking share network that became deleted by\nanother test suite within ""cleanup"" operation.\n\nMake isolated creds use separate networks. It will make concurrent test suites\nwith and without isolated creds use different share networks.\n\nRemove usage of external lock for method ""provide_share_network"" for tests\nthat use isolated creds.\n\nChange-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda\nCloses-Bug: #1406655\n'}]",6,144741,28a5debbe21a70eab5d6cf0303605bff46702d39,20,7,6,8851,,,0,"Fix concurrency problem in getting share network in Tempest

In CI Tempest jobs we get error ""share network not found"" from time to time.
Cause for it was improper usage of networks for isolated creds, that were
deleting share networks but did not use separate networks.
So, concurrent test suites were taking share network that became deleted by
another test suite within ""cleanup"" operation.

Make isolated creds use separate networks. It will make concurrent test suites
with and without isolated creds use different share networks.

Remove usage of external lock for method ""provide_share_network"" for tests
that use isolated creds.

Change-Id: I26194e77dfb0c6e303772d5924f0a0f512a48cda
Closes-Bug: #1406655
",git fetch https://review.opendev.org/openstack/manila refs/changes/41/144741/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/base.py'],1,f12833f18d0c3ed3a86394fa77443a2e7b2a997b,bug/1406655," share_network_id = cls.provide_share_network(client, nc, True) def provide_share_network(cls, shares_client, network_client, clear_network_resources=False): :param clear_network_resources: boolean -- whether to clean up net resources, that will be created or not. If set to False, then network will stay. It is common case. If set to True, we assume this net will not be reused and can/should be deleted. It is useful for case with isolated creds. if clear_network_resources: # Add tenant_id at beggining. It will allow us to use this net # only for current isolated creds. We use searching by subset # because suffix will be added to net name by operation # of automatic network creation. service_net_name = sc.tenant_id + service_net_name else: # Search for networks, created in previous runs networks = network_client.list_networks() if ""networks"" in networks.keys(): networks = networks[""networks""] for network in networks: if service_net_name in network[""name""]: net_id = network[""id""] if len(network[""subnets""]) > 0: subnet_id = network[""subnets""][0] break if clear_network_resources: # Add it to list of resources that will be used for cleanup ic.isolated_net_resources[service_net_name] = net_data if not clear_network_resources: # Try get suitable share-network __, share_networks = sc.list_share_networks_with_detail() for share_network in share_networks: if (net_id == share_network[""neutron_net_id""] and subnet_id == share_network[""neutron_subnet_id""]): share_network_id = share_network[""id""] break"," share_network_id = cls.provide_share_network(client, nc) def provide_share_network(cls, shares_client, network_client): # Search for networks, created in previous runs networks = network_client.list_networks() if ""networks"" in networks.keys(): networks = networks[""networks""] for network in networks: if service_net_name in network[""name""]: net_id = network[""id""] if len(network[""subnets""]) > 0: subnet_id = network[""subnets""][0] break # Try get suitable share-network __, share_networks = sc.list_share_networks_with_detail() for share_network in share_networks: if (net_id == share_network[""neutron_net_id""] and subnet_id == share_network[""neutron_subnet_id""]): share_network_id = share_network[""id""] break",37,20
openstack%2Fmanila~master~Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a,openstack/manila,master,Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a,Make it possible to update tempest conf in all CI Tempest jobs,MERGED,2014-12-31 09:14:53.000000000,2015-01-07 16:32:39.000000000,2015-01-07 16:32:38.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-31 09:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ca1d53722ce2b84b35e2df99980a1f84439dcd89', 'message': ""Make it possible to update tempest conf in all CI Tempest jobs\n\nFor the moment bash function 'iniset' is imported from devstack only for\nmulti backend Tempest job. It causes absense of set options for single backend\ninstallation, because absent function 'iniset' is tried to be used.\n\nDue to described problem single backend installation does not have enabled\nerror suppressing in resource cleanup and retry mechanism is disabled.\n\nChange-Id: Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a\n""}, {'number': 2, 'created': '2015-01-02 19:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b729b0120329c63541ec9789475aa8e2403b5306', 'message': ""Make it possible to update tempest conf in all CI Tempest jobs\n\nFor the moment bash function 'iniset' is imported from devstack only for\nmulti backend Tempest job. It causes absense of set options for single backend\ninstallation, because absent function 'iniset' is tried to be used.\n\nDue to described problem single backend installation does not have enabled\nerror suppressing in resource cleanup and retry mechanism is disabled.\n\nChange-Id: Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a\n""}, {'number': 3, 'created': '2015-01-04 07:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/65f1ab30fcb4f4b60ceb79da16249450a87d313f', 'message': ""Make it possible to update tempest conf in all CI Tempest jobs\n\nFor the moment bash function 'iniset' is imported from devstack only for\nmulti backend Tempest job. It causes absence of set options for single backend\ninstallation, because absent function 'iniset' is attempted to be used.\n\nDue to described problem single backend installation does not have enabled\nerror suppressing in resource cleanup and retry mechanism is disabled.\n\nChange-Id: Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a\n""}, {'number': 4, 'created': '2015-01-04 07:47:17.000000000', 'files': ['contrib/ci/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/4e74778ab004dc100afdac2e6bf46ea0dac2b431', 'message': ""Make it possible to update tempest conf in all CI Tempest jobs\n\nFor the moment bash function 'iniset' is imported from devstack only for\nmulti backend Tempest job. It causes absence of set options for single backend\ninstallation, because absent function 'iniset' is attempted to be used.\n\nDue to described problem single backend installation does not have enabled\nerror suppressing in resource cleanup and retry mechanism is disabled.\n\nChange-Id: Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a\n""}]",4,144616,4e74778ab004dc100afdac2e6bf46ea0dac2b431,17,7,4,8851,,,0,"Make it possible to update tempest conf in all CI Tempest jobs

For the moment bash function 'iniset' is imported from devstack only for
multi backend Tempest job. It causes absence of set options for single backend
installation, because absent function 'iniset' is attempted to be used.

Due to described problem single backend installation does not have enabled
error suppressing in resource cleanup and retry mechanism is disabled.

Change-Id: Ib79be4c6b781e7c9e000dcea617cc8b03e5b4e7a
",git fetch https://review.opendev.org/openstack/manila refs/changes/16/144616/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/ci/post_test_hook.sh'],1,ca1d53722ce2b84b35e2df99980a1f84439dcd89,tempest,# Import devstack function 'iniset' source $BASE/new/devstack/functions , source $BASE/new/devstack/functions,3,1
openstack%2Fpython-magnumclient~master~I965512e9c87ec00c33ef273bc7421151ebd3ea9c,openstack/python-magnumclient,master,I965512e9c87ec00c33ef273bc7421151ebd3ea9c,Add client test for test_pods,MERGED,2015-01-04 14:44:20.000000000,2015-01-07 16:20:44.000000000,2015-01-07 16:20:44.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-04 14:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/dac3b49fc633fa2b26ba28e1cf3857563f6b8cfd', 'message': 'Add client test for test_pods\n\nChange-Id: I965512e9c87ec00c33ef273bc7421151ebd3ea9c\n'}, {'number': 2, 'created': '2015-01-07 14:16:06.000000000', 'files': ['magnumclient/tests/v1/test_pods.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/692f8ab50f4ecf8d40605d535e85077b8e79c510', 'message': 'Add client test for test_pods\n\nChange-Id: I965512e9c87ec00c33ef273bc7421151ebd3ea9c\n'}]",0,144886,692f8ab50f4ecf8d40605d535e85077b8e79c510,11,4,2,7494,,,0,"Add client test for test_pods

Change-Id: I965512e9c87ec00c33ef273bc7421151ebd3ea9c
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/86/144886/1 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/tests/v1/test_pods.py'],1,dac3b49fc633fa2b26ba28e1cf3857563f6b8cfd,master,"# -*- coding: utf-8 -*- # # Copyright 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import testtools from testtools import matchers from magnumclient.tests import utils from magnumclient.v1 import pods POD1 = {'id': 123, 'uuid': '66666666-7777-8888-9999-000000000000', 'name': 'pod1', 'desc': ""desc"", 'bay_uuid': '5d12f6fd-a196-4bf0-ae4c-1f639a523a52', 'images': ['image1', 'image2'], 'labels': {'foo': 'bar'}, 'status': 'Running' } POD2 = {'id': 124, 'uuid': '66666666-7777-8888-9999-000000000001', 'name': 'pod1', 'desc': ""desc"", 'bay_uuid': '5d12f6fd-a196-4bf0-ae4c-1f639a523a53', 'images': ['image1', 'image2'], 'labels': {'foo': 'bar'}, 'status': 'Running' } CREATE_POD = copy.deepcopy(POD1) fake_responses = { '/v1/pods': { 'GET': ( {}, {'pods': [POD1, POD2]}, ), }, '/v1/pods/%s' % POD1['id']: { 'GET': ( {}, POD1 ), } } class PodManagerTest(testtools.TestCase): def setUp(self): super(PodManagerTest, self).setUp() self.api = utils.FakeAPI(fake_responses) self.mgr = pods.PodManager(self.api) def test_pod_list(self): pods = self.mgr.list() expect = [ ('GET', '/v1/pods', {}, None), ] self.assertEqual(expect, self.api.calls) self.assertThat(pods, matchers.HasLength(2)) def test_pod_show(self): pod = self.mgr.get(POD1['id']) expect = [ ('GET', '/v1/pods/%s' % POD1['id'], {}, None) ] self.assertEqual(expect, self.api.calls) self.assertEqual(POD1['name'], pod.name) self.assertEqual(POD1['desc'], pod.desc) ''' def test_pod_delete(self): pod = self.mgr.delete(POD1['id']) expect = [ ('DELETE', '/v1/pods/%s' % POD1['id'], {}, None), ] self.assertEqual(expect, self.api.calls) self.assertIsNone(pod) ''' ",,96,0
openstack%2Fgovernance~master~Ie9d3bc4b340680916d65cb9690703da79a6609f0,openstack/governance,master,Ie9d3bc4b340680916d65cb9690703da79a6609f0,First part of reworking the TC charter,ABANDONED,2014-10-07 15:05:58.000000000,2015-01-07 16:19:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 105}, {'_account_id': 308}, {'_account_id': 688}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 4257}]","[{'number': 1, 'created': '2014-10-07 15:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a83671a10d15623d5873238f07d2204ee44f8ba8', 'message': ""First part of reworking the TC charter\n\nThis is my alternative proposal which, I admit, is a pretty dramatic\ndeparture from our current charter and organization. In summary, I've\nchanged the role of the TC from Judge to Advisor, removed the notion of\nPrograms entirely, and defined OpenStack Projects as source code that is\nrecognized as enhancing the experience of OpenStack users that lives in\nthe openstack/ code namespace.\n\nA follow-up patch will define some of the tags that will be used to\nconvey useful information about a project's purpose, integration,\nrelease cadence, named liaisons, operational status, etc.\n\nA related patch moves some of the content of the programs.yaml file to\nthe project-config repository:\n\nhttps://review.openstack.org/126581\n\nChange-Id: Ie9d3bc4b340680916d65cb9690703da79a6609f0\n""}, {'number': 2, 'created': '2014-10-07 15:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/b9c4c2dec2a84573fdde21630cdd1cc5bb4e6014', 'message': ""First part of reworking the TC charter\n\nThis is my alternative proposal which, I admit, is a pretty dramatic\ndeparture from our current charter and organization. In summary, I've\nchanged the role of the TC from Judge to Advisor, removed the notion of\nPrograms entirely, and defined OpenStack Projects as source code that is\nrecognized as enhancing the experience of OpenStack users that lives in\nthe openstack/ code namespace.\n\nA follow-up patch will define some of the tags that will be used to\nconvey useful information about a project's purpose, integration,\nrelease cadence, named liaisons, operational status, etc.\n\nA related patch moves some of the content of the programs.yaml file to\nthe project-config repository:\n\nhttps://review.openstack.org/126581\n\nChange-Id: Ie9d3bc4b340680916d65cb9690703da79a6609f0\n""}, {'number': 3, 'created': '2014-11-18 20:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/5039a6635da1027671443a9ca92cf5695339ba19', 'message': ""First part of reworking the TC charter\n\nThis is my alternative proposal which, I admit, is a pretty dramatic\ndeparture from our current charter and organization. In summary, I've\nchanged the role of the TC from Judge to Advisor, removed the notion of\nPrograms entirely, and defined OpenStack Projects as source code that is\nrecognized as enhancing the experience of OpenStack users that lives in\nthe openstack/ code namespace.\n\nA follow-up patch will define some of the tags that will be used to\nconvey useful information about a project's purpose, integration,\nrelease cadence, named liaisons, operational status, etc.\n\nA related patch moves some of the content of the programs.yaml file to\nthe project-config repository:\n\nhttps://review.openstack.org/126581\n\nChange-Id: Ie9d3bc4b340680916d65cb9690703da79a6609f0\n""}, {'number': 4, 'created': '2014-11-18 20:06:56.000000000', 'files': ['reference/index.rst', 'reference/incubation-integration-requirements.rst', 'reference/programs.yaml', 'reference/charter.rst', 'reference/new-programs-requirements.rst', 'reference/openstack-projects.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/0080386d831be43c354e581d5edacf48c3d08c39', 'message': ""First part of reworking the TC charter\n\nThis is my alternative proposal which, I admit, is a pretty dramatic\ndeparture from our current charter and organization. In summary, I've\nchanged the role of the TC from Judge to Advisor, removed the notion of\nPrograms entirely, and defined OpenStack Projects as source code that is\nrecognized as enhancing the experience of OpenStack users that lives in\nthe openstack/ code namespace.\n\nA follow-up patch will define some of the tags that will be used to\nconvey useful information about a project's purpose, integration,\nrelease cadence, named liaisons, operational status, etc.\n\nA related patch moves some of the content of the programs.yaml file to\nthe project-config repository:\n\nhttps://review.openstack.org/126581\n\nChange-Id: Ie9d3bc4b340680916d65cb9690703da79a6609f0\n""}]",26,126582,0080386d831be43c354e581d5edacf48c3d08c39,24,8,4,7,,,0,"First part of reworking the TC charter

This is my alternative proposal which, I admit, is a pretty dramatic
departure from our current charter and organization. In summary, I've
changed the role of the TC from Judge to Advisor, removed the notion of
Programs entirely, and defined OpenStack Projects as source code that is
recognized as enhancing the experience of OpenStack users that lives in
the openstack/ code namespace.

A follow-up patch will define some of the tags that will be used to
convey useful information about a project's purpose, integration,
release cadence, named liaisons, operational status, etc.

A related patch moves some of the content of the programs.yaml file to
the project-config repository:

https://review.openstack.org/126581

Change-Id: Ie9d3bc4b340680916d65cb9690703da79a6609f0
",git fetch https://review.opendev.org/openstack/governance refs/changes/82/126582/4 && git format-patch -1 --stdout FETCH_HEAD,"['reference/index.rst', 'reference/programs.yaml', 'reference/charter.rst', 'reference/new-programs-requirements.rst', 'reference/openstack-projects.rst']",5,a83671a10d15623d5873238f07d2204ee44f8ba8,tag-the-world,"OpenStack Projects ================== An OpenStack project is a source code repository that lives in the `openstack/` code namespace, and the associated individuals who contribute to the source code, tests and documentation for the project. Projects living under the `openstack/` code namespace are recognized as ''being a piece of code that enhances the experience of OpenStack users''. Requirements for Projects to Live in the `openstack/` Code Namespace -------------------------------------------------------------------- The requirements for inclusion in the `openstack/` code namespace are as follows: - The project source code is licensed under the Apache 2.0 License - Contributors to the project abide by a Developer's Certificate of Origin policy - The contributor community must have ''named liaisons'' for release management, cross-project coordination, and documentation. Note that a single individual may serve as the liaison for more than one of these areas - There should be documentation that clearly describes the function of the project, its intended audience, any public APIs it exposes, and how contribution to the project is handled The team working on a source code project that desire to host their project under the `openstack/` code namespace should file an ""application patch"" to the `openstack-infra/project-config` repository that adds their project to the `openstack/` code namespace. The `project-config-core` Gerrit team is responsible for checking that each of the above requirements are met by the applying project. Note that some members of the Technical Committee may be members of the `project-config-core` team, and members of the TC are expected to vote on new project application patches. Project Technical Leads ----------------------- Project Technical Leads (""PTLs"") traditionally manage day-to-day operations, drive the program goals and resolve technical disputes within their program. Each program community should be self-managing by the contributors, and all disputes should be resolved through active debate and discussion by the community itself. However if a given debate cannot be clearly resolved, the PTL can decide the outcome. Projects are free to elect a Project Technical Lead but are also free to self-organize without a single PTL. Projects ''must'' have a set of named liaisons that are responsible for cross-project coordination, however it is up to the project's contributor community to decide how it wishes to organize its leadership positions. ",,62,463
openstack%2Ffuel-library~stable%2F6.0~Ib71802a72251c6bff1c0f576f582f69adf61c2c7,openstack/fuel-library,stable/6.0,Ib71802a72251c6bff1c0f576f582f69adf61c2c7,Improve missing cib sections filters,MERGED,2014-12-15 17:38:27.000000000,2015-01-07 16:14:13.000000000,2015-01-07 16:14:12.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-15 17:38:27.000000000', 'files': ['deployment/puppet/corosync/lib/puppet/provider/pacemaker_common.rb', 'deployment/puppet/corosync/spec/unit/puppet/provider/pacemaker_common_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0827676fbec9ed28e6ce0d6142a034f0a7b8574b', 'message': 'Improve missing cib sections filters\n\nChange-Id: Ib71802a72251c6bff1c0f576f582f69adf61c2c7\nCloses-Bug: 1402637\n'}]",0,141856,0827676fbec9ed28e6ce0d6142a034f0a7b8574b,14,5,1,9037,,,0,"Improve missing cib sections filters

Change-Id: Ib71802a72251c6bff1c0f576f582f69adf61c2c7
Closes-Bug: 1402637
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/56/141856/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/corosync/lib/puppet/provider/pacemaker_common.rb', 'deployment/puppet/corosync/spec/unit/puppet/provider/pacemaker_common_spec.rb']",2,0827676fbec9ed28e6ce0d6142a034f0a7b8574b,bug/1402637, @class.expects(:cibadmin).returns(true)," @class.expects(:pcs).with 'constraint', 'location', 'add', 'myprimitive_on_mynode', 'myprimitive', 'mynode', '200'",8,8
openstack%2Ffuel-library~master~Ib71802a72251c6bff1c0f576f582f69adf61c2c7,openstack/fuel-library,master,Ib71802a72251c6bff1c0f576f582f69adf61c2c7,Improve missing cib sections filters,MERGED,2014-12-15 18:45:51.000000000,2015-01-07 16:13:07.000000000,2015-01-07 16:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-15 18:45:51.000000000', 'files': ['deployment/puppet/corosync/lib/puppet/provider/pacemaker_common.rb', 'deployment/puppet/corosync/spec/unit/puppet/provider/pacemaker_common_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7c14681b5597e7f03b43f51bcacb72f7cb9ad55e', 'message': 'Improve missing cib sections filters\n\nChange-Id: Ib71802a72251c6bff1c0f576f582f69adf61c2c7\nCloses-Bug: 1402637\n'}]",1,141875,7c14681b5597e7f03b43f51bcacb72f7cb9ad55e,15,6,1,8786,,,0,"Improve missing cib sections filters

Change-Id: Ib71802a72251c6bff1c0f576f582f69adf61c2c7
Closes-Bug: 1402637
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/75/141875/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/corosync/lib/puppet/provider/pacemaker_common.rb', 'deployment/puppet/corosync/spec/unit/puppet/provider/pacemaker_common_spec.rb']",2,7c14681b5597e7f03b43f51bcacb72f7cb9ad55e,, @class.expects(:cibadmin).returns(true)," @class.expects(:pcs).with 'constraint', 'location', 'add', 'myprimitive_on_mynode', 'myprimitive', 'mynode', '200'",8,8
openstack%2Fpycadf~master~Ibccabb9b3b6ca4f7324e2b6a384c1322006de374,openstack/pycadf,master,Ibccabb9b3b6ca4f7324e2b6a384c1322006de374,Updated from global requirements,MERGED,2014-12-18 10:20:27.000000000,2015-01-07 16:02:07.000000000,2015-01-07 16:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-12-18 10:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/7641ad62e9f8125a3ce5114c5ff2c37d5958a9ce', 'message': 'Updated from global requirements\n\nChange-Id: Ibccabb9b3b6ca4f7324e2b6a384c1322006de374\n'}, {'number': 2, 'created': '2015-01-06 22:51:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/cfc761b42a86b903c419aefefffd9db31b7930f2', 'message': 'Updated from global requirements\n\nChange-Id: Ibccabb9b3b6ca4f7324e2b6a384c1322006de374\n'}]",0,142714,cfc761b42a86b903c419aefefffd9db31b7930f2,12,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ibccabb9b3b6ca4f7324e2b6a384c1322006de374
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/14/142714/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7641ad62e9f8125a3ce5114c5ff2c37d5958a9ce,openstack/requirements,pytz>=2013.6,pytz,1,1
openstack%2Fheat~master~Ib5fc4640b33c238ddb4e59a441c6710f607296b1,openstack/heat,master,Ib5fc4640b33c238ddb4e59a441c6710f607296b1,Update oslo-hacking and disable failing checks,MERGED,2015-01-02 14:33:29.000000000,2015-01-07 15:50:47.000000000,2015-01-07 15:50:44.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-02 14:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f909f57483f99043e8835ad2b35effe07538663', 'message': 'Update oslo-hacking and disable failing checks\n\nThis also brings in newer versions of flake8, pyflakes and pep8,\nwith new and updated checks.\nSome of them fail on our current code base, so first those failing are\ndisabled.\nMost of them will be enabled one-by-one in subsequent patches.\n\nChange-Id: Ib5fc4640b33c238ddb4e59a441c6710f607296b1\n'}, {'number': 2, 'created': '2015-01-02 15:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6e448059e527ea24e8c5f6adbce555c291d2dfe0', 'message': 'Update oslo-hacking and disable failing checks\n\nThis also brings in newer versions of flake8, pyflakes and pep8,\nwith new and updated checks.\nSome of them fail on our current code base, so first those failing are\ndisabled.\nMost of them will be enabled one-by-one in subsequent patches.\n\nChange-Id: Ib5fc4640b33c238ddb4e59a441c6710f607296b1\n'}, {'number': 3, 'created': '2015-01-05 10:11:25.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/46e5897c3eefad875d29c96f997fb772e957b9e1', 'message': 'Update oslo-hacking and disable failing checks\n\nThis also brings in newer versions of flake8, pyflakes and pep8,\nwith new and updated checks.\nSome of them fail on our current code base, so first those failing are\ndisabled.\nMost of them will be enabled one-by-one in subsequent patches.\n\nChange-Id: Ib5fc4640b33c238ddb4e59a441c6710f607296b1\n'}]",2,144749,46e5897c3eefad875d29c96f997fb772e957b9e1,17,5,3,9542,,,0,"Update oslo-hacking and disable failing checks

This also brings in newer versions of flake8, pyflakes and pep8,
with new and updated checks.
Some of them fail on our current code base, so first those failing are
disabled.
Most of them will be enabled one-by-one in subsequent patches.

Change-Id: Ib5fc4640b33c238ddb4e59a441c6710f607296b1
",git fetch https://review.opendev.org/openstack/heat refs/changes/49/144749/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,8f909f57483f99043e8835ad2b35effe07538663,new-hacking,"# E122 continuation line missing indentation or outdented # E126 continuation line over-indented for hanging indent # E128 continuation line under-indented for visual indent # E251 unexpected spaces around keyword / parameter equals # E265 block comment should start with '# ' # F402 import shadowed by loop variable # F812 list comprehension redefines variable # H101 Use TODO(NAME) # H202 assertRaises Exception too broad # H233 Python 3.x incompatible use of print operator # H305 imports not grouped correctly # H307 like imports should be grouped togethe # H402 one line docstring needs punctuation# H405 multi line docstring summary not separated with an empty line# H904 Wrap long lines in parentheses instead of a backslash ignore = E122,E126,E128,E251,E265,F402,F812,H101,H202,H233,H305,H307,H402,H404,H405,H803,H904","ignore = H404,H803",17,2
openstack%2Fneutron~master~I8bce9bfc01859dad82e5a98f4ac1da54ed86392a,openstack/neutron,master,I8bce9bfc01859dad82e5a98f4ac1da54ed86392a,Updated keystone_admin conf section to reflect changes in middleware,MERGED,2014-04-28 13:09:40.000000000,2015-01-07 15:50:32.000000000,2015-01-07 15:50:30.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 167}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 2340}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 7191}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8213}, {'_account_id': 8449}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-04-28 13:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b24a8262e2e9b41e1ddc847de42d6e148f856a83', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 2, 'created': '2014-04-28 15:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fee59944b2263df190b93581b970de7f6b23f1ee', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 3, 'created': '2014-04-29 12:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c4cb271f7189aa1fd70729d9be16cd07cf89718', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 4, 'created': '2014-05-12 10:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc44df03c641fd3463c1eb9713707bda4f93b789', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 5, 'created': '2014-05-26 18:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5ed0d64b21402f9a2e51112726ac6a2d1f2ad73', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 6, 'created': '2014-08-03 20:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c639861568cfaa381c3525f4d4a0ebddbe93e1b6', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 7, 'created': '2014-09-08 09:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/30daf8360dbb043f3a976f7ffcb63ef1363d82e0', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 8, 'created': '2014-09-08 09:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/800e33e330ce28bba10af565957b97653c0a2a8e', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nDocImpact\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 9, 'created': '2014-09-08 11:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e332b00ab904625ec6877c53eafefe3a0a551476', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 10, 'created': '2014-09-15 08:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d42916561e005ffdc3900404eef71beba55732a4', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 11, 'created': '2014-09-15 12:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25182ba95ecc43cda1ed1f370a66b840b557fea9', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 12, 'created': '2014-09-16 13:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32dbe4b650a0aef6b47cddbe2001b698f26ba4db', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystoneclient module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 13, 'created': '2014-09-24 09:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f14784a66ca57e1e0e51e7db868675bcffdcf3d7', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystonemiddleware module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 14, 'created': '2014-10-16 15:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c04c9e2e0fee0241e3dd967b393820f098e433f', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystonemiddleware module now prefers auth_uri and identity_uri.\n\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 15, 'created': '2014-10-30 13:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16fab21af203fd6f877a9d881c4e304ed98e8450', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystonemiddleware module now prefers auth_uri and identity_uri.\n\nDocImpact\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 16, 'created': '2014-12-04 14:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5958cb43fb85667a9087529ef7e2c354bbf763d4', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystonemiddleware module now prefers auth_uri (for public auth\nendpoint) and identity_uri (for admin auth endpoint).\n\nMade cisco plugin to use public auth_uri instead of identity_uri.\n\nidentity_uri is used by keystonemiddleware only, anyway added it to\nseveral unit tests for consistency.\n\nDocImpact\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 17, 'created': '2014-12-08 10:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ece99f326c20d09a5e01e0da5cae347014e1ddd', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystonemiddleware module now prefers auth_uri (for public auth\nendpoint) and identity_uri (for admin auth endpoint).\n\nMade cisco plugin to use public auth_uri instead of identity_uri.\n\nidentity_uri is used by keystonemiddleware only, anyway added it to\nseveral unit tests for consistency.\n\nDocImpact\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}, {'number': 18, 'created': '2015-01-05 11:29:16.000000000', 'files': ['neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/tests/unit/cisco/l3/test_l3_router_appliance_plugin.py', 'etc/neutron.conf', 'neutron/plugins/cisco/db/l3/device_handling_db.py', 'neutron/tests/unit/ml2/drivers/arista/test_arista_mechanism_driver.py', 'neutron/common/utils.py', 'neutron/tests/unit/opencontrail/test_contrail_plugin.py', 'neutron/plugins/ibm/sdnve_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5928a4464ce73998803aaa520a6deba79cc5d19', 'message': 'Updated keystone_admin conf section to reflect changes in middleware\n\nkeystonemiddleware module now prefers auth_uri (for public auth\nendpoint) and identity_uri (for admin auth endpoint).\n\nMade cisco plugin to use public auth_uri instead of identity_uri.\n\nidentity_uri is used by keystonemiddleware only, anyway added it to\nseveral unit tests for consistency.\n\nDocImpact\nCloses-Bug: 1313783\nChange-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a\n'}]",36,90724,c5928a4464ce73998803aaa520a6deba79cc5d19,450,50,18,9656,,,0,"Updated keystone_admin conf section to reflect changes in middleware

keystonemiddleware module now prefers auth_uri (for public auth
endpoint) and identity_uri (for admin auth endpoint).

Made cisco plugin to use public auth_uri instead of identity_uri.

identity_uri is used by keystonemiddleware only, anyway added it to
several unit tests for consistency.

DocImpact
Closes-Bug: 1313783
Change-Id: I8bce9bfc01859dad82e5a98f4ac1da54ed86392a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/90724/18 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron.conf'],1,b24a8262e2e9b41e1ddc847de42d6e148f856a83,bug/1313783,auth_uri = http://127.0.0.1:5000/v2.0/ identity_uri = http://127.0.0.1:35357/,auth_host = 127.0.0.1 auth_port = 35357 auth_protocol = http,2,3
openstack%2Fneutron~master~I5beb8619d5045372472021ed7eb19bddd0de5862,openstack/neutron,master,I5beb8619d5045372472021ed7eb19bddd0de5862,Replace mention of nose with nose2 in devref,MERGED,2015-01-06 00:47:22.000000000,2015-01-07 15:49:15.000000000,2015-01-07 15:49:13.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 14208}]","[{'number': 1, 'created': '2015-01-06 00:47:22.000000000', 'files': ['TESTING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/930b4e3d7b05bab9573bdf4caf9aa64a1cbe5563', 'message': ""Replace mention of nose with nose2 in devref\n\nDocumentation for the nose test runner was previously included in the\ntesting section of the developer reference.  Due to nose's lack of\nsupport for the load_tests protocol - required to support\ntestscenarios-based generative testing - the documentation has been\nupdated to suggest the load_tests-supporting nose2 instead.\n\nChange-Id: I5beb8619d5045372472021ed7eb19bddd0de5862\n""}]",0,145103,930b4e3d7b05bab9573bdf4caf9aa64a1cbe5563,40,24,1,2035,,,0,"Replace mention of nose with nose2 in devref

Documentation for the nose test runner was previously included in the
testing section of the developer reference.  Due to nose's lack of
support for the load_tests protocol - required to support
testscenarios-based generative testing - the documentation has been
updated to suggest the load_tests-supporting nose2 instead.

Change-Id: I5beb8619d5045372472021ed7eb19bddd0de5862
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/145103/1 && git format-patch -1 --stdout FETCH_HEAD,['TESTING.rst'],1,930b4e3d7b05bab9573bdf4caf9aa64a1cbe5563,fix-testing-docs-nose,"and nose2. Before submitting a patch for review you should alwaysWith `nose2`You can use `nose2`_ to run individual tests, as well as use for debugging pip install nose2 nose2 There are disadvantages to running nose2 - the tests are run sequentially, soIt is also possible to use nose2's predecessor, `nose`_, to run the tests:: source .venv/bin/activate pip install nose nosetests nose has one additional disadvantage over nose2 - it does not understand the `load_tests protocol`_ introduced in Python 2.7. This limitation will result in errors being reported for modules that depend on load_tests (usually due to use of `testscenarios`_). .. _nose2: http://nose2.readthedocs.org/en/latest/index.html.. _load_tests protocol: https://docs.python.org/2/library/unittest.html#load-tests-protocol .. _testscenarios: https://pypi.python.org/pypi/testscenarios/","and nose. Before submitting a patch for review you should alwaysWith `nose`You can use `nose`_ to run individual tests, as well as use for debugging pip install nose nosetests There are disadvantages to running Nose - the tests are run sequentially, so",20,6
openstack%2Fneutron~master~I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc,openstack/neutron,master,I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc,Do not run neutron-ns-metadata-proxy as root on L3 agent,MERGED,2014-11-24 17:37:27.000000000,2015-01-07 15:44:54.000000000,2015-01-05 21:27:52.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11126}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 13051}, {'_account_id': 14024}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-24 17:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce8cb11472725f3ab548e51dde1d6065f2e3c432', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 2, 'created': '2014-11-25 09:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d95625bb2b860a7f6530b727b150fe64da645036', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 3, 'created': '2014-11-25 12:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ef4633f0993328c0b2e4f44321a6e02a01ff15b', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 4, 'created': '2014-11-25 12:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11fb8498997cf44d9631ab354007ff0bdcb405b1', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 5, 'created': '2014-11-25 12:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11b099884172857305ff2143c3780150175f5073', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 6, 'created': '2014-11-26 13:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37816086722293a324a6069169e1254da20dfd1f', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 7, 'created': '2014-11-27 16:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce86716ac58666ca3218a08a244bac9b0cc01199', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 8, 'created': '2014-12-01 23:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/008210b32e30c045dbc2381ccc71c18d846f9c7c', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace:\n\n  sudo ip netns exec qrouter-XXX ....\n\nBecause neutron-ns-metadata-proxy is reachable from vms, we should\nreduce permissions after entering in the namespace:\n\n  sudo ip netns exec qrouter-XXX sudo -u $euid ...\n\nwhere $euid is the effective user running the previous command.\n\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 9, 'created': '2014-12-10 12:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c0a686b92d12e266ee77b30f6b6b1b7c4ff9cc9', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new option metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization (by default: nobody user/group).\n\nRoot permissions are dropped by neutron-ns-metadata-proxy after the\ndaemon initialization otherwise the daemon cannot write its pid in the\npidfile.\n\nCurrently metadata_socket permissions must be changed to allow the\nmetadata proxy user/group to connect to the metadata socket everytime\na client request the metada proxy. Metadata proxy supports syslogging\nand logging to file is only supported with permissive permissions on\nlog_dir because of WatchedFileHandler use.\n\nTODO:\n* Choose the right default metadata user/group (root/neutron/nobody?)\n* Handle logging limitations:\n * Only allow syslogging when permissions are dropped?\n * Log in a $state_path subfolder?\n * Use FileHandler? It allows to remove permissions after grabbing\n   the log_file but disallows standard log rotations.\n* Handle socket limitations:\n * Could we allow a metadata socket with o666 permissions?\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 10, 'created': '2014-12-10 12:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5cc70baef74a852b28b3befe67705b502405951', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new option metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization (by default: nobody user/group).\n\nRoot permissions are dropped by neutron-ns-metadata-proxy after the\ndaemon initialization otherwise the daemon cannot write its pid in the\npidfile.\n\nCurrently metadata_socket permissions must be changed to allow the\nmetadata proxy user/group to connect to the metadata socket everytime\na client request the metada proxy. Metadata proxy supports syslogging\nand logging to file is only supported with permissive permissions on\nlog_dir because of WatchedFileHandler use.\n\nTODO:\n* Choose the right default metadata user/group (root/neutron/nobody?)\n* Handle logging limitations:\n * Only allow syslogging when permissions are dropped?\n * Log in a $state_path subfolder?\n * Use FileHandler? It allows to remove permissions after grabbing\n   the log_file but disallows standard log rotations.\n* Handle socket limitations:\n * Could we allow a metadata socket with o666 permissions?\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 11, 'created': '2014-12-10 13:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c8c51306376df2cec0c9d0a32382a51e1b0210a', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new option metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization (by default: nobody user/group).\n\nRoot permissions are dropped by neutron-ns-metadata-proxy after the\ndaemon initialization otherwise the daemon cannot write its pid in the\npidfile.\n\nCurrently metadata_socket permissions must be changed to allow the\nmetadata proxy user/group to connect to the metadata socket everytime\na client request the metada proxy. Metadata proxy supports syslogging\nand logging to file is only supported with permissive permissions on\nlog_dir because of WatchedFileHandler use.\n\nTODO:\n* Choose the right default metadata user/group (root/neutron/nobody?)\n* Handle logging limitations:\n * Only allow syslogging when permissions are dropped?\n * Log in a $state_path subfolder?\n * Use FileHandler? It allows to remove permissions after grabbing\n   the log_file but disallows standard log rotations.\n* Handle socket limitations:\n * Could we allow a metadata socket with o666 permissions?\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 12, 'created': '2014-12-10 15:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37f384317c0a4513e249581ce16d0d289ef8b269', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new option metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization (by default: nobody user/group).\n\nRoot permissions are dropped by neutron-ns-metadata-proxy after the\ndaemon initialization otherwise the daemon cannot write its pid in the\npidfile.\n\nRoot permissions drop implies to replace WatchedFileHandler by\nFileHandler as the WatchedFileHandler does not support permission drop.\nThe use of FileHandler implies to use the copytruncate option in\nlogrotate.\n\nCurrently metadata_socket permissions must be changed to allow the\nmetadata proxy user/group to connect to the metadata socket everytime\na client request the metada proxy.\n\nTODO:\n* Choose the right default metadata user/group (root/neutron/nobody?)\n* Handle socket limitations:\n * Could we allow a metadata socket with o666 permissions?\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 13, 'created': '2014-12-10 16:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c670ff2b258d5c196f39c29b9315f00ab29ac34f', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new option metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization (by default: nobody user/group).\n\nRoot permissions are dropped by neutron-ns-metadata-proxy after the\ndaemon initialization otherwise the daemon cannot write its pid in the\npidfile.\n\nRoot permissions drop implies to replace WatchedFileHandler by\nFileHandler as the WatchedFileHandler does not support permission drop.\nThe use of FileHandler implies to use the copytruncate option in\nlogrotate.\n\nCurrently metadata_socket permissions must be changed to allow the\nmetadata proxy user/group to connect to the metadata socket everytime\na client request the metada proxy.\n\nTODO:\n* Choose the right default metadata user/group (root/neutron/nobody?)\n* Handle socket limitations:\n * Could we allow a metadata socket with o666 permissions?\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 14, 'created': '2014-12-10 16:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/658c170904e735d98782135681a39a71ecdd48c5', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new option metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization (by default: nobody user/group).\n\nRoot permissions are dropped by neutron-ns-metadata-proxy after the\ndaemon initialization otherwise the daemon cannot write its pid in the\npidfile.\n\nRoot permissions drop implies to replace WatchedFileHandler by\nFileHandler as the WatchedFileHandler does not support permission drop.\nThe use of FileHandler implies to use the copytruncate option in\nlogrotate.\n\nCurrently metadata_socket permissions must be changed to allow the\nmetadata proxy user/group to connect to the metadata socket everytime\na client request the metada proxy.\n\nTODO:\n* Choose the right default metadata user/group (root/neutron/nobody?)\n* Handle socket limitations:\n * Could we allow a metadata socket with o666 permissions?\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 15, 'created': '2014-12-11 12:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/12e4d956eb0a5109f69f52b0688f4a81e43c65d6', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are nobody uid\nand nogroup gid because they have minimal permissions.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it\'s not more possible after permissions drop).\n\nPermissions drop implies to replace WatchedFileHandler by FileHandler\nas the WatchedFileHandler does not support permission drop. The use of\nFileHandler implies to use the copytruncate option in logrotate.\n\nPermissions drop implies also more permissive permissions (read/write\nfor others) to allow the metadata proxy user/group to connect to the\nmetadata socket everytime a client request the metadata proxy.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 16, 'created': '2014-12-11 12:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9ff624a88986b3b002387508f711197af42fd8fa', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are nobody uid\nand nogroup gid because they have minimal permissions.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it\'s not more possible after permissions drop).\n\nPermissions drop implies to replace WatchedFileHandler by FileHandler\nas the WatchedFileHandler does not support permission drop. The use of\nFileHandler implies to use the copytruncate option in logrotate.\n\nPermissions drop implies also more permissive permissions (read/write\nfor others) to allow the metadata proxy user/group to connect to the\nmetadata socket everytime a client request the metadata proxy.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 17, 'created': '2014-12-11 12:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2f0a7e4ded061a15511f75e2c677f0936891100', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are nobody uid\nand nogroup gid because they have minimal permissions.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it\'s not more possible after permissions drop).\n\nPermissions drop implies to replace WatchedFileHandler by FileHandler\nas the WatchedFileHandler does not support permission drop. The use of\nFileHandler implies to use the copytruncate option in logrotate.\n\nPermissions drop implies also more permissive permissions (read/write\nfor others) to allow the metadata proxy user/group to connect to the\nmetadata socket everytime a client request the metadata proxy.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 18, 'created': '2014-12-11 14:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/84243c2a44218014c86ff21ed27ab99fe150b969', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_user and\nmetadata_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are nobody uid\nand nogroup gid because they have minimal permissions.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it\'s not more possible after permissions drop).\n\nPermissions drop implies to replace WatchedFileHandler by FileHandler\nas the WatchedFileHandler does not support permission drop. The use of\nFileHandler implies to use the copytruncate option in logrotate.\n\nPermissions drop implies also more permissive permissions (read/write\nfor others) to allow the metadata proxy user/group to connect to the\nmetadata socket everytime a client request the metadata proxy.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 19, 'created': '2014-12-15 14:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27a01e7e4ef4392a82d74aeda682476455f6be74', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_proxy_user and\nmetadata_proxy_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are\nneutron-l3-agent effective user and group.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it could be disallowed after permissions drop).\n\nUsing nobody as metadata_proxy_user/group (more secure) is currently\nnot supported because:\n\n* nobody has not the permission to connect the metadata socket,\n* nobody has not the permission to log to file because neutron uses\n  WatchedFileHandler (which requires read/write permissions after\n  permissions drop).\nThis limitation will be addressed in a daughter change.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 20, 'created': '2014-12-15 15:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae04babb21c5566182bfdaa4c42b7107c1f7cb00', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_proxy_user and\nmetadata_proxy_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are\nneutron-l3-agent effective user and group.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it could be disallowed after permissions drop).\n\nUsing nobody as metadata_proxy_user/group (more secure) is currently\nnot supported because:\n\n* nobody has not the permission to connect the metadata socket,\n* nobody has not the permission to log to file because neutron uses\n  WatchedFileHandler (which requires read/write permissions after\n  permissions drop).\nThis limitation will be addressed in a daughter change.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 21, 'created': '2014-12-15 16:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9837b0f8b614e40d7d158a20c79d9c80b3823e42', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_proxy_user and\nmetadata_proxy_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are\nneutron-l3-agent effective user and group.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it could be disallowed after permissions drop).\n\nUsing nobody as metadata_proxy_user/group (more secure) is currently\nnot supported because:\n\n* nobody has not the permission to connect the metadata socket,\n* nobody has not the permission to log to file because neutron uses\n  WatchedFileHandler (which requires read/write permissions after\n  permissions drop).\nThis limitation will be addressed in a daughter change.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 22, 'created': '2014-12-15 16:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b97abf4828f59d079554b2303cc8df01251210ea', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_proxy_user and\nmetadata_proxy_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are\nneutron-l3-agent effective user and group.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it could be disallowed after permissions drop).\n\nUsing nobody as metadata_proxy_user/group (more secure) is currently\nnot supported because:\n\n* nobody has not the permission to connect the metadata socket,\n* nobody has not the permission to log to file because neutron uses\n  WatchedFileHandler (which requires read/write permissions after\n  permissions drop).\nThis limitation will be addressed in a daughter change.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 23, 'created': '2014-12-22 08:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/336a9a0ca885eb50798cf1a272d17996bc65f37c', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_proxy_user and\nmetadata_proxy_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are\nneutron-l3-agent effective user and group.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it could be disallowed after permissions drop).\n\nUsing nobody as metadata_proxy_user/group (more secure) is currently\nnot supported because:\n\n* nobody has not the permission to connect the metadata socket,\n* nobody has not the permission to log to file because neutron uses\n  WatchedFileHandler (which requires read/write permissions after\n  permissions drop).\nThis limitation will be addressed in a daughter change.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}, {'number': 24, 'created': '2014-12-24 10:45:07.000000000', 'files': ['neutron/tests/unit/test_metadata_namespace_proxy.py', 'neutron/agent/l3/agent.py', 'etc/l3_agent.ini', 'neutron/agent/metadata/namespace_proxy.py', 'neutron/tests/unit/test_linux_daemon.py', 'neutron/agent/linux/daemon.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b78c5e54abd10fc71a46788110f9f36e6496414e', 'message': 'Do not run neutron-ns-metadata-proxy as root on L3 agent\n\nCurrently neutron-ns-metadata-proxy runs with root permissions when\nnamespaces are enabled on the l3 agent because root permissions are\nrequired to ""enter"" in the namespace. But neutron-ns-metadata-proxy\npermissions should be reduced as much as possible because it is\nreachable from vms.\n\nThis change allows to change neutron-ns-metadata-proxy permissions\nafter its startup through the 2 new options metadata_proxy_user and\nmetadata_proxy_group which allow to define user/group running metadata\nproxy after its initialization. Their default values are\nneutron-l3-agent effective user and group.\n\nPermissions drop is done after metadata proxy daemon writes its\npid in its pidfile (it could be disallowed after permissions drop).\n\nUsing nobody as metadata_proxy_user/group (more secure) is currently\nnot supported because:\n\n* nobody has not the permission to connect the metadata socket,\n* nobody has not the permission to log to file because neutron uses\n  WatchedFileHandler (which requires read/write permissions after\n  permissions drop).\nThis limitation will be addressed in a daughter change.\n\nDocImpact\nPartial-Bug: #1187107\nChange-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc\n'}]",113,136840,b78c5e54abd10fc71a46788110f9f36e6496414e,444,38,24,8124,,,0,"Do not run neutron-ns-metadata-proxy as root on L3 agent

Currently neutron-ns-metadata-proxy runs with root permissions when
namespaces are enabled on the l3 agent because root permissions are
required to ""enter"" in the namespace. But neutron-ns-metadata-proxy
permissions should be reduced as much as possible because it is
reachable from vms.

This change allows to change neutron-ns-metadata-proxy permissions
after its startup through the 2 new options metadata_proxy_user and
metadata_proxy_group which allow to define user/group running metadata
proxy after its initialization. Their default values are
neutron-l3-agent effective user and group.

Permissions drop is done after metadata proxy daemon writes its
pid in its pidfile (it could be disallowed after permissions drop).

Using nobody as metadata_proxy_user/group (more secure) is currently
not supported because:

* nobody has not the permission to connect the metadata socket,
* nobody has not the permission to log to file because neutron uses
  WatchedFileHandler (which requires read/write permissions after
  permissions drop).
This limitation will be addressed in a daughter change.

DocImpact
Partial-Bug: #1187107
Change-Id: I55c8c3fb14ed91ae8570f98f19c2cdbaf89d42fc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/136840/10 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'etc/neutron/rootwrap.d/l3.filters']",3,ce8cb11472725f3ab548e51dde1d6065f2e3c432,bug/1187107,"ip_user_exec: ChainingRegExpFilter, ip, root, ip, netns, exec, .*, sudo, -u, .*",,23,16
openstack%2Fheat-translator~master~I715cf126c695c68649c6ae05bcfa95ff278187bb,openstack/heat-translator,master,I715cf126c695c68649c6ae05bcfa95ff278187bb,Add TOSCA service template for monitoring,MERGED,2014-12-31 00:59:50.000000000,2015-01-07 15:38:09.000000000,2015-01-07 15:38:08.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 11355}]","[{'number': 1, 'created': '2014-12-31 00:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/9d07590f5ae7d60b5bf51d40db725b9d378bc47c', 'message': 'Add TOSCA service template for monitoring\n\nAdd new node templates for elasticsearch, logstash, kibana, rsyslog and\ncollectd. Create new custom TOSCA types for each of them.\n\nChange-Id: I715cf126c695c68649c6ae05bcfa95ff278187bb\nImplements: blueprint enable-monitoring\n'}, {'number': 2, 'created': '2014-12-31 02:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8d7c0461f9d278ceede29bc66a8b00c16d666f57', 'message': 'Add TOSCA service template for monitoring\n\nAdd new node templates for elasticsearch, logstash, kibana, rsyslog and\ncollectd. Create new custom TOSCA types for each of them.\n\nChange-Id: I715cf126c695c68649c6ae05bcfa95ff278187bb\nImplements: blueprint enable-monitoring\n'}, {'number': 3, 'created': '2015-01-06 17:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/75259a2d5a6ae325f9f239925fe407a20e421f05', 'message': 'Add TOSCA service template for monitoring\n\nAdd new node templates for elasticsearch, logstash, kibana, rsyslog and\ncollectd. Create new custom TOSCA types for each of them.\n\nChange-Id: I715cf126c695c68649c6ae05bcfa95ff278187bb\nImplements: blueprint enable-monitoring\n'}, {'number': 4, 'created': '2015-01-07 14:30:05.000000000', 'files': ['translator/toscalib/tests/data/custom_types/rsyslog.yaml', 'translator/toscalib/tests/data/custom_types/collectd.yaml', 'translator/toscalib/tests/data/custom_types/kibana.yaml', 'translator/toscalib/tests/data/custom_types/elasticsearch.yaml', 'translator/toscalib/tests/data/custom_types/logstash.yaml', 'translator/toscalib/tests/data/tosca_elk.yaml', 'translator/toscalib/elements/nodetype.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/38a4b15664167aae286cd9503fe430a27d95db96', 'message': 'Add TOSCA service template for monitoring\n\nAdd new node templates for elasticsearch, logstash, kibana, rsyslog and\ncollectd. Create new custom TOSCA types for each of them.\n\nChange-Id: I715cf126c695c68649c6ae05bcfa95ff278187bb\nImplements: blueprint enable-monitoring\n'}]",13,144553,38a4b15664167aae286cd9503fe430a27d95db96,19,4,4,6456,,,0,"Add TOSCA service template for monitoring

Add new node templates for elasticsearch, logstash, kibana, rsyslog and
collectd. Create new custom TOSCA types for each of them.

Change-Id: I715cf126c695c68649c6ae05bcfa95ff278187bb
Implements: blueprint enable-monitoring
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/53/144553/4 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/tests/data/custom_types/collectd.yaml', 'translator/toscalib/tests/data/custom_types/rsyslog.yaml', 'translator/toscalib/tests/data/custom_types/kibana.yaml', 'translator/toscalib/tests/data/custom_types/elasticsearch.yaml', 'translator/toscalib/tests/data/custom_types/logstash.yaml', 'translator/toscalib/tests/data/tosca_elk.yaml']",6,9d07590f5ae7d60b5bf51d40db725b9d378bc47c,bp/enable-monitoring," TOSCA simple profile with nodejs, mongodb, elasticsearch, logstash, kibana, rsyslog and collectd. - custom_types/elasticsearch.yaml - custom_types/logstash.yaml - custom_types/kibana.yaml - custom_types/collectd.yaml - custom_types/rsyslog.yaml collectd_interface: &collectd_interface tosca.interfaces.relation.Configure: pre_configure_source: implementation: collectd/pre_configure_source.py input: host: { get_attribute: [ TARGET, ip_address]} tosca.interfaces.relationship.Configure: pre_configure_target: implementation: collectd/pre_configure_target.py rsyslog_interface: &rsyslog_interface tosca.interfaces.relation.Configure: pre_configure_source: implementation: rsyslog/pre_configure_source.py input: host: { get_attribute: [ TARGET, ip_address]} search_api_port: type: integer description: The default elasticsearch http client port. default: 9200 constraints: - in_range: [ 9200, 9300 ] elasticsearch: type: tosca.nodes.SoftwareComponent.Elasticsearch requirements: - host: elasticsearch_server properties: search_api_port: { get_input: search_api_port} capabilities: search_endpoint: properties: search_api_port: { get_input: search_api_port } kibana: type: tosca.nodes.SoftwareComponent.Kibana requirements: - host: kibana_server - search_endpoint: elasticsearch logstash: type: tosca.nodes.SoftwareComponent.Logstash requirements: - host: logstash_server - search_endpoint: elasticsearch interfaces: tosca.interfaces.relationship.Configure: pre_configure_source: implementation: pre_configure_source.py input: host: { get_attribute: [ TARGET, ip_address ] } port: { get_attribute: [ TARGET, port]} interfaces: tosca.interfaces.node.Lifecycle: create: lostash/create.sh configure: logstash/config.sh start: logstash/start.sh app_collectd: type: tosca.nodes.SoftwareComponent.Collectd requirements: - host: app_server - collectd_endpoint: logstash interfaces: *collectd_interface app_rsyslog: type: tosca.nodes.SoftwareComponent.Rsyslog requirements: - host: app_server - rsyslog_endpoint: logstash interfaces: *rsyslog_interface mongodb_collectd: type: tosca.nodes.SoftwareComponent.Collectd requirements: - host: mongo_server - collectd_endpoint: logstash interfaces: *collectd_interface mongodb_rsyslog: type: tosca.nodes.SoftwareComponent.Rsyslog requirements: - host: mongo_server - rsyslog_endpoint: logstash interfaces: *rsyslog_interface elasticsearch_collectd: type: tosca.nodes.SoftwareComponent.Collectd requirements: - host: elasticsearch_server - collectd_endpoint: logstash interfaces: *collectd_interface elasticsearch_rsyslog: type: tosca.nodes.SoftwareComponent.Rsyslog requirements: - host: logstash_server - rsyslog_endpoint: logstash interfaces: *rsyslog_interface logstash_collectd: type: tosca.nodes.SoftwareComponent.Collectd requirements: - host: logstash_server - collectd_endpoint: logstash interfaces: *collectd_interface logstash_rsyslog: type: tosca.nodes.SoftwareComponent.Rsyslog requirements: - host: elasticsearch_server - rsyslog_endpoint: logstash interfaces: *rsyslog_interface elasticsearch_server: type: tosca.nodes.Compute properties: *ubuntu_node logstash_server: type: tosca.nodes.Compute properties: *ubuntu_node kibana_server: type: tosca.nodes.Compute properties: *ubuntu_node elasticsearch_url: description: URL for the elasticsearch server. value: { get_attribute: [elasticsearch_server, ip_address] } logstash_url: description: URL for the logstash server. value: { get_attribute: [logstash_server, ip_address] } kibana_url: description: URL for the kibana server. value: { get_attribute: [kibana_server, ip_address] }", TOSCA simple profile with nodejs and mongodb.,202,2
openstack%2Ffuel-main~stable%2F5.1~I609fe6f4185d37134842332b9d35cfcb3e2e4cb6,openstack/fuel-main,stable/5.1,I609fe6f4185d37134842332b9d35cfcb3e2e4cb6,Fix issue with hardcoded versions for requirements,MERGED,2015-01-07 14:08:54.000000000,2015-01-07 15:35:34.000000000,2015-01-07 15:35:34.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6623}, {'_account_id': 6926}, {'_account_id': 7227}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 9546}, {'_account_id': 9582}, {'_account_id': 11082}, {'_account_id': 11090}, {'_account_id': 12200}, {'_account_id': 13948}]","[{'number': 1, 'created': '2015-01-07 14:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/72c13159401edb14589774bb89cdbf5c8c2d8774', 'message': 'Fix issue with hardcoded versions for requirements\n\nWe need to build fuel images with all packages from master branch\nand also we need support build from current stable version too.\n\nAdded python-babel to satisfy nailgun dependency\n\nChange-Id: I609fe6f4185d37134842332b9d35cfcb3e2e4cb6\nCloses-Bug: #1361279\n'}, {'number': 2, 'created': '2015-01-07 14:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/33f59ab2185bd34e2c3308819bb1931064276edf', 'message': 'Fix issue with hardcoded versions for requirements\n\nWe need to build fuel images with all packages from master branch\nand also we need support build from current stable version too.\n\nAdded python-babel to satisfy nailgun dependency\n\nChange-Id: I609fe6f4185d37134842332b9d35cfcb3e2e4cb6\nCloses-Bug: #1361279\n'}, {'number': 3, 'created': '2015-01-07 14:42:52.000000000', 'files': ['requirements-eggs.txt', 'requirements-rpm.txt', 'requirements-deb.txt', 'packages/rpm/specs/fuel-ostf.spec', 'packages/rpm/specs/nailgun.spec'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/aeb096ef4cfb9e22dbb855886c9933a8ac7bc3cc', 'message': 'Fix issue with hardcoded versions for requirements\n\nWe need to build fuel images with all packages from master branch\nand also we need support build from current stable version too.\n\nAdded python-babel to satisfy nailgun dependency\n\nChange-Id: I609fe6f4185d37134842332b9d35cfcb3e2e4cb6\nCloses-Bug: #1408309\n'}]",0,145512,aeb096ef4cfb9e22dbb855886c9933a8ac7bc3cc,28,13,3,13948,,,0,"Fix issue with hardcoded versions for requirements

We need to build fuel images with all packages from master branch
and also we need support build from current stable version too.

Added python-babel to satisfy nailgun dependency

Change-Id: I609fe6f4185d37134842332b9d35cfcb3e2e4cb6
Closes-Bug: #1408309
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/12/145512/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-eggs.txt', 'requirements-rpm.txt', 'requirements-deb.txt', 'packages/rpm/specs/fuel-ostf.spec', 'packages/rpm/specs/nailgun.spec']",5,72c13159401edb14589774bb89cdbf5c8c2d8774,bug/1408309,# Workaround for babel bug,# Workaroud for babel bug,5,3
openstack%2Fopenstack-ansible~master~I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d,openstack/openstack-ansible,master,I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d,Created an automated repo environment,ABANDONED,2014-12-04 23:14:21.000000000,2015-01-07 15:33:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 3114}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2014-12-04 23:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b513e5871a427cdab6e6747332760473e58c4894', 'message': 'Created an automated repo environment\n\nThis adds the ability for the user to stand up a repo for all of the python packages\nthat may be needed for a given environment. This will allow a user to maintain their\nown repo of packages for production purposes in CDC where public internet may not be\navailable or for development purposes.\n\n* The repo created by these plays will create a python wheel archive and a git server powered by NGINX enables support on port 8181 via haproxy for testing, and moves the wheel builder scripts into the ``pkg_repo`` roles.\n* The plays also have support for multi node environments which will provide for scalability of the internal repo. This is provided by lsync on the multiple nodes.\n* The repo storage is mounted in /openstack on the host.\n* The cloudserver-aio script has been updated with the new container type.\n\nRelated Issue: https://github.com/rcbops/u-suk-dev/issues/48\nRelated Issue: https://github.com/rcbops/ansible-lxc-rpc/issues/527\n\nOther updates impacted by the repo changes:\n* udpated md5sum in environment file.\n* added cron for report clean up weekly\n* changed working directory and made memcache detect memory\n* changed upstream url for repo\n* Updated pip configuration layout in common\n* incorporates changes made bt @nrb in commit d232585a062803c7033ab4dff482eec572dbd74updated memcached configs\n* added documentation to the python script\n* added show to the inventory-manage script\n\nChange-Id: I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d\n'}, {'number': 2, 'created': '2014-12-04 23:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a5d4079487e6b5bc6bd1252e3f3dbdbe1f1f60fe', 'message': 'Created an automated repo environment\n\nThis adds the ability for the user to stand up a repo for all of the python packages\nthat may be needed for a given environment. This will allow a user to maintain their\nown repo of packages for production purposes in CDC where public internet may not be\navailable or for development purposes.\n\n* The repo created by these plays will create a python wheel archive and a git\n  server powered by NGINX enables support on port 8181 via haproxy for testing, and\n  moves the wheel builder scripts into the ``pkg_repo`` roles.\n* The plays also have support for multi node environments which will provide for\n  scalability of the internal repo. This is provided by lsync on the multiple nodes.\n* The repo storage is mounted in /openstack on the host.\n* The cloudserver-aio script has been updated with the new container type.\n\nRelated Issue: https://github.com/rcbops/u-suk-dev/issues/48\nRelated Issue: https://github.com/rcbops/ansible-lxc-rpc/issues/527\n\nOther updates impacted by the repo changes:\n* udpated md5sum in environment file.\n* added cron for report clean up weekly\n* changed working directory and made memcache detect memory\n* changed upstream url for repo\n* Updated pip configuration layout in common\n* incorporates changes made bt @nrb in commit\n  d232585a062803c7033ab4dff482eec572dbd74updated memcached configs\n* added documentation to the python script\n* added show to the inventory-manage script\n\nChange-Id: I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d\n'}, {'number': 3, 'created': '2014-12-05 16:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0b754663bb5c7bff18738ffd5077032924a9ce98', 'message': 'Created an automated repo environment\n\nThis adds the ability for the user to stand up a repo for all of the python packages\nthat may be needed for a given environment. This will allow a user to maintain their\nown repo of packages for production purposes in CDC where public internet may not be\navailable or for development purposes.\n\n* The repo created by these plays will create a python wheel archive and a git\n  server powered by NGINX enables support on port 8181 via haproxy for testing, and\n  moves the wheel builder scripts into the ``pkg_repo`` roles.\n* The plays also have support for multi node environments which will provide for\n  scalability of the internal repo. This is provided by lsync on the multiple nodes.\n* The repo storage is mounted in /openstack on the host.\n* The cloudserver-aio script has been updated with the new container type.\n\nRelated Issue: https://github.com/rcbops/u-suk-dev/issues/48\nRelated Issue: https://github.com/rcbops/ansible-lxc-rpc/issues/527\n\nOther updates impacted by the repo changes:\n* udpated md5sum in environment file.\n* added cron for report clean up weekly\n* changed working directory and made memcache detect memory\n* changed upstream url for repo\n* Updated pip configuration layout in common\n* incorporates changes made bt @nrb in commit\n  d232585a062803c7033ab4dff482eec572dbd74updated memcached configs\n* added documentation to the python script\n* added show to the inventory-manage script\n\nChange-Id: I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d\n'}, {'number': 4, 'created': '2014-12-08 15:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9205ff8c52227f0627d78d97fc38dc974094aea4', 'message': 'Created an automated repo environment\n\nThis adds the ability for the user to stand up a repo for all of the python packages\nthat may be needed for a given environment. This will allow a user to maintain their\nown repo of packages for production purposes in CDC where public internet may not be\navailable or for development purposes.\n\n* The repo created by these plays will create a python wheel archive and a git\n  server powered by NGINX enables support on port 8181 via haproxy for testing, and\n  moves the wheel builder scripts into the ``pkg_repo`` roles.\n* The plays also have support for multi node environments which will provide for\n  scalability of the internal repo. This is provided by lsync on the multiple nodes.\n* The repo storage is mounted in /openstack on the host.\n* The cloudserver-aio script has been updated with the new container type.\n\nRelated Issue: https://github.com/rcbops/u-suk-dev/issues/48\nRelated Issue: https://github.com/rcbops/ansible-lxc-rpc/issues/527\n\nOther updates impacted by the repo changes:\n* udpated md5sum in environment file.\n* added cron for report clean up weekly\n* changed working directory and made memcache detect memory\n* changed upstream url for repo\n* Updated pip configuration layout in common\n* incorporates changes made bt @nrb in commit\n  d232585a062803c7033ab4dff482eec572dbd74updated memcached configs\n* added documentation to the python script\n* added show to the inventory-manage script\n\nChange-Id: I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d\n'}, {'number': 5, 'created': '2014-12-08 17:00:38.000000000', 'files': ['rpc_deployment/roles/pkg_repo_common/templates/sshd_config.j2', 'etc/rpc_deploy/rpc_user_config.yml', 'rpc_deployment/playbooks/infrastructure/memcached-install.yml', 'rpc_deployment/inventory/group_vars/repo_all.yml', 'rpc_deployment/roles/container_common/tasks/ensure_pip_installed.yml', 'rpc_deployment/roles/container_common/tasks/install_container_pip_deps.yml', 'rpc_deployment/roles/pkg_repo_common/handlers/main.yml', 'rpc_deployment/roles/pkg_repo_sync_master/templates/lsyncd.lua.j2', 'rpc_deployment/roles/common/tasks/utils.yml', 'rpc_deployment/roles/pkg_repo_common/templates/nginx.conf.j2', 'rpc_deployment/vars/config_vars/haproxy_config.yml', 'rpc_deployment/playbooks/infrastructure/repo-install.yml', 'rpc_deployment/roles/pkg_repo_common/templates/rpc-slushee.vhost.j2', 'rpc_deployment/playbooks/infrastructure/repo-container-setup.yml', 'rpc_deployment/roles/common/tasks/install_pip_deps.yml', 'rpc_deployment/roles/pkg_repo_sync_master/files/rpc-wheel-builder.sh', 'rpc_deployment/inventory/group_vars/all.yml', 'rpc_deployment/playbooks/infrastructure/repo-build.yml', 'rpc_deployment/roles/common/tasks/lock_pip_down.yml', 'scripts/cloudserver-aio.sh', 'rpc_deployment/roles/common/tasks/get_pip.yml', 'rpc_deployment/roles/container_extra_setup/tasks/container_setup.yml', 'rpc_deployment/roles/common/tasks/repos.yml', 'rpc_deployment/playbooks/infrastructure/repo-keys.yml', 'scripts/inventory-manage.py', 'rpc_deployment/roles/pkg_repo_common/templates/rsync.defaults.j2', 'rpc_deployment/playbooks/infrastructure/memcached-setup.yml', 'rpc_deployment/playbooks/infrastructure/repo-setup.yml', 'rpc_deployment/playbooks/infrastructure/repo-create.yml', 'rpc_deployment/playbooks/infrastructure/repo-clone-mirror.yml', 'rpc_deployment/roles/pkg_repo_sync_master/handlers/main.yml', 'rpc_deployment/playbooks/infrastructure/repo-config.yml', 'rpc_deployment/roles/memcached/templates/memcached.conf', 'rpc_deployment/roles/pkg_repo_sync_master/files/rpc-branch-grabber.py', 'rpc_deployment/library/memcached', 'rpc_deployment/roles/pkg_repo_sync_master/files/rpc-wheel-builder.py', 'rpc_deployment/vars/repo_packages/readme.rst', 'rpc_deployment/vars/config_vars/container_config_memcached.yml', 'rpc_deployment/playbooks/infrastructure/memcached-container-setup.yml', 'rpc_deployment/roles/pkg_repo_common/tasks/main.yml', 'rpc_deployment/roles/pkg_repo_keys/tasks/main.yml', 'etc/rpc_deploy/rpc_environment.yml', 'rpc_deployment/roles/container_common/tasks/main.yml', 'rpc_deployment/roles/common/tasks/main.yml', 'rpc_deployment/roles/pkg_repo_common/templates/rsyncd.conf.j2', 'rpc_deployment/vars/config_vars/container_config_repo.yml', 'rpc_deployment/roles/pkg_repo_sync_master/tasks/main.yml', 'rpc_deployment/vars/repo_packages/pkg_repo.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9c320621c69dc47a1aa57ef4ec5f139c3e77401e', 'message': 'Created an automated repo environment\n\nThis adds the ability for the user to stand up a repo for all of the python packages\nthat may be needed for a given environment. This will allow a user to maintain their\nown repo of packages for production purposes in CDC where public internet may not be\navailable or for development purposes.\n\n* The repo created by these plays will create a python wheel archive and a git\n  server powered by NGINX enables support on port 8181 via haproxy for testing, and\n  moves the wheel builder scripts into the ``pkg_repo`` roles.\n* The plays also have support for multi node environments which will provide for\n  scalability of the internal repo. This is provided by lsync on the multiple nodes.\n* The repo storage is mounted in /openstack on the host.\n* The cloudserver-aio script has been updated with the new container type.\n\nRelated Issue: https://github.com/rcbops/u-suk-dev/issues/48\nRelated Issue: https://github.com/rcbops/ansible-lxc-rpc/issues/527\n\nOther updates impacted by the repo changes:\n* udpated md5sum in environment file.\n* added cron for report clean up weekly\n* changed working directory and made memcache detect memory\n* changed upstream url for repo\n* Updated pip configuration layout in common\n* incorporates changes made bt @nrb in commit\n  d232585a062803c7033ab4dff482eec572dbd74updated memcached configs\n* added documentation to the python script\n* added show to the inventory-manage script\n\nChange-Id: I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d\n'}]",5,139260,9c320621c69dc47a1aa57ef4ec5f139c3e77401e,35,9,5,7353,,,0,"Created an automated repo environment

This adds the ability for the user to stand up a repo for all of the python packages
that may be needed for a given environment. This will allow a user to maintain their
own repo of packages for production purposes in CDC where public internet may not be
available or for development purposes.

* The repo created by these plays will create a python wheel archive and a git
  server powered by NGINX enables support on port 8181 via haproxy for testing, and
  moves the wheel builder scripts into the ``pkg_repo`` roles.
* The plays also have support for multi node environments which will provide for
  scalability of the internal repo. This is provided by lsync on the multiple nodes.
* The repo storage is mounted in /openstack on the host.
* The cloudserver-aio script has been updated with the new container type.

Related Issue: https://github.com/rcbops/u-suk-dev/issues/48
Related Issue: https://github.com/rcbops/ansible-lxc-rpc/issues/527

Other updates impacted by the repo changes:
* udpated md5sum in environment file.
* added cron for report clean up weekly
* changed working directory and made memcache detect memory
* changed upstream url for repo
* Updated pip configuration layout in common
* incorporates changes made bt @nrb in commit
  d232585a062803c7033ab4dff482eec572dbd74updated memcached configs
* added documentation to the python script
* added show to the inventory-manage script

Change-Id: I881f61205ef36d1c6d1e66af5e69a0764f7d9c1d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/60/139260/5 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/roles/pkg_repo_common/templates/sshd_config.j2', 'etc/rpc_deploy/rpc_user_config.yml', 'rpc_deployment/playbooks/infrastructure/memcached-install.yml', 'rpc_deployment/inventory/group_vars/repo_all.yml', 'rpc_deployment/roles/container_common/tasks/ensure_pip_installed.yml', 'rpc_deployment/roles/container_common/tasks/install_container_pip_deps.yml', 'rpc_deployment/roles/pkg_repo_common/handlers/main.yml', 'rpc_deployment/roles/pkg_repo_sync_master/templates/lsyncd.lua.j2', 'rpc_deployment/roles/common/tasks/utils.yml', 'rpc_deployment/roles/pkg_repo_common/templates/nginx.conf.j2', 'rpc_deployment/vars/config_vars/haproxy_config.yml', 'rpc_deployment/playbooks/infrastructure/repo-install.yml', 'rpc_deployment/roles/pkg_repo_common/templates/rpc-slushee.vhost.j2', 'rpc_deployment/playbooks/infrastructure/repo-container-setup.yml', 'rpc_deployment/roles/common/tasks/install_pip_deps.yml', 'rpc_deployment/roles/pkg_repo_sync_master/files/rpc-wheel-builder.sh', 'rpc_deployment/inventory/group_vars/all.yml', 'rpc_deployment/playbooks/infrastructure/repo-build.yml', 'rpc_deployment/roles/common/tasks/lock_pip_down.yml', 'scripts/cloudserver-aio.sh', 'rpc_deployment/roles/common/tasks/get_pip.yml', 'rpc_deployment/roles/container_extra_setup/tasks/container_setup.yml', 'rpc_deployment/roles/common/tasks/repos.yml', 'rpc_deployment/playbooks/infrastructure/repo-keys.yml', 'scripts/inventory-manage.py', 'rpc_deployment/roles/pkg_repo_common/templates/rsync.defaults.j2', 'rpc_deployment/playbooks/infrastructure/memcached-setup.yml', 'rpc_deployment/playbooks/infrastructure/repo-setup.yml', 'rpc_deployment/playbooks/infrastructure/repo-create.yml', 'rpc_deployment/playbooks/infrastructure/repo-clone-mirror.yml', 'rpc_deployment/roles/pkg_repo_sync_master/handlers/main.yml', 'rpc_deployment/playbooks/infrastructure/repo-config.yml', 'rpc_deployment/roles/memcached/templates/memcached.conf', 'rpc_deployment/roles/pkg_repo_sync_master/files/rpc-branch-grabber.py', 'rpc_deployment/library/memcached', 'rpc_deployment/roles/pkg_repo_sync_master/files/rpc-wheel-builder.py', 'rpc_deployment/vars/repo_packages/readme.rst', 'rpc_deployment/vars/config_vars/container_config_memcached.yml', 'rpc_deployment/playbooks/infrastructure/memcached-container-setup.yml', 'rpc_deployment/roles/pkg_repo_common/tasks/main.yml', 'rpc_deployment/roles/pkg_repo_keys/tasks/main.yml', 'etc/rpc_deploy/rpc_environment.yml', 'rpc_deployment/roles/container_common/tasks/main.yml', 'rpc_deployment/roles/common/tasks/main.yml', 'rpc_deployment/roles/pkg_repo_common/templates/rsyncd.conf.j2', 'rpc_deployment/vars/config_vars/container_config_repo.yml', 'rpc_deployment/roles/pkg_repo_sync_master/tasks/main.yml', 'rpc_deployment/vars/repo_packages/pkg_repo.yml']",48,b513e5871a427cdab6e6747332760473e58c4894,pkg-repo,"--- # Copyright 2014, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. container_packages: - nginx-extras - iptables - git-core - rsync - lsyncd - tmux - lynx - fcgiwrap - libldap2-dev - libsasl2-dev - libssl-dev - libxslt1.1 - libpq-dev - libffi-dev - libxml2-dev - libxslt1-dev - libkmod-dev - libkmod2 - aptitude - vlan - python-software-properties - python-dev - build-essential - lvm2 - dmeventd - bridge-utils - cgroup-lite - sqlite3 - iptables - sshpass - mariadb-client - libmariadbclient-dev pip_container_packages: - ipython - cloudlib - PyYAML - requests - turbolift - wheel - python-memcached - PyCrypto ",,1357,114
openstack%2Fmagnum~master~Ib27d1e580543091a1e465cdcf70883df4f5f225b,openstack/magnum,master,Ib27d1e580543091a1e465cdcf70883df4f5f225b,Update README.rst,MERGED,2015-01-07 04:57:11.000000000,2015-01-07 15:33:36.000000000,2015-01-07 15:33:35.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-07 04:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/965b61eeb8b7b31555b1930c1040a2e2e45695b0', 'message': 'Update README.rst\n\nFix a spelling error (ugh) and also change any reference of magnum-backend\nto magnum-conductor.\n\nChange-Id: Ib27d1e580543091a1e465cdcf70883df4f5f225b\n'}, {'number': 2, 'created': '2015-01-07 14:43:20.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d0fbd09874e50695eb8c5a468076a65cf549b0f6', 'message': 'Update README.rst\n\nFix a spelling error (ugh) and also change any reference of magnum-backend\nto magnum-conductor.\n\nChange-Id: Ib27d1e580543091a1e465cdcf70883df4f5f225b\n'}]",1,145401,d0fbd09874e50695eb8c5a468076a65cf549b0f6,12,5,2,2834,,,0,"Update README.rst

Fix a spelling error (ugh) and also change any reference of magnum-backend
to magnum-conductor.

Change-Id: Ib27d1e580543091a1e465cdcf70883df4f5f225b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/01/145401/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,965b61eeb8b7b31555b1930c1040a2e2e45695b0,,"is sent to the client API, the request is sent via AMQP to the magnum-conductor process. The ReST server is horizontally scalable. AT this time, the conductor is limited to one process, but we intend to add horizontal scalability to the conductor as well.* Integration with Neutron for k8s multi-tenancy network security.","is sent to the client API, the request is sent via AMQP to the magnum-backend process. The ReST server is horizontally scalable. AT this time, the backend is limited to one process, but we intend to add horizontal scalability to the backend as well.* Integraiton with Neutron for k8s multi-tenancy network security.",5,5
openstack%2Fproject-config~master~I2d4595abf68c6961eb331dd88ef75ce0d0002aa0,openstack/project-config,master,I2d4595abf68c6961eb331dd88ef75ce0d0002aa0,Unbreak stable neutron functional jobs,MERGED,2015-01-07 09:16:28.000000000,2015-01-07 15:29:15.000000000,2015-01-07 15:29:12.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1106}, {'_account_id': 2035}, {'_account_id': 5263}, {'_account_id': 5803}, {'_account_id': 9656}]","[{'number': 1, 'created': '2015-01-07 09:16:28.000000000', 'files': ['jenkins/jobs/neutron-functional.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8179ffbebd8315f84070d1c1c04d6b9289eef4b0', 'message': 'Unbreak stable neutron functional jobs\n\nThe 9c87abeeeefa8d298487c0cc597ffc4e7ee2dcef is supported\na neutron code reorganization on the master branch,\nbut did not considered the stable branches.\n\nThe neutron functional job will fall back to the previous location,\nwhen the new script is not available.\n\nChange-Id: I2d4595abf68c6961eb331dd88ef75ce0d0002aa0\n'}]",0,145438,8179ffbebd8315f84070d1c1c04d6b9289eef4b0,10,7,1,5803,,,0,"Unbreak stable neutron functional jobs

The 9c87abeeeefa8d298487c0cc597ffc4e7ee2dcef is supported
a neutron code reorganization on the master branch,
but did not considered the stable branches.

The neutron functional job will fall back to the previous location,
when the new script is not available.

Change-Id: I2d4595abf68c6961eb331dd88ef75ce0d0002aa0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/38/145438/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/neutron-functional.yaml'],1,8179ffbebd8315f84070d1c1c04d6b9289eef4b0,neutron-func-stable, if [[ -e $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh ]]; then bash -xe $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh dsvm-functional else # Before kilo bash -xe $BASE/new/neutron/neutron/tests/functional/contrib/gate_hook.sh fi if [[ -e $BASE/new/neutron/neutron/tests/contrib/post_test_hook.sh ]]; then bash -xe $BASE/new/neutron/neutron/tests/contrib/post_test_hook.sh dsvm-functional else # Before kilo bash -xe $BASE/new/neutron/neutron/tests/functional/contrib/post_test_hook.sh fi, bash -xe $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh dsvm-functional bash -xe $BASE/new/neutron/neutron/tests/contrib/post_test_hook.sh dsvm-functional,12,2
openstack%2Fsahara~master~I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640,openstack/sahara,master,I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640,Imported Translations from Transifex,MERGED,2015-01-03 06:13:27.000000000,2015-01-07 15:27:07.000000000,2015-01-07 15:27:05.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7604}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-03 06:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/eab2f0635da3255fea1fcc88ad355340fdb4c122', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640\n'}, {'number': 2, 'created': '2015-01-04 06:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b831651b3c845f9c940388b524dad8fc6063f4e2', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640\n'}, {'number': 3, 'created': '2015-01-05 06:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0c5740187dde54f0c7f04d49e79bcd3150d64964', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640\n'}, {'number': 4, 'created': '2015-01-06 06:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f0ad3e6e00e12867aa95ff7c8ede2bee5565c4f7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640\n'}, {'number': 5, 'created': '2015-01-07 06:13:19.000000000', 'files': ['sahara/locale/sahara-log-error.pot', 'sahara/locale/sahara.pot', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-error.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0725905f06cbe3106df0ccd5c2f9d9ee9093070f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640\n'}]",0,144830,0725905f06cbe3106df0ccd5c2f9d9ee9093070f,35,7,5,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1eee3f9d87872a47beaf6e21ffa5cb640c5dd640
",git fetch https://review.opendev.org/openstack/sahara refs/changes/30/144830/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/sahara-log-error.pot', 'sahara/locale/sahara.pot', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-error.po']",4,eab2f0635da3255fea1fcc88ad355340fdb4c122,transifex/translations,"# Copyright (C) 2015 ORGANIZATION""POT-Creation-Date: 2015-01-03 06:13+0000\n"" ""PO-Revision-Date: 2015-01-02 23:05+0000\n""","# Copyright (C) 2014 ORGANIZATION""POT-Creation-Date: 2014-12-15 06:12+0000\n"" ""PO-Revision-Date: 2014-12-12 10:20+0000\n""#: sahara/openstack/common/lockutils.py:117 #, python-format msgid ""Could not release the acquired lock `%s`"" msgstr ""Could not release the acquired lock `%s`"" ",30,92
openstack%2Ffuel-library~master~I6b676aa15a37a15868dee7899d4125c96fabd8a6,openstack/fuel-library,master,I6b676aa15a37a15868dee7899d4125c96fabd8a6,Adjust a value for shutdown-escalation cluster property,ABANDONED,2015-01-05 13:53:50.000000000,2015-01-07 15:17:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10489}, {'_account_id': 11090}, {'_account_id': 13343}]","[{'number': 1, 'created': '2015-01-05 13:53:50.000000000', 'files': ['deployment/puppet/openstack/manifests/corosync.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/725cd500dc24b593d08f1cc95856567c20986d71', 'message': 'Adjust a value for shutdown-escalation cluster property\n\nW/o this patch, then reboot was issued, some RA could make\nthe Corosync cluster to wait them for up to 20 min before to\nreboot the node.\n\nThe solution is to lower the gracefull shutdown wait time from\ndefault 20 min to 5 min.\n\nCloses-bug: #1407678\n\nChange-Id: I6b676aa15a37a15868dee7899d4125c96fabd8a6\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,144985,725cd500dc24b593d08f1cc95856567c20986d71,11,6,1,6926,,,0,"Adjust a value for shutdown-escalation cluster property

W/o this patch, then reboot was issued, some RA could make
the Corosync cluster to wait them for up to 20 min before to
reboot the node.

The solution is to lower the gracefull shutdown wait time from
default 20 min to 5 min.

Closes-bug: #1407678

Change-Id: I6b676aa15a37a15868dee7899d4125c96fabd8a6
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/85/144985/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/corosync.pp'],1,725cd500dc24b593d08f1cc95856567c20986d71,fix1407678,"cs_property { 'shutdown-escalation': ensure => present, value => ""5min"", } -> Anchor['corosync-done']","#Define shadow CIB #Cs_resource {cib => 'shadow'} #Cs_property {cib => 'shadow'} #Cs_order {cib => 'shadow'} #Cs_colocation {cib => 'shadow'} #Cs_group {cib => 'shadow'} #require =>[Package['corosync'],File['/root/openrc']], #require =>Package['corosync'],#cs_property { 'expected-quorum-votes': # ensure => present, # value => $expected_quorum_votes #} #cs_property { 'placement-strategy': # ensure => absent, # value => 'default', #}",4,19
openstack%2Frequirements~stable%2Ficehouse~Icc2640861505e578a9efd4b13c6350cd4571f06a,openstack/requirements,stable/icehouse,Icc2640861505e578a9efd4b13c6350cd4571f06a,Set the range of valid keyring versions for new pip,MERGED,2014-12-26 23:02:53.000000000,2015-01-07 15:17:25.000000000,2015-01-07 15:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 2903}, {'_account_id': 6786}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-12-26 23:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9dddd15dd2bb59800c200d2cdb1ca5c26ce0a023', 'message': 'Rephrase range of valid keyring version\n\nstable/icehouse is failing with:\n Could not find a version that satisfies the requirement keyring<2.0,>=1.6.1,>=2.1 (from -r /home/jenkins/workspace/periodic-keystone-docs-icehouse/test-requirements.txt (line 40)) (from versions: 0.1, 0.2, 0.3, 0.4, 0.5, 0.5.1, 0.6.2, 0.7, 0.7.1, 0.8, 0.8.1, 0.9, 0.9.1, 0.9.2, 0.9.3, 0.10, 0.10.1, 1.0, 1.1, 1.1.1, 1.1.2, 1.2.dev0, 1.2, 1.2.1, 1.2.2, 1.2.3, 1.3, 1.4, 1.5, 1.6, 1.6.1, 2.0, 2.0.1, 2.0.2, 2.0.3, 2.1, 2.1.1, 3.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.1, 3.2, 3.2.1, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 4.0)\n\nChange-Id: Icc2640861505e578a9efd4b13c6350cd4571f06a\n'}, {'number': 2, 'created': '2015-01-05 23:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f5e6222dd5895dcc082599089e23d9ba49592ee0', 'message': 'Set the range of valid keyring versions for new pip\n\nstable/icehouse is failing with:\n Could not find a version that satisfies the requirement\n keyring<2.0,>=1.6.1,>=2.1 (from -r /home/jenkins/workspace/periodic-keystone\n -docs-icehouse/test-requirements.txt (line 40)) (from versions: 0.1, 0.2, 0.3,\n 0.4, 0.5, 0.5.1, 0.6.2, 0.7, 0.7.1, 0.8, 0.8.1, 0.9, 0.9.1, 0.9.2, 0.9.3,\n 0.10, 0.10.1, 1.0, 1.1, 1.1.1, 1.1.2, 1.2.dev0, 1.2, 1.2.1, 1.2.2, 1.2.3,\n 1.3, 1.4, 1.5, 1.6, 1.6.1, 2.0, 2.0.1, 2.0.2, 2.0.3, 2.1, 2.1.1, 3.0, 3.0.1,\n 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.1, 3.2, 3.2.1, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 4.0)\n\nSkip 3.3 is from Juno commit 8f1842d2a7795c6e00726d94314d560a75304e36\n\nCloses-Bug: #1407793\n\nChange-Id: Icc2640861505e578a9efd4b13c6350cd4571f06a\n'}, {'number': 3, 'created': '2015-01-07 08:58:41.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/22ac0199b33135ad07598f45ec4efdda1130b52a', 'message': 'Set the range of valid keyring versions for new pip\n\nstable/icehouse is failing with:\n Could not find a version that satisfies the requirement\n keyring<2.0,>=1.6.1,>=2.1 (from -r /home/jenkins/workspace/periodic-keystone\n -docs-icehouse/test-requirements.txt (line 40)) (from versions: 0.1, 0.2, 0.3,\n 0.4, 0.5, 0.5.1, 0.6.2, 0.7, 0.7.1, 0.8, 0.8.1, 0.9, 0.9.1, 0.9.2, 0.9.3,\n 0.10, 0.10.1, 1.0, 1.1, 1.1.1, 1.1.2, 1.2.dev0, 1.2, 1.2.1, 1.2.2, 1.2.3,\n 1.3, 1.4, 1.5, 1.6, 1.6.1, 2.0, 2.0.1, 2.0.2, 2.0.3, 2.1, 2.1.1, 3.0, 3.0.1,\n 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.1, 3.2, 3.2.1, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 4.0)\n\nCloses-Bug: #1407793\n\nChange-Id: Icc2640861505e578a9efd4b13c6350cd4571f06a\n'}]",4,144182,22ac0199b33135ad07598f45ec4efdda1130b52a,28,7,3,1955,,,0,"Set the range of valid keyring versions for new pip

stable/icehouse is failing with:
 Could not find a version that satisfies the requirement
 keyring<2.0,>=1.6.1,>=2.1 (from -r /home/jenkins/workspace/periodic-keystone
 -docs-icehouse/test-requirements.txt (line 40)) (from versions: 0.1, 0.2, 0.3,
 0.4, 0.5, 0.5.1, 0.6.2, 0.7, 0.7.1, 0.8, 0.8.1, 0.9, 0.9.1, 0.9.2, 0.9.3,
 0.10, 0.10.1, 1.0, 1.1, 1.1.1, 1.1.2, 1.2.dev0, 1.2, 1.2.1, 1.2.2, 1.2.3,
 1.3, 1.4, 1.5, 1.6, 1.6.1, 2.0, 2.0.1, 2.0.2, 2.0.3, 2.1, 2.1.1, 3.0, 3.0.1,
 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.1, 3.2, 3.2.1, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 4.0)

Closes-Bug: #1407793

Change-Id: Icc2640861505e578a9efd4b13c6350cd4571f06a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/82/144182/3 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,9dddd15dd2bb59800c200d2cdb1ca5c26ce0a023,bug/1242992,"keyring>=1.6.1,!=2.0,!=2.0.1,!=2.0.2,!=2.0.3,!=3.3","keyring>=1.6.1,<2.0,>=2.1",1,1
openstack%2Fneutron-lbaas~master~Ide7dafafa3e43b3f27ec3d2dfdb3591ae7328f21,openstack/neutron-lbaas,master,Ide7dafafa3e43b3f27ec3d2dfdb3591ae7328f21,Moved lbaas-haproxy.filters from main neutron repo,MERGED,2014-12-18 12:24:04.000000000,2015-01-07 15:17:16.000000000,2015-01-07 15:17:15.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5756}, {'_account_id': 6951}, {'_account_id': 9656}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-18 12:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/d510af5a922c044c4664a77c9a47477e631c1ef0', 'message': 'Moved lbaas-haproxy.filters from main neutron repo\n\nThis file belongs to lbaas service and hence should be maintained in\nneutron-lbaas repository.\n\nChange-Id: Ide7dafafa3e43b3f27ec3d2dfdb3591ae7328f21\n'}, {'number': 2, 'created': '2014-12-22 10:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/187e34eda781cd021097ec7c0e44c7c421eec29f', 'message': 'Moved lbaas-haproxy.filters from main neutron repo\n\nThis file belongs to lbaas service and hence should be maintained in\nneutron-lbaas repository.\n\nChange-Id: Ide7dafafa3e43b3f27ec3d2dfdb3591ae7328f21\n'}, {'number': 3, 'created': '2015-01-05 11:21:10.000000000', 'files': ['etc/neutron/rootwrap.d/lbaas-haproxy.filters', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ed35d86a6e09c363ccce1261ff3c0e6ec855f110', 'message': 'Moved lbaas-haproxy.filters from main neutron repo\n\nThis file belongs to lbaas service and hence should be maintained in\nneutron-lbaas repository.\n\nChange-Id: Ide7dafafa3e43b3f27ec3d2dfdb3591ae7328f21\n'}]",0,142753,ed35d86a6e09c363ccce1261ff3c0e6ec855f110,32,8,3,9656,,,0,"Moved lbaas-haproxy.filters from main neutron repo

This file belongs to lbaas service and hence should be maintained in
neutron-lbaas repository.

Change-Id: Ide7dafafa3e43b3f27ec3d2dfdb3591ae7328f21
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/53/142753/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/rootwrap.d/lbaas-haproxy.filters', 'setup.cfg']",2,d510af5a922c044c4664a77c9a47477e631c1ef0,, etc/neutron/rootwrap.d = etc/neutron/rootwrap.d/lbaas-haproxy.filters,,28,0
openstack%2Fsahara~master~If0d6e70b84d60560b9c7a4302e65a71adfbace1d,openstack/sahara,master,If0d6e70b84d60560b9c7a4302e65a71adfbace1d,Fixes a job_configs update by wrong value when deleting proxy-user,MERGED,2014-12-24 10:35:58.000000000,2015-01-07 15:17:09.000000000,2015-01-07 15:17:09.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 11059}]","[{'number': 1, 'created': '2014-12-24 10:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f1d04dee38a27e4b9977af697b4f97e1f41f5870', 'message': 'Fixes a job_configs update by wrong value when deleting proxy-user\n\nChange-Id: If0d6e70b84d60560b9c7a4302e65a71adfbace1d\nCloses-Bug: 1405387\n'}, {'number': 2, 'created': '2015-01-07 02:25:30.000000000', 'files': ['sahara/utils/proxy.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/ba2a02a0f50ef10e75951b1ba4e0914b40f09da9', 'message': 'Fixes a job_configs update by wrong value when deleting proxy-user\n\nChange-Id: If0d6e70b84d60560b9c7a4302e65a71adfbace1d\nCloses-Bug: 1405387\n'}]",4,143808,ba2a02a0f50ef10e75951b1ba4e0914b40f09da9,33,8,2,11059,,,0,"Fixes a job_configs update by wrong value when deleting proxy-user

Change-Id: If0d6e70b84d60560b9c7a4302e65a71adfbace1d
Closes-Bug: 1405387
",git fetch https://review.opendev.org/openstack/sahara refs/changes/08/143808/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/utils/proxy.py'],1,f1d04dee38a27e4b9977af697b4f97e1f41f5870,bug/1405387, return update['job_configs'], return update,1,1
openstack%2Fironic~master~I9da09f65a46617aa1c837ae0fc71350276df8bea,openstack/ironic,master,I9da09f65a46617aa1c837ae0fc71350276df8bea,Add a fsm state -> dot diagram generator,MERGED,2014-12-18 19:33:32.000000000,2015-01-07 15:16:44.000000000,2015-01-07 15:16:44.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-18 19:33:32.000000000', 'files': ['tools/states_to_dot.py', 'ironic/common/fsm.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/47b49a009ca676bfced908770bfa4807369690f1', 'message': ""Add a fsm state -> dot diagram generator\n\nAdd a tool (derived from taskflow's similar tool)\nthat can turn the state machine defined in ironic\ninto a dot diagram.\n\nThis diagram is much easier to look at then trying\nto mentally create a similar diagram; this makes it\neasier to see issues and to visualize the state machines\nvalid states and transitions.\n\nFor this change we need to add back in the state machine\n__iter__ method so that we can correctly iterate over the\nstates and transitions (and events that will cause those\ntransitions).\n\nChange-Id: I9da09f65a46617aa1c837ae0fc71350276df8bea\n""}]",0,142887,47b49a009ca676bfced908770bfa4807369690f1,16,6,1,1297,,,0,"Add a fsm state -> dot diagram generator

Add a tool (derived from taskflow's similar tool)
that can turn the state machine defined in ironic
into a dot diagram.

This diagram is much easier to look at then trying
to mentally create a similar diagram; this makes it
easier to see issues and to visualize the state machines
valid states and transitions.

For this change we need to add back in the state machine
__iter__ method so that we can correctly iterate over the
states and transitions (and events that will cause those
transitions).

Change-Id: I9da09f65a46617aa1c837ae0fc71350276df8bea
",git fetch https://review.opendev.org/openstack/ironic refs/changes/87/142887/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/states_to_dot.py', 'ironic/common/fsm.py']",2,47b49a009ca676bfced908770bfa4807369690f1,," def __iter__(self): """"""Iterates over (start, event, end) transition tuples."""""" for state in six.iterkeys(self._states): for event, target in six.iteritems(self._transitions[state]): yield (state, event, target.name) ",,133,0
openstack%2Fsahara~master~I1748609caff74e073171d5e4a1b76fda9efef1d6,openstack/sahara,master,I1748609caff74e073171d5e4a1b76fda9efef1d6,Adding Storm entry point to setup.cfg,MERGED,2015-01-02 16:49:29.000000000,2015-01-07 15:16:32.000000000,2015-01-07 15:16:31.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8932}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-02 16:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f13c8f59970066f8cd3695e51a345fa3f6e0dbb8', 'message': 'Adding Storm entry point to setup.cfg\n\nThis change allows the stevedore package to find the Storm plugin when\nenabling extensions.\n\nChange-Id: I1748609caff74e073171d5e4a1b76fda9efef1d6\nCloses-Bug: 1407120\n'}, {'number': 2, 'created': '2015-01-06 21:18:56.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d39b6fc6cf62637b1afc1326fc5b04e866a6a5f5', 'message': 'Adding Storm entry point to setup.cfg\n\nThis change allows the stevedore package to find the Storm plugin when\nenabling extensions.\n\nChange-Id: I1748609caff74e073171d5e4a1b76fda9efef1d6\nCloses-Bug: 1407120\n'}]",0,144775,d39b6fc6cf62637b1afc1326fc5b04e866a6a5f5,25,8,2,10670,,,0,"Adding Storm entry point to setup.cfg

This change allows the stevedore package to find the Storm plugin when
enabling extensions.

Change-Id: I1748609caff74e073171d5e4a1b76fda9efef1d6
Closes-Bug: 1407120
",git fetch https://review.opendev.org/openstack/sahara refs/changes/75/144775/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f13c8f59970066f8cd3695e51a345fa3f6e0dbb8,bug/1407120, storm = sahara.plugins.storm.plugin:StormProvider,,1,0
openstack%2Ffuel-library~master~I7f0421b496e2a0150b5016bcacbd91c5ac28822c,openstack/fuel-library,master,I7f0421b496e2a0150b5016bcacbd91c5ac28822c,Add Nova Controller Services as pacemaker primitives,ABANDONED,2014-10-10 10:51:37.000000000,2015-01-07 15:03:12.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-10 10:51:37.000000000', 'files': ['deployment/puppet/nova/files/ocf/nova-network', 'deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/nova/files/ocf/nova-api', 'deployment/puppet/nova/files/ocf/nova-cert', 'deployment/puppet/openstack/manifests/nova/controller.pp', 'deployment/puppet/nova/manifests/api.pp', 'deployment/puppet/nova/files/ocf/nova-consoleauth', 'deployment/puppet/nova/files/ocf/nova-novnc', 'deployment/puppet/nova/manifests/generic_service.pp', 'deployment/puppet/nova/files/ocf/nova-scheduler'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d67da53a10d26a857740f0e0ea3cf65dc91c9365', 'message': 'Add Nova Controller Services as pacemaker primitives\n\n* Add OCF files for all services\n* Refactor Nova classes for ha_mode and primary_controller\n\nChange-Id: I7f0421b496e2a0150b5016bcacbd91c5ac28822c\nImplements: bp/pacemaker-improvements\n'}]",0,127486,d67da53a10d26a857740f0e0ea3cf65dc91c9365,8,3,1,11090,,,0,"Add Nova Controller Services as pacemaker primitives

* Add OCF files for all services
* Refactor Nova classes for ha_mode and primary_controller

Change-Id: I7f0421b496e2a0150b5016bcacbd91c5ac28822c
Implements: bp/pacemaker-improvements
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/86/127486/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nova/files/ocf/nova-network', 'deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/nova/files/ocf/nova-api', 'deployment/puppet/nova/files/ocf/nova-cert', 'deployment/puppet/openstack/manifests/nova/controller.pp', 'deployment/puppet/nova/manifests/api.pp', 'deployment/puppet/nova/files/ocf/nova-consoleauth', 'deployment/puppet/nova/files/ocf/nova-novnc', 'deployment/puppet/nova/manifests/generic_service.pp', 'deployment/puppet/nova/files/ocf/nova-scheduler']",10,d67da53a10d26a857740f0e0ea3cf65dc91c9365,bp/pacemaker-improvements,"#!/bin/sh # # # OpenStack Scheduler Service (nova-scheduler) # # Description: Manages an OpenStack Scheduler Service (nova-scheduler) process as an HA resource # # Authors: Sébastien Han # Mainly inspired by the Glance API resource agent written by Martin Gerhard Loschwitz from Hastexo: http://goo.gl/whLpr # # Support: openstack@lists.launchpad.net # License: Apache Software License (ASL) 2.0 # # # See usage() function below for more details ... # # OCF instance parameters: # OCF_RESKEY_binary # OCF_RESKEY_config # OCF_RESKEY_user # OCF_RESKEY_pid # OCF_RESKEY_monitor_binary # OCF_RESKEY_database_server_port # OCF_RESKEY_amqp_server_port # OCF_RESKEY_zeromq # OCF_RESKEY_additional_parameters ####################################################################### # Initialization: : ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat} . ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs ####################################################################### # Fill in some defaults if no values are specified OCF_RESKEY_binary_default=""nova-scheduler"" OCF_RESKEY_config_default=""/etc/nova/nova.conf"" OCF_RESKEY_user_default=""nova"" OCF_RESKEY_pid_default=""$HA_RSCTMP/$OCF_RESOURCE_INSTANCE.pid"" OCF_RESKEY_database_server_port_default=""3306"" OCF_RESKEY_amqp_server_port_default=""5672"" OCF_RESKEY_zeromq_default=""false"" : ${OCF_RESKEY_binary=${OCF_RESKEY_binary_default}} : ${OCF_RESKEY_config=${OCF_RESKEY_config_default}} : ${OCF_RESKEY_user=${OCF_RESKEY_user_default}} : ${OCF_RESKEY_pid=${OCF_RESKEY_pid_default}} : ${OCF_RESKEY_database_server_port=${OCF_RESKEY_database_server_port_default}} : ${OCF_RESKEY_amqp_server_port=${OCF_RESKEY_amqp_server_port_default}} : ${OCF_RESKEY_zeromq=${OCF_RESKEY_zeromq_default}} ####################################################################### usage() { cat <<UEND usage: $0 (start|stop|validate-all|meta-data|status|monitor) $0 manages an OpenStack SchedulerService (nova-scheduler) process as an HA resource The 'start' operation starts the scheduler service. The 'stop' operation stops the scheduler service. The 'validate-all' operation reports whether the parameters are valid The 'meta-data' operation reports this RA's meta-data information The 'status' operation reports whether the scheduler service is running The 'monitor' operation reports whether the scheduler service seems to be working UEND } meta_data() { cat <<END <?xml version=""1.0""?> <!DOCTYPE resource-agent SYSTEM ""ra-api-1.dtd""> <resource-agent name=""nova-scheduler""> <version>1.0</version> <longdesc lang=""en""> Resource agent for the OpenStack Nova Scheduler Service (nova-scheduler) May manage a nova-scheduler instance or a clone set that creates a distributed nova-scheduler cluster. </longdesc> <shortdesc lang=""en"">Manages the OpenStack Scheduler Service (nova-scheduler)</shortdesc> <parameters> <parameter name=""binary"" unique=""0"" required=""0""> <longdesc lang=""en""> Location of the OpenStack Nova Scheduler server binary (nova-scheduler) </longdesc> <shortdesc lang=""en"">OpenStack Nova Scheduler server binary (nova-scheduler)</shortdesc> <content type=""string"" default=""${OCF_RESKEY_binary_default}"" /> </parameter> <parameter name=""config"" unique=""0"" required=""0""> <longdesc lang=""en""> Location of the OpenStack Scheduler Service (nova-scheduler) configuration file </longdesc> <shortdesc lang=""en"">OpenStack Nova Scheduler (nova-scheduler) config file</shortdesc> <content type=""string"" default=""${OCF_RESKEY_config_default}"" /> </parameter> <parameter name=""user"" unique=""0"" required=""0""> <longdesc lang=""en""> User running OpenStack Scheduler Service (nova-scheduler) </longdesc> <shortdesc lang=""en"">OpenStack Scheduler Service (nova-scheduler) user</shortdesc> <content type=""string"" default=""${OCF_RESKEY_user_default}"" /> </parameter> <parameter name=""pid"" unique=""0"" required=""0""> <longdesc lang=""en""> The pid file to use for this OpenStack Scheduler Service (nova-scheduler) instance </longdesc> <shortdesc lang=""en"">OpenStack Scheduler Service (nova-scheduler) pid file</shortdesc> <content type=""string"" default=""${OCF_RESKEY_pid_default}"" /> </parameter> <parameter name=""database_server_port"" unique=""0"" required=""0""> <longdesc lang=""en""> The listening port number of the database server. Use for monitoring purposes </longdesc> <shortdesc lang=""en"">Database listening port</shortdesc> <content type=""integer"" default=""${OCF_RESKEY_database_server_port_default}"" /> </parameter> <parameter name=""amqp_server_port"" unique=""0"" required=""0""> <longdesc lang=""en""> The listening port number of the AMQP server. Use for monitoring purposes </longdesc> <shortdesc lang=""en"">AMQP listening port</shortdesc> <content type=""integer"" default=""${OCF_RESKEY_amqp_server_port_default}"" /> </parameter> <parameter name=""zeromq"" unique=""0"" required=""0""> <longdesc lang=""en""> If zeromq is used, this will disable the connection test to the AMQP server. Use for monitoring purposes </longdesc> <shortdesc lang=""en"">Zero-MQ usage</shortdesc> <content type=""boolean"" default=""${OCF_RESKEY_zeromq_default}"" /> </parameter> <parameter name=""additional_parameters"" unique=""0"" required=""0""> <longdesc lang=""en""> Additional parameters to pass on to the OpenStack Scheduler Service (nova-scheduler) </longdesc> <shortdesc lang=""en"">Additional parameters for nova-scheduler</shortdesc> <content type=""string"" /> </parameter> </parameters> <actions> <action name=""start"" timeout=""20"" /> <action name=""stop"" timeout=""20"" /> <action name=""status"" timeout=""20"" /> <action name=""monitor"" timeout=""30"" interval=""20"" /> <action name=""validate-all"" timeout=""5"" /> <action name=""meta-data"" timeout=""5"" /> </actions> </resource-agent> END } ####################################################################### # Functions invoked by resource manager actions nova_scheduler_check_port() { # This function has been taken from the squid RA and improved a bit # The length of the integer must be 4 # Examples of valid port: ""1080"", ""0080"" # Examples of invalid port: ""1080bad"", ""0"", ""0000"", """" local int local cnt int=""$1"" cnt=${#int} echo $int |egrep -qx '[0-9]+(:[0-9]+)?(,[0-9]+(:[0-9]+)?)*' if [ $? -ne 0 ] || [ $cnt -ne 4 ]; then ocf_log err ""Invalid port number: $1"" exit $OCF_ERR_CONFIGURED fi } nova_scheduler_validate() { local rc check_binary $OCF_RESKEY_binary check_binary netstat nova_scheduler_check_port $OCF_RESKEY_database_server_port nova_scheduler_check_port $OCF_RESKEY_amqp_server_port # A config file on shared storage that is not available # during probes is OK. if [ ! -f $OCF_RESKEY_config ]; then if ! ocf_is_probe; then ocf_log err ""Config $OCF_RESKEY_config doesn't exist"" return $OCF_ERR_INSTALLED fi ocf_log_warn ""Config $OCF_RESKEY_config not available during a probe"" fi getent passwd $OCF_RESKEY_user >/dev/null 2>&1 rc=$? if [ $rc -ne 0 ]; then ocf_log err ""User $OCF_RESKEY_user doesn't exist"" return $OCF_ERR_INSTALLED fi true } nova_scheduler_status() { local pid local rc if [ ! -f $OCF_RESKEY_pid ]; then ocf_log info ""OpenStack Nova Scheduler (nova-scheduler) is not running"" return $OCF_NOT_RUNNING else pid=`cat $OCF_RESKEY_pid` fi ocf_run -warn kill -s 0 $pid rc=$? if [ $rc -eq 0 ]; then return $OCF_SUCCESS else ocf_log info ""Old PID file found, but OpenStack Nova Scheduler (nova-scheduler) is not running"" return $OCF_NOT_RUNNING fi } nova_scheduler_monitor() { local rc local pid local rc_db local rc_amqp local scheduler_db_check local scheduler_amqp_check nova_scheduler_status rc=$? # If status returned anything but success, return that immediately if [ $rc -ne $OCF_SUCCESS ]; then return $rc fi # Check the connections according to the PID. # We are sure to hit the scheduler process and not other nova process with the same connection behavior (for example nova-cert) if ocf_is_true ""$OCF_RESKEY_zeromq""; then pid=`cat $OCF_RESKEY_pid` scheduler_db_check=`netstat -punt | grep -s ""$OCF_RESKEY_database_server_port"" | grep -s ""$pid"" | grep -qs ""ESTABLISHED""` rc_db=$? if [ $rc_db -ne 0 ]; then ocf_log err ""Nova Scheduler is not connected to the database server: $rc_db"" return $OCF_NOT_RUNNING fi else pid=`cat $OCF_RESKEY_pid` scheduler_db_check=`netstat -punt | grep -s ""$OCF_RESKEY_database_server_port"" | grep -s ""$pid"" | grep -qs ""ESTABLISHED""` rc_db=$? scheduler_amqp_check=`netstat -punt | grep -s ""$OCF_RESKEY_amqp_server_port"" | grep -s ""$pid"" | grep -qs ""ESTABLISHED""` rc_amqp=$? if [ $rc_amqp -ne 0 ] || [ $rc_db -ne 0 ]; then ocf_log err ""Nova Scheduler is not connected to the AMQP server and/or the database server: AMQP connection test returned $rc_amqp and database connection test returned $rc_db"" return $OCF_NOT_RUNNING fi fi ocf_log debug ""OpenStack Nova Scheduler (nova-scheduler) monitor succeeded"" return $OCF_SUCCESS } nova_scheduler_start() { local rc nova_scheduler_status rc=$? if [ $rc -eq $OCF_SUCCESS ]; then ocf_log info ""OpenStack Nova Scheduler (nova-scheduler) already running"" return $OCF_SUCCESS fi # run the actual nova-scheduler daemon. Don't use ocf_run as we're sending the tool's output # straight to /dev/null anyway and using ocf_run would break stdout-redirection here. su ${OCF_RESKEY_user} -s /bin/sh -c ""${OCF_RESKEY_binary} --config-file=$OCF_RESKEY_config \ $OCF_RESKEY_additional_parameters""' >> /dev/null 2>&1 & echo $!' > $OCF_RESKEY_pid # Spin waiting for the server to come up. while true; do nova_scheduler_monitor rc=$? [ $rc -eq $OCF_SUCCESS ] && break if [ $rc -ne $OCF_NOT_RUNNING ]; then ocf_log err ""OpenStack Nova Scheduler (nova-scheduler) start failed"" exit $OCF_ERR_GENERIC fi sleep 1 done ocf_log info ""OpenStack Nova Scheduler (nova-scheduler) started"" return $OCF_SUCCESS } nova_scheduler_stop() { local rc local pid nova_scheduler_status rc=$? if [ $rc -eq $OCF_NOT_RUNNING ]; then ocf_log info ""OpenStack Nova Scheduler (nova-scheduler) already stopped"" return $OCF_SUCCESS fi # Try SIGTERM pid=`cat $OCF_RESKEY_pid` ocf_run kill -s TERM $pid rc=$? if [ $rc -ne 0 ]; then ocf_log err ""OpenStack Nova Scheduler (nova-scheduler) couldn't be stopped"" exit $OCF_ERR_GENERIC fi # stop waiting shutdown_timeout=15 if [ -n ""$OCF_RESKEY_CRM_meta_timeout"" ]; then shutdown_timeout=$((($OCF_RESKEY_CRM_meta_timeout/1000)-5)) fi count=0 while [ $count -lt $shutdown_timeout ]; do nova_scheduler_status rc=$? if [ $rc -eq $OCF_NOT_RUNNING ]; then break fi count=`expr $count + 1` sleep 1 ocf_log debug ""OpenStack Nova Scheduler (nova-scheduler) still hasn't stopped yet. Waiting ..."" done nova_scheduler_status rc=$? if [ $rc -ne $OCF_NOT_RUNNING ]; then # SIGTERM didn't help either, try SIGKILL ocf_log info ""OpenStack Nova Scheduler (nova-scheduler) failed to stop after ${shutdown_timeout}s \ using SIGTERM. Trying SIGKILL ..."" ocf_run kill -s KILL $pid fi ocf_log info ""OpenStack Nova Scheduler (nova-scheduler) stopped"" rm -f $OCF_RESKEY_pid return $OCF_SUCCESS } ####################################################################### case ""$1"" in meta-data) meta_data exit $OCF_SUCCESS;; usage|help) usage exit $OCF_SUCCESS;; esac # Anything except meta-data and help must pass validation nova_scheduler_validate || exit $? # What kind of method was invoked? case ""$1"" in start) nova_scheduler_start;; stop) nova_scheduler_stop;; status) nova_scheduler_status;; monitor) nova_scheduler_monitor;; validate-all) ;; *) usage exit $OCF_ERR_UNIMPLEMENTED;; esac ",,2295,23
openstack%2Ffuel-main~master~I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63,openstack/fuel-main,master,I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63,Added Corosync 2 requirements,ABANDONED,2014-10-17 13:18:50.000000000,2015-01-07 15:02:43.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-17 13:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a7094faa4e3d927156a378cce4cf66c6a85291e4', 'message': 'Added Corosync 2 requierements\n\n* Removed requirements for Corosync 1.4.4\n* Added requirements for Corosync 2.3.3\n* Sorted requirements\n\nChange-Id: I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63\n'}, {'number': 2, 'created': '2014-10-17 13:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1efe3e8f7c6c671e919e99c13e11a20e41939ab3', 'message': 'Added Corosync 2 requirements\n\n* Removed requirements for Corosync 1.4.4\n* Added requirements for Corosync 2.3.3\n* Removed requirements for Pacemaker 1.0\n* Added requirements for Pacemaker 1.1.2\n* Sorted requirements\n\nChange-Id: I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63\n'}, {'number': 3, 'created': '2014-10-17 14:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0c1716c75374a88800dc50b526232e1b24e75295', 'message': 'Added Corosync 2 requirements\n\n* Removed requirements for Corosync 1.4.4\n* Added requirements for Corosync 2.3.3\n* Removed requirements for Pacemaker 1.0\n* Added requirements for Pacemaker 1.1.2\n* Sorted requirements\n\nChange-Id: I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63\n'}, {'number': 4, 'created': '2014-10-21 11:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f4d777d04cc8d27b8afcb808af09d05b3766e1a3', 'message': 'Added Corosync 2 requirements\n\n* Removed requirements for Corosync 1.4.4\n* Added requirements for Corosync 2.3.3\n* Removed requirements for Pacemaker 1.0\n* Added requirements for Pacemaker 1.1.2\n* Sorted requirements\n\nChange-Id: I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63\n'}, {'number': 5, 'created': '2014-10-22 19:58:06.000000000', 'files': ['requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ed87e61c4766dbef6d705eb1c7d2a8d8dc19b991', 'message': 'Added Corosync 2 requirements\n\n* Removed requirements for Corosync 1.4.4\n* Added requirements for Corosync 2.3.3\n* Removed requirements for Pacemaker 1.1.10\n* Added requirements for Pacemaker 1.1.12\n* Sorted requirements\n\nChange-Id: I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63\n'}]",0,129239,ed87e61c4766dbef6d705eb1c7d2a8d8dc19b991,28,2,5,11090,,,0,"Added Corosync 2 requirements

* Removed requirements for Corosync 1.4.4
* Added requirements for Corosync 2.3.3
* Removed requirements for Pacemaker 1.1.10
* Added requirements for Pacemaker 1.1.12
* Sorted requirements

Change-Id: I0caf4f848b5cdd40aaef588b8ac94cadb3f48b63
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/39/129239/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-deb.txt'],1,a7094faa4e3d927156a378cce4cf66c6a85291e4,corosync2,ceilometer-agent-central ceilometer-agent-compute ceilometer-agent-notificationfence-agents fencing-agentipmitoollibcfg6libcmap4libcorosync-common4libdbus-1-3libnl1libpgm-5.1mount mountallmurano-dashboardneutron-plugin-bigswitch-agentneutron-plugin-ibm-agentneutron-plugin-linuxbridge-agentneutron-plugin-mlnx-agentneutron-plugin-nec-agentneutron-plugin-oneconvergence-agentneutron-plugin-openvswitch-agentneutron-plugin-ryu-agentpercona-xtrabackuppython-pexpectpython-pylibmcpython-zmqsheepdog snmpzabbix-agent zabbix-frontend-php zabbix-sender zabbix-server-mysql zabbix-server-pgsql,ceilometer-agent-compute ceilometer-agent-centralceilometer-agent-notificationfence-agents fencing-agentipmitoollibcfg4libcman3libconfdb4libcoroipcc4 libcoroipcs4libevs4liblogsys4libnl1libpgm-5.1libpload4libquorum4libsam4libtotem-pg4libvotequorum4mount mountallmurano-dashboardneutron-plugin-bigswitch-agentneutron-plugin-ibm-agentneutron-plugin-linuxbridge-agentneutron-plugin-mlnx-agentneutron-plugin-nec-agentneutron-plugin-oneconvergence-agentneutron-plugin-openvswitch-agentneutron-plugin-ryu-agentpython-pylibmcpython-zmqpython-pexpectsheepdog snmppercona-xtrabackupzabbix-server-mysql zabbix-agent zabbix-sender zabbix-server-pgsql zabbix-frontend-php,34,42
openstack%2Fpython-neutronclient~master~Ifc08ac326e8130f69f864b05781076951a306fa0,openstack/python-neutronclient,master,Ifc08ac326e8130f69f864b05781076951a306fa0,Fix True/False to accept Camel and Lower case,MERGED,2014-12-05 02:16:03.000000000,2015-01-07 15:02:33.000000000,2015-01-07 15:02:32.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 7016}, {'_account_id': 8873}]","[{'number': 1, 'created': '2014-12-05 02:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5118a6a5e9ef6ffe2af9788f50c7be32e7921358', 'message': ""Router create ha accepts lower case\n\nNeutron router create optional argument\n'--ha' only accepts Camelcase 'True/False'.\nWith this fix it accepts both Camelcase\nand lowercase.\n\nChange-Id: Ifc08ac326e8130f69f864b05781076951a306fa0\n""}, {'number': 2, 'created': '2014-12-23 00:40:39.000000000', 'files': ['neutronclient/neutron/v2_0/router.py', 'neutronclient/neutron/v2_0/fw/firewallrule.py', 'neutronclient/tests/unit/test_cli20_router.py', 'neutronclient/neutron/v2_0/nec/packetfilter.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4beadef8b5a254a08e03ab80ae1f32a5c07d5278', 'message': ""Fix True/False to accept Camel and Lower case\n\nThere are couple of inconsistency in using\nthe Camelcase and Lower case for 'True/False'\noptions in the python-neutronclient.\n\nWith this fix it will be consistent across all\nCLI commands.\n\nChange-Id: Ifc08ac326e8130f69f864b05781076951a306fa0\n""}]",2,139301,4beadef8b5a254a08e03ab80ae1f32a5c07d5278,21,5,2,7016,,,0,"Fix True/False to accept Camel and Lower case

There are couple of inconsistency in using
the Camelcase and Lower case for 'True/False'
options in the python-neutronclient.

With this fix it will be consistent across all
CLI commands.

Change-Id: Ifc08ac326e8130f69f864b05781076951a306fa0
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/01/139301/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/router.py', 'neutronclient/tests/unit/test_cli20_router.py']",2,5118a6a5e9ef6ffe2af9788f50c7be32e7921358,bug/fix-ha-lowercase, def test_create_router_ha_with_True(self): self._create_router_distributed_or_ha(ha='True') def test_create_router_ha_with_true(self): self._create_router_distributed_or_ha(ha='true') def test_create_router_ha_with_False(self): self._create_router_distributed_or_ha(ha='False') def test_create_router_ha_with_false(self): self._create_router_distributed_or_ha(ha='false'), def test_create_router_ha(self): self._create_router_distributed_or_ha(ha=True),13,4
openstack%2Fgnocchi~master~I6eae480fe0ae2b9c154e6414d87c8bda7be02213,openstack/gnocchi,master,I6eae480fe0ae2b9c154e6414d87c8bda7be02213,"carbonara: store timestamps as integer, not string",MERGED,2014-12-29 13:25:39.000000000,2015-01-07 14:46:21.000000000,2015-01-07 14:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-29 13:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f63b3e464ecf0b24b96c988b7248d5f37d451d8b', 'message': 'carbonara: store timestamps as integer, not string.\n\nThis should drop downs the number of bytes to store the timestamp from\n~27 bytes to ~9 bytes with msgpack.\n\nChange-Id: I6eae480fe0ae2b9c154e6414d87c8bda7be02213\n'}, {'number': 2, 'created': '2015-01-05 12:37:59.000000000', 'files': ['gnocchi/carbonara.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/cbbce73bd07bc42ada0cabf9886eb480f15adaeb', 'message': 'carbonara: store timestamps as integer, not string\n\nThis should drop downs the number of bytes to store the timestamp from\n~27 bytes to ~9 bytes with msgpack.\n\nChange-Id: I6eae480fe0ae2b9c154e6414d87c8bda7be02213\n'}]",0,144299,cbbce73bd07bc42ada0cabf9886eb480f15adaeb,14,3,2,1669,,,0,"carbonara: store timestamps as integer, not string

This should drop downs the number of bytes to store the timestamp from
~27 bytes to ~9 bytes with msgpack.

Change-Id: I6eae480fe0ae2b9c154e6414d87c8bda7be02213
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/99/144299/2 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/carbonara.py'],1,f63b3e464ecf0b24b96c988b7248d5f37d451d8b,jd/carbonara-serialize-timestamp," # NOTE(jd) Store up to the nanosecond 'values': dict((timestamp.value, float(v)) for timestamp, v"," 'values': dict((six.text_type(k), float(v)) for k, v",3,2
openstack%2Fneutron~master~Ieba81ddd423ba233413693fdcc94df3e390ffcdc,openstack/neutron,master,Ieba81ddd423ba233413693fdcc94df3e390ffcdc,Add Check for validation of peer_id field,ABANDONED,2014-08-26 09:34:48.000000000,2015-01-07 14:42:40.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1923}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 7293}, {'_account_id': 8645}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 11447}, {'_account_id': 12040}, {'_account_id': 12444}]","[{'number': 1, 'created': '2014-08-26 09:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66c5780b29c5bb0333e7622aabe90e0545f08230', 'message': 'Check for valid peer_id field\nin update ipsec-site-connection.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 2, 'created': '2014-08-26 10:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f85dd85e933caf69a5ff6270a9052ee58e161a66', 'message': 'Check for valid peer_id field\nin update ipsec-site-connection.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 3, 'created': '2014-08-27 03:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98b7b125b9a1ce33cc2b652e9303ff8bb530df2b', 'message': 'Check for valid peer_id field\nin update ipsec-site-connection.\n\npeer_id field can take IP Address format only.\nso adding the check for validation.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 4, 'created': '2014-08-27 06:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3bf1ea2b5591c292cbf924684e9883a17c6ded6', 'message': 'Check for valid peer_id field\n\nin update ipsec-site-connection.\npeer_id field can take IP Address format only.\nso adding the check for validation.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 5, 'created': '2014-09-02 05:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6f899c1a06fbb040b740c0eff53dcf23059be0b', 'message': 'Check for valid peer_id field\n\nin create/update ipsec-site-connection.\npeer_id field can take IP Address format only.\nso adding the check for validation.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 6, 'created': '2014-09-02 05:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/47abd16b82b506ae8318fdcfe73ba44cb88c0e09', 'message': 'Check for valid peer_id field\n\nin create/update ipsec-site-connection.\npeer_id field can take IP Address format only.\nso adding the check for validation.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 7, 'created': '2014-09-02 05:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f2ffc7f01a859f122dd1968cb60faeb5a2d3942', 'message': 'Check for valid peer_id field\n\nin create/update ipsec-site-connection.\npeer_id field can take IP Address format only.\nso adding the check for validation.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 8, 'created': '2014-09-12 15:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1acbb2bce36d1309a0183705d14d55433f7ac754', 'message': 'Added Check for validation of peer_id field\n\nin create/update ipsec-site-connection.\nSince peer_id field can take IP Address format only.\nBut API definition states it can be email-id,name and FQDN.\nNeed DocImpact as this changes the API definition.\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 9, 'created': '2014-09-23 07:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6197df82b944e936cfb1230e6d3fbe33b6360b6e', 'message': 'Added Check for validation of peer_id field\n\nPeer_id field in VPN ipsec_site_connection\ncan take IP Address format only.But API definition\nstates it can be email-id,name and FQDN.\n\nDocImpact\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}, {'number': 10, 'created': '2014-09-23 08:55:46.000000000', 'files': ['neutron/db/vpn/vpn_validator.py', 'neutron/db/vpn/vpn_db.py', 'neutron/extensions/vpnaas.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/service_drivers/cisco_validator.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad79b1df331f86104810c3012f19d9111dcf7d7c', 'message': 'Add Check for validation of peer_id field\n\nPeer_id field in VPN ipsec_site_connection\ncan take IP Address format only.But API definition\nstates it can be email-id,name and FQDN.\n\nDocImpact\n\nCloses-Bug: 1316731\nChange-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc\n'}]",27,116835,ad79b1df331f86104810c3012f19d9111dcf7d7c,184,31,10,11447,,,0,"Add Check for validation of peer_id field

Peer_id field in VPN ipsec_site_connection
can take IP Address format only.But API definition
states it can be email-id,name and FQDN.

DocImpact

Closes-Bug: 1316731
Change-Id: Ieba81ddd423ba233413693fdcc94df3e390ffcdc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/116835/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/vpn/vpn_db.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py']",2,66c5780b29c5bb0333e7622aabe90e0545f08230,bug/1316731," def test_update_ipsec_site_connection_with_invalid_peer_id(self): """"""Test updates to ipsec_site_connection with invalid peer_id."""""" self._test_update_ipsec_site_connection( update={'peer_id': 'abc@hp.com'}, expected_status_int=400) ",,8,0
openstack%2Frally~master~I029cc3d7f8c5e2ad06599b65023b1ed6922ab448,openstack/rally,master,I029cc3d7f8c5e2ad06599b65023b1ed6922ab448,Skipping CliUtilsTestCase,MERGED,2015-01-07 11:18:13.000000000,2015-01-07 14:20:36.000000000,2015-01-07 14:20:31.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2015-01-07 11:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b62421c9a9df02ab73000f675b9a21d9aea95c94', 'message': 'Skipping CliUtilsTestCase\n\nThese tests are not working with latest(1.6.0) oslo.config.\nSee https://review.openstack.org/#/c/135150 for more details.\nWe should wait for new release of oslo.config with appropriate fix\nto re-enable it.\n\nChange-Id: I029cc3d7f8c5e2ad06599b65023b1ed6922ab448\n'}, {'number': 2, 'created': '2015-01-07 12:42:36.000000000', 'files': ['tests/unit/cmd/test_cliutils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/2e4cd1985b2d427a05dc061b44136270a5443c17', 'message': 'Skipping CliUtilsTestCase\n\nThese tests are not working with latest(1.6.0) oslo.config.\nSee https://review.openstack.org/#/c/135150 for more details.\nWe should wait for new release of oslo.config with appropriate fix\nto re-enable it.\n\nChange-Id: I029cc3d7f8c5e2ad06599b65023b1ed6922ab448\n'}]",1,145470,2e4cd1985b2d427a05dc061b44136270a5443c17,14,4,2,8367,,,0,"Skipping CliUtilsTestCase

These tests are not working with latest(1.6.0) oslo.config.
See https://review.openstack.org/#/c/135150 for more details.
We should wait for new release of oslo.config with appropriate fix
to re-enable it.

Change-Id: I029cc3d7f8c5e2ad06599b65023b1ed6922ab448
",git fetch https://review.opendev.org/openstack/rally refs/changes/70/145470/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/cmd/test_cliutils.py'],1,b62421c9a9df02ab73000f675b9a21d9aea95c94,skip_oslo,"@testtools.skip( ""These tests are not work with latest(1.6.0) oslo.config (see "" ""https://review.openstack.org/#/c/135150 for more details). "" ""Should wait for new release of oslo.config with appropriate fix."")"," @testtools.skip( ""This test is not work with latest(1.6.0) oslo.config(see "" ""https://review.openstack.org/#/c/135150 for more details). "" ""Should wait for new release of oslo.config with appropriate fix."") @testtools.skip( ""This test is not work with latest(1.6.0) oslo.config(see "" ""https://review.openstack.org/#/c/135150 for more details). "" ""Should wait for new release of oslo.config with appropriate fix."") @testtools.skip( ""This test is not work with latest(1.6.0) oslo.config(see "" ""https://review.openstack.org/#/c/135150 for more details). "" ""Should wait for new release of oslo.config with appropriate fix."")",4,13
openstack%2Fdevstack~master~I80a6ad5841ea4a8d36bcf89eade4d782cccd50f0,openstack/devstack,master,I80a6ad5841ea4a8d36bcf89eade4d782cccd50f0,Setup notification properly for Trove,ABANDONED,2014-08-25 16:24:48.000000000,2015-01-07 14:10:45.000000000,,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6172}, {'_account_id': 6549}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-25 16:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7c543e70bb26ecf8b85f42ed20f681c6772a1784', 'message': 'Setup notification properly for Trove\n\nAs we integrated OSprofiler with Trove by change\nI580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5 , then services\ntrove-api, taskmanager, conductor and guestagent\nstarted requiring notification API to send profiling data\nso it requires relevant options to make it work.\n\nChange-Id: I80a6ad5841ea4a8d36bcf89eade4d782cccd50f0\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-12-26 09:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c03e46bd8f452c773273a299aaa4a5a4a345ea3b', 'message': 'Setup notification properly for Trove\n\nAs we integrated OSprofiler with Trove by change\nI580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5 , then services\ntrove-api, taskmanager, conductor and guestagent\nstarted requiring notification API to send profiling data\nso it requires relevant options to make it work.\n\nChange-Id: I80a6ad5841ea4a8d36bcf89eade4d782cccd50f0\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 3, 'created': '2014-12-30 05:07:21.000000000', 'files': ['lib/trove'], 'web_link': 'https://opendev.org/openstack/devstack/commit/655fb7798b998c816d8d144ac56f40fe9b6c402b', 'message': 'Setup notification properly for Trove\n\nAs we integrated OSprofiler with Trove by change\nI580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5 , then services\ntrove-api, taskmanager, conductor and guestagent\nstarted requiring notification API to send profiling data\nso it requires relevant options to make it work.\n\nChange-Id: I80a6ad5841ea4a8d36bcf89eade4d782cccd50f0\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}]",4,116671,655fb7798b998c816d8d144ac56f40fe9b6c402b,15,6,3,6549,,,0,"Setup notification properly for Trove

As we integrated OSprofiler with Trove by change
I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5 , then services
trove-api, taskmanager, conductor and guestagent
started requiring notification API to send profiling data
so it requires relevant options to make it work.

Change-Id: I80a6ad5841ea4a8d36bcf89eade4d782cccd50f0
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>",git fetch https://review.opendev.org/openstack/devstack refs/changes/71/116671/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/trove'],1,7c543e70bb26ecf8b85f42ed20f681c6772a1784,, iniset $TROVE_CONF_DIR/trove.conf DEFAULT control_exchange trove iniset $TROVE_CONF_DIR/trove.conf DEFAULT notification_driver trove.openstack.common.notifier.rpc_notifier iniset $TROVE_CONF_DIR/trove-taskmanager.conf DEFAULT control_exchange trove iniset $TROVE_CONF_DIR/trove-taskmanager.conf DEFAULT notification_driver trove.openstack.common.notifier.rpc_notifier iniset $TROVE_CONF_DIR/trove-conductor.conf DEFAULT notification_driver trove.openstack.common.notifier.rpc_notifier iniset $TROVE_CONF_DIR/trove-guestagent.conf DEFAULT notification_driver trove.openstack.common.notifier.rpc_notifier,,6,0
openstack%2Fgnocchi~master~Idb2770e5cb8f01d4fa84234d4c8791cbe2c51187,openstack/gnocchi,master,Idb2770e5cb8f01d4fa84234d4c8791cbe2c51187,Create an archive_policy module,MERGED,2015-01-06 17:30:42.000000000,2015-01-07 14:05:01.000000000,2015-01-07 14:05:00.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2015-01-06 17:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7d6922341c15fdfcd7a5b0aa38d3b5ce52cfc6d2', 'message': 'Create an archive_policy module\n\nThis should store the ArchivePolicy related classes so it can be used by\nother modules than rest.\n\nChange-Id: Idb2770e5cb8f01d4fa84234d4c8791cbe2c51187\n'}, {'number': 2, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/09c5fcca10ca3dc03f64ae3c03a55b1c4ea948b9', 'message': 'Create an archive_policy module\n\nThis should store the ArchivePolicy related classes so it can be used by\nother modules than rest.\n\nChange-Id: Idb2770e5cb8f01d4fa84234d4c8791cbe2c51187\n'}, {'number': 3, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/archive_policy.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/3c297379f15433662e76b70f9429a460176ec29f', 'message': 'Create an archive_policy module\n\nThis should store the ArchivePolicy related classes so it can be used by\nother modules than rest.\n\nChange-Id: Idb2770e5cb8f01d4fa84234d4c8791cbe2c51187\n'}]",0,145274,3c297379f15433662e76b70f9429a460176ec29f,12,3,3,1669,,,0,"Create an archive_policy module

This should store the ArchivePolicy related classes so it can be used by
other modules than rest.

Change-Id: Idb2770e5cb8f01d4fa84234d4c8791cbe2c51187
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/74/145274/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/archive_policy.py', 'gnocchi/tests/test_rest.py']",3,7d6922341c15fdfcd7a5b0aa38d3b5ce52cfc6d2,jd/statsd,from gnocchi import archive_policy archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() archive_policy.ArchivePolicyItem( **d).to_human_readable_dict() archive_policy.ArchivePolicyItem( **d).to_human_readable_dict(), rest.ArchivePolicyItem(**d).to_human_readable_dict() rest.ArchivePolicyItem(**d).to_human_readable_dict() rest.ArchivePolicyItem(**d).to_human_readable_dict() rest.ArchivePolicyItem(**d).to_human_readable_dict(),120,72
openstack%2Frequirements~master~I3814ede07a145a18c2fe91b799436b3acf1a28a9,openstack/requirements,master,I3814ede07a145a18c2fe91b799436b3acf1a28a9,Add Octavia to project list,MERGED,2014-12-14 04:56:45.000000000,2015-01-07 14:04:46.000000000,2015-01-07 14:04:44.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 6786}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-12-14 04:56:45.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c6d382f82de09732a804a776a76dfb91682184ec', 'message': 'Add Octavia to project list\n\nChange-Id: I3814ede07a145a18c2fe91b799436b3acf1a28a9\n'}]",0,141620,c6d382f82de09732a804a776a76dfb91682184ec,9,4,1,10980,,,0,"Add Octavia to project list

Change-Id: I3814ede07a145a18c2fe91b799436b3acf1a28a9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/20/141620/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,c6d382f82de09732a804a776a76dfb91682184ec,add_octavia,stackforge/octavia,,1,0
openstack%2Fpuppet-keystone~master~Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0,openstack/puppet-keystone,master,Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0,Use openstackclient for keystone_service,MERGED,2014-12-17 23:17:12.000000000,2015-01-07 14:04:38.000000000,2015-01-07 14:04:37.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-12-17 23:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a27078d244d88e6810d62ebecb1ebfb93f17c44a', 'message': 'Migrate keystone_service to use openstackclient\n\nWIP: keystone_service never had any spec tests, we should probably\nwrite them...\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 2, 'created': '2014-12-17 23:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/fab60c9e58fa1e26c479da18236fcd4c52e1b5e0', 'message': 'Migrate keystone_service to use openstackclient\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 3, 'created': '2014-12-17 23:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/feded978f48b6a02b019361feefc112f5c683a57', 'message': 'Migrate keystone_service to use openstackclient\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 4, 'created': '2014-12-18 00:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/0c59f546ab94b85f07f36c808d515015c6d9312d', 'message': 'Migrate keystone_service to use openstackclient\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 5, 'created': '2014-12-18 00:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/135df1bd3248a92f72a0bc38c8adf6f270a2c1cb', 'message': 'Migrate keystone_service to use openstackclient\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 6, 'created': '2014-12-18 00:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a0773a64afed9f5c289f84abf68f08b4410bf24b', 'message': 'Migrate keystone_service to use openstackclient\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 7, 'created': '2014-12-18 17:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/e252351aafa6991e824c03b618df4978b9a483ed', 'message': 'Migrate keystone_service to use openstackclient\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 8, 'created': '2014-12-22 07:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/04de820da34dce87f553a9581db2f9a4195ce8d7', 'message': 'Use openstackclient for keystone_service\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 9, 'created': '2014-12-23 18:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/27a45cb9d30040186ba3d563ed35f0ba48f4c646', 'message': 'Use openstackclient for keystone_service\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}, {'number': 10, 'created': '2015-01-05 19:13:17.000000000', 'files': ['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb', 'lib/puppet/provider/keystone_service/keystone.rb', 'spec/unit/provider/keystone_service/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/72a02aa70880bb5cb07d0a2b1e828fffbae5d0ed', 'message': 'Use openstackclient for keystone_service\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n'}]",1,142608,72a02aa70880bb5cb07d0a2b1e828fffbae5d0ed,23,4,10,8482,,,0,"Use openstackclient for keystone_service

blueprint use-openstackclient-in-module-resources

Change-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/08/142608/10 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb', 'lib/puppet/provider/keystone_service/keystone.rb']",3,a27078d244d88e6810d62ebecb1ebfb93f17c44a,openstackclient,,"$LOAD_PATH.push(File.join(File.dirname(__FILE__), '..', '..', '..')) require 'puppet/provider/keystone' Puppet::Type.type(:keystone_service).provide( :keystone, :parent => Puppet::Provider::Keystone ) do desc <<-EOT Provider that uses the keystone client tool to manage keystone services This provider makes a few assumptions/ 1. assumes that the admin endpoint can be accessed via localhost. 2. Assumes that the admin token and port can be accessed from /etc/keystone/keystone.conf Does not support the ability to list all EOT optional_commands :keystone => ""keystone"" def self.prefetch(resource) # rebuild the cahce for every puppet run @service_hash = nil end def self.service_hash @service_hash ||= build_service_hash end def service_hash self.class.service_hash end def self.instances service_hash.collect do |k, v| new(:name => k) end end def create optional_opts = [] raise(Puppet::Error, ""Required property type not specified for KeystoneService[#{resource[:name]}]"") unless resource[:type] if resource[:description] optional_opts.push('--description').push(resource[:description]) end auth_keystone( 'service-create', '--name', resource[:name], '--type', resource[:type], optional_opts ) end def exists? service_hash[resource[:name]] end def destroy auth_keystone('service-delete', service_hash[resource[:name]][:id]) end def id service_hash[resource[:name]][:id] end def type service_hash[resource[:name]][:type] end def type=(value) raise(Puppet::Error, ""service-update is not currently supported by the keystone sql driver"") end def description service_hash[resource[:name]][:description] end def description=(value) raise(Puppet::Error, ""service-update is not currently supported by the keystone sql driver"") end private def self.build_service_hash hash = {} list_keystone_objects('service', 4).each do |user| hash[user[1]] = { :id => user[0], :type => user[2], :description => user[3] } end hash end end ",117,102
openstack%2Fgnocchi~master~Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d,openstack/gnocchi,master,Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d,indexer: only load metrics on explicit demand,MERGED,2015-01-06 16:09:20.000000000,2015-01-07 14:02:35.000000000,2015-01-07 14:02:34.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2015-01-06 16:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ef8bb0c5e9f65e0c027cde1b80f4eceed4b57941', 'message': 'indexer: only load metrics on explicit demand\n\nThis patch adds a new argument to get_resource() so it only returns the\nmetrics if asked for. If so, the metrics are loaded by a join so we\nminimize the number of query to… 1.\n\nLazy benchmark shows 10-15% speed improvement on running the unit tests.\n\nChange-Id: Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d\n'}, {'number': 2, 'created': '2015-01-06 17:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/64af8fa76654a59752506ccf03af5d51210df92c', 'message': 'indexer: only load metrics on explicit demand\n\nThis patch adds a new argument to get_resource() so it only returns the\nmetrics if asked for. If so, the metrics are loaded by a join so we\nminimize the number of query to… 1.\n\nLazy benchmark shows 10-15% speed improvement on running the unit tests.\n\nChange-Id: Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d\n'}, {'number': 3, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d9c30bbfc8d0e85330f93e64e0ae90042f9a3b5b', 'message': 'indexer: only load metrics on explicit demand\n\nThis patch adds a new argument to get_resource() so it only returns the\nmetrics if asked for. If so, the metrics are loaded by a join so we\nminimize the number of query to… 1.\n\nLazy benchmark shows 10-15% speed improvement on running the unit tests.\n\nChange-Id: Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d\n'}, {'number': 4, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d499c9943fb2d64f85697babba025e6f306034c5', 'message': 'indexer: only load metrics on explicit demand\n\nThis patch adds a new argument to get_resource() so it only returns the\nmetrics if asked for. If so, the metrics are loaded by a join so we\nminimize the number of query to… 1.\n\nLazy benchmark shows 10-15% speed improvement on running the unit tests.\n\nChange-Id: Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d\n'}]",0,145258,d499c9943fb2d64f85697babba025e6f306034c5,14,3,4,1669,,,0,"indexer: only load metrics on explicit demand

This patch adds a new argument to get_resource() so it only returns the
metrics if asked for. If so, the metrics are loaded by a join so we
minimize the number of query to… 1.

Lazy benchmark shows 10-15% speed improvement on running the unit tests.

Change-Id: Ifaaa4029ee99ebc1e3a93561d4ece5450ec3545d
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/58/145258/4 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py']",4,ef8bb0c5e9f65e0c027cde1b80f4eceed4b57941,jd/statsd," return self._resource_to_dict(r, with_metrics=True) def _resource_to_dict(resource, with_metrics=False): if with_metrics and isinstance(resource, Resource): return self._resource_to_dict(r, with_metrics=True) def get_resource(self, resource_type, uuid, with_metrics=False): if with_metrics: q = q.options(sqlalchemy.orm.joinedload(resource_cls.metrics)) return self._resource_to_dict(r, with_metrics) # Always include metrics q = q.options(sqlalchemy.orm.joinedload(resource_cls.metrics)) return [self._resource_to_dict(r, with_metrics=True) for r in all_resources]"," return self._resource_to_dict(r) def _resource_to_dict(resource): if isinstance(resource, Resource): return self._resource_to_dict(r) def get_resource(self, resource_type, uuid): return self._resource_to_dict(r) return [self._resource_to_dict(r) for r in all_resources]",36,34
openstack%2Fgnocchi~master~I9d1a4dcbc119e0d74cc0f43ed70d8278251410b6,openstack/gnocchi,master,I9d1a4dcbc119e0d74cc0f43ed70d8278251410b6,Check RBAC policy on aggregated metric access,MERGED,2015-01-05 16:35:52.000000000,2015-01-07 14:02:09.000000000,2015-01-07 14:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2015-01-05 16:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c50f99fb4c20cbeab7f04a6d15e5a281bc02eade', 'message': 'Check RBAC policy on aggregated metric access\n\nChange-Id: I9d1a4dcbc119e0d74cc0f43ed70d8278251410b6\n'}, {'number': 2, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/65b79b6a4b4ba4c27528c855a2fb1bcdb9045d8b', 'message': 'Check RBAC policy on aggregated metric access\n\nChange-Id: I9d1a4dcbc119e0d74cc0f43ed70d8278251410b6\n'}, {'number': 3, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1341e6247831f3612a69387dc16e0700e581680b', 'message': 'Check RBAC policy on aggregated metric access\n\nChange-Id: I9d1a4dcbc119e0d74cc0f43ed70d8278251410b6\n'}]",0,145017,1341e6247831f3612a69387dc16e0700e581680b,11,3,3,1669,,,0,"Check RBAC policy on aggregated metric access

Change-Id: I9d1a4dcbc119e0d74cc0f43ed70d8278251410b6
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/17/145017/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,c50f99fb4c20cbeab7f04a6d15e5a281bc02eade,jd/statsd," # Check RBAC policy metrics = pecan.request.indexer.get_metrics(self.metric_ids) missing_metric_ids = (set(m['id'] for m in metrics) - set(self.metric_ids)) if missing_metric_ids: # Return the first missing one in the error pecan.abort(404, storage.MetricDoesNotExist( missing_metric_ids[0])) for metric in metrics: enforce(""get metric"", metric) ",,12,0
openstack%2Fgnocchi~master~I5d81fcda95a266af02ca5123e409045eaa771f45,openstack/gnocchi,master,I5d81fcda95a266af02ca5123e409045eaa771f45,rest: do not retrieve the metric twice in get_all(),MERGED,2015-01-05 14:58:58.000000000,2015-01-07 14:02:06.000000000,2015-01-07 14:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2015-01-05 14:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/77c0cd0b813905f52f3b6178797dfabd40909cc4', 'message': 'rest: do not retrieve the metric twice in get_all()\n\nWe used to retrieve it once for enforce() and then one for returning. Do\nthat once and for all!\n\nChange-Id: I5d81fcda95a266af02ca5123e409045eaa771f45\n'}, {'number': 2, 'created': '2015-01-05 16:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/3326eda7973d9829adc8d70d99e7e95227007602', 'message': 'rest: do not retrieve the metric twice in get_all()\n\nWe used to retrieve it once for enforce() and then one for returning. Do\nthat once and for all!\n\nChange-Id: I5d81fcda95a266af02ca5123e409045eaa771f45\n'}, {'number': 3, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f77535d04309d5860aa5140340d45a25cdfc9a7e', 'message': 'rest: do not retrieve the metric twice in get_all()\n\nWe used to retrieve it once for enforce() and then one for returning. Do\nthat once and for all!\n\nChange-Id: I5d81fcda95a266af02ca5123e409045eaa771f45\n'}, {'number': 4, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9e608e94677665bead60d1e3a166b25b686725e8', 'message': 'rest: do not retrieve the metric twice in get_all()\n\nWe used to retrieve it once for enforce() and then one for returning. Do\nthat once and for all!\n\nChange-Id: I5d81fcda95a266af02ca5123e409045eaa771f45\n'}]",1,145001,9e608e94677665bead60d1e3a166b25b686725e8,14,3,4,1669,,,0,"rest: do not retrieve the metric twice in get_all()

We used to retrieve it once for enforce() and then one for returning. Do
that once and for all!

Change-Id: I5d81fcda95a266af02ca5123e409045eaa771f45
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/01/145001/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,77c0cd0b813905f52f3b6178797dfabd40909cc4,jd/statsd," enforce(""get metric"", metric)"," self.enforce_metric(""get metric"")",1,1
openstack%2Fbarbican~master~Iccb24665801e9c207fa90acbaa4ce6e24088cf90,openstack/barbican,master,Iccb24665801e9c207fa90acbaa4ce6e24088cf90,Add I18n-related unit tests (Part 3),MERGED,2014-12-13 05:17:30.000000000,2015-01-07 14:01:39.000000000,2015-01-07 14:01:37.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-13 05:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/db18f2408564a9c1f3bc024b1a7e493dcaff7a54', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 2, 'created': '2014-12-13 06:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9e455b7036c7306661ce0f81d2f0d1a3a520a092', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 3, 'created': '2014-12-14 01:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/285ffcd4dde5e2169c953de39d9dcf2a792aa27e', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 4, 'created': '2014-12-14 02:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b90a40b75f8fdddf3c4451ddac90093f7b072ba9', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 5, 'created': '2014-12-14 02:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c7cfce2092933551c54212415cdb7296c0b3a001', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 6, 'created': '2014-12-14 05:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ca6b3668878ebf1036335032a149b08662c92d72', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 7, 'created': '2014-12-15 14:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4b75a1c8a4574a9a782a00829304b99d5b96acc1', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 8, 'created': '2014-12-15 16:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/585836e295af398976618ab5299b5efc8c1d79f5', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 9, 'created': '2014-12-15 17:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0606f2c3e2c5401a3998860ce13a422d87dc9767', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 10, 'created': '2014-12-15 19:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/14e96582fc213b08e725353c76923476a97a25f1', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 11, 'created': '2014-12-15 19:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/2557dc683947b3fd406fe751748f39d0e45f3274', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 12, 'created': '2014-12-15 20:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0b8b0a45723b4d5de4bdd25eadccdb7ade06b4e1', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 13, 'created': '2014-12-15 22:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/dfa36c6f96a9fa963a42ebd2fa986c8df438312c', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 14, 'created': '2014-12-16 04:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ad9abb34ccf962f9d3ac466c9c1e12aa3a5b3e23', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 15, 'created': '2014-12-16 06:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ef1f682063cab69c72834efe32a9587c47eb6660', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 16, 'created': '2014-12-16 13:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f565afb417dec5d1ee84efffd1158b0920250f98', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 17, 'created': '2014-12-16 13:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0a3552e5e74ba726ee7a124bd6a6ce88326d8c06', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 18, 'created': '2015-01-05 04:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/16e6a0c68bb63dd7986fe1c333a7a1d2b5f6f8e7', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 19, 'created': '2015-01-05 19:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1fe5bed94f44f629df574f77542015d530640dc9', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}, {'number': 20, 'created': '2015-01-05 22:41:09.000000000', 'files': ['barbican/tests/model/repositories/test_repositories_consumers.py', 'barbican/tests/model/repositories/test_repositories_projects.py', 'barbican/tests/model/repositories/test_repositories_containers.py', 'barbican/plugin/interface/secret_store.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/api/__init__.py', 'barbican/tests/api/middleware/test_context.py', 'barbican/tests/database_utils.py', 'barbican/tests/api/middleware/test_simple.py', 'barbican/tests/model/repositories/test_repositories_secrets.py', 'barbican/tasks/resources.py', 'barbican/api/controllers/__init__.py', 'barbican/model/models.py', 'barbican/tests/model/repositories/test_repositories_transport_keys.py', '.coveragerc', 'barbican/locale/barbican.pot', 'barbican/plugin/interface/certificate_manager.py', 'barbican/tests/model/repositories/test_repositories_orders.py', 'barbican/tests/tasks/test_resources.py', 'barbican/tests/api/test_init.py', 'barbican/tests/plugin/interface/test_secret_store.py', 'barbican/api/middleware/context.py', 'barbican/tests/api/middleware/__init__.py', 'barbican/tasks/keystone_consumer.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/010b397e9ea5ee5afabdf109d76d5b1db658ffdd', 'message': ""Add I18n-related unit tests (Part 3)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database/repository unit tests to the 'repository'\npackage.\n\nChange-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90\n""}]",6,141535,010b397e9ea5ee5afabdf109d76d5b1db658ffdd,65,5,20,7789,,,0,"Add I18n-related unit tests (Part 3)

This CR is the first of several dependent CRs that break up the overall
tests added via this abandoned CR:
https://review.openstack.org/#/c/139894
This CR adds the new database/repository unit tests to the 'repository'
package.

Change-Id: Iccb24665801e9c207fa90acbaa4ce6e24088cf90
",git fetch https://review.opendev.org/openstack/barbican refs/changes/35/141535/20 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/model/repositories/test_repositories_consumers.py', 'barbican/tests/model/repositories/test_repositories_containers.py']",2,db18f2408564a9c1f3bc024b1a7e493dcaff7a54,add-i18n-related-unit-tests-add-remaining-tests,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from barbican.common import exception from barbican.model import repositories from barbican.tests import database_utils class WhenTestingContainerRepository(database_utils.RepositoryTestCase): def setUp(self): super(WhenTestingContainerRepository, self).setUp() self.repo = repositories.ContainerRepo() def test_should_raise_no_result_found(self): session = self.repo.get_session() self.assertRaises( exception.NotFound, self.repo.get_by_create_date, ""my keystone id"", session=session, suppress_exception=False) ",,159,0
openstack%2Fgnocchi~master~I83e3431a6e2fe3ef51edea3858907156cb526f49,openstack/gnocchi,master,I83e3431a6e2fe3ef51edea3858907156cb526f49,Allow to retrieve several metrics at once from the indexer,MERGED,2015-01-05 14:58:58.000000000,2015-01-07 13:56:55.000000000,2015-01-07 13:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2015-01-05 14:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4a16277688d7a9b4f7751d8c517daccd4065a38c', 'message': 'Allow to retrieve several metrics at once from the indexer\n\nChange-Id: I83e3431a6e2fe3ef51edea3858907156cb526f49\n'}, {'number': 2, 'created': '2015-01-05 16:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/382909b7ab7239dcb99ee1a8181a57b532c3610f', 'message': 'Allow to retrieve several metrics at once from the indexer\n\nChange-Id: I83e3431a6e2fe3ef51edea3858907156cb526f49\n'}, {'number': 3, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1f59b181306299e3e9f49228349d21d585560fcf', 'message': 'Allow to retrieve several metrics at once from the indexer\n\nChange-Id: I83e3431a6e2fe3ef51edea3858907156cb526f49\n'}, {'number': 4, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7f8e23272f85041466ce52ade746798549efbc85', 'message': 'Allow to retrieve several metrics at once from the indexer\n\nChange-Id: I83e3431a6e2fe3ef51edea3858907156cb526f49\n'}]",0,145000,7f8e23272f85041466ce52ade746798549efbc85,14,3,4,1669,,,0,"Allow to retrieve several metrics at once from the indexer

Change-Id: I83e3431a6e2fe3ef51edea3858907156cb526f49
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/00/145000/3 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py']",6,4a16277688d7a9b4f7751d8c517daccd4065a38c,jd/statsd," params={""archive_policy_name"": ap}, params={""archive_policy_name"": ap}) params={""archive_policy_name"": ""medium""}, self.assertEqual(metric['archive_policy_name'], ""medium"") params={""archive_policy_name"": ""medium""}, self.assertEqual(metric['archive_policy_name'], ""medium"") params={""archive_policy_name"": ""medium""}, params={""archive_policy_name"": ""medium""}, params={""archive_policy_name"": ""medium""}, params={""archive_policy_name"": ""medium""}, params={""archive_policy_name"": ""medium""}, params={""archive_policy_name"": policy}, params={""archive_policy_name"": ""medium""}, params={""archive_policy_name"": ""medium""}) params={""archive_policy_name"": ""medium""}) params={""archive_policy_name"": ""medium""}) result = self.app.post_json( ""/v1/metric"", params={""archive_policy_name"": 'foobar123'}, expect_errors=True, status=400) params={""archive_policy_name"": ""high""}) params={""archive_policy_name"": ""high""}) params={""archive_policy_name"": ""high""}, params={""archive_policy_name"": ap_name}) params={""archive_policy_name"": ""low""}) params={""archive_policy_name"": ""low""}) params={""archive_policy_name"": ""low""}) params={""archive_policy_name"": ""high""}) params={""archive_policy_name"": ""high""}) params={""archive_policy_name"": ""medium""}) params={""archive_policy_name"": ""medium""}) params={""archive_policy_name"": ""medium""}) params={'archive_policy_name': ""high""}) self.attributes['metrics'] = {'foo': {'archive_policy_name': ""high""}} self.attributes['metrics'] = {'foo': {'archive_policy_name': ""high""}} metrics = {'foo': {'archive_policy_name': ""high""}} metrics = {'foo': {'archive_policy_name': ""low""}} metrics = {'foo': {'archive_policy_name': ""high""}} params={'archive_policy_name': ""high""}) new_metrics = {'foo': {'archive_policy_name': ""medium""}} result = self.app.post_json( ""/v1/metric"", params={'archive_policy_name': ""medium""}) params={""archive_policy_name"": ""medium""}) self.attributes['metrics'] = {""foo"": {""archive_policy_name"": ""low""}} params={""archive_policy_name"": ""low""}) params={""archive_policy_name"": params={""archive_policy_name"": ""medium""}) params={""archive_policy_name"": ""medium""})"," params={""archive_policy"": ap}, params={""archive_policy"": ap}) params={""archive_policy"": ""medium""}, self.assertEqual(metric['archive_policy'], ""medium"") params={""archive_policy"": ""medium""}, self.assertEqual(metric['archive_policy'], ""medium"") params={""archive_policy"": ""medium""}, params={""archive_policy"": ""medium""}, params={""archive_policy"": ""medium""}, params={""archive_policy"": ""medium""}, params={""archive_policy"": ""medium""}, params={""archive_policy"": policy}, params={""archive_policy"": ""medium""}, params={""archive_policy"": ""medium""}) params={""archive_policy"": ""medium""}) params={""archive_policy"": ""medium""}) result = self.app.post_json(""/v1/metric"", params={""archive_policy"": 'foobar123'}, expect_errors=True, status=400) params={""archive_policy"": ""high""}) params={""archive_policy"": ""high""}) params={""archive_policy"": ""high""}, params={""archive_policy"": ap_name}) params={""archive_policy"": ""low""}) params={""archive_policy"": ""low""}) params={""archive_policy"": ""low""}) params={""archive_policy"": ""high""}) params={""archive_policy"": ""high""}) params={""archive_policy"": ""medium""}) params={""archive_policy"": ""medium""}) params={""archive_policy"": ""medium""}) params={'archive_policy': ""high""}) self.attributes['metrics'] = {'foo': {'archive_policy': ""high""}} self.attributes['metrics'] = {'foo': {'archive_policy': ""high""}} metrics = {'foo': {'archive_policy': ""high""}} metrics = {'foo': {'archive_policy': ""low""}} metrics = {'foo': {'archive_policy': ""high""}} params={'archive_policy': ""high""}) new_metrics = {'foo': {'archive_policy': ""medium""}} result = self.app.post_json(""/v1/metric"", params={'archive_policy': ""medium""}) params={""archive_policy"": ""medium""}) self.attributes['metrics'] = {""foo"": {""archive_policy"": ""low""}} params={""archive_policy"": ""low""}) params={""archive_policy"": params={""archive_policy"": ""medium""}) params={""archive_policy"": ""medium""})",130,117
openstack%2Fgnocchi~master~I54a0f48214b5f8c283b121a64907e2f0e212002f,openstack/gnocchi,master,I54a0f48214b5f8c283b121a64907e2f0e212002f,rest: fix typo in metric policy,MERGED,2014-12-31 15:46:47.000000000,2015-01-07 13:56:45.000000000,2015-01-07 13:56:43.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-31 15:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/030328adf6379a68a28fe6bf0b5c47c3a41d16a0', 'message': 'rest: fix typo in metric policy\n\nChange-Id: I54a0f48214b5f8c283b121a64907e2f0e212002f\n'}, {'number': 2, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/aeff48715157dc51b11b804bc34ac2ad808f3fc6', 'message': 'rest: fix typo in metric policy\n\nChange-Id: I54a0f48214b5f8c283b121a64907e2f0e212002f\n'}, {'number': 3, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/56c072811503a488287bda2f9b4ae8d88cb929da', 'message': 'rest: fix typo in metric policy\n\nChange-Id: I54a0f48214b5f8c283b121a64907e2f0e212002f\n'}]",0,144640,56c072811503a488287bda2f9b4ae8d88cb929da,12,3,3,1669,,,0,"rest: fix typo in metric policy

Change-Id: I54a0f48214b5f8c283b121a64907e2f0e212002f
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/40/144640/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,030328adf6379a68a28fe6bf0b5c47c3a41d16a0,jd/statsd," enforce(""list metric"", {})"," enforce(""list resource"", {})",1,1
openstack%2Fneutron~master~Idfe93cace0c1b633be6e786206fbec6e1f3c13cd,openstack/neutron,master,Idfe93cace0c1b633be6e786206fbec6e1f3c13cd,HA for DVR - schema migration and change,MERGED,2014-12-23 19:03:03.000000000,2015-01-07 13:53:32.000000000,2015-01-07 02:48:09.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-23 19:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8fbbcce47d01eb72b93b88028721322d873499b3', 'message': 'HA for DVR - schema migration and change\n\nTo support HA for DVR SNAT, default SNAT has to be schedulable\non multiple L3 agents. The csnat_l3_agent_bindings table is being\nmodified to include l3_agent_id in the primary key.\nThe migration script and Class definition update is included in\nthis patch. For modularity and code management, HA/DVR methods\nthat would make use of this change will be included in a different\npatch.\n\nChange-Id: Idfe93cace0c1b633be6e786206fbec6e1f3c13cd\nPartial-bug: #1365473\n'}, {'number': 2, 'created': '2014-12-24 21:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd50a6e984b9bdc2e0c30906b93c46031ef6f93a', 'message': 'HA for DVR - schema migration and change\n\nTo support HA for DVR SNAT, default SNAT has to be schedulable\non multiple L3 agents. The csnat_l3_agent_bindings table is being\nmodified to include l3_agent_id in the primary key.\nThe migration script and Class definition update is included in\nthis patch. For modularity and code management, HA/DVR methods\nthat would make use of this change will be included in a different\npatch.\n\nPartial-bug: #1365473\nChange-Id: Idfe93cace0c1b633be6e786206fbec6e1f3c13cd\n'}, {'number': 3, 'created': '2014-12-29 20:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc228d51ca3678354374ef071ea51349adb2e6fd', 'message': 'HA for DVR - schema migration and change\n\nTo support HA for DVR SNAT, default SNAT has to be schedulable\non multiple L3 agents. The csnat_l3_agent_bindings table is being\nmodified to include l3_agent_id in the primary key.\nThe migration script and Class definition update is included in\nthis patch. For modularity and code management, HA/DVR methods\nthat would make use of this change will be included in a different\npatch.\n\nPartial-bug: #1365473\nChange-Id: Idfe93cace0c1b633be6e786206fbec6e1f3c13cd\n'}, {'number': 4, 'created': '2015-01-06 15:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8b19da0429e7b45a10974c657bf9e7025306ea2', 'message': 'HA for DVR - schema migration and change\n\nTo support HA for DVR SNAT, default SNAT has to be schedulable\non multiple L3 agents. The csnat_l3_agent_bindings table is being\nmodified to include l3_agent_id in the primary key.\nThe migration script and Class definition update is included in\nthis patch. For modularity and code management, HA/DVR methods\nthat would make use of this change will be included in a different\npatch.\n\nPartial-bug: #1365473\nChange-Id: Idfe93cace0c1b633be6e786206fbec6e1f3c13cd\n'}, {'number': 5, 'created': '2015-01-06 22:55:27.000000000', 'files': ['neutron/db/l3_dvrscheduler_db.py', 'neutron/db/migration/alembic_migrations/versions/41662e32bce2_l3_dvr_snat_mapping.py', 'neutron/db/migration/alembic_migrations/versions/HEAD'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ee81d35fc269863f1fe08c57f3672fdc48197cf', 'message': 'HA for DVR - schema migration and change\n\nTo support HA for DVR SNAT, default SNAT has to be schedulable\non multiple L3 agents. The csnat_l3_agent_bindings table is being\nmodified to include l3_agent_id in the primary key.\nThe migration script and Class definition update is included in\nthis patch. For modularity and code management, HA/DVR methods\nthat would make use of this change will be included in a different\npatch.\n\nPartial-bug: #1365473\nChange-Id: Idfe93cace0c1b633be6e786206fbec6e1f3c13cd\n'}]",11,143719,6ee81d35fc269863f1fe08c57f3672fdc48197cf,107,27,5,9077,,,0,"HA for DVR - schema migration and change

To support HA for DVR SNAT, default SNAT has to be schedulable
on multiple L3 agents. The csnat_l3_agent_bindings table is being
modified to include l3_agent_id in the primary key.
The migration script and Class definition update is included in
this patch. For modularity and code management, HA/DVR methods
that would make use of this change will be included in a different
patch.

Partial-bug: #1365473
Change-Id: Idfe93cace0c1b633be6e786206fbec6e1f3c13cd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/143719/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_dvrscheduler_db.py', 'neutron/db/migration/alembic_migrations/versions/41662e32bce2_l3_dvr_snat_mapping.py', 'neutron/db/migration/alembic_migrations/versions/HEAD']",3,8fbbcce47d01eb72b93b88028721322d873499b3,HA_migrate,41662e32bce2,57086602ca0a,68,2
openstack%2Fopenstack-ansible~master~I0c167a168838600551dad1cab77ad15956b12b96,openstack/openstack-ansible,master,I0c167a168838600551dad1cab77ad15956b12b96,Add socat to galera package list,MERGED,2015-01-07 08:50:02.000000000,2015-01-07 13:52:19.000000000,2015-01-07 13:52:19.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-07 08:50:02.000000000', 'files': ['rpc_deployment/vars/repo_packages/galera.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b24a69a8d435a257c785b11f8e064234967dde1a', 'message': 'Add socat to galera package list\n\nIt looks like socat is no longer being pulled in when installing\ngalera, and this is required for a cluster to sync.  Deploying a multi\nnode controller cluster currently fails without this change.\n\nCloses-Bug: #1408138\nChange-Id: I0c167a168838600551dad1cab77ad15956b12b96\n'}]",0,145432,b24a69a8d435a257c785b11f8e064234967dde1a,10,6,1,7307,,,0,"Add socat to galera package list

It looks like socat is no longer being pulled in when installing
galera, and this is required for a cluster to sync.  Deploying a multi
node controller cluster currently fails without this change.

Closes-Bug: #1408138
Change-Id: I0c167a168838600551dad1cab77ad15956b12b96
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/32/145432/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/vars/repo_packages/galera.yml'],1,b24a69a8d435a257c785b11f8e064234967dde1a,bug/1408138, - socat,,1,0
openstack%2Fgnocchi~master~I8ee00fa1462642b6beeee4499037088405c83a48,openstack/gnocchi,master,I8ee00fa1462642b6beeee4499037088405c83a48,Disallow linking resources and metrics from different users,MERGED,2014-12-30 12:05:23.000000000,2015-01-07 13:52:13.000000000,2015-01-07 13:52:12.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-30 12:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7a67ec61d17182f1b5e6f26a592f9782eaa1d4ad', 'message': 'Disallow linking resources and metrics from different users\n\nThis patch implements user/project creator checking when linking\nresources and metrics together.\n\nChange-Id: I8ee00fa1462642b6beeee4499037088405c83a48\n'}, {'number': 2, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/2ac1e762480ecea14749b72eba8fb12c3592b4e5', 'message': 'Disallow linking resources and metrics from different users\n\nThis patch implements user/project creator checking when linking\nresources and metrics together.\n\nChange-Id: I8ee00fa1462642b6beeee4499037088405c83a48\n'}, {'number': 3, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9585c163174c6f645c25e30184420202261c70df', 'message': 'Disallow linking resources and metrics from different users\n\nThis patch implements user/project creator checking when linking\nresources and metrics together.\n\nChange-Id: I8ee00fa1462642b6beeee4499037088405c83a48\n'}]",0,144445,9585c163174c6f645c25e30184420202261c70df,15,3,3,1669,,,0,"Disallow linking resources and metrics from different users

This patch implements user/project creator checking when linking
resources and metrics together.

Change-Id: I8ee00fa1462642b6beeee4499037088405c83a48
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/45/144445/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_rest.py']",2,7a67ec61d17182f1b5e6f26a592f9782eaa1d4ad,jd/statsd," def test_post_resource_with_metric_from_other_user(self): with self.app.use_another_user(): metric = self.app.post_json( ""/v1/metric"", params={'archive_policy': ""high""}) metric_id = json.loads(metric.text)['id'] self.attributes['metrics'] = {""foo"": metric_id} result = self.app.post_json( ""/v1/resource/"" + self.resource_type, params=self.attributes, status=400) self.assertIn(""Metric %s does not exist"" % metric_id, result.text) def test_post_append_metrics_created_by_different_user(self): self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes) with self.app.use_another_user(): metric = self.app.post_json( ""/v1/metric"", params={'archive_policy': ""high""}) metric_id = json.loads(metric.text)['id'] result = self.app.post_json(""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id'] + ""/metric"", params={str(uuid.uuid4()): metric_id}, status=400) self.assertIn(""Metric %s does not exist"" % metric_id, result.text) def test_patch_resource_existent_metrics_from_another_user(self): self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes) with self.app.use_another_user(): result = self.app.post_json(""/v1/metric"", params={'archive_policy': ""medium""}) metric_id = json.loads(result.text)['id'] result = self.app.patch_json( ""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id'], params={'metrics': {'foo': metric_id}}, status=400) self.assertIn(""Metric %s does not exist"" % metric_id, result.text) result = self.app.get(""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id']) result = json.loads(result.text) self.assertEqual(result['metrics'], {}) ",,63,5
openstack%2Fgnocchi~master~Id908f2d8e373d6aae621e6bea776ad0eeb3f6a40,openstack/gnocchi,master,Id908f2d8e373d6aae621e6bea776ad0eeb3f6a40,rest: allow to filter metrics listing by user/project,MERGED,2014-12-29 16:19:13.000000000,2015-01-07 13:51:02.000000000,2015-01-07 13:51:01.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-29 16:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/300e43f2c0e103353abda6794cf52dbaa351d197', 'message': 'rest: allow to filter metrics listing by user/project\n\nChange-Id: Id908f2d8e373d6aae621e6bea776ad0eeb3f6a40\n'}, {'number': 2, 'created': '2015-01-07 12:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/21db9b3d5addb28f1d031bf412683a97b3e14511', 'message': 'rest: allow to filter metrics listing by user/project\n\nChange-Id: Id908f2d8e373d6aae621e6bea776ad0eeb3f6a40\n'}, {'number': 3, 'created': '2015-01-07 13:10:28.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/fd54da1d334470fe31cc16292b105fc4e42141b6', 'message': 'rest: allow to filter metrics listing by user/project\n\nChange-Id: Id908f2d8e373d6aae621e6bea776ad0eeb3f6a40\n'}]",2,144323,fd54da1d334470fe31cc16292b105fc4e42141b6,13,3,3,1669,,,0,"rest: allow to filter metrics listing by user/project

Change-Id: Id908f2d8e373d6aae621e6bea776ad0eeb3f6a40
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/23/144323/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py']",2,300e43f2c0e103353abda6794cf52dbaa351d197,jd/statsd," result = self.app.get(""/v1/metric?user_id="" + FakeMemcache.USER_ID) self.assertIn(metric['id'], [r['id'] for r in json.loads(result.text)]) def test_list_metric_filter_as_admin(self): result = self.app.post_json( ""/v1/metric"", params={""archive_policy"": ""medium""}) metric = json.loads(result.text) with self.app.use_admin_user(): result = self.app.get(""/v1/metric?user_id="" + FakeMemcache.USER_ID) self.assertIn(metric['id'], [r['id'] for r in json.loads(result.text)]) def test_list_metric_invalid_user(self): result = self.app.get(""/v1/metric?user_id="" + FakeMemcache.USER_ID_2, status=400) self.assertIn(""Insufficient privileges to filter by user/project"", result.text)",,28,2
openstack%2Fsahara-specs~master~I14f85c03623e3830976b565c06c53751fc171baf,openstack/sahara-specs,master,I14f85c03623e3830976b565c06c53751fc171baf,Provide default templates for each plugin,MERGED,2014-12-11 21:49:13.000000000,2015-01-07 13:50:55.000000000,2015-01-07 13:50:54.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7244}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-12-11 21:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/cd481f2ead00537af25d7514f784093bd9fde833', 'message': 'Provide default templates for each plugin\n\nSpec for providing default templates that will be loaded\nat startup.  These templates provide the skeleton for\na basic cluster of each plugin to facilitate quicker launching\nof simple clusters.  Additionally, they can be used as a\nbase set of templates to tweak rapidly into something\nmore interesting.\n\nChange-Id: I14f85c03623e3830976b565c06c53751fc171baf\nPartial-Implements:  bp default-templates\n'}, {'number': 2, 'created': '2014-12-22 19:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/0c3a713bb25b3341d691e2897c2cf02fedb8623a', 'message': 'Provide default templates for each plugin\n\nSpec for providing default templates that will be loaded\nat startup.  These templates provide the skeleton for\na basic cluster of each plugin to facilitate quicker launching\nof simple clusters.  Additionally, they can be used as a\nbase set of templates to tweak rapidly into something\nmore interesting.\n\nChange-Id: I14f85c03623e3830976b565c06c53751fc171baf\nPartial-Implements:  bp default-templates\n'}, {'number': 3, 'created': '2015-01-02 15:51:27.000000000', 'files': ['specs/kilo/default-templates.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/02a551d41b395344d80fcd95d143939ce5107b26', 'message': 'Provide default templates for each plugin\n\nSpec for providing default templates that will be loaded\nat startup.  These templates provide the skeleton for\na basic cluster of each plugin to facilitate quicker launching\nof simple clusters.  Additionally, they can be used as a\nbase set of templates to tweak rapidly into something\nmore interesting.\n\nChange-Id: I14f85c03623e3830976b565c06c53751fc171baf\nPartial-Implements:  bp default-templates\n'}]",25,141178,02a551d41b395344d80fcd95d143939ce5107b26,22,6,3,8090,,,0,"Provide default templates for each plugin

Spec for providing default templates that will be loaded
at startup.  These templates provide the skeleton for
a basic cluster of each plugin to facilitate quicker launching
of simple clusters.  Additionally, they can be used as a
base set of templates to tweak rapidly into something
more interesting.

Change-Id: I14f85c03623e3830976b565c06c53751fc171baf
Partial-Implements:  bp default-templates
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/78/141178/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/default-templates.rst'],1,cd481f2ead00537af25d7514f784093bd9fde833,bp/default-templates,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== Include the URL of your launchpad blueprint: Sahara Service: https://blueprints.launchpad.net/sahara/+spec/default-templates In order to create a basic cluster for any plugin, a user currently has to go through several steps to create an appropriate set of node group and cluster templates. We believe that set of actions should be captured in a default set of templates (per plugin) and loaded into the database ahead of time so that users do not need to repeat some of the most basic steps to provision a simple cluster. Problem description =================== Creating even a basic cluster currently requires several steps before the user is able to launch their cluster. In an effort to reduce the amount of effort and time to get a simple cluster running, we propose a set of default templates for each plugin that will be pre-loaded and available for use. Other potential issues/answers: 1) How do we make the set of templates available for all users/tenants. Today, any given template is only read/writable by one tenant. 2) Do we allow editing of default templates? I don't think we should allow editing of the default templates since they are shared among all tenants. The flow to ""edit"" one would be to make a copy of the template and work from there. I propose that each template will be stored with a flag in the database that identifies each default template as being a default template so that we can enforce that users cannot change the default templates. 3) How do we avoid uploading the same default templates each time at startup while still allowing for them to be updated as necessary? We could use a numbering system in the template file names to indicate the version number and store that in the database (perhaps instead of a boolean flag indicating that the template is a default template, we could store an int that is the version number). At startup time, we would go through all of the template files for each plugin and compare the version numbers to the version numbers that are stored in the database. 4) How do we make a json default cluster template reference a json default node group template since we won't know the node group template IDs? Proposed change =============== 1) Create a set of default template json files for each plugin. I propose that they will exist in sahara/plugins/<plugin>/<version>/resources. The contents of each default template set will be 1 or more node group templates and a cluster template. 2) Add a hook, possibly in plugins/base:PluginManager for ""load_default_templates"". This method would be responsible for triggering the loading of the defaults at startup time. Alternatives ------------ The loading process could be done via the REST API if we wanted to have some sort of external process that manages the default templates. That might require changing the API a bit to add endpoints for managing the default templates and seems like a fair bit of unnecessary work since the management of default templates should be something done only within Sahara. Data model impact ----------------- The node group template and cluster template tables will be changed to add a new column for the ""is_default"" flag. Both of these updates would be done in a single migration. Since it's just adding an optional column, all existing templates will not be changed other than having this column added. The default value will be blank. REST API impact --------------- N/A Other end user impact --------------------- End users will see the default templates show up just like any other template that they may have created. Deployer impact --------------- N/A Developer impact ---------------- N/A Sahara-image-elements impact ---------------------------- N/A Horizon impact -------------- N/A The default templates will show-up in the UI and look like regular templates. Implementation ============== Assignee(s) ----------- Primary assignee: croberts Secondary assignee: tmckay Work Items ---------- 1) Come up with a set of default templates for each plugin. These will probably be json formatted files. 2) Come up with some sort of mechanism to load the templates or ensure that they are already loaded when Sahara starts-up. 3) Update the Sahara documentation. Dependencies ============ N/A Testing ======= Ideally, tests will be added to ensure that a functioning cluster can be started based on each of the default template sets. If that is determined to be too time-consuming per-run, then tests to ensure the validity of each set of templates may be sufficient. Documentation Impact ==================== The Sahara documentation should be updated to note that the default templates are available for use. Additionally, any future plugins will be expected to provide their own set of default templates. References ========== N/A",,163,0
openstack%2Fanchor~master~I1894ea991ff279eca85092173f6b65f0425d1dc5,openstack/anchor,master,I1894ea991ff279eca85092173f6b65f0425d1dc5,Making anchor use pyca/cryptography,MERGED,2014-12-17 15:42:33.000000000,2015-01-07 13:35:33.000000000,2015-01-07 13:35:33.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-12-17 15:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/61f2c93c8bc8b6c88d14a8d802436a6e7a329e45', 'message': 'Making anchor use pyca/cryptography\n\n- lots of changes required to move away from M2Crypto\n- line wrapping and other formatting changes included\n- lots of X509 related stuff added making use of pyca\n  low level bindings to OpenSSL\n\n- This change requires pyca/cryptography 0.7\n\nChange-Id: I1894ea991ff279eca85092173f6b65f0425d1dc5\n'}, {'number': 2, 'created': '2015-01-07 10:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/5b9be26ac70f23ec5c18e15775914b4724270e79', 'message': 'Making anchor use pyca/cryptography\n\n- lots of changes required to move away from M2Crypto\n- line wrapping and other formatting changes included\n- lots of X509 related stuff added making use of pyca\n  low level bindings to OpenSSL\n\n- This change requires pyca/cryptography 0.7\n\nChange-Id: I1894ea991ff279eca85092173f6b65f0425d1dc5\n'}, {'number': 3, 'created': '2015-01-07 11:44:44.000000000', 'files': ['anchor/X509/__init__.py', 'anchor/X509/certificate.py', 'anchor/auth/__init__.py', 'anchor/certificate_ops.py', 'anchor/X509/signing_request.py', 'anchor/X509/name.py', 'anchor/X509/message_digest.py', 'anchor/validators.py', 'anchor/X509/utils.py', 'anchor/X509/errors.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/8b35b345427060614e7f0c9dd0035c57769afa3f', 'message': 'Making anchor use pyca/cryptography\n\n- lots of changes required to move away from M2Crypto\n- line wrapping and other formatting changes included\n- lots of X509 related stuff added making use of pyca\n  low level bindings to OpenSSL\n\n- This change requires pyca/cryptography 0.7\n\nChange-Id: I1894ea991ff279eca85092173f6b65f0425d1dc5\n'}]",2,142470,8b35b345427060614e7f0c9dd0035c57769afa3f,15,4,3,11716,,,0,"Making anchor use pyca/cryptography

- lots of changes required to move away from M2Crypto
- line wrapping and other formatting changes included
- lots of X509 related stuff added making use of pyca
  low level bindings to OpenSSL

- This change requires pyca/cryptography 0.7

Change-Id: I1894ea991ff279eca85092173f6b65f0425d1dc5
",git fetch https://review.opendev.org/openstack/anchor refs/changes/70/142470/1 && git format-patch -1 --stdout FETCH_HEAD,"['anchor/auth/__init__.py', 'anchor/certificate_ops.py', 'anchor/X509.py', 'anchor/validators.py', 'anchor/message_digest.py']",5,61f2c93c8bc8b6c88d14a8d802436a6e7a329e45,cryptography,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from cryptography.hazmat.backends.openssl import backend class MessageDigestError(Exception): def __init__(self, what): super(MessageDigestError, self).__init__(what) class MessageDigest(object): def __init__(self, algo): self._lib = backend._lib self._ffi = backend._ffi md = getattr(self._lib, ""EVP_%s"" % algo, None) if md is None: msg = 'MessageDigest error: unknown algorithm {a}'.format(a=algo) raise MessageDigestError(msg) ret = 0 ctx = self._lib.EVP_MD_CTX_create() if ctx != self._ffi.NULL: self.ctx = ctx self.mda = md() ret = self._lib.EVP_DigestInit_ex(self.ctx, self.mda, self._ffi.NULL) if ret == 0: raise MessageDigestError(""Could not setup message digest context."") def __del__(self): if getattr(self, 'ctx', None): self._lib.EVP_MD_CTX_cleanup(self.ctx) self._lib.EVP_MD_CTX_destroy(self.ctx) def _octx_to_num(self, x): v = 0L lx = len(x) for i in range(lx): v = v + ord(x[i]) * (256L ** (lx-i-1)) return v def update(self, data): ret = self._lib.EVP_DigestUpdate(self.ctx, data, len(data)) if ret == 0: raise MessageDigestError(""Failed to update message digest data."") def final(self): sz = self._lib.EVP_MD_size(self.mda) data = self._ffi.new(""char[]"", sz) ret = self._lib.EVP_DigestFinal_ex(self.ctx, data, self._ffi.NULL) if ret == 0: raise MessageDigestError(""Failed to get message digest."") return self._ffi.string(data) ",,555,58
openstack%2Fgnocchi~master~I84550874ec70f2b93f111c1bc2b11a2d51eb1e38,openstack/gnocchi,master,I84550874ec70f2b93f111c1bc2b11a2d51eb1e38,Update oslo-incubator,MERGED,2014-12-26 10:41:19.000000000,2015-01-07 13:16:29.000000000,2015-01-07 13:16:27.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-26 10:41:19.000000000', 'files': ['gnocchi/openstack/common/_i18n.py', 'gnocchi/openstack/common/log.py', 'gnocchi/openstack/common/policy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/59d0b64c44c7f2d1b3b27cc3c5614851e2d43a13', 'message': 'Update oslo-incubator\n\nTo commit cbd3b358a7ccfb33ce6eca56a182d8b1288debb7\n\nChange-Id: I84550874ec70f2b93f111c1bc2b11a2d51eb1e38\n'}]",0,144115,59d0b64c44c7f2d1b3b27cc3c5614851e2d43a13,16,3,1,1669,,,0,"Update oslo-incubator

To commit cbd3b358a7ccfb33ce6eca56a182d8b1288debb7

Change-Id: I84550874ec70f2b93f111c1bc2b11a2d51eb1e38
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/15/144115/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/openstack/common/_i18n.py', 'gnocchi/openstack/common/log.py', 'gnocchi/openstack/common/policy.py']",3,59d0b64c44c7f2d1b3b27cc3c5614851e2d43a13,jd/update-oslo,"# -*- coding: utf-8 -*- #combined as with an ""or"" conjunction. As an example, take the following rule, expressed in the list-of-lists representation::This is the original way of expressing policies, but there now exists a new way: the policy language. In the policy language, each check is specified the same way as in the list-of-lists representation: a simple ""a:b"" pair that is matched to the correct class to perform that check:: +===========================================================================+ | TYPE | SYNTAX | +===========================================================================+ |User's Role | role:admin | +---------------------------------------------------------------------------+ |Rules already defined on policy | rule:admin_required | +---------------------------------------------------------------------------+ |Against URL's¹ | http://my-url.org/check | +---------------------------------------------------------------------------+ |User attributes² | project_id:%(target.project.id)s | +---------------------------------------------------------------------------+ |Strings | <variable>:'xpto2035abc' | | | 'myproject':<variable> | +---------------------------------------------------------------------------+ | | project_id:xpto2035abc | |Literals | domain_id:20 | | | True:%(user.enabled)s | +===========================================================================+ ¹URL checking must return 'True' to be valid ²User attributes (obtained through the token): user_id, domain_id or project_id Conjunction operators are available, allowing for more expressiveness in crafting policies. So, in the policy language, the previous check in list-of-lists becomes:: <some_value>:%(user.id)s <some_value>:%(target.role.name)simport copyfrom gnocchi.openstack.common._i18n import _, _LE, _LI 'stored. They can be relative to any directory ' 'in the search path defined by the config_dir ' 'option, or absolute paths. The file defined by ' 'policy_file must exist for these directories to ' 'be searched.')),def list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(policy_opts))] :param overwrite: Whether to overwrite existing rules when reload rules from config file. default_rule=None, use_conf=True, overwrite=True): self.overwrite = overwrite :param force_reload: Whether to reload rules from config file. self._load_policy_file(self.policy_path, force_reload, overwrite=self.overwrite) LOG.info(_LI(""Can not find policy directory: %s""), path) @staticmethod def _walk_through_policy_directory(path, func, *args): if reloaded or not self.rules or not overwrite: self.set_rules(rules, overwrite=overwrite, use_conf=True) # Convert instances of object() in target temporarily to # empty dict to avoid circular reference detection # errors in jsonutils.dumps(). temp_target = copy.deepcopy(target) for key in target.keys(): element = target.get(key) if type(element) is object: temp_target[key] = {} data = {'target': jsonutils.dumps(temp_target),","combined as with an ""or"" conjunction. This is the original way of expressing policies, but there now exists a new way: the policy language. In the policy language, each check is specified the same way as in the list-of-lists representation: a simple ""a:b"" pair that is matched to the correct code to perform that check. However, conjunction operators are available, allowing for more expressiveness in crafting policies. As an example, take the following rule, expressed in the list-of-lists representation::In the policy language, this becomes::It is possible to perform policy checks on the following user attributes (obtained through the token): user_id, domain_id or project_id:: domain_id:<some_value> <some_value>:user.id <some_value>:target.role.name All these attributes (related to users, API calls, and context) can be checked against each other or against constants, be it literals (True, <a_number>) or strings.from gnocchi.openstack.common._i18n import _, _LE, _LW 'stored.')), default_rule=None, use_conf=True): :param force_reload: Whether to overwrite current rules. self._load_policy_file(self.policy_path, force_reload) LOG.warn(_LW(""Can not find policy directory: %s""), path) def _walk_through_policy_directory(self, path, func, *args): if reloaded or not self.rules: self.set_rules(rules, overwrite) data = {'target': jsonutils.dumps(target),",112,56
openstack%2Fzaqar~master~I8716a718265230b5ce022daabec6484769e42467,openstack/zaqar,master,I8716a718265230b5ce022daabec6484769e42467,Version discovery for root URI,MERGED,2014-10-22 02:14:28.000000000,2015-01-07 13:12:14.000000000,2015-01-07 13:12:13.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 7488}, {'_account_id': 10634}]","[{'number': 1, 'created': '2014-10-22 02:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fe896cb136eff2c9c139865c917be3136f714e66', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}, {'number': 2, 'created': '2014-10-28 13:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fd21f92cd7d411aef067d91c714453b12fe1f757', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}, {'number': 3, 'created': '2014-11-18 03:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0efcf679e8cecf46f5824e55a85c95ed6f4cffdb', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}, {'number': 4, 'created': '2014-12-11 07:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d02a775690cf4faa94f870927969943ab102d90a', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}, {'number': 5, 'created': '2014-12-15 09:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0f08af234169f9a479598b2ee27fd188ff43b342', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}, {'number': 6, 'created': '2015-01-05 15:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1a9441d4e1e25bee10192032a53ff18aef116f6d', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}, {'number': 7, 'created': '2015-01-07 03:39:43.000000000', 'files': ['tests/functional/wsgi/test_version.py', 'zaqar/transport/wsgi/driver.py', 'zaqar/transport/wsgi/version.py', 'zaqar/transport/wsgi/v1_0/__init__.py', 'zaqar/transport/wsgi/v1_1/__init__.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c08ff747ada45dbd260e6a87ac55ffb5faf596f9', 'message': 'Version discovery for root URI\n\nVersion discovery is now available by accessing the root URI path\n\nImplements: blueprint api-version-discovery\nChange-Id: I8716a718265230b5ce022daabec6484769e42467\n'}]",19,130094,c08ff747ada45dbd260e6a87ac55ffb5faf596f9,33,6,7,7488,,,0,"Version discovery for root URI

Version discovery is now available by accessing the root URI path

Implements: blueprint api-version-discovery
Change-Id: I8716a718265230b5ce022daabec6484769e42467
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/94/130094/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/functional/wsgi/test_version.py', 'zaqar/queues/transport/wsgi/version.py', 'zaqar/queues/transport/wsgi/driver.py']",3,fe896cb136eff2c9c139865c917be3136f714e66,bp/api-version-discovery,"from zaqar.queues.transport.wsgi import version ('/', [('', version.Resource())])",,140,0
openstack%2Fopenstack-manuals~master~If05700c6155f38b50d85ac7c4ab51e91bf005f8f,openstack/openstack-manuals,master,If05700c6155f38b50d85ac7c4ab51e91bf005f8f,Remove deprecated note in doc-tools-check-languages.conf,MERGED,2015-01-07 09:47:19.000000000,2015-01-07 13:11:07.000000000,2015-01-07 13:11:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-07 09:47:19.000000000', 'files': ['doc-tools-check-languages.conf'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/49d4d9c09de6614f458d1f06c05ecfb4cca24b68', 'message': 'Remove deprecated note in doc-tools-check-languages.conf\n\nChange-Id: If05700c6155f38b50d85ac7c4ab51e91bf005f8f\n'}]",0,145451,49d4d9c09de6614f458d1f06c05ecfb4cca24b68,6,2,1,167,,,0,"Remove deprecated note in doc-tools-check-languages.conf

Change-Id: If05700c6155f38b50d85ac7c4ab51e91bf005f8f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/145451/1 && git format-patch -1 --stdout FETCH_HEAD,['doc-tools-check-languages.conf'],1,49d4d9c09de6614f458d1f06c05ecfb4cca24b68,remove_deprecated_note,,# Example configuration for the languages 'ja' and 'fr'. ,0,2
openstack%2Fdjango_openstack_auth~master~If6a7f489058c80c969975dc0658e6f2ae979eca3,openstack/django_openstack_auth,master,If6a7f489058c80c969975dc0658e6f2ae979eca3,add last_activity to session,MERGED,2014-12-18 11:56:19.000000000,2015-01-07 13:10:50.000000000,2015-01-07 13:10:49.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6650}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-12-18 11:56:19.000000000', 'files': ['openstack_auth/views.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/336d7a531d8fb422e3b86a46b865339b3a321902', 'message': 'add last_activity to session\n\nActually, the fix for CVE-2014-8124 included a regression, resulting\nusers had to log in a second time, after being logged out due to\ninactivity.\n\nChange-Id: If6a7f489058c80c969975dc0658e6f2ae979eca3\nCloses-Bug: 1403037\n'}]",0,142737,336d7a531d8fb422e3b86a46b865339b3a321902,17,6,1,4264,,,0,"add last_activity to session

Actually, the fix for CVE-2014-8124 included a regression, resulting
users had to log in a second time, after being logged out due to
inactivity.

Change-Id: If6a7f489058c80c969975dc0658e6f2ae979eca3
Closes-Bug: 1403037
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/37/142737/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/views.py'],1,336d7a531d8fb422e3b86a46b865339b3a321902,bug/1403037,import time request.session['last_activity'] = int(time.time()),,2,0
openstack%2Fmagnum~master~Ibf71853e2468ff95d4055be09cb0b460be28a3db,openstack/magnum,master,Ibf71853e2468ff95d4055be09cb0b460be28a3db,Add unit tests for dbapi of Node and Container,MERGED,2015-01-06 03:16:08.000000000,2015-01-07 13:09:32.000000000,2015-01-07 13:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-06 03:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/dbcec657cc5beb049df4287716a2f032085f4f29', 'message': ""Add unit tests for dbapi of Node and Container\n\nDo the following fixes to pass the tests:\n* Add unique constraint to 'ironic_node_id'.\n* Throw an exception on deleting a non-existent Node or Container.\n* Throw an exception on associating an ironic node to an already\n  associated magnum node.\n* Throw an exception on associating an already associated ironic\n  node to a magnum node.\n* Fix the methods _add_containers_filters and _add_nodes_filters.\n\nChange-Id: Ibf71853e2468ff95d4055be09cb0b460be28a3db\n""}, {'number': 2, 'created': '2015-01-06 04:30:05.000000000', 'files': ['magnum/db/sqlalchemy/api.py', 'magnum/tests/db/utils.py', 'magnum/tests/db/test_node.py', 'magnum/tests/db/test_container.py', 'magnum/db/sqlalchemy/models.py', 'tox.ini', 'magnum/common/exception.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/2cf34a243a4a6295f58c2523cecd2f770495bcab', 'message': ""Add unit tests for dbapi of Node and Container\n\nDo the following fixes to pass the tests:\n* Add unique constraint to 'ironic_node_id'.\n* Throw an exception on deleting a non-existent Node or Container.\n* Throw an exception on associating an ironic node to an already\n  associated magnum node.\n* Throw an exception on associating an already associated ironic\n  node to a magnum node.\n* Fix the methods _add_containers_filters and _add_nodes_filters.\n\nChange-Id: Ibf71853e2468ff95d4055be09cb0b460be28a3db\n""}]",5,145121,2cf34a243a4a6295f58c2523cecd2f770495bcab,15,6,2,11536,,,0,"Add unit tests for dbapi of Node and Container

Do the following fixes to pass the tests:
* Add unique constraint to 'ironic_node_id'.
* Throw an exception on deleting a non-existent Node or Container.
* Throw an exception on associating an ironic node to an already
  associated magnum node.
* Throw an exception on associating an already associated ironic
  node to a magnum node.
* Fix the methods _add_containers_filters and _add_nodes_filters.

Change-Id: Ibf71853e2468ff95d4055be09cb0b460be28a3db
",git fetch https://review.opendev.org/openstack/magnum refs/changes/21/145121/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/db/sqlalchemy/api.py', 'magnum/tests/db/utils.py', 'magnum/tests/db/test_node.py', 'magnum/tests/db/test_container.py', 'magnum/db/sqlalchemy/models.py', 'tox.ini', 'magnum/common/exception.py']",7,dbcec657cc5beb049df4287716a2f032085f4f29,bp/increase-test-coverage," message = _(""A container with UUID %(uuid)s already exists."")"," message = _(""A node with UUID %(uuid)s already exists."")",429,52
openstack%2Fswift~master~I805c7c200107e2d56278f0fb35692a51cb1edc0b,openstack/swift,master,I805c7c200107e2d56278f0fb35692a51cb1edc0b,Avoid unnecessary unlink() on every successful PUT,MERGED,2014-12-25 09:13:00.000000000,2015-01-07 12:57:49.000000000,2015-01-07 12:57:47.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8542}, {'_account_id': 9625}, {'_account_id': 10206}, {'_account_id': 13777}]","[{'number': 1, 'created': '2014-12-25 09:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f079bd0cfaf466029377b9ffc9a2efcad51d56e7', 'message': ""Avoid unnecessary unlink() on every successful PUT\n\nIf you do a strace on object-server PUT operation, you'd see that\nthere's an unlink() sys call which _always_ fails with ENOENT.\n\nmkstemp() creates a temp file which is renamed later to it's final\nobject path in filsystem. Hence, on a successful object PUT, the\ntempfile would never exist in its original location after rename.\n\nChange-Id: I805c7c200107e2d56278f0fb35692a51cb1edc0b\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}, {'number': 2, 'created': '2014-12-30 07:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/266fb4e17686a9197334de1ad252eb2656762366', 'message': ""Avoid unnecessary unlink() on every successful PUT\n\nIf you do a strace on object-server PUT operation, you'd see that\nthere's an unlink() sys call which _always_ fails with ENOENT.\n\nmkstemp() creates a temp file which is renamed later to it's final\nobject path in filesystem. Hence, on a successful object PUT, the\ntempfile would never exist in its original location after rename.\n\nChange-Id: I805c7c200107e2d56278f0fb35692a51cb1edc0b\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}, {'number': 3, 'created': '2015-01-06 09:09:28.000000000', 'files': ['test/unit/obj/test_diskfile.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/42c790d04b85e2d2665da7c13f800d03b263a22f', 'message': ""Avoid unnecessary unlink() on every successful PUT\n\nIf you do a strace on object-server PUT operation, you'd see that\nthere's an unlink() sys call which _always_ fails with ENOENT.\n\nmkstemp() creates a temp file which is renamed later to it's final\nobject path in filesystem. Hence, on a successful object PUT, the\ntempfile would never exist in its original location after rename.\n\nChange-Id: I805c7c200107e2d56278f0fb35692a51cb1edc0b\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n""}]",11,143943,42c790d04b85e2d2665da7c13f800d03b263a22f,25,11,3,8542,,,0,"Avoid unnecessary unlink() on every successful PUT

If you do a strace on object-server PUT operation, you'd see that
there's an unlink() sys call which _always_ fails with ENOENT.

mkstemp() creates a temp file which is renamed later to it's final
object path in filesystem. Hence, on a successful object PUT, the
tempfile would never exist in its original location after rename.

Change-Id: I805c7c200107e2d56278f0fb35692a51cb1edc0b
Signed-off-by: Prashanth Pai <ppai@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/143943/3 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/diskfile.py'],1,f079bd0cfaf466029377b9ffc9a2efcad51d56e7,avoid-unlink," (key or ''))) # If put is successful, avoid unnecessary os.unlink() of tempfile # later as the rename would have succeeded. Hence, the tempfile # wouldn't exist at its original location. self._tmppath = None dfw = None dfw = DiskFileWriter(self._name, self._datadir, fd, tmppath, yield dfw if (dfw is None) or dfw._tmppath: # Try removing the temp file only if: # * the rename was _not_ successful or # * fallocate() failed before DiskFileWriter got instantiated. # # dfw._tmppath is set to None in DiskFileWriter.put() # after a successful rename. try: os.unlink(tmppath) except OSError: pass"," (key or ''))) yield DiskFileWriter(self._name, self._datadir, fd, tmppath, try: os.unlink(tmppath) except OSError: pass",19,6
openstack%2Ftooz~master~I205ed88c72587d9f5f916d344c44192bee2aa41a,openstack/tooz,master,I205ed88c72587d9f5f916d344c44192bee2aa41a,Add support for an optional redis-sentinel,MERGED,2015-01-05 14:51:55.000000000,2015-01-07 12:55:51.000000000,2015-01-07 12:55:51.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-01-05 14:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/6717b6114a85896a586421391895ff69f9988f7e', 'message': 'Add support for an optional redis-sentinel\n\nIf sentinel support is desired then the connection URI should take\nthe form:\n\n   redis://<sentinel host>:<sentinel port>?sentinel=<master name>\n\nThis will be parsed to connect to a Sentinel server to discover a\nmaster. The response will be used to make a connection to the\ncurrent master.\n\nChange-Id: I205ed88c72587d9f5f916d344c44192bee2aa41a\n'}, {'number': 2, 'created': '2015-01-05 15:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/382c56c46479d44ccc69aa05169a5459113da29f', 'message': 'Add support for an optional redis-sentinel\n\nIf sentinel support is desired then the connection URI should take\nthe form:\n\n   redis://<sentinel host>:<sentinel port>?sentinel=<master name>\n\nThis will be parsed to connect to a Sentinel server to discover a\nmaster. The response will be used to make a connection to the\ncurrent master.\n\nThe setup-sentinel-env.sh script will exit with an error if either\nthe redis-server or sentinel cannot be found. When the script is\ndone it will clean up the mess it makes.\n\nChange-Id: I205ed88c72587d9f5f916d344c44192bee2aa41a\n'}, {'number': 3, 'created': '2015-01-07 11:17:24.000000000', 'files': ['doc/source/drivers.rst', 'setup-sentinel-env.sh', 'tox.ini', 'tooz/drivers/redis.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/a2216e383e78b08324e5f873a35376b57cf29d3f', 'message': 'Add support for an optional redis-sentinel\n\nIf sentinel support is desired then the connection URI should take\nthe form:\n\n   redis://<sentinel host>:<sentinel port>?sentinel=<master name>\n\nThis will be parsed to connect to a Sentinel server to discover a\nmaster. The response will be used to make a connection to the\ncurrent master.\n\nThe setup-sentinel-env.sh script will exit with an error if either\nthe redis-server or sentinel cannot be found. When the script is\ndone it will clean up the mess it makes.\n\nChange-Id: I205ed88c72587d9f5f916d344c44192bee2aa41a\n'}]",8,144999,a2216e383e78b08324e5f873a35376b57cf29d3f,23,7,3,11564,,,0,"Add support for an optional redis-sentinel

If sentinel support is desired then the connection URI should take
the form:

   redis://<sentinel host>:<sentinel port>?sentinel=<master name>

This will be parsed to connect to a Sentinel server to discover a
master. The response will be used to make a connection to the
current master.

The setup-sentinel-env.sh script will exit with an error if either
the redis-server or sentinel cannot be found. When the script is
done it will clean up the mess it makes.

Change-Id: I205ed88c72587d9f5f916d344c44192bee2aa41a
",git fetch https://review.opendev.org/openstack/tooz refs/changes/99/144999/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/drivers.rst', 'setup-sentinel-env.sh', 'tox.ini', 'tooz/drivers/redis.py']",4,6717b6114a85896a586421391895ff69f9988f7e,cd/redis-sentinel-support,"from redis import sentinel To use a sentinel the connection URI must point to the Sentinel server. At connection time the sentinel will be asked for the current IP and port of the master and then connect there. The connection URI for sentinel should be written as follows:: redis://<sentinel host>:<sentinel port>?sentinel=<master name> 'sentinel', # Ask the sentinel for the current master if there is a # sentinel arg. if 'sentinel' in kwargs: sentinel_server = sentinel.Sentinel( [(kwargs['host'], kwargs['port'])], socket_timeout=kwargs['socket_timeout']) master_host, master_port = sentinel_server.discover_master( kwargs['sentinel']) kwargs['host'] = master_host kwargs['port'] = master_port del kwargs['sentinel']",,74,4
openstack%2Fnova~master~Ie8f149b069950b238bb7d2fbea09543116b3f603,openstack/nova,master,Ie8f149b069950b238bb7d2fbea09543116b3f603,Change host to host_name in show host output,ABANDONED,2015-01-05 14:38:54.000000000,2015-01-07 12:49:27.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-05 14:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e5f8a4225ac0b76ada2719ea0fc77f9a9a610dc', 'message': 'Change host to host_name in show host output\n\nWhen doing a list with the os-host extension the host name attribute\nis host_name in all other cases the host name attribute is host.\nE.g. when doing a list operation a result like this is expected:\n\n{""hosts"": [\n  {""zone"": ""internal"", ""host_name"": ""awesome-node1"", ""service"": ""compute""}]}\n\nWhen doing a describe of the same host:\n\n{""host"": [{""resource"": {""project"": ""(total)"", ""memory_mb"": 193278,\n""host"": ""awesome-node1"", ""cpu"": 48, ""disk_gb"": 98}},\n\nThis patch only update V3 API by using microversion.\n\nAPIImpact\n\nCloses-Bug: #1390498\nPartially implements blueprint api-microversions\n\nChange-Id: Ie8f149b069950b238bb7d2fbea09543116b3f603\n'}, {'number': 2, 'created': '2015-01-05 14:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f001316071ced169f417debd2627054dc8ba3bbb', 'message': 'Change host to host_name in show host output\n\nWhen doing a list with the os-host extension the host name attribute\nis host_name in all other cases the host name attribute is host.\nE.g. when doing a list operation a result like this is expected:\n\n{""hosts"": [\n  {""zone"": ""internal"", ""host_name"": ""awesome-node1"", ""service"": ""compute""}]}\n\nWhen doing a describe of the same host:\n\n{""host"": [{""resource"": {""project"": ""(total)"", ""memory_mb"": 193278,\n""host"": ""awesome-node1"", ""cpu"": 48, ""disk_gb"": 98}},\n\nThis patch only update V3 API by using microversion.\n\nAPIImpact\n\nCloses-Bug: #1390498\nPartially implements blueprint api-microversions\n\nChange-Id: Ie8f149b069950b238bb7d2fbea09543116b3f603\n'}, {'number': 3, 'created': '2015-01-06 06:37:59.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hosts.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/rest_api_version_history.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/ed8dae4ec63031260fc617a672ac5a783977b136', 'message': 'Change host to host_name in show host output\n\nWhen doing a list with the os-host extension the host name attribute\nis host_name in all other cases the host name attribute is host.\nE.g. when doing a list operation a result like this is expected:\n\n{""hosts"": [\n  {""zone"": ""internal"", ""host_name"": ""awesome-node1"", ""service"": ""compute""}]}\n\nWhen doing a describe of the same host:\n\n{""host"": [{""resource"": {""project"": ""(total)"", ""memory_mb"": 193278,\n""host"": ""awesome-node1"", ""cpu"": 48, ""disk_gb"": 98}},\n\nThis patch only update V3 API by using microversion.\n\nAPIImpact\n\nCloses-Bug: #1390498\nPartially implements blueprint api-microversions\n\nChange-Id: Ie8f149b069950b238bb7d2fbea09543116b3f603\n'}]",0,144995,ed8dae4ec63031260fc617a672ac5a783977b136,19,9,3,6062,,,0,"Change host to host_name in show host output

When doing a list with the os-host extension the host name attribute
is host_name in all other cases the host name attribute is host.
E.g. when doing a list operation a result like this is expected:

{""hosts"": [
  {""zone"": ""internal"", ""host_name"": ""awesome-node1"", ""service"": ""compute""}]}

When doing a describe of the same host:

{""host"": [{""resource"": {""project"": ""(total)"", ""memory_mb"": 193278,
""host"": ""awesome-node1"", ""cpu"": 48, ""disk_gb"": 98}},

This patch only update V3 API by using microversion.

APIImpact

Closes-Bug: #1390498
Partially implements blueprint api-microversions

Change-Id: Ie8f149b069950b238bb7d2fbea09543116b3f603
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/144995/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hosts.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/rest_api_version_history.rst']",4,7e5f8a4225ac0b76ada2719ea0fc77f9a9a610dc,bp/api-microversions," - **2.2** According to bug 1390498, make the output of show hosts API /v2/{tenant_id}/os-hosts/{host_name} output from host: [ { ""resource"": { ... ""host"": ""5ca60c6792a1442f9471ff575443f94d"", ... } } to host: [ { ""resource"": { ... ""host_name"": ""5ca60c6792a1442f9471ff575443f94d"", ... } }",,80,23
openstack%2Fswift~master~I8f44f032caac25c44778a497dedf23f5cb61b6bb,openstack/swift,master,I8f44f032caac25c44778a497dedf23f5cb61b6bb,Only move too-close-together replicas when they can spread out.,MERGED,2014-12-11 00:37:48.000000000,2015-01-07 12:31:44.000000000,2015-01-07 12:31:42.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7848}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-11 00:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/51c4e94f2bad56122dfaed5db4326f1c00f0519d', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}, {'number': 2, 'created': '2014-12-12 19:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6ca31b7c8a05d73dac10d48caa582d5e6eb60a8e', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}, {'number': 3, 'created': '2014-12-18 01:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/616659bcd433946e56d4b0767a71bf0ff4f41947', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}, {'number': 4, 'created': '2014-12-19 22:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/056147ee559817cab8defa1b40ad45927ce8e3fb', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}, {'number': 5, 'created': '2014-12-30 19:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/733c25167933ca247d49a10151cd967ff5f1200c', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}, {'number': 6, 'created': '2015-01-05 22:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d80e26fe14fe6357de36da7fa0b4a57f62fd8a1b', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}, {'number': 7, 'created': '2015-01-06 18:28:25.000000000', 'files': ['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1880351f1a862ae434ab23701535628f6f9258e1', 'message': ""Only move too-close-together replicas when they can spread out.\n\nImagine a 3-zone ring, and consider a partition in that ring with\nreplicas placed as follows:\n\n* replica 0 is on device A (zone 2)\n* replica 1 is on device B (zone 1)\n* replica 2 is on device C (zone 2)\n\nFurther, imagine that there are zero parts_wanted in all of zone 3;\nthat is, zone 3 is completely full. However, zones 1 and 2 each have\nat least one parts_wanted on at least one device.\n\nWhen the ring builder goes to gather replicas to move, it gathers\nreplica 0 because there are three zones available, but the replicas\nare only in two of them. Then, it places replica 0 in zone 1 or 2\nsomewhere because those are the only zones with parts_wanted. Notice\nthat this does *not* do anything to spread the partition out better.\n\nThen, on the next rebalance, replica 0 gets picked up and moved\n(again) but doesn't improve its placement (again).\n\nIf your builder has min_part_hours > 0 (and it should), then replicas\n1 and 2 cannot move at all. A coworker observed the bug because a\ncustomer had such a partition, and its replica 2 was on a zero-weight\ndevice. He thought it odd that a zero-weight device should still have\none partition on it despite the ring having been rebalanced dozens of\ntimes.\n\nEven if you don't have zero-weight devices, having a bunch of\npartitions trade places on each rebalance isn't particularly good.\n\nNote that this only happens with an unbalanceable ring; if the ring\n*can* balance, the gathered partitions will swap places, but they will\nget spread across more zones, so they won't get gathered up again on\nthe next rebalance.\n\nChange-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb\nCloses-Bug: 1400083\n""}]",6,140879,1880351f1a862ae434ab23701535628f6f9258e1,39,9,7,2622,,,0,"Only move too-close-together replicas when they can spread out.

Imagine a 3-zone ring, and consider a partition in that ring with
replicas placed as follows:

* replica 0 is on device A (zone 2)
* replica 1 is on device B (zone 1)
* replica 2 is on device C (zone 2)

Further, imagine that there are zero parts_wanted in all of zone 3;
that is, zone 3 is completely full. However, zones 1 and 2 each have
at least one parts_wanted on at least one device.

When the ring builder goes to gather replicas to move, it gathers
replica 0 because there are three zones available, but the replicas
are only in two of them. Then, it places replica 0 in zone 1 or 2
somewhere because those are the only zones with parts_wanted. Notice
that this does *not* do anything to spread the partition out better.

Then, on the next rebalance, replica 0 gets picked up and moved
(again) but doesn't improve its placement (again).

If your builder has min_part_hours > 0 (and it should), then replicas
1 and 2 cannot move at all. A coworker observed the bug because a
customer had such a partition, and its replica 2 was on a zero-weight
device. He thought it odd that a zero-weight device should still have
one partition on it despite the ring having been rebalanced dozens of
times.

Even if you don't have zero-weight devices, having a bunch of
partitions trade places on each rebalance isn't particularly good.

Note that this only happens with an unbalanceable ring; if the ring
*can* balance, the gathered partitions will swap places, but they will
get spread across more zones, so they won't get gathered up again on
the next rebalance.

Change-Id: I8f44f032caac25c44778a497dedf23f5cb61b6bb
Closes-Bug: 1400083
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/140879/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/ring/builder.py', 'test/unit/common/ring/test_builder.py']",2,51c4e94f2bad56122dfaed5db4326f1c00f0519d,hershey-constant,"from array import array def test_remove_last_partition_from_zero_weight(self): rb = ring.RingBuilder(4, 3, 1) rb.add_dev({'id': 0, 'region': 0, 'zone': 1, 'weight': 1.0, 'ip': '127.0.0.1', 'port': 10000, 'device': 'sda'}) rb.add_dev({'id': 1, 'region': 0, 'zone': 2, 'weight': 2.0, 'ip': '127.0.0.2', 'port': 10000, 'device': 'sda'}) rb.add_dev({'id': 2, 'region': 0, 'zone': 3, 'weight': 3.0, 'ip': '127.0.0.3', 'port': 10000, 'device': 'sda'}) rb.add_dev({'id': 3, 'region': 0, 'zone': 3, 'weight': 0.5, 'ip': '127.0.0.3', 'port': 10001, 'device': 'zero'}) zero_weight_dev = 3 rb.rebalance() # We want at least one partition with replicas only in zone 2 and 3 # due to device weights. It would *like* to spread out into zone 1, # but can't, due to device weight. # # Also, we want such a partition to have a replica on device 3, # which we will then reduce to zero weight. This should cause the # removal of the replica from device 3. # # Getting this to happen by chance is hard, so let's just set up a # builder so that it's in the state we want. This is a synthetic # example; while the bug has happened on a real cluster, that # builder file had a part_power of 16, so its contents are much too # big to include here. rb._replica2part2dev = [ # these are the relevant ones # | | | | # v v v v array('H', [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), array('H', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]), array('H', [0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2, 2])] rb.set_dev_weight(zero_weight_dev, 0.0) rb.pretend_min_part_hours_passed() rb.rebalance(seed=1) node_counts = defaultdict(int) for part2dev_id in rb._replica2part2dev: for dev_id in part2dev_id: node_counts[dev_id] += 1 self.assertEqual(node_counts[zero_weight_dev], 0) ",,78,2
openstack%2Fsahara~master~I32682b1ecf951d0c6990e06325ef29fb30b3ca54,openstack/sahara,master,I32682b1ecf951d0c6990e06325ef29fb30b3ca54,Fixed topology parameters help in config,MERGED,2015-01-06 18:31:11.000000000,2015-01-07 12:31:28.000000000,2015-01-07 12:31:27.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-06 18:31:11.000000000', 'files': ['etc/sahara/sahara.conf.sample', 'sahara/topology/topology_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7b884b1455bff7011a74ee236c53532f9706afbe', 'message': 'Fixed topology parameters help in config\n\nThere is no way to make multi-line help for config parameters.\nOfficial documentation contains description of required format\nfor the files. Removing this information from config parameters\ndescription.\n\nChange-Id: I32682b1ecf951d0c6990e06325ef29fb30b3ca54\nCloses-Bug: #1407837\n'}]",0,145288,7b884b1455bff7011a74ee236c53532f9706afbe,9,4,1,8411,,,0,"Fixed topology parameters help in config

There is no way to make multi-line help for config parameters.
Official documentation contains description of required format
for the files. Removing this information from config parameters
description.

Change-Id: I32682b1ecf951d0c6990e06325ef29fb30b3ca54
Closes-Bug: #1407837
",git fetch https://review.opendev.org/openstack/sahara refs/changes/88/145288/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/sahara/sahara.conf.sample', 'sahara/topology/topology_helper.py']",2,7b884b1455bff7011a74ee236c53532f9706afbe,bug/1407837," help=""Enables data locality for hadoop cluster. "" ""Also enables data locality for Swift used by hadoop. "" ""If enabled, 'compute_topology' and 'swift_topology' "" ""configuration parameters should point to OpenStack and "" ""Swift topology correspondingly.""), help=""Enables four-level topology for data locality. "" ""Works only if corresponding plugin supports such mode.""), help=""File with nova compute topology. "" ""It should contain mapping between nova computes and "" ""racks.""), help=""File with Swift topology."" ""It should contain mapping between Swift nodes and "" ""racks."")"," help=""""""Enables data locality for hadoop cluster. Also enables data locality for Swift used by hadoop. If enabled, 'compute_topology' and 'swift_topology' configuration parameters should point to OpenStack and Swift topology correspondingly.""""""), help=""""""Enables four-level topology for data locality. Works only if corresponding plugin supports such mode.""""""), help=""""""File with nova compute topology. It should contain mapping between nova computes and racks. File format: compute1 /rack1 compute2 /rack2 compute3 /rack2""""""), help=""""""File with Swift topology. It should contain mapping between Swift nodes and racks. File format: node1 /rack1 node2 /rack2 node3 /rack2"""""")",23,34
openstack%2Fproject-config~master~Ie3a638fb8834dcdbbb829887a3f9295c739c2997,openstack/project-config,master,Ie3a638fb8834dcdbbb829887a3f9295c739c2997,Update tooz project config for sentinel support,MERGED,2015-01-06 13:04:05.000000000,2015-01-07 12:26:30.000000000,2015-01-07 12:26:29.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 1297}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6133}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 6928}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-01-06 13:04:05.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2921c281b606968ae3075dbb80f7f287327ebf5a', 'message': 'Update tooz project config for sentinel support\n\nAdditional tox environments are used to test redis-sentinel support\nin tooz, py{27,34}-sentinel, via setup-sentinel-env.sh.\n\nChange-Id: Ie3a638fb8834dcdbbb829887a3f9295c739c2997\n'}]",0,145220,2921c281b606968ae3075dbb80f7f287327ebf5a,12,19,1,11564,,,0,"Update tooz project config for sentinel support

Additional tox environments are used to test redis-sentinel support
in tooz, py{27,34}-sentinel, via setup-sentinel-env.sh.

Change-Id: Ie3a638fb8834dcdbbb829887a3f9295c739c2997
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/145220/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,2921c281b606968ae3075dbb80f7f287327ebf5a,cd/tooz-sentinel-support, - gate-tooz-tox-py27-sentinel - gate-tooz-tox-py34-sentinel - gate-tooz-tox-py27-sentinel - gate-tooz-tox-py34-sentinel,,6,0
openstack%2Fsecurity-doc~master~I410e9c667e4350bcd1a7b1b999ea79a77f0a41f2,openstack/security-doc,master,I410e9c667e4350bcd1a7b1b999ea79a77f0a41f2,Imported Translations from Transifex,MERGED,2015-01-07 06:01:13.000000000,2015-01-07 12:22:46.000000000,2015-01-07 12:22:45.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-07 06:01:13.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/3e9e6b80e9388af775a913b36a520c6bdf1c9e9b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I410e9c667e4350bcd1a7b1b999ea79a77f0a41f2\n'}]",0,145410,3e9e6b80e9388af775a913b36a520c6bdf1c9e9b,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I410e9c667e4350bcd1a7b1b999ea79a77f0a41f2
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/10/145410/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,3e9e6b80e9388af775a913b36a520c6bdf1c9e9b,transifex/translations,"""POT-Creation-Date: 2015-01-06 16:06+0000\n"" ""PO-Revision-Date: 2015-01-06 16:06+0000\n""""md5=330f2abb9c69a0aad725e8572a82ddbf"" msgstr """"","""POT-Creation-Date: 2015-01-01 17:47+0000\n"" ""PO-Revision-Date: 2015-01-01 18:13+0000\n""""md5=4ab13a64f80c210be3120abc5c7aee8a"" msgstr ""@@image: 'static/marketecture-diagram.png'; md5=4ab13a64f80c210be3120abc5c7aee8a""",6,6
openstack%2Fapi-site~master~If81469286471bb089a7e8f99bd7737b2648c12fd,openstack/api-site,master,If81469286471bb089a7e8f99bd7737b2648c12fd,Imported Translations from Transifex,MERGED,2015-01-07 06:02:46.000000000,2015-01-07 12:22:37.000000000,2015-01-07 12:22:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-07 06:02:46.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-guide/locale/nl_NL.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/6511a9677646638ea597213636f0579f2309da14', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If81469286471bb089a7e8f99bd7737b2648c12fd\n'}]",0,145411,6511a9677646638ea597213636f0579f2309da14,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: If81469286471bb089a7e8f99bd7737b2648c12fd
",git fetch https://review.opendev.org/openstack/api-site refs/changes/11/145411/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-guide/locale/nl_NL.po']",3,6511a9677646638ea597213636f0579f2309da14,transifex/translations,"""POT-Creation-Date: 2015-01-07 04:31+0000\n"" ""PO-Revision-Date: 2015-01-06 15:01+0000\n""msgstr ""Roeltje, 2015""","""POT-Creation-Date: 2014-06-24 15:24+0000\n"" ""PO-Revision-Date: 2014-06-09 16:11+0000\n""msgstr """"",9,9
openstack%2Fha-guide~master~I5c8d71dd0740fdb24e7189d09a5240c0c8bb6966,openstack/ha-guide,master,I5c8d71dd0740fdb24e7189d09a5240c0c8bb6966,Imported Translations from Transifex,MERGED,2015-01-07 06:00:29.000000000,2015-01-07 12:21:37.000000000,2015-01-07 12:21:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-07 06:00:29.000000000', 'files': ['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/f2d93a425033f36cc5b9cd247b401fd698667c4f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I5c8d71dd0740fdb24e7189d09a5240c0c8bb6966\n'}]",0,145408,f2d93a425033f36cc5b9cd247b401fd698667c4f,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I5c8d71dd0740fdb24e7189d09a5240c0c8bb6966
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/08/145408/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/high-availability-guide.pot']",2,f2d93a425033f36cc5b9cd247b401fd698667c4f,transifex/translations,"""POT-Creation-Date: 2015-01-07 06:00+0000\n""msgid ""Here is the <link href=\""http://docs.openstack.org/trunk/config-reference/content/networking-options-l3_agent.html\"">documentation</link> for installing neutron L3 agent.""msgid ""Here is the <link href=\""http://docs.openstack.org/trunk/config-reference/content/networking-options-dhcp.html\"">documentation</link> for installing neutron DHCP agent.""","""POT-Creation-Date: 2015-01-02 06:01+0000\n""msgid ""Here is the <link href=\""http://docs.openstack.org/trunk/config-reference/content/section_adv_cfg_l3_agent.html\"">documentation</link> for installing neutron L3 agent.""msgid ""Here is the <link href=\""http://docs.openstack.org/trunk/config-reference/content/section_adv_cfg_dhcp_agent.html\"">documentation</link> for installing neutron DHCP agent.""",11,11
openstack%2Fnova~master~I02458af37e0c39d9a9d7309a9a3cc1d2545f3da1,openstack/nova,master,I02458af37e0c39d9a9d7309a9a3cc1d2545f3da1,initialize objects with context in Flavor object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-07 12:06:19.000000000,2015-01-06 23:23:38.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46851b4022f226bab033656701f9dfb97aee9da6', 'message': ""initialize objects with context in Flavor object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I02458af37e0c39d9a9d7309a9a3cc1d2545f3da1\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': ['nova/tests/unit/objects/test_flavor.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d2ca9487038e41d28c96df7bed4965edb015dc6b', 'message': ""initialize objects with context in Flavor object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I02458af37e0c39d9a9d7309a9a3cc1d2545f3da1\n""}]",0,142277,d2ca9487038e41d28c96df7bed4965edb015dc6b,17,7,2,4690,,,0,"initialize objects with context in Flavor object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: I02458af37e0c39d9a9d7309a9a3cc1d2545f3da1
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/142277/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_flavor.py'],1,46851b4022f226bab033656701f9dfb97aee9da6,bp/kilo-objects," flavor = flavor_obj.Flavor(context=self.context) flavor.create() flavor = flavor_obj.Flavor(context=context) flavor.create() flavor = flavor_obj.Flavor(context=self.context, id=123, name='foo') with mock.patch.object(db, 'flavor_destroy') as destroy: flavor.destroy()"," flavor = flavor_obj.Flavor() flavor.create(self.context) flavor = flavor_obj.Flavor() flavor.create(context) flavor = flavor_obj.Flavor(id=123, name='foo') with mock.patch.object(db, 'flavor_destroy') as destroy: flavor.destroy(self.context)",6,6
openstack%2Fnova~master~I60be29ba0c6ccbadd4c4d9a2d5426d1047c01a82,openstack/nova,master,I60be29ba0c6ccbadd4c4d9a2d5426d1047c01a82,initialize objects with context in FixedIP object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-07 12:03:50.000000000,2015-01-06 23:23:09.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c25f6789f979d648f8062e172b0e21ab039f8f2', 'message': ""initialize objects with context in FixedIP object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I60be29ba0c6ccbadd4c4d9a2d5426d1047c01a82\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': ['nova/tests/unit/objects/test_fixed_ip.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/814bb16dfe198d048acc7a69dba8b68ebfd01685', 'message': ""initialize objects with context in FixedIP object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I60be29ba0c6ccbadd4c4d9a2d5426d1047c01a82\n""}]",0,142276,814bb16dfe198d048acc7a69dba8b68ebfd01685,17,7,2,4690,,,0,"initialize objects with context in FixedIP object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: I60be29ba0c6ccbadd4c4d9a2d5426d1047c01a82
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/142276/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_fixed_ip.py'],1,6c25f6789f979d648f8062e172b0e21ab039f8f2,bp/kilo-objects," fixedip = fixed_ip.FixedIP(context=self.context, address='1.2.3.4') fixedip.create()", fixedip = fixed_ip.FixedIP(address='1.2.3.4') fixedip.create(self.context),2,2
openstack%2Fheat~master~I14f600cfc9f0f56b2acf366ef7fcbef25d16f003,openstack/heat,master,I14f600cfc9f0f56b2acf366ef7fcbef25d16f003,"Clarify ""attributes"" support status for ResourceGroup",MERGED,2014-12-19 19:06:48.000000000,2015-01-07 11:57:00.000000000,2015-01-07 11:41:18.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6983}, {'_account_id': 7256}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-19 19:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e67a1734113886fb53ab4f1a21b01eda0e7a5c3b', 'message': 'Clarify ""attributes"" support status for ResourceGroup\n\nThis was added during juno but not documented as such.  Also clarify\nthat latest HOT is required, or the path based get_att call won\'t\nwork (currently in a really non-obvious way..)\n\nChange-Id: I14f600cfc9f0f56b2acf366ef7fcbef25d16f003\nPartial-Bug: #1404360\n'}, {'number': 2, 'created': '2015-01-06 12:47:48.000000000', 'files': ['heat/engine/resources/resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0d746a9dde3cfcccfb3fe84a9671d3b6cca595b1', 'message': 'Clarify ""attributes"" support status for ResourceGroup\n\nThis was added during juno but not documented as such.  Also clarify\nthat latest HOT is required, or the path based get_attr call won\'t\nwork (currently in a really non-obvious way..)\n\nChange-Id: I14f600cfc9f0f56b2acf366ef7fcbef25d16f003\nPartial-Bug: #1404360\n'}]",3,143156,0d746a9dde3cfcccfb3fe84a9671d3b6cca595b1,21,7,2,4328,,,0,"Clarify ""attributes"" support status for ResourceGroup

This was added during juno but not documented as such.  Also clarify
that latest HOT is required, or the path based get_attr call won't
work (currently in a really non-obvious way..)

Change-Id: I14f600cfc9f0f56b2acf366ef7fcbef25d16f003
Partial-Bug: #1404360
",git fetch https://review.opendev.org/openstack/heat refs/changes/56/143156/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/resource_group.py'],1,e67a1734113886fb53ab4f1a21b01eda0e7a5c3b,bug/1404360," ""individual resource. Requires 2014-10-16 HOT.""), support_status=support.SupportStatus(version='2014.2')"," ""individual resource."")",2,1
openstack%2Fnova~stable%2Fjuno~I192d236e4f37fd28009186695f72acbe57fbb530,openstack/nova,stable/juno,I192d236e4f37fd28009186695f72acbe57fbb530,Stop using eventlet.util,ABANDONED,2015-01-06 21:57:47.000000000,2015-01-07 11:54:49.000000000,,[{'_account_id': 5170}],"[{'number': 1, 'created': '2015-01-06 21:57:47.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8164b46b3ba8822660934c036db9eab8f1f53e20', 'message': 'Stop using eventlet.util\n\nThis module has been removed in eventlet 0.16.0. As the code in\nquestion was copied from eventlet.tpool anyway, updated it to\nthe new version.\n\nChange-Id: I192d236e4f37fd28009186695f72acbe57fbb530\nCloses-Bug: 1407685\n'}]",0,145356,8164b46b3ba8822660934c036db9eab8f1f53e20,3,1,1,13252,,,0,"Stop using eventlet.util

This module has been removed in eventlet 0.16.0. As the code in
question was copied from eventlet.tpool anyway, updated it to
the new version.

Change-Id: I192d236e4f37fd28009186695f72acbe57fbb530
Closes-Bug: 1407685
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/145356/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,8164b46b3ba8822660934c036db9eab8f1f53e20,bug/1407685," sock = patcher.original('socket').socket(socket.AF_INET, csock = patcher.original('socket').socket(socket.AF_INET,","from eventlet import util as eventlet_util sock = eventlet_util.__original_socket__(socket.AF_INET, csock = eventlet_util.__original_socket__(socket.AF_INET,",2,3
openstack%2Frally~master~I99c94b9a2d99d54de5a93a4e15e82ab0173e5592,openstack/rally,master,I99c94b9a2d99d54de5a93a4e15e82ab0173e5592,Python 3 fix '+' operand in dict in test_osclients.py,MERGED,2015-01-07 09:46:29.000000000,2015-01-07 11:46:42.000000000,2015-01-07 11:46:38.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2015-01-07 09:46:29.000000000', 'files': ['tests/unit/test_osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/e3f71de9783e8433d5cfaf36724a57636b2ba765', 'message': ""Python 3 fix '+' operand in dict in test_osclients.py\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is using the update method in dict\nobject.\n\nChange-Id: I99c94b9a2d99d54de5a93a4e15e82ab0173e5592\n""}]",0,145450,e3f71de9783e8433d5cfaf36724a57636b2ba765,9,4,1,8367,,,0,"Python 3 fix '+' operand in dict in test_osclients.py

In Python 3, the dict.items() return a dict_items object, which
does not support the + operand.
The way to make it compatible is using the update method in dict
object.

Change-Id: I99c94b9a2d99d54de5a93a4e15e82ab0173e5592
",git fetch https://review.opendev.org/openstack/rally refs/changes/50/145450/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/test_osclients.py'],1,e3f71de9783e8433d5cfaf36724a57636b2ba765,os_client_dict_sum, kwargs = self.endpoint.to_dict() kwargs.update(endpoint.items()) kwargs = self.endpoint_https.to_dict() kwargs.update(endpoint.items()), kwargs = dict(self.endpoint.to_dict().items() + endpoint.items()) kwargs = dict(self.endpoint_https.to_dict().items() + endpoint.items()),4,2
openstack%2Fironic-inspector~master~I8e04d76c6310c1db3576e0dc37d38a8b3af8c4b8,openstack/ironic-inspector,master,I8e04d76c6310c1db3576e0dc37d38a8b3af8c4b8,Make database a required configuration option,MERGED,2015-01-06 14:20:00.000000000,2015-01-07 11:26:15.000000000,2015-01-07 11:26:15.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-01-06 14:20:00.000000000', 'files': ['README.rst', 'ironic_discoverd/test/base.py', 'functest/run.py', 'ironic_discoverd/node_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/b340f089603145af6c71b60be8e9b7be5e7e7d7c', 'message': 'Make database a required configuration option\n\nThe more we rely on this database, the less sane is to use\ntemporary file as the default.\n\nChange-Id: I8e04d76c6310c1db3576e0dc37d38a8b3af8c4b8\nCloses-Bug: #1407602\n'}]",0,145231,b340f089603145af6c71b60be8e9b7be5e7e7d7c,8,4,1,10239,,,0,"Make database a required configuration option

The more we rely on this database, the less sane is to use
temporary file as the default.

Change-Id: I8e04d76c6310c1db3576e0dc37d38a8b3af8c4b8
Closes-Bug: #1407602
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/31/145231/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'ironic_discoverd/test/base.py', 'functest/run.py', 'ironic_discoverd/node_cache.py']",4,b340f089603145af6c71b60be8e9b7be5e7e7d7c,bug/1407602,import sys if not _DB_NAME: # pragma: no cover LOG.critical('Configuration option discoverd.database should be set') sys.exit(1) ,"import atexitimport osimport tempfile if not _DB_NAME: # We can't use in-memory, so we create a temporary file fd, _DB_NAME = tempfile.mkstemp(prefix='discoverd-') os.close(fd) def cleanup(): # pragma: no cover if os.path.exists(_DB_NAME): os.unlink(_DB_NAME) atexit.register(cleanup)",24,20
openstack%2Ftripleo-ci~master~Ica7b291f3e2d2da859d1fbe145419fc79016f5f2,openstack/tripleo-ci,master,Ica7b291f3e2d2da859d1fbe145419fc79016f5f2,Remove chown .cache workaround,MERGED,2014-12-30 19:06:47.000000000,2015-01-07 11:23:49.000000000,2015-01-07 11:23:49.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6133}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-30 19:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/820455d84d1cb66cbe73b475ecbd0bd9fce6b963', 'message': ""Remove cown .cache workaround\n\nWe added this to work around a bug where we were running pip as root\nbefore .cache existed. This should be fixed by sudo'ing with -H when we\nsudo pip install.\n\nChange-Id: Ica7b291f3e2d2da859d1fbe145419fc79016f5f2\n""}, {'number': 2, 'created': '2014-12-30 19:08:00.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/29019244ba4a2ec1e4fee4434b1259bb6ea838f3', 'message': ""Remove chown .cache workaround\n\nWe added this to work around a bug where we were running pip as root\nbefore .cache existed. This should be fixed by sudo'ing with -H when we\nsudo pip install.\n\nChange-Id: Ica7b291f3e2d2da859d1fbe145419fc79016f5f2\n""}]",0,144500,29019244ba4a2ec1e4fee4434b1259bb6ea838f3,11,4,2,10035,,,0,"Remove chown .cache workaround

We added this to work around a bug where we were running pip as root
before .cache existed. This should be fixed by sudo'ing with -H when we
sudo pip install.

Change-Id: Ica7b291f3e2d2da859d1fbe145419fc79016f5f2
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/00/144500/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,820455d84d1cb66cbe73b475ecbd0bd9fce6b963,fix/remove-cache-workaround,,# workaround for bug 1101404 [[ -d ~/.cache ]] && sudo chown -R $(whoami) ~/.cache ,0,3
openstack%2Fneutron~master~Ice7ae845d1d5063b116824f49961ff060a0b2baa,openstack/neutron,master,Ice7ae845d1d5063b116824f49961ff060a0b2baa,"Revert ""Revert ""Add metadata proxy L3 agent driver""""",MERGED,2014-12-21 14:24:35.000000000,2015-01-07 11:18:59.000000000,2015-01-07 00:10:44.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-12-21 14:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea0a6a6db453572793a9dc805f750dd845a4cd5a', 'message': 'Revert ""Revert ""Add metadata proxy L3 agent driver""""\n\nThis reverts commit 658dc9d30cfb337159df40fdd62c50de182d83aa.\n\nChange-Id: Ice7ae845d1d5063b116824f49961ff060a0b2baa\n'}, {'number': 2, 'created': '2014-12-21 14:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f53711edfb8572a64f9209c8a2842ec26fb8784', 'message': 'Revert ""Revert ""Add metadata proxy L3 agent driver""""\n\nThis reverts commit 658dc9d30cfb337159df40fdd62c50de182d83aa.\n\nChange-Id: Ice7ae845d1d5063b116824f49961ff060a0b2baa\n'}, {'number': 3, 'created': '2014-12-22 15:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13959674ec4661cb60689fc073216d05deb404f9', 'message': 'Revert ""Revert ""Add metadata proxy L3 agent driver""""\n\nThis reverts commit 658dc9d30cfb337159df40fdd62c50de182d83aa.\n\nChange-Id: Ice7ae845d1d5063b116824f49961ff060a0b2baa\n'}, {'number': 4, 'created': '2014-12-22 16:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/49d6879bc9b57c1bdd5c4f3da80b570e62327cae', 'message': 'Revert ""Revert ""Add metadata proxy L3 agent driver""""\n\nThis reverts commit 658dc9d30cfb337159df40fdd62c50de182d83aa.\n\nThe L3 agent metadata driver was added but then reverted\nbecause it broke the functional job. The fix to the functional\njob was merged, and this patch reverts the revert, thereby\nadding the metadata driver back.\n\nChange-Id: Ice7ae845d1d5063b116824f49961ff060a0b2baa\n'}, {'number': 5, 'created': '2015-01-06 21:43:08.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/metadata/__init__.py', 'neutron/agent/l3/ha.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d682d2fb7667f65501761dad36d28a63ababa4b', 'message': 'Revert ""Revert ""Add metadata proxy L3 agent driver""""\n\nThis reverts commit 658dc9d30cfb337159df40fdd62c50de182d83aa.\n\nThe L3 agent metadata driver was added but then reverted\nbecause it broke the functional job. The fix to the functional\njob was merged, and this patch reverts the revert, thereby\nadding the metadata driver back.\n\nChange-Id: Ice7ae845d1d5063b116824f49961ff060a0b2baa\n'}]",0,143301,3d682d2fb7667f65501761dad36d28a63ababa4b,99,26,5,8873,,,0,"Revert ""Revert ""Add metadata proxy L3 agent driver""""

This reverts commit 658dc9d30cfb337159df40fdd62c50de182d83aa.

The L3 agent metadata driver was added but then reverted
because it broke the functional job. The fix to the functional
job was merged, and this patch reverts the revert, thereby
adding the metadata driver back.

Change-Id: Ice7ae845d1d5063b116824f49961ff060a0b2baa
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/143301/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/metadata/__init__.py', 'neutron/agent/l3/ha.py', 'neutron/tests/unit/test_l3_agent.py']",6,ea0a6a6db453572793a9dc805f750dd845a4cd5a,bug/1404662,"from neutron.agent.metadata import driver as metadata_driverfrom neutron.openstack.common import log self.conf.register_cli_opts(log.common_cli_opts) self.conf.register_cli_opts(log.logging_cli_opts) router = {'id': router_id, driver = metadata_driver.MetadataDriver driver, '_destroy_metadata_proxy') as destroy_proxy: driver, '_spawn_metadata_proxy') as spawn_proxy: agent._process_added_router(router) if enableflag: spawn_proxy.assert_called_with(router_id, mock.ANY, mock.ANY) destroy_proxy.assert_called_with(router_id, mock.ANY, mock.ANY)"," def test_ha_router_keepalived_config(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = prepare_router_data(enable_ha=True) router['routes'] = [ {'destination': '8.8.8.8/32', 'nexthop': '35.4.0.10'}, {'destination': '8.8.4.4/32', 'nexthop': '35.4.0.11'}] ri = l3router.RouterInfo(router['id'], self.conf.root_helper, router=router) ri.router = router with contextlib.nested(mock.patch.object(agent, '_spawn_metadata_proxy'), mock.patch('neutron.agent.linux.' 'utils.replace_file'), mock.patch('neutron.agent.linux.' 'utils.execute'), mock.patch('os.makedirs')): agent.process_ha_router_added(ri) agent.process_router(ri) config = ri.keepalived_manager.config ha_iface = agent.get_ha_device_name(ri.ha_port['id']) ex_iface = agent.get_external_device_name(ri.ex_gw_port['id']) int_iface = agent.get_internal_device_name( ri.internal_ports[0]['id']) expected = """"""vrrp_sync_group VG_1 { group { VR_1 } } vrrp_instance VR_1 { state BACKUP interface %(ha_iface)s virtual_router_id 1 priority 50 nopreempt advert_int 2 track_interface { %(ha_iface)s } virtual_ipaddress { 19.4.4.4/24 dev %(ex_iface)s } virtual_ipaddress_excluded { 35.4.0.4/24 dev %(int_iface)s } virtual_routes { 0.0.0.0/0 via 19.4.4.1 dev %(ex_iface)s 8.8.8.8/32 via 35.4.0.10 8.8.4.4/32 via 35.4.0.11 } }"""""" % {'ha_iface': ha_iface, 'ex_iface': ex_iface, 'int_iface': int_iface} self.assertEqual(expected, config.get_config_str()) router = {'id': _uuid(), agent, '_destroy_metadata_proxy') as destroy_proxy: agent, '_spawn_metadata_proxy') as spawn_proxy: agent._router_added(router_id, router) if enableflag: spawn_proxy.assert_called_with(router_id, mock.ANY) destroy_proxy.assert_called_with(mock.ANY, mock.ANY) def test_metadata_nat_rules(self): self.conf.set_override('enable_metadata_proxy', False) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertEqual([], agent.metadata_nat_rules()) self.conf.set_override('metadata_port', '8775') self.conf.set_override('enable_metadata_proxy', True) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) rules = ('PREROUTING', '-s 0.0.0.0/0 -d 169.254.169.254/32 ' '-p tcp -m tcp --dport 80 -j REDIRECT --to-port 8775') self.assertEqual([rules], agent.metadata_nat_rules()) def test_metadata_filter_rules(self): self.conf.set_override('enable_metadata_proxy', False) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertEqual([], agent.metadata_filter_rules()) self.conf.set_override('metadata_port', '8775') self.conf.set_override('enable_metadata_proxy', True) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) rules = ('INPUT', '-s 0.0.0.0/0 -d 127.0.0.1 ' '-p tcp -m tcp --dport 8775 -j ACCEPT') self.assertEqual([rules], agent.metadata_filter_rules()) class TestL3AgentEventHandler(base.BaseTestCase): def setUp(self): super(TestL3AgentEventHandler, self).setUp() cfg.CONF.register_opts(l3_agent.L3NATAgent.OPTS) cfg.CONF.register_opts(ha.OPTS) agent_config.register_interface_driver_opts_helper(cfg.CONF) agent_config.register_use_namespaces_opts_helper(cfg.CONF) cfg.CONF.set_override( 'interface_driver', 'neutron.agent.linux.interface.NullDriver' ) cfg.CONF.set_override('use_namespaces', True) cfg.CONF.set_override('verbose', False) agent_config.register_root_helper(cfg.CONF) device_exists_p = mock.patch( 'neutron.agent.linux.ip_lib.device_exists') device_exists_p.start() utils_exec_p = mock.patch( 'neutron.agent.linux.utils.execute') utils_exec_p.start() drv_cls_p = mock.patch('neutron.agent.linux.interface.NullDriver') driver_cls = drv_cls_p.start() mock_driver = mock.MagicMock() mock_driver.DEV_NAME_LEN = ( interface.LinuxInterfaceDriver.DEV_NAME_LEN) driver_cls.return_value = mock_driver l3_plugin_p = mock.patch( 'neutron.agent.l3.agent.L3PluginApi') l3_plugin_cls = l3_plugin_p.start() l3_plugin_cls.return_value = mock.MagicMock() self.external_process_p = mock.patch( 'neutron.agent.linux.external_process.ProcessManager' ) self.external_process_p.start() looping_call_p = mock.patch( 'neutron.openstack.common.loopingcall.FixedIntervalLoopingCall') looping_call_p.start() self.agent = l3_agent.L3NATAgent(HOSTNAME) def test_spawn_metadata_proxy(self): router_id = _uuid() metadata_port = 8080 ip_class_path = 'neutron.agent.linux.ip_lib.IPWrapper' cfg.CONF.set_override('metadata_port', metadata_port) cfg.CONF.set_override('log_file', 'test.log') cfg.CONF.set_override('debug', True) self.external_process_p.stop() ri = l3router.RouterInfo(router_id, None, None) with mock.patch(ip_class_path) as ip_mock: self.agent._spawn_metadata_proxy(ri.router_id, ri.ns_name) ip_mock.assert_has_calls([ mock.call('sudo', ri.ns_name), mock.call().netns.execute([ 'neutron-ns-metadata-proxy', mock.ANY, mock.ANY, '--router_id=%s' % router_id, mock.ANY, '--metadata_port=%s' % metadata_port, '--debug', '--log-file=neutron-ns-metadata-proxy-%s.log' % router_id ], addl_env=None) ])",206,226
openstack%2Ffuel-library~master~I4e862384ec9c435ec7077633c8254c1c9f547b10,openstack/fuel-library,master,I4e862384ec9c435ec7077633c8254c1c9f547b10,Hardcode the location of Horizon policy files on CentOS,ABANDONED,2014-12-01 13:58:34.000000000,2015-01-07 11:16:25.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8040}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13948}]","[{'number': 1, 'created': '2014-12-01 13:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/08cd606621c220b7dab3e0fb9c07477c6a6273a9', 'message': 'Hardcode the location of Horizon policy files\n\nBy default Horizon looks for these files in ROOT_PATH/conf,\nwhich is wrong location. This results in displaying unusable\nelements supposed to be shown only for administrator, without\nlisting objects that user has no access to.\n\nChange-Id: I4e862384ec9c435ec7077633c8254c1c9f547b10\nCloses-Bug: 1397069\n'}, {'number': 2, 'created': '2014-12-01 19:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9f7dcf943992af29521562a191160519760edd39', 'message': 'Hardcode the location of Horizon policy files on CentOS\n\nBy default Horizon looks for these files in ROOT_PATH/conf,\nwhich is a symlink to [1] on CentOS. This results in displaying\nunusable elements supposed to be shown only for administrator, without\nlisting objects that user has no access to.\n\n[1] /usr/share/openstack-dashboard/openstack_dashboard/local/local_settings.py\n\nChange-Id: I4e862384ec9c435ec7077633c8254c1c9f547b10\nCloses-Bug: 1397069\n'}, {'number': 3, 'created': '2014-12-02 10:15:23.000000000', 'files': ['deployment/puppet/horizon/templates/local_settings.py.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/032936777c2b5c41a37b726efd0f93cc5fcbe9a6', 'message': 'Hardcode the location of Horizon policy files on CentOS\n\nBy default Horizon looks for these files in ROOT_PATH/conf,\nwhich is a symlink to [1] on CentOS. This results in displaying\nunusable elements supposed to be shown only for administrator, without\nlisting objects that user has no access to.\n\n[1] /usr/share/openstack-dashboard/openstack_dashboard/local/local_settings.py\n\nChange-Id: I4e862384ec9c435ec7077633c8254c1c9f547b10\nCloses-Bug: 1397069\n'}]",2,138071,032936777c2b5c41a37b726efd0f93cc5fcbe9a6,31,7,3,13948,,,0,"Hardcode the location of Horizon policy files on CentOS

By default Horizon looks for these files in ROOT_PATH/conf,
which is a symlink to [1] on CentOS. This results in displaying
unusable elements supposed to be shown only for administrator, without
listing objects that user has no access to.

[1] /usr/share/openstack-dashboard/openstack_dashboard/local/local_settings.py

Change-Id: I4e862384ec9c435ec7077633c8254c1c9f547b10
Closes-Bug: 1397069
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/71/138071/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/horizon/templates/local_settings.py.erb'],1,08cd606621c220b7dab3e0fb9c07477c6a6273a9,bug/1397069,"POLICY_FILES_PATH = ""/etc/openstack-dashboard/"" ","#POLICY_FILES_PATH = os.path.join(ROOT_PATH, ""conf"")",2,1
openstack%2Fhorizon~master~I1c41a48fc9805b1b730dec5f13a43b73989b349b,openstack/horizon,master,I1c41a48fc9805b1b730dec5f13a43b73989b349b,Filter current flavor in resize instance/database,MERGED,2014-12-30 19:55:57.000000000,2015-01-07 11:13:08.000000000,2015-01-07 11:13:07.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 9576}, {'_account_id': 9659}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-12-30 19:55:57.000000000', 'files': ['openstack_dashboard/dashboards/project/databases/forms.py', 'openstack_dashboard/dashboards/project/instances/workflows/resize_instance.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/databases/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bad59c2345eb23f4ac9d068d27dc4a35226e06f', 'message': 'Filter current flavor in resize instance/database\n\nRemoved the validation that checks if the new flavor selected\nis the same as the old flavor, this case now will never happen\nsince the current flavor is removed from the choices.\n\nChange-Id: I1c41a48fc9805b1b730dec5f13a43b73989b349b\nCloses-Bug: #1395777\n'}]",0,144506,3bad59c2345eb23f4ac9d068d27dc4a35226e06f,16,7,1,1941,,,0,"Filter current flavor in resize instance/database

Removed the validation that checks if the new flavor selected
is the same as the old flavor, this case now will never happen
since the current flavor is removed from the choices.

Change-Id: I1c41a48fc9805b1b730dec5f13a43b73989b349b
Closes-Bug: #1395777
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/144506/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/databases/forms.py', 'openstack_dashboard/dashboards/project/instances/workflows/resize_instance.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/databases/tests.py']",4,3bad59c2345eb23f4ac9d068d27dc4a35226e06f,bug/1395777," 'flavor_list')}) def test_resize_instance_get(self): database = self.databases.first() # views.py: DetailView.get_data api.trove.instance_get(IsA(http.HttpRequest), database.id)\ .AndReturn(database) api.trove.flavor_list(IsA(http.HttpRequest)).\ AndReturn(self.database_flavors.list()) self.mox.ReplayAll() url = reverse('horizon:project:databases:resize_instance', args=[database.id]) res = self.client.get(url) self.assertTemplateUsed(res, 'project/databases/resize_instance.html') option = '<option value=""%s"">%s</option>' for flavor in self.database_flavors.list(): if flavor.id == database.flavor['id']: self.assertNotContains(res, option % (flavor.id, flavor.name)) else: self.assertContains(res, option % (flavor.id, flavor.name)) @test.create_stubs( {api.trove: ('instance_get',"," @test.create_stubs( {api.trove: ('instance_get', 'flavor_list')}) def test_resize_instance_bad_value(self): database = self.databases.first() api.trove.instance_get(IsA(http.HttpRequest), database.id).AndReturn(database) api.trove.flavor_list(IsA(http.HttpRequest)).\ AndReturn(self.database_flavors.list()) old_flavor = self.database_flavors.list()[0] self.mox.ReplayAll() url = reverse('horizon:project:databases:resize_instance', args=[database.id]) post = { 'instance_id': database.id, 'old_flavor_name': old_flavor.name, 'old_flavor_id': old_flavor.id, 'new_flavor': old_flavor.id } res = self.client.post(url, post) self.assertContains(res, ""Please choose a new flavor that is "" ""not the same as the old one."")",46,46
openstack%2Fhorizon~master~Ibc439cd383011c8523ac9ccf086823c9874b6c69,openstack/horizon,master,Ibc439cd383011c8523ac9ccf086823c9874b6c69,Imported Translations from Transifex,MERGED,2015-01-07 06:08:13.000000000,2015-01-07 11:12:57.000000000,2015-01-07 11:12:56.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}]","[{'number': 1, 'created': '2015-01-07 06:08:13.000000000', 'files': ['horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d02a6010b66f3fb940cde8ddce4877e0a453cd02', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibc439cd383011c8523ac9ccf086823c9874b6c69\n'}]",0,145412,d02a6010b66f3fb940cde8ddce4877e0a453cd02,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibc439cd383011c8523ac9ccf086823c9874b6c69
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/145412/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/nl_NL/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po']",4,d02a6010b66f3fb940cde8ddce4877e0a453cd02,transifex/translations,"# Roeltje, 2015""POT-Creation-Date: 2015-01-06 10:18-0600\n"" ""PO-Revision-Date: 2015-01-06 12:10+0000\n"" ""Last-Translator: Roeltje\n""msgstr ""Grootte van het gebruikt werkgeheugen in MB""#: api/keystone.py:369 api/keystone.py:390msgstr ""Locale Opslag (gebruikt)""msgstr ""Locale Opslag (totaal)""msgstr ""Hypervisor Exemplaren""msgstr ""Hypervisor""msgstr ""Huidige Host""msgstr ""Doelhost""msgstr ""Gedeelde Opslag""msgstr ""Selecteer een doelhost""msgstr ""Geen andere host beschikbaar.""msgstr ""Reden""msgstr ""Service Deactiveren""msgstr[0] ""Service Activeren"" msgstr[1] ""Services Activeren""msgstr[0] ""Service Geactiveerd"" msgstr[1] ""Services Geactiveerd""msgstr ""Locaal Schijfverbruik""msgstr ""Afbeeldingsnaam =""msgstr ""Statuus =""msgstr ""Formaat =""msgstr ""Min. Grootte (MB)""msgstr ""Max. grootte (MB)""msgstr ""Pas de details van de afbeelding aan.""msgstr ""Update Afbeeldings-metadata""msgstr ""Systeeminformatie""msgstr ""Blokkeer Opslagservices""msgstr ""Reden: %(disabled_reason)s""msgstr ""Nieuwe Host""msgstr ""Kies een Host om naar te verplaatsen.""msgstr ""Selecteer een nieuwe host""msgstr ""Host =""msgstr ""IPv4 Adres =""msgstr ""IPv6 Adres =""msgstr ""Afbeelding ID =""msgstr ""IP Adres""msgstr ""Live Verplaatsen""msgstr ""Alle Exemplaren""msgstr ""Directe Invoer""msgstr ""Metadata Definities""msgstr ""Naamplaatsen""msgstr ""Inhouden""msgstr ""Onbepaald""msgstr ""Naam Weergeven""msgstr ""Naamplaats""msgstr ""Voorvoegsel:""msgstr ""Beschikbare Types""msgstr ""Pas Gebruiksrapport Parameters Aan""msgstr ""Dagelijks Gebruiksrapport""msgstr ""Datum wordt niet herkent.""msgstr ""Tijd""msgstr ""Groeperen bij:""msgstr ""Waarde:""msgstr ""Van:""msgstr ""Naar:""msgstr ""Locaal""msgstr ""Plat""msgstr ""GRE""msgstr ""OMHOOG""msgstr ""OMLAAG""msgstr[0] ""Netwerk Verwijderen"" msgstr[1] ""Netwerken Verwijderen""msgstr[0] ""Netwerk Verwijderd"" msgstr[1] ""Netwerken Verwijderd""msgstr ""OMHOOG""msgstr ""OMLAAG""msgstr ""DHCP Agenten""msgstr ""Nieuw DHCP Agent""msgstr ""Selecteer een nieuw agent""msgstr ""Geen andere agenten beschikbaar.""msgstr ""Mislukt om agent %(agent_name)s toe te voegen voor netwerk %(network)s.""msgstr[0] ""DHCP Agent Verwijderen"" msgstr[1] ""DHCP Agenten Verwijderen""msgstr[0] ""DHCP Agent Verwijderd"" msgstr[1] ""DHCP Agenten Verwijderd""msgstr ""Mislukt om agent te verwijderen: %s""msgstr ""Voeg DHCP Agent Toe""msgstr[0] ""Poort Verwijderen"" msgstr[1] ""Poorten Verwijderen""msgstr[0] ""Poorten Verwijderd"" msgstr[1] ""Poorten Verwijderd""msgstr ""Netwerk Details""msgstr ""Verbruiksrapport Voor Periode""msgstr ""Totale Schijfgrootte (GB)""msgstr ""Totaal Schijfverbruik (uren)""msgstr ""Verbruiks-overzicht""msgstr ""Monitoren:""msgstr ""Router Aanpassen""msgstr ""Router Vernieuwen""msgstr ""Aanmaken""msgstr ""Verwijderen""msgstr ""Fout""msgstr ""Fout Verwijderen""msgstr ""Informatie""msgstr ""Pas Verbruiker Aan""msgstr ""Sleutelgrootte (bits)""msgstr ""Extra Specificaties""msgstr ""Fout""msgstr ""Sjabloon""msgstr ""Cluster Sjabloon""msgstr ""Sjabloon Vernieuwen""msgstr ""Cluster Starten""msgstr ""Sjabloon Kopiëren""msgstr[1] ""Sjablonen Verwijderen""msgstr[1] ""Sjablonen Verwijderd""msgstr ""Creër Sjabloon""msgstr ""Plug-in""msgstr ""Versie""msgstr ""Algemene Info""msgstr ""Sjabloon Overzicht""msgstr ""Uploaden""msgstr ""Plug-in Naam""msgstr ""Kan niet aanmaken""msgstr ""Sjabloon Naam""msgstr ""Clusters""msgstr[1] ""Clusters Verwijderen""msgstr[1] ""Clusters Verwijderd""msgstr ""Configureer Cluster""msgstr ""Exemplaren Tel""msgstr ""Interne IP""msgstr ""Klaar""msgstr ""Cluster Overzicht""msgstr ""Foutendetails""msgstr ""Basisafbeelding""msgstr ""Cluster Exemplaren""msgstr ""Cluster Details""msgstr ""Cluster Naam""msgstr ""Cluster Sjabloon""msgstr ""Geen Sleutelpaar""msgstr ""Creër Cluster %s""msgstr ""Niet in staat om de cluster te creëren""msgstr ""Schaal""msgstr ""Afbeelding succesvol bijgewerkt.""msgstr ""Tags Bewerken""msgstr ""Tags""msgstr ""Afbeeldingstags Bewerken""msgstr ""Klaar""msgstr ""Plug-ins""msgstr ""Titel""msgstr ""Ondersteunde Versies""msgstr ""Databronnen""msgstr ""Creër Databron""msgstr ""Niet in staat om de datbrondetails op te halen""msgstr ""Databron Overzicht""msgstr ""Creër Tijd""msgstr ""Bestand Uploaden""msgstr ""Scriptnaam""msgstr ""Script-tekst""msgstr ""Gebruikersnaam""msgstr ""Kies een bestaand bestand""msgstr ""Nieuw bestand uploaden""msgstr ""Job""msgstr ""Cluster""msgstr ""Tel""msgstr ""Plug-in Naam""msgstr ""Stapsgewijs""msgstr ""Archiefdetails""msgstr ""Stapsgewijs Archief""msgstr ""Geen Archief Beschikbaar""msgstr ""Huidige Grootte (GB)""msgstr ""Nieuwe Grootte (GB)""msgstr ""Toegestane Host""msgstr ""Niet in staat om gebruikersdata te ontvangen.""msgstr ""Niet in staat om database data te ontvangen.""msgstr ""Niet in staat om database archief data te ontvangen.""msgstr ""GEBRUIKERSNAAM""msgstr ""WACHTWOORD""msgstr ""DATABASE""msgstr ""Toegestane Host (optioneel)""msgstr ""Geselecteerde netwerken""msgstr ""Selecteer archief""msgstr[1] ""Beleiden Verwijderen""msgstr[1] ""Firewalls Verwijderen""msgstr ""Fout""msgstr ""Verwijderen""msgstr ""OMHOOG""msgstr ""OMLAAG""","""POT-Creation-Date: 2015-01-05 15:30-0600\n"" ""PO-Revision-Date: 2015-01-05 20:29+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"#: api/keystone.py:369 api/keystone.py:388msgstr """"msgstr """"msgstr ""Hypervisor exemplaren""msgstr """"msgstr ""Huidige gastheer""msgstr """"msgstr """"msgstr """"msgstr ""Geen andere gastheren beschikbaar.""msgstr """"msgstr """"msgstr[0] """" msgstr[1] """"msgstr[0] """" msgstr[1] """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""Nieuwe gastheer""msgstr ""Kies een gastheer om naar te verplaatsen.""msgstr ""Selecteer een nieuwe gastheer""msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""IP adres""msgstr ""Live verplaatsen""msgstr ""Alle exemplaren""msgstr ""Directe invoer""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr[0] """" msgstr[1] """"msgstr[0] """" msgstr[1] """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr[0] """" msgstr[1] """"msgstr[0] """" msgstr[1] """"msgstr """"msgstr """"msgstr[0] """" msgstr[1] """"msgstr[0] """" msgstr[1] """"msgstr """"msgstr ""Verbruiksrapport voor periode""msgstr """"msgstr """"msgstr ""Verbruiks overzicht""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""Extra specificaties""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr[1] """"msgstr[1] """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr[1] """"msgstr[1] """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr[1] """"msgstr[1] """"msgstr """"msgstr """"msgstr """"msgstr """"",291,289
openstack%2Fnova~master~Id672fab7a840a8e07be305a06083b3e9ca30d18e,openstack/nova,master,Id672fab7a840a8e07be305a06083b3e9ca30d18e,initialize objects with context in BlockDeviceMapping object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-07 11:06:53.000000000,2015-01-06 23:14:26.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/065133194468eef7b26ed721e39b5c5c61167e27', 'message': ""initialize objects with context in BlockDeviceMapping object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Id672fab7a840a8e07be305a06083b3e9ca30d18e\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': ['nova/tests/unit/objects/test_block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d35e43121a124fd81520d9336a1c9dd944969fc9', 'message': ""initialize objects with context in BlockDeviceMapping object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Id672fab7a840a8e07be305a06083b3e9ca30d18e\n""}]",1,142273,d35e43121a124fd81520d9336a1c9dd944969fc9,19,7,2,4690,,,0,"initialize objects with context in BlockDeviceMapping object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: Id672fab7a840a8e07be305a06083b3e9ca30d18e
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/142273/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_block_device.py'],1,065133194468eef7b26ed721e39b5c5c61167e27,bp/kilo-objects," bdm = objects.BlockDeviceMapping(context=self.context, **values) bdm.create() bdm.create() bdm = objects.BlockDeviceMapping(context=self.context, **values) bdm.create() bdm = objects.BlockDeviceMapping(context=self.context, **values) bdm.create() bdm = objects.BlockDeviceMapping(context=self.context, **values) bdm.destroy()", bdm = objects.BlockDeviceMapping(**values) bdm.create(self.context) bdm.create(self.context) bdm = objects.BlockDeviceMapping(**values) bdm.create(self.context) bdm = objects.BlockDeviceMapping(**values) bdm.create(self.context) bdm = objects.BlockDeviceMapping(**values) bdm.destroy(self.context),9,9
openstack%2Fswift~feature%2Fec~I700979d95f676cb5f1f2570215f506e6b1963937,openstack/swift,feature/ec,I700979d95f676cb5f1f2570215f506e6b1963937,Merge master to feature/ec,MERGED,2014-12-31 21:55:43.000000000,2015-01-07 10:36:26.000000000,2015-01-01 00:05:13.000000000,"[{'_account_id': 3}, {'_account_id': 7479}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-31 21:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eca955de79774471c68aee9e30cbe1d4b4b844e6', 'message': 'Merge master to feature/ec\n\nChange-Id: I700979d95f676cb5f1f2570215f506e6b1963937\n'}]",0,144664,eca955de79774471c68aee9e30cbe1d4b4b844e6,7,3,1,7479,,,0,"Merge master to feature/ec

Change-Id: I700979d95f676cb5f1f2570215f506e6b1963937
",git fetch https://review.opendev.org/openstack/swift refs/changes/64/144664/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,eca955de79774471c68aee9e30cbe1d4b4b844e6,ec_merge,,,0,0
openstack%2Fnova~master~Ibad6b1f94686117cd67984858c8ac17237540bed,openstack/nova,master,Ibad6b1f94686117cd67984858c8ac17237540bed,initialize objects with context in ComputeNode object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-07 10:35:53.000000000,2015-01-06 23:22:18.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/715842fce273c5b211e6f30188bf893ada665244', 'message': ""initialize objects with context in ComputeNode object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ibad6b1f94686117cd67984858c8ac17237540bed\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': ['nova/tests/unit/objects/test_compute_node.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3920fab2fe531f8a4900add26e1f1736d24ec200', 'message': ""initialize objects with context in ComputeNode object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ibad6b1f94686117cd67984858c8ac17237540bed\n""}]",0,142274,3920fab2fe531f8a4900add26e1f1736d24ec200,17,7,2,4690,,,0,"initialize objects with context in ComputeNode object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: Ibad6b1f94686117cd67984858c8ac17237540bed
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/142274/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_compute_node.py'],1,715842fce273c5b211e6f30188bf893ada665244,bp/kilo-objects, compute = compute_node.ComputeNode(context=self.context) compute.create() compute = compute_node.ComputeNode(context=self.context) compute.create() compute = compute_node.ComputeNode(context=self.context) compute.save() compute = compute_node.ComputeNode(context=self.context) compute.create() compute = compute_node.ComputeNode(context=self.context) compute.destroy(), compute = compute_node.ComputeNode() compute.create(self.context) compute = compute_node.ComputeNode() compute.create(self.context) compute = compute_node.ComputeNode() compute.save(self.context) compute = compute_node.ComputeNode() compute.create(self.context) compute = compute_node.ComputeNode() compute.destroy(self.context),10,10
openstack%2Fproject-config~master~I140d60ca8903b0f392dbb301ee0fccd68a03b1ed,openstack/project-config,master,I140d60ca8903b0f392dbb301ee0fccd68a03b1ed,move neutron-api job to use gate hooks,MERGED,2014-12-17 22:53:44.000000000,2015-01-07 10:29:09.000000000,2015-01-06 18:33:00.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1106}, {'_account_id': 2035}, {'_account_id': 5263}, {'_account_id': 6524}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-12-17 22:53:44.000000000', 'files': ['jenkins/jobs/neutron-functional.yaml', 'jenkins/jobs/neutron-api.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9c87abeeeefa8d298487c0cc597ffc4e7ee2dcef', 'message': 'move neutron-api job to use gate hooks\n\nThis change is dependent on [1,2] being merged first\n\n[1] https://review.openstack.org/#/c/142558/\n[2] https://review.openstack.org/#/c/142601/\n\nChange-Id: I140d60ca8903b0f392dbb301ee0fccd68a03b1ed\n'}]",0,142603,9c87abeeeefa8d298487c0cc597ffc4e7ee2dcef,13,9,1,748,,,0,"move neutron-api job to use gate hooks

This change is dependent on [1,2] being merged first

[1] https://review.openstack.org/#/c/142558/
[2] https://review.openstack.org/#/c/142601/

Change-Id: I140d60ca8903b0f392dbb301ee0fccd68a03b1ed
",git fetch https://review.opendev.org/openstack/project-config refs/changes/03/142603/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/neutron-functional.yaml', 'jenkins/jobs/neutron-api.yaml']",2,9c87abeeeefa8d298487c0cc597ffc4e7ee2dcef,hook-api-job, function gate_hook {{ bash -xe $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh api }} export -f gate_hook function post_test_hook {{ bash -xe $BASE/new/neutron/neutron/tests/contrib/post_test_hook.sh api," function post_test_hook {{ cd $BASE/new/neutron # Ensure that the executing user can invoke tox on the # neutron source tree. sudo chown -R tempest:stack $BASE/new/neutron echo ""Configuring venv for neutron api test suite"" # Manually install tempest pending a decision on how # best to include tempest as an explicit test dependency # of neutron. sudo -H -u tempest tox -e api --notest sudo -H -u tempest .tox/api/bin/pip install $BASE/new/tempest echo ""Running neutron api test suite"" sudo -H -u tempest tox -e api",9,14
openstack%2Fnova~master~I4405407f0f9e20bedbfd714b98492eb9beb39722,openstack/nova,master,I4405407f0f9e20bedbfd714b98492eb9beb39722,initialize objects with context in EC2 object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-07 10:24:55.000000000,2015-01-06 23:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c2b07cfac4778d2ba33203a7591c432e17f54fc', 'message': ""initialize objects with context in EC2 object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I4405407f0f9e20bedbfd714b98492eb9beb39722\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': ['nova/tests/unit/objects/test_ec2.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/04199878011f676709cbbc4ac8e43bc2f6e1fb46', 'message': ""initialize objects with context in EC2 object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I4405407f0f9e20bedbfd714b98492eb9beb39722\n""}]",0,142275,04199878011f676709cbbc4ac8e43bc2f6e1fb46,17,7,2,4690,,,0,"initialize objects with context in EC2 object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: I4405407f0f9e20bedbfd714b98492eb9beb39722
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/142275/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_ec2.py'],1,9c2b07cfac4778d2ba33203a7591c432e17f54fc,bp/kilo-objects, imap = ec2_obj.EC2InstanceMapping(context=self.context) imap.create() vmap = ec2_obj.EC2VolumeMapping(context=self.context) vmap.create() smap = ec2_obj.EC2SnapshotMapping(context=self.context) smap.create() s3imap = ec2_obj.S3ImageMapping(context=self.context) s3imap.create(), imap = ec2_obj.EC2InstanceMapping() imap.create(self.context) vmap = ec2_obj.EC2VolumeMapping() vmap.create(self.context) smap = ec2_obj.EC2SnapshotMapping() smap.create(self.context) s3imap = ec2_obj.S3ImageMapping() s3imap.create(self.context),8,8
openstack%2Fneutron~master~I17cbc1ba59131bd3bdefa232800842a9e739945f,openstack/neutron,master,I17cbc1ba59131bd3bdefa232800842a9e739945f,VMWare-NSXv: VMWare NSXv database models,MERGED,2014-12-25 10:28:27.000000000,2015-01-07 10:18:07.000000000,2015-01-06 22:31:46.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7249}, {'_account_id': 7317}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13438}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-25 10:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cce1d6d15a81dd40d5a0bb2bde96a80f1ea9153e', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nThis is part of the blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 2, 'created': '2014-12-25 11:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c91fa0a48b262aeded37db4e201ff09f1db475d', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nThis is part of the blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 3, 'created': '2014-12-25 12:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3724f5adb2bb2ac124eb5298bcc4a8ced174784b', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 4, 'created': '2014-12-25 13:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/986329ef029b68ab36b200460149382d029617c9', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 5, 'created': '2014-12-28 09:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/043b535d741f33024761d991a441b4b916be6b4b', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 6, 'created': '2014-12-29 10:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5bf01fb6d7706b7c06882e56adc2aed318b56450', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 7, 'created': '2014-12-30 15:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b5ee81cac7dd27a3cc27a894cdccf008a510a1a', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 8, 'created': '2014-12-30 16:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5cce43d41d18cfe8530028943ea4796e1ad95647', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 9, 'created': '2014-12-31 14:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d8d52f3f70ea3f15554ebb28ef481852b957179', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 10, 'created': '2014-12-31 14:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/839cda311798c938470ed9b2a7ba7b5360390b55', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 11, 'created': '2014-12-31 16:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01ad210fbb180c4f5ee3433473e4a7dcc83f91a3', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 12, 'created': '2015-01-06 07:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/090008f0be90523f592f2080483a8448e01225ed', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 13, 'created': '2015-01-06 08:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db640c5281a911e8b1c261803781c1a96d606993', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}, {'number': 14, 'created': '2015-01-06 12:13:43.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/4dbe243cd84d_nsxv.py', 'neutron/db/migration/models/head.py', 'neutron/plugins/vmware/common/nsxv_constants.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/vmware/dbexts/nsxv_models.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/93bf7a02d4ece28bdfb88c852b8557a50017361d', 'message': 'VMWare-NSXv: VMWare NSXv database models\n\nFor Kilo, the vendor-specific code should be moved to stackforge repo,\nexcluding the database models (https://review.openstack.org/#/c/134680/).\nThis patch adds the database model for VMWare NSXv plugin from\nstackforge/vmware-nsx repo.\n\nPartially-Implements: blueprint vmware-nsx-v\n\nChange-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f\n'}]",69,143949,93bf7a02d4ece28bdfb88c852b8557a50017361d,258,29,14,13438,,,0,"VMWare-NSXv: VMWare NSXv database models

For Kilo, the vendor-specific code should be moved to stackforge repo,
excluding the database models (https://review.openstack.org/#/c/134680/).
This patch adds the database model for VMWare NSXv plugin from
stackforge/vmware-nsx repo.

Partially-Implements: blueprint vmware-nsx-v

Change-Id: I17cbc1ba59131bd3bdefa232800842a9e739945f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/143949/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/plugins/vmware/dbexts/nsxv_constants.py', 'neutron/db/migration/alembic_migrations/versions/3da1335f4787_nsxv.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/vmware/dbexts/nsxv_models.py']",5,cce1d6d15a81dd40d5a0bb2bde96a80f1ea9153e,bp/vmware-nsx-v,"# Copyright 2013 VMware, Inc. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sqlalchemy as sa from sqlalchemy import orm from neutron.db import l3_db from neutron.db import model_base from neutron.db import models_v2 from neutron.plugins.vmware.dbexts import nsxv_constants class NsxvRouterBinding(model_base.BASEV2, models_v2.HasStatusDescription): """"""Represents the mapping between neutron router and vShield Edge."""""" __tablename__ = 'nsxv_router_bindings' # no ForeignKey to routers.id because for now, a router can be removed # from routers when delete_router is executed, but the binding is only # removed after the Edge is deleted router_id = sa.Column(sa.String(36), primary_key=True) edge_id = sa.Column(sa.String(16), nullable=True) lswitch_id = sa.Column(sa.String(36), nullable=True) appliance_size = sa.Column(sa.Enum(nsxv_constants.COMPACT, nsxv_constants.LARGE, nsxv_constants.XLARGE, nsxv_constants.QUADLARGE)) edge_type = sa.Column(sa.Enum(nsxv_constants.SERVICE_EDGE, nsxv_constants.VDR_EDGE)) class NsxvEdgeVnicBinding(model_base.BASEV2): """"""Represents mapping between vShield Edge vnic and neutron netowrk."""""" __tablename__ = 'nsxv_edge_vnic_bindings' # every edge has at most 10 availiable vnics for network mapping edge_id = sa.Column(sa.String(36), primary_key=True) vnic_index = sa.Column(sa.Integer(), primary_key=True) tunnel_index = sa.Column(sa.Integer(), primary_key=True) network_id = sa.Column(sa.String(36), nullable=True) class NsxvEdgeDhcpStaticBinding(model_base.BASEV2): """"""Represents mapping between mac addr and bindingId."""""" __tablename__ = 'nsxv_edge_dhcp_static_bindings' edge_id = sa.Column(sa.String(36), primary_key=True) mac_address = sa.Column(sa.String(32), primary_key=True) binding_id = sa.Column(sa.String(36), nullable=False) class NsxvInternalNetworks(model_base.BASEV2): """"""Represents internal networks between NSXV plugin elements."""""" __tablename__ = 'nsxv_internal_networks' network_purpose = sa.Column( sa.Enum(nsxv_constants.InternalEdgePurposes.INTER_EDGE_PURPOSE), primary_key=True) network_id = sa.Column(sa.String(36), nullable=False) class NsxvInternalEdges(model_base.BASEV2): """"""Represents internal Edge appliances for NSXV plugin operations."""""" __tablename__ = 'nsxv_internal_edges' ext_ip_address = sa.Column(sa.String(64), primary_key=True) router_id = sa.Column(sa.String(36), nullable=False) purpose = sa.Column( sa.Enum(nsxv_constants.InternalEdgePurposes.INTER_EDGE_PURPOSE)) class NsxvSectionMapping(model_base.BASEV2): """"""Backend mappings for Neutron Rule Sections. This class maps a neutron security group identifier to the corresponding NSX layer 3 and layer 2 sections. """""" __tablename__ = 'nsxv_section_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('securitygroups.id', ondelete=""CASCADE""), primary_key=True) ip_section_id = sa.Column(sa.String(100)) mac_section_id = sa.Column(sa.String(100)) class NsxvRuleMapping(model_base.BASEV2): """"""Backend mappings for Neutron Rule Sections. This class maps a neutron security group identifier to the corresponding NSX layer 3 and layer 2 sections. """""" __tablename__ = 'nsxv_rule_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('securitygrouprules.id', ondelete=""CASCADE""), primary_key=True) nsx_rule_id = sa.Column(sa.String(36), primary_key=True) class NsxvPortVnicMapping(model_base.BASEV2): """"""Maps neutron port to NSXv VM Vnic Id."""""" __tablename__ = 'nsxv_port_vnic_mappings' neutron_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) nsx_id = sa.Column(sa.String(42), primary_key=True) class NsxvRouterExtAttributes(model_base.BASEV2): """"""Router attributes managed by NSX plugin extensions."""""" router_id = sa.Column(sa.String(36), sa.ForeignKey('routers.id', ondelete=""CASCADE""), primary_key=True) distributed = sa.Column(sa.Boolean, default=False, nullable=False) exclusive = sa.Column(sa.Boolean, default=False, nullable=False) service_router = sa.Column(sa.Boolean, default=False, nullable=False) # Add a relationship to the Router model in order to instruct # SQLAlchemy to eagerly load this association router = orm.relationship( l3_db.Router, backref=orm.backref(""nsx_attributes"", lazy='joined', uselist=False, cascade='delete')) class NsxvTzNetworkBinding(model_base.BASEV2): """"""Represents a binding of a virtual network with a transport zone. This model class associates a Neutron network with a transport zone; optionally a vlan ID might be used if the binding type is 'bridge' """""" __tablename__ = 'nsxv_tz_network_bindings' # TODO(arosen) - it might be worth while refactoring the how this data # is stored later so every column does not need to be a primary key. network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete=""CASCADE""), primary_key=True) # 'flat', 'vlan', stt' or 'gre' binding_type = sa.Column(sa.Enum('flat', 'vlan', 'portgroup', name='tz_network_bindings_binding_type'), nullable=False, primary_key=True) phy_uuid = sa.Column(sa.String(36), primary_key=True, nullable=True) vlan_id = sa.Column(sa.Integer, primary_key=True, nullable=True, autoincrement=False) def __init__(self, network_id, binding_type, phy_uuid, vlan_id): self.network_id = network_id self.binding_type = binding_type self.phy_uuid = phy_uuid self.vlan_id = vlan_id def __repr__(self): return ""<NetworkBinding(%s,%s,%s,%s)>"" % (self.network_id, self.binding_type, self.phy_uuid, self.vlan_id) class NsxvPortIndexMapping(model_base.BASEV2): """"""Associates attached Neutron ports with the instance VNic index."""""" __tablename__ = 'nsxv_port_index_mappings' port_id = sa.Column(sa.String(36), sa.ForeignKey('ports.id', ondelete=""CASCADE""), primary_key=True) device_id = sa.Column(sa.String(255), nullable=False) index = sa.Column(sa.Integer, nullable=False) __table_args__ = (sa.UniqueConstraint(device_id, index),) # Add a relationship to the Port model in order to instruct SQLAlchemy to # eagerly read port vnic-index port = orm.relationship( models_v2.Port, backref=orm.backref(""vnic_index"", lazy='joined', uselist=False, cascade='delete')) class NsxvEdgeFirewallRuleBinding(model_base.BASEV2): """"""1:1 mapping between firewall rule and edge firewall rule_id."""""" __tablename__ = 'nsxv_firewall_rule_bindings' rule_id = sa.Column(sa.String(36), primary_key=True) edge_id = sa.Column(sa.String(36), primary_key=True) rule_vseid = sa.Column(sa.String(36)) class NsxvSpoofGuardPolicyNetworkMapping(model_base.BASEV2): __tablename__ = 'nsxv_spoofguard_policy_network_mappings' network_id = sa.Column(sa.String(36), sa.ForeignKey('networks.id', ondelete='CASCADE'), primary_key=True, nullable=False) policy_id = sa.Column(sa.String(36), nullable=False) ",,683,1
openstack%2Fheat~stable%2Fjuno~I4a0e51ff649aaaad5f18f52383dab186dab54230,openstack/heat,stable/juno,I4a0e51ff649aaaad5f18f52383dab186dab54230,Fix error msg invalid stack or res name,MERGED,2014-12-16 12:50:41.000000000,2015-01-07 10:15:32.000000000,2015-01-07 10:15:30.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-16 12:50:41.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/test_parser.py', 'heat/engine/stack.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bbf71825604b6d165e1d97fc875ed01f5d6a1cc8', 'message': ""Fix error msg invalid stack or res name\n\nIf template contains resource with name like\n'res/name', we will get traceback instead of\ncorrect error message. The same situation with\nstack name: if it's incorrect, we will get\ntraceback.\n\nChange-Id: I4a0e51ff649aaaad5f18f52383dab186dab54230\nCloses-bug: #1397313\n(cherry picked from commit 9c877f3172fca65619b1b50bd327b30541cdc439)\n""}]",0,142093,bbf71825604b6d165e1d97fc875ed01f5d6a1cc8,20,8,1,6577,,,0,"Fix error msg invalid stack or res name

If template contains resource with name like
'res/name', we will get traceback instead of
correct error message. The same situation with
stack name: if it's incorrect, we will get
traceback.

Change-Id: I4a0e51ff649aaaad5f18f52383dab186dab54230
Closes-bug: #1397313
(cherry picked from commit 9c877f3172fca65619b1b50bd327b30541cdc439)
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/142093/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/test_parser.py', 'heat/engine/stack.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py']",5,bbf71825604b6d165e1d97fc875ed01f5d6a1cc8,bug/1397313," def test_resource_invalid_name(self): snippet = rsrc_defn.ResourceDefinition('wrong/name', 'GenericResourceType') ex = self.assertRaises(exception.StackValidationFailed, resource.Resource, 'wrong/name', snippet, self.stack) self.assertEqual('Resource name may not contain ""/""', six.text_type(ex)) ",,32,41
openstack%2Fmanila~master~I7f1bb8e0f6eecde37a0c9ac16ca84d0629e843b2,openstack/manila,master,I7f1bb8e0f6eecde37a0c9ac16ca84d0629e843b2,Fix using anyjson in fake_notifier,MERGED,2014-12-28 17:21:15.000000000,2015-01-07 10:10:24.000000000,2015-01-07 10:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-28 17:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/04f10f771f9128731e47d555dfe40dbd4a83dd98', 'message': 'Fix using anyjson in fake_notifier\n\nFor some reason we were using anyjson.serialize() in our fake_notifier.\nThat may have been to mirror kombu, but really we need to mirror\nwhat we do when we convert our payloads to primitives, which is using\njsonutils.\nanyjson is then no longer needed as a requirement.\n\nChange-Id: I7f1bb8e0f6eecde37a0c9ac16ca84d0629e843b2\n'}, {'number': 2, 'created': '2015-01-06 18:16:00.000000000', 'files': ['requirements.txt', 'manila/tests/fake_notifier.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/a26022e62be88b50d8f2febf1e5215935d0e4435', 'message': 'Fix using anyjson in fake_notifier\n\nFor some reason we were using anyjson.serialize() in our fake_notifier.\nThat may have been to mirror kombu, but really we need to mirror\nwhat we do when we convert our payloads to primitives, which is using\njsonutils.\nanyjson is then no longer needed as a requirement.\n\nChange-Id: I7f1bb8e0f6eecde37a0c9ac16ca84d0629e843b2\n'}]",0,144233,a26022e62be88b50d8f2febf1e5215935d0e4435,18,8,2,7102,,,0,"Fix using anyjson in fake_notifier

For some reason we were using anyjson.serialize() in our fake_notifier.
That may have been to mirror kombu, but really we need to mirror
what we do when we convert our payloads to primitives, which is using
jsonutils.
anyjson is then no longer needed as a requirement.

Change-Id: I7f1bb8e0f6eecde37a0c9ac16ca84d0629e843b2
",git fetch https://review.opendev.org/openstack/manila refs/changes/33/144233/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'manila/tests/fake_notifier.py']",2,04f10f771f9128731e47d555dfe40dbd4a83dd98,144233,from oslo.serialization import jsonutils jsonutils.to_primitive(payload),import anyjson anyjson.serialize(payload),2,3
openstack%2Fgnocchi~master~I392da77c03ffdd4df346996c4b75106d3878c9fd,openstack/gnocchi,master,I392da77c03ffdd4df346996c4b75106d3878c9fd,Remove py33-postgresql,MERGED,2014-12-31 16:00:16.000000000,2015-01-07 10:10:05.000000000,2015-01-07 10:10:05.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-31 16:00:16.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/dae79def0d98b2c008a4d0fa1678d4224770dd7f', 'message': ""Remove py33-postgresql\n\nIt's not used and has a wrong basepython.\n\nChange-Id: I392da77c03ffdd4df346996c4b75106d3878c9fd\n""}]",0,144643,dae79def0d98b2c008a4d0fa1678d4224770dd7f,6,2,1,1669,,,0,"Remove py33-postgresql

It's not used and has a wrong basepython.

Change-Id: I392da77c03ffdd4df346996c4b75106d3878c9fd
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/43/144643/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dae79def0d98b2c008a4d0fa1678d4224770dd7f,jd/remove-py33,,"[testenv:py33-postgresql] deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements-py3.txt basepython = python3.4 commands = {toxinidir}/setup-postgresql-tests.sh python setup.py testr --slowest --testr-args=""{posargs}"" ",0,6
openstack%2Ffuel-library~master~Ib827c08f90dfd50251965b624d698c46d7fb08e0,openstack/fuel-library,master,Ib827c08f90dfd50251965b624d698c46d7fb08e0,Allow haproxy to work with PKI,MERGED,2014-12-24 17:01:19.000000000,2015-01-07 09:50:34.000000000,2015-01-07 09:50:34.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7244}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-12-24 17:01:19.000000000', 'files': ['deployment/puppet/cluster/manifests/haproxy.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/49ee42154e98729d268985fe322aa4f00c0ac46d', 'message': 'Allow haproxy to work with PKI\n\nAllow haproxy to work with PKI\ntokens in keystone v3\n\nChange-Id: Ib827c08f90dfd50251965b624d698c46d7fb08e0\nCloses-Bug: 1372655\n'}]",0,143878,49ee42154e98729d268985fe322aa4f00c0ac46d,14,8,1,13344,,,0,"Allow haproxy to work with PKI

Allow haproxy to work with PKI
tokens in keystone v3

Change-Id: Ib827c08f90dfd50251965b624d698c46d7fb08e0
Closes-Bug: 1372655
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/78/143878/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cluster/manifests/haproxy.pp'],1,49ee42154e98729d268985fe322aa4f00c0ac46d,bug/1372655," $haproxy_maxconn = '4000', $haproxy_bufsize = '16384', $haproxy_maxrewrite = '1024', 'log' => '/dev/log local0', 'pidfile' => '/var/run/haproxy.pid', 'maxconn' => $haproxy_maxconn, 'user' => 'haproxy', 'group' => 'haproxy', 'daemon' => '', 'stats' => 'socket /var/lib/haproxy/stats', 'tune.bufsize' => $haproxy_bufsize, 'tune.maxrewrite' => $haproxy_maxrewrite,"," $haproxy_maxconn = '4000', $haproxy_bufsize = '16384', 'log' => '/dev/log local0', 'pidfile' => '/var/run/haproxy.pid', 'maxconn' => $haproxy_maxconn, 'user' => 'haproxy', 'group' => 'haproxy', 'daemon' => '', 'stats' => 'socket /var/lib/haproxy/stats', 'tune.bufsize' => $haproxy_bufsize,",12,10
openstack%2Ffuel-library~master~Ifef25a02f7b9bf098b50d3a81269116874e1ee66,openstack/fuel-library,master,Ifef25a02f7b9bf098b50d3a81269116874e1ee66,Enable events in ceilometer,MERGED,2014-12-19 14:37:42.000000000,2015-01-07 09:49:46.000000000,2015-01-07 09:49:46.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6926}, {'_account_id': 7126}, {'_account_id': 7195}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-19 14:37:42.000000000', 'files': ['deployment/puppet/openstack/manifests/ceilometer.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f4b7ffad407cdf2b3608fb05e7aa8a7263c44306', 'message': 'Enable events in ceilometer\n\nChange-Id: Ifef25a02f7b9bf098b50d3a81269116874e1ee66\nCloses-bug: #1404185\n'}]",0,143100,f4b7ffad407cdf2b3608fb05e7aa8a7263c44306,14,8,1,7732,,,0,"Enable events in ceilometer

Change-Id: Ifef25a02f7b9bf098b50d3a81269116874e1ee66
Closes-bug: #1404185
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/00/143100/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/ceilometer.pp'],1,f4b7ffad407cdf2b3608fb05e7aa8a7263c44306,bug/1404185," class { '::ceilometer::agent::notification': store_events => true, }", class { '::ceilometer::agent::notification': },3,1
openstack%2Fnova~master~I82671546e40dbb06a2854d6ff6448beab7bbd763,openstack/nova,master,I82671546e40dbb06a2854d6ff6448beab7bbd763,Deal with neutron and nova-network data formats,ABANDONED,2014-10-14 13:51:50.000000000,2015-01-07 09:48:12.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 935}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6450}, {'_account_id': 6873}, {'_account_id': 8788}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-10-14 13:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/907ef181c842a8c117e49a74ce408c0396ce045c', 'message': ""Align floating ip view to underlying data\n\nThe data structure of floating_ip has changed; re-align the code\nto query the right keys, ensuring that server id's are correctly\ndisplayed when using 'nova floating-ip-list'.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 2, 'created': '2014-10-14 15:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43d41ec4aed7e10451bced9522920507fc376f80', 'message': ""Align floating ip view to underlying data\n\nThe data structure of floating_ip has changed; re-align the code\nto query the right keys, ensuring that server id's are correctly\ndisplayed when using 'nova floating-ip-list'.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 3, 'created': '2014-10-16 08:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78cd76adfae9e080ca59ce90fdc97d14ba591d60', 'message': ""Deal with neutron and nova-network data formats\n\nThe Floating IP model returned via the Neutron v2 API is different to\nthat provided by the nova-network API; check to see if instance uuid\nis present in the top level of the Floating IP data and use that if\nfound.\n\nResolves missing server uuids in 'nova floating-ip-list'.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 4, 'created': '2014-10-16 08:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b40fc8b18d0294ca68cc53aaea158bf622371cf', 'message': ""Deal with neutron and nova-network data formats\n\nThe Floating IP model returned via the Neutron v2 API is different to\nthat provided by the Nova Network API; check to see if instance uuid\nis present in the top level of the Floating IP data and use that if\nfound.\n\nResolves missing server uuids in 'nova floating-ip-list' when used\nwith Neutron networking.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 5, 'created': '2014-11-13 12:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6b839da14c7e09df794e4c3dc3ac8ea19cbd176', 'message': ""Deal with neutron and nova-network data formats\n\nThe Floating IP model returned via the Neutron v2 API is different to\nthat provided by the Nova Network API; check to see if instance uuid\nis present in the top level of the Floating IP data and use that if\nfound.\n\nResolves missing server uuids in 'nova floating-ip-list' when used\nwith Neutron networking.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 6, 'created': '2014-12-09 14:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9dc055d93a008f057df11ab388b38f97c1933fe2', 'message': ""Deal with neutron and nova-network data formats\n\nThe Floating IP model returned via the Neutron v2 API is different to\nthat provided by the Nova Network API; check to see if instance uuid\nis present in the top level of the Floating IP data and use that if\nfound.\n\nResolves missing server uuids in 'nova floating-ip-list' when used\nwith Neutron networking.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 7, 'created': '2014-12-09 16:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e996235168f48c7802004c33fc6e8665c6d6f629', 'message': ""Deal with neutron and nova-network data formats\n\nThe Floating IP model returned via the Neutron v2 API is different to\nthat provided by the Nova Network API; check to see if instance uuid\nis present in the top level of the Floating IP data and use that if\nfound.\n\nResolves missing server uuids in 'nova floating-ip-list' when used\nwith Neutron networking.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}, {'number': 8, 'created': '2015-01-06 09:41:12.000000000', 'files': ['nova/api/openstack/compute/contrib/floating_ips.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ips.py', 'nova/api/openstack/compute/plugins/v3/floating_ips.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/09715cd41783b1c10d74dd56ffe06e704747c2cd', 'message': ""Deal with neutron and nova-network data formats\n\nThe Floating IP model returned via the Neutron v2 API is different to\nthat provided by the Nova Network API; check to see if instance uuid\nis present in the top level of the Floating IP data and use that if\nfound.\n\nResolves missing server uuids in 'nova floating-ip-list' when used\nwith Neutron networking.\n\nChange-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763\nCloses-Bug: #1380965\n""}]",4,128293,09715cd41783b1c10d74dd56ffe06e704747c2cd,78,17,8,935,,,0,"Deal with neutron and nova-network data formats

The Floating IP model returned via the Neutron v2 API is different to
that provided by the Nova Network API; check to see if instance uuid
is present in the top level of the Floating IP data and use that if
found.

Resolves missing server uuids in 'nova floating-ip-list' when used
with Neutron networking.

Change-Id: I82671546e40dbb06a2854d6ff6448beab7bbd763
Closes-Bug: #1380965
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/128293/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/floating_ips.py'],1,907ef181c842a8c117e49a74ce408c0396ce045c,bug/1380965, result['instance_id'] = floating_ip['instance']['uuid'], result['instance_id'] = floating_ip['fixed_ip']['instance_uuid'],1,1
openstack%2Ftricircle~master~I547111874c42e41599eb0b031fc68b3eb5897c40,openstack/tricircle,master,I547111874c42e41599eb0b031fc68b3eb5897c40,refresh README.md and install script,MERGED,2015-01-07 09:44:23.000000000,2015-01-07 09:47:03.000000000,2015-01-07 09:47:03.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2015-01-07 09:44:23.000000000', 'files': ['juno-patches/cinder/timestamp-query-patch/README.md', 'cinderproxy/README.md', 'cinderproxy/installation/install.sh'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/3dc060db63eb97c017746c88dcba7a805452e543', 'message': 'refresh README.md and install script\n\nChange-Id: I547111874c42e41599eb0b031fc68b3eb5897c40\n'}]",0,145448,3dc060db63eb97c017746c88dcba7a805452e543,6,2,1,13924,,,0,"refresh README.md and install script

Change-Id: I547111874c42e41599eb0b031fc68b3eb5897c40
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/48/145448/1 && git format-patch -1 --stdout FETCH_HEAD,"['juno-patches/cinder/timestamp-query-patch/README.md', 'cinderproxy/README.md', 'cinderproxy/installation/install.sh']",3,3dc060db63eb97c017746c88dcba7a805452e543,master,"_CINDER_CONF_OPTION=(""volume_manager=cinder.volume.cinder_proxy.CinderProxy volume_sync_interval=5 voltype_sync_interval=3600 periodic_interval=5 volume_sync_timestamp_flag=True cinder_tenant_name=admin cinder_tenant_id=1234 pagination_limit=50 cinder_username=admin cinder_password=1234 keystone_auth_url=http://10.67.148.210:5000/v2.0/ glance_cascading_flag=False cascading_glance_url=10.67.148.210:9292 cascaded_glance_url=http://10.67.148.201:9292 cascaded_cinder_url=http://10.67.148.201:8776/v2/%(project_id)s cascaded_region_name=Region_AZ1 cascaded_available_zone=AZ1"")","_CINDER_CONF_OPTION=(""volume_manager=cinder.volume.cinder_proxy.CinderProxy volume_sync_interval=5 voltype_sync_interval=3600 periodic_interval=5 cinder_tenant_name=admin cinder_tenant_id=1234 pagination_limit=50 cinder_username=admin cinder_password=1234 keystone_auth_url=http://10.67.148.210:5000/v2.0/ glance_cascading_flag=False cascading_glance_url=10.67.148.210:9292 cascaded_glance_url=http://10.67.148.201:9292 cascaded_cinder_url=http://10.67.148.201:8776/v2/%(project_id)s cascaded_region_name=Region_AZ1 cascaded_available_zone=AZ1"")",59,17
openstack%2Fheat~master~I80b5b8969007319e9a8fa1d104f4eb4fcbf7ebad,openstack/heat,master,I80b5b8969007319e9a8fa1d104f4eb4fcbf7ebad,Add a strict_validate flag to Stacks,MERGED,2015-01-02 21:25:28.000000000,2015-01-07 09:21:12.000000000,2015-01-07 09:21:10.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7256}]","[{'number': 1, 'created': '2015-01-02 21:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f74e1d1274bed670399a481a4286c0467c8ba3d5', 'message': 'Add a strict_validate flag to Stacks\n\nEnables optionally disabling strict validation, which atm just\ndisables the value part of properties validation.\n\nThis is needed for a similar reason to bug #1347571, which\nconditionally disables value validation when inter-resource\nreferences cause a default pre-create value to be evaluated by\na custom constraint (e.g the default resource name returned by\nget_resource until a resource is actually created).\n\nThis flag enables a similar fix for StackResource, so we avoid\nstrictly validating before create, otherwise the nested stack\nvalidation fails when the default resource name is passed in\nduring validation, even though create-time validation would succeed.\n\nChange-Id: I80b5b8969007319e9a8fa1d104f4eb4fcbf7ebad\nPartial-Bug: #1407100\n'}, {'number': 2, 'created': '2015-01-06 09:34:12.000000000', 'files': ['heat/engine/stack.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/35853f5223bd91e76b2064bc47b04c0caccaed6b', 'message': 'Add a strict_validate flag to Stacks\n\nEnables optionally disabling strict validation, which atm just\ndisables the value part of properties validation.\n\nThis is needed for a similar reason to bug #1347571, which\nconditionally disables value validation when inter-resource\nreferences cause a default pre-create value to be evaluated by\na custom constraint (e.g the default resource name returned by\nget_resource until a resource is actually created).\n\nThis flag enables a similar fix for StackResource, so we avoid\nstrictly validating before create, otherwise the nested stack\nvalidation fails when the default resource name is passed in\nduring validation, even though create-time validation would succeed.\n\nChange-Id: I80b5b8969007319e9a8fa1d104f4eb4fcbf7ebad\nPartial-Bug: #1407100\n'}]",0,144804,35853f5223bd91e76b2064bc47b04c0caccaed6b,13,4,2,4328,,,0,"Add a strict_validate flag to Stacks

Enables optionally disabling strict validation, which atm just
disables the value part of properties validation.

This is needed for a similar reason to bug #1347571, which
conditionally disables value validation when inter-resource
references cause a default pre-create value to be evaluated by
a custom constraint (e.g the default resource name returned by
get_resource until a resource is actually created).

This flag enables a similar fix for StackResource, so we avoid
strictly validating before create, otherwise the nested stack
validation fails when the default resource name is passed in
during validation, even though create-time validation would succeed.

Change-Id: I80b5b8969007319e9a8fa1d104f4eb4fcbf7ebad
Partial-Bug: #1407100
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/144804/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/stack.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py']",3,f74e1d1274bed670399a481a4286c0467c8ba3d5,bug/1407100," def test_validate_value_fail(self): tmpl = template.Template({ 'heat_template_version': '2013-05-23', 'resources': { 'bar': { 'type': 'ResourceWithPropsType', 'properties': { 'FooInt': 'notanint', } } } }) stack = parser.Stack(utils.dummy_context(), 'test', tmpl) ex = self.assertRaises(exception.StackValidationFailed, stack.validate) expected = ""FooInt Value 'notanint' is not an integer"" self.assertIn(expected, six.text_type(ex)) # You can turn off value validation via strict_validate stack_novalidate = parser.Stack(utils.dummy_context(), 'test', tmpl, strict_validate=False) self.assertIsNone(stack_novalidate.validate()) ",,26,2
openstack%2Fheat~master~Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2,openstack/heat,master,Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2,Need to call _delete_resource() anyway for sd deletion,MERGED,2014-12-31 07:42:49.000000000,2015-01-07 09:03:38.000000000,2015-01-07 09:03:37.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-12-31 07:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/60fec3fdffa881c5079e990d9c53ae9a7a108f6e', 'message': 'Need to call _delete_resource() anyway\n\nIf there is no need to wait for the result\nof deployment, we should delete the resources\ninclude the credentials and the software deployment\nitself.\n\nChange-Id: Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2\nCloses-Bug: #1406718\n'}, {'number': 2, 'created': '2014-12-31 07:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ea225b3ca0c18e52891630c0226c91ff84920784', 'message': 'Need to call _delete_resource() anyway for sd deletion\n\nIf there is no need to wait for the result\nof deployment, we should delete the resources\ninclude the credentials and the software deployment\nitself.\n\nChange-Id: Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2\nCloses-Bug: #1406718\n'}, {'number': 3, 'created': '2015-01-04 08:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/42b418e66b377410abfcf7ddb067bbede1bf964c', 'message': 'Need to call _delete_resource() anyway for sd deletion\n\nIf there is no need to wait for the result\nof deployment, we should delete the resources\ninclude the credentials and the software deployment\nitself.\n\nChange-Id: Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2\nCloses-Bug: #1406718\n'}, {'number': 4, 'created': '2015-01-06 07:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa47640e39de07d68b11f714010843a677856ad2', 'message': 'Need to call _delete_resource() anyway for sd deletion\n\nIf there is no need to wait for the result\nof deployment, we should delete the resources\ninclude the credentials and the software deployment\nitself.\n\nChange-Id: Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2\nCloses-Bug: #1406718\n'}, {'number': 5, 'created': '2015-01-07 03:24:19.000000000', 'files': ['heat/tests/test_software_deployment.py', 'heat/engine/resources/software_config/software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/25fbb17756ae17f6cf98b1d09fbc21e59f414bf5', 'message': 'Need to call _delete_resource() anyway for sd deletion\n\nIf there is no need to wait for the result\nof deployment, we should delete the resources\ninclude the credentials and the software deployment\nitself.\n\nChange-Id: Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2\nCloses-Bug: #1406718\n'}]",0,144593,25fbb17756ae17f6cf98b1d09fbc21e59f414bf5,33,7,5,8289,,,0,"Need to call _delete_resource() anyway for sd deletion

If there is no need to wait for the result
of deployment, we should delete the resources
include the credentials and the software deployment
itself.

Change-Id: Ief7b8067d34d43ebe47d337cc61e77c21fdbdec2
Closes-Bug: #1406718
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/144593/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_software_deployment.py', 'heat/engine/resources/software_config/software_deployment.py']",2,60fec3fdffa881c5079e990d9c53ae9a7a108f6e,bug/1406718, if not sd or self._check_complete():, if not sd: return True if self._check_complete():,14,3
openstack%2Ftraining-guides~master~Iedd14c6666b6072b79545082afd8e39d1011ffbf,openstack/training-guides,master,Iedd14c6666b6072b79545082afd8e39d1011ffbf,Ignore <option> tags in generatepot,MERGED,2015-01-01 12:40:55.000000000,2015-01-07 09:02:09.000000000,2015-01-07 09:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2015-01-01 12:40:55.000000000', 'files': ['tools/generatepot'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8530311ff82b3d51a471ddef28c2a7658531b523', 'message': 'Ignore <option> tags in generatepot\n\nAfter https://review.openstack.org/#/c/144685 merges,\nthe automatically generated configuration reference\ntables will be marked up as\n<option>option_name</option> = <replaceable>default_value</replaceable>\n\nAs none of this should be translated (option_name is the same\nregardless of language), this patch updates generatepot to ignore\noption_name s tagged with <option> for translation.\n\nThis should significantly reduce the number of strings required for\ntranslation from the common directory in particular, where\nmany of the 8000-odd strings do not actually need translation.\n\nChange-Id: Iedd14c6666b6072b79545082afd8e39d1011ffbf\n'}]",0,144692,8530311ff82b3d51a471ddef28c2a7658531b523,10,5,1,612,,,0,"Ignore <option> tags in generatepot

After https://review.openstack.org/#/c/144685 merges,
the automatically generated configuration reference
tables will be marked up as
<option>option_name</option> = <replaceable>default_value</replaceable>

As none of this should be translated (option_name is the same
regardless of language), this patch updates generatepot to ignore
option_name s tagged with <option> for translation.

This should significantly reduce the number of strings required for
translation from the common directory in particular, where
many of the 8000-odd strings do not actually need translation.

Change-Id: Iedd14c6666b6072b79545082afd8e39d1011ffbf
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/92/144692/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/generatepot'],1,8530311ff82b3d51a471ddef28c2a7658531b523,ignore-option-in-generatepot," 'screenshot','literallayout', 'programlisting', 'option' ]"," 'screenshot','literallayout', 'programlisting' ]",2,1
openstack%2Fceilometer~master~I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532,openstack/ceilometer,master,I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532,Publish samples on other threads,ABANDONED,2014-07-29 10:21:53.000000000,2015-01-07 08:42:58.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7729}, {'_account_id': 8052}, {'_account_id': 9061}, {'_account_id': 10068}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-07-29 10:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8d23c079927f75b6e518b0da38ffbf3a43215d1b', 'message': 'Publish samples on other threads.\nThe bug (https://bugs.launchpad.net/ceilometer/+bug/1337761) reports that ""publish_sample"" is a main cause of performance degradation as a result of re-measurement without the ""self.publish_sample()"" execution.\nThe publish_sample publishes samples to pipeline. The sample is sequentially published. A GET/PUT request is published twice and a DELETE request is published once. The performance is degraded with the behavior above. Therefore, publish samples on asynchronous from main thread. The performance is improved by reducing the publishing cost.\nChanges as follows:\n * Create a Greenthread pool.\n * Publish samples on other threads.\n * Manage samples by Queue.\n * Retry when it failed to publish.\n * Add two parameters (publisher_workers, and publisher_expire) to config.\nCloses-Bug: #1337761\n\nChange-Id: I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532\n'}, {'number': 2, 'created': '2014-07-29 11:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c79057f8d72bc9acffd460718797fd773ac0c59b', 'message': 'Publish samples on other threads.\nThe bug (https://bugs.launchpad.net/ceilometer/+bug/1337761) reports that ""publish_sample"" is a main cause of performance degradation as a result of re-measurement without the ""self.publish_sample()"" execution.\nThe publish_sample publishes samples to pipeline. The sample is sequentially published. A GET/PUT request is published twice and a DELETE request is published once. The performance is degraded with the behavior above. \nTherefore, publish samples on asynchronous from main thread. The performance is improved by reducing the publishing cost.\n\nChanges as follows:\n * Create a Greenthread pool.\n * Publish samples on other threads.\n * Manage samples by Queue.\n * Retry when it failed to publish.\n * Add two parameters (publisher_workers, and publisher_expire) to config.\nCloses-Bug: #1337761\n\nChange-Id: I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532\n'}, {'number': 3, 'created': '2014-07-29 11:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ef7e5266bda2e7e2415b636f06dc1f5fe1a56210', 'message': 'Publish samples on other threads.\nThe bug (https://bugs.launchpad.net/ceilometer/+bug/1337761) reports that \n""publish_sample"" is a main cause of performance degradation as a result of\n re-measurement without the ""self.publish_sample()"" execution.\nThe publish_sample publishes samples to pipeline. The sample is sequential\nly published. A GET/PUT request is published twice and a DELETE request is\n published once. The performance is degraded with the behavior above. \nTherefore, publish samples on asynchronous from main thread. The performan\nce is improved by reducing the publishing cost.\n\nChanges as follows:\n * Create a Greenthread pool.\n * Publish samples on other threads.\n * Manage samples by Queue.\n * Retry when it failed to publish.\n * Add two parameters (publisher_workers, and publisher_expire) to config.\nCloses-Bug: #1337761\n\nChange-Id: I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532\n'}, {'number': 4, 'created': '2014-07-29 23:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8e84410445be31f84c500ea64bcddc3d3fc313af', 'message': 'Publish samples on other threads.\n\nThe bug (https://bugs.launchpad.net/ceilometer/+bug/1337761) reports that \n""publish_sample"" is a main cause of performance degradation as a result of\n re-measurement without the ""self.publish_sample()"" execution.\nThe publish_sample publishes samples to pipeline. The sample is sequential\nly published. A GET/PUT request is published twice and a DELETE request is\n published once. The performance is degraded with the behavior above. \nTherefore, publish samples on asynchronous from main thread. The performan\nce is improved by reducing the publishing cost.\n\nChanges as follows:\n * Create a Greenthread pool.\n * Publish samples on other threads.\n * Manage samples by Queue.\n * Retry when it failed to publish.\n * Add two parameters (publisher_workers, and publisher_expire) to config.\nCloses-Bug: #1337761\n\nChange-Id: I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532\n'}, {'number': 5, 'created': '2014-07-30 06:33:41.000000000', 'files': ['ceilometer/objectstore/swift_middleware.py', 'ceilometer/tests/objectstore/test_swift_middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b71820dba76411bfeba6f2089006ca83b702766c', 'message': 'Publish samples on other threads\n\nThe bug (https://bugs.launchpad.net/ceilometer/+bug/1337761) reports that \n""publish_sample"" is a main cause of performance degradation as a result of\n re-measurement without the ""self.publish_sample()"" execution.\nThe publish_sample publishes samples to pipeline. The sample is sequential\nly published. A GET/PUT request is published twice and a DELETE request is\n published once. The performance is degraded with the behavior above. \nTherefore, publish samples on asynchronous from main thread. The performan\nce is improved by reducing the publishing cost.\n\nChanges as follows:\n * Create a Greenthread pool.\n * Publish samples on other threads.\n * Manage samples by Queue.\n * Retry when it failed to publish.\n * Add two parameters (publisher_workers, and publisher_expire) to config.\nCloses-Bug: #1337761\n\nChange-Id: I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532\n'}]",8,110257,b71820dba76411bfeba6f2089006ca83b702766c,25,7,5,12307,,,0,"Publish samples on other threads

The bug (https://bugs.launchpad.net/ceilometer/+bug/1337761) reports that 
""publish_sample"" is a main cause of performance degradation as a result of
 re-measurement without the ""self.publish_sample()"" execution.
The publish_sample publishes samples to pipeline. The sample is sequential
ly published. A GET/PUT request is published twice and a DELETE request is
 published once. The performance is degraded with the behavior above. 
Therefore, publish samples on asynchronous from main thread. The performan
ce is improved by reducing the publishing cost.

Changes as follows:
 * Create a Greenthread pool.
 * Publish samples on other threads.
 * Manage samples by Queue.
 * Retry when it failed to publish.
 * Add two parameters (publisher_workers, and publisher_expire) to config.
Closes-Bug: #1337761

Change-Id: I84fb9f2b4cab8f3f41a4a9d9f008df53f12cc532
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/57/110257/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/objectstore/swift_middleware.py', 'ceilometer/tests/objectstore/test_swift_middleware.py']",2,8d23c079927f75b6e518b0da38ffbf3a43215d1b,bug/1337761,"import time def _get_samples(self, pipelines, samples_len=1): for i in xrange(5): samples = pipelines[0].samples if len(samples) >= samples_len: break time.sleep(0.5) return samples samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 1) samples = self._get_samples(self.pipeline_manager.pipelines, 1) samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 2) samples = self._get_samples(self.pipeline_manager.pipelines, 0) samples = self._get_samples(self.pipeline_manager.pipelines, 0) samples = self._get_samples(self.pipeline_manager.pipelines, 0) _samples = self._get_samples(self.pipeline_manager.pipelines, 1) samples = _samples[0] _samples = self._get_samples(self.pipeline_manager.pipelines, 1) samples = _samples[1] _samples = self._get_samples(self.pipeline_manager.pipelines, 1) samples = _samples[0]", samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples samples = self.pipeline_manager.pipelines[0].samples[0] samples = self.pipeline_manager.pipelines[0].samples[0] samples = self.pipeline_manager.pipelines[0].samples[0],88,48
openstack%2Fneutron~master~Ib5470040c0fa91ec143f38d273e1e259b3adfb2e,openstack/neutron,master,Ib5470040c0fa91ec143f38d273e1e259b3adfb2e,Add support for retargetable functional api testing,MERGED,2014-02-11 08:11:16.000000000,2015-01-07 08:31:18.000000000,2015-01-07 01:25:13.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1192}, {'_account_id': 1923}, {'_account_id': 2035}, {'_account_id': 4395}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 7317}, {'_account_id': 7498}, {'_account_id': 7787}, {'_account_id': 8576}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10354}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-02-11 08:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dfff0a8ea9efb1692467242fc97fdf8a5d94e9ae', 'message': 'Add retargetable api test.\n\nThis change adds a proof-of-concept api test that is targeted\nat the plugin api by default but that can be reused by tempest\ntargeting a live system.  The hope is that api testing can then\nbe maintained in the neutron tree, run as part of the unit tests,\nand not have to be duplicated by tempest.\n\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n'}, {'number': 2, 'created': '2014-02-11 08:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6364b3aa04ae93318b18482d66e60fd474c988e', 'message': 'Add retargetable api test\n\nThis change adds a proof-of-concept api test that is targeted\nat the plugin api by default but that can be reused by tempest\ntargeting a live system.  The hope is that api testing can then\nbe maintained in the neutron tree, run as part of the unit tests,\nand not have to be duplicated by tempest.\n\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n'}, {'number': 3, 'created': '2014-02-11 08:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c4d5825676cbcc40ccad6a5fadd667343a1f214', 'message': 'Add retargetable api test\n\nThis change adds a proof-of-concept api test that is targeted\nat the plugin api by default but that can be reused by tempest\ntargeting a live system.  The hope is that api testing can then\nbe maintained in the neutron tree, run as part of the unit tests,\nand not have to be duplicated by tempest.\n\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n'}, {'number': 4, 'created': '2014-02-11 19:25:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c8f1f3bcc7821d161f94b0f53a01fe42ab05634', 'message': 'Add retargetable api test\n\nThis change adds a proof-of-concept api test that is targeted\nat the plugin api by default but that can be reused by tempest\ntargeting a live system.  The hope is that api testing can then\nbe maintained in the neutron tree, run as part of the unit tests,\nand not have to be duplicated by tempest.\n\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n'}, {'number': 5, 'created': '2014-02-27 07:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3953983ff12665fd3c3caa97df685743bd960b2', 'message': 'Add retargetable api test\n\nThis change adds a proof-of-concept api test that is targeted\nat the plugin api by default but that can be reused by tempest\ntargeting a live system.  The hope is that api testing can then\nbe maintained in the neutron tree, run as part of the unit tests,\nand not have to be duplicated by tempest.\n\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n'}, {'number': 6, 'created': '2014-03-21 18:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19da2b13234f21f05dd31a48d5597a76125b297b', 'message': 'Add retargetable api test\n\nThis change adds a proof-of-concept api test that is targeted\nat the plugin api by default but that can be reused by tempest\ntargeting a live system.  The hope is that api testing can then\nbe maintained in the neutron tree, run as part of the unit tests,\nand not have to be duplicated by tempest.\n\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n'}, {'number': 7, 'created': '2014-03-25 08:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aded1b58d5afe2175a535c351688a4b3d6282445', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest, though, so manual invocation is\nnot recommended.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather that through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: blueprint neutron-testing-refactor\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 8, 'created': '2014-03-25 08:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a5ab0b8606c1120e110c9c24349766eb332d274', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest, though, so manual invocation is\nnot recommended.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather that through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: blueprint neutron-testing-refactor\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 9, 'created': '2014-03-25 11:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d958d6da08ea7241ec4aeaf4c434347ffccd5cf', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest, though, so manual invocation is\nnot recommended.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather that through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: blueprint neutron-testing-refactor\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 10, 'created': '2014-03-25 18:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65dfec41c839143cbc7437376630e0e93b3d56de', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest, though, so manual invocation is\nnot recommended.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather that through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: blueprint neutron-testing-refactor\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 11, 'created': '2014-04-22 22:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a77afaeb6bdc1fb2b17f09755d6ab66829462df', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest, though, so manual invocation is\nnot recommended.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather that through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: blueprint neutron-testing-refactor\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 12, 'created': '2014-04-23 00:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1b4dca9a78b403ecabad7b787f6be85c017594f5', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest, though, so manual invocation is\nnot recommended.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather that through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: blueprint neutron-testing-refactor\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 13, 'created': '2014-08-23 13:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e555ffa31f48c27dd8f1f7a7609d5c83a3bb08f', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 14, 'created': '2014-08-23 18:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5862139b1e364175916f41cf3e80027abba3fc8', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 15, 'created': '2014-08-23 20:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d03d00eba635cf8ac4c7d7127d45dda6b1a2e937', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 16, 'created': '2014-09-11 14:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e47287a00abc25db64201990cd8e14bcaa63f5a', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 17, 'created': '2014-09-12 22:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/747ca1330b4028726de2cc00f10bc9b31cebb5da', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 18, 'created': '2014-09-12 22:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab73abb3364bc68ca55fbbbe98d280f0ce732d5e', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 19, 'created': '2014-10-31 00:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/582f58d443fedddea543b9f907ea54a6c6da07f7', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 20, 'created': '2014-10-31 00:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c048635962ff7f1ba350fe6f5da081664f03987c', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 21, 'created': '2014-10-31 01:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc55872bd5c84b57a5b3877337c27092b4185293', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 22, 'created': '2014-10-31 01:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90f55e7f8f4d6a34979ee33fc8c41f53837b3257', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 23, 'created': '2014-12-02 19:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c831dff625d4be5815b3c56adc78cbd8bfba34b2', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 24, 'created': '2014-12-03 22:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27f9e0fc0885cc8a6064c00a4234a3f1afd117f4', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for both json and xml serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 25, 'created': '2014-12-09 05:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae0099f111cd334fc48a55834931af369c887495', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 26, 'created': '2014-12-09 16:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff4bc5f95acd1e3034a74709e560402b1c1416d6', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 27, 'created': '2014-12-09 20:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e330fb67065d7a1f4998718fa536d7cc10a83d5', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 28, 'created': '2014-12-30 23:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50c6f81b8aacfb225e567045d4a9c4f8be698dfa', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 29, 'created': '2014-12-31 01:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d6185781d1a656e9e2c97ea920dd6eb5317baf9', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via 'tox\n-e functional'.  This will run as part of the check queue by the\nneutron-dsvm-functional job.\n\nThe test can also be run against the Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 30, 'created': '2014-12-31 19:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebb01b4751b7ed8762333a528d3ff6185ca997ad', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via both tox -e functional and tox -e dsvm-functional.  The latter env is used by  the gating neutron-dsvm-functional job.\n\nThe test can also be run against a live Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 31, 'created': '2014-12-31 19:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3e1ccd38ab74505cf4cd7a3327a52f29c0576c4', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via both\ntox -e functional and tox -e dsvm-functional.  The latter env is used \nby the gating neutron-dsvm-functional job.\n\nThe test can also be run against a live Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 32, 'created': '2015-01-06 02:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/493278c89a9cf35099ab61e7b4b5d32274b85f29', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via both\ntox -e functional and tox -e dsvm-functional.  The latter env is used\nby the gating neutron-dsvm-functional job.\n\nThe test can also be run against a live Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}, {'number': 33, 'created': '2015-01-06 02:38:15.000000000', 'files': ['neutron/tests/functional/api/test_v2_plugin.py', 'neutron/tests/api/__init__.py', '.gitignore', 'neutron/tests/functional/agent/linux/base.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/tests/sub_base.py', 'neutron/tests/api/base_v2.py', 'neutron/tests/functional/api/__init__.py', 'tox.ini', 'neutron/tests/api/test_v2_rest.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/501df939a543908554e268ade0c1dc9d12cf11a5', 'message': ""Add support for retargetable functional api testing\n\nThis patch introduces the concept of a 'retargetable' functional api\ntest.  Such a test targets an abstract client class, and by varying\nthe implementation of the client, the test can target multiple\nbackends.\n\nThe test added by this patch (test_network_lifecycle) can be run\nagainst the programmatic plugin api (for configured plugins) via both\ntox -e functional and tox -e dsvm-functional.  The latter env is used\nby the gating neutron-dsvm-functional job.\n\nThe test can also be run against a live Neutron service via 'tox -e api'\nwhich will soon be run as part of the check queue by the\nneutron-dsvm-api job [1].  Running this tox env requires\ndevstack-deployed Neutron and Tempest.\n\nThe intention is to refactor the existing plugin tests\n(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests\ndon't have to isolate functionality - they just need to exercise it -\nso fewer tests will be required.  The new tests will be able to target\nplugins directly rather than through the wsgi stack, so execution time\nwill be decreased.  The refactored tests should be easier to maintain\nand take less time to run.\n\nPerhaps best of all, since the same tests will be able to target a\ndeployed service in the neutron-dsvm-api job, the deployed behaviour\nof api changes will finally be able to gate merges to the Neutron\ntree.\n\nNotable parts of the change:\n\n- tests/api\n  - base_v2 -      defines the client interface (BaseNeutronClient)\n                   and the base class (BaseTestApi) for the\n                   retargetable test (test_network_lifecycle)\n\n  - test_v2_rest - implements the client interface for the tempest\n                   rest client and configures the retargetable test\n                   with scenarios for json serialization\n\n- tests/functional/api\n  - test_v2_plugin - implements the client interface for the\n                     programmatic plugin api and configures the\n                     retargetable test with scenarios targeting the\n                     linuxbridge and openvswitch plugins\n\n- tests/unit\n  - refactor bits of the existing plugin tests for reuse\n\n1: https://review.openstack.org/#/c/82226/\n\nImplements: bp retargetable-functional-testing\nChange-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e\n""}]",99,72585,501df939a543908554e268ade0c1dc9d12cf11a5,655,45,33,2035,,,0,"Add support for retargetable functional api testing

This patch introduces the concept of a 'retargetable' functional api
test.  Such a test targets an abstract client class, and by varying
the implementation of the client, the test can target multiple
backends.

The test added by this patch (test_network_lifecycle) can be run
against the programmatic plugin api (for configured plugins) via both
tox -e functional and tox -e dsvm-functional.  The latter env is used
by the gating neutron-dsvm-functional job.

The test can also be run against a live Neutron service via 'tox -e api'
which will soon be run as part of the check queue by the
neutron-dsvm-api job [1].  Running this tox env requires
devstack-deployed Neutron and Tempest.

The intention is to refactor the existing plugin tests
(e.g. NeutronDbPluginV2TestCase) to use this model.  Functional tests
don't have to isolate functionality - they just need to exercise it -
so fewer tests will be required.  The new tests will be able to target
plugins directly rather than through the wsgi stack, so execution time
will be decreased.  The refactored tests should be easier to maintain
and take less time to run.

Perhaps best of all, since the same tests will be able to target a
deployed service in the neutron-dsvm-api job, the deployed behaviour
of api changes will finally be able to gate merges to the Neutron
tree.

Notable parts of the change:

- tests/api
  - base_v2 -      defines the client interface (BaseNeutronClient)
                   and the base class (BaseTestApi) for the
                   retargetable test (test_network_lifecycle)

  - test_v2_rest - implements the client interface for the tempest
                   rest client and configures the retargetable test
                   with scenarios for json serialization

- tests/functional/api
  - test_v2_plugin - implements the client interface for the
                     programmatic plugin api and configures the
                     retargetable test with scenarios targeting the
                     linuxbridge and openvswitch plugins

- tests/unit
  - refactor bits of the existing plugin tests for reuse

1: https://review.openstack.org/#/c/82226/

Implements: bp retargetable-functional-testing
Change-Id: Ib5470040c0fa91ec143f38d273e1e259b3adfb2e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/72585/33 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'neutron/tests/unit/linuxbridge/test_linuxbridge_plugin.py', 'neutron/tests/unit/openvswitch/test_openvswitch_plugin.py', 'neutron/tests/unit/test_plugin_api.py']",4,dfff0a8ea9efb1692467242fc97fdf8a5d94e9ae,bp/retargetable-functional-testing,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2014, Red Hat Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import functools import os import random from oslo.config import cfg import testscenarios import testtools from neutron.common import config from neutron.common import exceptions as q_exc from neutron.common.test_lib import test_config from neutron import context from neutron.openstack.common import importutils from neutron.tests import base from neutron.tests.unit.linuxbridge import test_linuxbridge_plugin from neutron.tests.unit.openvswitch import test_openvswitch_plugin from neutron.tests.unit import testlib_api from neutronclient.common import exceptions as nc_exc ROOTDIR = os.path.dirname(os.path.join(os.path.dirname(__file__), '..', '..')) ETCDIR = os.path.join(ROOTDIR, 'etc') def etcdir(*p): return os.path.join(ETCDIR, *p) def rand_name(prefix='test-'): return prefix + str(random.randint(1, 0x7fffffff)) #NOTE(marun) Scenario generation won't work with nose. load_tests = testscenarios.load_tests_apply_scenarios class BaseNeutronClient(object): """""" Base class for a client that can interact the neutron api in some manner. Reference: :file:`neutron/neutron_plugin_base_v2.py` """""" def setUp(self, test_case): """"""Setup the api for use with a test case :param test_case: The test case that will exercise the api """""" self.test_case = test_case @property def NetworkNotFound(self): """"""The exception that indicates a network could not be found."""""" raise NotImplementedError def _cleanup_network(self, id): try: self.delete_network(id) except self.NetworkNotFound: pass def create_network(self, **kwargs): network = self._create_network(**kwargs) self.test_case.addCleanup(functools.partial(self._cleanup_network, network.id)) return network def update_network(self, id, **kwargs): raise NotImplementedError def get_network(self, id, fields=None): raise NotImplementedError def get_networks(self, filters=None, fields=None, sorts=None, limit=None, marker=None, page_reverse=False): raise NotImplementedError def get_networks_count(self, filters=None): return len(self.get_networks(filters=filters)) def delete_network(self, id): raise NotImplementedError class AttributeDict(dict): """""" Provide attribute access (dict.key) to dictionary values. """""" def __getattr__(self, name): """"""Allow attribute access for all keys in the dict."""""" if name in self: return self[name] raise AttributeError(_(""Unknown attribute '%s'.""), name) class PluginClient(BaseNeutronClient): def __init__(self, plugin_conf): super(PluginClient, self).__init__() # Instantiate the class lazily to ensure that things like rpc # have a chance to be mocked out during setup. self.plugin_class = importutils.import_class(plugin_conf.plugin_name) self.plugin_setup = plugin_conf.setUp self.ctx = context.Context('', 'test-tenant') @property def plugin(self): if not hasattr(self, '_plugin'): self._plugin = self.plugin_class() return self._plugin def setUp(self, test_case): super(PluginClient, self).setUp(test_case) # Create the default configurations args = ['--config-file', etcdir('neutron.conf.test')] # If test_config specifies some config-file, use it, as well for config_file in test_config.get('config_files', []): args.extend(['--config-file', config_file]) config.parse(args=args) self.test_case.addCleanup(cfg.CONF.reset) self.plugin_setup(self.test_case) @property def NetworkNotFound(self): return q_exc.NetworkNotFound def _create_network(self, **kwargs): # Internal method - use create_network() instead # Supply defaults that are expected to be set by the api # framwork kwargs.setdefault('admin_state_up', True) kwargs.setdefault('shared', False) data = dict(network=kwargs) result = self.plugin.create_network(self.ctx, data) return AttributeDict(result) def update_network(self, id, **kwargs): data = dict(network=kwargs) result = self.plugin.update_network(self.ctx, id, data) return AttributeDict(result) def get_network(self, *args, **kwargs): result = self.plugin.get_network(self.ctx, *args, **kwargs) return AttributeDict(result) def get_networks(self, *args, **kwargs): result = self.plugin.get_networks(self.ctx, *args, **kwargs) return [AttributeDict(x) for x in result] def get_networks_count(self, *args, **kwargs): return self.plugin.get_networks_count(self.ctx, *args, **kwargs) def delete_network(self, id): self.plugin.delete_network(self.ctx, id) class NativeClient(BaseNeutronClient): def __init__(self, client): super(NativeClient, self).__init__() self.client = client @property def NetworkNotFound(self): return nc_exc.NetworkNotFoundClient def _create_network(self, **kwargs): # Internal method - use create_network() instead if not kwargs: kwargs = {} data = dict(network=kwargs) result = self.client.create_network(body=data) return AttributeDict(result['network']) def update_network(self, id, **kwargs): data = dict(network=kwargs) result = self.client.update_network(id, body=data) return AttributeDict(result['network']) def get_network(self, *args, **kwargs): result = self.client.show_network(*args, **kwargs) return AttributeDict(result['network']) def get_networks(self, *args, **kwargs): result = self.client.list_networks(*args, **kwargs) return [AttributeDict(x) for x in result['networks']] def get_networks_count(self, filters=None): return len(self.get_networks()) def delete_network(self, id): self.client.delete_network(id) class TempestRestClient(BaseNeutronClient): def __init__(self, client, not_found_exception): super(TempestRestClient, self).__init__() self.client = client self.not_found_exception = not_found_exception @property def NetworkNotFound(self): return self.not_found_exception def create_network(self, _expected_status='201', **kwargs): network = self._create_network(_expected_status, **kwargs) self.test_case.addCleanup(functools.partial(self._cleanup_network, network.id)) return network def _create_network(self, _expected_status, **kwargs): # Internal method - use create_network() instead if not kwargs: kwargs = {} data = dict(network=kwargs) resp, body = self.client.create_network(**kwargs) self.test_case.assertEqual(_expected_status, resp['status']) return AttributeDict(body['network']) def update_network(self, id, _expected_status='200', **kwargs): resp, body = self.client.update_network(id, **kwargs) self.test_case.assertEqual(_expected_status, resp['status']) return AttributeDict(body['network']) def get_network(self, id, _expected_status='200', **kwargs): resp, body = self.client.show_network(id, **kwargs) self.test_case.assertEqual(_expected_status, resp['status']) return AttributeDict(body['network']) def get_networks(self, _expected_status='200', **kwargs): resp, body = self.client.list_networks(**kwargs) self.test_case.assertEqual(_expected_status, resp['status']) return [AttributeDict(x) for x in body['networks']] def delete_network(self, id, _expected_status='204'): resp, body = self.client.delete_network(id) self.test_case.assertEqual(_expected_status, resp['status']) class TestApi(base.BaseTestCase): scenarios = [ ('ovs_plugin', dict( client=PluginClient(test_openvswitch_plugin.OvsPluginConf), )), ('lb_plugin', dict( client=PluginClient(test_linuxbridge_plugin.LinuxBridgePluginConf), )), ] def setUp(self): super(TestApi, self).setUp() # Set a default to allow trival debugging of single tests if not hasattr(self, 'client'): self.__dict__.update(self.scenarios[0][1]) self.client.setUp(self) def test_network_lifecycle(self): pre_creation_count = self.client.get_networks_count() net = self.client.create_network(name=rand_name()) post_creation_count = self.client.get_networks_count() self.assertGreater(post_creation_count, pre_creation_count) listed_networks = dict((x['id'], x['name']) for x in self.client.get_networks()) self.assertIn(net.id, listed_networks) self.assertEqual(listed_networks[net.id], net.name, 'Listed network name is not as expected.') updated_name = 'new %s' % net.name updated_net = self.client.update_network(net.id, name=updated_name) self.assertEqual(updated_name, updated_net.name, 'Updated network name is not as expected.') self.client.delete_network(net.id) with testtools.ExpectedException(self.client.NetworkNotFound, msg='Network was not deleted'): self.client.get_network(net.id) ",,332,8
openstack%2Fneutron~master~Ida78652ed50e2cb16fa0ab7194d8468714b99d61,openstack/neutron,master,Ida78652ed50e2cb16fa0ab7194d8468714b99d61,moving vxlan module check to sanity checks and making practical,MERGED,2014-12-15 20:44:25.000000000,2015-01-07 08:22:10.000000000,2015-01-06 23:54:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5756}, {'_account_id': 7353}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}, {'_account_id': 14288}]","[{'number': 1, 'created': '2014-12-15 20:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6648ea969b0b40a90550a846505936088f8fc8c7', 'message': 'check that the vxlan kernel module is available in the proper way\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks that the module is loaded into the running\nkernel.  It also checks via sysfs which is both a more reliable and more\navailable way of checking that a module is available.  It also works on\nstatically compiled kernels.\n\nmoving vxlan module check to sanity checks as well\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}, {'number': 2, 'created': '2014-12-15 20:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2cd96f4cbaf1aad747878137b740e394637fa1a', 'message': 'check that the vxlan kernel module is available in the proper way\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks that the module is loaded into the running\nkernel.  It also checks via sysfs which is both a more reliable and more\navailable way of checking that a module is available.  It also works on\nstatically compiled kernels.\n\nmoving vxlan module check to sanity checks as well\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}, {'number': 3, 'created': '2014-12-18 23:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b14e3f9cb753bafc292ca56fbb5e700a4e7a9850', 'message': 'check that the vxlan kernel module is available in the proper way\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks that the module is loaded into the running\nkernel.  It also checks via sysfs which is both a more reliable and more\navailable way of checking that a module is available.  It also works on\nstatically compiled kernels.\n\nmoving vxlan module check to sanity checks as well\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}, {'number': 4, 'created': '2014-12-19 19:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/677286c98a250919ba40bc6f211926339f7bd091', 'message': 'check that the vxlan kernel module is available in the proper way\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks that the module is loaded into the running\nkernel.  It also checks via sysfs which is both a more reliable and more\navailable way of checking that a module is available.  It also works on\nstatically compiled kernels.\n\nmoving vxlan module check to sanity checks as well\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}, {'number': 5, 'created': '2014-12-23 20:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/91956aa35a88c412ff5c942233d50cc830e716db', 'message': 'check that the vxlan kernel module is available in the proper way\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks that the module is loaded into the running\nkernel.  It also checks via sysfs which is both a more reliable and more\navailable way of checking that a module is available.  It also works on\nstatically compiled kernels.\n\nmoving vxlan module check to sanity checks as well\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}, {'number': 6, 'created': '2014-12-30 16:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e287eaec771dc28206127be4fc008787a3cedab', 'message': 'check that the vxlan kernel module is available in the proper way\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks that the module is loaded into the running\nkernel.  It also checks via sysfs which is both a more reliable and more\navailable way of checking that a module is available.  It also works on\nstatically compiled kernels.\n\nmoving vxlan module check to sanity checks as well\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}, {'number': 7, 'created': '2015-01-06 20:52:38.000000000', 'files': ['neutron/cmd/sanity/checks.py', 'neutron/tests/functional/sanity/test_sanity.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/cmd/sanity_check.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ccd411831183df5eb23e14393fb890ac103929e', 'message': 'moving vxlan module check to sanity checks and making practical\n\nInstead of checking via modinfo (which only checks if a module is\navailable) this checks actual usage, which is a more reliable way of\ntesting real world problems.\n\nChange-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61\nCloses-Bug: 1339197\n'}]",3,141899,6ccd411831183df5eb23e14393fb890ac103929e,126,29,7,14288,,,0,"moving vxlan module check to sanity checks and making practical

Instead of checking via modinfo (which only checks if a module is
available) this checks actual usage, which is a more reliable way of
testing real world problems.

Change-Id: Ida78652ed50e2cb16fa0ab7194d8468714b99d61
Closes-Bug: 1339197
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/141899/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/cmd/sanity/checks.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/cmd/sanity_check.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py']",4,6648ea969b0b40a90550a846505936088f8fc8c7,bug/1339197," def _check_vxlan_support(self, expected, vxlan_ucast_supported, vxlan_mcast_supported):"," def _check_vxlan_support(self, expected, vxlan_module_supported, vxlan_ucast_supported, vxlan_mcast_supported): mock.patch.object(self.lbm, 'vxlan_module_supported', return_value=vxlan_module_supported), vxlan_module_supported=True, vxlan_module_supported=True, vxlan_module_supported=False, vxlan_module_supported=True, def _check_vxlan_module_supported(self, expected, execute_side_effect): with mock.patch.object( utils, 'execute', side_effect=execute_side_effect): self.assertEqual(expected, self.lbm.vxlan_module_supported()) def test_vxlan_module_supported(self): self._check_vxlan_module_supported( expected=True, execute_side_effect=None) self._check_vxlan_module_supported( expected=False, execute_side_effect=RuntimeError()) ",31,37
openstack%2Fheat~master~I7c5509564e8eb6ba8cc676513e94e4f8e3476f4f,openstack/heat,master,I7c5509564e8eb6ba8cc676513e94e4f8e3476f4f,Don't validate the nested stack if there are references,ABANDONED,2015-01-06 08:30:50.000000000,2015-01-07 08:14:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}]","[{'number': 1, 'created': '2015-01-06 08:30:50.000000000', 'files': ['heat/engine/stack_resource.py', 'heat/engine/properties.py', 'heat/engine/resources/template_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/49d75e21cee2993cadd8068096ebc89129c6abaf', 'message': ""Don't validate the nested stack if there are references\n\nSong Li: feel free to take this patch over, this is just an idea.\n\nChange-Id: I7c5509564e8eb6ba8cc676513e94e4f8e3476f4f\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nCloses-bug: #1407877\n""}]",1,145164,49d75e21cee2993cadd8068096ebc89129c6abaf,8,3,1,4715,,,0,"Don't validate the nested stack if there are references

Song Li: feel free to take this patch over, this is just an idea.

Change-Id: I7c5509564e8eb6ba8cc676513e94e4f8e3476f4f
Co-Authored-by: Angus Salkeld <asalkeld@mirantis.com>
Closes-bug: #1407877
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/145164/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/stack_resource.py', 'heat/engine/properties.py', 'heat/engine/resources/template_resource.py']",3,49d75e21cee2993cadd8068096ebc89129c6abaf,image_dep," def validate_nested_stack(self): if self.properties.needs_resolving(): return return super(TemplateResource, self).validate_nested_stack() ",,14,0
openstack%2Fheat~master~Icb5c0e1e2f0087ecf3b4c655d9a5780bd3b98fc8,openstack/heat,master,Icb5c0e1e2f0087ecf3b4c655d9a5780bd3b98fc8,fix res group adopt,ABANDONED,2015-01-07 06:18:45.000000000,2015-01-07 08:09:33.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-07 06:18:45.000000000', 'files': ['heat_integrationtests/functional/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/02aef96385369e9456d09f67382f122fad89259b', 'message': 'fix res group adopt\n\nChange-Id: Icb5c0e1e2f0087ecf3b4c655d9a5780bd3b98fc8\n'}]",0,145417,02aef96385369e9456d09f67382f122fad89259b,4,1,1,4715,,,0,"fix res group adopt

Change-Id: Icb5c0e1e2f0087ecf3b4c655d9a5780bd3b98fc8
",git fetch https://review.opendev.org/openstack/heat refs/changes/17/145417/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_resource_group.py'],1,02aef96385369e9456d09f67382f122fad89259b,cleaner-series,"heat_template_version: ""2013-05-23"" resources: group1: type: OS::Heat::ResourceGroup properties: count: 2 resource_def: type: OS::Heat::RandomString outputs: test0: value: {get_attr: [group1, resource.0.value]} test1: value: {get_attr: [group1, resource.1.value]} ""resource_data"": {""value"": ""goopie""}, ""resource_data"": {""value"": ""different""}, stack = self.client.stacks.get(stack_identifier) self.assertEqual('goopie', self._stack_output(stack, 'test0')) self.assertEqual('different', self._stack_output(stack, 'test1'))","heat_template_version: 2013-05-23 resources: group1: type: OS::Heat::ResourceGroup properties: count: 2 resource_def: type: OS::Heat::RandomString properties: ""Foo"": ""Bar"" ""resource_data"": {}, ""resource_data"": {}, #stack = self.client.stacks.get(stack_identifier) #self.assertEqual('goopie', self._stack_output(stack, 'value'))",17,13
openstack%2Fneutron~master~I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3,openstack/neutron,master,I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3,Validate IPv6 subnet while associating to Router,MERGED,2014-11-24 10:20:26.000000000,2015-01-07 07:49:32.000000000,2015-01-07 07:49:30.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6635}, {'_account_id': 6685}, {'_account_id': 6695}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7743}, {'_account_id': 8279}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10294}, {'_account_id': 10354}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11061}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-24 10:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48f0035ad884f8d3c06dea64cc56f6d2d46985a2', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode = slaac and leaving ipv6_ra_mode\nunset) to Neutron Router. Ideally Neutron should not allow this operation\nand should return an appropriate error message to the user.\n\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 2, 'created': '2014-11-24 14:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38f12f75cd04c9ba5bb2790a21d5ac9b18a27a2f', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode = slaac and leaving ipv6_ra_mode\nunset) to Neutron Router. Ideally Neutron should not allow this operation\nand should return an appropriate error message to the user.\n\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 3, 'created': '2014-11-24 17:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b1fabd7977cfbde380437b99bacfda8b047a009', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode = slaac and leaving ipv6_ra_mode\nunset) to Neutron Router. Ideally Neutron should not allow this operation\nand should return an appropriate error message to the user.\n\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 4, 'created': '2014-12-15 04:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/410f3cdc822c7981be253413cd6be877b4bf607f', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode and leaving ipv6_ra_mode unset)\nto Neutron Router. Ideally Neutron should not allow this operation and\nshould return an appropriate error message to the user.\n\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 5, 'created': '2014-12-16 06:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8760faf41fd7d3076192f3f125fce3e7ce2969e5', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode and leaving ipv6_ra_mode unset)\nto Neutron Router. Ideally Neutron should not allow this operation and\nshould return an appropriate error message to the user.\n\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 6, 'created': '2014-12-19 05:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cab2fe51f67b298afe373092e864816f2dcd21f8', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode and leaving ipv6_ra_mode unset)\nto Neutron Router. Ideally Neutron should not allow this operation and\nshould return an appropriate error message to the user.\n\nAPIImpact\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 7, 'created': '2014-12-23 17:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2644cfd739164e6410dab437de48ff520c4536f7', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode and leaving ipv6_ra_mode unset)\nto Neutron Router. Ideally Neutron should not allow this operation and\nshould return an appropriate error message to the user.\n\nAPIImpact\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}, {'number': 8, 'created': '2015-01-06 16:09:04.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5713f932482210107dcfd7bac6a78524c8bad26', 'message': 'Validate IPv6 subnet while associating to Router\n\nCurrently Neutron allows attaching a subnet (configured to use an external\nrouter, by only setting ipv6_address_mode and leaving ipv6_ra_mode unset)\nto Neutron Router. Ideally Neutron should not allow this operation and\nshould return an appropriate error message to the user.\n\nAPIImpact\nCloses-Bug: #1393527\nChange-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3\n'}]",39,136733,e5713f932482210107dcfd7bac6a78524c8bad26,191,38,8,10257,,,0,"Validate IPv6 subnet while associating to Router

Currently Neutron allows attaching a subnet (configured to use an external
router, by only setting ipv6_address_mode and leaving ipv6_ra_mode unset)
to Neutron Router. Ideally Neutron should not allow this operation and
should return an appropriate error message to the user.

APIImpact
Closes-Bug: #1393527
Change-Id: I9d597e6f5e8aea63222bb9f5ed8289e4ce28bbc3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/136733/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_plugin.py', 'neutron/db/l3_db.py']",2,48f0035ad884f8d3c06dea64cc56f6d2d46985a2,bug/1393527," if (subnet['ip_version'] == 6 and not subnet['ipv6_ra_mode']): msg = _('IPv6 subnet configured to receive RAs from an' ' external router cannot be added to Neutron Router.') raise n_exc.BadRequest(resource='router', msg=msg)",,67,32
openstack%2Fkeystonemiddleware~master~I1b95a3239b3d4f3fbf0a08b1aaf49ba2e85e99c6,openstack/keystonemiddleware,master,I1b95a3239b3d4f3fbf0a08b1aaf49ba2e85e99c6,add more tests for auth_version option,ABANDONED,2014-12-30 07:09:37.000000000,2015-01-07 07:42:21.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-30 07:09:37.000000000', 'files': ['keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/bed899ad9011ea10040af6bd0f85e21b5fa5cb51', 'message': 'add more tests for auth_version option\n\nChange-Id: I1b95a3239b3d4f3fbf0a08b1aaf49ba2e85e99c6\n'}]",0,144410,bed899ad9011ea10040af6bd0f85e21b5fa5cb51,3,1,1,9101,,,0,"add more tests for auth_version option

Change-Id: I1b95a3239b3d4f3fbf0a08b1aaf49ba2e85e99c6
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/10/144410/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/test_auth_token_middleware.py'],1,bed899ad9011ea10040af6bd0f85e21b5fa5cb51,more_tests," def _assert_auth_version(self, conf_version, identity_server_version): self.set_middleware(conf={'auth_version': conf_version}) identity_server = self.middleware._create_identity_server() self.assertEqual(identity_server_version, identity_server.auth_version) def test_micro_version(self): self._assert_auth_version('v2.0', (2, 0)) self._assert_auth_version('v3.0', (3, 0)) self._assert_auth_version('v3.1', (3, 0)) self._assert_auth_version('v3.3.1', (3, 0)) def test_default_auth_version(self): # VERSION_LIST_v3 contains both v2 and v3 version elements self._assert_auth_version(None, (3, 0)) # VERSION_LIST_v2 contains only v2 version elements self.requests.get(BASE_URI, json=VERSION_LIST_v2, status_code=300) self._assert_auth_version(None, (2, 0)) def test_unsupported_auth_version(self): self._assert_auth_version('v1', (2, 0)) self._assert_auth_version('v4', (2, 0))"," def test_micro_version(self): # test v2.0 version self.set_middleware(conf={'auth_version': 'v2.0'}) identity_server = self.middleware._create_identity_server() self.assertEqual((2, 0), identity_server.auth_version) # test v3.0 version self.set_middleware(conf={'auth_version': 'v3.0'}) identity_server = self.middleware._create_identity_server() self.assertEqual((3, 0), identity_server.auth_version) # test v3.1 version self.set_middleware(conf={'auth_version': 'v3.1'}) identity_server = self.middleware._create_identity_server() self.assertEqual((3, 0), identity_server.auth_version) # test v3.3.1 version self.set_middleware(conf={'auth_version': 'v3.3.1'}) identity_server = self.middleware._create_identity_server() self.assertEqual((3, 0), identity_server.auth_version) # test default None version self.set_middleware() identity_server = self.middleware._create_identity_server() self.assertEqual((3, 0), identity_server.auth_version)",21,28
openstack%2Fneutron~master~Idbe0814e6b258d2f394894c1923f459cc1bdd4d2,openstack/neutron,master,Idbe0814e6b258d2f394894c1923f459cc1bdd4d2,Drop functional/contrib directory,MERGED,2015-01-06 19:04:56.000000000,2015-01-07 07:24:43.000000000,2015-01-06 23:26:42.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-06 19:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a65fd4d1e475e215e8f0a20f1033e6a550a5de6', 'message': 'Drop functional/contrib directory\n\nThis has been replaced by tests/contrib and the infra change [1]\nis now in force and this copy is no longer necessary.\n\n[1] https://review.openstack.org/#/c/142603/\n\nChange-Id: Idbe0814e6b258d2f394894c1923f459cc1bdd4d2\n'}, {'number': 2, 'created': '2015-01-06 20:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e11fe4e1746e70e1579f2ab15f68d1f386b816a7', 'message': 'Drop functional/contrib directory\n\nThis has been replaced by tests/contrib and the infra change [1]\nis now in force and this copy is no longer necessary.\n\n[1] https://review.openstack.org/#/c/142603/\n\nChange-Id: Idbe0814e6b258d2f394894c1923f459cc1bdd4d2\n'}, {'number': 3, 'created': '2015-01-06 20:22:05.000000000', 'files': ['neutron/tests/functional/contrib/filters.template', 'neutron/tests/functional/contrib/gate_hook.sh', 'neutron/tests/functional/contrib/post_test_hook.sh', 'neutron/tests/contrib/README', 'neutron/tests/contrib/gate_hook.sh', 'neutron/tests/functional/contrib/README'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d848353fb1979d3c9cb7e5970073dcf28d60516', 'message': 'Drop functional/contrib directory\n\nThis has been replaced by tests/contrib and the infra change [1]\nis now in force and this copy is no longer necessary.\n\n[1] https://review.openstack.org/#/c/142603/\n\nChange-Id: Idbe0814e6b258d2f394894c1923f459cc1bdd4d2\n'}]",0,145303,8d848353fb1979d3c9cb7e5970073dcf28d60516,35,15,3,748,,,0,"Drop functional/contrib directory

This has been replaced by tests/contrib and the infra change [1]
is now in force and this copy is no longer necessary.

[1] https://review.openstack.org/#/c/142603/

Change-Id: Idbe0814e6b258d2f394894c1923f459cc1bdd4d2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/145303/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/contrib/filters.template', 'neutron/tests/functional/contrib/gate_hook.sh', 'neutron/tests/functional/contrib/post_test_hook.sh', 'neutron/tests/functional/contrib/README']",4,8a65fd4d1e475e215e8f0a20f1033e6a550a5de6,drop-contrib,,The files in this directory are intended for use by the neutron-dsvm-functional infra jobs that run the functional test suite in the gate. ,0,137
openstack%2Fopenstack-manuals~master~I3ce2eccbb06243e894460dafc2e72b7a8250b6b1,openstack/openstack-manuals,master,I3ce2eccbb06243e894460dafc2e72b7a8250b6b1,Sort lists on docs.openstack.org,ABANDONED,2014-09-24 08:56:13.000000000,2015-01-07 07:15:57.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 6843}]","[{'number': 1, 'created': '2014-09-24 08:56:13.000000000', 'files': ['www/icehouse/index.html', 'www/api/api-ref-guides.html', 'www/havana/index.html', 'www/trunk/index.html', 'www/developer/language-bindings.html', 'www/grizzly/index.html', 'www/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4ddb7710a4489e2beac62cb8d22fbd0fb2a6c7c7', 'message': 'Sort lists on docs.openstack.org\n\n* according to the alphabet\n* according to the version\n\nChange-Id: I3ce2eccbb06243e894460dafc2e72b7a8250b6b1\n'}]",2,123661,4ddb7710a4489e2beac62cb8d22fbd0fb2a6c7c7,13,8,1,167,,,0,"Sort lists on docs.openstack.org

* according to the alphabet
* according to the version

Change-Id: I3ce2eccbb06243e894460dafc2e72b7a8250b6b1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/123661/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/icehouse/index.html', 'www/api/api-ref-guides.html', 'www/havana/index.html', 'www/trunk/index.html', 'www/developer/language-bindings.html', 'www/grizzly/index.html', 'www/index.html']",7,4ddb7710a4489e2beac62cb8d22fbd0fb2a6c7c7,sort_html_lists," <a href=""http://docs.openstack.org/admin-guide-cloud/content/""> Cloud Administrator Guide <a href=""http://docs.openstack.org/icehouse/config-reference/content/""> Configuration Reference <a href=""http://docs.openstack.org/api/quick-start/content/""> API Quick Start </a> </dd> <dd> <a href=""http://docs.openstack.org/user-guide/content/""> End User Guide (includes Python SDK) </a> </dd> <dd> <a href=""http://docs.openstack.org/api/openstack-block-storage/1.0/content/""> Block Storage API v1.0 Reference <a href=""http://docs.openstack.org/api/openstack-block-storage/2.0/content/""> Block Storage API v2.0 Reference <a href=""http://docs.openstack.org/api/openstack-image-service/1.1/content/""> Image Service API v1 Reference <a href=""http://docs.openstack.org/api/openstack-network/2.0/content/""> Networking API v2.0 Reference <a href=""http://docs.openstack.org/developer/language-bindings.html""> Language Bindings and Python Clients </a> </dd> <dd> <a href=""http://docs.openstack.org/infra/manual/""> OpenStack Infrastructure User Manual <a href=""http://docs.openstack.org/developer/openstack-projects.html""> Python Developer Documentation"," <a href=""http://docs.openstack.org/icehouse/config-reference/content/""> Configuration Reference <a href=""http://docs.openstack.org/admin-guide-cloud/content/""> Cloud Administrator Guide <a href=""http://docs.openstack.org/api/quick-start/content/""> API Quick Start </a> </dd> <dd> <a href=""http://docs.openstack.org/user-guide/content/""> End User Guide (includes Python SDK) </a> </dd> <dd> <a href=""http://docs.openstack.org/api/openstack-block-storage/2.0/content/""> Block Storage API v2.0 Reference <a href=""http://docs.openstack.org/api/openstack-block-storage/1.0/content/""> Block Storage API v1.0 Reference <a href=""http://docs.openstack.org/api/openstack-network/2.0/content/""> Networking API v2.0 Reference <a href=""http://docs.openstack.org/api/openstack-image-service/1.1/content/""> Image Service API v1 Reference <a href=""http://docs.openstack.org/developer/openstack-projects.html""> Python Developer Documentation </a> </dd> <dd> <a href=""http://docs.openstack.org/developer/language-bindings.html""> Language Bindings and Python Clients <a href=""http://docs.openstack.org/infra/manual/""> OpenStack Infrastructure User Manual",185,185
openstack%2Fdevstack~master~I8655a955ebb322516d92bee418b93d4cc23bdc5c,openstack/devstack,master,I8655a955ebb322516d92bee418b93d4cc23bdc5c,Do not modify rsyslog files if rsyslog is not used.,MERGED,2014-04-16 11:38:20.000000000,2015-01-07 07:06:18.000000000,2014-04-17 21:19:44.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 7350}, {'_account_id': 8674}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-16 11:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/371a4f5fe5f23ce6751875310a169adff825ac68', 'message': 'Do not modify rsyslog files if rsyslog is not used.\n\nSwift was missing asan \'if [[ $SYSLOG != ""False"" ]]\' statement which is used\nby other services, and therefor failed with a \'No such file or directory\'\nerror when \'SYSLOG=False\' was set in localrc.\n\nCloses-Bug: 1308461\n\nChange-Id: I8655a955ebb322516d92bee418b93d4cc23bdc5c\n'}, {'number': 2, 'created': '2014-04-17 08:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0ef5ad5d5a5b8678ddb94531b42cfa1ae8350faf', 'message': 'Do not modify rsyslog files if rsyslog is not used.\n\nSwift was missing an \'if [[ $SYSLOG != ""False"" ]]\' statement which is used\nby other services, and therefor failed with a \'No such file or directory\'\nerror when \'SYSLOG=False\' was set in localrc.\n\nCloses-Bug: 1308461\n\nChange-Id: I8655a955ebb322516d92bee418b93d4cc23bdc5c\n'}, {'number': 3, 'created': '2014-04-17 12:08:08.000000000', 'files': ['lib/swift'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f894c2ab805f9dfc0dfdd3668ccd3a83ee4eb9f2', 'message': 'Do not modify rsyslog files if rsyslog is not used.\n\nSwift was missing an \'if [[ $SYSLOG != ""False"" ]]\' statement which is used\nby other services, and therefor failed with a \'No such file or directory\'\nerror when \'SYSLOG=False\' was set in localrc.\n\nCloses-Bug: 1308461\n\nChange-Id: I8655a955ebb322516d92bee418b93d4cc23bdc5c\n'}]",5,87942,f894c2ab805f9dfc0dfdd3668ccd3a83ee4eb9f2,29,7,3,8674,,,0,"Do not modify rsyslog files if rsyslog is not used.

Swift was missing an 'if [[ $SYSLOG != ""False"" ]]' statement which is used
by other services, and therefor failed with a 'No such file or directory'
error when 'SYSLOG=False' was set in localrc.

Closes-Bug: 1308461

Change-Id: I8655a955ebb322516d92bee418b93d4cc23bdc5c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/42/87942/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/swift'],1,371a4f5fe5f23ce6751875310a169adff825ac68,bug/1308461," if [[ $SYSLOG != ""False"" ]]; then sudo chown -R ${STACK_USER}:adm ${swift_log_dir} sed ""s,%SWIFT_LOGDIR%,${swift_log_dir},"" $FILES/swift/rsyslog.conf | sudo \ tee /etc/rsyslog.d/10-swift.conf # restart syslog to take the changes sudo killall -HUP rsyslogd fi"," sudo chown -R ${STACK_USER}:adm ${swift_log_dir} sed ""s,%SWIFT_LOGDIR%,${swift_log_dir},"" $FILES/swift/rsyslog.conf | sudo \ tee /etc/rsyslog.d/10-swift.conf # restart syslog to take the changes sudo killall -HUP rsyslogd",8,5
openstack%2Fopenstack-manuals~master~I600053d25b21f11862362a339fdd50432bbbe399,openstack/openstack-manuals,master,I600053d25b21f11862362a339fdd50432bbbe399,Imported Translations from Transifex,MERGED,2015-01-07 06:14:59.000000000,2015-01-07 07:03:01.000000000,2015-01-07 07:03:00.000000000,"[{'_account_id': 3}, {'_account_id': 167}]","[{'number': 1, 'created': '2015-01-07 06:14:59.000000000', 'files': ['doc/install-guide/locale/pt_BR.po', 'doc/config-reference/locale/config-reference.pot', 'doc/common/locale/common.pot', 'doc/image-guide/locale/fr.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/412187e45454e10a9a30cb3a74fb99e40288cace', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I600053d25b21f11862362a339fdd50432bbbe399\n'}]",0,145414,412187e45454e10a9a30cb3a74fb99e40288cace,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I600053d25b21f11862362a339fdd50432bbbe399
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/14/145414/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/pt_BR.po', 'doc/config-reference/locale/config-reference.pot', 'doc/common/locale/common.pot', 'doc/image-guide/locale/fr.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/image-guide/locale/ja.po']",7,412187e45454e10a9a30cb3a74fb99e40288cace,transifex/translations,"# Tom Fifield <tom@openstack.org>, 2015""POT-Creation-Date: 2015-01-06 15:46+0000\n"" ""PO-Revision-Date: 2015-01-06 10:11+0000\n"" ""Last-Translator: Tom Fifield <tom@openstack.org>\n""msgstr ""15GB qcow2 イメージを作成します。""msgstr ""Block Storage のボリュームをイメージから作成した場合、イメージのプロパティを設定することを考慮します。イメージの主要プロパティを変更する場合、Block Storage の設定も更新すべきです。すべてのコントローラーノードで <filename>/etc/cinder/cinder.conf</filename> ファイルの <placeholder-1/> を修正して、Image Service に設定した主要プロパティを一致させます。""","""POT-Creation-Date: 2015-01-03 16:25+0000\n"" ""PO-Revision-Date: 2015-01-02 19:10+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"",286,271
openstack%2Fopenstack-manuals~master~I77e00cc2e73ea9fee689c17faf1e9e62ab74886f,openstack/openstack-manuals,master,I77e00cc2e73ea9fee689c17faf1e9e62ab74886f,Fix spelling,MERGED,2015-01-06 23:36:39.000000000,2015-01-07 07:02:53.000000000,2015-01-07 07:02:52.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}, {'_account_id': 10068}, {'_account_id': 10705}]","[{'number': 1, 'created': '2015-01-06 23:36:39.000000000', 'files': ['doc/user-guide/section_cli_nova_configure_instances.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6c05c92d1367f1608e5de388dccb1095f7796249', 'message': 'Fix spelling\n\nThe sentence read, The command generates a key pair with the name that\nyou specify fir KEY_NAME.  Replaced fir with for.\n\nChange-Id: I77e00cc2e73ea9fee689c17faf1e9e62ab74886f\nbackport: none\nCloses-Bug: #1408098\n'}]",0,145379,6c05c92d1367f1608e5de388dccb1095f7796249,9,5,1,14531,,,0,"Fix spelling

The sentence read, The command generates a key pair with the name that
you specify fir KEY_NAME.  Replaced fir with for.

Change-Id: I77e00cc2e73ea9fee689c17faf1e9e62ab74886f
backport: none
Closes-Bug: #1408098
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/145379/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/section_cli_nova_configure_instances.xml'],1,6c05c92d1367f1608e5de388dccb1095f7796249,bug/1408098," specify for <replaceable>KEY_NAME</replaceable>, writes the"," specify fir <replaceable>KEY_NAME</replaceable>, writes the",1,1
openstack%2Fheat~master~I65a95b74ec9e902a7eaee0c94b4f320cd20e3ae5,openstack/heat,master,I65a95b74ec9e902a7eaee0c94b4f320cd20e3ae5,external link not working in heat doc,MERGED,2015-01-06 09:20:12.000000000,2015-01-07 06:59:56.000000000,2015-01-07 06:59:55.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 10442}]","[{'number': 1, 'created': '2015-01-06 09:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1e598818b8944e4ad4b023ab5e5d6cfa36247384', 'message': 'external link not working in heat doc\n\nIn HOT templates document, there is a link\nto the example heat template in the github.\nThe link is not working because there is a _ present\nin before the link.\n\nIt is removed now.\n\nChange-Id: I65a95b74ec9e902a7eaee0c94b4f320cd20e3ae5\nCloses-Bug: #1407892\n'}, {'number': 2, 'created': '2015-01-06 10:15:31.000000000', 'files': ['doc/source/templates/index.rst', 'doc/source/templates/hot/hello_world.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/6d4a07f2f7e7b8aab8f800e0998510ff7feeee67', 'message': 'external link not working in heat doc\n\nIn HOT templates document, there is a link\nto the example heat template in the github.\nThe link is not working because there is a _ present\nin before the link.\n\nIt is removed now.\n\nChange-Id: I65a95b74ec9e902a7eaee0c94b4f320cd20e3ae5\nCloses-Bug: #1407892\n'}]",0,145175,6d4a07f2f7e7b8aab8f800e0998510ff7feeee67,22,7,2,10442,,,0,"external link not working in heat doc

In HOT templates document, there is a link
to the example heat template in the github.
The link is not working because there is a _ present
in before the link.

It is removed now.

Change-Id: I65a95b74ec9e902a7eaee0c94b4f320cd20e3ae5
Closes-Bug: #1407892
",git fetch https://review.opendev.org/openstack/heat refs/changes/75/145175/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/templates/hot/hello_world.rst'],1,1e598818b8944e4ad4b023ab5e5d6cfa36247384,bug/1407892,https://github.com/openstack/heat-templates/blob/master/hot/hello_world.yaml,_https://github.com/openstack/heat-templates/blob/master/hot/hello_world.yaml,1,1
openstack%2Ftricircle~master~I730a0ca953513b9f965155141d04b90b39963432,openstack/tricircle,master,I730a0ca953513b9f965155141d04b90b39963432,Add port name for mapping,MERGED,2015-01-07 06:47:42.000000000,2015-01-07 06:48:51.000000000,2015-01-07 06:48:51.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2015-01-07 06:47:42.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/ca2f9eeb5e86f6682df46a41ec14065743a53c88', 'message': ""Add port name for mapping\n\nWhen creating cascading port in nova proxy, add the 'name' field which\ncontains a cascading network_name and port uuid.\n\nChange-Id: I730a0ca953513b9f965155141d04b90b39963432\n""}]",0,145419,ca2f9eeb5e86f6682df46a41ec14065743a53c88,6,2,1,9684,,,0,"Add port name for mapping

When creating cascading port in nova proxy, add the 'name' field which
contains a cascading network_name and port uuid.

Change-Id: I730a0ca953513b9f965155141d04b90b39963432
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/19/145419/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,ca2f9eeb5e86f6682df46a41ec14065743a53c88,, csd_port_name = netObj['ovs_interfaceid']," csd_port_name = self._gen_csd_nets_name(net_name, netObj['ovs_interfaceid'])",1,2
openstack%2Ftempest~master~I4ffa85fb0eefa96a71f1b279947caa6028632251,openstack/tempest,master,I4ffa85fb0eefa96a71f1b279947caa6028632251,Separate NegativeRestClient from rest_client,MERGED,2014-12-24 06:58:38.000000000,2015-01-07 06:23:17.000000000,2015-01-07 06:23:16.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 7872}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-24 06:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/df15c06963d3b1de8ebc194f913039c8fd57ab96', 'message': 'Separate NegativeRestClient from rest_client\n\nWe have a plan that both RestClient and NegativeRestClient are moved\nto tempest-lib, and RestClient will be moved before NegativeRestClient.\nThis patch separates NegativeRestClient from rest_client for moving\nthese classes smoothly.\n\nChange-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251\n'}, {'number': 2, 'created': '2014-12-24 07:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3624093407dfb0984f45376a37b4073a92bea376', 'message': 'Separate NegativeRestClient from rest_client\n\nWe have a plan that both RestClient and NegativeRestClient are moved\nto tempest-lib, and RestClient will be moved before NegativeRestClient.\nThis patch separates NegativeRestClient from rest_client for moving\nthese classes smoothly.\n\nChange-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251\n'}, {'number': 3, 'created': '2014-12-24 08:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b3314ba87f2090a6293bcfeac7ce3f4dcab900fd', 'message': 'Separate NegativeRestClient from rest_client\n\nWe have a plan that both RestClient and NegativeRestClient are moved\nto tempest-lib, and RestClient will be moved before NegativeRestClient.\nThis patch separates NegativeRestClient from rest_client for moving\nthese classes smoothly.\n\nChange-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251\n'}, {'number': 4, 'created': '2015-01-05 05:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae3648199dadfa5798e44960d1c4fb71fd2ceab1', 'message': 'Separate NegativeRestClient from rest_client\n\nWe have a plan that both RestClient and NegativeRestClient are moved\nto tempest-lib, and RestClient will be moved before NegativeRestClient.\nThis patch separates NegativeRestClient from rest_client for moving\nthese classes smoothly.\n\nChange-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251\n'}, {'number': 5, 'created': '2015-01-05 05:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/93941769f54b2009c16ba322b774c69d2234882f', 'message': 'Separate NegativeRestClient from rest_client\n\nWe have a plan that both RestClient and NegativeRestClient are moved\nto tempest-lib, and RestClient will be moved before NegativeRestClient.\nThis patch separates NegativeRestClient from rest_client for moving\nthese classes smoothly.\n\nChange-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251\n'}, {'number': 6, 'created': '2015-01-05 23:32:55.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/clients.py', 'tempest/tests/test_rest_client.py', 'tempest/common/negative_rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4266268ef2d9f8a3165e0de98567b1e5aec7410c', 'message': 'Separate NegativeRestClient from rest_client\n\nWe have a plan that both RestClient and NegativeRestClient are moved\nto tempest-lib, and RestClient will be moved before NegativeRestClient.\nThis patch separates NegativeRestClient from rest_client for moving\nthese classes smoothly.\n\nChange-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251\n'}]",3,143781,4266268ef2d9f8a3165e0de98567b1e5aec7410c,41,8,6,6167,,,0,"Separate NegativeRestClient from rest_client

We have a plan that both RestClient and NegativeRestClient are moved
to tempest-lib, and RestClient will be moved before NegativeRestClient.
This patch separates NegativeRestClient from rest_client for moving
these classes smoothly.

Change-Id: I4ffa85fb0eefa96a71f1b279947caa6028632251
",git fetch https://review.opendev.org/openstack/tempest refs/changes/81/143781/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/rest_client.py', 'tempest/clients.py', 'tempest/tests/test_rest_client.py', 'tempest/common/negative_rest_client.py']",4,df15c06963d3b1de8ebc194f913039c8fd57ab96,rest-client,"# (c) 2014 Deutsche Telekom AG # Copyright 2014 Red Hat, Inc. # Copyright 2014 NEC Corporation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import rest_client from tempest import config CONF = config.CONF class NegativeRestClient(rest_client.RestClient): """""" Version of RestClient that does not raise exceptions. """""" def __init__(self, auth_provider, service): region = self._get_region(service) super(NegativeRestClient, self).__init__(auth_provider, service, region) def _get_region(self, service): """""" Returns the region for a specific service """""" service_region = None for cfgname in dir(CONF._config): # Find all config.FOO.catalog_type and assume FOO is a service. cfg = getattr(CONF, cfgname) catalog_type = getattr(cfg, 'catalog_type', None) if catalog_type == service: service_region = getattr(cfg, 'region', None) if not service_region: service_region = CONF.identity.region return service_region def _error_checker(self, method, url, headers, body, resp, resp_body): pass def send_request(self, method, url_template, resources, body=None): url = url_template % tuple(resources) if method == ""GET"": resp, body = self.get(url) elif method == ""POST"": resp, body = self.post(url, body) elif method == ""PUT"": resp, body = self.put(url, body) elif method == ""PATCH"": resp, body = self.patch(url, body) elif method == ""HEAD"": resp, body = self.head(url) elif method == ""DELETE"": resp, body = self.delete(url) elif method == ""COPY"": resp, body = self.copy(url) else: assert False return resp, body ",,76,53
openstack%2Ftempest~master~Ib26badf64e7cddf4158e4720e193b3129e8fdb12,openstack/tempest,master,Ib26badf64e7cddf4158e4720e193b3129e8fdb12,Move _get_region() to NegativeRestClient,MERGED,2014-12-11 11:10:32.000000000,2015-01-07 06:10:25.000000000,2015-01-07 06:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 11:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/13a311a2f226cd7c0707ef6a38185f3461768b39', 'message': ""Move _get_region and _get_endpoint_type to RestClient\n\n_get_region() and _get_endpoint_type() get each project's connection\ninformation from Tempest own CONF values. This patch moves them to\nRestClient which is a Tempest specific class, and BaseRestClient will\nbe simple for using it on each project tests.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 2, 'created': '2014-12-11 11:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d9970443373d5b1b5a3b39c3ba204ccc770c49f6', 'message': ""Move _get_region and _get_endpoint_type to RestClient\n\n_get_region() and _get_endpoint_type() get each project's connection\ninformation from Tempest own CONF values. This patch moves them to\nRestClient which is a Tempest specific class, and BaseRestClient will\nbe simple for using it on each project tests.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 3, 'created': '2014-12-24 05:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/55b374c9599c5d2735f32562d48a9e56ac14cea6', 'message': ""Remove _get_region() from RestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch removes _get_region() and makes each client specify its own\nCONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 4, 'created': '2014-12-24 05:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9cbce24babe1efb112b93773ed1f8b870e8cb0b9', 'message': ""Remove _get_region() from RestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch removes _get_region() and makes each client specify its own\nCONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 5, 'created': '2014-12-24 06:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c167c3e4248fe11b829f00af0ea9ad87962c44d9', 'message': ""Remove _get_region() from RestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch removes _get_region() and makes each client specify its own\nCONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 6, 'created': '2014-12-24 06:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dda2393e74b69c1b33308f5a6a9366bf8bb076ad', 'message': ""Move _get_region() to NegativeRestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch moves _get_region() to NegativeRestClient and makes each client\nspecify its own CONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 7, 'created': '2014-12-24 08:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/373f80bbf9ccd6e681782a21647d9d1c86d8512e', 'message': ""Move _get_region() to NegativeRestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch moves _get_region() to NegativeRestClient and makes each client\nspecify its own CONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 8, 'created': '2015-01-05 05:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/698e347f4a6520394f2756f3b58b876f5035b785', 'message': ""Move _get_region() to NegativeRestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch moves _get_region() to NegativeRestClient and makes each client\nspecify its own CONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 9, 'created': '2015-01-05 05:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/232bf6df725d76533e6da31d862c0b114057e288', 'message': ""Move _get_region() to NegativeRestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch moves _get_region() to NegativeRestClient and makes each client\nspecify its own CONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}, {'number': 10, 'created': '2015-01-05 23:32:55.000000000', 'files': ['tempest/services/orchestration/json/orchestration_client.py', 'tempest/common/rest_client.py', 'tempest/services/network/json/network_client.py', 'tempest/services/identity/v3/json/base.py', 'tempest/services/messaging/json/messaging_client.py', 'tempest/services/object_storage/base.py', 'tempest/services/volume/json/base.py', 'tempest/tests/test_rest_client.py', 'tempest/services/compute/json/base.py', 'tempest/services/telemetry/json/telemetry_client.py', 'tempest/services/data_processing/v1_1/client.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/database/json/flavors_client.py', 'tempest/services/baremetal/base.py', 'tempest/services/database/json/versions_client.py', 'tempest/services/image/v1/json/image_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e9f50413adc87a593c4e13d53fecd130e4da2f7c', 'message': ""Move _get_region() to NegativeRestClient\n\n_get_region() was used for getting a region from CONF for each project,\nbut most projects' sections contain a region value and it is easy to\nspecify its value instead of _get_region().\nIn addition, RestClient will become a tempest-lib class and it is needed\nto separate CONF values from a RestClient class.\nThis patch moves _get_region() to NegativeRestClient and makes each client\nspecify its own CONF value.\n\nChange-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12\n""}]",0,141015,e9f50413adc87a593c4e13d53fecd130e4da2f7c,50,6,10,6167,,,0,"Move _get_region() to NegativeRestClient

_get_region() was used for getting a region from CONF for each project,
but most projects' sections contain a region value and it is easy to
specify its value instead of _get_region().
In addition, RestClient will become a tempest-lib class and it is needed
to separate CONF values from a RestClient class.
This patch moves _get_region() to NegativeRestClient and makes each client
specify its own CONF value.

Change-Id: Ib26badf64e7cddf4158e4720e193b3129e8fdb12
",git fetch https://review.opendev.org/openstack/tempest refs/changes/15/141015/9 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,13a311a2f226cd7c0707ef6a38185f3461768b39,rest-client," def __init__(self, auth_provider, region=""RegionOne"", endpoint_type=None, build_interval=1, build_timeout=300, trace_regex="""", disable_ssl_certificate=False, ca_certificates_file=None): self.region = region self.endpoint_type = endpoint_type endpoint_type=self.endpoint_type, region=self.region region = self._get_region(self.service) endpoint_type = self._get_endpoint_type(self.service) auth_provider, region=region, endpoint_type=endpoint_type, def _get_region(self, service): """""" Returns the region for a specific service """""" service_region = None for cfgname in dir(CONF._config): # Find all config.FOO.catalog_type and assume FOO is a service. cfg = getattr(CONF, cfgname) catalog_type = getattr(cfg, 'catalog_type', None) if catalog_type == service: service_region = getattr(cfg, 'region', None) if not service_region: service_region = CONF.identity.region return service_region def _get_endpoint_type(self, service): """""" Returns the endpoint type for a specific service """""" # If the client requests a specific endpoint type, then be it if self.endpoint_url: return self.endpoint_url endpoint_type = None for cfgname in dir(CONF._config): # Find all config.FOO.catalog_type and assume FOO is a service. cfg = getattr(CONF, cfgname) catalog_type = getattr(cfg, 'catalog_type', None) if catalog_type == service: endpoint_type = getattr(cfg, 'endpoint_type', 'publicURL') break return endpoint_type "," def __init__(self, auth_provider, build_interval=1, build_timeout=300, trace_regex="""", disable_ssl_certificate=False, ca_certificates_file=None): def _get_region(self, service): """""" Returns the region for a specific service """""" service_region = None for cfgname in dir(CONF._config): # Find all config.FOO.catalog_type and assume FOO is a service. cfg = getattr(CONF, cfgname) catalog_type = getattr(cfg, 'catalog_type', None) if catalog_type == service: service_region = getattr(cfg, 'region', None) if not service_region: service_region = CONF.identity.region return service_region def _get_endpoint_type(self, service): """""" Returns the endpoint type for a specific service """""" # If the client requests a specific endpoint type, then be it if self.endpoint_url: return self.endpoint_url endpoint_type = None for cfgname in dir(CONF._config): # Find all config.FOO.catalog_type and assume FOO is a service. cfg = getattr(CONF, cfgname) catalog_type = getattr(cfg, 'catalog_type', None) if catalog_type == service: endpoint_type = getattr(cfg, 'endpoint_type', 'publicURL') break return endpoint_type endpoint_type=self._get_endpoint_type(self.service), region=self._get_region(self.service) auth_provider,",43,38
openstack%2Fneutron-lbaas~master~I65b9b54e21294705abee611231f7706bb385674a,openstack/neutron-lbaas,master,I65b9b54e21294705abee611231f7706bb385674a,Cleaned up requirements.txt,MERGED,2014-12-16 10:54:16.000000000,2015-01-07 06:02:36.000000000,2015-01-07 06:02:34.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6951}, {'_account_id': 9656}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-16 10:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/6596c91b5aaa9c8f6ac5e7db4f973f98454b250b', 'message': 'Cleaned up requirements.txt\n\nChange-Id: I65b9b54e21294705abee611231f7706bb385674a\n'}, {'number': 2, 'created': '2014-12-22 10:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/8c544a9db9a599d3447cf6566621d92f7f49d52f', 'message': 'Cleaned up requirements.txt\n\nChange-Id: I65b9b54e21294705abee611231f7706bb385674a\n'}, {'number': 3, 'created': '2015-01-05 11:21:10.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/2515ff794fb9fd6685ccf4d1ab5c05e53bf5acf2', 'message': 'Cleaned up requirements.txt\n\nChange-Id: I65b9b54e21294705abee611231f7706bb385674a\n'}]",0,142063,2515ff794fb9fd6685ccf4d1ab5c05e53bf5acf2,32,7,3,9656,,,0,"Cleaned up requirements.txt

Change-Id: I65b9b54e21294705abee611231f7706bb385674a
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/63/142063/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,6596c91b5aaa9c8f6ac5e7db4f973f98454b250b,,WebOb>=1.2.3,,1,20
openstack%2Fcinder~master~I2ae3d9b98c107cebaf386adbdcdb3cfafee070be,openstack/cinder,master,I2ae3d9b98c107cebaf386adbdcdb3cfafee070be,Remove import of private _lazy module,MERGED,2015-01-06 22:09:53.000000000,2015-01-07 05:50:23.000000000,2015-01-07 02:27:08.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 6601}, {'_account_id': 7198}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12779}, {'_account_id': 14259}]","[{'number': 1, 'created': '2015-01-06 22:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/61bc2e6483da0ec3516d82c09286c643807bd63d', 'message': ""Remove import of private _lazy module\n\nNew version of oslo.i18n released and some things\nmoved around (internal private modules in the lib).\n\nThis should be fine and shouldn't matter to us, BUT\nit seems we had some hackery going on in our unit tests\nthat were being lazy and importing and manipulating the\nprivate library.\n\nThis patch removes those cases and fixed up the cinder.i18n\nhelper method for enable_lazy to accept a bool (which is how\nthe libraries method works to begin with).\n\nThere were several tests in test_faults that were actually\nperforming and comparing translations of messages.  These\ntests aren't quite working now because they had a number\nof things they imported from private variables and methods\nin the i18n module.  Honestly I'm not sure of the value of\ntesting those things here anyway, but for now I've just\nadded a skip to those and we can sort out long term fixes\nand plans later.\n\nChange-Id: I2ae3d9b98c107cebaf386adbdcdb3cfafee070be\nPartial-Bug: #1408099\n""}, {'number': 2, 'created': '2015-01-06 23:28:34.000000000', 'files': ['cinder/test.py', 'cinder/tests/api/middleware/test_faults.py', 'cinder/i18n.py', 'cinder/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/894f20d9cf57b36ccf9a675c6b2b070d56c9b297', 'message': ""Remove import of private _lazy module\n\nNew version of oslo.i18n released and some things\nmoved around (internal private modules in the lib).\n\nThis should be fine and shouldn't matter to us, BUT\nit seems we had some hackery going on in our unit tests\nthat were being lazy and importing and manipulating the\nprivate library.\n\nThis patch removes those cases and fixed up the cinder.i18n\nhelper method for enable_lazy to accept a bool (which is how\nthe libraries method works to begin with).\n\nThere were several tests in test_faults that were actually\nperforming and comparing translations of messages.  These\ntests aren't quite working now because they had a number\nof things they imported from private variables and methods\nin the i18n module.  Honestly I'm not sure of the value of\ntesting those things here anyway, but for now I've just\nadded a skip to those and we can sort out long term fixes\nand plans later.\n\nChange-Id: I2ae3d9b98c107cebaf386adbdcdb3cfafee070be\nPartial-Bug: #1408099\n""}]",6,145359,894f20d9cf57b36ccf9a675c6b2b070d56c9b297,34,15,2,2243,,,0,"Remove import of private _lazy module

New version of oslo.i18n released and some things
moved around (internal private modules in the lib).

This should be fine and shouldn't matter to us, BUT
it seems we had some hackery going on in our unit tests
that were being lazy and importing and manipulating the
private library.

This patch removes those cases and fixed up the cinder.i18n
helper method for enable_lazy to accept a bool (which is how
the libraries method works to begin with).

There were several tests in test_faults that were actually
performing and comparing translations of messages.  These
tests aren't quite working now because they had a number
of things they imported from private variables and methods
in the i18n module.  Honestly I'm not sure of the value of
testing those things here anyway, but for now I've just
added a skip to those and we can sort out long term fixes
and plans later.

Change-Id: I2ae3d9b98c107cebaf386adbdcdb3cfafee070be
Partial-Bug: #1408099
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/145359/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/test.py', 'cinder/i18n.py', 'cinder/tests/api/middleware/test_faults.py', 'cinder/tests/test_wsgi.py']",4,61bc2e6483da0ec3516d82c09286c643807bd63d,bug/1408099, i18n.enable_lazy(False),"from oslo.i18n import _lazy back_use_lazy = _lazy.USE_LAZY self.addCleanup(self._restore_use_lazy, back_use_lazy) def _restore_use_lazy(self, back_use_lazy): _lazy.USE_LAZY = back_use_lazy",13,57
openstack%2Fsolum~master~I3747fe9140969f10f87c58d63432e9a7fb38e7aa,openstack/solum,master,I3747fe9140969f10f87c58d63432e9a7fb38e7aa,Configurable storage of solum-generated variables,MERGED,2015-01-05 23:48:11.000000000,2015-01-07 05:29:50.000000000,2015-01-07 05:29:49.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 9095}]","[{'number': 1, 'created': '2015-01-05 23:48:11.000000000', 'files': ['solum/worker/api.py', 'contrib/lp-cedarish/docker/build-lp', 'solum/common/clients.py', 'solum/api/handlers/assembly_handler.py', 'solum/tests/api/handlers/test_assembly.py', 'contrib/lp-chef/docker/unittest-app', 'solum/worker/handlers/shell.py', 'contrib/lp-cedarish/docker/unittest-app', 'solum/objects/sqlalchemy/plan.py', 'solum/tests/worker/handlers/test_noop.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'solum/worker/handlers/noop.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/27dff58cbc65_drop_column_deploy_keys_uri_in_plan.py', 'solum/api/handlers/plan_handler.py', 'contrib/lp-cedarish/docker/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/8fe7544a5cd947cccf6f97a9d62256d18873f9c4', 'message': ""Configurable storage of solum-generated variables\n\nAdded a new solum config option 'system_param_store' which\nindicates the storage of solum-generated variables, e.g. deploy\nkeys. 'system_param_store' defaults to 'database', other acceptable\nsettings are 'barbican' and 'local_file'.\n\nDB schema change: removed column plan.deploy_keys_uri.\n\nChange-Id: I3747fe9140969f10f87c58d63432e9a7fb38e7aa\n""}]",0,145093,8fe7544a5cd947cccf6f97a9d62256d18873f9c4,9,3,1,6662,,,0,"Configurable storage of solum-generated variables

Added a new solum config option 'system_param_store' which
indicates the storage of solum-generated variables, e.g. deploy
keys. 'system_param_store' defaults to 'database', other acceptable
settings are 'barbican' and 'local_file'.

DB schema change: removed column plan.deploy_keys_uri.

Change-Id: I3747fe9140969f10f87c58d63432e9a7fb38e7aa
",git fetch https://review.opendev.org/openstack/solum refs/changes/93/145093/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/api.py', 'contrib/lp-cedarish/docker/build-lp', 'solum/common/clients.py', 'solum/api/handlers/assembly_handler.py', 'solum/tests/api/handlers/test_assembly.py', 'contrib/lp-chef/docker/unittest-app', 'solum/worker/handlers/shell.py', 'contrib/lp-cedarish/docker/unittest-app', 'solum/objects/sqlalchemy/plan.py', 'solum/tests/worker/handlers/test_noop.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'solum/worker/handlers/noop.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/27dff58cbc65_drop_column_deploy_keys_uri_in_plan.py', 'solum/api/handlers/plan_handler.py', 'contrib/lp-cedarish/docker/build-app']",17,8fe7544a5cd947cccf6f97a9d62256d18873f9c4,config_var,GIT_PRIVATE_KEY=${REPO_DEPLOY_KEYS:-''} TLOG Usage: $0 git_url appname project_id base_image, TLOG Usage: $0 git_url appname project_id base_image [git_private_key]GIT_PRIVATE_KEY=$1 shift,204,173
openstack%2Fnova~master~I744869bb41a4938268c0769939fa998eeeb476c8,openstack/nova,master,I744869bb41a4938268c0769939fa998eeeb476c8,Nuke XML support from Nova REST API - Phase 3,MERGED,2015-01-06 13:53:29.000000000,2015-01-07 04:56:30.000000000,2015-01-06 23:13:20.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-06 13:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09bb0c0562ef003f2aa23624713e762185453b11', 'message': ""Nuke XML support from Nova REST API - Phase 3\n\nRemove every single *_nsmap definition, they are only used\nto provide an argument to the template constructors and\nwas used for XML namespacing.\n\nPretty much every single ResponseObject.attach() call can\ngo away as well, they're only used to attach XML slave\ntemplates to the master templates, and the method does\nnothing if no arguments are passed.\n\nChange-Id: I744869bb41a4938268c0769939fa998eeeb476c8\n""}, {'number': 2, 'created': '2015-01-06 14:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e00749763290cce2032768c3429435a20b585d3', 'message': ""Nuke XML support from Nova REST API - Phase 3\n\nRemove every single *_nsmap definition, they are only used\nto provide an argument to the template constructors and\nwas used for XML namespacing.\n\nPretty much every single ResponseObject.attach() call can\ngo away as well, they're only used to attach XML slave\ntemplates to the master templates, and the method does\nnothing if no arguments are passed.\n\nChange-Id: I744869bb41a4938268c0769939fa998eeeb476c8\n""}, {'number': 3, 'created': '2015-01-06 18:00:05.000000000', 'files': ['nova/api/openstack/compute/contrib/flavorextradata.py', 'nova/api/openstack/compute/contrib/flavor_access.py', 'nova/api/openstack/compute/contrib/server_groups.py', 'nova/api/openstack/compute/ips.py', 'nova/api/openstack/compute/contrib/cells.py', 'nova/api/openstack/compute/flavors.py', 'nova/api/openstack/compute/contrib/virtual_interfaces.py', 'nova/api/openstack/compute/contrib/flavor_swap.py', 'nova/api/openstack/compute/contrib/server_diagnostics.py', 'nova/api/openstack/compute/contrib/config_drive.py', 'nova/api/openstack/compute/contrib/server_usage.py', 'nova/api/openstack/compute/contrib/disk_config.py', 'nova/tests/functional/api_samples_test_base.py', 'nova/api/openstack/compute/contrib/extended_availability_zone.py', 'nova/api/openstack/compute/contrib/extended_ips_mac.py', 'nova/api/openstack/compute/versions.py', 'nova/api/openstack/compute/contrib/flavor_disabled.py', 'nova/api/openstack/compute/contrib/keypairs.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/api/openstack/compute/contrib/extended_status.py', 'nova/api/openstack/compute/contrib/extended_volumes.py', 'nova/api/openstack/compute/images.py', 'nova/api/openstack/compute/contrib/used_limits.py', 'nova/api/openstack/compute/contrib/extended_ips.py', 'nova/api/openstack/compute/servers.py', 'nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/contrib/flavor_rxtx.py', 'nova/api/openstack/compute/contrib/image_size.py', 'nova/api/openstack/compute/limits.py', 'nova/api/openstack/compute/contrib/security_group_default_rules.py', 'nova/api/openstack/compute/contrib/server_group_quotas.py', 'nova/api/openstack/compute/contrib/extended_server_attributes.py', 'nova/api/openstack/compute/contrib/extended_virtual_interfaces_net.py', 'nova/api/openstack/extensions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f3ee2212e019437d09541599089cde536d75ad62', 'message': ""Nuke XML support from Nova REST API - Phase 3\n\nRemove every single *_nsmap definition, they are only used\nto provide an argument to the template constructors and\nwas used for XML namespacing.\n\nPretty much every single ResponseObject.attach() call can\ngo away as well, they're only used to attach XML slave\ntemplates to the master templates, and the method does\nnothing if no arguments are passed.\n\nChange-Id: I744869bb41a4938268c0769939fa998eeeb476c8\n""}]",1,145228,f3ee2212e019437d09541599089cde536d75ad62,25,10,3,5638,,,0,"Nuke XML support from Nova REST API - Phase 3

Remove every single *_nsmap definition, they are only used
to provide an argument to the template constructors and
was used for XML namespacing.

Pretty much every single ResponseObject.attach() call can
go away as well, they're only used to attach XML slave
templates to the master templates, and the method does
nothing if no arguments are passed.

Change-Id: I744869bb41a4938268c0769939fa998eeeb476c8
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/145228/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/flavorextradata.py', 'nova/api/openstack/compute/contrib/flavor_access.py', 'nova/api/openstack/compute/contrib/server_groups.py', 'nova/api/openstack/compute/ips.py', 'nova/api/openstack/compute/contrib/cells.py', 'nova/api/openstack/compute/flavors.py', 'nova/api/openstack/compute/contrib/virtual_interfaces.py', 'nova/api/openstack/compute/contrib/flavor_swap.py', 'nova/api/openstack/compute/contrib/server_diagnostics.py', 'nova/api/openstack/compute/contrib/config_drive.py', 'nova/api/openstack/compute/contrib/server_usage.py', 'nova/api/openstack/compute/contrib/disk_config.py', 'nova/tests/functional/api_samples_test_base.py', 'nova/api/openstack/compute/contrib/extended_availability_zone.py', 'nova/api/openstack/compute/contrib/extended_ips_mac.py', 'nova/api/openstack/compute/versions.py', 'nova/api/openstack/compute/contrib/flavor_disabled.py', 'nova/api/openstack/compute/contrib/keypairs.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/api/openstack/compute/contrib/extended_status.py', 'nova/api/openstack/compute/contrib/extended_volumes.py', 'nova/api/openstack/compute/images.py', 'nova/api/openstack/compute/contrib/used_limits.py', 'nova/api/openstack/compute/contrib/extended_ips.py', 'nova/api/openstack/compute/servers.py', 'nova/api/openstack/compute/contrib/flavor_rxtx.py', 'nova/api/openstack/compute/contrib/image_size.py', 'nova/api/openstack/compute/limits.py', 'nova/api/openstack/compute/contrib/security_group_default_rules.py', 'nova/api/openstack/compute/contrib/server_group_quotas.py', 'nova/api/openstack/compute/contrib/extended_server_attributes.py', 'nova/api/openstack/compute/contrib/extended_virtual_interfaces_net.py', 'nova/api/openstack/extensions.py']",33,09bb0c0562ef003f2aa23624713e762185453b11,nuke-xml,," # The XML namespace for the extension, e.g., # 'http://www.fox.in.socks/api/ext/pie/v1.0' namespace = None @classmethod def nsmap(cls): """"""Synthesize a namespace map from extension."""""" # Start with a base nsmap nsmap = ext_nsmap.copy() # Add the namespace for the extension nsmap[cls.alias] = cls.namespace return nsmap ext_nsmap = {} ",5,125
openstack%2Ftaskflow~master~I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274,openstack/taskflow,master,I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274,Rework the in-memory backend,MERGED,2014-09-27 00:56:46.000000000,2015-01-07 04:52:09.000000000,2015-01-07 04:52:08.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-09-27 00:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2cb0c590b62b40dd31516d813925909a854bf8fb', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 2, 'created': '2014-09-27 01:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ede43e01dde147b9828696114053b7be1296df19', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 3, 'created': '2014-09-27 02:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b8d68a25d7b44865a5c9f75dfd95e8c0dd76f0ef', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 4, 'created': '2014-09-27 03:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ba692bcfdcbfee5061bb21f4e6dd90686e6b95cf', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 5, 'created': '2014-09-27 05:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3a854377770e82520a16e535d84548b72cc9b11e', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 6, 'created': '2014-09-27 19:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dc5f00fd5f20582be0f980c224edc7147587948d', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 7, 'created': '2014-09-29 19:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fbb5286adbc2ce1e33637e694b451047f807dd0f', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 8, 'created': '2014-09-29 22:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/572db97d540212af11609d98b591a0b303706a05', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 9, 'created': '2014-09-29 22:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2e0b3089001525aa2b0447fc8e39d5edf269cfe6', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 10, 'created': '2014-09-30 02:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/203638facc2615ea45633a8473b502f151618917', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 11, 'created': '2014-09-30 04:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/70bf4b09fe9c4da6ef5f0a8c7126c0a5b839fd12', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 12, 'created': '2014-09-30 04:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6a33309c628ceb8091268216a396b5e0040e4a97', 'message': 'Simplify the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 13, 'created': '2014-09-30 15:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fb9999ff870146ea2ee61c6d8f50898b4269248e', 'message': 'Rework the in-memory backend\n\nInstead of storing the logbook and detail objects as objects\njust store them as plain dictionaries and convert them back and\nforth as needed to avoid any potential for reference leaks and\nother inherent complexity.\n\nTo avoid this we add a new storage class that has a few helper\nfunctions and use the to_dict() and from_dict() methods of the stored\nobjects to store there representations as dictionaries. This also\nfixes returning references to live objects since now only dictionaries\nare stored and retrieved (and converted from/to).\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due to this more\neasily useable/understandable memory backend changes...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 14, 'created': '2014-10-01 05:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1c5a049f6be182a77407e4a81b4aa286ba1a93a9', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrevial we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 15, 'created': '2014-10-01 05:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/18cf227df9faeb598f91d7468a14ab72503a2785', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 16, 'created': '2014-10-01 22:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6e5f6c1c19a7ddbdf02d74d0997b204a2dddb0ae', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 17, 'created': '2014-10-21 02:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d90ccf64de1664425e8488a3dc209b0dbaac5583', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 18, 'created': '2014-12-02 00:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/533a1fcf782237935eb5de1879a95c538d7a9266', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 19, 'created': '2014-12-02 00:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a91ee70e7a0702e06d920070158b37dcc4590680', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 20, 'created': '2014-12-11 04:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d914c9761a8d6221e4294c7167847f33d99c9829', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}, {'number': 21, 'created': '2014-12-18 21:10:12.000000000', 'files': ['taskflow/persistence/logbook.py', 'taskflow/persistence/backends/impl_memory.py', 'taskflow/types/failure.py', 'taskflow/tests/unit/test_retries.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/84b387f8bb56d7c03dbe56a84ddbad94bf46262e', 'message': 'Rework the in-memory backend\n\nThis avoids storing direct copies of incoming objects and\nmakes sure that we always merge incoming objects (if a\nsaved object already exists) or create a copy of the\nincoming object if it does not exist when storing.\n\nOn retrieval we also always return copies instead of\nreturning the data that is stored internally to avoid the\nproblems that can be hard to detect when users (engine\nor other) modify those source objects.\n\nFixes bug 1365830\n\nAlso fixes a retry test case issue that was discovered due\nto this more easily useable/understandable memory backend\nchanges...\n\nChange-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274\n'}]",0,124552,84b387f8bb56d7c03dbe56a84ddbad94bf46262e,49,2,21,1297,,,0,"Rework the in-memory backend

This avoids storing direct copies of incoming objects and
makes sure that we always merge incoming objects (if a
saved object already exists) or create a copy of the
incoming object if it does not exist when storing.

On retrieval we also always return copies instead of
returning the data that is stored internally to avoid the
problems that can be hard to detect when users (engine
or other) modify those source objects.

Fixes bug 1365830

Also fixes a retry test case issue that was discovered due
to this more easily useable/understandable memory backend
changes...

Change-Id: I2afdda7beb71e35f7e12d9fd7ccf90b6c5447274
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/52/124552/20 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/persistence/backends/impl_memory.py', 'taskflow/persistence/logbook.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/tests/unit/test_retries.py', 'taskflow/utils/misc.py']",5,2cb0c590b62b40dd31516d813925909a854bf8fb,bp/more-examples," """"""Make copy of exception info tuple."""""" return (exc_type, copy.copy(exc_value), tb) def to_dict(self, retain_exc_info=False): dct = { if retain_exc_info: dct['exc_info'] = copy_exc_info(self.exc_info) return dct"," """"""Make copy of exception info tuple, as deep as possible."""""" # NOTE(imelnikov): there is no need to copy type, and # we can't copy traceback. return (exc_type, copy.deepcopy(exc_value), tb) def to_dict(self): return {",126,70
openstack%2Fneutron~master~Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1,openstack/neutron,master,Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1,Add developer documentation for plugins/drivers contributions,MERGED,2014-12-11 21:26:18.000000000,2015-01-07 04:51:35.000000000,2015-01-07 04:51:33.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 642}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6547}, {'_account_id': 6598}, {'_account_id': 6854}, {'_account_id': 7244}, {'_account_id': 7962}, {'_account_id': 8124}, {'_account_id': 8279}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10182}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12171}, {'_account_id': 13051}, {'_account_id': 13523}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 21:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0cc07d818b8ffe446052ef1aa526215a51adfdd', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nMore to follow, with working examples, as we bootstrap this\neffort.\n\nPartially-implements: bp/core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 2, 'created': '2014-12-12 02:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4bdce939efa2e619e3d6de00b16be5217bb56d90', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nMore to follow, with working examples, as we bootstrap this\neffort.\n\nPartially-implements: bp/core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 3, 'created': '2014-12-12 18:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6f9aa1c3becbcb4b1ff9d233ff054fa131f9963', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nMore to follow, with working examples, as we bootstrap this\neffort.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 4, 'created': '2014-12-12 19:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7914f8400ed2d272302dd3e2a0350e00598dc7c1', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nMore to follow, with working examples, as we bootstrap this\neffort.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 5, 'created': '2014-12-13 04:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b05c7a77f225d308fb2f641ba58ba015bfbe93d9', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nMore to follow, with working examples, as we bootstrap this\neffort.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 6, 'created': '2014-12-13 04:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23a9cf5707d3e64c6479215e652119870ccad4b6', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nThere is probably enough material in this patch to merge as is,\nbut I will provide more content as reviews come in.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 7, 'created': '2014-12-13 06:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/259ac8cce4a3829a0a99040531edf7d4f2924ea4', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nThere is probably enough material in this patch to merge as is,\nbut I will provide more content as reviews come in.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 8, 'created': '2014-12-13 21:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/95f88b8c8648963335380ff517f2bbf83fed6d59', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nThere is probably enough material in this patch to merge as is,\nbut I will provide more content as reviews come in.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 9, 'created': '2014-12-16 20:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e0eb70f8ee662715d4ba2f9cd127edaf05bff1c', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nThere is probably enough material in this patch to merge as is,\nbut I will provide more content as reviews come in.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 10, 'created': '2014-12-17 06:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3702db61d90fed22bfcf4a8ea2ebe702d74a2cac', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nThere is probably enough material in this patch to merge as is,\nbut I will provide more content as reviews come in.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 11, 'created': '2014-12-23 19:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fcd5a17aa44861c4a8d423a8e3c209ad5a24f43f', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nThere is probably enough material in this patch to merge as is,\nbut I will provide more content as reviews come in.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}, {'number': 12, 'created': '2015-01-06 00:37:19.000000000', 'files': ['tools/split.sh', 'doc/source/devref/development.environment.rst', 'doc/source/devref/contribute.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9391526a5871d35f129ff42c33119ecc4c34e40d', 'message': 'Add developer documentation for plugins/drivers contributions\n\nThis is the initial step to provide documentation and\nhow-to for developers interested in contributing plugins and\ndrivers according to the core-vendor-decomp proposal.\n\nPartially-implements: blueprint core-vendor-decomposition\n\nChange-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1\n'}]",190,141171,9391526a5871d35f129ff42c33119ecc4c34e40d,252,39,12,748,,,0,"Add developer documentation for plugins/drivers contributions

This is the initial step to provide documentation and
how-to for developers interested in contributing plugins and
drivers according to the core-vendor-decomp proposal.

Partially-implements: blueprint core-vendor-decomposition

Change-Id: Ib8b6cc5fd72eb1b8b4b4b2bdbda132062c81cbc1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/141171/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/development.environment.rst', 'doc/source/devref/contribute.rst']",2,e0cc07d818b8ffe446052ef1aa526215a51adfdd,bp/core-vendor-decomposition,"Contributing new extensions to Neutron ====================================== Neutron has a pluggable architecture, with a number of extension points. This documentation covers aspects relevant to contributing new Neutron v2 core (aka monolithic) plugins and ML2 mechanism drivers, and L3 service plugins. This document will initially cover a number of process-oriented aspects of the contribution process, to then provide an how-to guide that shows how to go from 0 LOC's to successfully contributing new extensions with Neutron Development. In the remainder of this guide, we will try to use practical examples as much as we can so that people have working solutions they can start from. This guide is for a developer who wants to have a degree of visibility within the OpenStack Networking project. If you are a developer who wants to provide a Neutron-based solution without interacting with the Neutron community, you are free to do so, but you can stop reading now, as this guide is not for you. In fact, from the Kilo release onwards, the Neutron core team propose that additions to the codebase adopt a structure where the *monolithic plugins*, *ML2 MechanismDrivers*, and *L3 service plugins* are integration-only (called vendor integration hereinafter) to code that lives outside the tree (called vendor library hereinafter); the same applies for any vendor-specific agents: the only part that is to stay in the tree is the agent 'main' (a small python file that imports agent code from the vendor library and starts it). The 'outside the tree' can be anything which the vendor is comfortable with: it may be a stackforge repo for instance, a tarball, a pypi package, etc. It is however important that this vendor library be publicly accessible. A plugin/drivers maintainer team self-governs in order to promote sharing, reuse, innovation, and release of the 'out-of-tree' backbone. It should not be required for any member of the core team to be involved with this process, although core members of the Neutron team can be in whichever capacity necessary for out-of-tree development. Below, the following strategies will be documented: * Design and Development; * Testing and Continous Integration; * Defect Management; * Documentation; This document will then provide a working example on how to contribute new additions to Neutron. Blueprint Spec Submission Strategy ---------------------------------- Provided contributors adhere to the abovementioned development footprint they should not be required to follow the spec process for changes that only affect their vendor integration and library. New contributions can simply be submitted for code review, with the proviso that adequate documentation and 3rd CI party is supplied at the time of the code submission. For tracking purposes, the review itself can be tagged with a Launchpad bug report, marked as wishlist; design documents can still be supplied in form of RST documents, within the same vendor library repo, for documentation purposes; If substantial changes to the common Neutron code are required, a spec that targets the work to common Neutron code will be typically needed, and a contributor is invited to seek guidance from the Neutron core team as to what steps to follow. Once again, for submitting the integration module, no spec is required. Development Strategy -------------------- * The following elements are suggested to be contributed in the tree for plugins and drivers (called vendor integration hereinafter): * Data models; * Extension definitions; * Configuration files; * Requirements file targeting vendor code; * Things that do not remain in the tree (called vendor library hereinafter): * Vendor specific logic; * Associated unit tests; The idea here would be to provide in-tree the plugin/driver code that implements an API, but have it delegate to out-of-tree code for backend-specific interactions; the vendor integration will then typically involve minor passthrough/parsing of parameters, minor handling of DB objects as well as handling of responses, whereas the vendor library will do the heavylifting and implement the vendor-specific logic. The boundary between the in-tree layer and the out-of-tree one should be defined by the contributor while asking these types of questions: * If something changes in my backend, do I need to alter the integration layer drastically? Clearly, the least impact there is, the better the separation being achieved; * If I expose vendor details (e.g. protocols, auth, e.g.), can easily swap and replace (e.g. a hardware with a newer version being supplied) without affecting the integration too much? Clearly, the more reusable the integration the better separation. The vendor code *must* be publicly available via pypi, or public source repository compatible with pip requirements; this requirements file should not be confused with the Neutron requirements file that lists all common dependencies); instead it is a file 'requirements.txt' that is located in neutron/plugins/pluginXXX/, whose content is something along the lines of 'my_plugin_xxx_library>=X.Y.Z'. Vendors should be responsible for ensuring that their library did not depend on libraries conflicting with global requirements, but could include libraries not included in the global requirements. Versioning can be used to pin vendor code to specific versions; For instance a vendor integration module can become as simple as one that contains only the following: * Registering config options; * Registering the plugin class; * Registering the models; * Registering the extensions. Testing Strategy ---------------- The testing process will be as follow: * There will be no unit tests for plugins and drivers in the tree; The expectation is that contributors would run unit test in their own external library (e.g. in stackforge where Jenkins setup is for free); For unit tests that validate the vendor library, it is responsibility of the vendor to choose what CI system they see fit to run them; there is no need or requirement to use OpenStack CI resources if they do not want to; ultimately these tests can run as part of the 3rd party CI system that is currently required, based on specific filters, if necessary. * 3rd Party CI will continue to validate vendor integration with Neutron via functional testing; 3rd Party CI is a communication mechanism. This objective of this mechanism is threefold: * it communicates to plugin/driver contributors when someone has contributed a change that is potentially breaking. It is then up to the a given contributor maintaining the affected plugin to determine whether the failure is transient or real, and resolve the problem if it is; * it communicates to a patch author that they may be breaking a plugin/driver. If they have the time/energy/relationship with the maintainer of the plugin/driver in question, then they can (at their discretion) work to resolve the breakage; * it communicates to the community at large whether a given plugin/driver is being actively maintained. Review and Defect Management Strategies --------------------------------------- The usual process applies to the code that is part of OpenStack Neutron. More precisely: * Bugs that affect vendor code can be filed against the Neutron integration, if the integration code is at fault; otherwise, the code maintainer may decide to fix a bug without oversight, and issue a new version pin against the requirements file for the code in question in case the vendor library is being pinned; it makes sense to require 3rd party CI for a given plugin/driver to pass when changing their dependency before merging to any branch (i.e. both master and stable branches); * Vendor specific code follow the same review guidelines as any other code in the tree, however, the code being reviewed strictly applies to integration code or requirements' version bumps; as for the vendor library, it becomes an external repo; the vendor can choose anyone to approve/merge changes in this repo; Documentation Strategies ------------------------ It is a duty of the new contributor to provide working links to be referenced from the OpenStack upstream documentation. How-to ------ In case you wanted the vendor library to be hosted on StackForge, there are a number of steps to get you started. Roughly this is what you need to do: * Create a StackForge repository with the help of OpenStack Infra. The steps are documented on: http://ci.openstack.org/stackforge.html. It is worth noting that you only get one shot at creating this repository. If you want to prepulate this repository from another public github repo, you can do so by specifying the upstream section for your project in project-config/gerrit/project.yaml. This will help peserves the git history. Having said that, you can still import a repo at a later stage, but the steps are more involved and require active help from the infra team; * TODO(armax) The 'ODL ML2 Mechanism Driver' example -------------------------------------- * Create the StackForge repo: https://review.openstack.org/#/c/136854/ * TODO(armax) ",,189,0
openstack%2Fironic~master~I07497228cafab73df12253a5e652069a0a9918cb,openstack/ironic,master,I07497228cafab73df12253a5e652069a0a9918cb,Refactor async helper methods in conductor/manager.py,MERGED,2014-12-04 22:10:50.000000000,2015-01-07 04:32:43.000000000,2015-01-07 04:32:42.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-04 22:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d420453554a0ce8497c711967d1398c51a09cef4', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 2, 'created': '2014-12-05 00:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa8d64b48fdf74945180c3103d65a3ab1f7605ef', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 3, 'created': '2014-12-05 01:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/051e6af02affbfb17d81fe702c6f1bd52f3943e4', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 4, 'created': '2014-12-10 19:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2df126e3686772890417dde58144d901f092f5e9', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 5, 'created': '2014-12-11 00:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ca87241a06ffa58d03367292ede46d79db67b577', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 6, 'created': '2014-12-11 01:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4f4fee0878d26a0aeaa6edabdc3f71a74f68022d', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 7, 'created': '2014-12-11 20:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d7660e0d1459074582a25d40a509cace690748a4', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 8, 'created': '2014-12-15 20:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/da0ef7561696197dd89b0d0dd44098aad9e083d5', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- re-arrange a few class methods without changes\n- move some async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler\n- move _do_sync_power_state out of the main class.\n  However, this required returning the count instead of simply updating\n  self.power_state_sync_count, so a few test changes were required.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 9, 'created': '2014-12-18 23:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0986a8875b7dee1e993ce7290ce9261238b6c5e8', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- move a few class methods closer to where they are invoked,\n  to improve readability\n- move and rename async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler,\n    _do_sync_power_state\n- do_node_deploy now sets conductor affinity after error checking,\n  though this should have no functional impact\n- Moving _do_sync_power_state out of the main class required\n  returning the count instead of updating the counter directly.\n- Refactored _do_sync_power_state to improve readability, and in the\n  process of this refactoring, a bug in the unit tests was found:\n  fail_change=True was not properly tested.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 10, 'created': '2014-12-19 03:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36364ab80cd9b135837718811ddf993cad0cc169', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- move a few class methods closer to where they are invoked,\n  to improve readability\n- move and rename async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler,\n    _do_sync_power_state\n- do_node_deploy now sets conductor affinity after error checking,\n  though this should have no functional impact\n- Moving _do_sync_power_state out of the main class required\n  returning the count instead of updating the counter directly.\n- Consolidated a LOG.warning and LOG.error message within\n  _do_sync_power_state into a single LOG.error. Both were being logged\n  within the same exception block.\n- Refactored _do_sync_power_state to improve readability, and in the\n  process of this refactoring, a bug in the unit tests was found:\n  fail_change=True was not properly tested.\n\nA future patch should move these methods into conductor/utils.py.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 11, 'created': '2015-01-06 23:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f50aeb2d390dfed90c3f900db4702f4794e70d7d', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- move a few class methods closer to where they are invoked,\n  to improve readability\n- move and rename async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler,\n    _do_sync_power_state\n- do_node_deploy now sets conductor affinity after error checking,\n  though this should have no functional impact\n- Moving _do_sync_power_state out of the main class required\n  returning the count instead of updating the counter directly.\n- Consolidated a LOG.warning and LOG.error message within\n  _do_sync_power_state into a single LOG.error. Both were being logged\n  within the same exception block.\n- Refactored _do_sync_power_state to improve readability, and in the\n  process of this refactoring, a bug in the unit tests was found:\n  fail_change=True was not properly tested.\n- Corrects issue with max_retries running an extra attempt.\n\nA future patch should move these methods into conductor/utils.py.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}, {'number': 12, 'created': '2015-01-07 01:07:36.000000000', 'files': ['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/13aee6165a21751105aa87dc6e6aecb4cb89b0e6', 'message': 'Refactor async helper methods in conductor/manager.py\n\nThis patch performs multiple refactorings of conductor/manager.py:\n- move a few class methods closer to where they are invoked,\n  to improve readability\n- move and rename async helper methods out of the ConductorManager class:\n    _do_node_deploy, _do_node_teardown,\n    _provisioning_error_handler, _power_state_error_handler,\n    _do_sync_power_state\n- do_node_deploy now sets conductor affinity after error checking,\n  though this should have no functional impact\n- Moving _do_sync_power_state out of the main class required\n  returning the count instead of updating the counter directly.\n- Consolidated a LOG.warning and LOG.error message within\n  _do_sync_power_state into a single LOG.error. Both were being logged\n  within the same exception block.\n- Refactored _do_sync_power_state to improve readability, and in the\n  process of this refactoring, a bug in the unit tests was found:\n  fail_change=True was not properly tested.\n- Corrects issue with max_retries running an extra attempt.\n\nA future patch should move these methods into conductor/utils.py.\n\nRelated-To: blueprint new-ironic-state-machine\nChange-Id: I07497228cafab73df12253a5e652069a0a9918cb\n'}]",60,139217,13aee6165a21751105aa87dc6e6aecb4cb89b0e6,92,11,12,2889,,,0,"Refactor async helper methods in conductor/manager.py

This patch performs multiple refactorings of conductor/manager.py:
- move a few class methods closer to where they are invoked,
  to improve readability
- move and rename async helper methods out of the ConductorManager class:
    _do_node_deploy, _do_node_teardown,
    _provisioning_error_handler, _power_state_error_handler,
    _do_sync_power_state
- do_node_deploy now sets conductor affinity after error checking,
  though this should have no functional impact
- Moving _do_sync_power_state out of the main class required
  returning the count instead of updating the counter directly.
- Consolidated a LOG.warning and LOG.error message within
  _do_sync_power_state into a single LOG.error. Both were being logged
  within the same exception block.
- Refactored _do_sync_power_state to improve readability, and in the
  process of this refactoring, a bug in the unit tests was found:
  fail_change=True was not properly tested.
- Corrects issue with max_retries running an extra attempt.

A future patch should move these methods into conductor/utils.py.

Related-To: blueprint new-ironic-state-machine
Change-Id: I07497228cafab73df12253a5e652069a0a9918cb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/17/139217/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py']",2,d420453554a0ce8497c711967d1398c51a09cef4,foo," @lockutils.synchronized(WORKER_SPAWN_lOCK, 'ironic-') def _spawn_worker(self, func, *args, **kwargs): """"""Create a greenthread to run func(*args, **kwargs). Spawns a greenthread if there are free slots in pool, otherwise raises exception. Execution control returns immediately to the caller. :returns: GreenThread object. :raises: NoFreeConductorWorker if worker pool is currently full. """""" if self._worker_pool.free(): return self._worker_pool.spawn(func, *args, **kwargs) else: raise exception.NoFreeConductorWorker() def _conductor_service_record_keepalive(self): while not self._keepalive_evt.is_set(): try: self.dbapi.touch_conductor(self.host) except db_exception.DBConnectionError: LOG.warning(_LW('Conductor could not connect to database ' 'while heartbeating.')) self._keepalive_evt.wait(CONF.conductor.heartbeat_interval) task.set_spawn_error_hook(_power_state_error_handler, return _get_vendor_passthru_metadata( task.driver.vendor.vendor_routes) return _get_vendor_passthru_metadata(driver.vendor.driver_routes) task.set_spawn_error_hook(_provisioning_error_handler, _do_node_deploy, task, self.conductor.id) task.set_spawn_error_hook(_provisioning_error_handler, _do_node_tear_down, task) # NOTE(deva): This section is redundant, but unit tests want it if ((node.provision_state == states.DEPLOYWAIT) or node.maintenance or node.reservation): with task_manager.acquire(context, node_id) as task: if ((task.node.provision_state == states.DEPLOYWAIT) or task.node.maintenance): continue result = _do_sync_power_state( task, self.power_state_sync_count[node_uuid]) if result: self.power_state_sync_count[node_uuid] = result else: del self.power_state_sync_count[node_uuid] def _get_vendor_passthru_metadata(route_dict): d = {} for method, metadata in route_dict.iteritems(): # 'func' is the vendor method reference, ignore it d[method] = {k: metadata[k] for k in metadata if k != 'func'} return d def _power_state_error_handler(e, node, power_state): """"""Set the node's power states if error occurs. This hook gets called upon an execption being raised when spawning the worker thread to change the power state of a node. :param e: the exception object that was raised. :param node: an Ironic node object. :param power_state: the power state to set on the node. """""" if isinstance(e, exception.NoFreeConductorWorker): node.power_state = power_state node.target_power_state = states.NOSTATE node.last_error = (_(""No free conductor workers available"")) node.save() LOG.warning(_LW(""No free conductor workers available to perform "" ""an action on node %(node)s, setting node's "" ""power state back to %(power_state)s.""), {'node': node.uuid, 'power_state': power_state}) def _provisioning_error_handler(e, node, provision_state, target_provision_state): """"""Set the node's provisioning states if error occurs. This hook gets called upon an exception being raised when spawning the worker to do the deployment or tear down of a node. :param e: the exception object that was raised. :param node: an Ironic node object. :param provision_state: the provision state to be set on the node. :param target_provision_state: the target provision state to be set on the node. """""" if isinstance(e, exception.NoFreeConductorWorker): # NOTE(deva): there is no need to clear conductor_affinity # because it isn't updated on a failed deploy node.provision_state = provision_state node.target_provision_state = target_provision_state node.last_error = (_(""No free conductor workers available"")) node.save() LOG.warning(_LW(""No free conductor workers available to perform "" ""an action on node %(node)s, setting node's "" ""provision_state back to %(prov_state)s and "" ""target_provision_state to %(tgt_prov_state)s.""), {'node': node.uuid, 'prov_state': provision_state, 'tgt_prov_state': target_provision_state}) def _do_node_deploy(task, conductor_id): """"""Prepare the environment and deploy a node."""""" node = task.node try: task.driver.deploy.prepare(task) new_state = task.driver.deploy.deploy(task) except Exception as e: # NOTE(deva): there is no need to clear conductor_affinity with excutils.save_and_reraise_exception(): task.process_event('fail') LOG.warning(_LW('Error in deploy of node %(node)s: %(err)s'), {'node': task.node.uuid, 'err': e}) node.last_error = _(""Failed to deploy. Error: %s"") % e else: # Update conductor_affinity to reference this conductor's ID # since there may be local persistent state node.conductor_affinity = conductor_id # NOTE(deva): Some drivers may return states.DEPLOYWAIT # eg. if they are waiting for a callback if new_state == states.DEPLOYDONE: task.process_event('done') LOG.info(_LI('Successfully deployed node %(node)s with ' 'instance %(instance)s.'), {'node': node.uuid, 'instance': node.instance_uuid}) elif new_state == states.DEPLOYWAIT: task.process_event('wait') else: LOG.error(_LE('Unexpected state %(state)s returned while ' 'deploying node %(node)s.'), {'state': new_state, 'node': node.uuid}) finally: node.save() def _do_node_tear_down(task): """"""Internal RPC method to tear down an existing node deployment."""""" node = task.node try: task.driver.deploy.clean_up(task) task.driver.deploy.tear_down(task) except Exception as e: with excutils.save_and_reraise_exception(): task.process_event('error') LOG.warning(_LW('Error in tear_down of node %(node)s: ' '%(err)s'), {'node': task.node.uuid, 'err': e}) task.node.last_error = _(""Failed to tear down. Error: %s"") % e else: # NOTE(deva): When tear_down finishes, the deletion is done task.process_event('done') LOG.info(_LI('Successfully unprovisioned node %(node)s with ' 'instance %(instance)s.'), {'node': node.uuid, 'instance': node.instance_uuid}) # NOTE(deva): For compatibility with ""NOSTATE is None"" # we need to clear the target_state here manually # This can be removed once we migrate to an AVAILABLE state node.target_provision_state = None finally: # NOTE(deva): there is no need to unset conductor_affinity # because it is a reference to the most recent conductor which # deployed a node, and does not limit any future actions. # But we do need to clear the instance_info node.instance_info = {} node.save() def _handle_sync_power_state_max_retries_exceeded(task, actual_power_state): node = task.node msg = (_(""During sync_power_state, max retries exceeded "" ""for node %(node)s, node state %(actual)s "" ""does not match expected state '%(state)s'. "" ""Updating DB state to '%(actual)s' "" ""Switching node to maintenance mode."") % {'node': node.uuid, 'actual': actual_power_state, 'state': node.power_state}) node.power_state = actual_power_state node.last_error = msg node.maintenance = True node.maintenance_reason = msg node.save() LOG.error(msg) def _do_sync_power_state(task, count): """"""Sync the power state and increment the counter upon failure."""""" node = task.node power_state = None # Power driver info should be set properly for new node, otherwise # prevent node from switching to maintenance mode. if node.power_state is None: try: task.driver.power.validate(task) except (exception.InvalidParameterValue, exception.MissingParameterValue): return try: count += 1 power_state = task.driver.power.get_power_state(task) if power_state == states.ERROR: raise exception.PowerStateFailure(_(""Driver returns ERROR"" "" state."")) if power_state == node.power_state: return except Exception as e: LOG.warning(_LW(""During sync_power_state, could not get power "" ""state for node %(node)s. Error: %(err)s.""), {'node': node.uuid, 'err': e}) if (count >= CONF.conductor.power_state_sync_max_retries): _handle_sync_power_state_max_retries_exceeded(task, power_state) return count else: return count if node.power_state is None: LOG.info(_LI(""During sync_power_state, node %(node)s has no "" ""previous known state. Recording current state "" ""'%(state)s'.""), {'node': node.uuid, 'state': power_state}) node.power_state = power_state node.save() return if not CONF.conductor.force_power_state_during_sync: LOG.warning(_LW(""During sync_power_state, node %(node)s state "" ""does not match expected state '%(state)s'. "" ""Updating recorded state to '%(actual)s'.""), {'node': node.uuid, 'actual': power_state, 'state': node.power_state}) node.power_state = power_state node.save() return if count > CONF.conductor.power_state_sync_max_retries: _handle_sync_power_state_max_retries_exceeded(task, power_state) return count # Force actual power_state of node equal to DB power_state of node LOG.warning(_LW(""During sync_power_state, node %(node)s state "" ""'%(actual)s' does not match expected state. "" ""Changing hardware state to '%(state)s'.""), {'node': node.uuid, 'actual': power_state, 'state': node.power_state}) try: # node_power_action will update the node record # so don't do that again here. utils.node_power_action(task, node.power_state) except Exception as e: LOG.error(_LE(""Failed to change power state of node %(node)s "" ""to '%(state)s'.""), {'node': node.uuid, 'state': node.power_state}) attempts_left = CONF.conductor.power_state_sync_max_retries - count LOG.warning(_LW(""%(left)s attempts remaining to "" ""sync_power_state for node %(node)s""), {'left': attempts_left, 'node': node.uuid}) return count"," def _power_state_error_handler(self, e, node, power_state): """"""Set the node's power states if error occurs. This hook gets called upon an execption being raised when spawning the worker thread to change the power state of a node. :param e: the exception object that was raised. :param node: an Ironic node object. :param power_state: the power state to set on the node. """""" if isinstance(e, exception.NoFreeConductorWorker): node.power_state = power_state node.target_power_state = states.NOSTATE node.last_error = (_(""No free conductor workers available"")) node.save() LOG.warning(_LW(""No free conductor workers available to perform "" ""an action on node %(node)s, setting node's "" ""power state back to %(power_state)s.""), {'node': node.uuid, 'power_state': power_state}) task.set_spawn_error_hook(self._power_state_error_handler, def _get_vendor_passthru_metadata(self, route_dict): d = {} for method, metadata in route_dict.iteritems(): # 'func' is the vendor method reference, ignore it d[method] = {k: metadata[k] for k in metadata if k != 'func'} return d return self._get_vendor_passthru_metadata( task.driver.vendor.vendor_routes) return self._get_vendor_passthru_metadata(driver.vendor.driver_routes) def _provisioning_error_handler(self, e, node, provision_state, target_provision_state): """"""Set the node's provisioning states if error occurs. This hook gets called upon an exception being raised when spawning the worker to do the deployment or tear down of a node. :param e: the exception object that was raised. :param node: an Ironic node object. :param provision_state: the provision state to be set on the node. :param target_provision_state: the target provision state to be set on the node. """""" if isinstance(e, exception.NoFreeConductorWorker): # NOTE(deva): there is no need to clear conductor_affinity # because it isn't updated on a failed deploy node.provision_state = provision_state node.target_provision_state = target_provision_state node.last_error = (_(""No free conductor workers available"")) node.save() LOG.warning(_LW(""No free conductor workers available to perform "" ""an action on node %(node)s, setting node's "" ""provision_state back to %(prov_state)s and "" ""target_provision_state to %(tgt_prov_state)s.""), {'node': node.uuid, 'prov_state': provision_state, 'tgt_prov_state': target_provision_state}) task.set_spawn_error_hook(self._provisioning_error_handler, self._do_node_deploy, task) def _do_node_deploy(self, task): """"""Prepare the environment and deploy a node."""""" node = task.node try: task.driver.deploy.prepare(task) new_state = task.driver.deploy.deploy(task) # Update conductor_affinity to reference this conductor's ID # since there may be local persistent state node.conductor_affinity = self.conductor.id except Exception as e: # NOTE(deva): there is no need to clear conductor_affinity with excutils.save_and_reraise_exception(): task.process_event('fail') LOG.warning(_LW('Error in deploy of node %(node)s: %(err)s'), {'node': task.node.uuid, 'err': e}) node.last_error = _(""Failed to deploy. Error: %s"") % e else: # NOTE(deva): Some drivers may return states.DEPLOYWAIT # eg. if they are waiting for a callback if new_state == states.DEPLOYDONE: task.process_event('done') LOG.info(_LI('Successfully deployed node %(node)s with ' 'instance %(instance)s.'), {'node': node.uuid, 'instance': node.instance_uuid}) elif new_state == states.DEPLOYWAIT: task.provess_event('wait') else: LOG.error(_LE('Unexpected state %(state)s returned while ' 'deploying node %(node)s.'), {'state': new_state, 'node': node.uuid}) finally: node.save() task.set_spawn_error_hook(self._provisioning_error_handler, self._do_node_tear_down, task) def _do_node_tear_down(self, task): """"""Internal RPC method to tear down an existing node deployment."""""" node = task.node try: task.driver.deploy.clean_up(task) task.driver.deploy.tear_down(task) except Exception as e: with excutils.save_and_reraise_exception(): task.process_event('error') LOG.warning(_LW('Error in tear_down of node %(node)s: ' '%(err)s'), {'node': task.node.uuid, 'err': e}) task.node.last_error = _(""Failed to tear down. Error: %s"") % e else: # NOTE(deva): When tear_down finishes, the deletion is done task.process_event('done') LOG.info(_LI('Successfully unprovisioned node %(node)s with ' 'instance %(instance)s.'), {'node': node.uuid, 'instance': node.instance_uuid}) # NOTE(deva): For compatibility with ""NOSTATE is None"" # we need to clear the target_state here manually # This can be removed once we migrate to an AVAILABLE state node.target_provision_state = None finally: # NOTE(deva): there is no need to unset conductor_affinity # because it is a reference to the most recent conductor which # deployed a node, and does not limit any future actions. # But we do need to clear the instance_info node.instance_info = {} node.save() def _conductor_service_record_keepalive(self): while not self._keepalive_evt.is_set(): try: self.dbapi.touch_conductor(self.host) except db_exception.DBConnectionError: LOG.warning(_LW('Conductor could not connect to database ' 'while heartbeating.')) self._keepalive_evt.wait(CONF.conductor.heartbeat_interval) def _handle_sync_power_state_max_retries_exceeded(self, task, actual_power_state): node = task.node msg = (_(""During sync_power_state, max retries exceeded "" ""for node %(node)s, node state %(actual)s "" ""does not match expected state '%(state)s'. "" ""Updating DB state to '%(actual)s' "" ""Switching node to maintenance mode."") % {'node': node.uuid, 'actual': actual_power_state, 'state': node.power_state}) node.power_state = actual_power_state node.last_error = msg node.maintenance = True node.maintenance_reason = msg node.save() LOG.error(msg) def _do_sync_power_state(self, task): node = task.node power_state = None # Power driver info should be set properly for new node, otherwise # prevent node from switching to maintenance mode. if node.power_state is None: try: task.driver.power.validate(task) except (exception.InvalidParameterValue, exception.MissingParameterValue): return try: power_state = task.driver.power.get_power_state(task) if power_state == states.ERROR: raise exception.PowerStateFailure(_(""Driver returns ERROR"" "" state."")) except Exception as e: LOG.warning(_LW(""During sync_power_state, could not get power "" ""state for node %(node)s. Error: %(err)s.""), {'node': node.uuid, 'err': e}) self.power_state_sync_count[node.uuid] += 1 if (self.power_state_sync_count[node.uuid] >= CONF.conductor.power_state_sync_max_retries): self._handle_sync_power_state_max_retries_exceeded(task, power_state) return if node.power_state is None: LOG.info(_LI(""During sync_power_state, node %(node)s has no "" ""previous known state. Recording current state "" ""'%(state)s'.""), {'node': node.uuid, 'state': power_state}) node.power_state = power_state node.save() if power_state == node.power_state: if node.uuid in self.power_state_sync_count: del self.power_state_sync_count[node.uuid] return if not CONF.conductor.force_power_state_during_sync: LOG.warning(_LW(""During sync_power_state, node %(node)s state "" ""does not match expected state '%(state)s'. "" ""Updating recorded state to '%(actual)s'.""), {'node': node.uuid, 'actual': power_state, 'state': node.power_state}) node.power_state = power_state node.save() return if (self.power_state_sync_count[node.uuid] >= CONF.conductor.power_state_sync_max_retries): self._handle_sync_power_state_max_retries_exceeded(task, power_state) return # Force actual power_state of node equal to DB power_state of node LOG.warning(_LW(""During sync_power_state, node %(node)s state "" ""'%(actual)s' does not match expected state. "" ""Changing hardware state to '%(state)s'.""), {'node': node.uuid, 'actual': power_state, 'state': node.power_state}) try: # node_power_action will update the node record # so don't do that again here. utils.node_power_action(task, node.power_state) except Exception as e: LOG.error(_LE(""Failed to change power state of node %(node)s "" ""to '%(state)s'.""), {'node': node.uuid, 'state': node.power_state}) attempts_left = (CONF.conductor.power_state_sync_max_retries - self.power_state_sync_count[node.uuid]) - 1 LOG.warning(_LW(""%(left)s attempts remaining to "" ""sync_power_state for node %(node)s""), {'left': attempts_left, 'node': node.uuid}) finally: # Update power state sync count for current node self.power_state_sync_count[node.uuid] += 1 if (node.provision_state == states.DEPLOYWAIT or node.maintenance or node.reservation is not None): with task_manager.acquire(context, node_id) as task: if (task.node.provision_state != states.DEPLOYWAIT and not task.node.maintenance): self._do_sync_power_state(task) @lockutils.synchronized(WORKER_SPAWN_lOCK, 'ironic-') def _spawn_worker(self, func, *args, **kwargs): """"""Create a greenthread to run func(*args, **kwargs). Spawns a greenthread if there are free slots in pool, otherwise raises exception. Execution control returns immediately to the caller. :returns: GreenThread object. :raises: NoFreeConductorWorker if worker pool is currently full. """""" if self._worker_pool.free(): return self._worker_pool.spawn(func, *args, **kwargs) else: raise exception.NoFreeConductorWorker() ",291,273
openstack%2Fapi-site~master~Idffb005d1d39d758974e05a8bc44c0cbfe89026c,openstack/api-site,master,Idffb005d1d39d758974e05a8bc44c0cbfe89026c,Ensures that flavor-access is correctly named without os- prefix,MERGED,2015-01-06 19:01:12.000000000,2015-01-07 04:31:29.000000000,2015-01-07 04:31:29.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-06 19:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/4d24e719ceaf00f5d8b9f17e052300145435518c', 'message': 'Ensures that flavor-access is correctly named without os- prefix\n\nChange-Id: Idffb005d1d39d758974e05a8bc44c0cbfe89026c\nCloses-bug: 1257136\n'}, {'number': 2, 'created': '2015-01-06 20:11:23.000000000', 'files': ['api-ref/src/docbkx/ch_compute-v2.1.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/flavor-access-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/419ed01ba3481de646fad2fd4c40a4844f2ceb6f', 'message': 'Ensures that flavor-access is correctly named without os- prefix\n\nChange-Id: Idffb005d1d39d758974e05a8bc44c0cbfe89026c\nCloses-bug: 1257136\n'}]",0,145301,419ed01ba3481de646fad2fd4c40a4844f2ceb6f,11,4,2,964,,,0,"Ensures that flavor-access is correctly named without os- prefix

Change-Id: Idffb005d1d39d758974e05a8bc44c0cbfe89026c
Closes-bug: 1257136
",git fetch https://review.opendev.org/openstack/api-site refs/changes/01/145301/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/docbkx/ch_compute-v2.1.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/flavor-access-v2.1.wadl']",2,4d24e719ceaf00f5d8b9f17e052300145435518c,bug/1257136,,,2,2
openstack%2Fnova~master~I01df2096ced51eb9ebfd994cf8397f2fa094f6e3,openstack/nova,master,I01df2096ced51eb9ebfd994cf8397f2fa094f6e3,Return floating_ip['fixed_ip']['instance_uuid'] from neutronv2 API,MERGED,2015-01-06 17:13:50.000000000,2015-01-07 03:59:15.000000000,2015-01-06 21:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-06 17:13:50.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/48c24dbb6bc1e55973dce2b8bc3e74105b0020ce', 'message': ""Return floating_ip['fixed_ip']['instance_uuid'] from neutronv2 API\n\nThe os-floating-ips extension translates the floating IP information\nfrom the network API for the response but is only checking fields based\non what comes back from nova-network, which is using the FloatingIP\nobject. The neutronv2 API returns a different set of keys for the\ninstance/instance_uuid which the API extension doesn't handle and\ntherefore doesn't show the associated instance id for a given floating\nIP.\n\nThe network APIs should return consistent data formats so this change\nadds the expected key to fix the bug in the API extension (since the API\nextensions shouldn't have to know the implementation details of the\nnetwork API, there are some extensions actually checking if it's the\nneutron API and parsing the result set based on that).\n\nThis change will be used to backport the fix to the stable branches.\n\nThe longer term fix is to convert the neutronv2 get_floating_ip* API\nmethods to use nova objects which will be done as part of blueprint\nkilo-objects in a separate change.\n\nCloses-Bug: #1380965\n\nChange-Id: I01df2096ced51eb9ebfd994cf8397f2fa094f6e3\n""}]",0,145269,48c24dbb6bc1e55973dce2b8bc3e74105b0020ce,11,8,1,6873,,,0,"Return floating_ip['fixed_ip']['instance_uuid'] from neutronv2 API

The os-floating-ips extension translates the floating IP information
from the network API for the response but is only checking fields based
on what comes back from nova-network, which is using the FloatingIP
object. The neutronv2 API returns a different set of keys for the
instance/instance_uuid which the API extension doesn't handle and
therefore doesn't show the associated instance id for a given floating
IP.

The network APIs should return consistent data formats so this change
adds the expected key to fix the bug in the API extension (since the API
extensions shouldn't have to know the implementation details of the
network API, there are some extensions actually checking if it's the
neutron API and parsing the result set based on that).

This change will be used to backport the fix to the stable branches.

The longer term fix is to convert the neutronv2 get_floating_ip* API
methods to use nova objects which will be done as part of blueprint
kilo-objects in a separate change.

Closes-Bug: #1380965

Change-Id: I01df2096ced51eb9ebfd994cf8397f2fa094f6e3
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/145269/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,48c24dbb6bc1e55973dce2b8bc3e74105b0020ce,bug/1380965, if expected['instance'] is not None: expected['fixed_ip']['instance_uuid'] = \ expected['instance']['uuid'],,6,0
openstack%2Ftricircle~master~I40418f24f4f4813b90add46fe11457819c2bf6ec,openstack/tricircle,master,I40418f24f4f4813b90add46fe11457819c2bf6ec,Add port name for mapping,MERGED,2015-01-07 03:40:12.000000000,2015-01-07 03:41:33.000000000,2015-01-07 03:41:33.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2015-01-07 03:40:12.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/429e12ea34dfc957bb634f8ba43c46ed32247546', 'message': ""Add port name for mapping\n\nWhen creating cascading port in nova proxy, add the 'name' field which\ncontains a cascading network_name and port uuid.\n\nChange-Id: I40418f24f4f4813b90add46fe11457819c2bf6ec\n""}]",0,145399,429e12ea34dfc957bb634f8ba43c46ed32247546,6,2,1,9684,,,0,"Add port name for mapping

When creating cascading port in nova proxy, add the 'name' field which
contains a cascading network_name and port uuid.

Change-Id: I40418f24f4f4813b90add46fe11457819c2bf6ec
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/99/145399/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,429e12ea34dfc957bb634f8ba43c46ed32247546,," net_name = netObj['network']['label'] csd_port_name = self._gen_csd_nets_name(net_name, netObj['ovs_interfaceid']) 'name': csd_port_name,",,4,0
openstack%2Ftempest~master~I548cade87fdd719f71ffdd87950831e2b7c2287e,openstack/tempest,master,I548cade87fdd719f71ffdd87950831e2b7c2287e,Remove ObjectClientCustomizedHeader class,MERGED,2014-12-26 01:43:21.000000000,2015-01-07 03:09:46.000000000,2015-01-07 03:09:44.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-26 01:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/73e625de4843cf908cd694d4603db72a7d04eb0a', 'message': 'WIP: Remove request() from ObjectClientCustomizedHeader\n\nThis patch is WIP for removing the method.\n\nChange-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e\n'}, {'number': 2, 'created': '2014-12-26 02:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9bfe2e0cf740a8c70bcdce5146c3b4cb051696c3', 'message': 'Use common request() for ObjectClientCustomizedHeader\n\nIn ObjectClientCustomizedHeader, there is its own request() method\nbut we can use common request() which is from RestClient for the class.\nThis patch removes request() from ObjectClientCustomizedHeader and\nmakes ObjectClientCustomizedHeader use common request() for cleanup.\n\nChange-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e\n'}, {'number': 3, 'created': '2015-01-01 14:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/39001e7b9722400943737fb4b46c38511ada5103', 'message': 'Use common request() for ObjectClientCustomizedHeader\n\nIn ObjectClientCustomizedHeader, there is its own request() method\nbut we can use common request() which is from RestClient for the class.\nThis patch removes request() from ObjectClientCustomizedHeader and\nmakes ObjectClientCustomizedHeader use common request() for cleanup.\n\nChange-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e\n'}, {'number': 4, 'created': '2015-01-02 15:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7546b9bdc04fd2dc8b5c2e578c6479b069079c8e', 'message': 'Use common request() for ObjectClientCustomizedHeader\n\nIn ObjectClientCustomizedHeader, there is its own request() method\nbut we can use common request() which is from RestClient for the class.\nThis patch removes request() from ObjectClientCustomizedHeader and\nmakes ObjectClientCustomizedHeader use common request() for cleanup.\n\nChange-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e\n'}, {'number': 5, 'created': '2015-01-05 02:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/284840355a7e5d2673f31f2f62e4d394c308b316', 'message': 'Remove ObjectClientCustomizedHeader class\n\nObjectClientCustomizedHeader contains some API methods, and most of\nthem are duplicated with ObjectClient and we can replace them with\nObjectClient methods in many cases.\nThis patch removes ObjectClientCustomizedHeader and makes some tests\nuse ObjectClient instead.\n\nChange-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e\n'}, {'number': 6, 'created': '2015-01-05 23:32:55.000000000', 'files': ['tempest/api/object_storage/base.py', 'tempest/services/object_storage/object_client.py', 'tempest/api/object_storage/test_object_services.py', 'tempest/api/object_storage/test_container_acl.py', 'tempest/api/object_storage/test_container_staticweb.py', 'tempest/clients.py', 'tempest/api/object_storage/test_container_acl_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/179ea57f7afbe76b915e76cef2f83ef35a561f34', 'message': 'Remove ObjectClientCustomizedHeader class\n\nObjectClientCustomizedHeader contains some API methods, and most of\nthem are duplicated with ObjectClient and we can replace them with\nObjectClient methods in many cases.\nThis patch removes ObjectClientCustomizedHeader and makes some tests\nuse ObjectClient instead.\n\nChange-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e\n'}]",3,144070,179ea57f7afbe76b915e76cef2f83ef35a561f34,42,7,6,6167,,,0,"Remove ObjectClientCustomizedHeader class

ObjectClientCustomizedHeader contains some API methods, and most of
them are duplicated with ObjectClient and we can replace them with
ObjectClient methods in many cases.
This patch removes ObjectClientCustomizedHeader and makes some tests
use ObjectClient instead.

Change-Id: I548cade87fdd719f71ffdd87950831e2b7c2287e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/70/144070/6 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/object_storage/object_client.py'],1,73e625de4843cf908cd694d4603db72a7d04eb0a,rest-client, headers = self.get_headers() headers = self.get_headers(), headers = {} headers = {},2,2
openstack%2Fnova~stable%2Fjuno~Icc42e060492bc74febc9414b63970ee71fb9c27c,openstack/nova,stable/juno,Icc42e060492bc74febc9414b63970ee71fb9c27c,fix pep8 errors that apparently slipped in,MERGED,2015-01-02 14:48:06.000000000,2015-01-07 02:54:50.000000000,2015-01-06 21:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-01-02 14:48:06.000000000', 'files': ['nova/tests/compute/test_rpcapi.py', 'nova/tests/compute/test_resources.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5e44c9f7d43ead980ec58fcabbe8036f3234030e', 'message': 'fix pep8 errors that apparently slipped in\n\nApparently, a couple of H302 issues have slipped into Nova, possibly\ndue to hacking releases or a bad merge commit. Fix these as they are\nblocking some other patches.\n\nConflicts:\n        nova/tests/unit/compute/test_resources.py\n        nova/tests/unit/compute/test_rpcapi.py\n\nCloses-Bug: #1407024\n\nChange-Id: Icc42e060492bc74febc9414b63970ee71fb9c27c\n(cherry picked from commit f3b9d9e7b9a123e55a48393bd07e491ca03bd8f3)\n'}]",0,144760,5e44c9f7d43ead980ec58fcabbe8036f3234030e,26,10,1,6873,,,0,"fix pep8 errors that apparently slipped in

Apparently, a couple of H302 issues have slipped into Nova, possibly
due to hacking releases or a bad merge commit. Fix these as they are
blocking some other patches.

Conflicts:
        nova/tests/unit/compute/test_resources.py
        nova/tests/unit/compute/test_rpcapi.py

Closes-Bug: #1407024

Change-Id: Icc42e060492bc74febc9414b63970ee71fb9c27c
(cherry picked from commit f3b9d9e7b9a123e55a48393bd07e491ca03bd8f3)
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/144760/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_rpcapi.py', 'nova/tests/compute/test_resources.py']",2,5e44c9f7d43ead980ec58fcabbe8036f3234030e,bug/1407024,from nova.tests import fake_instance self._instance = fake_instance.fake_instance_obj(None),from nova.tests.fake_instance import fake_instance_obj self._instance = fake_instance_obj(None),4,4
openstack%2Ftempest-lib~master~Ie5218c7576f0fe3bc56a44c38a6101d6e16618bb,openstack/tempest-lib,master,Ie5218c7576f0fe3bc56a44c38a6101d6e16618bb,Update cli/base.py to add interface for python-openstackclient.,ABANDONED,2015-01-07 02:25:45.000000000,2015-01-07 02:51:56.000000000,,[{'_account_id': 5196}],"[{'number': 1, 'created': '2015-01-07 02:25:45.000000000', 'files': ['tempest_lib/cli/base.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/33ab291e9bcbaba5c525d4689eb87f003f2dadd9', 'message': 'Update cli/base.py to add interface for python-openstackclient.\n\nChange-Id: Ie5218c7576f0fe3bc56a44c38a6101d6e16618bb\n'}]",0,145395,33ab291e9bcbaba5c525d4689eb87f003f2dadd9,3,1,1,47,,,0,"Update cli/base.py to add interface for python-openstackclient.

Change-Id: Ie5218c7576f0fe3bc56a44c38a6101d6e16618bb
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/95/145395/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest_lib/cli/base.py'],1,33ab291e9bcbaba5c525d4689eb87f003f2dadd9,cli," def openstack(self, action, flags='', params='', fail_ok=False, merge_stderr=False): """"""Executes openstack command for the given action. :param action: the cli command to run using openstack :type action: string :param flags: any optional cli flags to use :type flags: string :param params: any optional positional args to use :type params: string :param fail_ok: if True an exception is not raised when the cli return code is non-zero :type fail_ok: boolean :param merge_stderr: if True the stderr buffer is merged into stdout :type merge_stderr: boolean """""" return self.cmd_with_auth( 'openstack', action, flags, params, fail_ok, merge_stderr) ",,20,0
openstack%2Foslo.config~master~Icebbf3ce2bdf0d2deae9b057bd70ab706aad820e,openstack/oslo.config,master,Icebbf3ce2bdf0d2deae9b057bd70ab706aad820e,Fix of wrong cli opts unregistration,MERGED,2015-01-06 12:37:27.000000000,2015-01-07 02:49:48.000000000,2015-01-07 02:49:47.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6172}]","[{'number': 1, 'created': '2015-01-06 12:37:27.000000000', 'files': ['oslo_config/cfg.py', 'tests/test_cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/035636ddd6afdb899550efce6d1da6511a0ba8d8', 'message': ""Fix of wrong cli opts unregistration\n\nThis code allows to unregister a cli option by passing to\nthe method any Opt object with 'dest' field and not exactly\nthe one that was used during creation.\n\nChange-Id: Icebbf3ce2bdf0d2deae9b057bd70ab706aad820e\nCloses-Bug: 1407950\n""}]",0,145214,035636ddd6afdb899550efce6d1da6511a0ba8d8,8,4,1,11391,,,0,"Fix of wrong cli opts unregistration

This code allows to unregister a cli option by passing to
the method any Opt object with 'dest' field and not exactly
the one that was used during creation.

Change-Id: Icebbf3ce2bdf0d2deae9b057bd70ab706aad820e
Closes-Bug: 1407950
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/14/145214/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_config/cfg.py', 'tests/test_cfg.py']",2,035636ddd6afdb899550efce6d1da6511a0ba8d8,bug/1407950," cfg.CONF.register_group(cfg.OptGroup('blaa')) self.conf.register_cli_opt(arg2, group='blaa') self.assertEqual(3, len(self.conf._cli_opts)) self.assertEqual(1, len(self.conf._groups)) self.assertEqual('command', self.conf._cli_opts[0]['opt'].dest) self.assertEqual('arg1', self.conf._cli_opts[1]['opt'].dest) self.assertEqual('arg2', self.conf._cli_opts[2]['opt'].dest) self.assertEqual('blaa', self.conf._cli_opts[2]['group'].name) new_arg1 = cfg.StrOpt('arg1', positional=True) new_arg2 = cfg.StrOpt('arg2', positional=True) self.conf.unregister_opt(new_arg1) self.assertEqual(2, len(self.conf._cli_opts)) self.assertRaises(cfg.NoSuchGroupError, self.conf.unregister_opt, new_arg2, group='foo') self.conf.unregister_opt(new_arg2, group='blaa') self.assertEqual(1, len(self.conf._cli_opts)) self.assertEqual('command', self.conf._cli_opts[0]['opt'].dest) self.conf.reset() self.assertEqual('command', self.conf._cli_opts[0]['opt'].dest) self.assertEqual('arg0', self.conf._cli_opts[1]['opt'].dest) self.assertEqual('arg1', self.conf._cli_opts[2]['opt'].dest)"," self.conf.register_cli_opt(arg2) self.assertEqual('command', self.conf.command) self.assertEqual('arg1', self.conf.arg1) self.assertEqual('arg2', self.conf.arg2) self.conf.unregister_opt(arg1) self.conf.unregister_opt(arg2) self.assertEqual('command', self.conf.command) self.assertEqual('arg0', self.conf.arg0) self.assertEqual('arg1', self.conf.arg1)",38,12
openstack%2Fironic~master~Ia310a5430dcb0a38f8653bbdf5caac82b6990414,openstack/ironic,master,Ia310a5430dcb0a38f8653bbdf5caac82b6990414,Hide oslo.messaging DEBUG logs by default,MERGED,2015-01-06 22:17:13.000000000,2015-01-07 02:27:18.000000000,2015-01-07 02:27:17.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 10342}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-06 22:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f08a31a515bb95a568e9abe0b8f7f9bc12ebbfca', 'message': 'Hide oslo.messaging DEBUG logs by default\n\nThis change moves the default log level for oslo.messaging\nfrom DEBUG to INFO.\n\nThis hides the once-per-second debug log lines which started in\noslo.messaging 1.5.0.\n\nChange-Id: Ia310a5430dcb0a38f8653bbdf5caac82b6990414\nCloses-bug: #1403106\n'}, {'number': 2, 'created': '2015-01-06 23:58:39.000000000', 'files': ['ironic/common/service.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7ec094c2c26da3fec809e1fab07426ec631570fa', 'message': 'Hide oslo.messaging DEBUG logs by default\n\nThis change moves the default log level for oslo.messaging\nfrom DEBUG to INFO.\n\nThis hides the once-per-second debug log lines which started in\noslo.messaging 1.5.0.\n\nChange-Id: Ia310a5430dcb0a38f8653bbdf5caac82b6990414\nCloses-bug: #1399257\n'}]",1,145361,7ec094c2c26da3fec809e1fab07426ec631570fa,20,5,2,2889,,,0,"Hide oslo.messaging DEBUG logs by default

This change moves the default log level for oslo.messaging
from DEBUG to INFO.

This hides the once-per-second debug log lines which started in
oslo.messaging 1.5.0.

Change-Id: Ia310a5430dcb0a38f8653bbdf5caac82b6990414
Closes-bug: #1399257
",git fetch https://review.opendev.org/openstack/ironic refs/changes/61/145361/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/service.py'],1,f08a31a515bb95a568e9abe0b8f7f9bc12ebbfca,fix-1403106," 'oslo.messaging=INFO',",,1,0
openstack%2Fheat~master~Ie2d57c406665748f287d08eac76c28f90e2b3697,openstack/heat,master,Ie2d57c406665748f287d08eac76c28f90e2b3697,Stop patching oslo.messaging private bits,MERGED,2015-01-05 23:53:30.000000000,2015-01-07 02:26:59.000000000,2015-01-07 02:26:58.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 8289}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-01-05 23:53:30.000000000', 'files': ['heat/tests/test_stack_lock.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5168a169f88637a5c9abbe8df72122776ec2590a', 'message': 'Stop patching oslo.messaging private bits\n\nThis patches at the level of the engine_alive method, then\ntests that method separately.\n\nChange-Id: Ie2d57c406665748f287d08eac76c28f90e2b3697\n'}]",0,145094,5168a169f88637a5c9abbe8df72122776ec2590a,22,8,1,4715,,,0,"Stop patching oslo.messaging private bits

This patches at the level of the engine_alive method, then
tests that method separately.

Change-Id: Ie2d57c406665748f287d08eac76c28f90e2b3697
",git fetch https://review.opendev.org/openstack/heat refs/changes/94/145094/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_stack_lock.py'],1,5168a169f88637a5c9abbe8df72122776ec2590a,," self.patchobject(slock, 'engine_alive', return_value=False) self.patchobject(slock, 'engine_alive', return_value=True) self.patchobject(slock, 'engine_alive', return_value=False) self.patchobject(slock, 'engine_alive', return_value=False) self.patchobject(slock, 'engine_alive', return_value=False) def test_engine_alive_ok(self): slock = stack_lock.StackLock(self.context, self.stack, self.engine_id) mget_client = self.patchobject(stack_lock.rpc_messaging, 'get_rpc_client') mclient = mget_client.return_value mclient_ctx = mclient.prepare.return_value mclient_ctx.call.return_value = True ret = slock.engine_alive(self.context, self.engine_id) self.assertTrue(ret) mclient.prepare.assert_called_once_with(timeout=2) mclient_ctx.call.assert_called_once_with(self.context, 'listening') def test_engine_alive_timeout(self): slock = stack_lock.StackLock(self.context, self.stack, self.engine_id) mget_client = self.patchobject(stack_lock.rpc_messaging, 'get_rpc_client') mclient = mget_client.return_value mclient_ctx = mclient.prepare.return_value mclient_ctx.call.side_effect = messaging.MessagingTimeout('too slow') ret = slock.engine_alive(self.context, self.engine_id) self.assertIs(False, ret) mclient.prepare.assert_called_once_with(timeout=2) mclient_ctx.call.assert_called_once_with(self.context, 'listening')"," self.m.StubOutWithMock(messaging.rpc.client._CallContext, ""call"") messaging.rpc.client._CallContext.call( self.context, ""listening"").AndRaise(messaging.MessagingTimeout) self.m.StubOutWithMock(messaging.rpc.client._CallContext, ""call"") messaging.rpc.client._CallContext.call( self.context, ""listening"").AndReturn(True) self.m.StubOutWithMock(messaging.rpc.client._CallContext, ""call"") messaging.rpc.client._CallContext.call( self.context, ""listening"").AndRaise(messaging.MessagingTimeout) self.m.StubOutWithMock(messaging.rpc.client._CallContext, ""call"") messaging.rpc.client._CallContext.call( self.context, ""listening"").AndRaise(messaging.MessagingTimeout) messaging.rpc.client._CallContext.call( self.context, ""listening"").AndRaise(messaging.MessagingTimeout) self.m.StubOutWithMock(messaging.rpc.client._CallContext, ""call"") messaging.rpc.client._CallContext.call( self.context, ""listening"").AndRaise(messaging.MessagingTimeout) messaging.rpc.client._CallContext.call( self.context, ""listening"").AndRaise(messaging.MessagingTimeout) ",29,27
openstack%2Fneutron~master~I2e373f8fe26f77db832da00c56ada6cfa3c50746,openstack/neutron,master,I2e373f8fe26f77db832da00c56ada6cfa3c50746,Reduce duplicate code in test_iptables_manager,MERGED,2014-12-29 11:03:05.000000000,2015-01-07 02:26:46.000000000,2015-01-07 02:26:44.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 704}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 12076}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-29 11:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e7a38e3989ca9b60484633f43940bcbba3255c4', 'message': 'Reduce duplicate code in test_iptables_manager\n\ntest_iptables_manager contains many hard-code iptables dumps\nwhich share most of the contents, extract the common part to\nreduce duplication.\n\nChange-Id: I2e373f8fe26f77db832da00c56ada6cfa3c50746\n'}, {'number': 2, 'created': '2014-12-30 03:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/87b8bb55d07eb62c2958b445d51adc77db0a9889', 'message': 'Reduce duplicate code in test_iptables_manager\n\ntest_iptables_manager contains many hard-code iptables dumps\nwhich share most of the contents, extract the common part to\nreduce duplication.\n\nChange-Id: I2e373f8fe26f77db832da00c56ada6cfa3c50746\n'}, {'number': 3, 'created': '2015-01-06 10:46:00.000000000', 'files': ['neutron/tests/unit/test_iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8af2cc5c21a17cb05d1733feae4e501e614d028c', 'message': 'Reduce duplicate code in test_iptables_manager\n\ntest_iptables_manager contains many hard-code iptables dumps\nwhich share most of the contents, extract the common part to\nreduce duplication.\n\nChange-Id: I2e373f8fe26f77db832da00c56ada6cfa3c50746\n'}]",4,144284,8af2cc5c21a17cb05d1733feae4e501e614d028c,59,23,3,12076,,,0,"Reduce duplicate code in test_iptables_manager

test_iptables_manager contains many hard-code iptables dumps
which share most of the contents, extract the common part to
reduce duplication.

Change-Id: I2e373f8fe26f77db832da00c56ada6cfa3c50746
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/144284/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_iptables_manager.py'],1,0e7a38e3989ca9b60484633f43940bcbba3255c4,reduce-duplicate-code," 'snat_out_comment': ic.SNAT_OUT, 'filter_rules': ''} NAT_TEMP = ('# Generated by iptables_manager\n' '# Completed by iptables_manager\n') NAT_DUMP = NAT_TEMP % IPTABLES_ARG FILTER_TEMP = ('# Generated by iptables_manager\n' '# Completed by iptables_manager\n') FILTER_DUMP = FILTER_TEMP % IPTABLES_ARG FILTER_WITH_RULES_TEMP = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' '%(filter_rules)s' 'COMMIT\n' '# Completed by iptables_manager\n') iptables_args = {} iptables_args.update(IPTABLES_ARG) filter_rules = ('[0:0] -A %(bn)s-filter -j DROP\n' '[0:0] -A %(bn)s-INPUT -s 0/0 -d 192.168.0.2 -j ' '%(bn)s-filter\n' % iptables_args) iptables_args['filter_rules'] = filter_rules filter_dump_mod = FILTER_WITH_RULES_TEMP % iptables_args iptables_args = {'bn': bn[:16], 'filter_rules': ''} filter_dump = FILTER_WITH_RULES_TEMP % iptables_args filter_dump_ipv6 = FILTER_TEMP % iptables_args filter_dump_mod = filter_dump nat_dump = NAT_TEMP % iptables_args filter_dump = FILTER_TEMP % iptables_args filter_rules = ('[0:0] -A %(bn)s-filter -s 0/0 -d 192.168.0.2\n' % iptables_args) iptables_args['filter_rules'] = filter_rules filter_dump_mod = FILTER_WITH_RULES_TEMP % iptables_args nat_dump = NAT_TEMP % iptables_args filter_dump_mod = FILTER_WITH_RULES_TEMP % IPTABLES_ARG iptables_args = {} iptables_args.update(IPTABLES_ARG) filter_rules = ('[0:0] -A %(bn)s-filter -j DROP\n' '[0:0] -A %(bn)s-INPUT -s 0/0 -d 192.168.0.2 -j ' '%(bn)s-filter\n' % iptables_args) iptables_args['filter_rules'] = filter_rules filter_dump_mod = FILTER_WITH_RULES_TEMP % iptables_args nat_dump = NAT_TEMP % IPTABLES_ARG", 'snat_out_comment': ic.SNAT_OUT} NAT_DUMP = ('# Generated by iptables_manager\n' '# Completed by iptables_manager\n' % IPTABLES_ARG) FILTER_DUMP = ('# Generated by iptables_manager\n' '# Completed by iptables_manager\n' % IPTABLES_ARG) filter_dump_mod = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' '[0:0] -A %(bn)s-filter -j DROP\n' '[0:0] -A %(bn)s-INPUT -s 0/0 -d 192.168.0.2 -j ' '%(bn)s-filter\n' 'COMMIT\n' '# Completed by iptables_manager\n' % IPTABLES_ARG) iptables_args = {'bn': bn[:16]} filter_dump = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) filter_dump_ipv6 = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) filter_dump_mod = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) nat_dump = ('# Generated by iptables_manager\n' '*nat\n' ':neutron-postrouting-bottom - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-POSTROUTING - [0:0]\n' ':%(bn)s-PREROUTING - [0:0]\n' ':%(bn)s-float-snat - [0:0]\n' ':%(bn)s-snat - [0:0]\n' '[0:0] -A PREROUTING -j %(bn)s-PREROUTING\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A POSTROUTING -j %(bn)s-POSTROUTING\n' '[0:0] -A POSTROUTING -j neutron-postrouting-bottom\n' '[0:0] -A neutron-postrouting-bottom -j %(bn)s-snat\n' '[0:0] -A %(bn)s-snat -j ' '%(bn)s-float-snat\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) filter_dump = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) filter_dump_mod = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' '[0:0] -A %(bn)s-filter -s 0/0 -d 192.168.0.2\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) nat_dump = ('# Generated by iptables_manager\n' '*nat\n' ':neutron-postrouting-bottom - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-POSTROUTING - [0:0]\n' ':%(bn)s-PREROUTING - [0:0]\n' ':%(bn)s-float-snat - [0:0]\n' ':%(bn)s-snat - [0:0]\n' '[0:0] -A PREROUTING -j %(bn)s-PREROUTING\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A POSTROUTING -j %(bn)s-POSTROUTING\n' '[0:0] -A POSTROUTING -j neutron-postrouting-bottom\n' '[0:0] -A neutron-postrouting-bottom -j %(bn)s-snat\n' '[0:0] -A %(bn)s-snat -j ' '%(bn)s-float-snat\n' 'COMMIT\n' '# Completed by iptables_manager\n' % iptables_args) filter_dump_mod = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' 'COMMIT\n' '# Completed by iptables_manager\n' % IPTABLES_ARG) filter_dump_mod = ('# Generated by iptables_manager\n' '*filter\n' ':neutron-filter-top - [0:0]\n' ':%(bn)s-FORWARD - [0:0]\n' ':%(bn)s-INPUT - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-filter - [0:0]\n' ':%(bn)s-local - [0:0]\n' '[0:0] -A FORWARD -j neutron-filter-top\n' '[0:0] -A OUTPUT -j neutron-filter-top\n' '[0:0] -A neutron-filter-top -j %(bn)s-local\n' '[0:0] -A INPUT -j %(bn)s-INPUT\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A FORWARD -j %(bn)s-FORWARD\n' '[0:0] -A %(bn)s-filter -j DROP\n' '[0:0] -A %(bn)s-INPUT -s 0/0 -d 192.168.0.2 -j ' '%(bn)s-filter\n' 'COMMIT\n' '# Completed by iptables_manager\n' % IPTABLES_ARG) nat_dump = ('# Generated by iptables_manager\n' '*nat\n' ':neutron-postrouting-bottom - [0:0]\n' ':%(bn)s-OUTPUT - [0:0]\n' ':%(bn)s-POSTROUTING - [0:0]\n' ':%(bn)s-PREROUTING - [0:0]\n' ':%(bn)s-float-snat - [0:0]\n' ':%(bn)s-snat - [0:0]\n' '[0:0] -A PREROUTING -j %(bn)s-PREROUTING\n' '[0:0] -A OUTPUT -j %(bn)s-OUTPUT\n' '[0:0] -A POSTROUTING -j %(bn)s-POSTROUTING\n' '[0:0] -A POSTROUTING -j neutron-postrouting-bottom\n' '[0:0] -A neutron-postrouting-bottom -j %(bn)s-snat\n' '[0:0] -A %(bn)s-snat -j %(bn)s-float-snat\n' 'COMMIT\n' '# Completed by iptables_manager\n' % IPTABLES_ARG),55,196
openstack%2Fneutron-lbaas~master~I8343d83c645f3037ac237d7f47744c1c7e4356f8,openstack/neutron-lbaas,master,I8343d83c645f3037ac237d7f47744c1c7e4356f8,Merge feature/lbaasv2,MERGED,2014-12-12 02:17:00.000000000,2015-01-07 02:20:35.000000000,2015-01-07 02:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 6951}, {'_account_id': 7590}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-12 02:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e9f12efb889e139657dda19302ef288c2705602e', 'message': 'Merge feature/lbaasv2\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\n'}, {'number': 2, 'created': '2014-12-12 02:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/bba593fb83f666fa60150309becefe5206f7ab78', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\n'}, {'number': 3, 'created': '2014-12-12 21:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/250776d33d57d9808e4c7fa4174e37e57df3a2c3', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\n'}, {'number': 4, 'created': '2014-12-13 02:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/55d7e5aa245b28cd9665b31985c35e17c704f38e', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\n'}, {'number': 5, 'created': '2014-12-13 03:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/53f7393dc42caeffad7e0025988f0eefa0c23603', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\n'}, {'number': 6, 'created': '2014-12-14 05:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/060d58d3ab102229befbfde274e4d2d63a3bb473', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\n'}, {'number': 7, 'created': '2014-12-16 23:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/9a7a30b7cfaa8f9457d7bc406b047bbfba6fea22', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\nCo-authored-by: Pattabi Ayyasami <pattabi@brocade.com>\n'}, {'number': 8, 'created': '2014-12-17 01:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b70d42c51f17eb227390b98c07adf942f209e409', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\nCo-authored-by: Pattabi Ayyasami <pattabi@brocade.com>\n'}, {'number': 9, 'created': '2014-12-19 22:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/a1d233329039964e26a50071d707bfb8970f02e6', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\nCo-authored-by: Pattabi Ayyasami <pattabi@brocade.com>\n'}, {'number': 10, 'created': '2014-12-21 09:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e69ee5a263e119d0eeb19f172ec96f508182f131', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\nCo-authored-by: Pattabi Ayyasami <pattabi@brocade.com>\n'}, {'number': 11, 'created': '2015-01-03 07:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b61ac93728fade2a6fbc003ba984edecb1cb106f', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\nCo-authored-by: Pattabi Ayyasami <pattabi@brocade.com>\n'}, {'number': 12, 'created': '2015-01-06 23:27:35.000000000', 'files': ['neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_base.template', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_v1.4_proxies.template', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_v1.4.template', 'neutron_lbaas/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/tests/base.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_base.py', 'neutron_lbaas/services/loadbalancer/constants.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py', 'neutron_lbaas/db/loadbalancer/models.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_mixins.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/lbaasv2.py', 'neutron_lbaas/services/loadbalancer/data_models.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/HEAD'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c7c77b33ba02b64ffa887bb9b837be5e8a3c22ef', 'message': 'Merge feature/lbaasv2\n\nNew extension for version 2 of LBaaS API\n\nAlso added some constants for supported protocols, algorithms,\nhealth monitor types, and session persistence types.\n\nImplement Jinja templates for haproxy config\n\nAdded templates dir\nAdded haproxy v1.4 template\nAdded template tests\nAdded jinja_cfg for new haproxy jinja templating\n\nTests for extension, db and plugin for LBaaS V2\n\nAdding needed driver interface changes for tests.\nAdding LoggingNoop driver needed changes for tests.\nAdding extension, plugin, and db unit tests.\n\nPlugin/DB additions for version 2 of LBaaS API\n\nAdded alembic migrations, models, db methods and plugin methods.\nAdded DEFERRED status for entities not linked to a load balancer.\nAdded to_dict method in BaseNeutron model.\nSql Alchemy models in its own module.\nPlugin database methods are accessed by composition through the plugin.\nAdded data models to convert sql alchemy models before passing to driver.\n\nPartially-implements: blueprint lbaas-api-and-objmodel-improvement\nPartially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n\nPartially-implements: blueprint services-split\n\nChange-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nCo-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>\nCo-authored-by: Craig Tracey <Craig.Tracey@gmail.com>\nCo-authored-by: Pattabi Ayyasami <pattabi@brocade.com>\n'}]",6,141247,c7c77b33ba02b64ffa887bb9b837be5e8a3c22ef,63,8,12,10980,,,0,"Merge feature/lbaasv2

New extension for version 2 of LBaaS API

Also added some constants for supported protocols, algorithms,
health monitor types, and session persistence types.

Implement Jinja templates for haproxy config

Added templates dir
Added haproxy v1.4 template
Added template tests
Added jinja_cfg for new haproxy jinja templating

Tests for extension, db and plugin for LBaaS V2

Adding needed driver interface changes for tests.
Adding LoggingNoop driver needed changes for tests.
Adding extension, plugin, and db unit tests.

Plugin/DB additions for version 2 of LBaaS API

Added alembic migrations, models, db methods and plugin methods.
Added DEFERRED status for entities not linked to a load balancer.
Added to_dict method in BaseNeutron model.
Sql Alchemy models in its own module.
Plugin database methods are accessed by composition through the plugin.
Added data models to convert sql alchemy models before passing to driver.

Partially-implements: blueprint lbaas-api-and-objmodel-improvement
Partially-implements: blueprint lbaas-refactor-haproxy-namespace-driver-to-n
Partially-implements: blueprint services-split

Change-Id: I8343d83c645f3037ac237d7f47744c1c7e4356f8
Co-Authored-By: Brandon Logan <brandon.logan@rackspace.com>
Co-Authored-By: Phillip Toohill <phillip.toohill@rackspace.com>
Co-Authored-By: Dustin Lundquist <dustin@null-ptr.net>
Co-authored-by: Vijayendra Bhamidipati <vbhamidipati@paypal.com>
Co-authored-by: Craig Tracey <Craig.Tracey@gmail.com>
Co-authored-by: Pattabi Ayyasami <pattabi@brocade.com>
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/47/141247/12 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_base.template', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_v1.4_proxies.template', 'neutron_lbaas/tests.skip/unit/db/loadbalancer/test_db_loadbalancerv2.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_v1.4.template', 'neutron_lbaas/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_base.py', 'neutron_lbaas/services/loadbalancer/constants.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron_lbaas/db/loadbalancer/models.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_mixins.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/drivers/haproxy/sample_configs/__init__.py', 'neutron_lbaas/services/loadbalancer/data_models.py']",19,e9f12efb889e139657dda19302ef288c2705602e,bp/lbaas-api-and-objmodel-improvement,"# Copyright (c) 2014 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" This module holds the data models for the load balancer service plugin. These are meant simply as replacement data structures for dictionaries and SQLAlchemy models. Using dictionaries as data containers for many components causes readability issues and does not intuitively give the benefits of what classes and OO give. Using SQLAlchemy models as data containers for many components can become an issue if you do not want to give certain components access to the database. These data models do provide methods for instantiation from SQLAlchemy models and also converting to dictionaries. """""" from sqlalchemy.orm import collections from neutron.db.loadbalancer import models from neutron.db import model_base from neutron.db import models_v2 from neutron.db import servicetype_db class BaseDataModel(object): # NOTE(brandon-logan) This does not discover dicts for relationship # attributes. def to_dict(self): ret = {} for attr in self.__dict__: if (attr.startswith('_') or isinstance(getattr(self, attr), BaseDataModel)): continue ret[attr] = self.__dict__[attr] return ret @classmethod def from_sqlalchemy_model(cls, sa_model, calling_class=None): instance = cls() for attr_name in vars(instance): if attr_name.startswith('_'): continue attr = getattr(sa_model, attr_name) # Handles M:1 or 1:1 relationships if isinstance(attr, model_base.BASEV2): if hasattr(instance, attr_name): data_class = SA_MODEL_TO_DATA_MODEL_MAP[attr.__class__] if calling_class != data_class and data_class: setattr(instance, attr_name, data_class.from_sqlalchemy_model( attr, calling_class=cls)) # Handles 1:M or M:M relationships elif isinstance(attr, collections.InstrumentedList): for item in attr: if hasattr(instance, attr_name): data_class = SA_MODEL_TO_DATA_MODEL_MAP[item.__class__] attr_list = getattr(instance, attr_name) or [] attr_list.append(data_class.from_sqlalchemy_model( item, calling_class=cls)) setattr(instance, attr_name, attr_list) # This isn't a relationship so it must be a ""primitive"" else: setattr(instance, attr_name, getattr(sa_model, attr_name)) return instance # NOTE(brandon-logan) IPAllocation, Port, and ProviderResourceAssociation are # defined here because there aren't any data_models defined in core neutron # or neutron services. Instead of jumping through the hoops to create those # I've just defined them here. If ever data_models or similar are defined # in those packages, those should be used instead of these. class IPAllocation(BaseDataModel): def __init__(self, port_id=None, ip_address=None, subnet_id=None, network_id=None): self.port_id = port_id self.ip_address = ip_address self.subnet_id = subnet_id self.network_id = network_id class Port(BaseDataModel): def __init__(self, id=None, tenant_id=None, name=None, network_id=None, mac_address=None, admin_state_up=None, status=None, device_id=None, device_owner=None, fixed_ips=None): self.id = id self.tenant_id = tenant_id self.name = name self.network_id = network_id self.mac_address = mac_address self.admin_state_up = admin_state_up self.status = status self.device_id = device_id self.device_owner = device_owner self.fixed_ips = fixed_ips or [] class ProviderResourceAssociation(BaseDataModel): def __init__(self, provider_name=None, resource_id=None): self.provider_name = provider_name self.resource_id = resource_id class SessionPersistence(BaseDataModel): def __init__(self, pool_id=None, type=None, cookie_name=None, pool=None): self.pool_id = pool_id self.type = type self.cookie_name = cookie_name self.pool = pool def to_dict(self): ret_dict = super(SessionPersistence, self).to_dict() ret_dict.pop('pool_id', None) ret_dict.pop('pool', None) return ret_dict class LoadBalancerStatistics(BaseDataModel): def __init__(self, loadbalancer_id=None, bytes_in=None, bytes_out=None, active_connections=None, total_connections=None, loadbalancer=None): self.loadbalancer_id = loadbalancer_id self.bytes_in = bytes_in self.bytes_out = bytes_out self.active_connections = active_connections self.total_connections = total_connections self.loadbalancer = loadbalancer def to_dict(self): ret = super(LoadBalancerStatistics, self).to_dict() ret.pop('loadbalancer_id', None) return ret class HealthMonitor(BaseDataModel): def __init__(self, id=None, tenant_id=None, type=None, delay=None, timeout=None, max_retries=None, http_method=None, url_path=None, expected_codes=None, status=None, admin_state_up=None, pool=None): self.id = id self.tenant_id = tenant_id self.type = type self.delay = delay self.timeout = timeout self.max_retries = max_retries self.http_method = http_method self.url_path = url_path self.expected_codes = expected_codes self.status = status self.admin_state_up = admin_state_up self.pool = pool def attached_to_loadbalancer(self): return bool(self.pool and self.pool.listener and self.pool.listener.loadbalancer) class Pool(BaseDataModel): def __init__(self, id=None, tenant_id=None, name=None, description=None, healthmonitor_id=None, protocol=None, lb_algorithm=None, admin_state_up=None, status=None, members=None, healthmonitor=None, sessionpersistence=None, listener=None): self.id = id self.tenant_id = tenant_id self.name = name self.description = description self.healthmonitor_id = healthmonitor_id self.protocol = protocol self.lb_algorithm = lb_algorithm self.admin_state_up = admin_state_up self.status = status self.members = members or [] self.healthmonitor = healthmonitor self.sessionpersistence = sessionpersistence self.listener = listener def attached_to_loadbalancer(self): return bool(self.listener and self.listener.loadbalancer) def to_dict(self): ret_dict = super(Pool, self).to_dict() ret_dict['members'] = [member.to_dict() for member in self.members] if self.sessionpersistence: ret_dict['session_persistence'] = self.sessionpersistence.to_dict() return ret_dict class Member(BaseDataModel): def __init__(self, id=None, tenant_id=None, pool_id=None, address=None, protocol_port=None, weight=None, admin_state_up=None, subnet_id=None, status=None, pool=None): self.id = id self.tenant_id = tenant_id self.pool_id = pool_id self.address = address self.protocol_port = protocol_port self.weight = weight self.admin_state_up = admin_state_up self.subnet_id = subnet_id self.status = status self.pool = pool def attached_to_loadbalancer(self): return bool(self.pool and self.pool.listener and self.pool.listener.loadbalancer) class Listener(BaseDataModel): def __init__(self, id=None, tenant_id=None, name=None, description=None, default_pool_id=None, loadbalancer_id=None, protocol=None, protocol_port=None, connection_limit=None, admin_state_up=None, status=None, default_pool=None, loadbalancer=None): self.id = id self.tenant_id = tenant_id self.name = name self.description = description self.default_pool_id = default_pool_id self.loadbalancer_id = loadbalancer_id self.protocol = protocol self.protocol_port = protocol_port self.connection_limit = connection_limit self.admin_state_up = admin_state_up self.status = status self.default_pool = default_pool self.loadbalancer = loadbalancer def attached_to_loadbalancer(self): return bool(self.loadbalancer) class LoadBalancer(BaseDataModel): def __init__(self, id=None, tenant_id=None, name=None, description=None, vip_subnet_id=None, vip_port_id=None, vip_address=None, status=None, admin_state_up=None, vip_port=None, stats=None, provider=None, listeners=None): self.id = id self.tenant_id = tenant_id self.name = name self.description = description self.vip_subnet_id = vip_subnet_id self.vip_port_id = vip_port_id self.vip_address = vip_address self.status = status self.admin_state_up = admin_state_up self.vip_port = vip_port self.stats = stats self.provider = provider self.listeners = listeners or [] def attached_to_loadbalancer(self): return True SA_MODEL_TO_DATA_MODEL_MAP = { models.LoadBalancer: LoadBalancer, models.HealthMonitorV2: HealthMonitor, models.Listener: Listener, models.PoolV2: Pool, models.MemberV2: Member, models.LoadBalancerStatistics: LoadBalancerStatistics, models.SessionPersistenceV2: SessionPersistence, models_v2.IPAllocation: IPAllocation, models_v2.Port: Port, servicetype_db.ProviderResourceAssociation: ProviderResourceAssociation } ",,4902,75
openstack%2Fneutron~master~Id91161ecacd902d1dc28a4a0dd01da3778486a88,openstack/neutron,master,Id91161ecacd902d1dc28a4a0dd01da3778486a88,Delete the console scripts for lbaas and vpnaas,MERGED,2014-12-29 08:11:07.000000000,2015-01-07 02:20:23.000000000,2015-01-07 02:20:22.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10980}, {'_account_id': 11159}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-29 08:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ea3d63b09e0395eaaa07addd8db9ee3863217e4', 'message': 'Delete the console scripts for lbaas and vpnaas, as the code has been moved out.\n\nFix bug 1405095\n\nChange-Id: Id91161ecacd902d1dc28a4a0dd01da3778486a88\n'}, {'number': 2, 'created': '2014-12-31 05:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/830d18d011377a69cc69825780220622093b2e25', 'message': 'Delete the console scripts for lbaas and vpnaas\n\nCodes of lbaas and vnpaas have been moved out, so we need to remove these console scripts.\n\nCloses-Bug: #1405095\n\nChange-Id: Id91161ecacd902d1dc28a4a0dd01da3778486a88\n'}, {'number': 3, 'created': '2014-12-31 10:32:54.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc343dc92d4b8f25fc32d0d4039249ccdfb01304', 'message': 'Delete the console scripts for lbaas and vpnaas\n\nCodes of lbaas and vnpaas have been moved out, so we need to\nremove these console scripts.\n\nCloses-Bug: #1405095\n\nChange-Id: Id91161ecacd902d1dc28a4a0dd01da3778486a88\n'}]",4,144266,bc343dc92d4b8f25fc32d0d4039249ccdfb01304,62,24,3,11159,,,0,"Delete the console scripts for lbaas and vpnaas

Codes of lbaas and vnpaas have been moved out, so we need to
remove these console scripts.

Closes-Bug: #1405095

Change-Id: Id91161ecacd902d1dc28a4a0dd01da3778486a88
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/144266/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,0ea3d63b09e0395eaaa07addd8db9ee3863217e4,bug/1405095,, neutron-lbaas-agent = neutron.services.loadbalancer.agent.agent:main neutron-vpn-agent = neutron.services.vpn.agent:main,0,2
openstack%2Fneutron~master~I7b59ca18f13b583b404be61558224384bc2db2c5,openstack/neutron,master,I7b59ca18f13b583b404be61558224384bc2db2c5,refactor l3-agent to include dvr.py,MERGED,2014-12-19 00:55:47.000000000,2015-01-07 01:55:17.000000000,2015-01-06 21:08:33.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-19 00:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c49d0652f14cc11d052489a4b30883cf2e743df3', 'message': 'refactor l3-agent to include dvr.py\n\nCreation of a dvr.py file to hold dvr related\nclasses/data/methods.\n\nChange-Id: I7b59ca18f13b583b404be61558224384bc2db2c5\n'}, {'number': 2, 'created': '2014-12-19 19:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec39d0108ea6881d4fcb76034d1f15d0005bd0f1', 'message': 'refactor l3-agent to include dvr.py\n\nCreation of a dvr.py file to hold dvr related\nclasses/data/methods.\n\nChange-Id: I7b59ca18f13b583b404be61558224384bc2db2c5\nPartially-Implements: bp/restructure-l3-agent\n'}, {'number': 3, 'created': '2014-12-19 21:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56e8c0e07a962e1bd8a4000270ae15e096b02b17', 'message': 'refactor l3-agent to include dvr.py\n\nCreation of a dvr.py file to hold dvr related\nclasses/data/methods.\n\nChange-Id: I7b59ca18f13b583b404be61558224384bc2db2c5\nPartially-Implements: bp/restructure-l3-agent\n'}, {'number': 4, 'created': '2015-01-05 18:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b062c35860d89ef311f648e9cd502ba79188035', 'message': 'refactor l3-agent to include dvr.py\n\nCreation of a dvr.py file to hold dvr related\nclasses/data/methods.\n\nChange-Id: I7b59ca18f13b583b404be61558224384bc2db2c5\nPartially-Implements: bp/restructure-l3-agent\n'}, {'number': 5, 'created': '2015-01-06 16:28:42.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/agent/l3/router_info.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/agent/l3/dvr.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/75832ea45a4a14ded26fc488d6eae80a30fcde24', 'message': 'refactor l3-agent to include dvr.py\n\nCreation of a dvr.py file to hold dvr related\nclasses/data/methods.\n\nChange-Id: I7b59ca18f13b583b404be61558224384bc2db2c5\nPartially-Implements: bp/restructure-l3-agent\n'}]",26,142946,75832ea45a4a14ded26fc488d6eae80a30fcde24,118,25,5,10971,,,0,"refactor l3-agent to include dvr.py

Creation of a dvr.py file to hold dvr related
classes/data/methods.

Change-Id: I7b59ca18f13b583b404be61558224384bc2db2c5
Partially-Implements: bp/restructure-l3-agent
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/142946/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/agent/l3/router_info.py', 'neutron/agent/common/constants.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/agent/l3/dvr.py']",5,c49d0652f14cc11d052489a4b30883cf2e743df3,bp/restructure-l3-agent,"# Copyright (c) 2014 Openstack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr from neutron.agent.common import constants from neutron.agent.linux import ip_lib from neutron.agent.linux import iptables_manager from neutron.common import constants as l3_constants from neutron.i18n import _LE from neutron.openstack.common import log as logging LOG = logging.getLogger(__name__) # Route Table index for FIPs FIP_RT_TBL = 16 class RouterMixin(object): def __init__(self): self.snat_ports = [] self.floating_ips_dict = {} self.snat_iptables_manager = None # DVR Data # Linklocal subnet for router and floating IP namespace link self.rtr_fip_subnet = None self.dist_fip_count = 0 class AgentMixin(object): def __init__(self, host): super(AgentMixin, self).__init__(host) def _destroy_snat_namespace(self, ns): ns_ip = ip_lib.IPWrapper(self.root_helper, namespace=ns) # delete internal interfaces for d in ns_ip.get_devices(exclude_loopback=True): if d.name.startswith(constants.SNAT_INT_DEV_PREFIX): LOG.debug('Unplugging DVR device %s', d.name) self.driver.unplug(d.name, namespace=ns, prefix=constants.SNAT_INT_DEV_PREFIX) # TODO(mrsmith): delete ext-gw-port LOG.debug('DVR: destroy snat ns: %s', ns) if self.conf.router_delete_namespaces: self._delete_namespace(ns_ip, ns) def _destroy_fip_namespace(self, ns): ns_ip = ip_lib.IPWrapper(self.root_helper, namespace=ns) for d in ns_ip.get_devices(exclude_loopback=True): if d.name.startswith(constants.FIP_2_ROUTER_DEV_PREFIX): # internal link between IRs and FIP NS ns_ip.del_veth(d.name) elif d.name.startswith(constants.FIP_EXT_DEV_PREFIX): # single port from FIP NS to br-ext # TODO(carl) Where does the port get deleted? LOG.debug('DVR: unplug: %s', d.name) self.driver.unplug(d.name, bridge=self.conf.external_network_bridge, namespace=ns, prefix=constants.FIP_EXT_DEV_PREFIX) LOG.debug('DVR: destroy fip ns: %s', ns) # TODO(mrsmith): add LOG warn if fip count != 0 if self.conf.router_delete_namespaces: self._delete_namespace(ns_ip, ns) self.agent_gateway_port = None def _set_subnet_arp_info(self, ri, port): """"""Set ARP info retrieved from Plugin for existing ports."""""" if 'id' not in port['subnet'] or not ri.router['distributed']: return subnet_id = port['subnet']['id'] subnet_ports = ( self.plugin_rpc.get_ports_by_subnet(self.context, subnet_id)) for p in subnet_ports: if (p['device_owner'] not in ( l3_constants.DEVICE_OWNER_ROUTER_INTF, l3_constants.DEVICE_OWNER_DVR_INTERFACE)): for fixed_ip in p['fixed_ips']: self._update_arp_entry(ri, fixed_ip['ip_address'], p['mac_address'], subnet_id, 'add') def get_internal_port(self, ri, subnet_id): """"""Return internal router port based on subnet_id."""""" router_ports = ri.router.get(l3_constants.INTERFACE_KEY, []) for port in router_ports: fips = port['fixed_ips'] for f in fips: if f['subnet_id'] == subnet_id: return port def get_fip_ext_device_name(self, port_id): return (constants.FIP_EXT_DEV_PREFIX + port_id)[:self.driver.DEV_NAME_LEN] def get_rtr_int_device_name(self, router_id): return (constants.ROUTER_2_FIP_DEV_PREFIX + router_id)[:self.driver.DEV_NAME_LEN] def get_fip_int_device_name(self, router_id): return (constants.FIP_2_ROUTER_DEV_PREFIX + router_id)[:self.driver.DEV_NAME_LEN] def get_snat_int_device_name(self, port_id): return (constants.SNAT_INT_DEV_PREFIX + port_id)[:self.driver.DEV_NAME_LEN] def get_fip_ns_name(self, ext_net_id): return (constants.FIP_NS_PREFIX + ext_net_id) def get_snat_ns_name(self, router_id): return (constants.SNAT_NS_PREFIX + router_id) def get_snat_interfaces(self, ri): return ri.router.get(l3_constants.SNAT_ROUTER_INTF_KEY, []) def get_gw_port_host(self, router): host = router.get('gw_port_host') if not host: LOG.debug(""gw_port_host missing from router: %s"", router['id']) return host def _handle_router_fip_nat_rules(self, ri, interface_name, action): """"""Configures NAT rules for Floating IPs for DVR. Remove all the rules. This is safe because if use_namespaces is set as False then the agent can only configure one router, otherwise each router's NAT rules will be in their own namespace. """""" ri.iptables_manager.ipv4['nat'].empty_chain('POSTROUTING') ri.iptables_manager.ipv4['nat'].empty_chain('snat') # Add back the jump to float-snat ri.iptables_manager.ipv4['nat'].add_rule('snat', '-j $float-snat') # And add them back if the action is add_rules if action == 'add_rules' and interface_name: rule = ('POSTROUTING', '! -i %(interface_name)s ' '! -o %(interface_name)s -m conntrack ! ' '--ctstate DNAT -j ACCEPT' % {'interface_name': interface_name}) ri.iptables_manager.ipv4['nat'].add_rule(*rule) ri.iptables_manager.apply() def _create_dvr_gateway(self, ri, ex_gw_port, gw_interface_name, snat_ports): """"""Create SNAT namespace."""""" snat_ns_name = self.get_snat_ns_name(ri.router['id']) self._create_namespace(snat_ns_name) # connect snat_ports to br_int from SNAT namespace for port in snat_ports: # create interface_name self._set_subnet_info(port) interface_name = self.get_snat_int_device_name(port['id']) self._internal_network_added(snat_ns_name, port['network_id'], port['id'], port['ip_cidr'], port['mac_address'], interface_name, constants.SNAT_INT_DEV_PREFIX) self._external_gateway_added(ri, ex_gw_port, gw_interface_name, snat_ns_name, preserve_ips=[]) ri.snat_iptables_manager = iptables_manager.IptablesManager( root_helper=self.root_helper, namespace=snat_ns_name, use_ipv6=self.use_ipv6) # kicks the FW Agent to add rules for the snat namespace self.process_router_add(ri) def agent_gateway_added(self, ns_name, ex_gw_port, interface_name): """"""Add Floating IP gateway port to FIP namespace."""""" if not ip_lib.device_exists(interface_name, root_helper=self.root_helper, namespace=ns_name): self.driver.plug(ex_gw_port['network_id'], ex_gw_port['id'], interface_name, ex_gw_port['mac_address'], bridge=self.conf.external_network_bridge, namespace=ns_name, prefix=constants.FIP_EXT_DEV_PREFIX) self.driver.init_l3(interface_name, [ex_gw_port['ip_cidr']], namespace=ns_name) ip_address = ex_gw_port['ip_cidr'].split('/')[0] self._send_gratuitous_arp_packet(ns_name, interface_name, ip_address) gw_ip = ex_gw_port['subnet']['gateway_ip'] if gw_ip: ipd = ip_lib.IPDevice(interface_name, self.root_helper, namespace=ns_name) ipd.route.add_gateway(gw_ip) cmd = ['sysctl', '-w', 'net.ipv4.conf.%s.proxy_arp=1' % interface_name] ip_wrapper = ip_lib.IPWrapper(self.root_helper, namespace=ns_name) ip_wrapper.netns.execute(cmd, check_exit_code=False) def _create_agent_gateway_port(self, ri, network_id): """"""Create Floating IP gateway port. Request port creation from Plugin then creates Floating IP namespace and adds gateway port. """""" self.agent_gateway_port = ( self.plugin_rpc.get_agent_gateway_port( self.context, network_id)) if 'subnet' not in self.agent_gateway_port: LOG.error(_LE('Missing subnet/agent_gateway_port')) return self._set_subnet_info(self.agent_gateway_port) # add fip-namespace and agent_gateway_port fip_ns_name = ( self.get_fip_ns_name(str(network_id))) self._create_namespace(fip_ns_name) ri.fip_iptables_manager = iptables_manager.IptablesManager( root_helper=self.root_helper, namespace=fip_ns_name, use_ipv6=self.use_ipv6) # no connection tracking needed in fip namespace ri.fip_iptables_manager.ipv4['raw'].add_rule('PREROUTING', '-j CT --notrack') ri.fip_iptables_manager.apply() interface_name = ( self.get_fip_ext_device_name(self.agent_gateway_port['id'])) self.agent_gateway_added(fip_ns_name, self.agent_gateway_port, interface_name) def create_rtr_2_fip_link(self, ri, network_id): """"""Create interface between router and Floating IP namespace."""""" rtr_2_fip_name = self.get_rtr_int_device_name(ri.router_id) fip_2_rtr_name = self.get_fip_int_device_name(ri.router_id) fip_ns_name = self.get_fip_ns_name(str(network_id)) # add link local IP to interface if ri.rtr_fip_subnet is None: ri.rtr_fip_subnet = self.local_subnets.allocate(ri.router_id) rtr_2_fip, fip_2_rtr = ri.rtr_fip_subnet.get_pair() ip_wrapper = ip_lib.IPWrapper(self.root_helper, namespace=ri.ns_name) if not ip_lib.device_exists(rtr_2_fip_name, self.root_helper, namespace=ri.ns_name): int_dev = ip_wrapper.add_veth(rtr_2_fip_name, fip_2_rtr_name, fip_ns_name) self.internal_ns_interface_added(str(rtr_2_fip), rtr_2_fip_name, ri.ns_name) self.internal_ns_interface_added(str(fip_2_rtr), fip_2_rtr_name, fip_ns_name) int_dev[0].link.set_up() int_dev[1].link.set_up() # add default route for the link local interface device = ip_lib.IPDevice(rtr_2_fip_name, self.root_helper, namespace=ri.ns_name) device.route.add_gateway(str(fip_2_rtr.ip), table=FIP_RT_TBL) #setup the NAT rules and chains self._handle_router_fip_nat_rules(ri, rtr_2_fip_name, 'add_rules') # kicks the FW Agent to add rules for the IR namespace if configured self.process_router_add(ri) def floating_ip_added_dist(self, ri, fip): """"""Add floating IP to FIP namespace."""""" floating_ip = fip['floating_ip_address'] fixed_ip = fip['fixed_ip_address'] rule_pr = self.fip_priorities.pop() ri.floating_ips_dict[floating_ip] = rule_pr fip_2_rtr_name = self.get_fip_int_device_name(ri.router_id) ip_rule = ip_lib.IpRule(self.root_helper, namespace=ri.ns_name) ip_rule.add_rule_from(fixed_ip, FIP_RT_TBL, rule_pr) #Add routing rule in fip namespace fip_cidr = str(floating_ip) + constants.FLOATING_IP_CIDR_SUFFIX fip_ns_name = self.get_fip_ns_name(str(fip['floating_network_id'])) rtr_2_fip, _ = ri.rtr_fip_subnet.get_pair() device = ip_lib.IPDevice(fip_2_rtr_name, self.root_helper, namespace=fip_ns_name) device.route.add_route(fip_cidr, str(rtr_2_fip.ip)) interface_name = ( self.get_fip_ext_device_name(self.agent_gateway_port['id'])) self._send_gratuitous_arp_packet(fip_ns_name, interface_name, floating_ip, distributed=True) # update internal structures ri.dist_fip_count = ri.dist_fip_count + 1 def floating_ip_removed_dist(self, ri, fip_cidr): """"""Remove floating IP from FIP namespace."""""" floating_ip = fip_cidr.split('/')[0] rtr_2_fip_name = self.get_rtr_int_device_name(ri.router_id) fip_2_rtr_name = self.get_fip_int_device_name(ri.router_id) rtr_2_fip, fip_2_rtr = ri.rtr_fip_subnet.get_pair() fip_ns_name = self.get_fip_ns_name(str(self._fetch_external_net_id())) ip_rule_rtr = ip_lib.IpRule(self.root_helper, namespace=ri.ns_name) if floating_ip in ri.floating_ips_dict: rule_pr = ri.floating_ips_dict[floating_ip] #TODO(rajeev): Handle else case - exception/log? else: rule_pr = None ip_rule_rtr.delete_rule_priority(rule_pr) self.fip_priorities.add(rule_pr) device = ip_lib.IPDevice(fip_2_rtr_name, self.root_helper, namespace=fip_ns_name) device.route.delete_route(fip_cidr, str(rtr_2_fip.ip)) # check if this is the last FIP for this router ri.dist_fip_count = ri.dist_fip_count - 1 if ri.dist_fip_count == 0: #remove default route entry device = ip_lib.IPDevice(rtr_2_fip_name, self.root_helper, namespace=ri.ns_name) ns_ip = ip_lib.IPWrapper(self.root_helper, namespace=fip_ns_name) device.route.delete_gateway(str(fip_2_rtr.ip), table=FIP_RT_TBL) self.local_subnets.release(ri.router_id) ri.rtr_fip_subnet = None ns_ip.del_veth(fip_2_rtr_name) is_last = self._fip_ns_unsubscribe(ri.router_id) # clean up fip-namespace if this is the last FIP if is_last: self._destroy_fip_namespace(fip_ns_name) def _snat_redirect_add(self, ri, gateway, sn_port, sn_int): """"""Adds rules and routes for SNAT redirection."""""" try: snat_idx = netaddr.IPNetwork(sn_port['ip_cidr']).value ns_ipr = ip_lib.IpRule(self.root_helper, namespace=ri.ns_name) ns_ipd = ip_lib.IPDevice(sn_int, self.root_helper, namespace=ri.ns_name) ns_ipd.route.add_gateway(gateway, table=snat_idx) ns_ipr.add_rule_from(sn_port['ip_cidr'], snat_idx, snat_idx) ns_ipr.netns.execute(['sysctl', '-w', 'net.ipv4.conf.%s.' 'send_redirects=0' % sn_int]) except Exception: LOG.exception(_LE('DVR: error adding redirection logic')) def _snat_redirect_remove(self, ri, sn_port, sn_int): """"""Removes rules and routes for SNAT redirection."""""" try: snat_idx = netaddr.IPNetwork(sn_port['ip_cidr']).value ns_ipr = ip_lib.IpRule(self.root_helper, namespace=ri.ns_name) ns_ipd = ip_lib.IPDevice(sn_int, self.root_helper, namespace=ri.ns_name) ns_ipd.route.delete_gateway(table=snat_idx) ns_ipr.delete_rule_priority(snat_idx) except Exception: LOG.exception(_LE('DVR: removed snat failed')) def _update_arp_entry(self, ri, ip, mac, subnet_id, operation): """"""Add or delete arp entry into router namespace for the subnet."""""" port = self.get_internal_port(ri, subnet_id) # update arp entry only if the subnet is attached to the router if port: ip_cidr = str(ip) + '/32' try: # TODO(mrsmith): optimize the calls below for bulk calls net = netaddr.IPNetwork(ip_cidr) interface_name = self.get_internal_device_name(port['id']) device = ip_lib.IPDevice(interface_name, self.root_helper, namespace=ri.ns_name) if operation == 'add': device.neigh.add(net.version, ip, mac) elif operation == 'delete': device.neigh.delete(net.version, ip, mac) except Exception: LOG.exception(_LE(""DVR: Failed updating arp entry"")) self.fullsync = True def add_arp_entry(self, context, payload): """"""Add arp entry into router namespace. Called from RPC."""""" arp_table = payload['arp_table'] router_id = payload['router_id'] ip = arp_table['ip_address'] mac = arp_table['mac_address'] subnet_id = arp_table['subnet_id'] ri = self.router_info.get(router_id) if ri: self._update_arp_entry(ri, ip, mac, subnet_id, 'add') def del_arp_entry(self, context, payload): """"""Delete arp entry from router namespace. Called from RPC."""""" arp_table = payload['arp_table'] router_id = payload['router_id'] ip = arp_table['ip_address'] mac = arp_table['mac_address'] subnet_id = arp_table['subnet_id'] ri = self.router_info.get(router_id) if ri: self._update_arp_entry(ri, ip, mac, subnet_id, 'delete') ",,494,425
openstack%2Fheat-translator~master~Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e,openstack/heat-translator,master,Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e,Add new support for get_attribute,MERGED,2014-12-04 01:12:29.000000000,2015-01-07 01:25:30.000000000,2015-01-07 01:25:30.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 9591}]","[{'number': 1, 'created': '2014-12-04 01:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8f9cb5ca1a18613abd45f9acd8d0f5502bfb286b', 'message': 'Add new support for get_attribute\n\nFix in TOSCA function GetAttribute to return the parameters.\nAdd new handler in the translation to Heat to map from the\nparticular TOSCA attribute to the matching Heat attribute of\nthe Heat resource type\n\nChange-Id: Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e\n'}, {'number': 2, 'created': '2014-12-05 19:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/eeab78ce02ba232b2e662ce9e96160f44dbdfe59', 'message': 'Add new support for get_attribute\n\nFix in TOSCA function GetAttribute to return the parameters.\nAdd new handler in the translation to Heat to map from the\nparticular TOSCA attribute to the matching Heat attribute of\nthe Heat resource type\n\nChange-Id: Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e\n'}, {'number': 3, 'created': '2014-12-06 07:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/70a9ee9e5f0a887a21ecfa61edbf5c1ec4785de6', 'message': 'Add new support for get_attribute\n\nFix in TOSCA function GetAttribute to return the parameters.\nAdd new handler in the translation to Heat to map from the\nparticular TOSCA attribute to the matching Heat attribute of\nthe Heat resource type\n\nChange-Id: Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e\n'}, {'number': 4, 'created': '2014-12-10 23:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/fb1cd25b7599d56b928754462ae03cab593d48c3', 'message': 'Add new support for get_attribute\n\nFix in TOSCA function GetAttribute to return the parameters.\nAdd new handler in the translation to Heat to map from the\nparticular TOSCA attribute to the matching Heat attribute of\nthe Heat resource type\n\nChange-Id: Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e\n'}, {'number': 5, 'created': '2015-01-06 23:20:16.000000000', 'files': ['translator/hot/tosca/tosca_compute.py', 'translator/hot/tosca/tosca_block_storage.py', 'translator/toscalib/functions.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/e814b85f37f093d17abcfedce295fd4986877962', 'message': 'Add new support for get_attribute\n\nFix in TOSCA function GetAttribute to return the parameters.\nAdd new handler in the translation to Heat to map from the\nparticular TOSCA attribute to the matching Heat attribute of\nthe Heat resource type\n\nChange-Id: Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e\n'}]",6,138926,e814b85f37f093d17abcfedce295fd4986877962,24,4,5,9591,,,0,"Add new support for get_attribute

Fix in TOSCA function GetAttribute to return the parameters.
Add new handler in the translation to Heat to map from the
particular TOSCA attribute to the matching Heat attribute of
the Heat resource type

Change-Id: Ied1c0f08594aa4d9894cd5ceb71bbbd27ae7339e
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/26/138926/2 && git format-patch -1 --stdout FETCH_HEAD,"['translator/hot/tosca/tosca_compute.py', 'translator/hot/tosca/tosca_block_storage.py', 'translator/toscalib/functions.py']",3,8f9cb5ca1a18613abd45f9acd8d0f5502bfb286b,bp/heat-translator-tosca, return self.args, pass,24,2
openstack%2Fswift~feature%2Fec~I21fff56558fde21e1c1ac2678a5d9bf0125eac4b,openstack/swift,feature/ec,I21fff56558fde21e1c1ac2678a5d9bf0125eac4b,Reduce container_updates requests in EC,ABANDONED,2014-12-26 07:33:15.000000000,2015-01-07 01:23:57.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-12-26 07:33:15.000000000', 'files': ['swift/obj/server.py', 'test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/de23a278f6ce4fd8bb7f083c93d8e4588274845d', 'message': ""Reduce container_updates requests in EC\n\nFor EC we'll base the number on the quorum value which is available\nvia a policy method. So, when its time to do container updates,\nonly the first (total - quorum) of the nodes participating in the EC\nscheme should actually perform the updates.\n\nChange-Id: I21fff56558fde21e1c1ac2678a5d9bf0125eac4b\n""}]",2,144091,de23a278f6ce4fd8bb7f083c93d8e4588274845d,5,3,1,5189,,,0,"Reduce container_updates requests in EC

For EC we'll base the number on the quorum value which is available
via a policy method. So, when its time to do container updates,
only the first (total - quorum) of the nodes participating in the EC
scheme should actually perform the updates.

Change-Id: I21fff56558fde21e1c1ac2678a5d9bf0125eac4b
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/144091/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/obj/test_server.py']",2,de23a278f6ce4fd8bb7f083c93d8e4588274845d,ec_container_updates,"from swift.common.storage_policy import StoragePolicy, REPL_POLICY, EC_POLICY @patch_policies([ StoragePolicy.from_conf( EC_POLICY, {'idx': 0, 'name': 'zero', 'is_default': True, 'ec_ndata': 4, 'ec_nparity': 2, 'ec_type': 'jerasure_rs_vand'}), ]) def test_PUT_container_updates_ec(self): # Test swift.obj.server.ObjectController.PUT and container # updates, making sure container update is called in the correct # state. calls_made = [0] def our_container_update(*args, **kwargs): calls_made[0] += 1 orig_cu = self.object_controller.container_update self.object_controller.container_update = our_container_update start = time() orig_timestamp = utils.Timestamp(start) try: # call container_update from this obj-server req = Request.blank('/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={ 'X-Timestamp': orig_timestamp.internal, 'Content-Type': 'application/octet-stream', 'X-Object-Sysmeta-Ec-Archive-Index': 0, 'Content-Length': '4', }) req.body = 'test' resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 201) self.assertEquals(1, calls_made[0]) # should not call container_update from this obj-server timestamp = utils.Timestamp(start + 0.00001) req = Request.blank('/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={ 'X-Timestamp': timestamp.internal, 'Content-Type': 'application/octet-stream', 'X-Object-Sysmeta-Ec-Archive-Index': 2, 'Content-Length': '4', }) req.body = 'test' resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 201) self.assertEquals(1, calls_made[0]) finally: self.object_controller.container_update = orig_cu @patch_policies([ StoragePolicy.from_conf( EC_POLICY, {'idx': 0, 'name': 'zero', 'is_default': True, 'ec_ndata': 4, 'ec_nparity': 2, 'ec_type': 'jerasure_rs_vand'}), ]) def test_DELETE_container_updates_ec(self): # Test swift.obj.server.ObjectController.DELETE and container # updates, making sure container update is called in the correct # state. start = time() orig_timestamp = utils.Timestamp(start) req = Request.blank('/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={ 'X-Timestamp': orig_timestamp.internal, 'X-Object-Sysmeta-Ec-Archive-Index': 0, 'Content-Type': 'application/octet-stream', 'Content-Length': '4', }) req.body = 'test' resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 201) req = Request.blank('/sda1/p/a/c/o1', environ={'REQUEST_METHOD': 'PUT'}, headers={ 'X-Timestamp': orig_timestamp.internal, 'X-Object-Sysmeta-Ec-Archive-Index': 2, 'Content-Type': 'application/octet-stream', 'Content-Length': '4', }) req.body = 'test' resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 201) calls_made = [0] def our_container_update(*args, **kwargs): calls_made[0] += 1 orig_cu = self.object_controller.container_update self.object_controller.container_update = our_container_update try: # should call container_update timestamp = utils.Timestamp(start + 0.00001) req = Request.blank('/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'DELETE'}, headers={'X-Timestamp': timestamp.internal}) resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 204) self.assertEquals(1, calls_made[0]) # should not call container_update timestamp = utils.Timestamp(start + 0.00001) req = Request.blank('/sda1/p/a/c/o1', environ={'REQUEST_METHOD': 'DELETE'}, headers={'X-Timestamp': timestamp.internal}) resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 204) self.assertEquals(1, calls_made[0]) finally: self.object_controller.container_update = orig_cu ","from swift.common.storage_policy import StoragePolicy, REPL_POLICY",139,1
openstack%2Ffuel-docs~stable%2F6.0~Id27533f02c8885b084713edfc61528bf0b2f17d6,openstack/fuel-docs,stable/6.0,Id27533f02c8885b084713edfc61528bf0b2f17d6,Fix broken PDF file names and external links,MERGED,2015-01-07 00:34:06.000000000,2015-01-07 00:54:53.000000000,2015-01-07 00:54:53.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-01-07 00:34:06.000000000', 'files': ['pages/release-notes/v6-0/0060-obtain-the-product.rst', 'index.rst', 'pdf/conf.py'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7ad2c44d7f60a759013c2e2c8d7bf26890de9eee', 'message': 'Fix broken PDF file names and external links\n\n* File Format Reference PDF\n* Plugin Guide PDF\n* Mirantis OpenStack Express\n\nChange-Id: Id27533f02c8885b084713edfc61528bf0b2f17d6\nCloses-Bug: 1405604\n(cherry picked from commit d08fdb0b006657075fd3ccaae05f7fa6d9c32b7a)\n'}]",0,145388,7ad2c44d7f60a759013c2e2c8d7bf26890de9eee,7,4,1,8787,,,0,"Fix broken PDF file names and external links

* File Format Reference PDF
* Plugin Guide PDF
* Mirantis OpenStack Express

Change-Id: Id27533f02c8885b084713edfc61528bf0b2f17d6
Closes-Bug: 1405604
(cherry picked from commit d08fdb0b006657075fd3ccaae05f7fa6d9c32b7a)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/88/145388/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-0/0060-obtain-the-product.rst', 'index.rst', 'pdf/conf.py']",3,7ad2c44d7f60a759013c2e2c8d7bf26890de9eee,," ('pdf/pdf_file-ref', u'Mirantis-OpenStack-6.0-File-Format-Reference', u'File Format Reference', u'2014, Mirantis Inc.'), ('pdf/pdf_plugin-dev', u'Mirantis-OpenStack-6.0-Fuel-Plugin-Guide', u'Fuel Plugin Guide', u'2014, Mirantis Inc.'),"," ('pdf/pdf_file-ref', u'Mirantis-OpenStack-6.0-File-Reference', u'File Reference', u'2014, Mirantis Inc.'), ('pdf/pdf_plugin-dev', u'Mirantis-OpenStack-6.0-FuelPlug-inGuide', u'Fuel Plug-in Guide', u'2014, Mirantis Inc.'),",7,8
openstack%2Ffuel-docs~master~Id27533f02c8885b084713edfc61528bf0b2f17d6,openstack/fuel-docs,master,Id27533f02c8885b084713edfc61528bf0b2f17d6,Fix broken PDF file names and external links,MERGED,2014-12-25 12:33:51.000000000,2015-01-07 00:34:06.000000000,2015-01-07 00:33:51.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-25 12:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e52e333ee748448c00d15ff89b7c5d69b8c237b5', 'message': 'Fix the problem with File Format Referencee pdf\n\nChange-Id: Id27533f02c8885b084713edfc61528bf0b2f17d6\nCloses-Bug: 1405604\n'}, {'number': 2, 'created': '2014-12-25 12:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/03e3d92d6ff4e84ccb06778bbf7e4093fb0e87ed', 'message': 'Fix the problem with File Format Reference pdf\n\nChange-Id: Id27533f02c8885b084713edfc61528bf0b2f17d6\nCloses-Bug: 1405604\n'}, {'number': 3, 'created': '2015-01-06 23:57:12.000000000', 'files': ['pages/release-notes/v6-0/0060-obtain-the-product.rst', 'index.rst', 'pdf/conf.py'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d08fdb0b006657075fd3ccaae05f7fa6d9c32b7a', 'message': 'Fix broken PDF file names and external links\n\n* File Format Reference PDF\n* Plugin Guide PDF\n* Mirantis OpenStack Express\n\nChange-Id: Id27533f02c8885b084713edfc61528bf0b2f17d6\nCloses-Bug: 1405604\n'}]",0,143975,d08fdb0b006657075fd3ccaae05f7fa6d9c32b7a,22,6,3,13082,,,0,"Fix broken PDF file names and external links

* File Format Reference PDF
* Plugin Guide PDF
* Mirantis OpenStack Express

Change-Id: Id27533f02c8885b084713edfc61528bf0b2f17d6
Closes-Bug: 1405604
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/75/143975/3 && git format-patch -1 --stdout FETCH_HEAD,['index.rst'],1,e52e333ee748448c00d15ff89b7c5d69b8c237b5,bug/1405604,:ref:`file-ref` `(pdf) <pdf/Mirantis-OpenStack-6.0-Fuel-File-Format-Reference.pdf>`__,:ref:`file-ref` `(pdf) <pdf/Mirantis-OpenStack-6.0-Fuel File-Format-Reference.pdf>`__,1,1
openstack%2Ftempest~master~I0d4b5b2a280813d54b0c2712a504e472370bd196,openstack/tempest,master,I0d4b5b2a280813d54b0c2712a504e472370bd196,printout testr tests that fail,MERGED,2015-01-06 22:15:02.000000000,2015-01-07 00:18:32.000000000,2015-01-07 00:18:31.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-06 22:15:02.000000000', 'files': ['tempest/tests/test_list_tests.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a9764dd73928bc9f6af5718779dcce64540d0df', 'message': ""printout testr tests that fail\n\nWe test whether or not testr fails to list all the tests, however\nwe're not being very nice about reporting when it fails (especially\nnot what caused the failure), and throw a cryptic 0 != 3 mismatch\nerror.\n\nThis should help make it easy to find syntax issues in the future.\n\nChange-Id: I0d4b5b2a280813d54b0c2712a504e472370bd196\n""}]",0,145360,6a9764dd73928bc9f6af5718779dcce64540d0df,8,4,1,2750,,,0,"printout testr tests that fail

We test whether or not testr fails to list all the tests, however
we're not being very nice about reporting when it fails (especially
not what caused the failure), and throw a cryptic 0 != 3 mismatch
error.

This should help make it easy to find syntax issues in the future.

Change-Id: I0d4b5b2a280813d54b0c2712a504e472370bd196
",git fetch https://review.opendev.org/openstack/tempest refs/changes/60/145360/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/test_list_tests.py'],1,6a9764dd73928bc9f6af5718779dcce64540d0df,bp/clients-return-one-value," ""error on import %s"" % ids)"," ""error on import"")",1,1
openstack%2Fironic-python-agent~master~I2df16033affe9e7f070f1a8fb69d7a4592ff8129,openstack/ironic-python-agent,master,I2df16033affe9e7f070f1a8fb69d7a4592ff8129,Updated from global requirements,MERGED,2014-12-17 04:05:31.000000000,2015-01-06 23:59:13.000000000,2015-01-06 23:59:12.000000000,"[{'_account_id': 3}, {'_account_id': 10342}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-12-17 04:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5afdc252e789c8a14e21c9b204a3ae11e80b4a57', 'message': 'Updated from global requirements\n\nChange-Id: I2df16033affe9e7f070f1a8fb69d7a4592ff8129\n'}, {'number': 2, 'created': '2015-01-06 22:45:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b381a49e48ca3921cc612c56ad7e0a3b86a64eae', 'message': 'Updated from global requirements\n\nChange-Id: I2df16033affe9e7f070f1a8fb69d7a4592ff8129\n'}]",0,142334,b381a49e48ca3921cc612c56ad7e0a3b86a64eae,14,3,2,11131,,,0,"Updated from global requirements

Change-Id: I2df16033affe9e7f070f1a8fb69d7a4592ff8129
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/34/142334/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5afdc252e789c8a14e21c9b204a3ae11e80b4a57,openstack/requirements,oslo.concurrency>=0.3.0 # Apache-2.0 oslo.i18n>=1.0.0 # Apache-2.0 oslo.serialization>=1.0.0 # Apache-2.0 oslo.utils>=1.1.0 # Apache-2.0,oslo.concurrency>=0.3.0 # Apache-2.0 oslo.i18n>=1.0.0 # Apache-2.0 oslo.serialization>=1.0.0 # Apache-2.0 oslo.utils>=1.0.0 # Apache-2.0,4,4
openstack%2Fsolum~master~I43b24bb556334c399eb0996f50d71252d1a20cd7,openstack/solum,master,I43b24bb556334c399eb0996f50d71252d1a20cd7,Report configured Solum build in reponse headers,MERGED,2014-12-12 22:02:45.000000000,2015-01-06 23:55:25.000000000,2015-01-06 23:55:24.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-12-12 22:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/045fcfa3f106cb4fa93ad2bc789f8f3e4cfa13d3', 'message': ""Report configured Solum build in reponse headers\n\nIf solum.conf bears a value for the key 'release' at the\nDEFAULT level, then this new hook will add the header\nX-Solum-Release to all responses.\n\nChange-Id: I43b24bb556334c399eb0996f50d71252d1a20cd7\nImplements: blueprint report-release-version\n""}, {'number': 2, 'created': '2015-01-06 19:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/92b4f12431a7cc45f540632b0cdea18c5eb9ac54', 'message': ""Report configured Solum build in reponse headers\n\nIf solum.conf bears a value for the key 'release' at the\nDEFAULT level, then this new hook will add the header\nX-Solum-Release to all responses.\n\nChange-Id: I43b24bb556334c399eb0996f50d71252d1a20cd7\nImplements: blueprint report-release-version\n""}, {'number': 3, 'created': '2015-01-06 20:59:24.000000000', 'files': ['solum/api/release.py', 'functionaltests/api/test_release.py', 'solum/api/config.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/eac61123132a8396d40f71308637b6b09be317d1', 'message': ""Report configured Solum build in reponse headers\n\nIf solum.conf bears a value for the key 'release' at the\nDEFAULT level, then this new hook will add the header\nX-Solum-Release to all responses.\n\nChange-Id: I43b24bb556334c399eb0996f50d71252d1a20cd7\nImplements: blueprint report-release-version\n""}]",0,141501,eac61123132a8396d40f71308637b6b09be317d1,14,3,3,1375,,,0,"Report configured Solum build in reponse headers

If solum.conf bears a value for the key 'release' at the
DEFAULT level, then this new hook will add the header
X-Solum-Release to all responses.

Change-Id: I43b24bb556334c399eb0996f50d71252d1a20cd7
Implements: blueprint report-release-version
",git fetch https://review.opendev.org/openstack/solum refs/changes/01/141501/3 && git format-patch -1 --stdout FETCH_HEAD,"['solum/api/release.py', 'solum/api/config.py']",2,045fcfa3f106cb4fa93ad2bc789f8f3e4cfa13d3,bp/report-release-version,"from solum.api import release 'hooks': [auth.AuthInformationHook(), release.ReleaseReporter(), ]", 'hooks': [auth.AuthInformationHook()],41,1
openstack%2Fkeystone~master~I51e87129fb3efcc1abae9c59915eaca38eb91227,openstack/keystone,master,I51e87129fb3efcc1abae9c59915eaca38eb91227,Ensure manager grant methods throw exception if role_id is invalid.,MERGED,2014-12-31 20:15:31.000000000,2015-01-06 23:54:40.000000000,2015-01-06 23:54:39.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 8533}, {'_account_id': 9142}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-12-31 20:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0aab9a8fbf64aac5d12857742f431b0063c0b2b1', 'message': ""Ensure manager grant methods throw exception if role_id is invalid.\n\nWe currently don't test whether the assignment manager grant\nmethods correctly thow a RoleNotFound exception if the role\nis invalid. This patch adds a test for this.\n\nChange-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227\nCloses-bug: 1406721\n""}, {'number': 2, 'created': '2015-01-01 00:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cec0afb3c89ff65fb71ee730db729c264160980b', 'message': ""Ensure manager grant methods throw exception if role_id is invalid.\n\nWe currently don't test whether the assignment manager/driver\ngrant methods correctly throw a RoleNotFound exception if the role\nis invalid. This patch adds a test for this.\n\nChange-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227\nCloses-bug: 1406721\n""}, {'number': 3, 'created': '2015-01-01 16:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ac84c8aec83edf803976950114658a706c7b7e3f', 'message': ""Ensure manager grant methods throw exception if role_id is invalid.\n\nWe currently don't test whether the assignment manager/driver\ngrant methods correctly throw a RoleNotFound exception if the role\nis invalid. This patch adds a test for this.\n\nChange-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227\nCloses-bug: 1406721\n""}, {'number': 4, 'created': '2015-01-03 02:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/13d0290d6ad6b3acac36c800febeaa24de303904', 'message': ""Ensure manager grant methods throw exception if role_id is invalid.\n\nWe currently don't test whether the assignment manager/driver\ngrant methods correctly throw a RoleNotFound exception if the role\nis invalid. This patch adds a test for this.\n\nSuch a test will be useful to ensure this functionality is\nmaintained as we migrate roles to their own backend.\n\nChange-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227\nCloses-bug: 1406721\n""}, {'number': 5, 'created': '2015-01-03 17:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a9df71c91dc9b4c5860d8ba49c85b4e043bb520', 'message': ""Ensure manager grant methods throw exception if role_id is invalid.\n\nWe currently don't test whether the assignment manager/driver\ngrant methods correctly throw a RoleNotFound exception if the role\nis invalid. This patch adds a test for this.\n\nSuch a test will be useful to ensure this functionality is\nmaintained as we migrate roles to their own backend.\n\nChange-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227\nCloses-bug: 1406721\n""}, {'number': 6, 'created': '2015-01-05 21:14:07.000000000', 'files': ['keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/71d8c6e4d4692c5515b0642e1dfb72e0a83e53fa', 'message': ""Ensure manager grant methods throw exception if role_id is invalid.\n\nWe currently don't test whether the assignment manager/driver\ngrant methods correctly throw a RoleNotFound exception if the role\nis invalid. This patch adds a test for this.\n\nSuch a test will be useful to ensure this functionality is\nmaintained as we migrate roles to their own backend.\n\nChange-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227\nCloses-bug: 1406721\n""}]",16,144658,71d8c6e4d4692c5515b0642e1dfb72e0a83e53fa,29,8,6,5707,,,0,"Ensure manager grant methods throw exception if role_id is invalid.

We currently don't test whether the assignment manager/driver
grant methods correctly throw a RoleNotFound exception if the role
is invalid. This patch adds a test for this.

Such a test will be useful to ensure this functionality is
maintained as we migrate roles to their own backend.

Change-Id: I51e87129fb3efcc1abae9c59915eaca38eb91227
Closes-bug: 1406721
",git fetch https://review.opendev.org/openstack/keystone refs/changes/58/144658/6 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/tests/test_backend.py']",2,0aab9a8fbf64aac5d12857742f431b0063c0b2b1,bug/1406721," def test_grant_crud_throws_exception_if_invalid_role(self): """""" Check RoleNotFound thrown if role does not exist."""""" def assert_exception_raised_user_project(f, user_id, project_id): self.assertRaises( exception.RoleNotFound, f, user_id=user_id, project_id=project_id, role_id=uuid.uuid4().hex) def assert_exception_raised_group_project(f, group_id, project_id): self.assertRaises( exception.RoleNotFound, f, group_id=group_id, project_id=project_id, role_id=uuid.uuid4().hex) def assert_exception_raised_user_domain(f, user_id, domain_id): self.assertRaises( exception.RoleNotFound, f, user_id=user_id, domain_id=domain_id, role_id=uuid.uuid4().hex) def assert_exception_raised_group_domain(f, group_id, domain_id): self.assertRaises( exception.RoleNotFound, f, group_id=group_id, domain_id=domain_id, role_id=uuid.uuid4().hex) user = {'name': uuid.uuid4().hex, 'domain_id': DEFAULT_DOMAIN_ID, 'password': uuid.uuid4().hex, 'enabled': True} user = self.identity_api.create_user(user) group = {'name': uuid.uuid4().hex, 'domain_id': DEFAULT_DOMAIN_ID, 'enabled': True} group = self.identity_api.create_group(group) project = {'id': uuid.uuid4().hex, 'name': uuid.uuid4().hex, 'domain_id': DEFAULT_DOMAIN_ID} self.assignment_api.create_project(project['id'], project) for manager_call in [self.assignment_api.create_grant, self.assignment_api.get_grant, self.assignment_api.delete_grant]: assert_exception_raised_user_project( manager_call, user['id'], project['id']) assert_exception_raised_group_project( manager_call, group['id'], project['id']) assert_exception_raised_user_domain( manager_call, user['id'], DEFAULT_DOMAIN_ID) assert_exception_raised_group_domain( manager_call, group['id'], DEFAULT_DOMAIN_ID) ",,50,2
openstack%2Foslo.utils~master~Ic6dd62097399bf75e3d11b4d8a6400971069c415,openstack/oslo.utils,master,Ic6dd62097399bf75e3d11b4d8a6400971069c415,Move files out of the namespace package,MERGED,2015-01-05 21:19:09.000000000,2015-01-06 23:45:06.000000000,2015-01-06 23:45:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-05 21:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/b1ff82095f26cd0bbcac292bdf95b371cf591f8b', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.utils to oslo_utils. Retain the ability\nto import from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ic6dd62097399bf75e3d11b4d8a6400971069c415\n'}, {'number': 2, 'created': '2015-01-05 22:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/5b0ec3bcbf05611fed176aefe21af561cee54db7', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.utils to oslo_utils. Retain the ability\nto import from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ic6dd62097399bf75e3d11b4d8a6400971069c415\n'}, {'number': 3, 'created': '2015-01-06 21:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/13ca215d0aee037db918e502c99c170bc79ca76e', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.utils to oslo_utils. Retain the ability\nto import from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ic6dd62097399bf75e3d11b4d8a6400971069c415\n'}, {'number': 4, 'created': '2015-01-06 22:19:15.000000000', 'files': ['tests/test_warning.py', 'oslo_utils/tests/test_netutils.py', 'oslo_utils/tests/fake/__init__.py', 'oslo_utils/encodeutils.py', 'doc/source/usage.rst', 'oslo/utils/encodeutils.py', 'oslo_utils/__init__.py', 'oslo/utils/netutils.py', 'oslo_utils/uuidutils.py', 'oslo/utils/uuidutils.py', 'doc/source/api/excutils.rst', 'doc/source/api/encodeutils.rst', 'oslo_utils/reflection.py', 'oslo/utils/timeutils.py', 'oslo_utils/tests/base.py', 'oslo_utils/_i18n.py', 'oslo/utils/importutils.py', 'doc/source/api/units.rst', 'doc/source/api/netutils.rst', 'doc/source/api/timeutils.rst', 'oslo_utils/netutils.py', 'oslo_utils/tests/test_importutils.py', 'oslo_utils/tests/__init__.py', 'oslo_utils/units.py', 'oslo/utils/strutils.py', 'oslo/utils/excutils.py', 'tests/test_importutils.py', 'oslo_utils/tests/test_uuidutils.py', 'oslo/utils/reflection.py', 'doc/source/api/strutils.rst', 'oslo_utils/strutils.py', 'oslo_utils/excutils.py', 'oslo_utils/tests/test_reflection.py', 'oslo_utils/tests/tests_encodeutils.py', 'oslo_utils/tests/test_excutils.py', 'oslo_utils/tests/test_strutils.py', 'oslo_utils/importutils.py', 'oslo_utils/timeutils.py', 'oslo/utils/units.py', 'doc/source/api/importutils.rst', 'setup.cfg', 'tests/test_netutils.py', 'tox.ini', 'oslo_utils/tests/test_timeutils.py', 'oslo/utils/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/ca76fdcb52a5149f2b266bfb28c446f652c49128', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.utils to oslo_utils. Retain the ability\nto import from the old namespace package for backwards compatibility for\nthis release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ic6dd62097399bf75e3d11b4d8a6400971069c415\n'}]",3,145058,ca76fdcb52a5149f2b266bfb28c446f652c49128,19,5,4,2472,,,0,"Move files out of the namespace package

Move the public API out of oslo.utils to oslo_utils. Retain the ability
to import from the old namespace package for backwards compatibility for
this release cycle.

bp/drop-namespace-packages

Change-Id: Ic6dd62097399bf75e3d11b4d8a6400971069c415
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/58/145058/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_warning.py', 'oslo_utils/tests/test_netutils.py', 'oslo_utils/tests/fake/__init__.py', 'oslo_utils/encodeutils.py', 'doc/source/usage.rst', 'oslo/utils/encodeutils.py', 'oslo_utils/__init__.py', 'oslo/utils/netutils.py', 'oslo_utils/uuidutils.py', 'oslo/utils/uuidutils.py', 'doc/source/api/excutils.rst', 'doc/source/api/encodeutils.rst', 'oslo_utils/reflection.py', 'oslo/utils/timeutils.py', 'oslo_utils/tests/base.py', 'oslo_utils/_i18n.py', 'oslo/utils/importutils.py', 'doc/source/api/units.rst', 'doc/source/api/netutils.rst', 'doc/source/api/timeutils.rst', 'oslo_utils/netutils.py', 'oslo_utils/tests/test_importutils.py', 'oslo_utils/tests/__init__.py', 'oslo_utils/units.py', 'oslo/utils/strutils.py', 'oslo/utils/excutils.py', 'tests/test_importutils.py', 'oslo_utils/tests/test_uuidutils.py', 'oslo/utils/reflection.py', 'doc/source/api/strutils.rst', 'oslo_utils/strutils.py', 'oslo_utils/excutils.py', 'oslo_utils/tests/test_reflection.py', 'oslo_utils/tests/tests_encodeutils.py', 'oslo_utils/tests/test_excutils.py', 'oslo_utils/tests/test_strutils.py', 'oslo_utils/importutils.py', 'oslo_utils/timeutils.py', 'oslo/utils/units.py', 'doc/source/api/importutils.rst', 'setup.cfg', 'tests/test_netutils.py', 'tox.ini', 'oslo_utils/tests/test_timeutils.py', 'oslo/utils/__init__.py']",45,b1ff82095f26cd0bbcac292bdf95b371cf591f8b,bp/drop-namespace-packages,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import warnings def deprecated(): new_name = __name__.replace('.', '_') warnings.warn( ('The oslo namespace package is deprecated. Please use %s instead.' % new_name), DeprecationWarning, stacklevel=3, ) deprecated() ",,3388,1267
openstack%2Fdevstack~master~I8350d2de8602472e5a7d80b490d2c24f43865e19,openstack/devstack,master,I8350d2de8602472e5a7d80b490d2c24f43865e19,Fix wsgi dir cleanup in Keystone,MERGED,2014-12-18 23:12:41.000000000,2015-01-06 23:41:21.000000000,2015-01-06 23:41:20.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 8074}, {'_account_id': 10385}, {'_account_id': 11444}]","[{'number': 1, 'created': '2014-12-18 23:12:41.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/305c4debde80a79676848c108cb42c0a12ce7405', 'message': 'Fix wsgi dir cleanup in Keystone\n\nChange-Id: I8350d2de8602472e5a7d80b490d2c24f43865e19\n'}]",0,142927,305c4debde80a79676848c108cb42c0a12ce7405,18,7,1,970,,,0,"Fix wsgi dir cleanup in Keystone

Change-Id: I8350d2de8602472e5a7d80b490d2c24f43865e19
",git fetch https://review.opendev.org/openstack/devstack refs/changes/27/142927/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,305c4debde80a79676848c108cb42c0a12ce7405,clean-wsgi, sudo rm -f $KEYSTONE_WSGI_DIR/*, sudo rm -f $KEYSTONE_WSGI_DIR/*.wsgi,1,1
openstack%2Fsolum~master~Iebca2ac3fe47acf274d931f9468529d6e57d38b3,openstack/solum,master,Iebca2ac3fe47acf274d931f9468529d6e57d38b3,Fixing test_components_get_all,MERGED,2015-01-06 21:59:58.000000000,2015-01-06 23:18:10.000000000,2015-01-06 23:18:10.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 9095}]","[{'number': 1, 'created': '2015-01-06 21:59:58.000000000', 'files': ['functionaltests/api/v1/test_component.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/f23c725348c6a5e8bcb94e87acf68072b2acbb6b', 'message': 'Fixing test_components_get_all\n\nChange-Id: Iebca2ac3fe47acf274d931f9468529d6e57d38b3\n'}]",0,145357,f23c725348c6a5e8bcb94e87acf68072b2acbb6b,7,3,1,7784,,,0,"Fixing test_components_get_all

Change-Id: Iebca2ac3fe47acf274d931f9468529d6e57d38b3
",git fetch https://review.opendev.org/openstack/solum refs/changes/57/145357/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/api/v1/test_component.py'],1,f23c725348c6a5e8bcb94e87acf68072b2acbb6b,component-test-fix,"sample_data = {'name': 'test_component', def _delete_component(self, uuid): uuid, assembly_uuid, plan_uuid = self._create_component() filtered = [com for com in data if com['uuid'] == uuid] self.assertEqual(len(filtered), 1) self.assertEqual(filtered[0]['uuid'], uuid) self._delete_component(uuid) self._delete_component(json_data['uuid']) self._delete_component(uuid) self._delete_component(uuid)","sample_data = {'name': 'test_service', def _delete_component(self, uuid, assembly_uuid, plan_uuid): self.assertEqual(data, []) self._delete_component(json_data['uuid'], assembly_uuid, plan_uuid) self._delete_component(uuid, assembly_uuid, plan_uuid) self._delete_component(uuid, assembly_uuid, plan_uuid)",10,6
openstack%2Fironic-python-agent~master~I2dc49fbe306430bf5b05a36fe56de5275fc128b2,openstack/ironic-python-agent,master,I2dc49fbe306430bf5b05a36fe56de5275fc128b2,Add standalone mode for IPA,MERGED,2014-12-16 01:30:15.000000000,2015-01-06 23:17:33.000000000,2015-01-06 23:17:32.000000000,"[{'_account_id': 3}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-12-16 01:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9e094c10ef0c7aba73e368d5eb3ae38a2cb2cc2f', 'message': 'Add standalone mode for IPA\n\nThis allows a developer to run IPA without an Ironic API. This can\nbe useful for testing (especially functional testing) or testing\nintegration of things like hardware managers.\n\nChange-Id: I2dc49fbe306430bf5b05a36fe56de5275fc128b2\n'}, {'number': 2, 'created': '2014-12-16 01:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/362e25dec35046a5092cb67de45548b01718b53f', 'message': 'Add standalone mode for IPA\n\nThis allows a developer to run IPA without an Ironic API. This can\nbe useful for testing (especially functional testing) or testing\nintegration of things like hardware managers.\n\nChange-Id: I2dc49fbe306430bf5b05a36fe56de5275fc128b2\n'}, {'number': 3, 'created': '2014-12-16 19:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0544a8d35cf6ee8858a5f68f25b3e7063747f5c8', 'message': 'Add standalone mode for IPA\n\nThis allows a developer to run IPA without an Ironic API. This can\nbe useful for testing (especially functional testing) or testing\nintegration of things like hardware managers.\n\nChange-Id: I2dc49fbe306430bf5b05a36fe56de5275fc128b2\n'}, {'number': 4, 'created': '2014-12-17 02:05:11.000000000', 'files': ['ironic_python_agent/agent.py', 'ironic_python_agent/tests/agent.py', 'ironic_python_agent/cmd/agent.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/417bf086a53da995fbf93cc2c04990f9c5f87c9f', 'message': 'Add standalone mode for IPA\n\nThis allows a developer to run IPA without an Ironic API. This can\nbe useful for testing (especially functional testing) or testing\nintegration of things like hardware managers.\n\nChange-Id: I2dc49fbe306430bf5b05a36fe56de5275fc128b2\n'}]",4,141957,417bf086a53da995fbf93cc2c04990f9c5f87c9f,21,4,4,10380,,,0,"Add standalone mode for IPA

This allows a developer to run IPA without an Ironic API. This can
be useful for testing (especially functional testing) or testing
integration of things like hardware managers.

Change-Id: I2dc49fbe306430bf5b05a36fe56de5275fc128b2
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/57/141957/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/agent.py', 'ironic_python_agent/ironic_api_client.py', 'ironic_python_agent/cmd/agent.py']",3,9e094c10ef0c7aba73e368d5eb3ae38a2cb2cc2f,standalone," default=APARAMS.get('ipa-api-url', 'http://127.0.0.1:6835'), help='The amount of seconds to wait for LLDP packets.'), cfg.BoolOpt('standalone', default=False, help='Note: for debugging only. Skipping doing a lookup ' 'to the Ironic API on boot and skip heartbeating.'), CONF.driver_name, CONF.standalone).run()"," required=('ipa-api-url' not in APARAMS), default=APARAMS.get('ipa-api-url'), help='The amount of seconds to wait for LLDP packets.') CONF.driver_name).run()",23,14
openstack%2Fheat~master~I6e907adf16d8cf6fbbcf526632c91ca81611ea09,openstack/heat,master,I6e907adf16d8cf6fbbcf526632c91ca81611ea09,Do not use private classes from oslo.i18n,MERGED,2015-01-06 16:08:46.000000000,2015-01-06 23:14:16.000000000,2015-01-06 23:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-06 16:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f4bb38ae9cb143eb35819730b8da862809a7027a', 'message': 'Do not use private classes from oslo.i18n\n\nUse oslo.i18n.translate() without first testing if the argument being\npassed is a Message instance. The Message class is meant to be hidden\nfrom consumers, and translate() correctly detects untranslatable strings\nand returns them as given.\n\nChange-Id: I6e907adf16d8cf6fbbcf526632c91ca81611ea09\n'}, {'number': 2, 'created': '2015-01-06 16:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/15825bbfcf4acc82dd9ae57433fd43a9cabe78ad', 'message': 'Do not use private classes from oslo.i18n\n\nUse oslo.i18n.translate() without first testing if the argument being\npassed is a Message instance. The Message class is meant to be hidden\nfrom consumers, and translate() correctly detects untranslatable strings\nand returns them as given.\n\nChange-Id: I6e907adf16d8cf6fbbcf526632c91ca81611ea09\n'}, {'number': 3, 'created': '2015-01-06 16:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3d556b9080b8f21700bbbdeac340ba9c8d0b4474', 'message': 'Do not use private classes from oslo.i18n\n\nUse oslo.i18n.translate() without first testing if the argument being\npassed is a Message instance. The Message class is meant to be hidden\nfrom consumers, and translate() correctly detects untranslatable strings\nand returns them as given.\n\nChange-Id: I6e907adf16d8cf6fbbcf526632c91ca81611ea09\n'}, {'number': 4, 'created': '2015-01-06 16:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1d2e5a4d1ebcca8c0ea51d527b09cccb0c3a0f81', 'message': 'Do not use private classes from oslo.i18n\n\nUse oslo.i18n.translate() without first testing if the argument being\npassed is a Message instance. The Message class is meant to be hidden\nfrom consumers, and translate() correctly detects untranslatable strings\nand returns them as given.\n\nChange-Id: I6e907adf16d8cf6fbbcf526632c91ca81611ea09\n'}, {'number': 5, 'created': '2015-01-06 18:43:31.000000000', 'files': ['heat/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/40fa30fd741968a182e21f98d70ec256e542d49a', 'message': 'Do not use private classes from oslo.i18n\n\nUse oslo.i18n.translate() without first testing if the argument being\npassed is a Message instance. The Message class is meant to be hidden\nfrom consumers, and translate() correctly detects untranslatable strings\nand returns them as given.\n\nChange-Id: I6e907adf16d8cf6fbbcf526632c91ca81611ea09\n'}]",4,145257,40fa30fd741968a182e21f98d70ec256e542d49a,19,6,5,2472,,,0,"Do not use private classes from oslo.i18n

Use oslo.i18n.translate() without first testing if the argument being
passed is a Message instance. The Message class is meant to be hidden
from consumers, and translate() correctly detects untranslatable strings
and returns them as given.

Change-Id: I6e907adf16d8cf6fbbcf526632c91ca81611ea09
",git fetch https://review.opendev.org/openstack/heat refs/changes/57/145257/5 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/wsgi.py'],1,f4bb38ae9cb143eb35819730b8da862809a7027a,fix-oslo-i18n-use," exc.message = i18n.translate(exc.message, locale) exc.explanation = i18n.translate(exc.explanation, locale) exc.detail = i18n.translate(exc.detail, locale)"," if isinstance(exc, exception.HeatException): exc.message = i18n.translate(exc.message, locale) else: exc.message = i18n.translate(six.text_type(exc), locale) if not isinstance(exc.explanation, i18n._message.Message): exc.explanation = six.text_type(exc) exc.detail = '' else: exc.explanation = \ i18n.translate(exc.explanation, locale) exc.detail = i18n.translate(exc.detail, locale)",3,11
openstack%2Fglance-specs~master~I182709bed737939193a278585a6838f34a061fb3,openstack/glance-specs,master,I182709bed737939193a278585a6838f34a061fb3,Enhanced User Experience Metadata Definitions,ABANDONED,2014-09-19 19:38:18.000000000,2015-01-06 23:13:52.000000000,,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 8959}, {'_account_id': 10383}, {'_account_id': 13161}]","[{'number': 1, 'created': '2014-09-19 19:38:18.000000000', 'files': ['specs/kilo/enhanced-ux-metadata-definitions.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/cf9a489996caad1bdc57026c762045a9dd15a686', 'message': 'Enhanced User Experience Metadata Definitions\n\nEnhance the metadata definitions to support namespace categories,\nicons, tagging of the metadata definitions themselves, and localization. This\nwill improve user understanding of the resource as well as enable faceted\nsearch and graphical imagery (icons) with little to no impact to the data\nstorage requirements on any particular resource today. It will also eliminate\nredundancy.\n\nChange-Id: I182709bed737939193a278585a6838f34a061fb3\n'}]",0,122844,cf9a489996caad1bdc57026c762045a9dd15a686,4,5,1,7665,,,0,"Enhanced User Experience Metadata Definitions

Enhance the metadata definitions to support namespace categories,
icons, tagging of the metadata definitions themselves, and localization. This
will improve user understanding of the resource as well as enable faceted
search and graphical imagery (icons) with little to no impact to the data
storage requirements on any particular resource today. It will also eliminate
redundancy.

Change-Id: I182709bed737939193a278585a6838f34a061fb3
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/44/122844/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/enhanced-ux-metadata-definitions.rst'],1,cf9a489996caad1bdc57026c762045a9dd15a686,bp/enhanced-ux-metadefs,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================ Enhanced User Experience Metadata Definitions ================================================================ Enhance the metadata definitions to support namespace categories, icons, tagging of the metadata definitions themselves, and localization. This will improve user understanding of the resource as well as enable faceted search and graphical imagery (icons) with little to no impact to the data storage requirements on any particular resource today. It will also eliminate redundancy. Problem description =================== In Juno, the metadata definitions catalog was introduced with a primary intent to improve collaboration on the metadata that can be applied to different resources such as images, flavors, host aggregates, and volumes. The primary development focus in Juno was on what is currently system metadata in OpenStack (properties that affect scheduling and driver behavior). https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst The metadata fields on these same resources can also be used to provide additional, rich information that describes the resource for user understanding and search. This information can be leveraged to improve instance launching, application catalogs, and a variety of other user interaction points. Current methodologies present and proposed in OpenStack require repetitive descriptions, categorization, imagery, and attributes to be applied on each instance of a resource. For example, if multiple images contain Apache then each image will require the user to type in information about Apache, will require them to provide some sort of categorization tag, and will not have any common ""template"" like fields for the software which can be used for faceted search. This leads to redundancy, spelling mistakes, inconsistency as well as a general lack of ability to present a rich UI experience. Proposed change =============== Enhance the metadata definitions to support namespace categories, icons, tagging of the metadata definitions themselves, and localization. This will enable consistency and rich descriptions of images and other artifacts by reference. For example, a certain type of software such as MySQL could be on multiple different virtual machine images and may be provided by multiple different orchestration artifacts (e.g. a Heat software configuration template). However, many informational things about it should be be common across all the instances of it. For example, they could all share a common base description, a standard icon, will have common base attributes (e.g. version), and may belong to a certain category (e.g. ""Database""). With this change, a vendor or admin will be able to do something like create a namespace that describes different types of database software. They may have an object for MySQL and an object for Postgres. Each object will have the following associated with it: * User friendly name * User friendly description * Icon associated with it (e.g. MySQL icon and Postgres icon respectively) * A set of properties specific to that software (e.g. version and listen_port) * A set of tags associated with it (such as ""database"", ""postgres"", ""sql"", etc) Once the namespace is published, the user will be able to simply browse the available objects and just apply any applicable metadata properties to the image or artifact. For example, if the ""MySQL"" object has a property of ""software_mysql_version"", the user would simply apply the property of software_mysql_version to the image with a value of something like ""5.6"". Using JUST this simple property, the image will essentially be linked back to the metadata definitions catalog where the standardized title, description, icon, and tags for MySQL will be defined. The UI will now be able to resolve the property against the metadata definitions in the metadata definitions catalog to enable rich display of information about the image. It will also by able to be referenced by faceted search and filtering (e.g. display all images with mysql version 5.6 on it). And finally, since the MySQL definition will have the tags of ""database"" and ""sql"" on it, the image will be tagged by reference, essentially meaning auto tagging is applied to the image. A key aspect to this is that it enables very easy information enablement for users and admins. If there are 30 images in the system with MySQL on it, the only action the user has to do to automatically give them a rich description, icon, and tagging is apply at least one property from the mysql object in the metadata definitions. All of them will then share common information and if the description needs to be changed, all of them will be basically updated simultaneously by simply updating the definition.. Finally, many times images or other artifacts, such as a heat template, may provide multiple different software components installed in them. For example, a ""LAMP"" image may have Linux, Apache, MySQL, and PHP. If each of these pieces of software are defined within the metadata definitions of the catalog, applying even a single property from each of those objects will enable a user experience that provides rich detail and faceted search on each of those pieces of software. Conceptual mockup: https://wiki.openstack.org/w/images/2/26/Enhanced-user-experinece-defs-screen-shots.PNG The namespace itself will also have a namespace category associated with it. The reason for providing a category on the namespace itself is that it will aid in laying out the user experience in UI or CLI. For example, a section of the UI will show all ""Installed Software"" and another section will show ""Advanced Details"" that would show system metadata if the user has RBAC permissions. The UI layout will simply display metadata in the correct section using the namespace categories. This type of concept will apply to all types of resources. So, if a vendor decides to offer some form of ""Gold"", ""Silver"", and ""Bronze"" service assurance that is enabled by selecting a particular flavor or volume type, they will simply publish the service assurance namespace into the metadata definitions catalog. When the flavor is created, the admin will simply add the correct properties. The UI will then be able to provide the rich description and iconography associated with the properties (perhaps a gold, silver, and bronze medal). Everything is esentially handled by reference As illustrated by the below:: +------------------------------+ +-------------------------------+ | Resource (e.g. Image) | | Object: MySQL | | | | Display Name | | | | Description | | Property A-------------------------> | Icon | | | | Tags | | Property B-------------------------> +-------------------------------+ | | | | | | +-------------------------------+ | | | Object: Apache | | Property C-------------------------> | Display Name | | | | Description | +------------------------------+ | Icon | | Tags | +-------------------------------+ Alternatives ------------ Every single image, artifact, or other type of resource is added to the system, the admin could be responsible for putting a good description that is consistent with other descriptions, could try to remember all the right tags to add, could upload a new to directly associate with it. This leads to redundancy, spelling mistakes, inconsistency as well as a general lack of ability to present a rich UI experience. It also doesn't enable predictable search facets for rich search experience. Data model impact ----------------- In Progress REST API impact --------------- In progress Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Other deployer impact --------------------- In Progress Developer impact ---------------- In Progress Implementation ============== Assignee(s) ----------- HP and Intel will contribute engineering resources to this effort similar to the effort contributed on the original release of the Metadata Defintions Catalog. Primary assignee: TBD Other contributors: TBD Work Items ---------- #. The database API layer on namespaces #. The database API layer on objects #. The REST API for updates to operations on the namespaces #. The REST API for updates to operations on the objects #. The python-glanceClient to support operations Dependencies ============ Same dependencies as Glance. Testing ======= Unit tests will be added for all possible code with a goal of being able to isolate functionality as much as possible. Tempest tests will be added wherever possible. Documentation Impact ==================== Docs needed for new API extension and usage References ========== https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst # noqa ",,255,0
openstack%2Fmagnum~master~I7f2731911a3fc71fbbf3b408b39e57b7521db81f,openstack/magnum,master,I7f2731911a3fc71fbbf3b408b39e57b7521db81f,Docker: Pull Image Before Container Create,MERGED,2015-01-06 21:25:55.000000000,2015-01-06 23:09:29.000000000,2015-01-06 23:09:28.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-06 21:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/909a3c8059972cab0fcfe74eac04c0fca9a8983c', 'message': ""Docker: Pull Image Before Container Create\n\nThe image needs to be pulled so that it's available for\nsubsequent inspect and create calls.\n\nChange-Id: I7f2731911a3fc71fbbf3b408b39e57b7521db81f\nCloses-bug: #1408101\n""}, {'number': 2, 'created': '2015-01-06 21:29:00.000000000', 'files': ['magnum/conductor/handlers/docker_conductor.py', 'magnum/tests/conductor/handlers/test_docker_conductor.py', 'magnum/common/docker_utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/46ebff53e6c5042b3ecbcf97830e81b1c10ec6a5', 'message': ""Docker: Pull Image Before Container Create\n\nThe image needs to be pulled so that it's available for\nsubsequent inspect and create calls.\n\nChange-Id: I7f2731911a3fc71fbbf3b408b39e57b7521db81f\nCloses-bug: #1408101\n""}]",0,145347,46ebff53e6c5042b3ecbcf97830e81b1c10ec6a5,8,3,2,5387,,,0,"Docker: Pull Image Before Container Create

The image needs to be pulled so that it's available for
subsequent inspect and create calls.

Change-Id: I7f2731911a3fc71fbbf3b408b39e57b7521db81f
Closes-bug: #1408101
",git fetch https://review.opendev.org/openstack/magnum refs/changes/47/145347/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/docker_conductor.py', 'magnum/tests/conductor/handlers/test_docker_conductor.py', 'magnum/common/docker_utils.py']",3,909a3c8059972cab0fcfe74eac04c0fca9a8983c,bug/1408101,"# Copyright 2014 Rackspace All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. def parse_docker_image(image_id): image_parts = image_id.split(':', 1) image_repo = image_parts[0] image_tag = None if len(image_parts) > 1: image_tag = image_parts[1] return image_repo, image_tag ",,74,2
openstack%2Foslo.concurrency~master~Ie763ef92f31c34869d83a533bc8761b0fbd77217,openstack/oslo.concurrency,master,Ie763ef92f31c34869d83a533bc8761b0fbd77217,Add a reader/writer lock,MERGED,2014-12-02 00:50:12.000000000,2015-01-06 22:59:34.000000000,2015-01-06 22:59:33.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-12-02 00:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/aa7c3bd5be068a6d3079f801e4d32c9142ae77c9', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 2, 'created': '2014-12-02 00:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/2aa651cfff85a25b9a5f56403bf13d6a55071882', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 3, 'created': '2014-12-02 01:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/81ecebcdf7d7518cf8137c087dc71f3582bacb93', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 4, 'created': '2014-12-02 01:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/3c970b7d37515d5a2a48887d227b516ef61b435d', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 5, 'created': '2014-12-02 01:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/6baa330a1d18bd51474fce2eb0f16af6079d42ba', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 6, 'created': '2014-12-03 22:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/12599145b612553557f76abad20a99af93df2d10', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 7, 'created': '2014-12-03 23:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/d05cc3feab33aa0ce2c0c162e1170e2c2660e290', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 8, 'created': '2014-12-03 23:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/baa40cadb9382aadd7a8e6488b56378ba2ac029d', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 9, 'created': '2014-12-04 05:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/60365d9ba4654ac308ed255b97cb572282ad3981', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 10, 'created': '2014-12-05 01:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/4dace557eaaecad1825787d435231c0a6cf8891e', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}, {'number': 11, 'created': '2014-12-19 23:42:42.000000000', 'files': ['oslo_concurrency/lockutils.py', 'test-requirements.txt', 'oslo_concurrency/tests/unit/test_lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/90663364f82966489856ffa0fbe03a1824bebb55', 'message': 'Add a reader/writer lock\n\nTaskflow has a reader/writer lock that is likely useful\nto other projects; and it seems better at home in this\nmodule.\n\nThe class provides a way to create reader/writer locks\nwhere there may be many readers at the same time (but\nonly one writer). It does not allow (currently) for privilege\nescalation (but this could be added with limited support\nin the future).\n\nChange-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217\n'}]",41,138217,90663364f82966489856ffa0fbe03a1824bebb55,53,7,11,1297,,,0,"Add a reader/writer lock

Taskflow has a reader/writer lock that is likely useful
to other projects; and it seems better at home in this
module.

The class provides a way to create reader/writer locks
where there may be many readers at the same time (but
only one writer). It does not allow (currently) for privilege
escalation (but this could be added with limited support
in the future).

Change-Id: Ie763ef92f31c34869d83a533bc8761b0fbd77217
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/17/138217/9 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_concurrency/lockutils.py', 'test-requirements.txt', 'oslo_concurrency/tests/unit/test_lockutils.py']",3,aa7c3bd5be068a6d3079f801e4d32c9142ae77c9,,"from concurrent import futuresclass ReadWriteLockTest(test_base.BaseTestCase): # We will spend this amount of time doing some ""fake"" work. WORK_TIMES = [(0.01 + x / 100.0) for x in range(0, 5)] # NOTE(harlowja): Sleep a little so time.time() can not be the same (which # will cause false positives when our overlap detection code runs). If # there are real overlaps then they will still exist. NAPPY_TIME = 0.05 @staticmethod def _find_overlaps(times, start, end): """"""Counts num of overlaps between start and end in the given times."""""" overlaps = 0 for (s, e) in times: if s >= start and e <= end: overlaps += 1 return overlaps @classmethod def _spawn_variation(cls, readers, writers, max_workers=None): """"""Spawns the given number of readers and writers."""""" start_stops = collections.deque() lock = lockutils.ReaderWriterLock() def read_func(ident): with lock.read_lock(): # TODO(harlowja): sometime in the future use a monotonic clock # here to avoid problems that can be caused by ntpd resyncing # the clock while we are actively running. enter_time = time.time() time.sleep(cls.WORK_TIMES[ident % len(cls.WORK_TIMES)]) exit_time = time.time() start_stops.append((lock.READER, enter_time, exit_time)) time.sleep(cls.NAPPY_TIME) def write_func(ident): with lock.write_lock(): enter_time = time.time() time.sleep(cls.WORK_TIMES[ident % len(cls.WORK_TIMES)]) exit_time = time.time() start_stops.append((lock.WRITER, enter_time, exit_time)) time.sleep(cls.NAPPY_TIME) if max_workers is None: max_workers = max(0, readers) + max(0, writers) if max_workers > 0: with futures.ThreadPoolExecutor(max_workers=max_workers) as e: count = 0 for _i in range(0, readers): e.submit(read_func, count) count += 1 for _i in range(0, writers): e.submit(write_func, count) count += 1 writer_times = [] reader_times = [] for (lock_type, start, stop) in list(start_stops): if lock_type == lock.WRITER: writer_times.append((start, stop)) else: reader_times.append((start, stop)) return (writer_times, reader_times) def test_writer_abort(self): lock = lockutils.ReaderWriterLock() self.assertFalse(lock.owner) def blow_up(): with lock.write_lock(): self.assertEqual(lock.WRITER, lock.owner) raise RuntimeError(""Broken"") self.assertRaises(RuntimeError, blow_up) self.assertFalse(lock.owner) def test_reader_abort(self): lock = lockutils.ReaderWriterLock() self.assertFalse(lock.owner) def blow_up(): with lock.read_lock(): self.assertEqual(lock.READER, lock.owner) raise RuntimeError(""Broken"") self.assertRaises(RuntimeError, blow_up) self.assertFalse(lock.owner) def test_double_reader_abort(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() def double_bad_reader(): with lock.read_lock(): with lock.read_lock(): raise RuntimeError(""Broken"") def happy_writer(): with lock.write_lock(): activated.append(lock.owner) with futures.ThreadPoolExecutor(max_workers=20) as e: for i in range(0, 20): if i % 2 == 0: e.submit(double_bad_reader) else: e.submit(happy_writer) self.assertEqual(10, len([a for a in activated if a == 'w'])) def test_double_reader_writer(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() active = threading.Event() def double_reader(): with lock.read_lock(): active.set() while not lock.has_pending_writers: time.sleep(0.001) with lock.read_lock(): activated.append(lock.owner) def happy_writer(): with lock.write_lock(): activated.append(lock.owner) reader = threading.Thread(target=double_reader) reader.daemon = True reader.start() active.wait() self.assertTrue(active.is_set()) writer = threading.Thread(target=happy_writer) writer.daemon = True writer.start() reader.join() writer.join() self.assertEqual(2, len(activated)) self.assertEqual(['r', 'w'], list(activated)) def test_reader_chaotic(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() def chaotic_reader(blow_up): with lock.read_lock(): if blow_up: raise RuntimeError(""Broken"") else: activated.append(lock.owner) def happy_writer(): with lock.write_lock(): activated.append(lock.owner) with futures.ThreadPoolExecutor(max_workers=20) as e: for i in range(0, 20): if i % 2 == 0: e.submit(chaotic_reader, blow_up=bool(i % 4 == 0)) else: e.submit(happy_writer) writers = [a for a in activated if a == 'w'] readers = [a for a in activated if a == 'r'] self.assertEqual(10, len(writers)) self.assertEqual(5, len(readers)) def test_writer_chaotic(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() def chaotic_writer(blow_up): with lock.write_lock(): if blow_up: raise RuntimeError(""Broken"") else: activated.append(lock.owner) def happy_reader(): with lock.read_lock(): activated.append(lock.owner) with futures.ThreadPoolExecutor(max_workers=20) as e: for i in range(0, 20): if i % 2 == 0: e.submit(chaotic_writer, blow_up=bool(i % 4 == 0)) else: e.submit(happy_reader) writers = [a for a in activated if a == 'w'] readers = [a for a in activated if a == 'r'] self.assertEqual(5, len(writers)) self.assertEqual(10, len(readers)) def test_single_reader_writer(self): results = [] lock = lockutils.ReaderWriterLock() with lock.read_lock(): self.assertTrue(lock.is_reader()) self.assertEqual(0, len(results)) with lock.write_lock(): results.append(1) self.assertTrue(lock.is_writer()) with lock.read_lock(): self.assertTrue(lock.is_reader()) self.assertEqual(1, len(results)) self.assertFalse(lock.is_reader()) self.assertFalse(lock.is_writer()) def test_reader_to_writer(self): lock = lockutils.ReaderWriterLock() def writer_func(): with lock.write_lock(): pass with lock.read_lock(): self.assertRaises(RuntimeError, writer_func) self.assertFalse(lock.is_writer()) self.assertFalse(lock.is_reader()) self.assertFalse(lock.is_writer()) def test_writer_to_reader(self): lock = lockutils.ReaderWriterLock() def reader_func(): with lock.read_lock(): pass with lock.write_lock(): self.assertRaises(RuntimeError, reader_func) self.assertFalse(lock.is_reader()) self.assertFalse(lock.is_reader()) self.assertFalse(lock.is_writer()) def test_double_writer(self): lock = lockutils.ReaderWriterLock() with lock.write_lock(): self.assertFalse(lock.is_reader()) self.assertTrue(lock.is_writer()) with lock.write_lock(): self.assertTrue(lock.is_writer()) self.assertTrue(lock.is_writer()) self.assertFalse(lock.is_reader()) self.assertFalse(lock.is_writer()) def test_double_reader(self): lock = lockutils.ReaderWriterLock() with lock.read_lock(): self.assertTrue(lock.is_reader()) self.assertFalse(lock.is_writer()) with lock.read_lock(): self.assertTrue(lock.is_reader()) self.assertTrue(lock.is_reader()) self.assertFalse(lock.is_reader()) self.assertFalse(lock.is_writer()) def test_multi_reader_multi_writer(self): writer_times, reader_times = self._spawn_variation(10, 10) self.assertEqual(10, len(writer_times)) self.assertEqual(10, len(reader_times)) for (start, stop) in writer_times: self.assertEqual(0, self._find_overlaps(reader_times, start, stop)) self.assertEqual(1, self._find_overlaps(writer_times, start, stop)) for (start, stop) in reader_times: self.assertEqual(0, self._find_overlaps(writer_times, start, stop)) def test_multi_reader_single_writer(self): writer_times, reader_times = self._spawn_variation(9, 1) self.assertEqual(1, len(writer_times)) self.assertEqual(9, len(reader_times)) start, stop = writer_times[0] self.assertEqual(0, self._find_overlaps(reader_times, start, stop)) def test_multi_writer(self): writer_times, reader_times = self._spawn_variation(0, 10) self.assertEqual(10, len(writer_times)) self.assertEqual(0, len(reader_times)) for (start, stop) in writer_times: self.assertEqual(1, self._find_overlaps(writer_times, start, stop)) ",,439,5
openstack%2Frequirements~master~I0d43c604c10e18c72810d42046d447fbf1deed10,openstack/requirements,master,I0d43c604c10e18c72810d42046d447fbf1deed10,Update only if version requirement has changed,MERGED,2015-01-02 20:00:03.000000000,2015-01-06 22:43:54.000000000,2015-01-06 22:43:53.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4264}, {'_account_id': 5263}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-01-02 20:00:03.000000000', 'files': ['update.py'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2b588aeb69ae1f89280f2d9c8fa8290d0e1cdf57', 'message': 'Update only if version requirement has changed\n\nPreviously, if any change was made to a line, it would update the line. This\nincludes whitespace changes around comments on the line. See\nhttps://review.openstack.org/#/c/144782/ for an example of a unhelpful update.\n\nChange-Id: I0d43c604c10e18c72810d42046d447fbf1deed10\n'}]",0,144799,2b588aeb69ae1f89280f2d9c8fa8290d0e1cdf57,23,6,1,12000,,,0,"Update only if version requirement has changed

Previously, if any change was made to a line, it would update the line. This
includes whitespace changes around comments on the line. See
https://review.openstack.org/#/c/144782/ for an example of a unhelpful update.

Change-Id: I0d43c604c10e18c72810d42046d447fbf1deed10
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/144799/1 && git format-patch -1 --stdout FETCH_HEAD,['update.py'],1,2b588aeb69ae1f89280f2d9c8fa8290d0e1cdf57,update-on-requirement-change,"def _functionally_equal(old_requirement, new_requirement): old_require = req.InstallRequirement.from_line(old_requirement) new_require = req.InstallRequirement.from_line(new_requirement) return old_require.req == new_require.req elif _functionally_equal(old_require, source_reqs[old_pip]): new_reqs.write(old_line)",,8,0
openstack%2Foslo.middleware~master~If88c65c82b64f096a02f7ec62e019aea4de2f9d3,openstack/oslo.middleware,master,If88c65c82b64f096a02f7ec62e019aea4de2f9d3,Move files out of the namespace package,MERGED,2015-01-06 17:16:27.000000000,2015-01-06 22:32:23.000000000,2015-01-06 22:32:23.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6537}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-06 17:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/3b9debafa9590b3dbfdb58e9ba91e34ef26bec28', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.middleware to oslo_middleware. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: If88c65c82b64f096a02f7ec62e019aea4de2f9d3\n'}, {'number': 2, 'created': '2015-01-06 18:55:40.000000000', 'files': ['oslo_middleware/debug.py', 'oslo_middleware/tests/test_request_id.py', 'tests/test_warning.py', 'oslo_middleware/sizelimit.py', 'doc/source/api.rst', 'oslo/middleware/request_id.py', 'oslo/middleware/sizelimit.py', 'oslo/middleware/base.py', 'oslo_middleware/base.py', 'oslo_middleware/tests/test_catch_errors.py', 'oslo/middleware/debug.py', 'oslo_middleware/correlation_id.py', 'oslo_middleware/catch_errors.py', 'oslo_middleware/tests/test_correlation_id.py', 'oslo_middleware/request_id.py', 'oslo_middleware/i18n.py', 'oslo_middleware/tests/__init__.py', 'oslo/middleware/correlation_id.py', 'setup.cfg', 'oslo/middleware/__init__.py', 'oslo_middleware/opts.py', 'tox.ini', 'oslo/middleware/catch_errors.py', 'oslo_middleware/__init__.py', 'oslo_middleware/tests/test_sizelimit.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/8e06ca5bd02660eb0b0980593f440ec7e46a00ac', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.middleware to oslo_middleware. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: If88c65c82b64f096a02f7ec62e019aea4de2f9d3\n'}]",2,145271,8e06ca5bd02660eb0b0980593f440ec7e46a00ac,13,4,2,2472,,,0,"Move files out of the namespace package

Move the public API out of oslo.middleware to oslo_middleware. Retain
the ability to import from the old namespace package for backwards
compatibility for this release cycle.

bp/drop-namespace-packages

Change-Id: If88c65c82b64f096a02f7ec62e019aea4de2f9d3
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/71/145271/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_middleware/debug.py', 'oslo_middleware/tests/test_request_id.py', 'tests/test_warning.py', 'oslo_middleware/sizelimit.py', 'doc/source/api.rst', 'oslo/middleware/request_id.py', 'oslo/middleware/sizelimit.py', 'oslo/middleware/base.py', 'oslo_middleware/base.py', 'oslo_middleware/tests/test_catch_errors.py', 'oslo/middleware/debug.py', 'oslo_middleware/correlation_id.py', 'oslo_middleware/catch_errors.py', 'oslo_middleware/tests/test_correlation_id.py', 'oslo_middleware/request_id.py', 'oslo_middleware/i18n.py', 'oslo_middleware/tests/__init__.py', 'oslo/middleware/correlation_id.py', 'setup.cfg', 'oslo/middleware/__init__.py', 'oslo_middleware/opts.py', 'tox.ini', 'oslo/middleware/catch_errors.py', 'oslo_middleware/__init__.py', 'oslo_middleware/tests/test_sizelimit.py']",25,3b9debafa9590b3dbfdb58e9ba91e34ef26bec28,bp/drop-namespace-packages,"# Copyright (c) 2012 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslotest import base as test_base import six import webob from oslo.config import fixture as config from oslo_middleware import sizelimit class TestLimitingReader(test_base.BaseTestCase): def test_limiting_reader(self): BYTES = 1024 bytes_read = 0 data = six.StringIO(""*"" * BYTES) for chunk in sizelimit.LimitingReader(data, BYTES): bytes_read += len(chunk) self.assertEqual(bytes_read, BYTES) bytes_read = 0 data = six.StringIO(""*"" * BYTES) reader = sizelimit.LimitingReader(data, BYTES) byte = reader.read(1) while len(byte) != 0: bytes_read += 1 byte = reader.read(1) self.assertEqual(bytes_read, BYTES) def test_read_default_value(self): BYTES = 1024 data_str = ""*"" * BYTES data = six.StringIO(data_str) reader = sizelimit.LimitingReader(data, BYTES) res = reader.read() self.assertEqual(data_str, res) def test_limiting_reader_fails(self): BYTES = 1024 def _consume_all_iter(): bytes_read = 0 data = six.StringIO(""*"" * BYTES) for chunk in sizelimit.LimitingReader(data, BYTES - 1): bytes_read += len(chunk) self.assertRaises(webob.exc.HTTPRequestEntityTooLarge, _consume_all_iter) def _consume_all_read(): bytes_read = 0 data = six.StringIO(""*"" * BYTES) reader = sizelimit.LimitingReader(data, BYTES - 1) byte = reader.read(1) while len(byte) != 0: bytes_read += 1 byte = reader.read(1) self.assertRaises(webob.exc.HTTPRequestEntityTooLarge, _consume_all_read) class TestRequestBodySizeLimiter(test_base.BaseTestCase): def setUp(self): super(TestRequestBodySizeLimiter, self).setUp() fixture = self.useFixture(config.Config(sizelimit.CONF)) self.MAX_REQUEST_BODY_SIZE = \ fixture.conf.oslo_middleware.max_request_body_size @webob.dec.wsgify() def fake_app(req): return webob.Response(req.body) self.middleware = sizelimit.RequestBodySizeLimiter(fake_app) self.request = webob.Request.blank('/', method='POST') def test_content_length_acceptable(self): self.request.headers['Content-Length'] = self.MAX_REQUEST_BODY_SIZE self.request.body = b""0"" * self.MAX_REQUEST_BODY_SIZE response = self.request.get_response(self.middleware) self.assertEqual(response.status_int, 200) def test_content_length_too_large(self): self.request.headers['Content-Length'] = self.MAX_REQUEST_BODY_SIZE + 1 self.request.body = b""0"" * (self.MAX_REQUEST_BODY_SIZE + 1) response = self.request.get_response(self.middleware) self.assertEqual(response.status_int, 413) def test_request_too_large_no_content_length(self): self.request.body = b""0"" * (self.MAX_REQUEST_BODY_SIZE + 1) self.request.headers['Content-Length'] = None response = self.request.get_response(self.middleware) self.assertEqual(response.status_int, 413) ",,676,265
openstack%2Fceilometer~master~I65180aeb43aa2e8a437f7c68391fd03d99669e71,openstack/ceilometer,master,I65180aeb43aa2e8a437f7c68391fd03d99669e71,Added metering for magnetodb,MERGED,2014-12-23 11:10:03.000000000,2015-01-06 22:28:04.000000000,2015-01-06 22:28:01.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7478}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11224}, {'_account_id': 11428}]","[{'number': 1, 'created': '2014-12-23 11:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bccc02d8a60138a0bed55cd34767cf0658c33f8e', 'message': 'Added metering for magnetodb\n\nWrote notification handler for notifications\nemitted by Magnetodb and corresponding unittests.\n\nChange-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71\nbp: support-magnetodb\n'}, {'number': 2, 'created': '2014-12-29 12:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7986729c22473f9df149eec559f6b7f2eea786fa', 'message': 'Added metering for magnetodb\n\nWrote notification handler for notifications\nemitted by Magnetodb and corresponding unittests.\n\nChange-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71\nbp: support-magnetodb\n'}, {'number': 3, 'created': '2015-01-05 11:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f1bd6c2ebd58eaf37aafcedfaf3eb341e034fc9b', 'message': 'Added metering for magnetodb\n\nWrote notification handler for notifications\nemitted by Magnetodb and corresponding unittests.\n\nChange-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71\nbp: support-magnetodb\n'}, {'number': 4, 'created': '2015-01-05 13:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5f59fed987a4c7b9a6bbb76cbd368000978f2292', 'message': 'Added metering for magnetodb\n\nWrote notification handler for notifications\nemitted by Magnetodb and corresponding unittests.\n\nChange-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71\nbp: support-magnetodb\n'}, {'number': 5, 'created': '2015-01-06 13:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d70f81dfd4a0cd62d2b3ea366f5e57d5f54fef21', 'message': 'Added metering for magnetodb\n\nWrote notification handler for notifications\nemitted by Magnetodb and corresponding unittests.\n\nChange-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71\nbp: support-magnetodb\nDocImpact\n'}, {'number': 6, 'created': '2015-01-06 16:50:16.000000000', 'files': ['doc/source/install/manual.rst', 'ceilometer/tests/key_value_storage/__init__.py', 'ceilometer/tests/key_value_storage/test_notifications.py', 'ceilometer/key_value_storage/__init__.py', 'ceilometer/key_value_storage/notifications.py', 'setup.cfg', 'doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4f4dcfe2dac2e1625a7a5eeda89a76cb93f16f87', 'message': 'Added metering for magnetodb\n\nWrote notification handler for notifications\nemitted by Magnetodb and corresponding unittests.\n\nChange-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71\nbp: support-magnetodb\nDocImpact\n'}]",3,143649,4f4dcfe2dac2e1625a7a5eeda89a76cb93f16f87,27,7,6,11428,,,0,"Added metering for magnetodb

Wrote notification handler for notifications
emitted by Magnetodb and corresponding unittests.

Change-Id: I65180aeb43aa2e8a437f7c68391fd03d99669e71
bp: support-magnetodb
DocImpact
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/49/143649/6 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/magnetodb/__init__.py', 'ceilometer/tests/magnetodb/test_notifications.py', 'ceilometer/magnetodb/notifications.py', 'ceilometer/tests/magnetodb/__init__.py', 'setup.cfg']",5,bccc02d8a60138a0bed55cd34767cf0658c33f8e,bp/support-magnetodb, magnetodb_table = ceilometer.magnetodb.notifications:Table magnetodb_index_count = ceilometer.magnetodb.notifications:Index,,196,0
openstack%2Fceilometer~master~I3ab6472c99abfe28e8c200ada2da91e97abed1d2,openstack/ceilometer,master,I3ab6472c99abfe28e8c200ada2da91e97abed1d2,Add test data generator via oslo messaging,MERGED,2014-12-03 17:59:30.000000000,2015-01-06 22:15:13.000000000,2015-01-06 22:15:12.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6763}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-03 17:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1a035a2428f86ae0be517ba9e0fc58b78a733699', 'message': 'Add test data generator via oslo messaging.\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 2, 'created': '2014-12-04 10:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/40f10e4281e55ad3ee60ca0d14a97d24c79896bb', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 3, 'created': '2014-12-08 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/65697da4842ac0981bd6fbfbace591f0b88c69cf', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 4, 'created': '2014-12-09 14:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d7d93786a4990bb92c60e311d910a862ace0659d', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 5, 'created': '2014-12-11 11:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a52f68501566f478dd9e62046303c6ac496e946f', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 6, 'created': '2014-12-19 14:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c7c1ceafcfe1bcc580ebdaa431c69652db77c3f0', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 7, 'created': '2014-12-22 10:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be483aa48e8901876b9770d687602267571280d7', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 8, 'created': '2014-12-24 14:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/707dc528d60b3881beefae97ed3f4c51c76a3c17', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}, {'number': 9, 'created': '2014-12-25 12:41:59.000000000', 'files': ['tools/send_test_data.py', 'tools/make_test_data.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2ea548f10fb22e8d5f6fe109b94b7b9dc09e1c7e', 'message': 'Add test data generator via oslo messaging\n\nThis script is helpful for emulate real workflow.\nGenerate and send sample batches with different resources and\nconfigurable counter_name.\n\nChange-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2\n'}]",29,138804,2ea548f10fb22e8d5f6fe109b94b7b9dc09e1c7e,71,13,9,7729,,,0,"Add test data generator via oslo messaging

This script is helpful for emulate real workflow.
Generate and send sample batches with different resources and
configurable counter_name.

Change-Id: I3ab6472c99abfe28e8c200ada2da91e97abed1d2
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/04/138804/9 && git format-patch -1 --stdout FETCH_HEAD,"['tools/send_test_data.py', 'tools/make_test_data.py']",2,1a035a2428f86ae0be517ba9e0fc58b78a733699,(detached,"./tools/make_test_data.py --user 1 --project 1 --resource 1 --counter cpu_util --volume 20import uuiddef make_test_data(name, meter_type, unit, volume, random_min, end, interval, resource_metadata=None, source='openstack',): resource_metadata = resource_metadata or {} yield datadef record_test_data(conn, *args, **kwargs): for data in make_test_data(*args, **kwargs): conn.record_metering_data(data) def get_parser(): type=int, type=int, dest='meter_type', dest='project_id', dest='user_id', '--resource', dest='resource_id', default=str(uuid.UUID(uuid.uuid4().hex)), '--counter', default='instance', '--volume', return parser def main(): cfg.CONF([], project='ceilometer') args = get_parser().parse_args() if not (args.user_id or args.project_id): for r in conn.get_resources(): if r.resource_id == args.resource_id: args.user_id = r.user_id args.project_id = r.project_id args.start = (datetime.datetime.utcnow() - datetime.timedelta(days=args.start)) args.end = datetime.datetime.utcnow() + datetime.timedelta(days=args.end) record_test_data(conn=conn, **args.__dict__)","./tools/make_test_data.py --user 1 --project 1 1 cpu_util 20def make_test_data(conn, name, meter_type, unit, volume, random_min, end, interval, resource_metadata={}, source='artificial',): conn.record_metering_data(data)def main(): cfg.CONF([], project='ceilometer') 'resource', 'counter', 'volume', args = parser.parse_args() if not (args.user or args.project): for r in conn.get_resources(): if r.resource_id == args.resource: args.user = r.user_id args.project = r.project_id start = datetime.datetime.utcnow() - datetime.timedelta(days=args.start) end = datetime.datetime.utcnow() + datetime.timedelta(days=args.end) make_test_data(conn=conn, name=args.counter, meter_type=args.type, unit=args.unit, volume=args.volume, random_min=args.random_min, random_max=args.random_max, user_id=args.user, project_id=args.project, resource_id=args.resource, start=start, end=end, interval=args.interval, resource_metadata={}, source='artificial',)",166,32
openstack%2Foctavia~master~I431931d32d6db57d10a8ff143c7d9ac2d17ca428,openstack/octavia,master,I431931d32d6db57d10a8ff143c7d9ac2d17ca428,Removing byte order marker that caused issues,MERGED,2015-01-06 21:46:17.000000000,2015-01-06 21:56:45.000000000,2015-01-06 21:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-01-06 21:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0d623c6373ae397a9f69156f751ca3d2517da5be', 'message': 'Removing byte order marker that caused issues\n\nA byte order marker was added into the beginning of the\nspecs/version0.5/controller.dot file which caused graphviz\n2.36 and earlier to fail, which caused sphinx to fail as well.\n\nChange-Id: I431931d32d6db57d10a8ff143c7d9ac2d17ca428\n'}, {'number': 2, 'created': '2015-01-06 21:47:11.000000000', 'files': ['specs/version0.5/controller.dot'], 'web_link': 'https://opendev.org/openstack/octavia/commit/c6a3a636cc1a1563839e2908be4ee69b1d33fd9e', 'message': 'Removing byte order marker that caused issues\n\nA byte order marker was added into the beginning of the\nspecs/version0.5/controller.dot file which caused graphviz\n2.36 and earlier to fail, which caused sphinx to fail as well.\n\nChange-Id: I431931d32d6db57d10a8ff143c7d9ac2d17ca428\n'}]",0,145350,c6a3a636cc1a1563839e2908be4ee69b1d33fd9e,8,3,2,6951,,,0,"Removing byte order marker that caused issues

A byte order marker was added into the beginning of the
specs/version0.5/controller.dot file which caused graphviz
2.36 and earlier to fail, which caused sphinx to fail as well.

Change-Id: I431931d32d6db57d10a8ff143c7d9ac2d17ca428
",git fetch https://review.opendev.org/openstack/octavia refs/changes/50/145350/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/version0.5/controller.dot'],1,0d623c6373ae397a9f69156f751ca3d2517da5be,remove-byte-order-marker, /*,﻿/*,1,1
openstack%2Fnova~master~I523cfb756a09c75e4f60015adadb3a1403298cd3,openstack/nova,master,I523cfb756a09c75e4f60015adadb3a1403298cd3,Support both list and dict for pci_passthrough_whitelist,MERGED,2014-10-24 15:46:47.000000000,2015-01-06 21:49:31.000000000,2015-01-06 21:09:01.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6598}, {'_account_id': 6685}, {'_account_id': 7118}, {'_account_id': 7543}, {'_account_id': 7823}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12171}]","[{'number': 1, 'created': '2014-10-24 15:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/793ec27a018841d50d7c92f21dd502b5b20a1011', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 2, 'created': '2014-10-24 16:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef261dad58b9cfa1729d3f27154928e717641e89', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 3, 'created': '2014-10-24 18:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d4afb953d0d33359615f4fab607870500bbb2f8', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 4, 'created': '2014-10-24 18:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db8bc4fb673d4c6d571e970bce8d3011c52b75a8', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are now supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 5, 'created': '2014-11-12 15:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/807e57b61dad523951f15b6a048bcec7af075f27', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are now supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 6, 'created': '2014-11-13 05:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f2bc77da88e4ffc3387237a95954e449a860b58', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are now supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 7, 'created': '2014-11-13 13:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72fa3c768a132d2b66ca9c4b5324350fac477e3c', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are now supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 8, 'created': '2014-11-20 18:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/542f94843d2d64d33ca1207d280df4c2de06a343', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are now supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}, {'number': 9, 'created': '2015-01-05 15:31:30.000000000', 'files': ['nova/pci/devspec.py', 'nova/tests/unit/pci/test_devspec.py', 'nova/tests/unit/pci/test_whitelist.py', 'nova/pci/whitelist.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bb7bfd313c9d4c052c85b4ad5ccd8361f5f3b004', 'message': 'Support both list and dict for pci_passthrough_whitelist\n\nIn Icehouse, pci_passthrough_whitelist is a json docstring that\nencodes a list. In Juno, it is a json docstring that encodes\na dict. This patch adds the list support back to\npci_passthrough_whitelist, and both list and dict are now supported.\n\nChange-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3\nCloses-Bug: 1383345\n'}]",16,130833,bb7bfd313c9d4c052c85b4ad5ccd8361f5f3b004,78,18,9,6685,,,0,"Support both list and dict for pci_passthrough_whitelist

In Icehouse, pci_passthrough_whitelist is a json docstring that
encodes a list. In Juno, it is a json docstring that encodes
a dict. This patch adds the list support back to
pci_passthrough_whitelist, and both list and dict are now supported.

Change-Id: I523cfb756a09c75e4f60015adadb3a1403298cd3
Closes-Bug: 1383345
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/130833/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/devspec.py', 'nova/tests/pci/test_devspec.py', 'nova/tests/pci/test_whitelist.py', 'nova/pci/whitelist.py']",4,793ec27a018841d50d7c92f21dd502b5b20a1011,pci-json-2-patch5,"from oslo.serialization import jsonutils from nova import exception try: dev_spec = jsonutils.loads(jsonspec) except Exception: raise exception.PciConfigInvalidWhitelist( reason=""Invalid entry: '%s'"" % jsonspec) if isinstance(dev_spec, dict): dev_spec = [dev_spec] elif not isinstance(dev_spec, list): raise exception.PciConfigInvalidWhitelist( reason=""Invalid entry: '%s'; "" ""Expecting list or dict"" % jsonspec) for ds in dev_spec: if not isinstance(ds, dict): raise exception.PciConfigInvalidWhitelist( reason=""Invalid entry: '%s'; "" ""Expecting dict"" % ds) spec = devspec.PciDeviceSpec(ds) specs.append(spec)", spec = devspec.PciDeviceSpec(jsonspec) specs.append(spec),65,44
openstack%2Fnova~stable%2Fjuno~Ib83e5780bfd0f2dd89a38d33072c12d8e64d7b6f,openstack/nova,stable/juno,Ib83e5780bfd0f2dd89a38d33072c12d8e64d7b6f,Only emit deprecation warnings once during tests,ABANDONED,2015-01-05 19:41:33.000000000,2015-01-06 21:48:18.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-01-05 19:41:33.000000000', 'files': ['nova/test.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d44be0d8c65ae90bfada317a3a04a67b1aab8eb1', 'message': 'Only emit deprecation warnings once during tests\n\nDuring unit tests we should only emit deprecation warnings once. This\nis configurable via core python calls to warnings module.\n\nCloses-Bug: #1407736\n(cherry picked from commit e3a9c60ee45c520258318b0751b1d39b52d4c5e3)\n\nConflicts:\n\tnova/test.py\n\nChange-Id: Ib83e5780bfd0f2dd89a38d33072c12d8e64d7b6f\n'}]",0,145037,d44be0d8c65ae90bfada317a3a04a67b1aab8eb1,5,3,1,2750,,,0,"Only emit deprecation warnings once during tests

During unit tests we should only emit deprecation warnings once. This
is configurable via core python calls to warnings module.

Closes-Bug: #1407736
(cherry picked from commit e3a9c60ee45c520258318b0751b1d39b52d4c5e3)

Conflicts:
	nova/test.py

Change-Id: Ib83e5780bfd0f2dd89a38d33072c12d8e64d7b6f
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/145037/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/test.py'],1,d44be0d8c65ae90bfada317a3a04a67b1aab8eb1,,"import warnings# NOTE(sdague): Make deprecation warnings only happen once. Otherwise # this gets kind of crazy given the way that upstream python libs use # this. warnings.simplefilter(""once"", DeprecationWarning) ",,6,0
openstack%2Fdiskimage-builder~master~I86b3b71a64b29d533b42fd0cae020e8ecf22cac2,openstack/diskimage-builder,master,I86b3b71a64b29d533b42fd0cae020e8ecf22cac2,Ignore stderr from pkg-map,MERGED,2014-12-12 23:38:21.000000000,2015-01-06 21:20:19.000000000,2015-01-06 21:20:18.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 9369}, {'_account_id': 10035}, {'_account_id': 12092}]","[{'number': 1, 'created': '2014-12-12 23:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/3b845a9105328b96b5d02c6686a1d4fbe542d0f2', 'message': 'Ignore stderr from pkg-map\n\nThe latest update to package-install captures both stderr and stdout\nfrom pkg-map, unfortunately, pkg-map has a \'missing-ok\' option\nwhich causes it to print an error message on stderr.\nThe result is that package-install tries to look for packages named\n""Missing"", ""package"", ""name"", etc.\n\nChange-Id: I86b3b71a64b29d533b42fd0cae020e8ecf22cac2\nCloses-bug: 1402085\n'}, {'number': 2, 'created': '2014-12-16 17:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5454c3d99fce4e9d0a393742903a3f5106a60a1c', 'message': 'Ignore stderr from pkg-map\n\nThe latest update to package-install captures both stderr and stdout\nfrom pkg-map, unfortunately, pkg-map has a \'missing-ok\' option\nwhich causes it to print an error message on stderr.\nThe result is that package-install tries to look for packages named\n""Missing"", ""package"", ""name"", etc.\n\nChange-Id: I86b3b71a64b29d533b42fd0cae020e8ecf22cac2\nCloses-bug: 1402085\n'}, {'number': 3, 'created': '2014-12-17 16:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/312bed16d0df1e172827bc5387d48c06e87701c5', 'message': 'Ignore stderr from pkg-map\n\nThe latest update to package-install captures both stderr and stdout\nfrom pkg-map, unfortunately, pkg-map has a \'missing-ok\' option\nwhich causes it to print an error message on stderr.\nThe result is that package-install tries to look for packages named\n""Missing"", ""package"", ""name"", etc.\n\nChange-Id: I86b3b71a64b29d533b42fd0cae020e8ecf22cac2\nCloses-bug: 1402085\n'}, {'number': 4, 'created': '2014-12-17 18:08:15.000000000', 'files': ['elements/package-installs/bin/package-installs-v2'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/da7787069df7c52e82ff6289d23ba8838a014d80', 'message': 'Ignore stderr from pkg-map\n\nThe latest update to package-install captures both stderr and stdout\nfrom pkg-map, unfortunately, pkg-map has a \'missing-ok\' option\nwhich causes it to print an error message on stderr.\nThe result is that package-install tries to look for packages named\n""Missing"", ""package"", ""name"", etc.\n\nChange-Id: I86b3b71a64b29d533b42fd0cae020e8ecf22cac2\nCloses-bug: 1402085\n'}]",12,141522,da7787069df7c52e82ff6289d23ba8838a014d80,37,8,4,12092,,,0,"Ignore stderr from pkg-map

The latest update to package-install captures both stderr and stdout
from pkg-map, unfortunately, pkg-map has a 'missing-ok' option
which causes it to print an error message on stderr.
The result is that package-install tries to look for packages named
""Missing"", ""package"", ""name"", etc.

Change-Id: I86b3b71a64b29d533b42fd0cae020e8ecf22cac2
Closes-bug: 1402085
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/22/141522/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/package-installs/bin/package-installs-v2'],1,3b845a9105328b96b5d02c6686a1d4fbe542d0f2,bug/1402085," pkg_map_args, stderr=None)"," pkg_map_args, stderr=subprocess.STDOUT)",1,1
openstack%2Fheat~stable%2Fjuno~I471b7ebe71ed262a8b0e2c971a32afc7062699cb,openstack/heat,stable/juno,I471b7ebe71ed262a8b0e2c971a32afc7062699cb,ResourceGroup allow update of resource_def,MERGED,2014-12-15 15:15:48.000000000,2015-01-06 21:20:09.000000000,2015-01-06 21:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6983}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-15 15:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/95814982f43c49df4d3eb81e98d434c35fe077ec', 'message': 'ResourceGroup allow update of resource_def\n\nCurrently the group is replaced if the resource_def is updated,\nbut instead we should allow updates and update the underlying\nnested stack instead.  This allows properties to be changed\nsuch that non-replacement updates can be performed on the\nresource-group members.\n\nChange-Id: I471b7ebe71ed262a8b0e2c971a32afc7062699cb\nCloses-Bug: #1396533\nCloses-Bug: #1380612\n(cherry picked from commit d5c84e5defdaccf6292ad154641a1197f827a949)\n'}, {'number': 2, 'created': '2015-01-06 12:51:18.000000000', 'files': ['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/edf0198151214336ab0d04bfc0e48e30c12864dd', 'message': 'ResourceGroup allow update of resource_def\n\nCurrently the group is replaced if the resource_def is updated,\nbut instead we should allow updates and update the underlying\nnested stack instead.  This allows properties to be changed\nsuch that non-replacement updates can be performed on the\nresource-group members.\n\nChange-Id: I471b7ebe71ed262a8b0e2c971a32afc7062699cb\nCloses-Bug: #1396533\nCloses-Bug: #1380612\n(cherry picked from commit d5c84e5defdaccf6292ad154641a1197f827a949)\n'}]",1,141820,edf0198151214336ab0d04bfc0e48e30c12864dd,22,10,2,4328,,,0,"ResourceGroup allow update of resource_def

Currently the group is replaced if the resource_def is updated,
but instead we should allow updates and update the underlying
nested stack instead.  This allows properties to be changed
such that non-replacement updates can be performed on the
resource-group members.

Change-Id: I471b7ebe71ed262a8b0e2c971a32afc7062699cb
Closes-Bug: #1396533
Closes-Bug: #1380612
(cherry picked from commit d5c84e5defdaccf6292ad154641a1197f827a949)
",git fetch https://review.opendev.org/openstack/heat refs/changes/20/141820/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py']",2,95814982f43c49df4d3eb81e98d434c35fe077ec,bug/1396533," def test_props_update(self): """"""Test update of resource_def properties."""""" resg = self._create_dummy_stack() self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['0', '1'], sorted(resource_names)) new_snip = copy.deepcopy(resg.t) new_snip['Properties']['resource_def']['properties']['Foo'] = 'xyz' preupdate_resgid = resg.id preupdate_nestedid = resg.nested().id scheduler.TaskRunner(resg.update, new_snip)() self.stack = resg.nested() self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.state) self.assertEqual((resg.UPDATE, resg.COMPLETE), resg.nested().state) self.assertEqual(2, len(resg.nested())) resource_names = [r.name for r in resg.nested().iter_resources()] self.assertEqual(['0', '1'], sorted(resource_names)) # resource_def update should recurse and update (not replace) nested self.assertEqual(preupdate_resgid, resg.id) self.assertEqual(preupdate_nestedid, resg.nested().id) ",,23,1
openstack%2Fneutron-lbaas~master~Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875,openstack/neutron-lbaas,master,Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875,Reordered neutron import statements in files,MERGED,2014-12-16 03:37:58.000000000,2015-01-06 21:18:08.000000000,2015-01-06 21:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-16 03:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/35640db881bb8238c9a7af8d37ead47215f17ea2', 'message': 'Reordered neutron import statements in files\n\nChange-Id: Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875\n'}, {'number': 2, 'created': '2014-12-17 18:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/02a47619a20eb7b22617b30d99dcd1ee611c7315', 'message': 'Reordered neutron import statements in files\n\nChange-Id: Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875\n'}, {'number': 3, 'created': '2014-12-30 14:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/387a1f09b8a449305eaf5e75655a731c37ebedad', 'message': 'Reordered neutron import statements in files\n\nChange-Id: Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875\n'}, {'number': 4, 'created': '2015-01-06 16:14:11.000000000', 'files': ['neutron_lbaas/services/loadbalancer/drivers/embrane/models.py', 'neutron_lbaas/services/loadbalancer/agent/agent_api.py', 'neutron_lbaas/services/loadbalancer/agent/agent_manager.py', 'neutron_lbaas/services/loadbalancer/drivers/a10networks/driver_v1.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/db.py', 'neutron_lbaas/services/loadbalancer/drivers/netscaler/netscaler_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/agent/lb_operations.py', 'neutron_lbaas/services/loadbalancer/drivers/radware/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/constants.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/poller.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_mixins.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/cfg.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_db.py', 'neutron_lbaas/services/loadbalancer/agent_scheduler.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/agent/dispatcher.py', 'neutron_lbaas/services/loadbalancer/drivers/netscaler/ncc_client.py', 'neutron_lbaas/services/loadbalancer/agent/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/3db31d134bec27a6a1439fab7ec6fc2c01b8f406', 'message': 'Reordered neutron import statements in files\n\nChange-Id: Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875\n'}]",4,141970,3db31d134bec27a6a1439fab7ec6fc2c01b8f406,28,7,4,6437,,,0,"Reordered neutron import statements in files

Change-Id: Ie03bad22b58dc226fdfed4c9bcbd87ae4ecec875
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/70/141970/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/drivers/embrane/models.py', 'neutron_lbaas/services/loadbalancer/agent/agent_manager.py', 'neutron_lbaas/openstack/common/threadgroup.py', 'neutron_lbaas/openstack/common/eventlet_backdoor.py', 'neutron_lbaas/openstack/common/loopingcall.py', 'neutron_lbaas/openstack/common/service.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/agent/lb_operations.py', 'neutron_lbaas/services/loadbalancer/drivers/radware/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/constants.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/poller.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/openstack/common/versionutils.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/cfg.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_db.py', 'neutron_lbaas/services/loadbalancer/agent_scheduler.py', 'neutron_lbaas/services/loadbalancer/drivers/embrane/agent/dispatcher.py', 'neutron_lbaas/services/loadbalancer/drivers/netscaler/ncc_client.py', 'neutron_lbaas/services/loadbalancer/agent/agent.py', 'neutron_lbaas/openstack/common/processutils.py', 'neutron_lbaas/services/loadbalancer/agent/agent_api.py', 'neutron_lbaas/services/loadbalancer/drivers/netscaler/netscaler_driver.py', 'neutron_lbaas/openstack/common/log.py', 'neutron_lbaas/openstack/common/middleware/request_id.py', 'neutron_lbaas/openstack/common/middleware/catch_errors.py', 'neutron_lbaas/openstack/common/policy.py', 'neutron_lbaas/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron_lbaas/openstack/common/periodic_task.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_mixins.py']",30,35640db881bb8238c9a7af8d37ead47215f17ea2,141970,import six,import six ,45,80
openstack%2Fnova~master~Ic7e6ac4d3f270e1b129cf556098e80e7c0738f39,openstack/nova,master,Ic7e6ac4d3f270e1b129cf556098e80e7c0738f39,initialize objects with context in Aggregate object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-06 21:17:48.000000000,2015-01-06 21:17:45.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': ['nova/tests/unit/objects/test_aggregate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/50c9d9c4e22149abf40efe8b7cc197cd8a815ad6', 'message': ""initialize objects with context in Aggregate object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ic7e6ac4d3f270e1b129cf556098e80e7c0738f39\n""}]",0,142272,50c9d9c4e22149abf40efe8b7cc197cd8a815ad6,14,8,1,4690,,,0,"initialize objects with context in Aggregate object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: Ic7e6ac4d3f270e1b129cf556098e80e7c0738f39
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/142272/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_aggregate.py'],1,50c9d9c4e22149abf40efe8b7cc197cd8a815ad6,bp/kilo-objects, agg = aggregate.Aggregate(context=self.context) agg.create() agg = aggregate.Aggregate(context=self.context) agg.create() agg = aggregate.Aggregate(context=self.context) agg.save() agg = aggregate.Aggregate(context=self.context) agg.destroy(), agg = aggregate.Aggregate() agg.create(self.context) agg = aggregate.Aggregate() agg.create(self.context) agg = aggregate.Aggregate() agg.save(self.context) agg = aggregate.Aggregate() agg.destroy(self.context),8,8
openstack%2Fpython-manilaclient~master~Iff86e4486e732c5c245cc9695aa76e032d9b7552,openstack/python-manilaclient,master,Iff86e4486e732c5c245cc9695aa76e032d9b7552,"Remove nonexistent directory ""tests"" from pep8 scanning",MERGED,2015-01-06 12:47:26.000000000,2015-01-06 21:13:44.000000000,2015-01-06 21:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}]","[{'number': 1, 'created': '2015-01-06 12:47:26.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/ea1e2c005d1d1b56dfe26257fa2adc1b7849f1ee', 'message': 'Remove nonexistent directory ""tests"" from pep8 scanning\n\nDirectory ""tests"" defined in run_tests.sh doesn\'t exist:\nhttps://github.com/openstack/python-manilaclient/blob/92bea7acb92ec17ef3184b9266a7886175e4eda5/run_tests.sh#L121\n\nChange-Id: Iff86e4486e732c5c245cc9695aa76e032d9b7552\n'}]",0,145216,ea1e2c005d1d1b56dfe26257fa2adc1b7849f1ee,8,6,1,14232,,,0,"Remove nonexistent directory ""tests"" from pep8 scanning

Directory ""tests"" defined in run_tests.sh doesn't exist:
https://github.com/openstack/python-manilaclient/blob/92bea7acb92ec17ef3184b9266a7886175e4eda5/run_tests.sh#L121

Change-Id: Iff86e4486e732c5c245cc9695aa76e032d9b7552
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/16/145216/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,ea1e2c005d1d1b56dfe26257fa2adc1b7849f1ee,," srcfiles=""manilaclient"""," srcfiles=""manilaclient tests""",1,1
openstack%2Fsahara~master~I196ff7e331235b16b430bbe0b4afe1f4d9915a63,openstack/sahara,master,I196ff7e331235b16b430bbe0b4afe1f4d9915a63,Fixed pep8 after oslo update (01/06/2015),MERGED,2015-01-06 18:01:43.000000000,2015-01-06 21:13:11.000000000,2015-01-06 21:13:10.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-06 18:01:43.000000000', 'files': ['etc/sahara/sahara.conf.sample'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e556f3331be94ae0ec14db0144a2238a4a7a1321', 'message': 'Fixed pep8 after oslo update (01/06/2015)\n\nChange-Id: I196ff7e331235b16b430bbe0b4afe1f4d9915a63\n'}]",0,145285,e556f3331be94ae0ec14db0144a2238a4a7a1321,12,6,1,8411,,,0,"Fixed pep8 after oslo update (01/06/2015)

Change-Id: I196ff7e331235b16b430bbe0b4afe1f4d9915a63
",git fetch https://review.opendev.org/openstack/sahara refs/changes/85/145285/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/sahara/sahara.conf.sample'],1,e556f3331be94ae0ec14db0144a2238a4a7a1321,,"# Auto-delete queues in AMQP. (boolean value) #amqp_auto_delete = false # Size of RPC connection pool. (integer value) #rpc_conn_pool_size = 30# Qpid HA cluster host:port pairs. (list value) #qpid_hosts = $qpid_hostname:$qpid_port # Username for Qpid connection. (string value) #qpid_username = # Password for Qpid connection. (string value) #qpid_password =# Seconds between connection keepalive heartbeats. (integer value) #qpid_heartbeat = 60 # Transport to use, either 'tcp' or 'ssl'. (string value) #qpid_protocol = tcp # The number of prefetched messages held by receiver. (integer value) #qpid_receiver_capacity = 1 # SSL version to use (valid only if SSL enabled). valid values are # TLSv1 and SSLv23. SSLv2 and SSLv3 may be available on some # distributions. (string value) #kombu_ssl_version = # SSL key file (valid only if SSL enabled). (string value) #kombu_ssl_keyfile = # SSL cert file (valid only if SSL enabled). (string value) #kombu_ssl_certfile = # SSL certification authority file (valid only if SSL enabled). # (string value) #kombu_ssl_ca_certs = # How long to wait before reconnecting in response to an AMQP consumer # cancel notification. (floating point value) #kombu_reconnect_delay = 1.0# RabbitMQ HA cluster host:port pairs. (list value) #rabbit_hosts = $rabbit_host:$rabbit_port# The RabbitMQ password. (string value) #rabbit_password = guest # The RabbitMQ login method. (string value) #rabbit_login_method = AMQPLAIN # How frequently to retry connecting with RabbitMQ. (integer value) #rabbit_retry_interval = 1 # How long to backoff for between retries when connecting to RabbitMQ. # (integer value) #rabbit_retry_backoff = 2 # Maximum number of RabbitMQ connection retries. Default is 0 # (infinite retry count). (integer value) #rabbit_max_retries = 0 # Use HA queues in RabbitMQ (x-ha-policy: all). If you change this # option, you must wipe the RabbitMQ database. (boolean value) #rabbit_ha_queues = false # Deprecated, use rpc_backend=kombu+memory or rpc_backend=fake # (boolean value) #fake_rabbit = false# Number of ZeroMQ contexts, defaults to 1. (integer value) #rpc_zmq_contexts = 1 # Directory for holding IPC sockets. (string value) #rpc_zmq_ipc_dir = /var/run/openstack # Name of this node. Must be a valid hostname, FQDN, or IP address. # Must match ""host"" option, if running Nova. (string value) #rpc_zmq_host = localhost # Seconds to wait before a cast expires (TTL). Only supported by # impl_zmq. (integer value) #rpc_cast_timeout = 30 # Heartbeat frequency. (integer value) #matchmaker_heartbeat_freq = 300 # Heartbeat time-to-live. (integer value) #matchmaker_heartbeat_ttl = 600 # Size of RPC greenthread pool. (integer value) #rpc_thread_pool_size = 64 # Driver or drivers to handle sending notifications. (multi valued) #notification_driver = # AMQP topic used for OpenStack notifications. (list value) # Deprecated group/name - [rpc_notifier2]/topics #notification_topics = notifications # Seconds to wait for a response from a call. (integer value) #rpc_response_timeout = 60 # The messaging driver to use, defaults to rabbit. Other drivers # include qpid and zmq. (string value) #rpc_backend = rabbit # The default exchange under which topics are scoped. May be # overridden by an exchange name specified in the transport_url # option. (string value) #control_exchange = openstack # Port that will be used to listen on. (integer value) #port = 8386 # Log request/response exchange details: environ, headers and bodies. # (boolean value) #log_exchange = false# If set to True, Sahara will use floating IPs to communicate with # instances. To make sure that all instances have floating IPs # assigned in Nova Network set ""auto_assign_floating_ip=True"" in # nova.conf. If Neutron is used for networking, make sure that all # Node Groups have ""floating_ip_pool"" parameter defined. (boolean#use_floating_ips = true# Use Neutron Networking (False indicates the use of Nova networking). # (boolean value) #use_neutron = false # Use network namespaces for communication (only valid to use in # conjunction with use_neutron=True). (boolean value) #use_namespaces = false # Use rootwrap facility to allow non-root users to run the sahara-all # server instance and access private network IPs (only valid to use in # conjunction with use_namespaces=True) (boolean value) #use_rootwrap = false # Rootwrap command to leverage. Use in conjunction with # use_rootwrap=True (string value) #rootwrap_command = sudo sahara-rootwrap /etc/sahara/rootwrap.conf # Driver to use for database access. (string value) #db_driver = sahara.db # The JSON file that defines policies. (string value) #policy_file = policy.json# Print debugging output (set logging level to DEBUG instead of # default WARNING level). (boolean value) #debug = false # Print more verbose output (set logging level to INFO instead of # default WARNING level). (boolean value) #verbose = false # Log output to standard error. (boolean value) #use_stderr = true # Format string to use for log messages with context. (string value) #logging_context_format_string = %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s # Format string to use for log messages without context. (string # value) #logging_default_format_string = %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s # Data to append to log format when level is DEBUG. (string value) #logging_debug_format_suffix = %(funcName)s %(pathname)s:%(lineno)d # Prefix each line of exception output with this format. (string # value) #logging_exception_prefix = %(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s # List of logger=LEVEL pairs. (list value) #default_log_levels = amqplib=WARN,qpid.messaging=INFO,stevedore=INFO,eventlet.wsgi.server=WARN,sqlalchemy=WARN,boto=WARN,suds=INFO,keystone=INFO,paramiko=WARN,requests=WARN,iso8601=WARN# Enables or disables fatal status of deprecations. (boolean value) #fatal_deprecations = false # The format for an instance that is passed with the log message. # (string value) #instance_format = ""[instance: %(uuid)s] "" # The format for an instance UUID that is passed with the log message. # (string value) #instance_uuid_format = ""[instance: %(uuid)s] "" # The name of a logging configuration file. This file is appended to # any existing logging configuration files. For details about logging # configuration files, see the Python logging module documentation. # (string value) # Deprecated group/name - [DEFAULT]/log_config #log_config_append = <None> # DEPRECATED. A logging.Formatter log message format string which may # use any of the available logging.LogRecord attributes. This option # is deprecated. Please use logging_context_format_string and # logging_default_format_string instead. (string value) #log_format = <None> # Format string for %%(asctime)s in log records. Default: %(default)s # . (string value) #log_date_format = %Y-%m-%d %H:%M:%S # (Optional) Name of log file to output to. If no default is set, # logging will go to stdout. (string value) # Deprecated group/name - [DEFAULT]/logfile #log_file = <None> # (Optional) The base directory used for relative --log-file paths. # (string value) # Deprecated group/name - [DEFAULT]/logdir #log_dir = <None># Syslog facility to receive log lines. (string value) #syslog_log_facility = LOG_USER # Some periodic tasks can be run in a separate process. Should we run # them here? (boolean value) #run_external_periodic_tasks = true # List of plugins to be loaded. Sahara preserves the order of the list # when returning it. (list value) #plugins = vanilla,hdp,spark # Enables data locality for hadoop cluster. Also # enables data locality for Swift used by hadoop. If # enabled, 'compute_topology' and 'swift_topology' # configuration parameters should point to OpenStack and Swift # topology correspondingly. (boolean value) #enable_data_locality = false # Enables four-level topology for data locality. Works # only if corresponding plugin supports such mode. (boolean value) #enable_hypervisor_awareness = true # File with nova compute topology. It should contain # mapping between nova computes and racks. File # format: compute1 /rack1 compute2 # /rack2 compute3 /rack2 (string value) #compute_topology_file = etc/sahara/compute.topology # File with Swift topology. It should contain mapping # between Swift nodes and racks. File format: # node1 /rack1 node2 /rack2 node3 # /rack2 (string value) #swift_topology_file = etc/sahara/swift.topology # Notification level for outgoing notifications (string value) #notification_level = INFO # Notification publisher_id for outgoing notifications (string value) #notification_publisher_id = <None> # Enables sending notifications to Ceilometer (boolean value) #enable_notifications = false # Version of the Cinder API to use. (integer value) #cinder_api_version = 2 # Enables Sahara to use Keystone API v3. If that flag is disabled, # per-job clusters will not be terminated automatically. (boolean # value) #use_identity_api_v3 = true # Maximum number of remote operations that will be running at the same # time. Note that each remote operation requires its own process to # run. (integer value) #global_remote_threshold = 100 # The same as global_remote_threshold, but for a single cluster. # (integer value) #cluster_remote_threshold = 70 # Proxy command used to connect to instances. If set, this command # should open a netcat socket, that Sahara will use for SSH and HTTP # connections. Use {host} and {port} to describe the destination. # Other available keywords: {tenant_id}, {network_id}, {router_id}. # (string value) #proxy_command =# Region name used to get services endpoints. (string value) #os_region_name = <None># A method for Sahara to execute commands on VMs. (string value) #remote = ssh # Minimal ""lifetime"" in seconds for a transient cluster. Cluster is # guaranteed to be ""alive"" within this time period. (integer value) #min_transient_cluster_active_time = 30 # Timeout for detaching volumes from instance (in seconds). (integer # value) #detach_volume_timeout = 300 # Enables Sahara to use a domain for creating temporary proxy users to # access Swift. If this is enabled a domain must be created for Sahara # to use. (boolean value) #use_domain_for_proxy_users = false # The file name to use with SQLite. (string value) # Deprecated group/name - [DEFAULT]/sqlite_db #sqlite_db = oslo.sqlite # If True, SQLite uses synchronous mode. (boolean value) # Deprecated group/name - [DEFAULT]/sqlite_synchronous #sqlite_synchronous = true # The SQLAlchemy connection string to use to connect to the slave # database. (string value) #slave_connection = <None> # The SQL mode to be used for MySQL sessions. This option, including # the default, overrides any server-set SQL mode. To use whatever SQL # mode is set by the server configuration, set this to no value. # Example: mysql_sql_mode= (string value) #mysql_sql_mode = TRADITIONAL# Minimum number of SQL connections to keep open in a pool. (integer# Deprecated group/name - [DEFAULT]/sql_min_pool_size # Deprecated group/name - [DATABASE]/sql_min_pool_size #min_pool_size = 1# If set, use this value for max_overflow with SQLAlchemy. (integer # value) # Deprecated group/name - [DEFAULT]/sql_max_overflow # Deprecated group/name - [DATABASE]/sqlalchemy_max_overflow #max_overflow = <None> # Verbosity of SQL debugging information: 0=None, 100=Everything. # (integer value) # Deprecated group/name - [DEFAULT]/sql_connection_debug #connection_debug = 0 # Add Python stack traces to SQL as comment strings. (boolean value) # Deprecated group/name - [DEFAULT]/sql_connection_trace #connection_trace = false # If set, use this value for pool_timeout with SQLAlchemy. (integer # value) # Deprecated group/name - [DATABASE]/sqlalchemy_pool_timeout #pool_timeout = <None># Seconds between database connection retries. (integer value) #db_retry_interval = 1 # If True, increases the interval between database connection retries # up to db_max_retry_interval. (boolean value) #db_inc_retry_interval = true # If db_inc_retry_interval is set, the maximum seconds between # database connection retries. (integer value) #db_max_retry_interval = 10 # Maximum database connection retries before error is raised. Set to # -1 to specify an infinite retry count. (integer value) #db_max_retries = 20 # Env key for the swift cache. (string value) #cache = <None> # Required if identity server requires client certificate (string#certfile = <None># A PEM encoded Certificate Authority to use when verifying HTTPs # connections. Defaults to system CAs. (string value) #cafile = <None> # Verify HTTPS connections. (boolean value) #insecure = false # Directory used to cache files related to PKI tokens. (string value) #signing_dir = <None> # Optionally specify a list of memcached server(s) to use for caching. # If left undefined, tokens will instead be cached in-process. (list # value) # Deprecated group/name - [DEFAULT]/memcache_servers #memcached_servers = <None> # In order to prevent excessive effort spent validating tokens, the # middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. (integer # value) #token_cache_time = 300 # Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may # significantly reduce performance. (integer value) #revocation_cache_time = 10 # (Optional) If defined, indicate whether token data should be # authenticated or authenticated and encrypted. Acceptable values are # MAC or ENCRYPT. If MAC, token data is authenticated (with HMAC) in # the cache. If ENCRYPT, token data is encrypted and authenticated in # the cache. If the value is not one of these options or empty, # auth_token will raise an exception on initialization. (string value) #memcache_security_strategy = <None> # (Optional, mandatory if memcache_security_strategy is defined) This # string is used for key derivation. (string value) #memcache_secret_key = <None># (Optional) Number of seconds that an operation will wait to get a # memcache client connection from the pool. (integer value) #memcache_pool_conn_get_timeout = 10# (Optional) Indicate whether to set the X-Service-Catalog header. If # False, middleware will not ask for service catalog on token # validation and will not set the X-Service-Catalog header. (boolean#include_service_catalog = true # Used to control the use and type of token binding. Can be set to: # ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to # the server and ignore it if not. ""strict"" like ""permissive"" but if # the bind type is unknown the token will be rejected. ""required"" any # form of token binding is needed to be allowed. Finally the name of a # binding method that must be present in tokens. (string value) #enforce_token_bind = permissive # If true, the revocation list will be checked for cached tokens. This # requires that PKI tokens are configured on the identity server. # (boolean value) #check_revocations_for_cached = false # Hash algorithms to use for hashing PKI tokens. This may be a single # algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, # so put the preferred one first for performance. The result of the # first hash will be stored in the cache. This will typically be set # to multiple values only while migrating from a less secure algorithm # to a more secure one. Once all the old tokens are expired this # option should be set to a single value for better performance. (list#hash_algorithms = md5 # Prefix to prepend at the beginning of the path. Deprecated, use # identity_uri. (string value) #auth_admin_prefix = # Host providing the admin Identity API endpoint. Deprecated, use # identity_uri. (string value) #auth_host = 127.0.0.1 # Port of the admin Identity API endpoint. Deprecated, use # identity_uri. (integer value) #auth_port = 35357 # Protocol of the admin Identity API endpoint (http or https). # Deprecated, use identity_uri. (string value) #auth_protocol = https # Complete admin Identity API endpoint. This should specify the # unversioned root endpoint e.g. https://localhost:35357/ (string # value) #identity_uri = <None> # This option is deprecated and may be removed in a future release. # Single shared secret with the Keystone configuration used for # bootstrapping a Keystone installation, or otherwise bypassing the # normal authentication process. This option should not be used, use # `admin_user` and `admin_password` instead. (string value) #admin_token = <None> # Service username. (string value) #admin_user = <None> # Service user password. (string value) #admin_password = <None> # Service tenant name. (string value) #admin_tenant_name = admin# Password for Redis server (optional). (string value) #password = <None> # address prefix used when sending to a specific server (string value) # Deprecated group/name - [amqp1]/server_request_prefix #server_request_prefix = exclusive# Name for the AMQP container (string value) # Deprecated group/name - [amqp1]/container_name #container_name = <None> # Debug: dump AMQP frames to stdout (boolean value) # Deprecated group/name - [amqp1]/trace #trace = false# Accept clients using either SSL or plain TCP (boolean value) # Deprecated group/name - [amqp1]/allow_insecure_clients #allow_insecure_clients = false","# Auto-delete queues in AMQP. (boolean value) #amqp_auto_delete = false # The default exchange under which topics are scoped. May be # overridden by an exchange name specified in the transport_url # option. (string value) #control_exchange = openstack # Deprecated, use rpc_backend=kombu+memory or rpc_backend=fake # (boolean value) #fake_rabbit = false # How long to wait before reconnecting in response to an AMQP consumer # cancel notification. (floating point value) #kombu_reconnect_delay = 1.0 # SSL certification authority file (valid only if SSL enabled). # (string value) #kombu_ssl_ca_certs = # SSL cert file (valid only if SSL enabled). (string value) #kombu_ssl_certfile = # SSL key file (valid only if SSL enabled). (string value) #kombu_ssl_keyfile = # SSL version to use (valid only if SSL enabled). valid values are # TLSv1 and SSLv23. SSLv2 and SSLv3 may be available on some # distributions. (string value) #kombu_ssl_version = # Heartbeat frequency. (integer value) #matchmaker_heartbeat_freq = 300 # Heartbeat time-to-live. (integer value) #matchmaker_heartbeat_ttl = 600 # Driver or drivers to handle sending notifications. (multi valued) #notification_driver = # AMQP topic used for OpenStack notifications. (list value) # Deprecated group/name - [rpc_notifier2]/topics #notification_topics = notifications # Seconds between connection keepalive heartbeats. (integer value) #qpid_heartbeat = 60# Qpid HA cluster host:port pairs. (list value) #qpid_hosts = $qpid_hostname:$qpid_port # Password for Qpid connection. (string value) #qpid_password = # Transport to use, either 'tcp' or 'ssl'. (string value) #qpid_protocol = tcp # The number of prefetched messages held by receiver. (integer value) #qpid_receiver_capacity = 1# Username for Qpid connection. (string value) #qpid_username = # Use HA queues in RabbitMQ (x-ha-policy: all). If you change this # option, you must wipe the RabbitMQ database. (boolean value) #rabbit_ha_queues = false# RabbitMQ HA cluster host:port pairs. (list value) #rabbit_hosts = $rabbit_host:$rabbit_port # The RabbitMQ login method. (string value) #rabbit_login_method = AMQPLAIN # Maximum number of RabbitMQ connection retries. Default is 0 # (infinite retry count). (integer value) #rabbit_max_retries = 0 # The RabbitMQ password. (string value) #rabbit_password = guest # How long to backoff for between retries when connecting to RabbitMQ. # (integer value) #rabbit_retry_backoff = 2 # How frequently to retry connecting with RabbitMQ. (integer value) #rabbit_retry_interval = 1# The messaging driver to use, defaults to rabbit. Other drivers # include qpid and zmq. (string value) #rpc_backend = rabbit # Seconds to wait before a cast expires (TTL). Only supported by # impl_zmq. (integer value) #rpc_cast_timeout = 30 # Size of RPC connection pool. (integer value) #rpc_conn_pool_size = 30 # Seconds to wait for a response from a call. (integer value) #rpc_response_timeout = 60 # Size of RPC greenthread pool. (integer value) #rpc_thread_pool_size = 64# Number of ZeroMQ contexts, defaults to 1. (integer value) #rpc_zmq_contexts = 1 # Name of this node. Must be a valid hostname, FQDN, or IP address. # Must match ""host"" option, if running Nova. (string value) #rpc_zmq_host = localhost # Directory for holding IPC sockets. (string value) #rpc_zmq_ipc_dir = /var/run/openstack # Version of the Cinder API to use. (integer value) #cinder_api_version = 2 # The same as global_remote_threshold, but for a single cluster. # (integer value) #cluster_remote_threshold = 70 # File with nova compute topology. It should contain # mapping between nova computes and racks. File # format: compute1 /rack1 compute2 # /rack2 compute3 /rack2 (string value) #compute_topology_file = etc/sahara/compute.topology # Driver to use for database access. (string value) #db_driver = sahara.db # Print debugging output (set logging level to DEBUG instead of # default WARNING level). (boolean value) #debug = false # List of logger=LEVEL pairs. (list value) #default_log_levels = amqplib=WARN,qpid.messaging=INFO,stevedore=INFO,eventlet.wsgi.server=WARN,sqlalchemy=WARN,boto=WARN,suds=INFO,keystone=INFO,paramiko=WARN,requests=WARN,iso8601=WARN # Enables data locality for hadoop cluster. Also # enables data locality for Swift used by hadoop. If # enabled, 'compute_topology' and 'swift_topology' # configuration parameters should point to OpenStack and Swift # topology correspondingly. (boolean value) #enable_data_locality = false # Enables four-level topology for data locality. Works # only if corresponding plugin supports such mode. (boolean value) #enable_hypervisor_awareness = true # Enables sending notifications to Ceilometer (boolean value) #enable_notifications = false # Enables or disables fatal status of deprecations. (boolean value) #fatal_deprecations = false # Maximum number of remote operations that will be running at the same # time. Note that each remote operation requires its own process to # run. (integer value) #global_remote_threshold = 100 # The format for an instance that is passed with the log message. # (string value) #instance_format = ""[instance: %(uuid)s] "" # The format for an instance UUID that is passed with the log message. # (string value) #instance_uuid_format = ""[instance: %(uuid)s] ""# The name of a logging configuration file. This file is appended to # any existing logging configuration files. For details about logging # configuration files, see the Python logging module documentation. # (string value) # Deprecated group/name - [DEFAULT]/log_config #log_config_append = <None> # Format string for %%(asctime)s in log records. Default: %(default)s # . (string value) #log_date_format = %Y-%m-%d %H:%M:%S # (Optional) The base directory used for relative --log-file paths. # (string value) # Deprecated group/name - [DEFAULT]/logdir #log_dir = <None> # Log request/response exchange details: environ, headers and bodies. # (boolean value) #log_exchange = false # (Optional) Name of log file to output to. If no default is set, # logging will go to stdout. (string value) # Deprecated group/name - [DEFAULT]/logfile #log_file = <None> # DEPRECATED. A logging.Formatter log message format string which may # use any of the available logging.LogRecord attributes. This option # is deprecated. Please use logging_context_format_string and # logging_default_format_string instead. (string value) #log_format = <None> # Format string to use for log messages with context. (string value) #logging_context_format_string = %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s # Data to append to log format when level is DEBUG. (string value) #logging_debug_format_suffix = %(funcName)s %(pathname)s:%(lineno)d # Format string to use for log messages without context. (string#logging_default_format_string = %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s # Prefix each line of exception output with this format. (string # value) #logging_exception_prefix = %(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s# Notification level for outgoing notifications (string value) #notification_level = INFO # Notification publisher_id for outgoing notifications (string value) #notification_publisher_id = <None> # List of plugins to be loaded. Sahara preserves the order of the list # when returning it. (list value) #plugins = vanilla,hdp,spark# The JSON file that defines policies. (string value) #policy_file = policy.json # Port that will be used to listen on. (integer value) #port = 8386 # Proxy command used to connect to instances. If set, this command # should open a netcat socket, that Sahara will use for SSH and HTTP # connections. Use {host} and {port} to describe the destination. # Other available keywords: {tenant_id}, {network_id}, {router_id}. # (string value) #proxy_command =# Rootwrap command to leverage. Use in conjunction with # use_rootwrap=True (string value) #rootwrap_command = sudo sahara-rootwrap /etc/sahara/rootwrap.conf # Some periodic tasks can be run in a separate process. Should we run # them here? (boolean value) #run_external_periodic_tasks = true # File with Swift topology. It should contain mapping # between Swift nodes and racks. File format: # node1 /rack1 node2 /rack2 node3 # /rack2 (string value) #swift_topology_file = etc/sahara/swift.topology # Syslog facility to receive log lines. (string value) #syslog_log_facility = LOG_USER # If set to True, Sahara will use floating IPs to communicate with # instances. To make sure that all instances have floating IPs # assigned in Nova Network set ""auto_assign_floating_ip=True"" in # nova.conf. If Neutron is used for networking, make sure that all # Node Groups have ""floating_ip_pool"" parameter defined. (boolean # value) #use_floating_ips = true # Enables Sahara to use Keystone API v3. If that flag is disabled, # per-job clusters will not be terminated automatically. (boolean # value) #use_identity_api_v3 = true # Use network namespaces for communication (only valid to use in # conjunction with use_neutron=True). (boolean value) #use_namespaces = false # Use Neutron Networking (False indicates the use of Nova networking). # (boolean value) #use_neutron = false # Use rootwrap facility to allow non-root users to run the sahara-all # server instance and access private network IPs (only valid to use in # conjunction with use_namespaces=True) (boolean value) #use_rootwrap = false # Log output to standard error. (boolean value) #use_stderr = true# Print more verbose output (set logging level to INFO instead of # default WARNING level). (boolean value) #verbose = false# Timeout for detaching volumes from instance (in seconds). (integer # value) #detach_volume_timeout = 300# Minimal ""lifetime"" in seconds for a transient cluster. Cluster is # guaranteed to be ""alive"" within this time period. (integer value) #min_transient_cluster_active_time = 30 # Region name used to get services endpoints. (string value) #os_region_name = <None> # A method for Sahara to execute commands on VMs. (string value) #remote = ssh # Enables Sahara to use a domain for creating temporary proxy users to # access Swift. If this is enabled a domain must be created for Sahara # to use. (boolean value) #use_domain_for_proxy_users = false # Verbosity of SQL debugging information: 0=None, 100=Everything. # (integer value) # Deprecated group/name - [DEFAULT]/sql_connection_debug #connection_debug = 0 # Add Python stack traces to SQL as comment strings. (boolean value) # Deprecated group/name - [DEFAULT]/sql_connection_trace #connection_trace = false # If True, increases the interval between database connection retries # up to db_max_retry_interval. (boolean value) #db_inc_retry_interval = true # Maximum database connection retries before error is raised. Set to # -1 to specify an infinite retry count. (integer value) #db_max_retries = 20 # If db_inc_retry_interval is set, the maximum seconds between # database connection retries. (integer value) #db_max_retry_interval = 10 # Seconds between database connection retries. (integer value) #db_retry_interval = 1# If set, use this value for max_overflow with SQLAlchemy. (integer# Deprecated group/name - [DEFAULT]/sql_max_overflow # Deprecated group/name - [DATABASE]/sqlalchemy_max_overflow #max_overflow = <None># Minimum number of SQL connections to keep open in a pool. (integer # value) # Deprecated group/name - [DEFAULT]/sql_min_pool_size # Deprecated group/name - [DATABASE]/sql_min_pool_size #min_pool_size = 1 # The SQL mode to be used for MySQL sessions. This option, including # the default, overrides any server-set SQL mode. To use whatever SQL # mode is set by the server configuration, set this to no value. # Example: mysql_sql_mode= (string value) #mysql_sql_mode = TRADITIONAL # If set, use this value for pool_timeout with SQLAlchemy. (integer # value) # Deprecated group/name - [DATABASE]/sqlalchemy_pool_timeout #pool_timeout = <None> # The SQLAlchemy connection string to use to connect to the slave # database. (string value) #slave_connection = <None> # The file name to use with SQLite. (string value) # Deprecated group/name - [DEFAULT]/sqlite_db #sqlite_db = oslo.sqlite # If True, SQLite uses synchronous mode. (boolean value) # Deprecated group/name - [DEFAULT]/sqlite_synchronous #sqlite_synchronous = true# Service user password. (string value) #admin_password = <None> # Service tenant name. (string value) #admin_tenant_name = admin # This option is deprecated and may be removed in a future release. # Single shared secret with the Keystone configuration used for # bootstrapping a Keystone installation, or otherwise bypassing the # normal authentication process. This option should not be used, use # `admin_user` and `admin_password` instead. (string value) #admin_token = <None> # Service username. (string value) #admin_user = <None> # Prefix to prepend at the beginning of the path. Deprecated, use # identity_uri. (string value) #auth_admin_prefix = # Host providing the admin Identity API endpoint. Deprecated, use # identity_uri. (string value) #auth_host = 127.0.0.1 # Port of the admin Identity API endpoint. Deprecated, use # identity_uri. (integer value) #auth_port = 35357 # Protocol of the admin Identity API endpoint (http or https). # Deprecated, use identity_uri. (string value) #auth_protocol = https # Env key for the swift cache. (string value) #cache = <None> # A PEM encoded Certificate Authority to use when verifying HTTPs # connections. Defaults to system CAs. (string value) #cafile = <None> # Required if identity server requires client certificate (string # value) #certfile = <None> # If true, the revocation list will be checked for cached tokens. This # requires that PKI tokens are configured on the identity server. # (boolean value) #check_revocations_for_cached = false # Used to control the use and type of token binding. Can be set to: # ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to # the server and ignore it if not. ""strict"" like ""permissive"" but if # the bind type is unknown the token will be rejected. ""required"" any # form of token binding is needed to be allowed. Finally the name of a # binding method that must be present in tokens. (string value) #enforce_token_bind = permissive # Hash algorithms to use for hashing PKI tokens. This may be a single # algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, # so put the preferred one first for performance. The result of the # first hash will be stored in the cache. This will typically be set # to multiple values only while migrating from a less secure algorithm # to a more secure one. Once all the old tokens are expired this # option should be set to a single value for better performance. (list # value) #hash_algorithms = md5 # Complete admin Identity API endpoint. This should specify the # unversioned root endpoint e.g. https://localhost:35357/ (string # value) #identity_uri = <None> # (Optional) Indicate whether to set the X-Service-Catalog header. If # False, middleware will not ask for service catalog on token # validation and will not set the X-Service-Catalog header. (boolean#include_service_catalog = true # Verify HTTPS connections. (boolean value) #insecure = false# (Optional) Number of seconds that an operation will wait to get a # memcache client connection from the pool. (integer value) #memcache_pool_conn_get_timeout = 10# (Optional, mandatory if memcache_security_strategy is defined) This # string is used for key derivation. (string value) #memcache_secret_key = <None> # (Optional) If defined, indicate whether token data should be # authenticated or authenticated and encrypted. Acceptable values are # MAC or ENCRYPT. If MAC, token data is authenticated (with HMAC) in # the cache. If ENCRYPT, token data is encrypted and authenticated in # the cache. If the value is not one of these options or empty, # auth_token will raise an exception on initialization. (string value) #memcache_security_strategy = <None># Optionally specify a list of memcached server(s) to use for caching. # If left undefined, tokens will instead be cached in-process. (list# Deprecated group/name - [DEFAULT]/memcache_servers #memcached_servers = <None> # Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may # significantly reduce performance. (integer value) #revocation_cache_time = 10 # Directory used to cache files related to PKI tokens. (string value) #signing_dir = <None> # In order to prevent excessive effort spent validating tokens, the # middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. (integer#token_cache_time = 300# Password for Redis server (optional). (string value) #password = <None> # Accept clients using either SSL or plain TCP (boolean value) # Deprecated group/name - [amqp1]/allow_insecure_clients #allow_insecure_clients = false# Name for the AMQP container (string value) # Deprecated group/name - [amqp1]/container_name #container_name = <None> # address prefix used when sending to a specific server (string value) # Deprecated group/name - [amqp1]/server_request_prefix #server_request_prefix = exclusive# Debug: dump AMQP frames to stdout (boolean value) # Deprecated group/name - [amqp1]/trace #trace = false",447,447
openstack%2Fneutron-vpnaas~master~I2986a9724396920071a3a22121e5b5a5a08ed059,openstack/neutron-vpnaas,master,I2986a9724396920071a3a22121e5b5a5a08ed059,Backward compatibility for vpnaas,MERGED,2014-12-17 16:25:43.000000000,2015-01-06 21:13:04.000000000,2015-01-06 21:13:04.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6659}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-17 16:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/6a8bce92cc9194af59209d92d5c38bb2392c9e6b', 'message': 'Backward compatibility for vpnaas\n\nVpnaas driver class is changed to one from this repo in case it attempts\nto be loaded from neutron repo.\n\nThis change depends on I76af175c4387326a4e5ff95c2f15d8b866dedab3\n\nChange-Id: I2986a9724396920071a3a22121e5b5a5a08ed059\nCloses-Bug: 1401895\n'}, {'number': 2, 'created': '2014-12-17 16:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/2b8744cb31c190c91ed79e3acb20599be99fdb74', 'message': 'Backward compatibility for vpnaas\n\nVpnaas driver class is changed to one from this repo in case it attempts\nto be loaded from neutron repo.\n\nThis change depends on I76af175c4387326a4e5ff95c2f15d8b866dedab3\n\nChange-Id: I2986a9724396920071a3a22121e5b5a5a08ed059\nCloses-Bug: 1401895\n'}, {'number': 3, 'created': '2015-01-05 09:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b23d8ac30eca33eec3cc2ddd9e46b0ee1c2651ea', 'message': 'Backward compatibility for vpnaas\n\nVpnaas driver class is changed to one from this repo in case it attempts\nto be loaded from neutron repo.\n\nThis change depends on I76af175c4387326a4e5ff95c2f15d8b866dedab3\n\nChange-Id: I2986a9724396920071a3a22121e5b5a5a08ed059\nCloses-Bug: 1401895\n'}, {'number': 4, 'created': '2015-01-06 12:48:31.000000000', 'files': ['neutron_vpnaas/services/vpn/vpn_service.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/30fe57e4a883bc64b42f858dbf02d3d79ee84018', 'message': 'Backward compatibility for vpnaas\n\nVpnaas driver class is changed to one from this repo in case it attempts\nto be loaded from neutron repo.\n\nThis change depends on I76af175c4387326a4e5ff95c2f15d8b866dedab3\n\nChange-Id: I2986a9724396920071a3a22121e5b5a5a08ed059\nCloses-Bug: 1401895\n'}]",14,142484,30fe57e4a883bc64b42f858dbf02d3d79ee84018,45,6,4,8655,,,0,"Backward compatibility for vpnaas

Vpnaas driver class is changed to one from this repo in case it attempts
to be loaded from neutron repo.

This change depends on I76af175c4387326a4e5ff95c2f15d8b866dedab3

Change-Id: I2986a9724396920071a3a22121e5b5a5a08ed059
Closes-Bug: 1401895
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/84/142484/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/services/vpn/agent.py', 'setup.cfg']",2,6a8bce92cc9194af59209d92d5c38bb2392c9e6b,bug/1401895,device_drivers = neutron_vpnaas.services.vpn.device_drivers.ipsec.OpenSwanDriver = neutron.services.vpn.device_drivers.ipsec:OpenSwanDriver,,7,0
openstack%2Fheat~stable%2Fjuno~I259249659c8b5dc846432f8e08985b148b30d682,openstack/heat,stable/juno,I259249659c8b5dc846432f8e08985b148b30d682,Add Dimensions Default in AWS_CloudWatch_Alarm.yaml,MERGED,2014-12-17 15:58:51.000000000,2015-01-06 21:09:32.000000000,2015-01-06 21:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 8289}, {'_account_id': 13278}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-17 15:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2caff68e46d1e3d69eb2a985dc2d91f1dadf9d8c', 'message': ""Add Dimensions Default in AWS_CloudWatch_Alarm.yaml\n\nRelying on [1], property Dimensions isn't required, but\nthis template has no Default value for Dimensions\n(thereby making it required). This patch fixes that omission.\nBesides that, parameters have wrong parsing, because if\nparameter with type 'CommaDelimitedList' has default\nvalue '', parameter's parsing result would be [u''] instead\nof []. this is wrong, so this patch fixes it.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html\n\nChange-Id: I259249659c8b5dc846432f8e08985b148b30d682\nCloses-bug: #1402015\n(cherry picked from commit 13435988905df7de2d804ba2201ec08f13f61de6)\n""}, {'number': 2, 'created': '2014-12-24 14:08:04.000000000', 'files': ['heat/tests/test_parameters.py', 'etc/heat/templates/AWS_CloudWatch_Alarm.yaml', 'heat/engine/parameters.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/aabd3d8fc7b301b2f9a92311f89274c64b1afa11', 'message': ""Add Dimensions Default in AWS_CloudWatch_Alarm.yaml\n\nRelying on [1], property Dimensions isn't required, but\nthis template has no Default value for Dimensions\n(thereby making it required). This patch fixes that omission.\nBesides that, parameters have wrong parsing, because if\nparameter with type 'CommaDelimitedList' has default\nvalue '', parameter's parsing result would be [u''] instead\nof []. this is wrong, so this patch fixes it.\n\n[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html\n\nChange-Id: I259249659c8b5dc846432f8e08985b148b30d682\nCloses-bug: #1402015\n(cherry picked from commit 13435988905df7de2d804ba2201ec08f13f61de6)\n""}]",0,142473,aabd3d8fc7b301b2f9a92311f89274c64b1afa11,17,10,2,13009,,,0,"Add Dimensions Default in AWS_CloudWatch_Alarm.yaml

Relying on [1], property Dimensions isn't required, but
this template has no Default value for Dimensions
(thereby making it required). This patch fixes that omission.
Besides that, parameters have wrong parsing, because if
parameter with type 'CommaDelimitedList' has default
value '', parameter's parsing result would be [u''] instead
of []. this is wrong, so this patch fixes it.

[1] http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html

Change-Id: I259249659c8b5dc846432f8e08985b148b30d682
Closes-bug: #1402015
(cherry picked from commit 13435988905df7de2d804ba2201ec08f13f61de6)
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/142473/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_parameters.py', 'etc/heat/templates/AWS_CloudWatch_Alarm.yaml', 'heat/engine/parameters.py']",3,2caff68e46d1e3d69eb2a985dc2d91f1dadf9d8c,add-dmns-dflt, if value == '': return [],,5,3
openstack%2Fhorizon~master~I4e16dc03f615369177c9f1d1323cf364339b2803,openstack/horizon,master,I4e16dc03f615369177c9f1d1323cf364339b2803,Using get_url_current_page wrapper method,MERGED,2014-12-21 10:14:44.000000000,2015-01-06 21:09:21.000000000,2015-01-06 21:09:20.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 8648}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 12355}, {'_account_id': 12609}, {'_account_id': 12954}]","[{'number': 1, 'created': '2014-12-21 10:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7ceceaf13eafb81793fcd2581511c086ae004f64', 'message': ""Using get_url_current_page wrapper method\n\nIn continuation to Imran's fix, I modified\ntest_dashboard_help_redirection so it will use pageobject's wrapper\nmethod get_url_current_page instead of calling the selenium driver\ndirectly.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I4e16dc03f615369177c9f1d1323cf364339b2803\n""}, {'number': 2, 'created': '2014-12-28 09:00:04.000000000', 'files': ['openstack_dashboard/test/integration_tests/tests/test_dashboard_help_redirection.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f1b4357a9cc9b7c8bc98cdc470b48a6bd146c9d2', 'message': ""Using get_url_current_page wrapper method\n\nIn continuation to Imran's fix, I modified\ntest_dashboard_help_redirection so it will use pageobject's wrapper\nmethod get_url_current_page instead of calling the selenium driver\ndirectly.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I4e16dc03f615369177c9f1d1323cf364339b2803\n""}]",0,143295,f1b4357a9cc9b7c8bc98cdc470b48a6bd146c9d2,14,9,2,8577,,,0,"Using get_url_current_page wrapper method

In continuation to Imran's fix, I modified
test_dashboard_help_redirection so it will use pageobject's wrapper
method get_url_current_page instead of calling the selenium driver
directly.

Partially implements blueprint: selenium-integration-testing

Change-Id: I4e16dc03f615369177c9f1d1323cf364339b2803
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/143295/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/tests/test_dashboard_help_redirection.py'],1,7ceceaf13eafb81793fcd2581511c086ae004f64,bp/selenium-integration-testing," self.home_pg.get_url_current_page(), self.home_pg.close_window()"," self.driver.current_url, self.driver.close()",2,2
openstack%2Fhorizon~master~If07e2a0e9931e1798d81035eac93b7722a3b308d,openstack/horizon,master,If07e2a0e9931e1798d81035eac93b7722a3b308d,Add fix for incorrect display email in inline editing input,MERGED,2014-09-18 16:04:00.000000000,2015-01-06 21:08:48.000000000,2015-01-06 21:08:47.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6637}, {'_account_id': 8040}, {'_account_id': 8054}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10068}, {'_account_id': 10295}, {'_account_id': 11880}, {'_account_id': 11941}, {'_account_id': 12355}, {'_account_id': 13325}, {'_account_id': 14151}]","[{'number': 1, 'created': '2014-09-18 16:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/30bc71ded4a02922a271c1336b7a9613050dfce3', 'message': 'Add fix for incorrect display email in inline editing input\nBecause of server sends users email as <input id = ""email__someid"" name=""email__someid"" type=""text"" value=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/> with wrong double quotes in the \'value\' attribute in input, inline edit input does not display correctly.\nThis fix replaces the double quotes in input value to single quotes and leaves only users email in input (without <a href> link).\n\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 2, 'created': '2014-09-19 09:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cf464f297f79cdf4a41a6e9e2f7681fc923a3251', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid"" name=""email__someid"" type=""text"" value=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>\nwith wrong double quotes in the \'value\' attribute in input, inline edit input does not display correctly.\nThis fix replaces the double quotes in input value to single quotes using javascript and leaves only users email in input (without <a href> link).\n\nCloses-Bug: #1371510.\n\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 3, 'created': '2014-09-19 15:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/27efacce784ce4f9b4fc443cd50902c3fd2b810d', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid"" name=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>\nwith wrong double quotes in the \'value\' attribute in input, inline edit input does not display correctly.\nThis fix replaces the double quotes in input value to single quotes using javascript and leaves only users email\nin input (without <a href> link).\n\nCloses-Bug: #1371510\n\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 4, 'created': '2014-09-19 16:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/46624ae6b377e46d6c67c89e52348cca0fffaa3e', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>\nwith wrong double quotes in the \'value\' attribute in input, inline edit input\ndoes not display correctly. This fix replaces the double quotes in input value\nto single quotes using javascript and leaves only users email\nin input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 5, 'created': '2014-09-24 13:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fa02c56712e6c9e901e571b0a68a29bb96114d76', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>\nwith wrong double quotes in the \'value\' attribute in input, inline edit input\ndoes not display correctly. This fix replaces the double quotes in input value\nto single quotes using javascript and leaves only users email\nin input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 6, 'created': '2014-09-26 10:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2dfedb83a812d828c94f0508f3c427034627506e', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>,\ninline edit input contents redundant html code.\nThis fix leaves only users email in input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 7, 'created': '2014-09-26 14:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/93604e9a2ef984de673ce18e199b719db1ddeaa0', 'message': 'Add fix for incorrect display email in inline editing input\nBecause of server sends users email as <input id = ""email__someid"" name=""email__someid"" type=""text"" value=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/> with wrong double quotes in the \'value\' attribute in input, inline edit input does not display correctly.\nThis fix replaces the double quotes in input value to single quotes and leaves only users email in input (without <a href> link).\n\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 8, 'created': '2014-09-26 14:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d116e7d5d3ac41061e6ece43b4bef9eb1c668309', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>,\ninline edit input contents redundant html code.\nThis fix leaves only users email in input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 9, 'created': '2014-09-30 14:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/378188424a896002633a49e0f6c6e4f29e0cf748', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>,\ninline edit input contents redundant html code.\nThis fix leaves only users email in input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 10, 'created': '2014-11-19 17:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1e9ccc7c174857b9bcfcf512d2b5a09b5a12da12', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>,\ninline edit input contents redundant html code.\nThis fix leaves only users email in input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}, {'number': 11, 'created': '2014-11-27 09:26:20.000000000', 'files': ['horizon/tables/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ce3b2b4180af3b91f3e17ec1fa11693c03d2dd70', 'message': 'Add fix for incorrect display email in inline editing input\n\nBecause of server sends users email as <input id = ""email__someid""\nname=""email__someid"" type=""text""\nvalue=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>,\ninline edit input contents redundant html code.\nThis fix leaves only users email in input (without <a href> link).\n\nCloses-Bug: #1371510\nChange-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d\n'}]",9,122454,ce3b2b4180af3b91f3e17ec1fa11693c03d2dd70,55,15,11,13325,,,0,"Add fix for incorrect display email in inline editing input

Because of server sends users email as <input id = ""email__someid""
name=""email__someid"" type=""text""
value=""<a href=""mailto: user@mail.com "">user@mail.com</a>""/>,
inline edit input contents redundant html code.
This fix leaves only users email in input (without <a href> link).

Closes-Bug: #1371510
Change-Id: If07e2a0e9931e1798d81035eac93b7722a3b308d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/54/122454/11 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.tables_inline_edit.js'],1,30bc71ded4a02922a271c1336b7a9613050dfce3,bug/1371510," var replaced_data = data.replace(/href=""([^""]+)""/g, ""href='$1'""); var td_element = $(replaced_data); var email_regEx = /(\w+([-+.']\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*)/; var emailsArray = data.match(email_regEx); if (emailsArray) { td_element.find('input').val(emailsArray[0]); }", var td_element = $(data);,7,1
openstack%2Fmonasca-agent~master~I55db0d59d783da19cffa53e7c34eff91f55db840,openstack/monasca-agent,master,I55db0d59d783da19cffa53e7c34eff91f55db840,Various fixes and code cleanup related to monasca statsd,MERGED,2014-12-22 23:26:54.000000000,2015-01-06 21:06:18.000000000,2015-01-06 21:06:18.000000000,"[{'_account_id': 3}, {'_account_id': 12108}]","[{'number': 1, 'created': '2014-12-22 23:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/b66c3db58b8ac1c9b2d2e50287c75d408f5a91e6', 'message': 'Various fixes and code cleanup related to monasca statsd\n\nFixed duplicate metrics being created for each statsd counter.\nFixed accidental setting of device_name for statsd counters.\nStandardized to 20 second report times.\n\nChange-Id: I55db0d59d783da19cffa53e7c34eff91f55db840\n'}, {'number': 2, 'created': '2015-01-06 15:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/bffce6032a3ab13412ad90ddb477360da6098384', 'message': 'Various fixes and code cleanup related to monasca statsd\n\nFixed duplicate metrics being created for each statsd counter.\nFixed accidental setting of device_name for statsd counters.\nStandardized to 20 second report times.\n\nChange-Id: I55db0d59d783da19cffa53e7c34eff91f55db840\n'}, {'number': 3, 'created': '2015-01-06 16:30:17.000000000', 'files': ['monasca_agent/collector/daemon.py', 'monasca_agent/common/aggregator.py', 'monasca_agent/statsd/reporter.py', 'monasca_agent/common/metrics.py', 'monasca_agent/common/config.py', 'monasca_agent/forwarder/daemon.py', 'monasca_agent/statsd/daemon.py', 'monasca_agent/forwarder/api/mon.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/82a870928b1cfd05312c72c388bda5975a49c840', 'message': 'Various fixes and code cleanup related to monasca statsd\n\nFixed duplicate metrics being created for each statsd counter.\nFixed accidental setting of device_name for statsd counters.\nStandardized to 20 second report times.\n\nChange-Id: I55db0d59d783da19cffa53e7c34eff91f55db840\n'}]",0,143561,82a870928b1cfd05312c72c388bda5975a49c840,11,2,3,11094,,,0,"Various fixes and code cleanup related to monasca statsd

Fixed duplicate metrics being created for each statsd counter.
Fixed accidental setting of device_name for statsd counters.
Standardized to 20 second report times.

Change-Id: I55db0d59d783da19cffa53e7c34eff91f55db840
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/61/143561/2 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_agent/collector/daemon.py', 'monasca_agent/common/aggregator.py', 'monasca_agent/statsd/reporter.py', 'monasca_agent/common/metrics.py', 'monasca_agent/common/config.py', 'monasca_agent/forwarder/daemon.py', 'monasca_agent/statsd/daemon.py', 'monasca_agent/forwarder/api/mon.py']",8,b66c3db58b8ac1c9b2d2e50287c75d408f5a91e6,feature/combine,,import requests ,60,127
openstack%2Fnova~stable%2Fjuno~Id7096153c649645777374ea6786221e431fe3d8e,openstack/nova,stable/juno,Id7096153c649645777374ea6786221e431fe3d8e,Pin eventlet to <0.16,ABANDONED,2015-01-05 17:07:32.000000000,2015-01-06 20:57:25.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-01-05 17:07:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/f35f3eceb6429704749d568f122f8ba08add4951', 'message': 'Pin eventlet to <0.16\n\nIn 0.16.0 the deprecated eventlet.util module has been removed, causing\nerrors in nova-manage.\n\nChange-Id: Id7096153c649645777374ea6786221e431fe3d8e\nCloses-Bug: 1407685\n'}]",0,145023,f35f3eceb6429704749d568f122f8ba08add4951,8,6,1,13252,,,0,"Pin eventlet to <0.16

In 0.16.0 the deprecated eventlet.util module has been removed, causing
errors in nova-manage.

Change-Id: Id7096153c649645777374ea6786221e431fe3d8e
Closes-Bug: 1407685
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/145023/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f35f3eceb6429704749d568f122f8ba08add4951,bug/1407685,"eventlet>=0.15.1,<0.16",eventlet>=0.15.1,1,1
openstack%2Fpycadf~master~I60820cc15d05b3c07215c2000d806b4a0aa42889,openstack/pycadf,master,I60820cc15d05b3c07215c2000d806b4a0aa42889,deprecate audit middleware,MERGED,2014-12-02 15:00:38.000000000,2015-01-06 20:55:51.000000000,2015-01-06 20:55:51.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-12-02 15:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/133453fd62c7b0714781f32082c30382b882c9c6', 'message': 'deprecate audit middleware\n\nwe should deprecate audit middleware as soon as possible so we can\nremove it from library.\n\nChange-Id: I60820cc15d05b3c07215c2000d806b4a0aa42889\nCloses-Bug: #1398411\n'}, {'number': 2, 'created': '2014-12-09 18:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/3b434d658d8bc22387c1fecdc1a1646031081ebc', 'message': 'deprecate audit middleware\n\nwe should deprecate audit middleware as soon as possible so we can\nremove it from library.\n\nChange-Id: I60820cc15d05b3c07215c2000d806b4a0aa42889\nCloses-Bug: #1398411\n'}, {'number': 3, 'created': '2014-12-09 19:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/fb25fdf36eb133ebab475eddc741833c4ccf9547', 'message': 'deprecate audit middleware\n\nwe should deprecate audit middleware as soon as possible so we can\nremove it from library. switch oslo.messaging to test as it is only\na requirement for middleware and not pycadf in general.\n\nChange-Id: I60820cc15d05b3c07215c2000d806b4a0aa42889\nCloses-Bug: #1398411\n'}, {'number': 4, 'created': '2014-12-10 17:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/ad27947f5d3e02548390353fa0d6af79927596aa', 'message': 'deprecate audit middleware\n\nwe should deprecate audit middleware as soon as possible so we can\nremove it from library. switch oslo.messaging to test as it is only\na requirement for middleware and not pycadf in general.\n\nChange-Id: I60820cc15d05b3c07215c2000d806b4a0aa42889\nCloses-Bug: #1398411\n'}, {'number': 5, 'created': '2014-12-15 16:55:38.000000000', 'files': ['pycadf/middleware/audit.py', 'requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/3d18b9c8ed269b489015c71ef6691ac4357f639e', 'message': 'deprecate audit middleware\n\nwe should deprecate audit middleware as soon as possible so we can\nremove it from library. switch oslo.messaging to test as it is only\na requirement for middleware and not pycadf in general.\n\nChange-Id: I60820cc15d05b3c07215c2000d806b4a0aa42889\nCloses-Bug: #1398411\n'}]",3,138386,3d18b9c8ed269b489015c71ef6691ac4357f639e,26,5,5,6537,,,0,"deprecate audit middleware

we should deprecate audit middleware as soon as possible so we can
remove it from library. switch oslo.messaging to test as it is only
a requirement for middleware and not pycadf in general.

Change-Id: I60820cc15d05b3c07215c2000d806b4a0aa42889
Closes-Bug: #1398411
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/86/138386/5 && git format-patch -1 --stdout FETCH_HEAD,"['pycadf/middleware/audit.py', 'pycadf/middleware/notifier.py', 'requirements.txt', 'test-requirements.txt']",4,133453fd62c7b0714781f32082c30382b882c9c6,bug/1398411,oslo.messaging>=1.4.0,,9,1
openstack%2Foslo.messaging~master~I556b112371bec2ec29cea4dc254bb3f9c6d2c07a,openstack/oslo.messaging,master,I556b112371bec2ec29cea4dc254bb3f9c6d2c07a,Add an optional executor callback to dispatcher,MERGED,2014-11-23 20:57:57.000000000,2015-01-06 20:54:26.000000000,2015-01-06 20:54:25.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 8415}, {'_account_id': 9107}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-11-23 20:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d50d1a8969cd14384cbbc17da279e1fbbc4278da', 'message': 'Add an optional executor callback to dispatcher\n\nThe callback will be used in the new aiogreen executor to support\ntrollius coroutines.\n\nThe change adds an unit test for the new callback.\n\nChange-Id: I556b112371bec2ec29cea4dc254bb3f9c6d2c07a\n'}, {'number': 2, 'created': '2014-11-23 21:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/587804bca60112987e9bcc6321a8549b9271b449', 'message': 'Add an optional executor callback to dispatcher\n\nThe callback will be used in the new aiogreen executor to support\ntrollius coroutines.\n\nThe change includes an unit test.\n\nChange-Id: I556b112371bec2ec29cea4dc254bb3f9c6d2c07a\n'}, {'number': 3, 'created': '2014-12-03 00:50:27.000000000', 'files': ['oslo/messaging/rpc/dispatcher.py', 'tests/notify/test_dispatcher.py', 'oslo/messaging/notify/dispatcher.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/0844037fadb2ab78ca23b6c0a55b0700608033af', 'message': 'Add an optional executor callback to dispatcher\n\nThe callback will be used in the new aiogreen executor to support\ntrollius coroutines.\n\nThe change includes an unit test.\n\nChange-Id: I556b112371bec2ec29cea4dc254bb3f9c6d2c07a\n'}]",3,136652,0844037fadb2ab78ca23b6c0a55b0700608033af,25,11,3,9107,,,0,"Add an optional executor callback to dispatcher

The callback will be used in the new aiogreen executor to support
trollius coroutines.

The change includes an unit test.

Change-Id: I556b112371bec2ec29cea4dc254bb3f9c6d2c07a
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/52/136652/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/rpc/dispatcher.py', 'tests/notify/test_dispatcher.py', 'oslo/messaging/notify/dispatcher.py']",3,d50d1a8969cd14384cbbc17da279e1fbbc4278da,bp/greenio-executor," def __call__(self, incoming, executor_callback=None): self._dispatch_and_handle_error(incoming, executor_callback)) def _dispatch_and_handle_error(self, incoming, executor_callback): return self._dispatch(incoming.ctxt, incoming.message, executor_callback) def _dispatch(self, ctxt, message, executor_callback=None): if executor_callback: ret = executor_callback(callback, ctxt, publisher_id, event_type, payload, metadata) else: ret = callback(ctxt, publisher_id, event_type, payload, metadata)"," def __call__(self, incoming): self._dispatch_and_handle_error(incoming)) def _dispatch_and_handle_error(self, incoming): return self._dispatch(incoming.ctxt, incoming.message) def _dispatch(self, ctxt, message): ret = callback(ctxt, publisher_id, event_type, payload, metadata)",49,16
openstack%2Fswift~master~I50077e8a0a840f64b197fecf266f0c8fcd605804,openstack/swift,master,I50077e8a0a840f64b197fecf266f0c8fcd605804,Imported Translations from Transifex,MERGED,2015-01-06 06:14:05.000000000,2015-01-06 20:44:31.000000000,2015-01-06 20:44:30.000000000,"[{'_account_id': 3}, {'_account_id': 7847}]","[{'number': 1, 'created': '2015-01-06 06:14:05.000000000', 'files': ['swift/locale/zh_CN/LC_MESSAGES/swift.po', 'swift/locale/swift.pot'], 'web_link': 'https://opendev.org/openstack/swift/commit/199bf8fce45cfedfc060a00ede8f603110872c14', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I50077e8a0a840f64b197fecf266f0c8fcd605804\n'}]",0,145138,199bf8fce45cfedfc060a00ede8f603110872c14,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I50077e8a0a840f64b197fecf266f0c8fcd605804
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/145138/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/locale/zh_CN/LC_MESSAGES/swift.po', 'swift/locale/swift.pot']",2,199bf8fce45cfedfc060a00ede8f603110872c14,transifex/translations,"# Copyright (C) 2015 ORGANIZATION# FIRST AUTHOR <EMAIL@ADDRESS>, 2015.""Project-Id-Version: swift 2.2.1.post18\n""""POT-Creation-Date: 2015-01-06 06:13+0000\n""#: swift/account/reaper.py:132 swift/common/utils.py:1964#: swift/common/db_replicator.py:142#: swift/common/db_replicator.py:192#: swift/common/db_replicator.py:198#: swift/common/db_replicator.py:199#: swift/common/db_replicator.py:230#: swift/common/db_replicator.py:292#: swift/common/db_replicator.py:449 swift/common/db_replicator.py:673#: swift/common/db_replicator.py:452#: swift/common/db_replicator.py:483#: swift/common/db_replicator.py:485#: swift/common/db_replicator.py:513#: swift/common/db_replicator.py:539#: swift/common/db_replicator.py:548#: swift/common/db_replicator.py:557#: swift/common/db_replicator.py:562#: swift/common/db_replicator.py:575#: swift/common/request_helpers.py:387 msgid ""ERROR: An error occurred while retrieving segments"" msgstr """" #: swift/common/utils.py:322#: swift/common/utils.py:496#: swift/common/utils.py:923#: swift/common/utils.py:925 swift/common/utils.py:928#: swift/common/utils.py:1162#: swift/common/utils.py:1164#: swift/common/utils.py:1166#: swift/common/utils.py:1468#: swift/common/utils.py:1523#: swift/common/utils.py:1528#: swift/common/utils.py:1825#: swift/common/utils.py:1831#: swift/common/utils.py:2185#: swift/common/utils.py:2190#: swift/common/utils.py:2194#: swift/common/utils.py:2203#: swift/common/utils.py:2207#: swift/common/utils.py:2210#: swift/common/utils.py:2215#: swift/common/utils.py:2407#: swift/common/middleware/cname_lookup.py:144#: swift/common/middleware/cname_lookup.py:156#: swift/common/middleware/x_profile/html_viewer.py:433#: swift/common/middleware/x_profile/html_viewer.py:444#: swift/common/middleware/x_profile/html_viewer.py:465#: swift/obj/diskfile.py:676#: swift/obj/diskfile.py:858#: swift/obj/diskfile.py:1157#: swift/obj/diskfile.py:1438#: swift/proxy/server.py:451 swift/proxy/server.py:469#: swift/proxy/server.py:539#: swift/proxy/controllers/obj.py:191 swift/proxy/controllers/obj.py:321 #: swift/proxy/controllers/obj.py:361 swift/proxy/controllers/obj.py:379 #: swift/proxy/controllers/obj.py:507#: swift/proxy/controllers/base.py:778 swift/proxy/controllers/base.py:1048#: swift/proxy/controllers/obj.py:353 swift/proxy/controllers/obj.py:393#: swift/proxy/controllers/base.py:1039 #, python-format msgid ""ERROR %(status)d Trying to %(method)s %(path)sFrom Container Server"" msgstr """" #: swift/proxy/controllers/base.py:1151#: swift/proxy/controllers/container.py:91 swift/proxy/controllers/obj.py:117#: swift/proxy/controllers/obj.py:322#: swift/proxy/controllers/obj.py:356 #, python-format msgid ""ERROR %(status)d Expect: 100-continue From Object Server"" msgstr """" #: swift/proxy/controllers/obj.py:362#: swift/proxy/controllers/obj.py:380#: swift/proxy/controllers/obj.py:397#: swift/proxy/controllers/obj.py:673#: swift/proxy/controllers/obj.py:679#: swift/proxy/controllers/obj.py:710#: swift/proxy/controllers/obj.py:721#: swift/proxy/controllers/obj.py:726#: swift/proxy/controllers/obj.py:731#: swift/proxy/controllers/obj.py:740#: swift/proxy/controllers/obj.py:744","# Copyright (C) 2014 ORGANIZATION# FIRST AUTHOR <EMAIL@ADDRESS>, 2014.""Project-Id-Version: swift 2.2.0.76.g2cf24e9\n""""POT-Creation-Date: 2014-11-26 06:13+0000\n""#: swift/account/reaper.py:132 swift/common/utils.py:1963#: swift/common/db_replicator.py:140#: swift/common/db_replicator.py:190#: swift/common/db_replicator.py:196#: swift/common/db_replicator.py:197#: swift/common/db_replicator.py:228#: swift/common/db_replicator.py:290#: swift/common/db_replicator.py:447 swift/common/db_replicator.py:671#: swift/common/db_replicator.py:450#: swift/common/db_replicator.py:481#: swift/common/db_replicator.py:483#: swift/common/db_replicator.py:511#: swift/common/db_replicator.py:537#: swift/common/db_replicator.py:546#: swift/common/db_replicator.py:555#: swift/common/db_replicator.py:560#: swift/common/db_replicator.py:573#: swift/common/utils.py:324#: swift/common/utils.py:498#: swift/common/utils.py:922#: swift/common/utils.py:924 swift/common/utils.py:927#: swift/common/utils.py:1161#: swift/common/utils.py:1163#: swift/common/utils.py:1165#: swift/common/utils.py:1467#: swift/common/utils.py:1522#: swift/common/utils.py:1527#: swift/common/utils.py:1824#: swift/common/utils.py:1830#: swift/common/utils.py:2184#: swift/common/utils.py:2189#: swift/common/utils.py:2193#: swift/common/utils.py:2202#: swift/common/utils.py:2206#: swift/common/utils.py:2209#: swift/common/utils.py:2214#: swift/common/utils.py:2406#: swift/common/middleware/cname_lookup.py:146#: swift/common/middleware/cname_lookup.py:158#: swift/common/middleware/x_profile/html_viewer.py:434#: swift/common/middleware/x_profile/html_viewer.py:445#: swift/common/middleware/x_profile/html_viewer.py:466#: swift/obj/diskfile.py:678#: swift/obj/diskfile.py:860#: swift/obj/diskfile.py:1156#: swift/obj/diskfile.py:1437#: swift/proxy/server.py:451 swift/proxy/server.py:466#: swift/proxy/server.py:535#: swift/proxy/controllers/obj.py:212 swift/proxy/controllers/obj.py:342 #: swift/proxy/controllers/obj.py:377 swift/proxy/controllers/obj.py:395 #: swift/proxy/controllers/obj.py:520#: swift/proxy/controllers/base.py:778 swift/proxy/controllers/base.py:1040#: swift/proxy/controllers/obj.py:374#: swift/proxy/controllers/base.py:1143#: swift/proxy/controllers/container.py:91 swift/proxy/controllers/obj.py:116#: swift/proxy/controllers/obj.py:343#: swift/proxy/controllers/obj.py:378#: swift/proxy/controllers/obj.py:396#: swift/proxy/controllers/obj.py:410#: swift/proxy/controllers/obj.py:684#: swift/proxy/controllers/obj.py:690#: swift/proxy/controllers/obj.py:721#: swift/proxy/controllers/obj.py:732#: swift/proxy/controllers/obj.py:737#: swift/proxy/controllers/obj.py:742#: swift/proxy/controllers/obj.py:751#: swift/proxy/controllers/obj.py:755",169,141
openstack%2Ftrove~master~Ibd886f3cb4a45250c7c434b3af711abee266671c,openstack/trove,master,Ibd886f3cb4a45250c7c434b3af711abee266671c,Integration with oslo.messaging library,MERGED,2014-05-20 21:56:50.000000000,2015-01-06 20:40:10.000000000,2015-01-06 18:04:05.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6159}, {'_account_id': 6162}, {'_account_id': 6413}, {'_account_id': 6549}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9746}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-05-20 21:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/203d0d797ae5ecea1ec1e8bdd1a3ca3cfa258666', 'message': 'Updates RPC API to use oslo.messaging for versions\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: rpc-versioning\n'}, {'number': 2, 'created': '2014-05-20 22:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5236db963cb8667122f7b630168bc4608beabd5b', 'message': 'Updates RPC API to use oslo.messaging for versions\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 3, 'created': '2014-05-28 23:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8f726be72605d0702eb068fe6d05aba430689e13', 'message': 'Updates RPC API to use oslo.messaging for versions\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 4, 'created': '2014-06-10 17:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/72c9bc9d833974bbc7dab156847cb043d2170b0b', 'message': 'Updates RPC API to use oslo.messaging for versions\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 5, 'created': '2014-06-11 19:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/90a4008216579bfe90b2505e0924e2baa7172f39', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 6, 'created': '2014-06-11 20:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7525f73e09a3e66e827151b6f4a1de31d6d15e86', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 7, 'created': '2014-06-11 21:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/518269e17763e9f934ec1d910b5bb918184150e3', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 8, 'created': '2014-06-12 22:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3ae55c6e8ede32d187d1658099b56e671c938b4f', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 9, 'created': '2014-06-12 22:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/68a2bd5b0f7119a77ed60bbb4ae2a72369f02ddf', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 10, 'created': '2014-06-23 20:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/63a33fbb8864077eb61bf60deb6ecc08728e9a65', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 11, 'created': '2014-07-01 21:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7cd71e7f3d38aec48c7a27ce123217bfe55bb8a2', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 12, 'created': '2014-07-07 21:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/88041bff5b71f1c07ba07a2da7260481d92e0a06', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 13, 'created': '2014-07-07 22:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/eed75970f891d95f3848271fbe8474de6b373d8f', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 14, 'created': '2014-07-11 22:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cc1b55fb7b9e8711930892e795fe77cfb8651640', 'message': 'Updates RPC API to use oslo.messaging\n\nAdded timeout to TroveContext\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 15, 'created': '2014-07-11 22:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cc0b98669ee6634c857efbaf2b0d3d0421b92476', 'message': 'Updates RPC API to use oslo.messaging\n\nAdded timeout to TroveContext\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 16, 'created': '2014-07-11 23:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f74a00b965ea81c1b204fd73b03bd50c9b8dffe2', 'message': 'Updates RPC API to use oslo.messaging\n\nAdded timeout to TroveContext\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 17, 'created': '2014-07-11 23:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2c734ff7bedc72fd762349ea924889af6d246809', 'message': 'Updates RPC API to use oslo.messaging\n\nAdded timeout to TroveContext\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 18, 'created': '2014-07-12 03:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fe407227814837375ab1e14765eef22ca2a41ede', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 19, 'created': '2014-08-21 17:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bd8dfbebd8bd6e5f242148cee4a6c074eb3602d8', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 20, 'created': '2014-09-07 08:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/244a1d97348b628c376e21ca0249f418bc8b2545', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 21, 'created': '2014-09-07 15:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/34f90c2a31a7780aeb15a07de162f9cfd25c0431', 'message': '[WIP] Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 22, 'created': '2014-09-07 19:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/09572399bcace5c7ce60ff8a2d30b2335cf04bfb', 'message': '[WIP] Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 23, 'created': '2014-09-08 16:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/83c9f7014abbaa14885077be58b42811289d65a7', 'message': '[WIP] Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 24, 'created': '2014-09-08 21:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b2991e963bd886bbd2c53226a345405302d258aa', 'message': '[WIP] Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 25, 'created': '2014-09-10 19:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a98f200e8431021b7903fa64c9780bad76b435d8', 'message': '[WIP] Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 26, 'created': '2014-09-10 22:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d454420ef8013c1db0b33eaf8ad0cd99637ec7e2', 'message': '[WIP] Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 27, 'created': '2014-09-11 08:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1cf7bc7951ad35911471c31f693600cbc78253f3', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 28, 'created': '2014-09-13 15:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2f83c1caf4be5acd1ea2a2c24281de3a3ab88328', 'message': 'Updates RPC API to use oslo.messaging\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 29, 'created': '2014-09-13 22:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ddbfbaed15a28a819c1f3e0d24793c4f39c2a4c6', 'message': 'Port RPC API to use oslo.messaging library\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 30, 'created': '2014-09-13 23:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/21a7a030861633d56f97d64f5611f849a79e6612', 'message': 'Port RPC API to use oslo.messaging library\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 31, 'created': '2014-09-14 20:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/72b0a75c49df537832dc63354e1b92a762206bf8', 'message': 'Port RPC API to use oslo.messaging library\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 32, 'created': '2014-09-14 20:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7040e4b2fa2a6253fd0659e16522d1ee248affed', 'message': 'Port RPC API to use oslo.messaging library\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 33, 'created': '2014-09-14 21:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/89ba1067c1fd42746b877067e45f563a564c2ea1', 'message': 'Port RPC API to use oslo.messaging library\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 34, 'created': '2014-09-15 09:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8ef923489bf403365154d4da7b4df9663042dedc', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 35, 'created': '2014-09-15 11:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1c816c508dc13c97c681b1c8148f9155e6a678d2', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 36, 'created': '2014-09-15 14:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e78b84db053303c448d6f2527334d29a99baf77d', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 37, 'created': '2014-09-16 07:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/deab4fec4a7c822fedc24dc7dbcedde6717ae15b', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 38, 'created': '2014-09-17 08:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4b02987e72c3824d7e1ba50c22fdf32b3034a1f8', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 39, 'created': '2014-09-17 13:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f3349383e06d6455cce26afc360608f92d42634a', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 40, 'created': '2014-09-30 12:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4007e3b876678f2aa622de5efbfeec370f53a8b4', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 41, 'created': '2014-10-12 21:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/da350e3819ed69499cd5054195fe2c4a7d8768e7', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 42, 'created': '2014-10-13 12:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/972988bff116e9e89a68d32e12697549a4c6f0a5', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 43, 'created': '2014-11-02 21:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/041c07c8f9b536ab4905b64376e8ffcb371e07d3', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 44, 'created': '2014-11-16 16:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/44fa17827b7d9f54b936cfb428d7037b0792c12b', 'message': ""Port RPC API to use oslo.messaging library\n\nNote: 'delete_queue' from guestagent is not supported anymore.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n""}, {'number': 45, 'created': '2014-11-23 14:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/93b7c7d5648784772873280a370b853601ac3400', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 46, 'created': '2014-11-24 22:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9ccc68f0b6dc37fc7fc785afbcb5028483e47c1a', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 47, 'created': '2014-12-05 10:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d82618f446b0c84829a90213afdf7ce79c43e7cf', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 48, 'created': '2014-12-07 09:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3f34b554b48ac74bff0cc6c567acd993a7c90580', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 49, 'created': '2014-12-08 15:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9c8ca0cff3fda9f41cc84507923b58f881211052', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 50, 'created': '2014-12-08 17:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c082e99df400071fb372b312c8d9b2214cc9407e', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 51, 'created': '2014-12-09 09:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2378240f7f61c13c949ede9b07fae1ab610ad6ab', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 52, 'created': '2014-12-09 12:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bfb52fcf407ff38d0c7a0c6c22ab8a2d655db5f0', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 53, 'created': '2014-12-11 07:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f565dab5e1cddd95cba60516833a78a6de1dd051', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 54, 'created': '2014-12-11 16:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fbffd9208e5dab199653851272ec9bb2447a03c3', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 55, 'created': '2014-12-14 09:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/35e5b040019b554ef588065de5210a8ce6c52fc7', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 56, 'created': '2014-12-18 18:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9d9ed37f553805565f5c2b8880d3fc83cdd6c2cc', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}, {'number': 57, 'created': '2015-01-06 07:16:42.000000000', 'files': ['trove/tests/api/instances_resize.py', 'trove/tests/fakes/guestagent.py', 'trove/openstack/common/notifier/rpc_notifier2.py', 'trove/openstack/common/rpc/dispatcher.py', 'trove/common/rpc/version.py', 'trove/common/rpc/impl_fake.py', 'trove/openstack/common/rpc/matchmaker_ring.py', 'trove/openstack/common/notifier/no_op_notifier.py', 'trove/openstack/common/notifier/test_notifier.py', 'trove/openstack/common/rpc/impl_qpid.py', 'trove/cmd/guest.py', 'trove/common/rpc/service.py', 'trove/tests/fakes/taskmanager.py', 'trove/cmd/fakemode.py', 'trove/openstack/common/notifier/api.py', 'trove/common/rpc/__init__.py', 'trove/taskmanager/manager.py', 'trove/openstack/common/rpc/impl_fake.py', 'trove/tests/util/usage.py', 'trove/common/context.py', 'trove/openstack/common/rpc/impl_kombu.py', 'trove/openstack/common/rpc/matchmaker_redis.py', 'trove/tests/unittests/instance/test_instance_models.py', 'trove/tests/unittests/taskmanager/test_models.py', 'etc/trove/trove-conductor.conf.sample', 'trove/rpc.py', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/taskmanager/api.py', 'trove/tests/unittests/mgmt/test_models.py', 'trove/taskmanager/models.py', 'trove/guestagent/api.py', 'trove/openstack/common/rpc/zmq_receiver.py', 'setup.cfg', 'trove/openstack/common/rpc/matchmaker.py', 'trove/tests/unittests/backup/test_backup_models.py', 'trove/tests/unittests/conductor/test_conf.py', 'trove/openstack/common/rpc/common.py', 'trove/instance/models.py', 'trove/openstack/common/notifier/rpc_notifier.py', 'etc/trove/trove.conf.test', 'trove/cmd/common.py', 'etc/trove/trove-guestagent.conf.sample', 'requirements.txt', 'trove/common/cfg.py', 'trove/openstack/common/rpc/securemessage.py', 'etc/trove/trove-taskmanager.conf.sample', 'trove/cmd/taskmanager.py', 'trove/openstack/common/rpc/__init__.py', 'trove/conductor/manager.py', 'trove/openstack/common/service.py', 'trove/tests/unittests/taskmanager/test_api.py', 'trove/conductor/api.py', 'trove/openstack/common/rpc/amqp.py', 'trove/openstack/common/notifier/rabbit_notifier.py', 'etc/trove/trove.conf.sample', 'trove/openstack/common/rpc/serializer.py', 'trove/tests/unittests/cluster/test_cluster.py', 'trove/openstack/common/rpc/impl_zmq.py', 'trove/tests/unittests/backup/test_backupagent.py', 'run_tests.py', 'trove/openstack/common/notifier/log_notifier.py', 'trove/openstack/common/rpc/service.py', 'trove/extensions/mgmt/instances/models.py', 'trove/tests/unittests/guestagent/test_api.py', 'trove/openstack/common/rpc/proxy.py', 'trove/cmd/conductor.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/ea148d7dfe5405bb45417a7a37659c03710c871a', 'message': 'Integration with oslo.messaging library\n\nPort Trove to use oslo messaging library instead of obsolete messaging\ncode from oslo incubator.\n\nChange-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c\nImplements: blueprint rpc-versioning\n'}]",107,94484,ea148d7dfe5405bb45417a7a37659c03710c871a,341,19,57,6162,,,0,"Integration with oslo.messaging library

Port Trove to use oslo messaging library instead of obsolete messaging
code from oslo incubator.

Change-Id: Ibd886f3cb4a45250c7c434b3af711abee266671c
Implements: blueprint rpc-versioning
",git fetch https://review.opendev.org/openstack/trove refs/changes/84/94484/15 && git format-patch -1 --stdout FETCH_HEAD,"['trove/conductor/manager.py', 'trove/guestagent/datastore/mysql/manager.py', 'requirements.txt', 'trove/conductor/api.py', 'trove/rpc.py', 'trove/common/cfg.py', 'trove/taskmanager/api.py', 'trove/taskmanager/manager.py', 'trove/guestagent/api.py']",9,203d0d797ae5ecea1ec1e8bdd1a3ca3cfa258666,bp/rpc-versioning,"# Copyright (c) 2014 OpenStack Foundationfrom oslo import messagingfrom trove import rpcfrom trove.openstack.common import rpc as common_rpcfrom trove.openstack.common.rpc import common from trove.guestagent import models as agent_modelsRPC_API_VERSION = ""3.0"" class API(object): """"""API for interacting with the guest manager. API version history: 3.0 - Initial version. (We started keeping track at icehouse-3) 3.1 - ... 3.2 - ... """""" VERSION_ALIASES = { 'icehouse': '3.0' } super(API, self).__init__() target = messaging.Target(topic=self._get_routing_key(), version=RPC_API_VERSION) version_cap = self.VERSION_ALIASES.get(CONF.upgrade_levels.guestagent) self.client = self.get_client(target, version_cap) def get_client(self, target, version_cap, serializer=None): return rpc.get_client(target, version_cap=version_cap, serializer=serializer) def _call(self, method_name, timeout_sec, version, **kwargs): cctxt = self.client.prepare(version=version) result = cctxt.call(self.context, method_name, timeout=timeout_sec, **kwargs) def _cast(self, method_name, version, **kwargs): cctxt = self.client.prepare(version=version) cctxt.cast(self.context, method_name, topic=kwargs.get('topic'), version=kwargs.get('version'), **kwargs) # Note(esp): Uses the older rpc api to create a connection! conn = common_rpc.create_connection(new=True) self._cast(""change_passwords"", '1.0', users=users) self._cast(""update_attributes"", '1.0', username=username, hostname=hostname, user_attrs=user_attrs) self._cast(""create_user"", '1.0', users=users) return self._call(""get_user"", AGENT_LOW_TIMEOUT, '1.0', return self._call(""list_access"", AGENT_LOW_TIMEOUT, '1.0', return self._call(""grant_access"", AGENT_LOW_TIMEOUT, '1.0', return self._call(""revoke_access"", AGENT_LOW_TIMEOUT, '1.0', return self._call(""list_users"", AGENT_LOW_TIMEOUT, '1.0', limit=limit, self._cast(""delete_user"", '1.0', user=user) self._cast(""create_database"", '1.0', databases=databases) return self._call(""list_databases"", AGENT_LOW_TIMEOUT, '1.0', limit=limit, marker=marker, include_marker=include_marker) self._cast(""delete_database"", '1.0', database=database) return self._call(""enable_root"", AGENT_HIGH_TIMEOUT, '1.0') return self._call(""disable_root"", AGENT_LOW_TIMEOUT, '1.0') return self._call(""is_root_enabled"", AGENT_LOW_TIMEOUT, '1.0') return self._call(""get_hwinfo"", AGENT_LOW_TIMEOUT, '1.0') return self._call(""get_diagnostics"", AGENT_LOW_TIMEOUT, '1.0') self._call(""restart"", AGENT_HIGH_TIMEOUT, '1.0') self._call(""start_db_with_conf_changes"", AGENT_HIGH_TIMEOUT, '1.0', self._call(""reset_configuration"", AGENT_HIGH_TIMEOUT, '1.0', self._call(""stop_db"", AGENT_HIGH_TIMEOUT, '1.0', return self._call(""get_filesystem_stats"", AGENT_LOW_TIMEOUT, '1.0', self._call(""update_guest"", AGENT_HIGH_TIMEOUT, '1.0') self._cast(""create_backup"", '1.0', backup_info=backup_info) self._call(""mount_volume"", AGENT_LOW_TIMEOUT, '1.0', self._call(""unmount_volume"", AGENT_LOW_TIMEOUT, '1.0', self._call(""resize_fs"", AGENT_HIGH_TIMEOUT, '1.0', device_path=device_path, mount_point=mount_point) self._cast(""update_overrides"", '1.0', overrides=overrides, remove=remove) self._cast(""apply_overrides"", '1.0', overrides=overrides)","# Copyright (c) 2011 OpenStack Foundationfrom trove.guestagent import models as agent_models from trove.openstack.common import rpcfrom trove.openstack.common.rpc import proxy from trove.openstack.common.rpc import commonRPC_API_VERSION = ""1.0"" class API(proxy.RpcProxy): """"""API for interacting with the guest manager."""""" super(API, self).__init__(self._get_routing_key(), RPC_API_VERSION) def _call(self, method_name, timeout_sec, **kwargs): result = self.call(self.context, self.make_msg(method_name, **kwargs), timeout=timeout_sec) def _cast(self, method_name, **kwargs): self.cast(self.context, self.make_msg(method_name, **kwargs), topic=kwargs.get('topic'), version=kwargs.get('version')) conn = rpc.create_connection(new=True) self._cast(""change_passwords"", users=users) self._cast(""update_attributes"", username=username, hostname=hostname, user_attrs=user_attrs) self._cast(""create_user"", users=users) return self._call(""get_user"", AGENT_LOW_TIMEOUT, return self._call(""list_access"", AGENT_LOW_TIMEOUT, return self._call(""grant_access"", AGENT_LOW_TIMEOUT, return self._call(""revoke_access"", AGENT_LOW_TIMEOUT, return self._call(""list_users"", AGENT_LOW_TIMEOUT, limit=limit, self._cast(""delete_user"", user=user) self._cast(""create_database"", databases=databases) return self._call(""list_databases"", AGENT_LOW_TIMEOUT, limit=limit, marker=marker, include_marker=include_marker) self._cast(""delete_database"", database=database) return self._call(""enable_root"", AGENT_HIGH_TIMEOUT) return self._call(""disable_root"", AGENT_LOW_TIMEOUT) return self._call(""is_root_enabled"", AGENT_LOW_TIMEOUT) return self._call(""get_hwinfo"", AGENT_LOW_TIMEOUT) return self._call(""get_diagnostics"", AGENT_LOW_TIMEOUT) self._call(""restart"", AGENT_HIGH_TIMEOUT) self._call(""start_db_with_conf_changes"", AGENT_HIGH_TIMEOUT, self._call(""reset_configuration"", AGENT_HIGH_TIMEOUT, self._call(""stop_db"", AGENT_HIGH_TIMEOUT, return self._call(""get_filesystem_stats"", AGENT_LOW_TIMEOUT, self._call(""update_guest"", AGENT_HIGH_TIMEOUT) self._cast(""create_backup"", backup_info=backup_info) self._call(""mount_volume"", AGENT_LOW_TIMEOUT, self._call(""unmount_volume"", AGENT_LOW_TIMEOUT, self._call(""resize_fs"", AGENT_HIGH_TIMEOUT, device_path=device_path, mount_point=mount_point) self._cast(""update_overrides"", overrides=overrides, remove=remove) self._cast(""apply_overrides"", overrides=overrides)",380,131
openstack%2Ftempest-lib~master~I21fdc709d6e5bcbb2d2f611611efdf147d4c888e,openstack/tempest-lib,master,I21fdc709d6e5bcbb2d2f611611efdf147d4c888e,bring over fail only functionality from nova,MERGED,2015-01-05 20:23:28.000000000,2015-01-06 20:36:07.000000000,2015-01-06 20:36:07.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 6524}]","[{'number': 1, 'created': '2015-01-05 20:23:28.000000000', 'files': ['tempest_lib/cmd/subunit_trace.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/b73b9eb2a040a155e9f59d6da976fe2136532d44', 'message': 'bring over fail only functionality from nova\n\nThis brings over the failonly flag from nova, which was extremely\nuseful when hunting failing tests.\n\nChange-Id: I21fdc709d6e5bcbb2d2f611611efdf147d4c888e\n'}]",1,145045,b73b9eb2a040a155e9f59d6da976fe2136532d44,10,4,1,2750,,,0,"bring over fail only functionality from nova

This brings over the failonly flag from nova, which was extremely
useful when hunting failing tests.

Change-Id: I21fdc709d6e5bcbb2d2f611611efdf147d4c888e
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/45/145045/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest_lib/cmd/subunit_trace.py'],1,b73b9eb2a040a155e9f59d6da976fe2136532d44,failonly,"import osdef show_outcome(stream, test, print_failures=False, failonly=False): if status == 'fail': elif not failonly: if status == 'success': stream.write('{%s} %s [%s] ... ok\n' % ( worker, name, duration)) print_attachments(stream, test) elif status == 'skip': stream.write('{%s} %s ... SKIPPED: %s\n' % ( worker, name, test['details']['reason'].as_text())) else: stream.write('{%s} %s [%s] ... %s\n' % ( worker, name, duration, test['status'])) if not print_failures: print_attachments(stream, test, all_channels=True) parser.add_argument('--failonly', action='store_true', dest='failonly', help=""Don't print success items"", default=( os.environ.get('TRACE_FAILONLY', False) is not False)) print_failures=args.print_failures, failonly=args.failonly))","def show_outcome(stream, test, print_failures=False): if status == 'success': stream.write('{%s} %s [%s] ... ok\n' % ( worker, name, duration)) print_attachments(stream, test) elif status == 'fail': elif status == 'skip': stream.write('{%s} %s ... SKIPPED: %s\n' % ( worker, name, test['details']['reason'].as_text())) else: stream.write('{%s} %s [%s] ... %s\n' % ( worker, name, duration, test['status'])) if not print_failures: print_attachments(stream, test, all_channels=True) print_failures=args.print_failures))",23,15
openstack%2Fdevstack~master~Ib976c3a53344717b9e9551acd16d3402c48cbd64,openstack/devstack,master,Ib976c3a53344717b9e9551acd16d3402c48cbd64,Require distro-provided python-requests for SSL/TLS proxy,ABANDONED,2014-10-24 15:40:37.000000000,2015-01-06 20:14:28.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7662}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-24 15:40:37.000000000', 'files': ['lib/tls'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7f2832cf92c9666d0b88ced52f83d3e61fba6357', 'message': 'Require distro-provided python-requests for SSL/TLS proxy\n\nrequests provides a method, where(), which returns the location\nof the CA bundle. One is provided with the package but it\nrecommends that distros override this. Both Fedora and Ubuntu\ndo this, and provide a means of installing additional CAs into\nthe bundle. This allows devstack to add its own self-signed CA\nto the global bundle. Not having this causes subtle failures.\n\nChange-Id: Ib976c3a53344717b9e9551acd16d3402c48cbd64\n'}]",0,130828,7f2832cf92c9666d0b88ced52f83d3e61fba6357,12,7,1,7662,,,0,"Require distro-provided python-requests for SSL/TLS proxy

requests provides a method, where(), which returns the location
of the CA bundle. One is provided with the package but it
recommends that distros override this. Both Fedora and Ubuntu
do this, and provide a means of installing additional CAs into
the bundle. This allows devstack to add its own self-signed CA
to the global bundle. Not having this causes subtle failures.

Change-Id: Ib976c3a53344717b9e9551acd16d3402c48cbd64
",git fetch https://review.opendev.org/openstack/devstack refs/changes/28/130828/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tls'],1,7f2832cf92c9666d0b88ced52f83d3e61fba6357,requests," check_requests # Ensure that the version of python-requests installed is a distro-specific # version and not one installed by pip. This is because the pip one will # use it's own CA bundle and not the system one which means it won't have # access to the devstack CA. function check_requests { if ! `python -c 'import sys; import requests; sys.exit(""etc"" not in requests.certs.where())'`; then die $LINENO ""The pip version of requests is installed rather than a distro-specific version. This means the devstack CA will not be found in the CA bundle. Ensure your distro satisfies the minimum version requirement for python-requests."" fi } ",,12,0
openstack%2Fcue~master~I6259b5779efbde6f4333b0edc88c56095a70e1c4,openstack/cue,master,I6259b5779efbde6f4333b0edc88c56095a70e1c4,Adding initial DB API unit tests,ABANDONED,2014-12-30 02:09:34.000000000,2015-01-06 20:09:27.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-30 02:09:34.000000000', 'files': ['cue/tests/db/test_api.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/49f0c127ea0fab84b9b499af2ee8356af0a8fe94', 'message': 'Adding initial DB API unit tests\n\nChange-Id: I6259b5779efbde6f4333b0edc88c56095a70e1c4\n'}]",0,144397,49f0c127ea0fab84b9b499af2ee8356af0a8fe94,3,1,1,13771,,,0,"Adding initial DB API unit tests

Change-Id: I6259b5779efbde6f4333b0edc88c56095a70e1c4
",git fetch https://review.opendev.org/openstack/cue refs/changes/97/144397/1 && git format-patch -1 --stdout FETCH_HEAD,['cue/tests/db/test_api.py'],1,49f0c127ea0fab84b9b499af2ee8356af0a8fe94,test,"# Copyright 2014 Hewlett-Packard Development Company, L.P. # # Authors: Davide Agnello <davide.agnello@hp.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # Copyright [2014] Hewlett-Packard Development Company, L.P. # limitations under the License. import uuid from cue.db import api as db_api from cue.tests import base UUID1 = str(uuid.uuid4()) UUID2 = str(uuid.uuid4()) class ApiTests(base.TestCase): dbapi = db_api.get_instance() def test_get_clusters(self): """"""Verifies get clusters DB API."""""" def test_create_clusters(self): """"""Verifies create cluster DB API."""""" cluster_values = { ""project_id"": UUID1, ""name"": ""Rabbit Cluster"", ""network_id"": UUID2, ""flavor"": ""medium"", ""size"": 5, ""volume_size"": 250, } db_cluster = self.dbapi.create_cluster(cluster_values) self.assertEqual(cluster_values[""name""], db_cluster.name, ""invalid name value"") self.assertEqual(cluster_values[""network_id""], db_cluster.network_id, ""invalid network_id value"") self.assertEqual(cluster_values[""flavor""], db_cluster.flavor, ""invalid flavor value"") self.assertEqual(cluster_values[""size""], db_cluster.size, ""invalid size value"") self.assertEqual(cluster_values[""volume_size""], db_cluster.volume_size, ""invalid volume_size value"") self.assertEqual(False, db_cluster.deleted, ""invalid deleted value"") def test_get_cluster_by_id(self): """"""Verifies create cluster DB API."""""" def test_get_nodes_in_cluster(self): """"""Verifies create cluster DB API."""""" cluster_values = { ""project_id"": UUID1, ""name"": ""Rabbit Cluster"", ""network_id"": UUID2, ""flavor"": ""medium"", ""size"": 5, ""volume_size"": 250, } db_cluster = self.dbapi.create_cluster(cluster_values) db_nodes = self.dbapi.get_nodes_in_cluster(db_cluster.id) for node in db_nodes: self.assertEqual(db_cluster.id, node.cluster_id, ""invalid flavor value"") self.assertEqual(cluster_values[""flavor""], node.flavor, ""invalid flavor value"") self.assertEqual(cluster_values[""volume_size""], node.volume_size, ""invalid volume_size value"") self.assertEqual(False, node.deleted, ""invalid deleted value"") def test_get_endpoints_in_node(self): """"""Verifies create cluster DB API."""""" def test_mark_cluster_as_delete(self): """"""Verifies create cluster DB API.""""""",,93,0
openstack%2Fcue~master~If42be3edad424b8da39203b1f671d30b0085bd57,openstack/cue,master,If42be3edad424b8da39203b1f671d30b0085bd57,Updating REST API to Second Approach,ABANDONED,2014-12-21 04:05:15.000000000,2015-01-06 20:09:10.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-21 04:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/b0cd7ac7562debd4dda25589037ef8af12beefa4', 'message': 'Updating REST API to Second Approach\n\nSecond approach removes details of nodes from request/response bodies.\nCluster objects will hold information on number of nodes and flavors.\n\nSecond approach of the API is documented here:\nhttps://wiki.openstack.org/wiki/Cue/api_2\n\nChange-Id: If42be3edad424b8da39203b1f671d30b0085bd57\n'}, {'number': 2, 'created': '2014-12-29 17:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/35bd482754d20aad8e38dc9f37a699262092ee4d', 'message': 'Updating REST API to Second Approach\n\nSecond approach removes details of nodes from request/response bodies.\nCluster objects will hold information on number of nodes and flavors.\n\nSecond approach of the API is documented here:\nhttps://wiki.openstack.org/wiki/Cue/api_2\n\nChange-Id: If42be3edad424b8da39203b1f671d30b0085bd57\n'}, {'number': 3, 'created': '2014-12-29 19:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/5f90bf5c677a55f70a1f4557ac0fa0bf5a470d36', 'message': 'Updating REST API to Second Approach\n\nSecond approach removes details of nodes from request/response bodies.\nCluster objects will hold information on number of nodes and flavors.\n\nSecond approach of the API is documented here:\nhttps://wiki.openstack.org/wiki/Cue/api_2\n\nChange-Id: If42be3edad424b8da39203b1f671d30b0085bd57\n'}, {'number': 4, 'created': '2014-12-30 23:04:22.000000000', 'files': ['cue/db/sqlalchemy/api.py', 'cue/db/sqlalchemy/models.py', 'cue/db/api.py', 'cue/db/sqlalchemy/alembic/versions/236f63c96b6a_.py', 'cue/api/controllers/v1.py', 'cue/tests/db/test_models.py', 'cue/objects/cluster.py', 'cue/tests/api/test_clusters.py', 'cue/tests/db/utils.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/9528c726721cb0de52513f1c4efad92ece44fbc5', 'message': 'Updating REST API to Second Approach\n\nSecond approach removes details of nodes from request/response bodies.\nCluster objects will hold information on number of nodes and flavors.\n\nSecond approach of the API is documented here:\nhttps://wiki.openstack.org/wiki/Cue/api_2\n\nChange-Id: If42be3edad424b8da39203b1f671d30b0085bd57\n'}]",0,143287,9528c726721cb0de52513f1c4efad92ece44fbc5,9,1,4,13771,,,0,"Updating REST API to Second Approach

Second approach removes details of nodes from request/response bodies.
Cluster objects will hold information on number of nodes and flavors.

Second approach of the API is documented here:
https://wiki.openstack.org/wiki/Cue/api_2

Change-Id: If42be3edad424b8da39203b1f671d30b0085bd57
",git fetch https://review.opendev.org/openstack/cue refs/changes/87/143287/4 && git format-patch -1 --stdout FETCH_HEAD,"['cue/db/sqlalchemy/api.py', 'cue/db/sqlalchemy/models.py', 'cue/db/api.py', 'cue/db/sqlalchemy/alembic/versions/236f63c96b6a_.py', 'cue/api/controllers/v1.py', 'cue/tests/db/test_models.py', 'cue/objects/cluster.py', 'cue/tests/db/utils.py']",8,b0cd7ac7562debd4dda25589037ef8af12beefa4,api_v2," 'flavor': kw.get('name', 'flavor1'), 'network_id': kw.get('network_id', '3dc26c0b-03f2-4d2e-ae87-c02d7f33c788'), 'size': kw.get('size', 1), 'flavor': cluster['flavor'], 'size': cluster['size'], 'network_id': cluster['network_id'], new_cluster.create_cluster(project_id)"," 'nic': kw.get('nic', '3dc26c0b-03f2-4d2e-ae87-c02d7f33c788'), 'nic': cluster['nic'], number_of_nodes = 1 new_cluster.create_cluster(project_id, ""flavor1"", number_of_nodes)",55,76
openstack%2Fcue~master~Ie5188e92b1632a5f6b8f0495c543750da35210fa,openstack/cue,master,Ie5188e92b1632a5f6b8f0495c543750da35210fa,Adding initial set of REST API and cue objects Unit Tests,ABANDONED,2015-01-06 18:59:38.000000000,2015-01-06 20:08:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-06 18:59:38.000000000', 'files': ['cue/tests/api/test_cluster.py', 'cue/tests/objects/__init__.py', 'cue/tests/api/api_common.py', 'cue/api/controllers/v1.py', 'cue/tests/objects/test_objects.py', 'cue/objects/cluster.py', 'cue/tests/api/test_clusters.py', 'cue/objects/node.py', 'cue/tests/db/utils.py', 'cue/objects/endpoint.py', 'cue/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/ec837864e92ef22d6e8b4d087d4d63f5601c2fe3', 'message': 'Adding initial set of REST API and cue objects Unit Tests\n\nChange-Id: Ie5188e92b1632a5f6b8f0495c543750da35210fa\n'}]",0,145299,ec837864e92ef22d6e8b4d087d4d63f5601c2fe3,3,1,1,13771,,,0,"Adding initial set of REST API and cue objects Unit Tests

Change-Id: Ie5188e92b1632a5f6b8f0495c543750da35210fa
",git fetch https://review.opendev.org/openstack/cue refs/changes/99/145299/1 && git format-patch -1 --stdout FETCH_HEAD,"['cue/tests/api/test_cluster.py', 'cue/tests/api/api_common.py', 'cue/tests/objects/__init__.py', 'cue/api/controllers/v1.py', 'cue/tests/objects/test_objects.py', 'cue/objects/cluster.py', 'cue/tests/api/test_clusters.py', 'cue/objects/node.py', 'cue/tests/db/utils.py', 'cue/objects/endpoint.py', 'cue/tests/utils.py']",11,ec837864e92ef22d6e8b4d087d4d63f5601c2fe3,test_api,"# Copyright 2013 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Cue test utilities."""""" from oslo.utils import timeutils from cue.api.controllers import v1 from cue.db.sqlalchemy import models from cue import objects def get_test_cluster(**kw): return { 'id': kw.get('id', '1be26c0b-03f2-4d2e-ae87-c02d7f33c781'), 'project_id': kw.get('project_id', '1234567890'), 'name': kw.get('name', 'sample_cluster'), 'network_id': kw.get('network_id', '3dc26c0b-03f2-4d2e-ae87-c02d7f33c788'), 'status': kw.get('status', 'BUILDING'), 'flavor': kw.get('flavor', 'flavor1'), 'size': kw.get('size', 1), 'volume_size': kw.get('volume_size', 10), 'deleted': kw.get('deleted', False), 'created_at': kw.get('created_at', timeutils.utcnow()), 'updated_at': kw.get('updated_at', timeutils.utcnow()), 'deleted_at': kw.get('deleted_at', None), } def create_api_test_cluster(**kw): """"""Create test Cluster api object and return this object. Function to be used to acquire an API Cluster object set with only required fields. This would mimic a cluster object values received from REST API. :param kw: kwargs with overriding values for cluster's attributes. :returns: Test Cluster API object. """""" cluster = get_test_cluster(**kw) cluster_parameters = { 'name': cluster['name'], 'network_id': cluster['network_id'], 'flavor': cluster['flavor'], 'size': str(cluster['size']), 'volume_size': str(cluster['volume_size']), } new_cluster = v1.Cluster(**cluster_parameters) return new_cluster def create_api_test_cluster_all(**kw): """"""Create fully-populated test Cluster api object and return this object. Function to be used to acquire an API Cluster object with all fields set. :param kw: kwargs with overriding values for cluster's attributes. :returns: Test Cluster API object. """""" cluster = get_test_cluster(**kw) cluster_parameters = { 'name': cluster['name'], 'network_id': cluster['network_id'], 'flavor': cluster['flavor'], 'size': cluster['size'], 'volume_size': cluster['volume_size'], 'id': cluster['id'], 'project_id': cluster['project_id'], 'status': cluster['status'], 'created_at': cluster['created_at'], 'updated_at': cluster['updated_at'], } new_cluster = v1.Cluster(**cluster_parameters) return new_cluster def create_db_test_cluster_from_objects_api(**kw): """"""Create test Cluster entry in DB from objects API and return Cluster DB object. Function to be used to create test Cluster objects in the database. :param kw: kwargs with overriding values for cluster's attributes. :returns: Test Cluster DB object. """""" cluster = get_test_cluster(**kw) cluster_parameters = { 'name': cluster['name'], 'network_id': cluster['network_id'], 'flavor': cluster['flavor'], 'size': cluster['size'], 'volume_size': cluster['volume_size'], } new_cluster = objects.Cluster(**cluster_parameters) project_id = cluster['project_id'] new_cluster.create_cluster(project_id) return new_cluster def create_db_test_cluster_model_object(**kw): """"""Create test Cluster DB model object. :param kw: kwargs with overriding values for cluster's attributes. :returns: Test Cluster DB model object. """""" cluster = get_test_cluster(**kw) cluster_parameters = { 'name': cluster['name'], 'network_id': cluster['network_id'], 'flavor': cluster['flavor'], 'size': cluster['size'], 'volume_size': cluster['volume_size'], 'id': cluster['id'], 'project_id': cluster['project_id'], 'status': cluster['status'], 'deleted': cluster['deleted'], 'created_at': cluster['created_at'], 'updated_at': cluster['updated_at'], 'deleted_at': cluster['deleted_at'], } new_cluster = models.Cluster() new_cluster.update(cluster_parameters) return new_cluster",,523,83
openstack%2Fnova~master~Id384d0e8d350fdd68ed03c83b94f6e558d53eb28,openstack/nova,master,Id384d0e8d350fdd68ed03c83b94f6e558d53eb28,Nuke XML support from Nova REST API - Phase 2,MERGED,2014-12-05 15:04:58.000000000,2015-01-06 20:03:48.000000000,2015-01-06 16:22:08.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6864}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-05 15:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b1a3bbb40dbb03123a9041c7455488a6cfab094', 'message': 'WIP: Nuke XML tests\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 2, 'created': '2014-12-05 15:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/792fb8f82c75e8998f8a8285e0f785e8857a82ec', 'message': 'WIP: Nuke XML tests\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 3, 'created': '2014-12-05 16:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c274b7ccca45c7933e87990fb802a44f7e522569', 'message': 'WIP: Nuke XML tests\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 4, 'created': '2014-12-05 16:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b610c681c0202f4a42a2135f342e92f520a9db8', 'message': 'WIP: Nuke XML tests\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 5, 'created': '2014-12-06 00:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad5b02c62d713420e7b58433bd4b59118502f2cd', 'message': 'WIP: Nuke XML\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 6, 'created': '2014-12-06 01:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/893bc003ed2f4fbdc8dfb2315d489b4169d66263', 'message': 'Nuke XML support from Nova REST API\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API and remove all\nrelevent code and tests.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 7, 'created': '2014-12-08 11:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f700400b5120f6545588dd7ba3eee2e3bcc6dec9', 'message': 'Nuke XML support from Nova REST API\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API and remove all\nrelevent code and tests.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 8, 'created': '2014-12-08 13:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56b8cdd7428b23dc44d9e4e69eec20c86bfa5b06', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 9, 'created': '2014-12-08 13:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47a14287203b5e62ef40e8844402861cc5dffd53', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 10, 'created': '2014-12-08 14:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e854d0789042f43ce36bf16a4a10189fc81a3c88', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 11, 'created': '2014-12-09 17:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5623c9c0e6bc7f4841ceb56f15e35ffce5bdf427', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 12, 'created': '2014-12-14 00:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf92a5ed96730ce9ee19b491c2069bfcd6626776', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 13, 'created': '2014-12-16 03:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55aa4dab49641368c7f883b1bf424f23ed3d8a31', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 14, 'created': '2014-12-17 21:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28bb9519f32b4adba000d6fc6568b224ff97d785', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 15, 'created': '2014-12-18 02:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ee4839dada7399d018d7c621d9cfa5f44895135', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 16, 'created': '2014-12-21 02:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cc4b1ac08db7a7ffb26d251816a2d0799a5b584', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 17, 'created': '2014-12-27 21:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8773270b6ac8808f8b021cb3d0fc969f4dde1b4d', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 18, 'created': '2014-12-29 21:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cc8aabee0dd9cefa79cdbe64b3c744faffdfdd9', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 19, 'created': '2015-01-03 12:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85df17cc9a44a2c0aea6436e0e6448c2a2963221', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 20, 'created': '2015-01-03 12:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/203b95f770685d5c55c67f210e81e5b26b5645db', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 21, 'created': '2015-01-05 17:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f4b5d836a0acde969e4fd45b898a53ce40cae3c', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 22, 'created': '2015-01-06 01:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/219addbfede6d96769bc1b2f08570ade31f7ef4d', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}, {'number': 23, 'created': '2015-01-06 12:03:55.000000000', 'files': ['nova/api/openstack/compute/contrib/hypervisors.py', 'nova/api/openstack/compute/contrib/floating_ips.py', 'nova/api/openstack/compute/contrib/quota_classes.py', 'nova/api/openstack/compute/contrib/cells.py', 'nova/api/openstack/common.py', 'nova/api/openstack/compute/contrib/virtual_interfaces.py', 'nova/api/openstack/compute/contrib/config_drive.py', 'nova/api/openstack/compute/contrib/server_usage.py', 'nova/api/openstack/compute/schemas/v1.1/servers.rng', 'nova/api/openstack/compute/contrib/disk_config.py', 'nova/api/openstack/compute/contrib/extended_availability_zone.py', 'nova/api/openstack/compute/image_metadata.py', 'nova/api/openstack/xmlutil.py', 'nova/api/openstack/compute/contrib/baremetal_nodes.py', 'nova/api/openstack/compute/schemas/v1.1/images.rng', 'nova/api/openstack/compute/versions.py', 'nova/api/openstack/compute/contrib/assisted_volume_snapshots.py', 'nova/api/openstack/compute/contrib/migrations.py', 'nova/api/openstack/compute/contrib/extended_status.py', 'nova/api/openstack/compute/server_metadata.py', 'nova/api/openstack/compute/contrib/extended_volumes.py', 'nova/api/openstack/compute/contrib/flavorextraspecs.py', 'nova/api/openstack/compute/schemas/v1.1/version.rng', 'nova/api/openstack/compute/contrib/volumes.py', 'nova/api/openstack/compute/contrib/used_limits.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/api/openstack/compute/plugins/v3/baremetal_nodes.py', 'nova/api/openstack/compute/contrib/extended_ips.py', 'nova/api/openstack/compute/contrib/floating_ip_dns.py', 'nova/compute/fakevirtinstance.xml', 'nova/api/openstack/compute/contrib/services.py', 'nova/api/openstack/compute/schemas/v1.1/metadata.rng', 'nova/api/openstack/compute/limits.py', 'nova/api/openstack/compute/contrib/hosts.py', 'nova/api/openstack/compute/schemas/atom.rng', 'nova/api/openstack/compute/contrib/extended_server_attributes.py', 'nova/api/openstack/compute/contrib/simple_tenant_usage.py', 'nova/api/openstack/extensions.py', 'nova/api/openstack/compute/contrib/flavorextradata.py', 'nova/api/openstack/compute/contrib/flavor_access.py', 'nova/api/openstack/compute/contrib/server_groups.py', 'nova/api/openstack/compute/ips.py', 'nova/api/openstack/compute/flavors.py', 'nova/api/openstack/compute/contrib/flavor_swap.py', 'nova/api/openstack/compute/contrib/floating_ip_pools.py', 'nova/api/openstack/compute/contrib/server_diagnostics.py', 'nova/tests/unit/api/openstack/compute/test_versions.py', 'nova/api/openstack/compute/contrib/cloudpipe.py', 'nova/api/openstack/compute/contrib/instance_actions.py', 'nova/api/openstack/compute/schemas/v1.1/image.rng', 'nova/test.py', 'nova/api/openstack/compute/schemas/atom-link.rng', 'nova/api/openstack/compute/contrib/availability_zone.py', 'nova/api/openstack/compute/contrib/extended_ips_mac.py', 'nova/api/openstack/compute/schemas/v1.1/addresses.rng', 'nova/api/openstack/compute/contrib/flavor_disabled.py', 'nova/api/openstack/compute/schemas/v1.1/flavor.rng', 'nova/api/openstack/compute/contrib/keypairs.py', 'nova/api/openstack/compute/contrib/security_groups.py', 'nova/api/openstack/compute/contrib/server_external_events.py', 'nova/api/openstack/compute/schemas/v1.1/server.rng', 'nova/api/openstack/compute/schemas/v1.1/extensions.rng', 'nova/api/openstack/compute/images.py', 'nova/api/openstack/compute/schemas/v1.1/extension.rng', 'nova/api/openstack/compute/schemas/v1.1/versions.rng', 'nova/api/openstack/compute/contrib/certificates.py', 'nova/api/openstack/compute/contrib/flavormanage.py', 'nova/api/openstack/compute/servers.py', 'nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/contrib/flavor_rxtx.py', 'nova/api/openstack/compute/contrib/agents.py', 'nova/api/openstack/compute/contrib/image_size.py', 'nova/api/openstack/compute/contrib/security_group_default_rules.py', 'nova/api/openstack/compute/contrib/server_password.py', 'nova/api/openstack/compute/consoles.py', 'nova/api/openstack/compute/schemas/v1.1/limits.rng', 'nova/api/openstack/compute/schemas/v1.1/flavors.rng', 'nova/api/openstack/compute/contrib/server_group_quotas.py', 'nova/api/openstack/compute/contrib/extended_virtual_interfaces_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8454a2b4f3f0f876f7dad0d81502475107d18eaa', 'message': 'Nuke XML support from Nova REST API - Phase 2\n\nIn I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In\nthis review we entirely remove all support for XML in the API.\n\nChange-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28\n'}]",9,139650,8454a2b4f3f0f876f7dad0d81502475107d18eaa,168,14,23,5638,,,0,"Nuke XML support from Nova REST API - Phase 2

In I5a580fc323c3809790b4a68a9f8f8129ecdc2cf0 we switched off XML support. In
this review we entirely remove all support for XML in the API.

Change-Id: Id384d0e8d350fdd68ed03c83b94f6e558d53eb28
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/139650/22 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/os-networks/network-add-req.xml', 'nova/tests/functional/api_samples/os-volumes/attach-volume-to-server-resp.xml.tpl', 'doc/api_samples/os-instance_usage_audit_log/inst-usage-audit-log-show-get-resp.xml', 'doc/api_samples/os-consoles/get-serial-console-post-resp.xml', 'doc/api_samples/os-attach-interfaces/attach-interfaces-list-resp.xml', 'nova/tests/functional/api_samples/os-security-groups/security-group-remove-post-req.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-inject-network-info.xml', 'nova/tests/functional/api_samples/OS-EXT-VIF-NET/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-AZ/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-create-resp.xml.tpl', 'doc/api_samples/os-deferred-delete/force-delete-post-req.xml', 'doc/api_samples/os-baremetal-nodes/baremetal-node-add-interface-req.xml', 'doc/api_samples/os-consoles/get-spice-console-post-resp.xml', 'doc/api_samples/os-floating-ips-bulk/floating-ips-bulk-list-by-host-resp.xml', 'doc/api_samples/OS-DCF/server-update-put-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-STS/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-keypairs/keypairs-get-resp.xml.tpl', 'doc/api_samples/os-floating-ips-bulk/floating-ips-bulk-create-req.xml', 'doc/api_samples/OS-SRV-USG/server-post-req.xml', 'nova/tests/functional/api_samples/os-console-output/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-floating-ips/floating-ips-create-nopool-req.xml.tpl', 'nova/tests/functional/api_samples/os-cells/cells-list-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-FLV-DISABLED/flavor-detail-get-resp.xml.tpl', 'doc/api_samples/os-certificates/certificate-get-root-resp.xml', 'doc/api_samples/os-console-output/console-output-post-resp.xml', 'nova/tests/functional/api_samples/os-rescue/server-get-resp-rescue.xml.tpl', 'nova/tests/functional/api_samples/os-deferred-delete/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-extra-specs/flavor-extra-specs-update-req.xml.tpl', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-search-resp.xml.tpl', 'nova/tests/functional/api_samples/image-meta-key-put-resp.xml.tpl', 'nova/tests/functional/api_samples/all_extensions/server-action-createimage.xml.tpl', 'doc/api_samples/os-flavor-access/flavor-access-remove-tenant-resp.xml', 'nova/tests/functional/api_samples/os-networks-associate/network-disassociate-project-req.xml.tpl', 'doc/api_samples/os-server-external-events/event-create-resp.xml', 'doc/api_samples/versions-get-resp.xml', 'nova/tests/functional/api_samples/flavors-list-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-IPS-MAC/server-post-req.xml.tpl', 'doc/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-list-resp.xml', 'doc/api_samples/os-aggregates/aggregates-add-host-post-resp.xml', 'nova/tests/unit/api/openstack/compute/test_versions.py', 'nova/tests/functional/api_samples/os-security-groups/server-post-resp.xml.tpl', 'doc/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-resp.xml', 'nova/tests/functional/api_samples/os-rescue/server-rescue.xml.tpl', 'doc/api_samples/server-metadata-resp.xml', 'nova/tests/functional/api_samples/os-extended-rescue-with-image/server-get-resp-rescue.xml.tpl', 'nova/api/openstack/compute/schemas/v1.1/image.rng', 'doc/api_samples/os-security-groups/server-post-resp.xml', 'nova/tests/functional/api_samples/image-metadata-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-sort-keys/server-post-req.xml.tpl', 'doc/api_samples/OS-EXT-SRV-ATTR/server-post-resp.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/flavors/valid/refs.xml', 'nova/tests/functional/api_samples/os-rescue/server-get-resp-unrescue.xml.tpl', 'doc/api_samples/os-evacuate/server-post-resp.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/invalid/partial.xml', 'nova/tests/functional/api_samples/OS-EXT-IPS-MAC/servers-detail-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/invalid/partial2.xml', 'doc/api_samples/os-hypervisors/hypervisors-show-resp.xml', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-servers-resp.xml.tpl', 'nova/tests/functional/api_samples/all_extensions/server-action-resize.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/list-servers-detail-get.xml.tpl', 'doc/api_samples/os-config-drive/server-post-resp.xml', 'nova/tests/functional/api_samples/os-extended-floating-ips/floating-ips-get-resp.xml.tpl', 'doc/api_samples/os-agents/agent-post-resp.xml', 'nova/tests/functional/api_samples/images-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-resume.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-AZ/server-post-resp.xml.tpl', 'doc/api_samples/os-multiple-create/multiple-create-post-resp.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/flavors/invalid/mixed.xml', 'doc/api_samples/os-console-auth-tokens/get-rdp-console-post-req.xml', 'nova/tests/functional/api_samples/os-floating-ips-bulk/floating-ips-bulk-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-preserve-ephemeral-rebuild/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hosts/hosts-list-resp.xml.tpl', 'nova/tests/functional/api_samples/servers-details-resp.xml.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-add-tenant-req.xml.tpl', 'nova/tests/functional/api_samples/os-fping/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hosts/host-put-maintenance-req.xml.tpl', 'doc/api_samples/os-server-group-quotas/quota-classes-update-post-resp.xml', 'nova/tests/functional/api_samples/os-consoles/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/list-volume-attachments-resp.xml.tpl', 'doc/api_samples/server-metadata-all-req.xml', 'nova/tests/functional/api_samples/os-availability-zone/availability-zone-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-log-put-req.xml.tpl', 'doc/api_samples/os-cell-capacities/cells-capacities-resp.xml', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/os-baremetal-nodes/baremetal-node-create-with-address-resp.xml', 'doc/api_samples/os-multiple-create/multiple-create-no-resv-post-req.xml', 'nova/api/openstack/compute/schemas/v1.1/version.rng', 'nova/tests/functional/api_samples/os-cells/cells-list-empty-resp.xml.tpl', 'doc/api_samples/os-server-group-quotas/quota-classes-show-get-resp.xml', 'nova/tests/functional/api_samples/os-consoles/get-serial-console-post-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/invalid/partial2.xml', 'doc/api_samples/image-meta-key-put-resp.xml', 'doc/api_samples/server-action-rebuild-resp.xml', 'nova/tests/functional/api_samples/os-admin-actions/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-instance_usage_audit_log/inst-usage-audit-log-index-get-resp.xml.tpl', 'doc/api_samples/OS-EXT-IPS-MAC/server-get-resp.xml', 'nova/tests/functional/api_samples/os-console-auth-tokens/get-console-connect-info-get-resp.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-unpause.xml', 'doc/api_samples/os-networks-associate/network-disassociate-host-req.xml', 'nova/tests/functional/api_samples/os-quota-class-sets/quota-classes-update-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-tenant-networks/networks-list-res.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/os-volumes-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-show-resp.xml.tpl', 'doc/api_samples/os-server-list-multi-status/servers-list-resp.xml', 'nova/tests/functional/api_samples/os-floating-ips/floating-ips-list-empty-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_availability_zone.py', 'doc/api_samples/os-used-limits-for-admin/usedlimitsforadmin-get-resp.xml', 'doc/api_samples/os-extended-floating-ips/floating-ips-create-nopool-req.xml', 'doc/api_samples/os-keypairs/keypairs-import-post-resp.xml', 'doc/api_samples/os-server-group-quotas/quotas-update-post-resp.xml', 'nova/tests/functional/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'doc/api_samples/os-fping/fping-get-resp.xml', 'doc/api_samples/os-cloudpipe/cloud-pipe-create-resp.xml', 'doc/api_samples/os-floating-ips/floating-ips-create-resp.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_volumes.py', 'nova/tests/functional/api_samples/os-floating-ips-bulk/floating-ips-bulk-delete-resp.xml.tpl', 'doc/api_samples/os-console-auth-tokens/server-post-resp.xml', 'nova/api/openstack/compute/schemas/v1.1/extension.rng', 'nova/tests/functional/api_samples/os-preserve-ephemeral-rebuild/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-consoles/get-spice-console-post-resp.xml.tpl', 'doc/api_samples/os-server-groups/server-groups-get-resp.xml', 'nova/tests/functional/api_samples/os-extended-networks/network-create-resp.xml.tpl', 'doc/api_samples/os-server-external-events/server-post-req.xml', 'doc/api_samples/os-volumes/snapshots-list-resp.xml', 'nova/tests/functional/api_samples/os-server-group-quotas/quota-classes-update-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-keypairs/keypairs-import-post-req.xml.tpl', 'doc/api_samples/os-shelve/os-shelve.xml', 'doc/api_samples/OS-EXT-STS/servers-detail-resp.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/invalid/partial3.xml', 'doc/api_samples/os-consoles/get-vnc-console-post-resp.xml', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-resp.xml.tpl', 'doc/api_samples/OS-DCF/server-update-put-req.xml', 'doc/api_samples/os-volumes/server-post-req.xml', 'doc/api_samples/os-volumes/snapshot-create-req.xml', 'doc/api_samples/os-evacuate/server-post-req.xml', 'nova/tests/functional/api_samples/os-security-groups/security-groups-create-resp.xml.tpl', 'doc/api_samples/os-evacuate/server-evacuate-req.xml', 'doc/api_samples/os-virtual-interfaces/vifs-list-resp.xml', 'nova/tests/functional/api_samples/os-flavor-manage/flavor-create-post-req.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-STS/server-post-req.xml.tpl', 'doc/api_samples/os-extended-volumes/server-post-req.xml', 'nova/tests/functional/api_samples/os-extended-quotas/quotas-update-post-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-SRV-ATTR/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/image-meta-key-get.xml.tpl', 'doc/api_samples/os-cloudpipe-update/cloud-pipe-update-req.xml', 'doc/api_samples/OS-DCF/server-action-rebuild-req.xml', 'doc/api_samples/os-server-groups/server-groups-post-resp.xml', 'doc/api_samples/limit-get-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-STS/servers-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-cloudpipe/cloud-pipe-create-resp.xml.tpl', 'doc/api_samples/os-attach-interfaces/attach-interfaces-create-resp.xml', 'nova/tests/functional/api_samples/os-networks/networks-list-resp.xml.tpl', 'doc/api_samples/os-security-groups/security-group-post-req.xml', 'doc/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild.xml', 'nova/tests/functional/api_samples/os-shelve/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-networks/networks-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-group-quotas/limit-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-rescue/server-unrescue-req.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/snapshot-create-req.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_createserverext.py', 'doc/api_samples/os-preserve-ephemeral-rebuild/server-post-resp.xml', 'doc/api_samples/image-metadata-put-resp.xml', 'doc/api_samples/os-extended-rescue-with-image/server-rescue.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/valid/refs.xml', 'nova/tests/functional/api_samples/os-extended-rescue-with-image/server-post-resp.xml.tpl', 'doc/api_samples/os-security-group-default-rules/security-group-default-rules-list-resp.xml', 'doc/api_samples/os-preserve-ephemeral-rebuild/server-post-req.xml', 'nova/tests/functional/api_samples/os-flavor-extra-specs/flavor-extra-specs-list-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/flavors/invalid/partial.xml', 'nova/tests/functional/api_samples/os-extended-floating-ips/floating-ips-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-rescue/server-post-resp.xml.tpl', 'doc/api_samples/os-baremetal-nodes/baremetal-node-remove-interface-req.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregate-post-req.xml.tpl', 'doc/api_samples/os-keypairs/keypairs-get-resp.xml', 'doc/api_samples/os-flavor-access/flavor-access-create-resp.xml', 'nova/tests/functional/api_samples/os-quota-sets/quotas-update-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-groups/server-groups-list-resp.xml.tpl', 'doc/api_samples/os-security-groups/security-group-remove-post-req.xml', 'nova/tests/functional/api_samples/os-simple-tenant-usage/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-IPS/server-post-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_ips.py', 'nova/tests/functional/api_samples/os-console-output/console-output-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-consoles/get-vnc-console-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-list-multi-status/server-post-req.xml.tpl', 'doc/api_samples/os-flavor-extra-specs/flavor-extra-specs-create-req.xml', 'doc/api_samples/os-floating-ips-bulk/floating-ips-bulk-delete-req.xml', 'doc/api_samples/os-deferred-delete/server-post-resp.xml', 'nova/tests/functional/api_samples/server-ips-resp.xml.tpl', 'doc/api_samples/OS-EXT-SRV-ATTR/servers-detail-resp.xml', 'doc/api_samples/os-floating-ips-bulk/floating-ips-bulk-delete-resp.xml', 'doc/api_samples/os-user-quotas/user-quotas-show-get-resp.xml', 'nova/tests/functional/api_samples/os-extended-hypervisors/hypervisors-show-with-ip-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_virtual_interfaces_net.py', 'nova/tests/functional/api_samples/OS-DCF/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-keypairs/keypairs-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-instance-actions/instance-actions-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-evacuate-find-host/server-evacuate-find-host-resp.xml.tpl', 'doc/api_samples/os-server-password/server-post-resp.xml', 'doc/api_samples/os-hosts/host-get-startup.xml', 'doc/api_samples/os-tenant-networks/networks-post-res.xml', 'doc/api_samples/server-ips-resp.xml', 'nova/tests/functional/api_samples/os-volumes/snapshots-list-resp.xml.tpl', 'doc/api_samples/flavors-list-resp.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_security_groups.py', 'nova/api/openstack/compute/schemas/v1.1/servers.rng', 'nova/tests/functional/api_samples/os-server-group-quotas/usedlimits-get-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/server-action-rebuild-req.xml.tpl', 'nova/tests/functional/api_samples/os-evacuate/server-post-resp.xml.tpl', 'doc/api_samples/os-shelve/os-unshelve.xml', 'nova/tests/functional/api_samples/OS-EXT-IPS/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-hosts/host-put-maintenance-resp.xml.tpl', 'nova/tests/functional/api_samples/os-networks/network-create-req.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/image-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-list-multi-status/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-networks/network-create-req.xml.tpl', 'doc/api_samples/os-attach-interfaces/attach-interfaces-show-resp.xml', 'nova/tests/functional/api_samples/all_extensions/flavors-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-networks/network-show-resp.xml.tpl', 'doc/api_samples/OS-EXT-VIF-NET/server-post-req.xml', 'nova/tests/functional/api_samples/os-server-sort-keys/server-sort-keys-list-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/server-resize-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-deferred-delete/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-attach-interfaces/attach-interfaces-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-group-quotas/quotas-show-defaults-get-resp.xml.tpl', 'doc/api_samples/os-flavor-extra-specs/flavor-extra-specs-get-resp.xml', 'nova/tests/functional/api_samples/os-hide-server-addresses/servers-details-resp.xml.tpl', 'doc/api_samples/os-simple-tenant-usage/simple-tenant-usage-get-specific.xml', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-create-with-address-resp.xml', 'nova/tests/functional/api_samples/os-keypairs/keypairs-post-resp.xml.tpl', 'doc/api_samples/os-server-password/server-post-req.xml', 'nova/tests/functional/api_samples/all_extensions/server-post-req.xml.tpl', 'doc/api_samples/os-block-device-mapping-v2-boot/server-post-req.xml', 'nova/tests/functional/api_samples/image-get-resp.xml.tpl', 'doc/api_samples/server-metadata-req.xml', 'nova/tests/unit/api/openstack/compute/test_api.py', 'doc/api_samples/os-aggregates/aggregate-post-req.xml', 'nova/api/openstack/compute/schemas/v1.1/addresses.rng', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-entry-get-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-IPS/servers-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hide-server-addresses/server-post-req.xml.tpl', 'doc/api_samples/os-server-diagnostics/server-post-req.xml', 'doc/api_samples/all_extensions/server-post-req.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_image_size.py', 'doc/api_samples/OS-EXT-AZ/server-post-resp.xml', 'doc/api_samples/os-shelve/server-post-req.xml', 'nova/tests/functional/api_samples/os-extended-volumes/server-post-resp.xml.tpl', 'doc/api_samples/NMN/server-post-req.xml', 'nova/tests/functional/api_samples/OS-SRV-USG/server-post-req.xml.tpl', 'doc/api_samples/all_extensions/flavor-get-resp.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/valid/empty.xml', 'doc/api_samples/os-console-output/server-post-req.xml', 'doc/api_samples/os-networks/networks-list-resp.xml', 'nova/api/openstack/wsgi.py', 'nova/tests/functional/api_samples/os-fping/fping-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-password/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-password/get-password-resp.xml.tpl', 'doc/api_samples/os-agents/agents-get-resp.xml', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-entry-list-resp.xml', 'doc/api_samples/os-virtual-interfaces/server-post-req.xml', 'nova/tests/functional/api_samples/os-extended-rescue-with-image/server-rescue.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-instance_usage_audit_log/inst-usage-audit-log-show-get-resp.xml.tpl', 'doc/api_samples/os-rescue/server-post-resp.xml', 'doc/api_samples/server-action-confirmresize.xml', 'nova/tests/functional/api_samples/os-user-quotas/user-quotas-update-post-resp.xml.tpl', 'doc/api_samples/all_extensions/server-action-reboot.xml', 'nova/tests/functional/api_samples/os-cells/cells-get-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/valid/detailed.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-suspend.xml.tpl', 'nova/tests/functional/api_samples/os-server-sort-keys/server-post-resp.xml.tpl', 'doc/api_samples/os-evacuate/server-evacuate-resp.xml', 'doc/api_samples/all_extensions/server-action-createimage.xml', 'nova/tests/functional/api_samples/OS-EXT-IMG-SIZE/image-get-resp.xml.tpl', 'doc/api_samples/os-user-data/userdata-post-req.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-unlock-server.xml.tpl', 'nova/tests/unit/bundle/1mb.manifest.xml', 'doc/api_samples/os-hosts/host-get-resp.xml', 'doc/api_samples/os-services/service-disable-put-resp.xml', 'nova/tests/functional/api_samples/os-extended-volumes/server-get-resp.xml.tpl', 'doc/api_samples/os-aggregates/aggregate-add-host-post-req.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/valid/full.xml', 'nova/tests/functional/api_samples/limit-get-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_status.py', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/valid/refs.xml', 'nova/tests/functional/api_samples/os-flavor-swap/flavor-swap-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-networks/networks-disassociate-req.xml.tpl', 'nova/tests/functional/api_samples/os-migrations/migrations-get.xml.tpl', 'nova/tests/functional/api_samples/os-hosts/host-get-reboot.xml.tpl', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-statistics-resp.xml.tpl', 'doc/api_samples/os-attach-interfaces/attach-interfaces-create-req.xml', 'nova/tests/functional/api_samples/os-server-groups/server-groups-post-resp.xml.tpl', 'doc/api_samples/os-services/services-list-get-resp.xml', 'nova/tests/functional/api_samples/os-console-auth-tokens/server-post-req.xml.tpl', 'doc/api_samples/os-quota-class-sets/quota-classes-update-post-req.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-migrate.xml.tpl', 'nova/tests/unit/bundle/1mb.no_kernel_or_ramdisk.manifest.xml', 'doc/api_samples/os-volume-attachment-update/server-post-resp.xml', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_disabled.py', 'nova/tests/functional/api_samples/all_extensions/server-action-changepassword.xml.tpl', 'nova/tests/functional/api_samples/all_extensions/server-action-confirmresize.xml.tpl', 'doc/api_samples/os-networks/networks-disassociate-req.xml', 'doc/api_samples/os-console-output/server-post-resp.xml', 'doc/api_samples/os-volumes/volume-attachment-detail-resp.xml', 'doc/api_samples/os-agents/agent-update-put-resp.xml', 'nova/tests/functional/api_samples/os-certificates/certificate-create-req.xml.tpl', 'doc/api_samples/os-user-quotas/user-quotas-update-post-resp.xml', 'doc/api_samples/image-metadata-get-resp.xml', 'doc/api_samples/os-extended-volumes/server-post-resp.xml', 'doc/api_samples/os-networks/network-create-resp.xml', 'nova/tests/functional/api_samples/os-shelve/server-post-req.xml.tpl', 'doc/api_samples/OS-EXT-IPS-MAC/server-post-resp.xml', 'nova/tests/functional/api_samples/os-services/service-enable-put-req.xml.tpl', 'doc/api_samples/os-simple-tenant-usage/server-post-resp.xml', 'doc/api_samples/os-admin-actions/server-post-req.xml', 'doc/api_samples/os-hide-server-addresses/server-get-resp.xml', 'nova/tests/functional/api_samples/os-extended-floating-ips/floating-ips-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-group-quotas/quota-classes-show-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-put-req.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/attach-volume-to-server-req.xml.tpl', 'doc/api_samples/os-multiple-create/multiple-create-no-resv-post-resp.xml', 'nova/tests/functional/api_samples/os-networks-associate/network-disassociate-req.xml.tpl', 'nova/tests/functional/api_samples/image-meta-key-put-req.xml.tpl', 'nova/tests/functional/api_samples/os-deferred-delete/restore-post-req.xml.tpl', 'doc/api_samples/server-post-req.xml', 'nova/tests/functional/api_samples/os-extended-rescue-with-image/server-post-req.xml.tpl', 'doc/api_samples/os-flavor-swap/flavor-swap-post-resp.xml', 'nova/tests/functional/api_samples/NMN/server-post-req.xml.tpl', 'doc/api_samples/os-hosts/host-get-reboot.xml', 'nova/tests/functional/api_samples/os-volumes/server-post-req.xml.tpl', 'doc/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-get-resp.xml', 'doc/api_samples/os-keypairs/keypairs-import-post-req.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-reset-state.xml.tpl', 'nova/tests/functional/api_samples/os-networks/network-add-req.xml.tpl', 'doc/api_samples/os-extended-rescue-with-image/server-rescue-req.xml', 'doc/api_samples/os-hide-server-addresses/servers-details-resp.xml', 'doc/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-post-resp.xml', 'doc/api_samples/server-get-resp.xml', 'nova/tests/functional/api_samples/os-consoles/server-post-resp.xml.tpl', 'doc/api_samples/os-server-sort-keys/server-post-req.xml', 'doc/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.xml', 'doc/api_samples/os-server-start-stop/server-post-req.xml', 'doc/api_samples/os-aggregates/aggregate-update-post-resp.xml', 'doc/api_samples/os-rescue/server-get-resp-unrescue.xml', 'nova/tests/functional/api_samples/os-extended-rescue-with-image/server-rescue-req.xml.tpl', 'nova/tests/functional/api_samples/image-metadata-get-resp.xml.tpl', 'nova/tests/functional/api_samples/server-metadata-all-resp.xml.tpl', 'doc/api_samples/os-consoles/server-post-resp.xml', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-req.xml.tpl', 'doc/api_samples/OS-DCF/server-resize-post-req.xml', 'doc/api_samples/os-server-groups/server-groups-list-resp.xml', 'doc/api_samples/os-consoles/server-post-req.xml', 'nova/api/openstack/compute/schemas/v1.1/server.rng', 'doc/api_samples/os-volumes/os-volumes-index-resp.xml', 'doc/api_samples/os-availability-zone/availability-zone-post-resp.xml', 'doc/api_samples/os-server-group-quotas/quotas-update-post-req.xml', 'nova/tests/functional/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-post-req.xml.tpl', 'doc/api_samples/os-networks/network-create-req.xml', 'doc/api_samples/os-flavor-swap/flavor-swap-post-req.xml', 'doc/api_samples/server-action-revertresize.xml', 'nova/tests/functional/api_samples/os-consoles/get-spice-console-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-virtual-interfaces/server-post-req.xml.tpl', 'doc/api_samples/os-quota-sets/quotas-update-post-resp.xml', 'doc/api_samples/os-server-external-events/event-create-req.xml', 'doc/api_samples/os-server-group-quotas/quotas-show-defaults-get-resp.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/invalid/mixed.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/flavors/valid/full.xml', 'nova/tests/functional/api_samples/os-multiple-create/multiple-create-no-resv-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-availability-zone/availability-zone-details-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/server-update-put-req.xml.tpl', 'nova/tests/functional/api_samples/os-aggregates/aggregates-remove-host-post-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/server-post-req.xml.tpl', 'doc/api_samples/os-server-group-quotas/usedlimits-get-resp.xml', 'nova/tests/unit/virt/xenapi/vm_rrd.xml', 'doc/api_samples/OS-EXT-IMG-SIZE/image-get-resp.xml', 'doc/api_samples/all_extensions/flavors-list-resp.xml', 'doc/api_samples/all_extensions/server-get-resp.xml', 'doc/api_samples/os-extended-floating-ips/floating-ips-create-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-STS/server-get-resp.xml.tpl', 'doc/api_samples/os-security-groups/security-groups-list-get-resp.xml', 'doc/api_samples/OS-DCF/server-post-resp.xml', 'doc/api_samples/all_extensions/servers-details-resp.xml', 'doc/api_samples/os-rescue/server-rescue-req.xml', 'doc/api_samples/os-hosts/host-get-shutdown.xml', 'doc/api_samples/os-floating-ips/floating-ips-create-nopool-req.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/invalid/no-metadata.xml', 'nova/tests/functional/api_samples/OS-EXT-SRV-ATTR/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-entry-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips-bulk/floating-ips-bulk-list-by-host-resp.xml.tpl', 'nova/tests/functional/api_samples/os-quota-sets/quotas-update-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips-bulk/floating-ips-bulk-delete-req.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips/floating-ips-create-nopool-req.xml.tpl', 'doc/api_samples/os-console-auth-tokens/server-post-req.xml', 'nova/tests/functional/api_samples/os-server-group-quotas/quotas-show-get-resp.xml.tpl', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-add-interface-req.xml', 'nova/tests/functional/api_samples/all_extensions/server-action-rebuild.xml.tpl', 'doc/api_samples/os-agents/agent-update-put-req.xml', 'doc/api_samples/os-aggregates/aggregate-metadata-post-req.xml', 'doc/api_samples/os-keypairs/keypairs-post-resp.xml', 'doc/api_samples/os-extended-volumes/servers-detail-resp.xml', 'nova/tests/functional/api_samples/os-volumes/snapshot-create-resp.xml.tpl', 'doc/api_samples/OS-EXT-IPS/servers-detail-resp.xml', 'doc/api_samples/os-cloudpipe/cloud-pipe-create-req.xml', 'doc/api_samples/os-migrations/migrations-get.xml', 'nova/tests/functional/api_samples/os-extended-networks/network-show-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-diagnostics/server-post-req.xml.tpl', 'nova/api/openstack/compute/schemas/v1.1/versions.rng', 'doc/api_samples/os-extended-rescue-with-image/server-post-req.xml', 'nova/tests/functional/api_samples/os-server-start-stop/server-post-req.xml.tpl', 'doc/api_samples/os-consoles/get-rdp-console-post-req.xml', 'doc/api_samples/all_extensions/server-action-resize.xml', 'nova/tests/unit/api/openstack/test_faults.py', 'doc/api_samples/os-server-diagnostics/server-post-resp.xml', 'nova/tests/functional/api_samples/os-attach-interfaces/attach-interfaces-create-resp.xml.tpl', 'doc/api_samples/os-extended-quotas/quotas-update-post-resp.xml', 'doc/api_samples/server-post-resp.xml', 'nova/tests/functional/api_samples/os-fixed-ips/fixedips-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-services/service-disable-log-put-resp.xml.tpl', 'doc/api_samples/OS-EXT-AZ/server-post-req.xml', 'doc/api_samples/os-cells/cells-get-resp.xml', 'nova/tests/functional/api_samples/os-cloudpipe-update/cloud-pipe-update-req.xml.tpl', 'nova/tests/functional/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-resp.xml.tpl', 'nova/tests/functional/api_samples/os-aggregates/aggregate-post-resp.xml.tpl', 'doc/api_samples/os-baremetal-nodes/baremetal-node-add-interface-resp.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_ips_mac.py', 'doc/api_samples/os-admin-actions/admin-actions-backup-server.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregate-add-host-post-req.xml.tpl', 'nova/tests/functional/api_samples/server-action-rebuild-resp.xml.tpl', 'nova/tests/functional/api_samples/all_extensions/server-action-reboot.xml.tpl', 'doc/api_samples/os-floating-ips/floating-ips-list-resp.xml', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-list-resp.xml.tpl', 'doc/api_samples/os-extended-evacuate-find-host/server-post-resp.xml', 'nova/tests/functional/api_samples/os-console-auth-tokens/get-rdp-console-post-req.xml.tpl', 'nova/api/openstack/compute/schemas/v1.1/images.rng', 'doc/api_samples/os-admin-actions/admin-actions-live-migrate.xml', 'doc/api_samples/os-admin-actions/server-post-resp.xml', 'nova/tests/functional/api_samples/OS-SCH-HNT/scheduler-hints-post-req.xml.tpl', 'doc/api_samples/image-metadata-post-req.xml', 'nova/tests/functional/api_samples/os-admin-actions/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips-bulk/floating-ips-bulk-create-resp.xml.tpl', 'doc/api_samples/os-rescue/server-unrescue-req.xml', 'doc/api_samples/os-server-start-stop/server-post-resp.xml', 'doc/api_samples/os-tenant-networks/networks-list-res.xml', 'doc/api_samples/os-extended-networks/network-create-resp.xml', 'nova/tests/functional/api_samples/server-action-confirmresize.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/flavors/invalid/partial2.xml', 'nova/tests/functional/api_samples/os-consoles/get-serial-console-post-req.xml.tpl', 'doc/api_samples/OS-DCF/image-list-resp.xml', 'nova/tests/functional/api_samples/os-security-groups/security-group-add-post-req.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_swap.py', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-req.xml.tpl', 'nova/tests/functional/api_samples/os-user-data/userdata-post-resp.xml.tpl', 'doc/api_samples/os-extended-rescue-with-image/server-post-resp.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregate-remove-host-post-req.xml.tpl', 'doc/api_samples/os-hosts/host-put-maintenance-req.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregates-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-external-events/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-groups/server-groups-get-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-IPS/server-get-resp.xml.tpl', 'doc/api_samples/image-metadata-put-req.xml', 'nova/tests/functional/api_samples/os-quota-sets/quotas-show-defaults-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-aggregates/aggregate-update-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-services/service-enable-put-resp.xml.tpl', 'nova/tests/functional/api_samples/server-metadata-all-req.xml.tpl', 'nova/tests/functional/api_samples/OS-SCH-HNT/scheduler-hints-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-reset-server-state.xml.tpl', 'doc/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.xml', 'nova/tests/functional/api_samples/os-volume-attachment-update/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-hide-server-addresses/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/NMN/multinic-add-fixed-ip-req.xml.tpl', 'nova/tests/functional/api_samples/os-security-groups/security-groups-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-aggregates/aggregate-metadata-post-req.xml.tpl', 'doc/api_samples/os-services/service-disable-log-put-resp.xml', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-entry-req.xml.tpl', 'doc/api_samples/os-multiple-create/multiple-create-post-req.xml', 'nova/tests/functional/api_samples/os-fixed-ips/fixedip-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-extended-floating-ips/floating-ips-list-empty-resp.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips/floating-ips-get-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/flavors/valid/empty.xml', 'nova/tests/functional/api_samples/os-server-list-multi-status/servers-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild.xml.tpl', 'doc/api_samples/all_extensions/server-action-revertresize.xml', 'nova/tests/unit/api/openstack/compute/test_limits.py', 'nova/tests/functional/api_samples/os-consoles/get-rdp-console-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-unpause.xml.tpl', 'doc/api_samples/os-hypervisors/hypervisors-servers-resp.xml', 'nova/tests/functional/api_samples/images-details-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-add-tenant-resp.xml.tpl', 'doc/api_samples/os-hypervisors/hypervisors-detail-resp.xml', 'nova/tests/functional/api_samples/os-quota-sets/quotas-show-get-resp.xml.tpl', 'doc/api_samples/OS-SRV-USG/server-get-resp.xml', 'doc/api_samples/os-quota-class-sets/quota-classes-show-get-resp.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-reset-network.xml.tpl', 'doc/api_samples/os-hypervisors/hypervisors-search-resp.xml', 'nova/tests/functional/api_samples/os-config-drive/server-post-req.xml.tpl', 'doc/api_samples/os-fixed-ips/fixedips-get-resp.xml', 'nova/tests/functional/api_samples/os-used-limits-for-admin/usedlimitsforadmin-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-backup-server.xml.tpl', 'doc/api_samples/os-aggregates/aggregate-remove-host-post-req.xml', 'nova/tests/functional/api_samples/os-aggregates/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-security-groups/security-group-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-simple-tenant-usage/simple-tenant-usage-get.xml.tpl', 'doc/api_samples/os-server-diagnostics/server-diagnostics-get-resp.xml', 'nova/tests/functional/api_samples/OS-SRV-USG/server-post-resp.xml.tpl', 'doc/api_samples/server-ips-network-resp.xml', 'doc/api_samples/os-aggregates/aggregate-post-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-IMG-SIZE/images-details-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.xml.tpl', 'doc/api_samples/os-quota-sets/quotas-show-defaults-get-resp.xml', 'nova/tests/unit/api/openstack/compute/test_extensions.py', 'doc/api_samples/os-flavor-access/flavor-access-add-tenant-req.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregate-update-post-resp.xml.tpl', 'doc/api_samples/os-extended-evacuate-find-host/server-evacuate-find-host-req.xml', 'nova/tests/functional/api_samples/os-extended-volumes/server-post-req.xml.tpl', 'doc/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild-resp.xml', 'nova/tests/functional/api_samples/os-hosts/host-get-startup.xml.tpl', 'nova/tests/functional/api_samples/os-attach-interfaces/attach-interfaces-show-resp.xml.tpl', 'doc/api_samples/os-aggregates/aggregates-get-resp.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregates-metadata-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hypervisor-status/hypervisors-show-with-status-resp.xml.tpl', 'doc/api_samples/os-hypervisors/hypervisors-statistics-resp.xml', 'nova/tests/functional/api_samples/os-security-group-default-rules/security-group-default-rules-create-req.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_rxtx.py', 'nova/tests/functional/api_samples/os-block-device-mapping-v2-boot/server-post-resp.xml.tpl', 'doc/api_samples/os-instance_usage_audit_log/inst-usage-audit-log-index-get-resp.xml', 'doc/api_samples/OS-DCF/server-action-rebuild-resp.xml', 'doc/api_samples/os-aggregates/aggregate-update-post-req.xml', 'doc/api_samples/flavor-get-resp.xml', 'doc/api_samples/os-extended-rescue-with-image/server-get-resp-rescue.xml', 'nova/tests/functional/api_samples/os-user-data/userdata-post-req.xml.tpl', 'doc/api_samples/os-flavor-extra-specs/flavor-extra-specs-list-resp.xml', 'doc/api_samples/os-floating-ips-bulk/floating-ips-bulk-create-resp.xml', 'nova/tests/functional/api_samples/os-server-diagnostics/server-diagnostics-get-resp.xml.tpl', 'nova/tests/functional/api_samples/versions-get-resp.xml.tpl', 'doc/api_samples/os-extended-evacuate-find-host/server-evacuate-find-host-resp.xml', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-resp.xml', 'doc/api_samples/OS-FLV-DISABLED/flavor-detail-get-resp.xml', 'doc/api_samples/os-consoles/get-vnc-console-post-req.xml', 'nova/tests/functional/api_samples/all_extensions/server-action-rebuild-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-password/server-post-resp.xml.tpl', 'doc/api_samples/os-user-quotas/user-quotas-update-post-req.xml', 'doc/api_samples/os-user-data/userdata-post-resp.xml', 'doc/api_samples/os-baremetal-nodes/baremetal-node-show-resp.xml', 'doc/api_samples/os-block-device-mapping-v2-boot/server-post-resp.xml', 'doc/api_samples/os-flavor-access/flavor-access-list-resp.xml', 'nova/tests/functional/api_samples/all_extensions/server-post-resp.xml.tpl', 'doc/api_samples/os-aggregates/aggregates-remove-host-post-resp.xml', 'doc/api_samples/all_extensions/server-action-confirmresize.xml', 'nova/tests/functional/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-get-resp.xml.tpl', 'doc/api_samples/os-server-sort-keys/server-post-resp.xml', 'doc/api_samples/os-hosts/host-put-maintenance-resp.xml', 'nova/tests/functional/api_samples/os-certificates/certificate-create-resp.xml.tpl', 'doc/api_samples/os-shelve/os-shelve-offload.xml', 'doc/api_samples/os-flavor-access/flavor-access-detail-resp.xml', 'nova/tests/functional/api_samples/os-services/services-list-get-resp.xml.tpl', 'doc/api_samples/os-server-groups/server-groups-post-req.xml', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-show-resp.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/os-volumes-index-resp.xml.tpl', 'doc/api_samples/os-extended-hypervisors/hypervisors-show-with-ip-resp.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_neutron_security_groups.py', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-entry-req.xml', 'doc/api_samples/os-quota-sets/quotas-show-get-resp.xml', 'nova/tests/functional/api_samples/os-flavor-rxtx/flavor-rxtx-post-req.xml.tpl', 'doc/api_samples/os-volumes/attach-volume-to-server-resp.xml', 'nova/tests/functional/api_samples/os-aggregates/server-post-req.xml.tpl', 'doc/api_samples/os-baremetal-nodes/baremetal-node-create-resp.xml', 'nova/tests/functional/api_samples/os-cloudpipe/cloud-pipe-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-agents/agent-update-put-resp.xml.tpl', 'doc/api_samples/OS-EXT-IMG-SIZE/images-details-get-resp.xml', 'nova/tests/functional/api_samples/os-volume-attachment-update/update-volume-req.xml.tpl', 'nova/tests/functional/api_samples/os-attach-interfaces/server-post-req.xml.tpl', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-add-interface-resp.xml', 'doc/api_samples/os-flavor-manage/flavor-create-post-req.xml', 'doc/api_samples/image-meta-key-get.xml', 'nova/tests/functional/api_samples/os-simple-tenant-usage/simple-tenant-usage-get-specific.xml.tpl', 'doc/api_samples/os-networks-associate/network-associate-host-req.xml', 'doc/api_samples/os-flavor-access/flavor-access-create-req.xml', 'nova/test.py', 'nova/tests/functional/api_samples/os-certificates/certificate-get-root-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_hide_server_addresses.py', 'nova/tests/functional/api_samples/os-floating-ips-bulk/floating-ips-bulk-list-resp.xml.tpl', 'doc/api_samples/os-networks-associate/network-disassociate-project-req.xml', 'nova/tests/functional/api_samples/os-shelve/os-shelve.xml.tpl', 'doc/api_samples/os-floating-ips/floating-ips-create-req.xml', 'doc/api_samples/server-action-reboot.xml', 'doc/api_samples/os-server-list-multi-status/server-post-req.xml', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-remove-interface-req.xml', 'doc/api_samples/os-flavor-access/flavor-access-show-resp.xml', 'nova/api/openstack/compute/schemas/v1.1/limits.rng', 'doc/api_samples/os-extended-networks/network-show-resp.xml', 'doc/api_samples/os-certificates/certificate-create-resp.xml', 'doc/api_samples/OS-EXT-IPS-MAC/servers-detail-resp.xml', 'nova/tests/functional/api_samples/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-services/services-get-resp.xml.tpl', 'doc/api_samples/os-volumes/attach-volume-to-server-req.xml', 'doc/api_samples/OS-EXT-VIF-NET/server-post-resp.xml', 'nova/tests/functional/api_samples/os-volumes/os-volumes-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-attach-interfaces/attach-interfaces-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-extra-specs/flavor-extra-specs-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/os-volumes-get-resp.xml.tpl', 'doc/api_samples/os-extended-quotas/quotas-update-post-req.xml', 'doc/api_samples/os-hypervisors/hypervisors-uptime-resp.xml', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-req.xml', 'doc/api_samples/os-rescue/server-get-resp-rescue.xml', 'doc/api_samples/os-networks-associate/network-disassociate-req.xml', 'doc/api_samples/os-flavor-extra-specs/flavor-extra-specs-update-req.xml', 'doc/api_samples/os-fping/fping-get-details-resp.xml', 'nova/tests/functional/api_samples/os-evacuate/server-post-req.xml.tpl', 'doc/api_samples/os-attach-interfaces/server-post-resp.xml', 'doc/api_samples/os-services/service-enable-put-req.xml', 'nova/tests/functional/api_samples/os-server-groups/server-groups-post-req.xml.tpl', 'nova/compute/fakevirtinstance.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/invalid/partial.xml', 'nova/tests/functional/api_samples/os-rescue/server-rescue-req.xml.tpl', 'nova/tests/functional/api_samples/os-multiple-create/multiple-create-no-resv-post-resp.xml.tpl', 'doc/api_samples/os-aggregates/aggregates-list-get-resp.xml', 'doc/api_samples/os-floating-ip-pools/floatingippools-list-resp.xml', 'doc/api_samples/os-admin-actions/admin-actions-pause.xml', 'nova/tests/functional/api_samples/os-security-group-default-rules/security-group-default-rules-list-resp.xml.tpl', 'nova/tests/functional/api_samples/servers-list-resp.xml.tpl', 'doc/api_samples/OS-DCF/server-get-resp.xml', 'nova/tests/functional/api_samples/os-hosts/host-get-shutdown.xml.tpl', 'doc/api_samples/servers-list-resp.xml', 'nova/tests/functional/api_samples/all_extensions/flavor-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-group-quotas/quotas-update-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-external-events/server-post-resp.xml.tpl', 'doc/api_samples/OS-EXT-IPS-MAC/server-post-req.xml', 'nova/tests/functional/api_samples/server-action-revertresize.xml.tpl', 'doc/api_samples/OS-EXT-SRV-ATTR/server-post-req.xml', 'nova/tests/functional/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.xml.tpl', 'doc/api_samples/os-extended-evacuate-find-host/server-post-req.xml', 'doc/api_samples/os-simple-tenant-usage/server-post-req.xml', 'doc/api_samples/os-services/services-get-resp.xml', 'nova/tests/functional/api_samples/os-fping/server-post-req.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-unlock-server.xml', 'doc/api_samples/OS-EXT-STS/server-post-resp.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_server_attributes.py', 'nova/tests/functional/api_samples/os-block-device-mapping-v2-boot/server-post-req.xml.tpl', 'doc/api_samples/os-volumes/list-volume-attachments-resp.xml', 'nova/api/openstack/compute/schemas/v1.1/flavors.rng', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-entry-get-resp.xml.tpl', 'doc/api_samples/os-extended-services-delete/services-get-resp.xml', 'nova/tests/functional/api_samples/os-agents/agent-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-networks/network-create-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-services-delete/services-get-resp.xml.tpl', 'doc/api_samples/os-config-drive/server-config-drive-get-resp.xml', 'doc/api_samples/os-extended-networks/network-create-req.xml', 'nova/tests/functional/api_samples/os-volumes/os-volumes-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/volume-attachment-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/images-list-get-resp.xml.tpl', 'doc/api_samples/OS-EXT-AZ/server-get-resp.xml', 'doc/api_samples/os-security-groups/security-group-add-post-req.xml', 'doc/api_samples/server-metadata-all-resp.xml', 'doc/api_samples/os-admin-actions/admin-actions-lock-server.xml', 'nova/tests/functional/api_samples/os-config-drive/servers-config-drive-details-resp.xml.tpl', 'nova/tests/functional/test_xml.py', 'doc/api_samples/images-details-get-resp.xml', 'nova/tests/functional/api_samples/os-console-output/console-output-post-resp.xml.tpl', 'doc/api_samples/os-services/service-disable-put-req.xml', 'nova/tests/functional/api_samples/NMN/server-post-resp.xml.tpl', 'doc/api_samples/os-deferred-delete/server-post-req.xml', 'doc/api_samples/all_extensions/server-action-rebuild.xml', 'nova/tests/functional/api_samples/OS-EXT-IPS-MAC/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-consoles/get-rdp-console-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-user-quotas/user-quotas-update-post-req.xml.tpl', 'doc/api_samples/os-agents/agent-post-req.xml', 'doc/api_samples/os-consoles/get-serial-console-post-req.xml', 'nova/tests/functional/api_samples/os-server-external-events/event-create-resp.xml.tpl', 'doc/api_samples/server-action-rebuild.xml', 'nova/tests/functional/api_samples/all_extensions/server-action-revertresize.xml.tpl', 'nova/tests/functional/api_samples/server-metadata-resp.xml.tpl', 'doc/api_samples/OS-SRV-USG/server-post-resp.xml', 'nova/tests/functional/api_samples/os-flavor-swap/flavor-swap-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-swap/flavor-swap-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-shelve/os-unshelve.xml.tpl', 'doc/api_samples/OS-EXT-AZ/servers-detail-resp.xml', 'nova/tests/functional/api_samples/os-security-groups/security-groups-list-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-evacuate-find-host/server-evacuate-find-host-req.xml.tpl', 'nova/api/openstack/compute/schemas/v1.1/flavor.rng', 'doc/api_samples/os-admin-actions/admin-actions-reset-server-state.xml', 'nova/tests/functional/api_samples/os-virtual-interfaces/server-post-resp.xml.tpl', 'doc/api_samples/os-keypairs/keypairs-list-resp.xml', 'doc/api_samples/image-get-resp.xml', 'nova/tests/functional/api_samples/os-used-limits/usedlimits-get-resp.xml.tpl', 'nova/tests/functional/api_samples/server-action-resize.xml.tpl', 'doc/api_samples/os-security-group-default-rules/security-group-default-rules-show-resp.xml', 'nova/tests/unit/api/openstack/compute/contrib/test_server_password.py', 'nova/tests/functional/api_samples/os-cell-capacities/cells-capacities-resp.xml.tpl', 'nova/tests/functional/api_samples/os-config-drive/server-config-drive-get-resp.xml.tpl', 'doc/api_samples/OS-EXT-IPS/server-get-resp.xml', 'doc/api_samples/os-volumes/os-volumes-get-resp.xml', 'doc/api_samples/os-aggregates/aggregates-metadata-post-resp.xml', 'doc/api_samples/os-volume-attachment-update/server-post-req.xml', 'nova/tests/functional/api_samples/os-agents/agent-update-put-req.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/valid/empty.xml', 'nova/tests/functional/api_samples/OS-EXT-VIF-NET/server-post-resp.xml.tpl', 'doc/api_samples/os-hosts/hosts-list-resp.xml', 'nova/tests/functional/api_samples/os-agents/agents-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-keypairs/keypairs-post-req.xml.tpl', 'doc/api_samples/os-security-groups/security-groups-get-resp.xml', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-entry-resp.xml', 'doc/api_samples/os-quota-class-sets/quota-classes-update-post-resp.xml', 'nova/tests/functional/api_samples/OS-DCF/server-update-put-resp.xml.tpl', 'nova/tests/functional/api_samples/os-evacuate/server-evacuate-req.xml.tpl', 'doc/api_samples/os-floating-ips/floating-ips-list-empty-resp.xml', 'doc/api_samples/os-volume-attachment-update/update-volume-req.xml', 'nova/tests/functional/api_samples/os-hide-server-addresses/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-server-start-stop/server-post-resp.xml.tpl', 'doc/api_samples/os-server-password/get-password-resp.xml', 'nova/tests/functional/api_samples/os-security-groups/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-IPS-MAC/server-post-resp.xml.tpl', 'doc/api_samples/os-server-start-stop/server_start_stop.xml', 'doc/api_samples/os-used-limits/usedlimits-get-resp.xml', 'nova/tests/functional/api_samples/images-details-get-resp.xml.tpl', 'doc/api_samples/os-server-external-events/server-post-resp.xml', 'doc/api_samples/OS-FLV-DISABLED/flavor-show-get-resp.xml', 'doc/api_samples/os-volumes/snapshots-detail-resp.xml', 'nova/api/openstack/compute/schemas/v1.1/metadata.rng', 'nova/tests/functional/api_samples/OS-EXT-VIF-NET/vifs-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-evacuate-find-host/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-quota-class-sets/quota-classes-show-get-resp.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-suspend.xml', 'nova/tests/functional/api_samples/os-multiple-create/multiple-create-post-req.xml.tpl', 'doc/api_samples/NMN/server-post-resp.xml', 'nova/tests/functional/api_samples/os-attach-interfaces/server-post-resp.xml.tpl', 'doc/api_samples/os-services/service-enable-put-resp.xml', 'doc/api_samples/os-server-list-multi-status/server-post-resp.xml', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-remove-tenant-resp.xml.tpl', 'doc/api_samples/os-services/service-disable-log-put-req.xml', 'nova/tests/functional/api_samples/os-deferred-delete/force-delete-post-req.xml.tpl', 'doc/api_samples/os-flavor-rxtx/flavor-rxtx-post-req.xml', 'doc/api_samples/all_extensions/servers-list-resp.xml', 'doc/api_samples/os-virtual-interfaces/server-post-resp.xml', 'nova/tests/functional/api_samples/os-hide-server-addresses/servers-list-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-post-resp.xml.tpl', 'doc/api_samples/os-quota-sets/quotas-update-post-req.xml', 'nova/tests/functional/api_samples/os-server-group-quotas/quota-classes-update-post-resp.xml.tpl', 'doc/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.xml', 'doc/api_samples/os-rescue/server-post-req.xml', 'doc/api_samples/os-availability-zone/availability-zone-post-req.xml', 'doc/api_samples/os-console-auth-tokens/get-console-connect-info-get-resp.xml', 'nova/tests/functional/api_samples/server-action-changepassword.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-create-or-update-entry-resp.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ip-pools/floatingippools-list-resp.xml.tpl', 'nova/tests/functional/api_samples/image-metadata-put-req.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips/floating-ips-create-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-manage/flavor-create-post-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-AZ/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/flavor-get-resp.xml.tpl', 'nova/tests/functional/api_samples/image-metadata-post-resp.xml.tpl', 'doc/api_samples/images-list-get-resp.xml', 'nova/tests/functional/api_samples/os-flavor-extra-specs/flavor-extra-specs-create-resp.xml.tpl', 'nova/tests/functional/api_samples/os-security-group-default-rules/security-group-default-rules-show-resp.xml.tpl', 'doc/api_samples/os-hide-server-addresses/server-post-req.xml', 'doc/api_samples/os-volumes/snapshots-show-resp.xml', 'doc/api_samples/os-certificates/certificate-create-req.xml', 'nova/tests/functional/api_samples/os-availability-zone/availability-zone-post-req.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-migrate.xml', 'doc/api_samples/os-flavor-extra-specs/flavor-extra-specs-update-resp.xml', 'nova/tests/functional/api_samples/os-fping/fping-get-details-resp.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-reset-state.xml', 'doc/api_samples/os-hide-server-addresses/server-post-resp.xml', 'doc/api_samples/os-instance-actions/instance-action-get-resp.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-lock-server.xml.tpl', 'doc/api_samples/os-fping/server-post-req.xml', 'doc/api_samples/os-tenant-networks/networks-post-req.xml', 'doc/api_samples/os-attach-interfaces/attach-interfaces-list.xml', 'doc/api_samples/os-volumes/snapshot-create-resp.xml', 'doc/api_samples/os-security-group-default-rules/security-group-default-rules-create-resp.xml', 'nova/tests/functional/api_samples/server-metadata-req.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-extra-specs/flavor-extra-specs-update-resp.xml.tpl', 'doc/api_samples/os-server-group-quotas/quota-classes-update-post-req.xml', 'doc/api_samples/os-security-groups/security-groups-create-resp.xml', 'doc/api_samples/os-shelve/server-post-resp.xml', 'doc/api_samples/os-baremetal-nodes/baremetal-node-list-resp.xml', 'doc/api_samples/os-assisted-volume-snapshots/snapshot-create-assisted-req.xml', 'doc/api_samples/os-extended-networks/networks-list-resp.xml', 'doc/api_samples/os-extended-floating-ips/floating-ips-list-resp.xml', 'doc/api_samples/images-list-resp.xml', 'doc/api_samples/os-baremetal-nodes/baremetal-node-create-req.xml', 'nova/tests/functional/api_samples/os-quota-class-sets/quota-classes-update-post-resp.xml.tpl', 'doc/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-post-req.xml', 'nova/api/openstack/compute/schemas/atom.rng', 'doc/api_samples/os-attach-interfaces/server-post-req.xml', 'doc/api_samples/os-extended-floating-ips/floating-ips-list-empty-resp.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-inject-network-info.xml.tpl', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-live-migrate.xml.tpl', 'nova/tests/functional/api_samples/os-volumes/snapshots-show-resp.xml.tpl', 'nova/tests/functional/api_samples/os-security-groups/server-security-groups-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-quotas/quotas-update-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-networks-associate/network-associate-host-req.xml.tpl', 'doc/api_samples/os-config-drive/server-post-req.xml', 'nova/tests/functional/api_samples/os-volumes/snapshots-detail-resp.xml.tpl', 'doc/api_samples/os-config-drive/servers-config-drive-details-resp.xml', 'nova/tests/functional/api_samples/os-consoles/get-vnc-console-post-resp.xml.tpl', 'doc/api_samples/OS-EXT-STS/server-post-req.xml', 'nova/tests/functional/api_samples/os-security-group-default-rules/security-group-default-rules-create-resp.xml.tpl', 'nova/tests/functional/api_samples/os-volume-attachment-update/server-post-resp.xml.tpl', 'doc/api_samples/servers-details-resp.xml', 'doc/api_samples/os-consoles/get-rdp-console-post-resp.xml', 'nova/tests/functional/api_samples/all_extensions/servers-details-resp.xml.tpl', 'doc/api_samples/os-server-sort-keys/server-sort-keys-list-resp.xml', 'doc/api_samples/os-flavor-swap/flavor-swap-get-resp.xml', 'nova/api/openstack/compute/schemas/v1.1/extensions.rng', 'nova/tests/functional/api_samples/OS-FLV-EXT-DATA/flavors-extra-data-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-tenant-networks/networks-post-req.xml.tpl', 'doc/api_samples/os-admin-actions/admin-actions-reset-network.xml', 'doc/api_samples/os-server-group-quotas/quotas-show-get-resp.xml', 'doc/api_samples/os-flavor-extra-specs/flavor-extra-specs-create-resp.xml', 'doc/api_samples/os-baremetal-nodes/baremetal-node-create-with-address-req.xml', 'nova/tests/functional/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.xml.tpl', 'doc/api_samples/OS-EXT-STS/server-get-resp.xml', 'nova/tests/functional/api_samples/os-networks-associate/network-disassociate-host-req.xml.tpl', 'doc/api_samples/OS-EXT-IPS/server-post-resp.xml', 'nova/tests/functional/api_samples/os-shelve/os-shelve-offload.xml.tpl', 'doc/api_samples/os-deferred-delete/restore-post-req.xml', 'doc/api_samples/os-security-group-default-rules/security-group-default-rules-create-req.xml', 'nova/tests/functional/api_samples/os-server-start-stop/server_start_stop.xml.tpl', 'doc/api_samples/os-floating-ips-bulk/floating-ips-bulk-list-resp.xml', 'nova/tests/functional/api_samples/server-action-createimage.xml.tpl', 'doc/api_samples/os-security-groups/server-security-groups-list-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-AZ/servers-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-remove-tenant-req.xml.tpl', 'nova/tests/functional/api_samples/os-floating-ips/floating-ips-create-req.xml.tpl', 'doc/api_samples/server-action-changepassword.xml', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/servers/valid/full.xml', 'doc/api_samples/server-action-createimage.xml', 'nova/tests/functional/api_samples/os-services/service-disable-put-resp.xml.tpl', 'nova/tests/functional/api_samples/os-keypairs/keypairs-import-post-resp.xml.tpl', 'doc/api_samples/os-hide-server-addresses/servers-list-resp.xml', 'nova/tests/functional/api_samples/os-admin-actions/admin-actions-pause.xml.tpl', 'doc/api_samples/server-action-resize.xml', 'doc/api_samples/all_extensions/server-action-rebuild-resp.xml', 'doc/api_samples/os-hypervisors/hypervisors-list-resp.xml', 'doc/api_samples/all_extensions/server-post-resp.xml', 'nova/tests/functional/api_samples/os-instance-actions/instance-action-get-resp.xml.tpl', 'nova/tests/functional/api_samples/all_extensions/servers-list-resp.xml.tpl', 'doc/api_samples/os-flavor-access/flavor-access-remove-tenant-req.xml', 'doc/api_samples/os-extended-volumes/server-get-resp.xml', 'nova/tests/functional/api_samples/os-rescue/server-post-req.xml.tpl', 'nova/tests/functional/api_samples/os-server-external-events/event-create-req.xml.tpl', 'nova/tests/functional/api_samples/os-simple-tenant-usage/server-post-resp.xml.tpl', 'doc/api_samples/os-networks/network-show-resp.xml', 'nova/tests/functional/api_samples/OS-EXT-SRV-ATTR/server-post-req.xml.tpl', 'doc/api_samples/OS-DCF/image-get-resp.xml', 'doc/api_samples/OS-DCF/server-post-req.xml', 'nova/tests/functional/api_samples/os-cloudpipe/cloud-pipe-get-resp.xml.tpl', 'doc/api_samples/os-keypairs/keypairs-post-req.xml', 'nova/tests/functional/api_samples/server-action-reboot.xml.tpl', 'nova/tests/functional/api_samples/os-user-quotas/user-quotas-show-get-resp.xml.tpl', 'doc/api_samples/os-security-groups/server-post-req.xml', 'nova/tests/functional/api_samples/server-action-rebuild.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-extra-specs/flavor-extra-specs-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-tenant-networks/networks-post-res.xml.tpl', 'nova/tests/functional/api_samples/os-agents/agent-post-resp.xml.tpl', 'nova/tests/unit/api/openstack/test_wsgi.py', 'nova/tests/functional/api_samples/os-server-group-quotas/quotas-update-post-resp.xml.tpl', 'doc/api_samples/OS-EXT-SRV-ATTR/server-get-resp.xml', 'doc/api_samples/os-hypervisor-status/hypervisors-show-with-status-resp.xml', 'nova/tests/functional/api_samples/OS-SRV-USG/servers-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-hypervisors/hypervisors-uptime-resp.xml.tpl', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-show-resp.xml', 'doc/api_samples/os-extended-floating-ips/floating-ips-create-req.xml', 'nova/tests/functional/api_samples/os-console-auth-tokens/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-evacuate/server-evacuate-resp.xml.tpl', 'doc/api_samples/os-volumes/os-volumes-detail-resp.xml', 'doc/api_samples/image-metadata-post-resp.xml', 'doc/api_samples/os-simple-tenant-usage/simple-tenant-usage-get.xml', 'doc/api_samples/images-details-resp.xml', 'doc/api_samples/os-admin-actions/admin-actions-resume.xml', 'nova/tests/functional/api_samples/os-floating-ip-dns/floating-ip-dns-list-resp.xml.tpl', 'doc/api_samples/os-fping/server-post-resp.xml', 'nova/tests/functional/api_samples/os-extended-volumes/servers-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-virtual-interfaces/vifs-list-resp.xml.tpl', 'nova/tests/functional/api_samples/os-console-output/server-post-req.xml.tpl', 'doc/api_samples/image-meta-key-put-req.xml', 'doc/api_samples/os-floating-ip-dns/floating-ip-dns-list-resp.xml', 'doc/api_samples/os-consoles/get-spice-console-post-req.xml', 'nova/tests/functional/api_samples/OS-SRV-USG/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-DCF/server-action-rebuild-resp.xml.tpl', 'nova/tests/functional/api_samples/os-extended-evacuate-find-host/server-post-resp.xml.tpl', 'nova/tests/functional/api_samples/os-config-drive/server-post-resp.xml.tpl', 'doc/api_samples/os-rescue/server-rescue.xml', 'doc/api_samples/os-cells/cells-list-empty-resp.xml', 'nova/tests/functional/api_samples/os-extended-floating-ips/floating-ips-create-resp.xml.tpl', 'doc/api_samples/OS-DCF/list-servers-detail-get.xml', 'nova/tests/functional/api_samples/os-server-diagnostics/server-post-resp.xml.tpl', 'doc/api_samples/os-fixed-ips/fixedip-post-req.xml', 'nova/tests/functional/api_samples/os-availability-zone/availability-zone-post-resp.xml.tpl', 'doc/api_samples/os-flavor-swap/flavor-swap-list-resp.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregates-list-get-resp.xml.tpl', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-create-req.xml', 'nova/tests/functional/api_samples/server-ips-network-resp.xml.tpl', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-create-with-address-req.xml', 'nova/tests/functional/api_samples/all_extensions/server-get-resp.xml.tpl', 'nova/tests/functional/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild-resp.xml.tpl', 'nova/tests/functional/api_samples/os-multiple-create/multiple-create-post-resp.xml.tpl', 'doc/api_samples/all_extensions/server-action-changepassword.xml', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-list-resp.xml', 'doc/api_samples/os-volumes/os-volumes-post-resp.xml', 'doc/api_samples/NMN/multinic-add-fixed-ip-req.xml', 'nova/tests/functional/api_samples/os-aggregates/aggregates-add-host-post-resp.xml.tpl', 'doc/api_samples/OS-SCH-HNT/scheduler-hints-post-req.xml', 'doc/api_samples/os-console-output/console-output-post-req.xml', 'doc/api_samples/OS-SCH-HNT/scheduler-hints-post-resp.xml', 'nova/tests/functional/api_samples/server-post-req.xml.tpl', 'doc/api_samples/os-volumes/server-post-resp.xml', 'doc/api_samples/OS-EXT-VIF-NET/vifs-list-resp.xml', 'nova/tests/functional/api_samples/image-metadata-put-resp.xml.tpl', 'doc/api_samples/os-flavor-access/flavor-access-add-tenant-resp.xml', 'nova/api/openstack/compute/schemas/atom-link.rng', 'doc/api_samples/os-server-group-quotas/limit-get-resp.xml', 'doc/api_samples/os-cloudpipe/cloud-pipe-get-resp.xml', 'nova/tests/functional/api_samples/OS-FLV-DISABLED/flavor-show-get-resp.xml.tpl', 'doc/api_samples/os-baremetal-ext-status/baremetal-node-create-resp.xml', 'nova/tests/functional/api_samples/OS-DCF/image-get-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_server_usage.py', 'doc/api_samples/os-instance-actions/instance-actions-list-resp.xml', 'doc/api_samples/os-volumes/os-volumes-post-req.xml', 'nova/tests/functional/api_samples/os-flavor-swap/flavor-swap-get-resp.xml.tpl', 'nova/tests/functional/api_samples/OS-EXT-SRV-ATTR/servers-detail-resp.xml.tpl', 'nova/tests/functional/api_samples/os-flavor-access/flavor-access-list-resp.xml.tpl', 'nova/tests/unit/api/openstack/compute/schemas/v1.1/images/invalid/mixed.xml', 'nova/tests/functional/api_samples/os-floating-ips/floating-ips-list-resp.xml.tpl', 'doc/api_samples/os-flavor-manage/flavor-create-post-resp.xml', 'nova/tests/functional/api_samples/os-hosts/host-get-resp.xml.tpl', 'doc/api_samples/OS-SRV-USG/servers-detail-resp.xml', 'doc/api_samples/OS-EXT-IPS/server-post-req.xml', 'nova/tests/functional/api_samples/NMN/multinic-remove-fixed-ip-req.xml.tpl', 'doc/api_samples/os-cells/cells-list-resp.xml', 'doc/api_samples/NMN/multinic-remove-fixed-ip-req.xml']",937,6b1a3bbb40dbb03123a9041c7455488a6cfab094,nuke-xml,,<removeFixedIp> <address>10.0.0.2</address> </removeFixedIp> ,18,13647
openstack%2Fironic-specs~master~Ia5180aa44d6b2967d4843b8ab176915181e5e77f,openstack/ironic-specs,master,Ia5180aa44d6b2967d4843b8ab176915181e5e77f,Check that filename is same as blueprint name,MERGED,2015-01-05 23:07:58.000000000,2015-01-06 19:57:32.000000000,2015-01-06 19:57:31.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10342}]","[{'number': 1, 'created': '2015-01-05 23:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/90bd03757d461015731a66ab402db492f7226a7a', 'message': 'Make sure the filename is the same as the blueprint name\n\nThe template was updated to indicate that the filename of the specification\nmust match the name of the blueprint, and that the title of the specification\ncould be the title of the blueprint.\n\nA unit test was added to check the filename against the blueprint name.\n\nChange-Id: Ia5180aa44d6b2967d4843b8ab176915181e5e77f\n'}, {'number': 2, 'created': '2015-01-06 02:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/532c74d531508fc3ea45c8d56ed60a026833f796', 'message': 'Make sure the filename is the same as the blueprint name\n\nThe template was updated to indicate that the filename of the specification\nmust match the name of the blueprint, and that the title of the specification\ncould be the title of the blueprint.\n\nA unit test was added to check the filename against the blueprint name.\n\nFixed a typo in one of the unit tests.\n\nChange-Id: Ia5180aa44d6b2967d4843b8ab176915181e5e77f\n'}, {'number': 3, 'created': '2015-01-06 18:09:07.000000000', 'files': ['tests/test_titles.py', 'specs/template.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9110d19447e7fcd5412dcddff611fadf39e06d5d', 'message': ""Check that filename is same as blueprint name\n\nThe template was updated to indicate that the filename of the\nspecification must match the name of the blueprint (changed the\nname of the sample blueprint be 'template' to match template.rst),\nand that the title of the specification could be the title of the\nblueprint.\n\nA unit test was added to check the filename against the blueprint name.\n\nFixed a typo in one of the unit tests.\n\nChange-Id: Ia5180aa44d6b2967d4843b8ab176915181e5e77f\n""}]",1,145088,9110d19447e7fcd5412dcddff611fadf39e06d5d,20,4,3,6618,,,0,"Check that filename is same as blueprint name

The template was updated to indicate that the filename of the
specification must match the name of the blueprint (changed the
name of the sample blueprint be 'template' to match template.rst),
and that the title of the specification could be the title of the
blueprint.

A unit test was added to check the filename against the blueprint name.

Fixed a typo in one of the unit tests.

Change-Id: Ia5180aa44d6b2967d4843b8ab176915181e5e77f
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/88/145088/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_titles.py', 'specs/template.rst']",2,90bd03757d461015731a66ab402db492f7226a7a,bp/name,"====================================================== Title of Example Spec - eg The title of your blueprint ====================================================== The title of your specification could be the same as the title of your blueprint, but it doesn't have to be.* The filename in the git repository must match the launchpad URL, for must be named awesome-thing.rst","========================================== Example Spec - The title of your blueprint ==========================================* The filename in the git repository should match the launchpad URL, for should be named awesome-thing.rst",38,6
openstack%2Foslo.log~master~I67b31f666172451fd6b061520b0f171ec8e7387b,openstack/oslo.log,master,I67b31f666172451fd6b061520b0f171ec8e7387b,Implement resource to logging extra keywords,MERGED,2015-01-03 00:14:14.000000000,2015-01-06 19:53:58.000000000,2015-01-06 19:53:56.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-03 00:14:14.000000000', 'files': ['oslo_log/tests/unit/test_log.py', 'oslo_log/formatters.py', 'oslo_log/log.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/9bed7ae402becbf4e67ad7757a43b1f842f103b9', 'message': 'Implement resource to logging extra keywords\n\nCleaning up log messages and thought it\nwould be useful to make it ""easier"" to log the\nvolume/snapshot/backup/image id\'s more easily.\n\nUnlike the Nova Instance work that was submitted this\nkey will work with any db ref object that has a ""name""\nmember.  Most OpenStack objects have an internal name\nthat is built using the UUID of the resource object.\nResource objects in Cinder for example use:\n  ""<resourceName-uuid>""\n\nFor those that don\'t have the name member, we also\ngive the ability to set resource as a dict, with\nkeys \'type\' and \'id\' that will form the same string.\n\nWith this change, LOG calls in projects can be sent like:\n  LOG.info(_LI(\'begin some operation\'), resource=dbref)\nor\n  LOG.info(_LI(\'begin some operation\'), resource=\n           mydict{\'type\': \'volume\',\n                  \'id\': \'40e0f194-0ccb-422f-a543-c5f9022acb6f\')\n\nThe result will be the resource identifier prepended to the msg:\n\n  INFO cinder.volume.manager [-]\\\n  [volume-40e0f194-0ccb-422f-a543-c5f9022acb6f] \\\n  succesfully deleted volume\n\nThis will be in addition to work being done to put the same info in context,\nthen we\'ll automatically pick this info up from context if it\'s there but still\nallow it to be overridden with the extra keys in this change.\n\nChange-Id: I67b31f666172451fd6b061520b0f171ec8e7387b\nPartially-Implements: blueprint app-agnostic-logging-parameters\n'}]",1,144813,9bed7ae402becbf4e67ad7757a43b1f842f103b9,7,3,1,2243,,,0,"Implement resource to logging extra keywords

Cleaning up log messages and thought it
would be useful to make it ""easier"" to log the
volume/snapshot/backup/image id's more easily.

Unlike the Nova Instance work that was submitted this
key will work with any db ref object that has a ""name""
member.  Most OpenStack objects have an internal name
that is built using the UUID of the resource object.
Resource objects in Cinder for example use:
  ""<resourceName-uuid>""

For those that don't have the name member, we also
give the ability to set resource as a dict, with
keys 'type' and 'id' that will form the same string.

With this change, LOG calls in projects can be sent like:
  LOG.info(_LI('begin some operation'), resource=dbref)
or
  LOG.info(_LI('begin some operation'), resource=
           mydict{'type': 'volume',
                  'id': '40e0f194-0ccb-422f-a543-c5f9022acb6f')

The result will be the resource identifier prepended to the msg:

  INFO cinder.volume.manager [-]\
  [volume-40e0f194-0ccb-422f-a543-c5f9022acb6f] \
  succesfully deleted volume

This will be in addition to work being done to put the same info in context,
then we'll automatically pick this info up from context if it's there but still
allow it to be overridden with the extra keys in this change.

Change-Id: I67b31f666172451fd6b061520b0f171ec8e7387b
Partially-Implements: blueprint app-agnostic-logging-parameters
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/13/144813/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/formatters.py', 'oslo_log/tests/unit/test_log.py', 'oslo_log/log.py']",3,9bed7ae402becbf4e67ad7757a43b1f842f103b9,bp/app-agnostic-logging-parameters," # NOTE(jdg): We would like an easy way to add resource info # to logging, for example a header like 'volume-<uuid>' # Turns out Nova implemented this but it's Nova specific with # instance. Also there's resource_uuid that's been added to # context, but again that only works for Instances, and it # only works for contexts that have the resource id set. resource = kwargs['extra'].get('resource', None) if resource: # Many OpenStack resources have a name entry in their db ref # of the form <resource_type>-<uuid>, let's just use that if # it's passed in if not resource.get('name', None): # For resources that don't have the name of the format we wish # to use (or places where the LOG call may not have the full # object ref, allow them to pass in a dict: # resource={resource_type: volume, resource_id: uuid} resource_type = resource.get('type', None) resource_id = resource.get('id', None) if resource_type and resource_id: kwargs['extra']['resource'] = ('[' + resource_type + '-' + resource_id + '] ') else: # FIXME(jdg): Since the name format can be specified via conf # entry, we may want to consider allowing this to be configured # here as well kwargs['extra']['resource'] = ('[' + resource.get('name', '') + '] ') ",,57,1
openstack%2Fpython-novaclient~master~I5e1ce2ab3ac60dc637c4416cbe1be088230c07b6,openstack/python-novaclient,master,I5e1ce2ab3ac60dc637c4416cbe1be088230c07b6,Document unexpected need for --all-tenants when using --tenant,MERGED,2015-01-06 14:36:39.000000000,2015-01-06 19:53:27.000000000,2015-01-06 19:53:26.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1192}, {'_account_id': 1849}]","[{'number': 1, 'created': '2015-01-06 14:36:39.000000000', 'files': ['novaclient/v1_1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/7bced6673c19c69ab7ab190084162dede416a9fb', 'message': 'Document unexpected need for --all-tenants when using --tenant\n\nThis behavior was changed in v3 but that is now obsolete.\n\nChange-Id: I5e1ce2ab3ac60dc637c4416cbe1be088230c07b6\nRelated-Bug: #1185290\n'}]",2,145236,7bced6673c19c69ab7ab190084162dede416a9fb,8,4,1,1192,,,0,"Document unexpected need for --all-tenants when using --tenant

This behavior was changed in v3 but that is now obsolete.

Change-Id: I5e1ce2ab3ac60dc637c4416cbe1be088230c07b6
Related-Bug: #1185290
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/36/145236/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/shell.py'],1,7bced6673c19c69ab7ab190084162dede416a9fb,single-tenant-docstring, help=_('Display information from single tenant (Admin only). ' 'The --all-tenants option must also be provided.')), help=_('Display information from single tenant (Admin only).')),2,1
openstack%2Fpython-cinderclient~master~I477baa7642feba72f80d884d6183512185b02cf1,openstack/python-cinderclient,master,I477baa7642feba72f80d884d6183512185b02cf1,Fix incorrect variable name,MERGED,2014-10-27 14:39:35.000000000,2015-01-06 19:52:01.000000000,2015-01-06 19:52:00.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 7111}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 11600}, {'_account_id': 12927}]","[{'number': 1, 'created': '2014-10-27 14:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/5d4ff2ba04fdba4e58693d3ebbd5a6918af9da69', 'message': 'Fix incorrect variable name\n\nvalid_versions does not exist here, it is obviously supposed to mean\n_VALID_VERSIONS.\n\nChange-Id: I477baa7642feba72f80d884d6183512185b02cf1\n'}, {'number': 2, 'created': '2014-10-27 14:41:54.000000000', 'files': ['cinderclient/client.py', 'cinderclient/tests/test_client.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/384b8825b485d4918f15713212d9e5d64eef2682', 'message': 'Fix incorrect variable name\n\nvalid_versions does not exist here, it is obviously supposed to mean\n_VALID_VERSIONS.\n\nCloses-Bug: #1386232\nChange-Id: I477baa7642feba72f80d884d6183512185b02cf1\n'}]",0,131163,384b8825b485d4918f15713212d9e5d64eef2682,22,10,2,7191,,,0,"Fix incorrect variable name

valid_versions does not exist here, it is obviously supposed to mean
_VALID_VERSIONS.

Closes-Bug: #1386232
Change-Id: I477baa7642feba72f80d884d6183512185b02cf1
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/63/131163/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/client.py', 'cinderclient/tests/test_client.py']",2,5d4ff2ba04fdba4e58693d3ebbd5a6918af9da69,valid-versions," def test_versions(self): v1_url = 'http://fakeurl/v1/tenants' v2_url = 'http://fakeurl/v2/tenants' unknown_url = 'http://fakeurl/v9/tenants' self.assertEqual('1', cinderclient.client.get_volume_api_from_url(v1_url)) self.assertEqual('2', cinderclient.client.get_volume_api_from_url(v2_url)) self.assertRaises(cinderclient.exceptions.UnsupportedVersion, cinderclient.client.get_volume_api_from_url, unknown_url)",,14,1
openstack%2Fmagnum~master~I7cb103e5370f1c367b20272918314231e65f35e7,openstack/magnum,master,I7cb103e5370f1c367b20272918314231e65f35e7,Add some comments for delete logic in bay_create,MERGED,2015-01-06 05:12:11.000000000,2015-01-06 19:46:57.000000000,2015-01-06 19:46:56.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-06 05:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b965ba3697507cea92f41a825f9898e7daeec9fe', 'message': 'Add some comments for delete logic in bay_create\n\nThis patch is adding some comments for why adding delete logic\nin bay_create for bay_k8s_heat.py\n\nChange-Id: I7cb103e5370f1c367b20272918314231e65f35e7\n'}, {'number': 2, 'created': '2015-01-06 06:07:51.000000000', 'files': ['magnum/conductor/handlers/bay_k8s_heat.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/bd8b58614bf7f39714230af4ab5d264ece627355', 'message': 'Add some comments for delete logic in bay_create\n\nThis patch is adding some comments for why adding delete logic\nin bay_create for bay_k8s_heat.py\n\nCloses-Bug: #1407832\n\nChange-Id: I7cb103e5370f1c367b20272918314231e65f35e7\n'}]",0,145127,bd8b58614bf7f39714230af4ab5d264ece627355,11,3,2,7494,,,0,"Add some comments for delete logic in bay_create

This patch is adding some comments for why adding delete logic
in bay_create for bay_k8s_heat.py

Closes-Bug: #1407832

Change-Id: I7cb103e5370f1c367b20272918314231e65f35e7
",git fetch https://review.opendev.org/openstack/magnum refs/changes/27/145127/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/bay_k8s_heat.py'],1,b965ba3697507cea92f41a825f9898e7daeec9fe,master," # poll_and_check is detached and polling long time to check status, # so another user/client can call delete bay/stack. return None ", return None,3,1
openstack%2Fmagnum~master~I913ff2be4754540e6d1e1f6f267c7cb356f707e8,openstack/magnum,master,I913ff2be4754540e6d1e1f6f267c7cb356f707e8,Adjusted README to add ReplicationController,MERGED,2015-01-06 16:53:28.000000000,2015-01-06 19:41:22.000000000,2015-01-06 19:41:21.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-06 16:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1ef373b7ca7afa7bd1a564b36721c0bcb2cf48cf', 'message': 'Adjusted README to add ReplicationController\n\nChange-Id: I913ff2be4754540e6d1e1f6f267c7cb356f707e8\n'}, {'number': 2, 'created': '2015-01-06 16:55:15.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b7905c76c484d16e5e5c4b893c5e6c2d3bf542a4', 'message': 'Adjusted README to add ReplicationController\n\nChange-Id: I913ff2be4754540e6d1e1f6f267c7cb356f707e8\n'}]",0,145265,b7905c76c484d16e5e5c4b893c5e6c2d3bf542a4,8,3,2,668,,,0,"Adjusted README to add ReplicationController

Change-Id: I913ff2be4754540e6d1e1f6f267c7cb356f707e8
",git fetch https://review.opendev.org/openstack/magnum refs/changes/65/145265/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1ef373b7ca7afa7bd1a564b36721c0bcb2cf48cf,,There are seven different types of objects in the Magnum system:* ReplicationController: An abstraction for grouping PODs,There are six different types of objects in the Magnum system:,2,1
openstack%2Foslo.log~master~I15163f1dd12713c71d42efdb128f8d12ec5dc307,openstack/oslo.log,master,I15163f1dd12713c71d42efdb128f8d12ec5dc307,Correct the position of the syslog handler,MERGED,2014-12-04 07:25:49.000000000,2015-01-06 19:41:15.000000000,2015-01-06 19:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6983}, {'_account_id': 13527}]","[{'number': 1, 'created': '2014-12-04 07:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/101beef5f09d00a0f0eb9d583249645271e7d074', 'message': 'Correct the position of the syslog handler\n\nCorrect the position of the syslog handler,\nthen the syslog handler can have same settings with\nother handlers.\n\nChange-Id: I15163f1dd12713c71d42efdb128f8d12ec5dc307\nCloses-Bug: #1399088\n'}, {'number': 2, 'created': '2014-12-20 08:01:34.000000000', 'files': ['oslo_log/log.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/250315b7b22bf348af1f36965fdae6a38c9d5f57', 'message': 'Correct the position of the syslog handler\n\nCorrect the position of the syslog handler,\nthen the syslog handler can have same settings with\nother handlers.\n\nChange-Id: I15163f1dd12713c71d42efdb128f8d12ec5dc307\nCloses-Bug: #1399088\n'}]",0,138971,250315b7b22bf348af1f36965fdae6a38c9d5f57,17,5,2,6983,,,0,"Correct the position of the syslog handler

Correct the position of the syslog handler,
then the syslog handler can have same settings with
other handlers.

Change-Id: I15163f1dd12713c71d42efdb128f8d12ec5dc307
Closes-Bug: #1399088
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/71/138971/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo/log/log.py'],1,101beef5f09d00a0f0eb9d583249645271e7d074,bug/1399088, if conf.use_syslog: try: facility = _find_facility_from_conf(conf) # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if conf.use_syslog_rfc_format: syslog = handlers.RFCSysLogHandler(facility=facility) else: syslog = logging.handlers.SysLogHandler(facility=facility) log_root.addHandler(syslog) except socket.error: log_root.error('Unable to add syslog handler. Verify that syslog ' 'is running.') , if conf.use_syslog: try: facility = _find_facility_from_conf(conf) # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if conf.use_syslog_rfc_format: syslog = handlers.RFCSysLogHandler(facility=facility) else: syslog = logging.handlers.SysLogHandler(facility=facility) log_root.addHandler(syslog) except socket.error: log_root.error('Unable to add syslog handler. Verify that syslog ' 'is running.') ,14,15
openstack%2Fneutron~master~Iaa9b475a4294db96a9645829d362e090b61ed3a2,openstack/neutron,master,Iaa9b475a4294db96a9645829d362e090b61ed3a2,Check metadata iptables chains during functional test,MERGED,2014-11-26 14:43:32.000000000,2015-01-06 18:53:33.000000000,2015-01-06 15:59:32.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-11-26 14:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/805cb50895585b22a4770624fca05390deaf5cfe', 'message': 'Check metadata iptables chains during functional test\n\nThe L3 agent functional test creates a router and asserts that\nthe proxy process is up. It will now also check that the NAT\nand filter rules were added via the iptables manager.\n\nThis is to allow us to move the metadata management out of the\nL3 agent and into its own L3 agent driver.\n\nChange-Id: Iaa9b475a4294db96a9645829d362e090b61ed3a2\nPartially-implements: blueprint restructure-l3-agent\n'}, {'number': 2, 'created': '2014-11-26 16:08:29.000000000', 'files': ['neutron/agent/linux/iptables_manager.py', 'neutron/tests/functional/agent/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/24a703c386764e0b478d6113fb51316ddf3c089f', 'message': 'Check metadata iptables chains during functional test\n\nThe L3 agent functional test creates a router and asserts that\nthe proxy process is up. It will now also check that the NAT\nand filter rules were added via the iptables manager.\n\nThis is to allow us to move the metadata management out of the\nL3 agent and into its own L3 agent driver.\n\nChange-Id: Iaa9b475a4294db96a9645829d362e090b61ed3a2\nPartially-implements: blueprint restructure-l3-agent\n'}]",7,137368,24a703c386764e0b478d6113fb51316ddf3c089f,64,28,2,8873,,,0,"Check metadata iptables chains during functional test

The L3 agent functional test creates a router and asserts that
the proxy process is up. It will now also check that the NAT
and filter rules were added via the iptables manager.

This is to allow us to move the metadata management out of the
L3 agent and into its own L3 agent driver.

Change-Id: Iaa9b475a4294db96a9645829d362e090b61ed3a2
Partially-implements: blueprint restructure-l3-agent
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/137368/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_manager.py', 'neutron/tests/functional/agent/test_l3_agent.py']",2,805cb50895585b22a4770624fca05390deaf5cfe,bp/restructure-l3-agent," self._assert_metadata_chains(router) def _get_rule(self, iptables_manager, table, chain, predicate): rules = iptables_manager.get_chain(table, chain) result = next(rule for rule in rules if predicate(rule)) return result def _assert_metadata_chains(self, router): metadata_port_filter = lambda rule: rule.rule.find( str(self.agent.conf.metadata_port)) != -1 self.assertTrue(self._get_rule(router.iptables_manager, 'nat', 'PREROUTING', metadata_port_filter)) self.assertTrue(self._get_rule(router.iptables_manager, 'filter', 'INPUT', metadata_port_filter)) ",,24,6
openstack%2Fpython-manilaclient~master~Idd4d5f6c7aff0cc67853b46774d567ded10bcded,openstack/python-manilaclient,master,Idd4d5f6c7aff0cc67853b46774d567ded10bcded,Sync the oslo commom exceptions file to resolve detailed error message,MERGED,2014-12-22 07:10:19.000000000,2015-01-06 18:46:54.000000000,2015-01-06 18:46:52.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 13634}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-22 07:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/7ed4c57b2c71e5a30aa2cb9d1ad63276c109045e', 'message': 'Show detailed CLI forbidden message while deleting share with snapshots\n\nWhen we try to delete share that has dependent snapshots we get expected\nerror:[403. Forbidden].But we do not have proper description why it is\nforbidden.\n\nThe patch of Bug1400816 gives the detailed message in the http response,\nbut the client does not show it to cli user.So this patch does it.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 2, 'created': '2014-12-23 06:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/829bd4c1ba375d7ac30a8225cc91727d50914823', 'message': 'Show detailed CLI forbidden message while deleting share with snapshots\n\nWhen we try to delete share that has dependent snapshots we get expected\nerror:[403. Forbidden].But we do not have proper description why it is\nforbidden.\n\nThe patch(https://review.openstack.org/#/c/141768/3) gives the detailed\nmessage in the http response,but manila client can not show it to cli user.\n\nThis patch does:\n*Update the file ""openstack/common/apiclient/exceptions.py"" from olso to\nget the detailed message.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 3, 'created': '2014-12-23 07:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4547952d4539181d0f2f6c49a67bb6945377f73f', 'message': 'Update the exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use now cannot resolve all the detailed error message from http response.  \n\nThis patch does:\n*Update the file ""openstack/common/apiclient/exceptions.py"" from olso to\nget the detailed message.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 4, 'created': '2014-12-23 07:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/e3873b66b2b0b5e05abb31ba9e512d7247eee9fd', 'message': 'Update the commom exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use now cannot\nresolve all the detailed error message from http response.\n\nThis patch does:\n*Update the file ""openstack/common/apiclient/exceptions.py"" from olso to\nget the detailed message.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 5, 'created': '2014-12-23 07:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/75f058dc9e4970afbb413cafead5bc79d5c11f05', 'message': 'Update the commom exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use cannot\nresolve all the detailed error message from http response.\n\nThis patch does:\n*Update the file ""openstack/common/apiclient/exceptions.py"" from oslo to\nget the detailed message.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 6, 'created': '2014-12-23 07:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/dcceb1c4629d3849519fcbbc15520893f3210646', 'message': 'Update the commom exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use cannot\nresolve all the detailed error message from http response.\n\nThis patch does:\n*Update the file ""openstack/common/apiclient/exceptions.py"" from oslo to\nget the detailed message.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 7, 'created': '2014-12-26 06:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/cc48ecf2a89ab17c28172f0262e3b7283fc770aa', 'message': 'Sync the oslo commom exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use cannot\nresolve all the detailed error message from http response.\n\nSync the file ""openstack/common/apiclient/exceptions.py"" from\noslo-incubator to get the detailed message.\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 8, 'created': '2014-12-31 03:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/9a3318bb1094f878323d3dc4c3752afee254a845', 'message': 'Sync the oslo commom exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use cannot\nresolve all the detailed error message from http response.\n\nSync the file ""openstack/common/apiclient/exceptions.py"" from\noslo-incubator to get the detailed message.\n\ncommit cbd3b358a7ccfb33ce6eca56a182d8b1288debb7\nMerge: 16bc436 317ec9c\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Tue Dec 23 23:24:11 2014 +0000\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}, {'number': 9, 'created': '2015-01-06 09:20:20.000000000', 'files': ['manilaclient/openstack/common/apiclient/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/92ef6273d2dd467ca359eb428270d8071fc674a7', 'message': 'Sync the oslo commom exceptions file to resolve detailed error message\n\nNow the file(openstack/common/apiclient/exceptions.py) we use cannot\nresolve all the detailed error message from http response.\n\nSync the file ""openstack/common/apiclient/exceptions.py"" from\noslo-incubator to get the detailed message.\n\ncommit c8d143bf942c34fc15678a61f5bcd5f460b280ac\nMerge: 103ebd5 80c4751\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Tue Jan 6 01:37:41 2015 +0000\n\nChange-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded\nCloses-Bug: #1404794\n'}]",7,143378,92ef6273d2dd467ca359eb428270d8071fc674a7,38,8,9,13634,,,0,"Sync the oslo commom exceptions file to resolve detailed error message

Now the file(openstack/common/apiclient/exceptions.py) we use cannot
resolve all the detailed error message from http response.

Sync the file ""openstack/common/apiclient/exceptions.py"" from
oslo-incubator to get the detailed message.

commit c8d143bf942c34fc15678a61f5bcd5f460b280ac
Merge: 103ebd5 80c4751
Author: Jenkins <jenkins@review.openstack.org>
Date:   Tue Jan 6 01:37:41 2015 +0000

Change-Id: Idd4d5f6c7aff0cc67853b46774d567ded10bcded
Closes-Bug: #1404794
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/78/143378/3 && git format-patch -1 --stdout FETCH_HEAD,['manilaclient/openstack/common/apiclient/exceptions.py'],1,7ed4c57b2c71e5a30aa2cb9d1ad63276c109045e,bug/1404794," if response.status_code == 403: kwargs[""message""] = response.json()[u'forbidden'][u'message'] ",,4,0
openstack%2Fopenstack-ansible~master~I003b3d07f599b8454247c94eaa56d0998b1f913f,openstack/openstack-ansible,master,I003b3d07f599b8454247c94eaa56d0998b1f913f,Adjust ordering of symlink creation for Horizon,MERGED,2015-01-05 14:48:04.000000000,2015-01-06 18:26:21.000000000,2015-01-06 18:26:20.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 7307}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-05 14:48:04.000000000', 'files': ['rpc_deployment/roles/horizon_common/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4f8917136f6a0d9f3571d8b4cb32bd48bd332272', 'message': 'Adjust ordering of symlink creation for Horizon\n\n* Move the symlink task to happen before the static files collection/compression task.\n\nChange-Id: I003b3d07f599b8454247c94eaa56d0998b1f913f\nCloses-Bug: 1407696\n'}]",0,144997,4f8917136f6a0d9f3571d8b4cb32bd48bd332272,9,5,1,2799,,,0,"Adjust ordering of symlink creation for Horizon

* Move the symlink task to happen before the static files collection/compression task.

Change-Id: I003b3d07f599b8454247c94eaa56d0998b1f913f
Closes-Bug: 1407696
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/97/144997/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/horizon_common/tasks/main.yml'],1,4f8917136f6a0d9f3571d8b4cb32bd48bd332272,bug/1407696," # /opt/horizon/lib/python2.7/site-packages/manage.py - name: Collect and compress static files command: ""{{ item }}"" sudo: yes sudo_user: ""{{ system_user }}"" with_items: - horizon-manage.py collectstatic --noinput - horizon-manage.py compress --force","# /opt/horizon/lib/python2.7/site-packages/manage.py - name: Collect and compress static files command: ""{{ item }}"" sudo: yes sudo_user: ""{{ system_user }}"" with_items: - horizon-manage.py collectstatic --noinput - horizon-manage.py compress --force ",9,9
openstack%2Fopenstack-ansible~master~Ia8d1f80e6631dd7dbe2bafe54ec62a34a603524a,openstack/openstack-ansible,master,Ia8d1f80e6631dd7dbe2bafe54ec62a34a603524a,Add newline to end of /etc/ssh/sshd_config,MERGED,2015-01-06 10:36:28.000000000,2015-01-06 18:26:10.000000000,2015-01-06 18:26:08.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-06 10:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3ffdea150eaa6f6a179cd30c731297070a9716c3', 'message': ""Add newline to end of /etc/ssh/sshd_config\n\nOn Rackspace cloud trusty image, /etc/ssh/sshd_config is missing a\ntrailing newline.  This is causing an issue w/ ansible when we append\nMaxSessions, as it doesn't end up putting it on a newline, resulting in\nsshd failing to restart.\n\nChange-Id: Ia8d1f80e6631dd7dbe2bafe54ec62a34a603524a\nCloses-Bug: #1407900\n""}, {'number': 2, 'created': '2015-01-06 13:10:21.000000000', 'files': ['scripts/os-ansible-aio-check.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f12970ee285101d95eeac921a0218af437a7f888', 'message': ""Add newline to end of /etc/ssh/sshd_config\n\nOn Rackspace cloud trusty image, /etc/ssh/sshd_config is missing a\ntrailing newline.  This is causing an issue w/ ansible when we append\nMaxSessions, as it doesn't end up putting it on a newline, resulting in\nsshd failing to restart.\n\nChange-Id: Ia8d1f80e6631dd7dbe2bafe54ec62a34a603524a\nCloses-Bug: #1407900\n""}]",1,145193,f12970ee285101d95eeac921a0218af437a7f888,14,6,2,7307,,,0,"Add newline to end of /etc/ssh/sshd_config

On Rackspace cloud trusty image, /etc/ssh/sshd_config is missing a
trailing newline.  This is causing an issue w/ ansible when we append
MaxSessions, as it doesn't end up putting it on a newline, resulting in
sshd failing to restart.

Change-Id: Ia8d1f80e6631dd7dbe2bafe54ec62a34a603524a
Closes-Bug: #1407900
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/93/145193/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/os-ansible-aio-check.sh'],1,3ffdea150eaa6f6a179cd30c731297070a9716c3,bug/1407900,"# Ensure newline at end of file (missing on Rackspace public cloud Trusty image) if ! cat -E /etc/ssh/sshd_config | tail -1 | grep -q ""\$$""; then echo >> /etc/ssh/sshd_config fi ",,5,0
openstack%2Ftripleo-image-elements~master~Id0fcb3828f0cdfafdbb7d421377642ee50240907,openstack/tripleo-image-elements,master,Id0fcb3828f0cdfafdbb7d421377642ee50240907,Only install CA cert if file is likely to be a valid cert,MERGED,2014-11-24 21:25:02.000000000,2015-01-06 18:21:54.000000000,2015-01-06 18:21:53.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 8399}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-11-24 21:25:02.000000000', 'files': ['elements/ssl-ca/os-refresh-config/configure.d/51-ssl-load-ca-certs'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/57feb708ea3b725b499308c05bec568a8aa1bbfb', 'message': 'Only install CA cert if file is likely to be a valid cert\n\nIn certain cases, the heat metadata and cert may not be available when the element\nis first ran. We should make a trivial attempt to guess if the cert is likely to\nbe valid before attempting to install it.\n\nChange-Id: Id0fcb3828f0cdfafdbb7d421377642ee50240907\n'}]",2,136895,57feb708ea3b725b499308c05bec568a8aa1bbfb,15,5,1,741,,,0,"Only install CA cert if file is likely to be a valid cert

In certain cases, the heat metadata and cert may not be available when the element
is first ran. We should make a trivial attempt to guess if the cert is likely to
be valid before attempting to install it.

Change-Id: Id0fcb3828f0cdfafdbb7d421377642ee50240907
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/95/136895/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ssl-ca/os-refresh-config/configure.d/51-ssl-load-ca-certs'],1,57feb708ea3b725b499308c05bec568a8aa1bbfb,(detached,"CA_CERT_SIZE=$(stat -c '%s' ""$CA_CERT"") # A PEM encoded SSL Cert will have at least 54 characters for the START/END # markers. if [ $CA_CERT_SIZE -gt 54 ]; then", if [ -s ${CA_CERT} ]; then,4,1
openstack%2Fgnocchi~master~I9328f425a8a678685ecc8e28ea6335ffcd3dcbf5,openstack/gnocchi,master,I9328f425a8a678685ecc8e28ea6335ffcd3dcbf5,tests: use non-admin user by default in test,MERGED,2014-12-23 14:42:13.000000000,2015-01-06 18:18:49.000000000,2015-01-06 18:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-23 14:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/5495bf4c7ad896bc58ee1f60a16f7816e534a913', 'message': ""tests: use non-admin user by default in test\n\nBy default we used to run query against the REST server in tests with an\nadmin user. This bypassed a lot of rules and filtering and didn't test\nall the code path.\n\nThis patch introduces a new context manager to do request as admin, and\nswitches to a non-admin user by default. This also fixes a lot of\nproblem in the code disovered by this change.\n\nChange-Id: I9328f425a8a678685ecc8e28ea6335ffcd3dcbf5\n""}, {'number': 2, 'created': '2014-12-23 15:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c12b5e5de0962dcaab4352c92570b8b7fd189c84', 'message': ""tests: use non-admin user by default in test\n\nBy default we used to run query against the REST server in tests with an\nadmin user. This bypassed a lot of rules and filtering and didn't test\nall the code path.\n\nThis patch introduces a new context manager to do request as admin, and\nswitches to a non-admin user by default. This also fixes a lot of\nproblem in the code disovered by this change.\n\nChange-Id: I9328f425a8a678685ecc8e28ea6335ffcd3dcbf5\n""}, {'number': 3, 'created': '2014-12-29 16:19:13.000000000', 'files': ['gnocchi/gendoc.py', 'gnocchi/rest/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e3f5304151cc1182cdd8ab6e4275490298695f94', 'message': ""tests: use non-admin user by default in test\n\nBy default we used to run query against the REST server in tests with an\nadmin user. This bypassed a lot of rules and filtering and didn't test\nall the code path.\n\nThis patch introduces a new context manager to do request as admin, and\nswitches to a non-admin user by default. This also fixes a lot of\nproblem in the code disovered by this change.\n\nChange-Id: I9328f425a8a678685ecc8e28ea6335ffcd3dcbf5\n""}]",0,143674,e3f5304151cc1182cdd8ab6e4275490298695f94,13,3,3,1669,,,0,"tests: use non-admin user by default in test

By default we used to run query against the REST server in tests with an
admin user. This bypassed a lot of rules and filtering and didn't test
all the code path.

This patch introduces a new context manager to do request as admin, and
switches to a non-admin user by default. This also fixes a lot of
problem in the code disovered by this change.

Change-Id: I9328f425a8a678685ecc8e28ea6335ffcd3dcbf5
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/74/143674/3 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/indexer/sqlalchemy.py', 'gnocchi/tests/test_rest.py']",3,5495bf4c7ad896bc58ee1f60a16f7816e534a913,jd/404-on-delete," VALID_TOKEN_ADMIN = '4562138218392830' USER_ID_ADMIN = str(uuid.uuid4()) PROJECT_ID_ADMIN = str(uuid.uuid4()) if key == ""tokens/%s"" % self.VALID_TOKEN_ADMIN: return json.dumps(({'access': { 'token': {'id': self.VALID_TOKEN_ADMIN, 'expires': timeutils.isotime(dt)}, 'user': { 'id': self.USER_ID_ADMIN, 'name': 'adminusername', 'tenantId': self.PROJECT_ID_ADMIN, 'tenantName': 'myadmintenant', 'roles': [ {'name': 'admin'}, ]}, }}, timeutils.isotime(dt))) elif key == ""tokens/%s"" % self.VALID_TOKEN: {'name': 'member'}, def use_admin_user(self): old_token = self.token self.token = FakeMemcache.VALID_TOKEN_ADMIN try: yield finally: self.token = old_token @contextlib.contextmanager with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=201) self.app.post_json( ""/v1/archive_policy"", params={""name"": str(uuid.uuid4()), ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=403) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""2 minutes"", }]}, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, ""timespan"": ""3 hours"", }]}, status=400) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, headers={'content-type': 'application/json; charset=UTF-8'}, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""10s"", ""timespan"": ""1 hour"", }]}, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""7s"", ""timespan"": ""1 hour"", }]}, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""points"": 1000, ""timespan"": ""1 hour"", }]}, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""points"": 1800, ""timespan"": ""1 hour"", }]}, status=201) with self.app.use_admin_user(): self.app.post_json( ""/v1/archive_policy"", params={""name"": str(uuid.uuid4()), ""definition"": [{ ""granularity"": ""10s"", ""timespan"": ""1 shenanigan"", }]}, status=400) with self.app.use_admin_user(): self.app.post_json( ""/v1/archive_policy"", params={""name"": ap, ""definition"": [{ ""granularity"": ""10s"", ""points"": 20, }]}, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": ""somenewname"", ""definition"": ""foobar""}, status=400) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params={""name"": ""high"", ""definition"": [{ ""granularity"": ""10s"", ""points"": 20, }]}, status=409) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params=params, status=201) with self.app.use_admin_user(): result = self.app.post_json( ""/v1/archive_policy"", params=params, status=201) with self.app.use_admin_user(): self.app.post_json( ""/v1/archive_policy"", params=params) self.app.delete(""/v1/archive_policy/%s"" % params['name'], status=204) with self.app.use_admin_user(): result = self.app.delete(""/v1/archive_policy/%s"" % ap, status=404) with self.app.use_admin_user(): self.app.post_json( ""/v1/archive_policy"", params=params) with self.app.use_admin_user(): result = self.app.delete(""/v1/archive_policy/%s"" % ap, status=400) with self.app.use_admin_user(): self.app.get(""/v1/archive_policy/"" + str(uuid.uuid4()), status=404) with self.app.use_admin_user(): self.app.post_json( ""/v1/archive_policy"", params={""name"": ap_name, ""back_window"": 2, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=201)"," if key == ""tokens/%s"" % self.VALID_TOKEN: {'name': 'admin'}, result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=201) with self.app.use_another_user(): self.app.post_json( ""/v1/archive_policy"", params={""name"": str(uuid.uuid4()), ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=403) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""2 minutes"", }]}, status=201) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, ""timespan"": ""3 hours"", }]}, status=400) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, headers={'content-type': 'application/json; charset=UTF-8'}, status=201) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""10s"", ""timespan"": ""1 hour"", }]}, status=201) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""granularity"": ""7s"", ""timespan"": ""1 hour"", }]}, status=201) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""points"": 1000, ""timespan"": ""1 hour"", }]}, status=201) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": name, ""definition"": [{ ""points"": 1800, ""timespan"": ""1 hour"", }]}, status=201) self.app.post_json( ""/v1/archive_policy"", params={""name"": str(uuid.uuid4()), ""definition"": [{ ""granularity"": ""10s"", ""timespan"": ""1 shenanigan"", }]}, expect_errors=True, status=400) self.app.post_json( ""/v1/archive_policy"", params={""name"": ap, ""definition"": [{ ""granularity"": ""10s"", ""points"": 20, }]}, status=201) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": ""somenewname"", ""definition"": ""foobar""}, expect_errors=True, status=400) result = self.app.post_json( ""/v1/archive_policy"", params={""name"": ""high"", ""definition"": [{ ""granularity"": ""10s"", ""points"": 20, }]}, expect_errors=True, status=409) result = self.app.post_json( ""/v1/archive_policy"", params=params, status=201) result = self.app.post_json( ""/v1/archive_policy"", params=params, status=201) self.app.post_json( ""/v1/archive_policy"", params=params) self.app.delete(""/v1/archive_policy/%s"" % params['name'], status=204) result = self.app.delete(""/v1/archive_policy/%s"" % ap, status=404) self.app.post_json( ""/v1/archive_policy"", params=params) result = self.app.delete(""/v1/archive_policy/%s"" % ap, status=400) self.app.get(""/v1/archive_policy/"" + str(uuid.uuid4()), status=404) self.app.post_json( ""/v1/archive_policy"", params={""name"": ap_name, ""back_window"": 2, ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=201)",195,148
openstack%2Fgnocchi~master~If4a52ae23d65ef98d0bde12755a3253d4934c532,openstack/gnocchi,master,If4a52ae23d65ef98d0bde12755a3253d4934c532,indexer: do not delete metric on resource delete,MERGED,2014-12-22 14:25:58.000000000,2015-01-06 18:16:36.000000000,2015-01-06 18:16:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-22 14:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a86dc007fb7e9b2bc9b91e42f62a48534a60c477', 'message': 'indexer: do not delete metric on resource delete\n\nThis is actually a mistake to do that at this time, as the metric in the\nstorage driver still exists and would never been cleaned if the indexer\ndoes that.\n\nChange-Id: If4a52ae23d65ef98d0bde12755a3253d4934c532\n'}, {'number': 2, 'created': '2014-12-29 16:19:13.000000000', 'files': ['gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c6f1ed08f4bb8f50479b4f3a3dba654becd92f5a', 'message': 'indexer: do not delete metric on resource delete\n\nThis is actually a mistake to do that at this time, as the metric in the\nstorage driver still exists and would never been cleaned if the indexer\ndoes that.\n\nChange-Id: If4a52ae23d65ef98d0bde12755a3253d4934c532\n'}]",0,143454,c6f1ed08f4bb8f50479b4f3a3dba654becd92f5a,13,3,2,1669,,,0,"indexer: do not delete metric on resource delete

This is actually a mistake to do that at this time, as the metric in the
storage driver still exists and would never been cleaned if the indexer
does that.

Change-Id: If4a52ae23d65ef98d0bde12755a3253d4934c532
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/54/143454/2 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/sqlalchemy.py'],1,a86dc007fb7e9b2bc9b91e42f62a48534a60c477,jd/404-on-delete," ondelete=""SET NULL""))"," ondelete=""CASCADE""))",1,1
openstack%2Fgnocchi~master~Ifc93aaa21b16a66053f155c863835d25d9931e40,openstack/gnocchi,master,Ifc93aaa21b16a66053f155c863835d25d9931e40,policy: fix creator rule,MERGED,2014-12-22 14:04:31.000000000,2015-01-06 18:16:30.000000000,2015-01-06 18:16:30.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-22 14:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6fbc5c1f6e34b04064510360577f6bee8c591fb3', 'message': ""policy: fix creator rule\n\nThe syntax was not correct and we didn't test it, let's do that and fix\nit.\n\nChange-Id: Ifc93aaa21b16a66053f155c863835d25d9931e40\n""}, {'number': 2, 'created': '2014-12-29 16:19:13.000000000', 'files': ['etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/735ceef208423bc1f92ded4b15324098cd8b8213', 'message': ""policy: fix creator rule\n\nThe syntax was not correct and we didn't test it, let's do that and fix\nit.\n\nChange-Id: Ifc93aaa21b16a66053f155c863835d25d9931e40\n""}]",0,143446,735ceef208423bc1f92ded4b15324098cd8b8213,12,4,2,1669,,,0,"policy: fix creator rule

The syntax was not correct and we didn't test it, let's do that and fix
it.

Change-Id: Ifc93aaa21b16a66053f155c863835d25d9931e40
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/46/143446/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py']",2,6fbc5c1f6e34b04064510360577f6bee8c591fb3,jd/404-on-delete," # We replace ""-"" to simulate a middleware that would send UUID in a non # normalized format. USER_ID_2 = str(uuid.uuid4()).replace(""-"", """") PROJECT_ID_2 = str(uuid.uuid4()).replace(""-"", """") def test_get_resource_non_admin(self): with self.app.use_another_user(): self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes, status=201) self.app.get(""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id'], status=200) ", USER_ID_2 = str(uuid.uuid4()) PROJECT_ID_2 = str(uuid.uuid4()),16,3
openstack%2Fgnocchi~master~I7ebd95ebf55773387eab84a913f2addb156fc563,openstack/gnocchi,master,I7ebd95ebf55773387eab84a913f2addb156fc563,"Fixing fallback from ""list all metric"" RBAC rule",ABANDONED,2015-01-06 18:03:26.000000000,2015-01-06 18:11:58.000000000,,[{'_account_id': 1669}],"[{'number': 1, 'created': '2015-01-06 18:03:26.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6bf8d1ee9c1ced3e957fa531e71b4f8d3be7ab22', 'message': 'Fixing fallback from ""list all metric"" RBAC rule\n\nShould revert to enforcing ""list metric"" as opposed to\n""list resource"" if enforcement of ""list all metric"" fails.\n\nChange-Id: I7ebd95ebf55773387eab84a913f2addb156fc563\n'}]",0,145286,6bf8d1ee9c1ced3e957fa531e71b4f8d3be7ab22,2,1,1,2284,,,0,"Fixing fallback from ""list all metric"" RBAC rule

Should revert to enforcing ""list metric"" as opposed to
""list resource"" if enforcement of ""list all metric"" fails.

Change-Id: I7ebd95ebf55773387eab84a913f2addb156fc563
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/86/145286/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,6bf8d1ee9c1ced3e957fa531e71b4f8d3be7ab22,," enforce(""list metric"", {})"," enforce(""list resource"", {})",1,1
openstack%2Fgnocchi~master~I842199988d9ec7aa4503dd01b8962d791261dc37,openstack/gnocchi,master,I842199988d9ec7aa4503dd01b8962d791261dc37,rest: convert UUID in token to correct format,MERGED,2014-12-22 14:04:31.000000000,2015-01-06 18:11:18.000000000,2015-01-06 18:11:17.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-22 14:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b321c5c2c972b3094604fcdada905ed77aa7796a', 'message': 'rest: convert UUID in token to correct format\n\nChange-Id: I842199988d9ec7aa4503dd01b8962d791261dc37\n'}, {'number': 2, 'created': '2014-12-29 16:19:13.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d38fd8738a00c9f4ba6e8e5c212f8d90f82251f5', 'message': 'rest: convert UUID in token to correct format\n\nChange-Id: I842199988d9ec7aa4503dd01b8962d791261dc37\n'}]",2,143445,d38fd8738a00c9f4ba6e8e5c212f8d90f82251f5,13,4,2,1669,,,0,"rest: convert UUID in token to correct format

Change-Id: I842199988d9ec7aa4503dd01b8962d791261dc37
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/45/143445/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,b321c5c2c972b3094604fcdada905ed77aa7796a,jd/404-on-delete," # NOTE(jd) If user_id or project_id are UUID, try to convert them in the # proper dashed format. It's indeed possible that a middleware passes # theses UUID without the dash representation. It's valid, we can parse, # but the policy module won't see the equality in the string # representations. user_id = headers.get(""X-User-Id"") try: user_id = six.text_type(uuid.UUID(user_id)) except Exception: pass project_id = headers.get(""X-Project-Id"") try: project_id = six.text_type(uuid.UUID(project_id)) except Exception: pass 'user_id': user_id, 'project_id': project_id"," 'user_id': headers.get(""X-User-Id""), 'project_id': headers.get(""X-Project-Id""),",21,2
openstack%2Fgnocchi~master~I49bd3c678831287a07f4389739e4b37ea845187b,openstack/gnocchi,master,I49bd3c678831287a07f4389739e4b37ea845187b,rest: enhance enforce context,MERGED,2014-12-22 00:08:37.000000000,2015-01-06 18:09:26.000000000,2015-01-06 18:09:26.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-22 00:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a99e58b576012702172b88a687982d2e38268287', 'message': 'rest: enhance enforce context\n\nIn many places the context gave to enforce() is too minimal to apply\ninteresting rules, e.g. we need to pass the whole resource so we can\napply fine grained rules.\n\nChange-Id: I49bd3c678831287a07f4389739e4b37ea845187b\n'}, {'number': 2, 'created': '2014-12-22 13:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1c86beb055a0d73b8612d49df465ec6404c79e7b', 'message': 'rest: enhance enforce context, fix created_by rule\n\nIn many places the context gave to enforce() is too minimal to apply\ninteresting rules, e.g. we need to pass the whole resource so we can\napply fine grained rules.\n\nThis also fixes created_by rule to match the created_by_project_id, not\nthe project_id as some entities such as metrics do not have these\nproperties anyway.\n\nChange-Id: I49bd3c678831287a07f4389739e4b37ea845187b\n'}, {'number': 3, 'created': '2014-12-22 13:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1477b10daffb23ae58d811b88c113e311aa70b78', 'message': 'rest: enhance enforce context\n\nIn many places the context given to enforce() is too minimal to apply\ninteresting rules, e.g. we need to pass the whole resource so we can\napply fine grained rules.\n\nChange-Id: I49bd3c678831287a07f4389739e4b37ea845187b\n'}, {'number': 4, 'created': '2014-12-29 16:19:13.000000000', 'files': ['gnocchi/rest/__init__.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ca071e08b117c5ba90cdbd1e21d455b79036f213', 'message': 'rest: enhance enforce context\n\nIn many places the context given to enforce() is too minimal to apply\ninteresting rules, e.g. we need to pass the whole resource so we can\napply fine grained rules.\n\nChange-Id: I49bd3c678831287a07f4389739e4b37ea845187b\n'}]",3,143335,ca071e08b117c5ba90cdbd1e21d455b79036f213,19,4,4,1669,,,0,"rest: enhance enforce context

In many places the context given to enforce() is too minimal to apply
interesting rules, e.g. we need to pass the whole resource so we can
apply fine grained rules.

Change-Id: I49bd3c678831287a07f4389739e4b37ea845187b
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/35/143335/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/rest/__init__.py'],1,a99e58b576012702172b88a687982d2e38268287,jd/404-on-delete," if ap: enforce(""get archive policy"", ap) resource = pecan.request.indexer.get_resource( self.resource_type, self.resource_id) enforce(""update resource"", resource) enforce(""get resource"", resource) resource = pecan.request.indexer.get_resource( self._resource_type, self.id) enforce(""update resource"", resource) resource = pecan.request.indexer.get_resource( self._resource_type, self.id) enforce(""delete resource"", resource) target = { ""resource_type"": self._resource_type, } target.update(body) enforce(""create resource"", target)"," enforce(""get archive policy"", ap) if ap: enforce(""update resource"", { ""resource_type"": self.resource_type, ""resource_id"": self.resource_id, }) enforce(""get resource"", { ""resource_type"": self._resource_type, ""resource_id"": self.id, }) enforce(""update resource"", { ""resource_type"": self._resource_type, ""resource_id"": self.id, }) enforce(""delete resource"", { ""resource_type"": self._resource_type, ""resource_id"": self.id, }) enforce(""create resource"", { ""resource_type"": self._resource_type, })",16,20
openstack%2Fmanila~master~I32ae271a15aaea6eac396e1349496f5b29433e3a,openstack/manila,master,I32ae271a15aaea6eac396e1349496f5b29433e3a,Fix typo in db migration test function name,MERGED,2015-01-06 09:54:58.000000000,2015-01-06 18:07:42.000000000,2015-01-06 18:07:41.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7491}, {'_account_id': 8851}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-01-06 09:54:58.000000000', 'files': ['manila/tests/db/test_migration.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/2dcb0d5475698209552a4f0ce8607b93d8411616', 'message': ""Fix typo in db migration test function name\n\nFunction name is 'test_downgrade_none_version', not\n'test_downgrade_none_verison'.\n\nChange-Id: I32ae271a15aaea6eac396e1349496f5b29433e3a\n""}]",0,145182,2dcb0d5475698209552a4f0ce8607b93d8411616,10,6,1,7102,,,0,"Fix typo in db migration test function name

Function name is 'test_downgrade_none_version', not
'test_downgrade_none_verison'.

Change-Id: I32ae271a15aaea6eac396e1349496f5b29433e3a
",git fetch https://review.opendev.org/openstack/manila refs/changes/82/145182/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/tests/db/test_migration.py'],1,2dcb0d5475698209552a4f0ce8607b93d8411616,," def test_downgrade_none_version(self, downgrade):"," def test_downgrade_none_verison(self, downgrade):",1,1
openstack%2Fmanila~master~I34619507268d0444d4b2c08d5f68ee7216eb5a49,openstack/manila,master,I34619507268d0444d4b2c08d5f68ee7216eb5a49,Remove unsed python modules from requirements,MERGED,2014-12-28 17:34:17.000000000,2015-01-06 18:06:16.000000000,2015-01-06 18:06:15.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-28 17:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/444ee67bc4758dc21f92c4326431a99892368f60', 'message': ""Remove unsed python modules from requirements\n\nThe following modules are no longer directly used in Manila's codebase\nso remove theses modules:\n\n * kombu\n * lockfile\n * posix_ipc\n * suds\n * wsgiref\n\nChange-Id: I34619507268d0444d4b2c08d5f68ee7216eb5a49\n""}, {'number': 2, 'created': '2014-12-28 18:28:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/ed3a120836b2e4fb3ae1064dd5807b89118b3596', 'message': ""Remove unsed python modules from requirements\n\nThe following modules are no longer directly used in Manila's codebase\nso remove theses modules:\n\n * argparse\n * kombu\n * lockfile\n * posix_ipc\n * suds\n * wsgiref\n\nChange-Id: I34619507268d0444d4b2c08d5f68ee7216eb5a49\n""}]",2,144234,ed3a120836b2e4fb3ae1064dd5807b89118b3596,20,8,2,7102,,,0,"Remove unsed python modules from requirements

The following modules are no longer directly used in Manila's codebase
so remove theses modules:

 * argparse
 * kombu
 * lockfile
 * posix_ipc
 * suds
 * wsgiref

Change-Id: I34619507268d0444d4b2c08d5f68ee7216eb5a49
",git fetch https://review.opendev.org/openstack/manila refs/changes/34/144234/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,444ee67bc4758dc21f92c4326431a99892368f60,144234,,kombu>=2.5.0 lockfile>=0.8posix_ipcsuds>=0.4wsgiref>=0.1.2,0,5
openstack%2Fnova~master~I5de095ac1f7f38fd37cc9d6010a876995f0f8841,openstack/nova,master,I5de095ac1f7f38fd37cc9d6010a876995f0f8841,XenAPI: Refactor message strings to remove locals,MERGED,2015-01-05 21:22:47.000000000,2015-01-06 18:04:30.000000000,2015-01-06 18:04:27.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-05 21:22:47.000000000', 'files': ['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'], 'web_link': 'https://opendev.org/openstack/nova/commit/43e89abeb2b68c6c9969c685a4d04eba4cd5d563', 'message': 'XenAPI: Refactor message strings to remove locals\n\nThis commit is a small refactor to the XenAPI glance plugin removing\nthe use of locals() to improve the readability.\n\nChange-Id: I5de095ac1f7f38fd37cc9d6010a876995f0f8841\n'}]",0,145059,43e89abeb2b68c6c9969c685a4d04eba4cd5d563,12,7,1,2537,,,0,"XenAPI: Refactor message strings to remove locals

This commit is a small refactor to the XenAPI glance plugin removing
the use of locals() to improve the readability.

Change-Id: I5de095ac1f7f38fd37cc9d6010a876995f0f8841
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/145059/1 && git format-patch -1 --stdout FETCH_HEAD,['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'],1,43e89abeb2b68c6c9969c685a4d04eba4cd5d563,refactor-xen-api-log," logging.info(msg % {'checksum': checksum}) raise RetryableError(msg % {'checksum': checksum, 'etag': etag}) logging.info(msg % {'checksum': checksum}) ""%(image_id)s"" % {'scheme': scheme, 'glance_host': glance_host, 'glance_port': glance_port, 'image_id': image_id}) logging.exception('Failed to retrieve %(url)s' % {'url': url}) logging.exception('Failed to connect %(url)s' % {'url': url}) logging.exception('Failed to upload %(url)s' % {'url': url})"," logging.info(msg % locals()) raise RetryableError(msg % locals()) logging.info(msg % locals()) ""%(image_id)s"" % locals()) logging.exception('Failed to retrieve %(url)s' % locals()) logging.exception('Failed to connect %(url)s' % locals()) logging.exception('Failed to upload %(url)s' % locals())",9,7
openstack%2Fdiskimage-builder~master~If40dd78ba793d508afb1a5ab345470ee5929afb0,openstack/diskimage-builder,master,If40dd78ba793d508afb1a5ab345470ee5929afb0,Add Activation Key Support For Customer Portal,MERGED,2014-11-26 15:30:52.000000000,2015-01-06 18:04:13.000000000,2015-01-06 18:04:12.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6928}, {'_account_id': 7585}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-11-26 15:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/18b46b23323e918c4d3024dd3b48b4de50ae0a44', 'message': 'Add Activation Key Support For Customer Portal\n\nThis patch adds support to register with the hosted customer portal\nusing activation keys.  If an activation key is present in either\nthe REG_ACTIVATION_KEY or rh_registration.activation_key, it will\nuse that value instead of username and password credentials when\nregistering with Satellite or the hosted Customer Portal.  This\npatch also enforces that an org must be set in either the REG_ORG\nor rh_registration.org to use the activation key.\n\nChange-Id: If40dd78ba793d508afb1a5ab345470ee5929afb0\n'}, {'number': 2, 'created': '2014-12-03 17:47:11.000000000', 'files': ['elements/rhel-common/os-refresh-config/pre-configure.d/06-rhel-registration', 'elements/rhel-common/pre-install.d/00-rhel-registration'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/bf8b77a8ea8cd6f00d496e62af634555a1ccfb15', 'message': 'Add Activation Key Support For Customer Portal\n\nThis patch adds support to register with the hosted customer portal\nusing activation keys.  If an activation key is present in either\nthe REG_ACTIVATION_KEY or rh_registration.activation_key, it will\nuse that value instead of username and password credentials when\nregistering with Satellite or the hosted Customer Portal.  This\npatch also enforces that an org must be set in either the REG_ORG\nor rh_registration.org to use the activation key.\n\nChange-Id: If40dd78ba793d508afb1a5ab345470ee5929afb0\n'}]",10,137378,bf8b77a8ea8cd6f00d496e62af634555a1ccfb15,16,5,2,8532,,,0,"Add Activation Key Support For Customer Portal

This patch adds support to register with the hosted customer portal
using activation keys.  If an activation key is present in either
the REG_ACTIVATION_KEY or rh_registration.activation_key, it will
use that value instead of username and password credentials when
registering with Satellite or the hosted Customer Portal.  This
patch also enforces that an org must be set in either the REG_ORG
or rh_registration.org to use the activation key.

Change-Id: If40dd78ba793d508afb1a5ab345470ee5929afb0
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/78/137378/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/rhel-common/os-refresh-config/pre-configure.d/06-rhel-registration', 'elements/rhel-common/pre-install.d/00-rhel-registration']",2,18b46b23323e918c4d3024dd3b48b4de50ae0a44,rhel-registration-activation,"satellite_repo=""rhel-7-server-rh-common-beta-rpms""if [ -n ""${REG_ACTIVATION_KEY:-}"" ]; then opts=""$opts --activationkey=$REG_ACTIVATION_KEY"" if [ -z ""${REG_ORG:-}"" ]; then echo ""WARNING: REG_ACTIVATION_KEY set without REG_ORG."" fi else if [ -n ""${REG_PASSWORD:-}"" ]; then opts=""$opts --password $REG_PASSWORD"" fi if [ -n ""${REG_USER:-}"" ]; then opts=""$opts --username $REG_USER"" fiif [ -n ""${REG_REPOS:-}"" ]; then for repo in $REG_REPOS; do repos=""$repos --enable $repo"" done fi if [ -n ""${REG_TYPE:-}"" ]; then opts=""$opts --type=$REG_TYPE"" fi repos=""$repos --enable ${satellite_repo}"""," if [ -n ""${REG_USER:-}"" ]; then opts=""$opts --username $REG_USER"" fi if [ -n ""${REG_PASSWORD:-}"" ]; then opts=""$opts --password $REG_PASSWORD"" if [ -n ""${REG_ACTIVATION_KEY:-}"" ]; then echo ""WARNING: Activation keys are not supported by the customer portal at this time."" fi if [ -n ""${REG_REPOS:-}"" ]; then for repo in $REG_REPOS; do repos=""$repos --enable $repo"" done fi repos=""$repos --enable rhel-7-server-rh-common-beta-rpms"" if [ -n ""${REG_REPOS:-}"" ]; then for repo in $REG_REPOS; do repos=""$repos --enable $repo"" done fi ",50,46
openstack%2Ftripleo-image-elements~master~Ide44075778b2445e0ade66bcc2f96b5458357e79,openstack/tripleo-image-elements,master,Ide44075778b2445e0ade66bcc2f96b5458357e79,Fix mustache context cascading in stunnel config,MERGED,2014-12-18 02:39:05.000000000,2015-01-06 17:57:17.000000000,2015-01-06 17:57:16.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8449}, {'_account_id': 9453}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-12-18 02:39:05.000000000', 'files': ['elements/openstack-ssl/os-apply-config/etc/stunnel/from-heat.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/30c539ed2cf94a764c539fd1d95faaf0b5829b30', 'message': ""Fix mustache context cascading in stunnel config\n\nIn order to use the 'connect_host' in the parent structure of stunnel,\nwe need to use the context before it will fall back. By using\n{{#stunnel.ports}} directly, mustache won't have any further context to\nfall back to to find connect_host.\n\nChange-Id: Ide44075778b2445e0ade66bcc2f96b5458357e79\n""}]",0,142650,30c539ed2cf94a764c539fd1d95faaf0b5829b30,30,5,1,6488,,,0,"Fix mustache context cascading in stunnel config

In order to use the 'connect_host' in the parent structure of stunnel,
we need to use the context before it will fall back. By using
{{#stunnel.ports}} directly, mustache won't have any further context to
fall back to to find connect_host.

Change-Id: Ide44075778b2445e0ade66bcc2f96b5458357e79
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/50/142650/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/openstack-ssl/os-apply-config/etc/stunnel/from-heat.conf'],1,30c539ed2cf94a764c539fd1d95faaf0b5829b30,,{{#stunnel}}{{#ports}}{{/ports}}{{/stunnel}},{{#stunnel.ports}}{{/stunnel.ports}},2,2
openstack%2Fpython-manilaclient~master~I88f2273304e3021408ad93c9b9b42987fa0acfeb,openstack/python-manilaclient,master,I88f2273304e3021408ad93c9b9b42987fa0acfeb,Add oslo.utils to requirements.txt,MERGED,2015-01-05 13:44:28.000000000,2015-01-06 17:56:42.000000000,2015-01-06 17:56:42.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-01-05 13:44:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/bbbcebf7710beb4c4f2b2ea868ffc83e02875940', 'message': 'Add oslo.utils to requirements.txt\n\noslo.utils is used in different places in the code so add it to the\nrequirements list.\n\nChange-Id: I88f2273304e3021408ad93c9b9b42987fa0acfeb\n'}]",0,144983,bbbcebf7710beb4c4f2b2ea868ffc83e02875940,9,5,1,7102,,,0,"Add oslo.utils to requirements.txt

oslo.utils is used in different places in the code so add it to the
requirements list.

Change-Id: I88f2273304e3021408ad93c9b9b42987fa0acfeb
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/83/144983/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bbbcebf7710beb4c4f2b2ea868ffc83e02875940,,oslo.utils>=1.1.0 # Apache-2.0,,1,0
openstack%2Foslo.config~master~I35b6c128f6f9d63793a7be8b22455cb510eb4b88,openstack/oslo.config,master,I35b6c128f6f9d63793a7be8b22455cb510eb4b88,_search_dirs only returns readable files,ABANDONED,2014-08-11 17:46:32.000000000,2015-01-06 17:30:52.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 9717}]","[{'number': 1, 'created': '2014-08-11 17:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/f39d75b4d02c344e064d6607a1edbd72abf2ff13', 'message': '_search_dirs only returns readable files\n\nWhen oslo.config performs a directory search, it will now only\nreturn files that are readable by the current user. If a file\nis found, but is discovered to not be readable by the current\nuser, it will log a warning to the console and move on to the\nnext file candidate.\n\nChange-Id: I35b6c128f6f9d63793a7be8b22455cb510eb4b88\n'}, {'number': 2, 'created': '2014-08-11 18:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/d5e6d9f739b13ebe839c7d9ae1c9a09328c6efbf', 'message': '_search_dirs only returns readable files\n\nWhen oslo.config performs a directory search, it will now only\nreturn files that are readable by the current user. If a file\nis found, but is discovered to not be readable by the current\nuser, it will log a warning to the console and move on to the\nnext file candidate.\n\nChange-Id: I35b6c128f6f9d63793a7be8b22455cb510eb4b88\n'}, {'number': 3, 'created': '2014-09-27 21:13:26.000000000', 'files': ['oslo/config/cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/a4761e1e65259c13ec49b4829e80798b71b1fa9d', 'message': '_search_dirs only returns readable files\n\nWhen oslo.config performs a directory search, it will now only\nreturn files that are readable by the current user. If a file\nis found, but is discovered to not be readable by the current\nuser, it will log a warning to the console and move on to the\nnext file candidate.\n\nChange-Id: I35b6c128f6f9d63793a7be8b22455cb510eb4b88\n'}]",1,113327,a4761e1e65259c13ec49b4829e80798b71b1fa9d,12,3,3,9717,,,0,"_search_dirs only returns readable files

When oslo.config performs a directory search, it will now only
return files that are readable by the current user. If a file
is found, but is discovered to not be readable by the current
user, it will log a warning to the console and move on to the
next file candidate.

Change-Id: I35b6c128f6f9d63793a7be8b22455cb510eb4b88
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/27/113327/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/config/cfg.py'],1,f39d75b4d02c344e064d6607a1edbd72abf2ff13,config_perm_check," if not os.access(path, os.R_OK): LOG.warn('File found at [%s], but not readable.' % (path)) else: return path", return path,4,1
openstack%2Fnova~master~I7cb4f74e588c18879a2a747f158049d83359ee4c,openstack/nova,master,I7cb4f74e588c18879a2a747f158049d83359ee4c,ironic: delete cpu_info data from get_available_resource,MERGED,2014-10-10 16:20:06.000000000,2015-01-06 17:26:26.000000000,2015-01-06 17:26:23.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6802}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-10-10 16:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cf695e5927688b119e0e8e9ffb3dc82a9b63edf', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 2, 'created': '2014-10-12 08:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bfb71161a138f7a98e490bad74ca1d30130b8a0', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 3, 'created': '2014-10-14 10:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/388fd30aff9a3119faee312e237b39a6a958071d', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 4, 'created': '2014-10-14 12:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd4f723ea8863aaa71ca87147844b0514b9bb0b1', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 5, 'created': '2014-10-15 08:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96a4ea72f9de3af689853de7b4b766a98611b669', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 6, 'created': '2014-10-15 08:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5020fa17d1e9a39c3fd8e146f8ab1d62f12bfb0b', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 7, 'created': '2014-10-22 12:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c734f2bc65913bffec0ae6b59281c884f4dd7680', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 8, 'created': '2014-11-10 13:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4eb615267c332793104c38a4be140e8063243ae8', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nCleanup before Blueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 9, 'created': '2014-11-13 09:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14846257b096e16a5704988c6e39b9034ab04470', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nCleanup before Blueprint: virt-driver-get-available-resources-object\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}, {'number': 10, 'created': '2014-12-08 17:36:07.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/scheduler/ironic_host_manager.py', 'nova/tests/unit/scheduler/test_ironic_host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f1bbc53206fc80941da27bfc28d1d71ed95d5511', 'message': 'ironic: delete cpu_info data from get_available_resource\n\nThe \'cpu_info\' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host, including arch, model, vendor, feature flags\nand topology. Instead Ironic simply returns a dummy string\n""baremetal cpu"".\n\nJust delete the \'cpu_info\' data entirely since there is nothing\nsensible that the Ironic driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nThe IronicHostManager was apparently looking for this string\n""baremetal cpu"" to distinguish Ironic compute hosts from\nnon-Ironic compute hosts. This is rather crazy when we have\nan explicit ""hypervisor_type"" field available, so replace that\ncheck.\n\nCleanup before Blueprint: resource-objects\nChange-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c\n'}]",0,127574,f1bbc53206fc80941da27bfc28d1d71ed95d5511,84,14,10,1779,,,0,"ironic: delete cpu_info data from get_available_resource

The 'cpu_info' field in the dict from get_available_resource
is supposed to provide information on the physical CPU model
used in the host, including arch, model, vendor, feature flags
and topology. Instead Ironic simply returns a dummy string
""baremetal cpu"".

Just delete the 'cpu_info' data entirely since there is nothing
sensible that the Ironic driver can return for this field, given
its 1:M  compute<->hypervisor relationship.

The IronicHostManager was apparently looking for this string
""baremetal cpu"" to distinguish Ironic compute hosts from
non-Ironic compute hosts. This is rather crazy when we have
an explicit ""hypervisor_type"" field available, so replace that
check.

Cleanup before Blueprint: resource-objects
Change-Id: I7cb4f74e588c18879a2a747f158049d83359ee4c
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/127574/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/scheduler/ironic_host_manager.py']",2,3cf695e5927688b119e0e8e9ffb3dc82a9b63edf,bp/resource-objects, if compute and compute.get('hypervisor_type') == 'ironic':, if compute and compute.get('cpu_info') == 'baremetal cpu':,6,2
openstack%2Fnova~master~I2071a60d6ad8e1208ac56af8b95b2daa63582bb6,openstack/nova,master,I2071a60d6ad8e1208ac56af8b95b2daa63582bb6,vmware: delete cpu_info data from get_available_resource,MERGED,2014-10-10 16:20:06.000000000,2015-01-06 17:26:04.000000000,2015-01-06 17:26:01.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6802}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-10 16:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c94a0be325f88bfe7df1f2ba144df3309175365', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 2, 'created': '2014-10-12 08:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c02a9930606c4af9879d3bba41e5086d9b0df697', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 3, 'created': '2014-10-14 10:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80abd5dc66563646d29205bbcfc09e770dc2729f', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 4, 'created': '2014-10-14 12:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec4c47e0b4ff5772206f7ef1b90c306b11362794', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 5, 'created': '2014-10-15 08:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d09951032f2be21f2b08f6e28382c0733c1098a', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 6, 'created': '2014-10-15 08:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4253b937ac236346fbf40911a3606df40a64acba', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 7, 'created': '2014-10-22 12:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53d17a20f7f078999ee39465b7693e7a692b6600', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nBlueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 8, 'created': '2014-11-10 13:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d140df5b38b61081a4d4f92421f3d3ddc4ff3e20', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nCleanup before Blueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 9, 'created': '2014-11-13 09:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3aef30b69266318b885e5c2eb9c534c9ab028050', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nCleanup before Blueprint: virt-driver-get-available-resources-object\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}, {'number': 10, 'created': '2014-12-08 17:36:07.000000000', 'files': ['nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/virt/vmwareapi/host.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6e31461553cb3d82ea0fdc4355f25b96ee1e8b7e', 'message': ""vmware: delete cpu_info data from get_available_resource\n\nThe 'cpu_info' field in the dict from get_available_resource\nis supposed to provide information on the physical CPU model\nused in the host. The topology was supposed to provide the\ntotal socket count, the cores per socket and the threads per\ncore.\n\nThe data provided by the VMWare driver did not remotely match\nthis definition. Instead the topology returned the total socket\ncount across the entire set of hypervisor hosts, the total core\ncount and the total thread count. The vendor/model information\nwas also not the same, instead of being a single name it returned\na list of names from each hypervisor host.\n\nJust delete the 'cpu_info' data entirely since there is nothing\nsensible that the VMWare driver can return for this field, given\nits 1:M  compute<->hypervisor relationship.\n\nCleanup before Blueprint: resource-objects\nChange-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6\n""}]",7,127573,6e31461553cb3d82ea0fdc4355f25b96ee1e8b7e,92,14,10,1779,,,0,"vmware: delete cpu_info data from get_available_resource

The 'cpu_info' field in the dict from get_available_resource
is supposed to provide information on the physical CPU model
used in the host. The topology was supposed to provide the
total socket count, the cores per socket and the threads per
core.

The data provided by the VMWare driver did not remotely match
this definition. Instead the topology returned the total socket
count across the entire set of hypervisor hosts, the total core
count and the total thread count. The vendor/model information
was also not the same, instead of being a single name it returned
a list of names from each hypervisor host.

Just delete the 'cpu_info' data entirely since there is nothing
sensible that the VMWare driver can return for this field, given
its 1:M  compute<->hypervisor relationship.

Cleanup before Blueprint: resource-objects
Change-Id: I2071a60d6ad8e1208ac56af8b95b2daa63582bb6
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/127573/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/driver.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/virt/vmwareapi/test_vm_util.py', 'nova/virt/vmwareapi/host.py', 'nova/tests/virt/vmwareapi/test_driver_api.py']",5,6c94a0be325f88bfe7df1f2ba144df3309175365,bp/resource-objects, self.assertIsNone(stats['cpu_info']),"from nova.openstack.common import jsonutils cpu_info = {""model"": [""Intel(R) Xeon(R)"", ""Intel(R) Xeon(R)""], ""vendor"": [""Intel"", ""Intel""], ""topology"": {""cores"": 16, ""threads"": 32}} self.assertEqual(stats['cpu_info'], jsonutils.dumps(cpu_info))",13,29
openstack%2Fnova~master~Icd0fe9bda6402d9bf7a4bab8077f0ce755703999,openstack/nova,master,Icd0fe9bda6402d9bf7a4bab8077f0ce755703999,libvirt: enable hyperv enlightenments for windows guests,MERGED,2014-12-08 17:21:39.000000000,2015-01-06 17:24:42.000000000,2015-01-06 17:24:39.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-12-08 17:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32860d3bdf816cc0683fe40fa18b16050bb6e268', 'message': ""libvirt: enable hyperv enlightenments for windows guests\n\nAll windows guests (ie os_type=windows) now get the following\nenabled\n\n       <features>\n         <hyperv>\n           <relaxed state='on'/>\n           <vapic state='on'/>\n           <spinlocks state='on' retries='8191'/>\n         </hyperv>\n       <features/>\n\nif running a new enough libvirt and QEMU\n\nCloses-bug: #1400315\nChange-Id: Icd0fe9bda6402d9bf7a4bab8077f0ce755703999\n""}, {'number': 2, 'created': '2014-12-11 16:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1e333f24c66eac78072eb2fce57999b6e0c7d83', 'message': ""libvirt: enable hyperv enlightenments for windows guests\n\nAll windows guests (ie os_type=windows) now get the following\nenabled\n\n       <features>\n         <hyperv>\n           <relaxed state='on'/>\n           <vapic state='on'/>\n           <spinlocks state='on' retries='8191'/>\n         </hyperv>\n       <features/>\n\nif running a new enough libvirt and QEMU\n\nCloses-bug: #1400315\nChange-Id: Icd0fe9bda6402d9bf7a4bab8077f0ce755703999\n""}, {'number': 3, 'created': '2014-12-16 11:44:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/12cf893fd9bc787d2c5c6ef0a8ca0f81582ead8a', 'message': ""libvirt: enable hyperv enlightenments for windows guests\n\nAll windows guests (ie os_type=windows) now get the following\nenabled\n\n       <features>\n         <hyperv>\n           <relaxed state='on'/>\n           <vapic state='on'/>\n           <spinlocks state='on' retries='8191'/>\n         </hyperv>\n       <features/>\n\nif running a new enough libvirt and QEMU\n\nCloses-bug: #1400315\nChange-Id: Icd0fe9bda6402d9bf7a4bab8077f0ce755703999\n""}]",5,140089,12cf893fd9bc787d2c5c6ef0a8ca0f81582ead8a,46,13,3,1779,,,0,"libvirt: enable hyperv enlightenments for windows guests

All windows guests (ie os_type=windows) now get the following
enabled

       <features>
         <hyperv>
           <relaxed state='on'/>
           <vapic state='on'/>
           <spinlocks state='on' retries='8191'/>
         </hyperv>
       <features/>

if running a new enough libvirt and QEMU

Closes-bug: #1400315
Change-Id: Icd0fe9bda6402d9bf7a4bab8077f0ce755703999
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/140089/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,32860d3bdf816cc0683fe40fa18b16050bb6e268,libvirt-win-timers," self.assertEqual(3, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureAPIC) self.assertIsInstance(cfg.features[2], vconfig.LibvirtConfigGuestFeatureHyperV) @mock.patch.object(host.Host, 'has_min_version') @mock.patch.object(objects.Flavor, 'get_by_id') def test_get_guest_config_windows_hyperv_feature1(self, mock_flavor, mock_version): def fake_version(lv_ver=None, hv_ver=None, hv_type=None): if lv_ver == (1, 0, 0) and hv_ver == (1, 1, 0): return True return False mock_version.side_effect = fake_version conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = objects.Instance(**self.test_instance) instance_ref['os_type'] = 'windows' flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) cfg = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) self.assertIsInstance(cfg.clock, vconfig.LibvirtConfigGuestClock) self.assertEqual(cfg.clock.offset, ""localtime"") self.assertEqual(3, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureAPIC) self.assertIsInstance(cfg.features[2], vconfig.LibvirtConfigGuestFeatureHyperV) self.assertTrue(cfg.features[2].relaxed) self.assertFalse(cfg.features[2].spinlocks) self.assertFalse(cfg.features[2].vapic) @mock.patch.object(host.Host, 'has_min_version') @mock.patch.object(objects.Flavor, 'get_by_id') def test_get_guest_config_windows_hyperv_feature2(self, mock_flavor, mock_version): mock_version.return_value = True conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = objects.Instance(**self.test_instance) instance_ref['os_type'] = 'windows' flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) cfg = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) self.assertIsInstance(cfg.clock, vconfig.LibvirtConfigGuestClock) self.assertEqual(cfg.clock.offset, ""localtime"") self.assertEqual(3, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureAPIC) self.assertIsInstance(cfg.features[2], vconfig.LibvirtConfigGuestFeatureHyperV) self.assertTrue(cfg.features[2].relaxed) self.assertTrue(cfg.features[2].spinlocks) self.assertTrue(cfg.features[2].vapic) ",,102,2
openstack%2Fnova~master~Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d,openstack/nova,master,Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d,Add methods for calculating CPU pinning,MERGED,2014-12-01 15:47:59.000000000,2015-01-06 17:24:20.000000000,2015-01-06 17:24:17.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-01 15:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d4dac62671868df5ac1c544418a57d4ee1ed5ac', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 2, 'created': '2014-12-02 15:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09bcfee1e67bc558a8037919716a7b24773f4819', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 3, 'created': '2014-12-02 19:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/573bb2cea6ff0c3a9705ea3129da5356bbbddcad', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 4, 'created': '2014-12-02 19:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf8a0c9385790bb127397099be67cc20d2750cda', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 5, 'created': '2014-12-03 16:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b5a728c5ed175809946cdb857f9c2b0bf1d07f4', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 6, 'created': '2014-12-04 10:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17aba019f0350a34d8ea55b92990b7655e1bee19', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 7, 'created': '2014-12-04 13:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09b2af3269ad23b01805d52bf0cff76331ecb5d5', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some  basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 8, 'created': '2014-12-04 18:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01665b4c375eaf204d0383697169ebd1e6ed7674', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 9, 'created': '2014-12-05 13:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/189ff7026d0bd981432d436127426ac07b2785ca', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 10, 'created': '2014-12-08 14:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2d91f2a65fb82a9dddd8aef9e820496d22f0fa7', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 11, 'created': '2014-12-08 18:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1843a67ba3556812e3ef66de93140c66ee0437e', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 12, 'created': '2014-12-09 15:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aeed9c8bbd11dac85731e0fa7a5b8b8be7041c82', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 13, 'created': '2014-12-09 18:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/969552bb4fc513fe0c45c6f2b575b748a429532e', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 14, 'created': '2015-01-05 16:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c36331a295c8c6f310c82b489021dff486c367e', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}, {'number': 15, 'created': '2015-01-06 10:35:35.000000000', 'files': ['nova/objects/numa.py', 'nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/objects/instance_numa_topology.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/892e4032acea379bac6d1ae18fc5271ea17c0131', 'message': 'Add methods for calculating CPU pinning\n\nThis commit adds some basic pinning logic that will allow us to make\npinning placements taking into consideration hyperthreading capabilities\nof the host (and instances if set).\n\n_numa_fit_instance_cell_with_pinning is the central method that will be\ncalled for each NUMA cell that will eventually be called from\nnuma_fit_instance_to_host for instances  that will require explicit CPU\npinning.\n\nNone of the methods here are meant to be exposed as public methods to be\ncalled outside of numa_fit_instance_to_host, however since they contain\nall the placement logic it is useful to test them separately.\n\nChange-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d\nBlueprint: virt-driver-cpu-pinning\n'}]",12,138101,892e4032acea379bac6d1ae18fc5271ea17c0131,111,13,15,5511,,,0,"Add methods for calculating CPU pinning

This commit adds some basic pinning logic that will allow us to make
pinning placements taking into consideration hyperthreading capabilities
of the host (and instances if set).

_numa_fit_instance_cell_with_pinning is the central method that will be
called for each NUMA cell that will eventually be called from
numa_fit_instance_to_host for instances  that will require explicit CPU
pinning.

None of the methods here are meant to be exposed as public methods to be
called outside of numa_fit_instance_to_host, however since they contain
all the placement logic it is useful to test them separately.

Change-Id: Ia846437f315bceb21d7ffd0cdfdd905a0b2d546d
Blueprint: virt-driver-cpu-pinning
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/138101/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py']",2,5d4dac62671868df5ac1c544418a57d4ee1ed5ac,bp/virt-driver-cpu-pinning,"def _can_pack_instance_cell(instance_pinning_cell, threads_per_core, cores_list): if threads_per_core * len(cores_list) < len(instance_pinning_cell): return False if instance_pinning_cell.siblings: return instance_pinning_cell.topology.threads <= threads_per_core else: return len(instance_pinning_cell) % threads_per_core == 0 def _pack_instance_onto_cores(available_siblings, instance_cell_pinning): """"""Pack an instance onto a set of siblings :param available_siblings: list of sets of CPU id's - available siblings per core :param instance_cell_pinning: An instance of objects.InstanceNUMACPUPinningCell describing the pinning requirements of the instance :returns: An instance of objects.InstanceNUMACPUPinningCell containing the pinning information, and potentially a new topology to be exposed to the instance. None if there is no valid way to satisfy the sibling requirements for the instance. This method will calculate the pinning for the given instance and it's topology, making sure that hyperthreads of the instance match up with those of the host when the pinning takes effect. """""" # We build up a data structure 'can_pack' that answers the question: # 'Given the number of threads I want to pack, give me a list of all # the available sibling sets that can accomodate it' can_pack = collections.defaultdict(list) for sib in available_siblings: for threads_no in range(1, len(sib) + 1): can_pack[threads_no].append(sib) # We iterate over the can_pack dict in descending order of cores that # can be packed - an attempt to get even distribution over time for cores_per_sib, sib_list in sorted( (t for t in can_pack.items()), reverse=True): if _can_pack_instance_cell(instance_cell_pinning, cores_per_sib, sib_list): sliced_sibs = map(lambda s: list(s)[:cores_per_sib], sib_list) if instance_cell_pinning.siblings: pinning = dict( zip(itertools.chain(*instance_cell_pinning.siblings), itertools.chain(*sliced_sibs))) else: pinning = dict(zip(sorted(instance_cell_pinning.cpuset), itertools.chain(*sliced_sibs))) topology = (instance_cell_pinning.topology or objects.VirtCPUTopology(sockets=1, cores=len(sliced_sibs), threads=cores_per_sib)) return objects.InstanceNUMACPUPinningCell( instance_cell_pinning.cpuset, pinning=pinning, topology=topology) def _numa_fit_instance_cell_with_pinning(host_cell_pinning, instance_cell_pinning): """"""Figure out if cells can be pinned to a host cell and return details :param host_cell_pinning: objects.NUMACPUPinningCell instance - the host cell that the isntance should be pinned to :param instance_cell_pinning: objects.InstanceNUMACPUPinningCell instance without any pinning information :returns: objects.InstanceNUMACPUPinningCell instance with pinning information, or None if instance cannot be pinned to the given host """""" # If we do not have enough CPUs available - bail early if len(host_cell_pinning.free_cpus) < len(instance_cell_pinning): return # There is hyperthreading enabled on the host so we want to make sure # we expose that to the guest if host_cell_pinning.siblings: available_siblings = [sibling_set & host_cell_pinning.free_cpus for sibling_set in host_cell_pinning.siblings] # Instance requires hyperthreading in it's topology - so we need to # pack it if instance_cell_pinning.topology and instance_cell_pinning.siblings: return _pack_instance_onto_cores(available_siblings, instance_cell_pinning) # If it does not and the host has hyperthreading - we have to # expose it else: largest_free_sibling_set = sorted( available_siblings, key=len)[-1] # We can pack the instance onto a single core if (len(instance_cell_pinning.cpuset) <= len(largest_free_sibling_set)): topology = (instance_cell_pinning.topology or objects.VirtCPUTopology( sockets=1, cores=1, threads=len(instance_cell_pinning))) return objects.InstanceNUMACPUPinningCell( instance_cell_pinning.cpuset.copy(), pinning=dict( zip(sorted(instance_cell_pinning.cpuset), largest_free_sibling_set)), topology=topology) # We can't so we need to pack it anyway and update the topology else: return _pack_instance_onto_cores(available_siblings, instance_cell_pinning) else: # Straightforward to pin to available cpus when there is no # hyperthreading on the host to_pin = sorted( host_cell_pinning.free_cpus)[:len(instance_cell_pinning)] return objects.InstanceNUMACPUPinningCell( instance_cell_pinning.cpuset, pinning=dict( zip(sorted(instance_cell_pinning.cpuset), to_pin)), topology=instance_cell_pinning.topology) ",,233,0
openstack%2Fhorizon~master~Iedf794470b159792d0d2bfa4a1b2341681f68ae4,openstack/horizon,master,Iedf794470b159792d0d2bfa4a1b2341681f68ae4,Imported Translations from Transifex,MERGED,2015-01-06 06:04:40.000000000,2015-01-06 17:24:05.000000000,2015-01-06 17:24:04.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4978}]","[{'number': 1, 'created': '2015-01-06 06:04:40.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9b5d8764f0bc6a262916a9ec0c325f39e58f0772', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iedf794470b159792d0d2bfa4a1b2341681f68ae4\n'}]",0,145134,9b5d8764f0bc6a262916a9ec0c325f39e58f0772,8,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iedf794470b159792d0d2bfa4a1b2341681f68ae4
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/145134/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,9b5d8764f0bc6a262916a9ec0c325f39e58f0772,transifex/translations,"""POT-Creation-Date: 2015-01-05 15:30-0600\n"" ""PO-Revision-Date: 2015-01-05 20:29+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgid ""Volume of RAM used in MB"" msgstr """" #: api/ceilometer.py:938#: api/ceilometer.py:942#: api/ceilometer.py:946#: api/ceilometer.py:950#: api/ceilometer.py:954#: api/ceilometer.py:958#: api/ceilometer.py:962#: api/ceilometer.py:966 msgid ""Average rate of read requests per second"" msgstr """" #: api/ceilometer.py:970 msgid ""Average rate of write requests per second"" msgstr """" #: api/ceilometer.py:974 msgid ""Average rate of reads in B per second"" msgstr """" #: api/ceilometer.py:978 msgid ""Average volume of writes in B per second"" msgstr """" #: api/ceilometer.py:982#: api/ceilometer.py:986#: api/ceilometer.py:991#: api/ceilometer.py:996#: api/ceilometer.py:1001#: api/ceilometer.py:1006#: api/ceilometer.py:1011 msgid ""Average rate per sec of incoming bytes on a VM network interface"" msgstr """" #: api/ceilometer.py:1016 msgid ""Average rate per sec of outgoing bytes on a VM network interface"" msgstr """" #: api/ceilometer.py:1021 msgid ""Average rate per sec of incoming packets on a VM network interface"" msgstr """" #: api/ceilometer.py:1026 msgid ""Average rate per sec of outgoing packets on a VM network interface"" msgstr """" #: api/ceilometer.py:1038#: api/ceilometer.py:1058#: api/ceilometer.py:1062#: api/ceilometer.py:1066#: api/ceilometer.py:1070#: api/ceilometer.py:1074#: api/ceilometer.py:1078#: api/ceilometer.py:1082#: api/ceilometer.py:1086#: api/ceilometer.py:1090#: api/ceilometer.py:1094#: api/ceilometer.py:1098#: api/ceilometer.py:1102#: api/ceilometer.py:1106#: api/ceilometer.py:1110#: api/ceilometer.py:1114#: api/ceilometer.py:1131#: api/ceilometer.py:1135#: api/ceilometer.py:1139#: api/ceilometer.py:1143#: api/ceilometer.py:1147#: api/ceilometer.py:1151#: api/ceilometer.py:1155#: api/ceilometer.py:1172#: api/ceilometer.py:1176#: api/ceilometer.py:1193#: api/ceilometer.py:1197#: api/ceilometer.py:1201#: api/ceilometer.py:1205#: api/ceilometer.py:1209#: api/ceilometer.py:1213#: api/ceilometer.py:1230#: api/ceilometer.py:1234#: api/neutron.py:868#: api/neutron.py:905#: api/neutron.py:1044#: api/neutron.py:1062#: api/neutron.py:1077#: dashboards/identity/projects/tables.py:225#: dashboards/admin/aggregates/panel.py:26#: dashboards/identity/projects/workflows.py:551#: dashboards/identity/projects/tables.py:235 #: dashboards/identity/projects/tables.py:237#: dashboards/identity/projects/tables.py:229#: dashboards/project/network_topology/templates/network_topology/_svg_element.html:177 #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:220#: dashboards/identity/projects/tables.py:234#: dashboards/identity/projects/tables.py:243#: dashboards/identity/projects/workflows.py:550#: dashboards/identity/projects/tables.py:216#: dashboards/identity/projects/workflows.py:533#: dashboards/identity/projects/workflows.py:530 msgid ""You cannot disable your current project"" msgstr """" #: dashboards/identity/projects/workflows.py:535#: dashboards/identity/projects/workflows.py:552#: dashboards/identity/projects/workflows.py:553#: dashboards/identity/projects/workflows.py:642#: dashboards/identity/projects/workflows.py:702#: dashboards/identity/projects/workflows.py:706#: dashboards/identity/projects/workflows.py:783#: dashboards/identity/projects/workflows.py:817#: dashboards/project/network_topology/templates/network_topology/_svg_element.html:202#: dashboards/project/firewalls/panel.py:26#: dashboards/project/loadbalancers/panel.py:26#: dashboards/project/network_topology/templates/network_topology/_svg_element.html:184#: dashboards/project/vpn/panel.py:28","""POT-Creation-Date: 2014-12-24 15:19-0600\n"" ""PO-Revision-Date: 2014-12-28 06:01+0000\n"" ""Last-Translator: Tom Fifield <tom@openstack.org>\n""#: api/ceilometer.py:938#: api/ceilometer.py:942#: api/ceilometer.py:946#: api/ceilometer.py:950#: api/ceilometer.py:954#: api/ceilometer.py:958#: api/ceilometer.py:962#: api/ceilometer.py:966#: api/ceilometer.py:971#: api/ceilometer.py:976#: api/ceilometer.py:981#: api/ceilometer.py:986#: api/ceilometer.py:998#: api/ceilometer.py:1018#: api/ceilometer.py:1022#: api/ceilometer.py:1026#: api/ceilometer.py:1030#: api/ceilometer.py:1034#: api/ceilometer.py:1038#: api/ceilometer.py:1042#: api/ceilometer.py:1046#: api/ceilometer.py:1050#: api/ceilometer.py:1054#: api/ceilometer.py:1058#: api/ceilometer.py:1062#: api/ceilometer.py:1066#: api/ceilometer.py:1070#: api/ceilometer.py:1074#: api/ceilometer.py:1091#: api/ceilometer.py:1095#: api/ceilometer.py:1099#: api/ceilometer.py:1103#: api/ceilometer.py:1107#: api/ceilometer.py:1111#: api/ceilometer.py:1115#: api/ceilometer.py:1132#: api/ceilometer.py:1136#: api/ceilometer.py:1153#: api/ceilometer.py:1157#: api/ceilometer.py:1161#: api/ceilometer.py:1165#: api/ceilometer.py:1169#: api/ceilometer.py:1173#: api/ceilometer.py:1190#: api/ceilometer.py:1194#: api/neutron.py:859#: api/neutron.py:896#: api/neutron.py:1035#: api/neutron.py:1053#: api/neutron.py:1068#: dashboards/identity/projects/tables.py:222#: dashboards/admin/aggregates/panel.py:22#: dashboards/identity/projects/workflows.py:543#: dashboards/identity/projects/tables.py:232 #: dashboards/identity/projects/tables.py:234#: dashboards/identity/projects/tables.py:226#: dashboards/identity/projects/tables.py:231#: dashboards/identity/projects/tables.py:240#: dashboards/identity/projects/workflows.py:542#: dashboards/identity/projects/tables.py:213#: dashboards/identity/projects/workflows.py:525#: dashboards/identity/projects/workflows.py:527#: dashboards/identity/projects/workflows.py:544#: dashboards/identity/projects/workflows.py:545#: dashboards/identity/projects/workflows.py:634#: dashboards/identity/projects/workflows.py:694#: dashboards/identity/projects/workflows.py:698#: dashboards/identity/projects/workflows.py:775#: dashboards/identity/projects/workflows.py:809#: dashboards/project/network_topology/templates/network_topology/_svg_element.html:196#: dashboards/project/firewalls/panel.py:22#: dashboards/project/loadbalancers/panel.py:22#: dashboards/project/network_topology/templates/network_topology/_svg_element.html:178#: dashboards/project/vpn/panel.py:24",2058,1344
openstack%2Fnova~master~If8da95ed36bd33506ce2370fe829acab468708b7,openstack/nova,master,If8da95ed36bd33506ce2370fe829acab468708b7,Use controller methods directly in test_admin_password,MERGED,2014-12-31 05:04:23.000000000,2015-01-06 17:23:48.000000000,2015-01-06 17:23:44.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13663}]","[{'number': 1, 'created': '2014-12-31 05:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c62e86a00eb38501174d39000d375f865a70566', 'message': ""Use controller methods directly in test_admin_password\n\nIn API unit testing, making call through WSGI is little bit overhead,\nwherever applicable, unit tests can make direct call to controller\nmethods.\nAlso URL given in controller method's request is not used\n(for direct call to controller methods), so pass blank URL\nto avoid confusion as tests are shared between V2 & V2.1\n\n1. This patch makes above cleanup in test_admin_password\n2. This patch cleans some codes with mock\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: If8da95ed36bd33506ce2370fe829acab468708b7\n""}, {'number': 2, 'created': '2015-01-04 02:50:59.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_admin_password.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4aed7a2543aaa2dd45b7a0156556ea3ae7079800', 'message': ""Use controller methods directly in test_admin_password\n\nIn API unit testing, making call through WSGI is little bit overhead,\nwherever applicable, unit tests can make direct call to controller\nmethods.\nAlso URL given in controller method's request is not used\n(for direct call to controller methods), so pass blank URL\nto avoid confusion as tests are shared between V2 & V2.1\n\n1. This patch makes above cleanup in test_admin_password\n2. This patch cleans some codes with mock\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: If8da95ed36bd33506ce2370fe829acab468708b7\n""}]",5,144575,4aed7a2543aaa2dd45b7a0156556ea3ae7079800,20,11,2,13663,,,0,"Use controller methods directly in test_admin_password

In API unit testing, making call through WSGI is little bit overhead,
wherever applicable, unit tests can make direct call to controller
methods.
Also URL given in controller method's request is not used
(for direct call to controller methods), so pass blank URL
to avoid confusion as tests are shared between V2 & V2.1

1. This patch makes above cleanup in test_admin_password
2. This patch cleans some codes with mock

Partially implements blueprint v2-on-v3-api

Change-Id: If8da95ed36bd33506ce2370fe829acab468708b7
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/144575/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/contrib/test_admin_password.py'],1,4c62e86a00eb38501174d39000d375f865a70566,bp/v2-on-v3-api,"import mockclass AdminPasswordTestV21(test.NoDBTestCase): self.controller = admin_password_v21.AdminPasswordController() self.fake_req = fakes.HTTPRequest.blank('') self.controller.change_password(self.fake_req, '1', body=body) self.assertEqual(self.controller.change_password.wsgi_code, 202) self.controller.change_password(self.fake_req, '1', body=body) self.assertEqual(self.controller.change_password.wsgi_code, 202) @mock.patch('nova.compute.api.API.set_admin_password', side_effect=NotImplementedError()) def test_change_password_with_non_implement(self, mock_set_admin_password): self.assertRaises(webob.exc.HTTPNotImplemented, self.controller.change_password, self.fake_req, '1', body=body) @mock.patch('nova.compute.api.API.get', side_effect=exception.InstanceNotFound(instance_id=id)) def test_change_password_with_non_existed_instance(self, mock_get): self.assertRaises(webob.exc.HTTPNotFound, self.controller.change_password, self.fake_req, '1', body=body) self.assertRaises(exception.ValidationError, self.controller.change_password, self.fake_req, '1', body=body) @mock.patch('nova.compute.api.API.set_admin_password', side_effect=exception.InstancePasswordSetFailed(instance=""1"", reason='')) def test_change_password_failed(self, mock_set_admin_password): self.assertRaises(webob.exc.HTTPConflict, self.controller.change_password, self.fake_req, '1', body=body) self.assertRaises(exception.ValidationError, self.controller.change_password, self.fake_req, '1', body=body) self.assertRaises(exception.ValidationError, self.controller.change_password, self.fake_req, '1', body=body)","from oslo.serialization import jsonutilsdef fake_get_non_existent(self, context, id, expected_attrs=None, want_objects=False): raise exception.InstanceNotFound(instance_id=id) def fake_set_admin_password_failed(self, context, instance, password=None): raise exception.InstancePasswordSetFailed(instance=instance, reason='') def fake_set_admin_password_not_implemented(self, context, instance, password=None): raise NotImplementedError() class AdminPasswordTestV21(test.NoDBTestCase): plugin = admin_password_v21 self.app = fakes.wsgi_app_v21(init_only=('servers', self.plugin.ALIAS)) def _make_request(self, body): req = webob.Request.blank('/v2/fake/servers/1/action') req.method = 'POST' req.body = jsonutils.dumps(body) req.content_type = 'application/json' res = req.get_response(self.app) return res res = self._make_request(body) self.assertEqual(res.status_int, 202) res = self._make_request(body) self.assertEqual(res.status_int, 202) def test_change_password_with_non_implement(self): self.stubs.Set(compute_api.API, 'set_admin_password', fake_set_admin_password_not_implemented) res = self._make_request(body) self.assertEqual(res.status_int, 501) def test_change_password_with_non_existed_instance(self): self.stubs.Set(compute_api.API, 'get', fake_get_non_existent) res = self._make_request(body) self.assertEqual(res.status_int, 404) res = self._make_request(body) self.assertEqual(res.status_int, 400) def test_change_password_failed(self): self.stubs.Set(compute_api.API, 'set_admin_password', fake_set_admin_password_failed) res = self._make_request(body) self.assertEqual(res.status_int, 409) res = self._make_request(body) self.assertEqual(res.status_int, 400) res = self._make_request(body) self.assertEqual(res.status_int, 400)",35,50
openstack%2Fnova~master~I5e145a8973c3dc0d41fba6073f3e5366f9c87764,openstack/nova,master,I5e145a8973c3dc0d41fba6073f3e5366f9c87764,Adds scheduler image extra requirements check,ABANDONED,2014-11-26 17:53:40.000000000,2015-01-06 17:11:41.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 8213}, {'_account_id': 8412}, {'_account_id': 8543}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10635}]","[{'number': 1, 'created': '2014-11-26 17:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7366639457a802253a4b69df0ca15e60c276428', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 2, 'created': '2014-11-27 14:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95189aba91cadce287dac02f6512e2386213d0cd', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 3, 'created': '2014-11-27 14:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3dd28a591a9a80c05be63834857e7c4d072228fe', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 4, 'created': '2014-11-27 17:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3382cbe84742fdf171d39d59c71e4127142ce53', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 5, 'created': '2014-11-28 15:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68581d2cdc47e78d339cc1cc7c30906023a53739', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 6, 'created': '2014-12-02 17:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0273b5725840e64155c959d72f27ba08fd55166e', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 7, 'created': '2014-12-03 23:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a4f7502d0d5a12653100f092fb3a71f697a043e', 'message': ""Adds scheduler compute extra_resources filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 8, 'created': '2014-12-10 17:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1124a352e75fc9e780bdf917a23f28256b728b1d', 'message': ""Adds scheduler compute extra_features filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 9, 'created': '2014-12-11 13:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc4fc71e9970c04beb4475f9ca805a4ed76d9287', 'message': ""Adds scheduler compute extra_features filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 10, 'created': '2014-12-16 09:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55d32f0dbd2da824f8cbb4460c3d9d19d0b42600', 'message': ""Adds scheduler compute extra_features filter\n\nAdds a filter which determines whether a host satisfies special\nrequirements for deploying certain instances. This is determined\nvia Compute Node's extra_resources.\n\nSuch a filter is useful for determining which hosts will support\ncertain generations of VMs.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 11, 'created': '2014-12-19 17:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9288b698041da0798464b1b8bbb7f2ec34fd1d11', 'message': ""Adds scheduler image extra requirements check\n\nEnhances ImagePropertyFilter by determining whether a host\nsatisfies any extra requirements for deploying certain instances.\nThis is determined by checking if the instance's image properties\nhaving the 'hypervisor:' prefix are found within the compute\nnode's stats.\n\nThis enhancement is useful for determining which hosts will\nsupport certain image requirements. E.g certain images can only\nbe used in Generation 2 VMs and determining which hosts support\nthis feature is crucial.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 12, 'created': '2015-01-05 18:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f2ce159ca1b5ad80bce2b40a972b28c2551fef6', 'message': ""Adds scheduler image extra requirements check\n\nEnhances ImagePropertyFilter by determining whether a host\nsatisfies any extra requirements for deploying certain instances.\nThis is determined by checking if the instance's image properties\nhaving the 'hypervisor:' prefix are found within the compute\nnode's stats.\n\nThis enhancement is useful for determining which hosts will\nsupport certain image requirements. E.g certain images can only\nbe used in Generation 2 VMs and determining which hosts support\nthis feature is crucial.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}, {'number': 13, 'created': '2015-01-05 21:33:34.000000000', 'files': ['nova/scheduler/filters/image_props_filter.py', 'doc/source/devref/filter_scheduler.rst', 'nova/tests/unit/scheduler/filters/test_image_props_filters.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c767695023a4b1858272c432e7545b6a8867e771', 'message': ""Adds scheduler image extra requirements check\n\nEnhances ImagePropertyFilter by determining whether a host\nsatisfies any extra requirements for deploying certain instances.\nThis is determined by checking if the instance's image properties\nhaving the 'hypervisor:' prefix are found within the compute\nnode's stats.\n\nThis enhancement is useful for determining which hosts will\nsupport certain image requirements. E.g certain images can only\nbe used in Generation 2 VMs and determining which hosts support\nthis feature is crucial.\n\nDocImpact\n\nPartially implements: blueprint hyper-v-generation-2-vms\n\nChange-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764\n""}]",23,137430,c767695023a4b1858272c432e7545b6a8867e771,112,15,13,8213,,,0,"Adds scheduler image extra requirements check

Enhances ImagePropertyFilter by determining whether a host
satisfies any extra requirements for deploying certain instances.
This is determined by checking if the instance's image properties
having the 'hypervisor:' prefix are found within the compute
node's stats.

This enhancement is useful for determining which hosts will
support certain image requirements. E.g certain images can only
be used in Generation 2 VMs and determining which hosts support
this feature is crucial.

DocImpact

Partially implements: blueprint hyper-v-generation-2-vms

Change-Id: I5e145a8973c3dc0d41fba6073f3e5366f9c87764
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/137430/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/compute_extra_resources_filter.py', 'nova/tests/unit/scheduler/filters/test_compute_extra_resources_filter.py', 'nova/scheduler/host_manager.py']",3,d7366639457a802253a4b69df0ca15e60c276428,bp/hyper-v-generation-2-vms," 'ComputeExtraResourcesFilter',",,154,0
openstack%2Fnova~master~I05a8a4e728efd95edca627271378172834d0df41,openstack/nova,master,I05a8a4e728efd95edca627271378172834d0df41,Adds extra_resources to scheduler HostStats class,ABANDONED,2014-11-26 17:53:40.000000000,2015-01-06 17:10:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-26 17:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95ba10535d63e6da8ce3ef0c734f7faa8b69f2f6', 'message': 'Adds extra_resources to scheduler HostStats class\n\nThis commit is necessary to create a filter for compute extra_resources,\nuseful for the schedule to determine which hosts are viable for\nrequests with certain resource requirements.\n\nFor example, such a filter is useful for determining which hosts will\nsupport certain generations of VMs.\n\nChange-Id: I05a8a4e728efd95edca627271378172834d0df41\n'}, {'number': 2, 'created': '2014-11-27 14:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e605d4a81a2c4711552d28ee2148448122d343bf', 'message': 'Adds extra_resources to scheduler HostStats class\n\nThis commit is necessary to create a filter for compute extra_resources,\nuseful for the schedule to determine which hosts are viable for\nrequests with certain resource requirements.\n\nFor example, such a filter is useful for determining which hosts will\nsupport certain generations of VMs.\n\nChange-Id: I05a8a4e728efd95edca627271378172834d0df41\n'}, {'number': 3, 'created': '2014-12-02 17:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/620f1bbc6f98349c26d8371a1f697339c31bed1b', 'message': 'Adds extra_resources to scheduler HostStats class\n\nThis commit is necessary to create a filter for compute extra_resources,\nuseful for the schedule to determine which hosts are viable for\nrequests with certain resource requirements.\n\nFor example, such a filter is useful for determining which hosts will\nsupport certain generations of VMs.\n\nChange-Id: I05a8a4e728efd95edca627271378172834d0df41\n'}, {'number': 4, 'created': '2014-12-03 23:28:42.000000000', 'files': ['nova/tests/unit/scheduler/test_host_manager.py', 'nova/tests/unit/scheduler/fakes.py', 'nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3d9f9ffd658c5ff0df13aa4abc9b3b913ad9d49d', 'message': 'Adds extra_resources to scheduler HostStats class\n\nThis commit is necessary to create a filter for compute extra_resources,\nuseful for the schedule to determine which hosts are viable for\nrequests with certain resource requirements.\n\nFor example, such a filter is useful for determining which hosts will\nsupport certain generations of VMs.\n\nChange-Id: I05a8a4e728efd95edca627271378172834d0df41\n'}]",2,137429,3d9f9ffd658c5ff0df13aa4abc9b3b913ad9d49d,50,11,4,8213,,,0,"Adds extra_resources to scheduler HostStats class

This commit is necessary to create a filter for compute extra_resources,
useful for the schedule to determine which hosts are viable for
requests with certain resource requirements.

For example, such a filter is useful for determining which hosts will
support certain generations of VMs.

Change-Id: I05a8a4e728efd95edca627271378172834d0df41
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/137429/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/test_host_manager.py', 'nova/tests/unit/scheduler/fakes.py', 'nova/scheduler/host_manager.py']",3,95ba10535d63e6da8ce3ef0c734f7faa8b69f2f6,bp/hyper-v-generation-2-vms, self.extra_resources = None if compute.get('extra_resources'): self.extra_resources = jsonutils.loads( compute.get('extra_resources')),,12,1
openstack%2Fneutron~feature%2Flbaasv2~I7615cdd5eb8cc9733f5db62c687c04682563fecd,openstack/neutron,feature/lbaasv2,I7615cdd5eb8cc9733f5db62c687c04682563fecd,TLS capability extension implementation for lbaas v2,ABANDONED,2014-09-23 16:03:10.000000000,2015-01-06 17:10:41.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7249}, {'_account_id': 8446}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 12040}, {'_account_id': 13375}]","[{'number': 1, 'created': '2014-09-23 16:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25ae8dee4f7ede8db85c089f4de9ba54564a0db2', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\nCo-Authored-By: Evgeny Fedoruk <evgenyf@radware.com>\nCo-Authored-By: Doug Wiegley <dougw@a10networks.com>\n'}, {'number': 2, 'created': '2014-10-15 07:44:16.000000000', 'files': ['neutron/db/loadbalancer/models.py', 'neutron/services/loadbalancer/data_models.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/loadbalancer/constants.py', 'neutron/db/migration/alembic_migrations/versions/6815e9450v77_tls_extension.py', 'neutron/extensions/loadbalancerv2.py', 'neutron/db/loadbalancer/loadbalancer_dbv2.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4ffea81c538610ea613a2475cca7a684913108c', 'message': 'TLS capability extension implementation for lbaas v2\n\nIncluding extension and db model modifications\nIncluding db model unit testing\nIncluding alembic migration\nIncluding usage of new common module for Barbican TLS containers API interaction\n\nChange-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd\nImplements: blueprint lbaas-ssl-termination\nCo-Authored-By: Evgeny Fedoruk <evgenyf@radware.com>\nCo-Authored-By: Doug Wiegley <dougw@a10networks.com>\n'}]",13,123495,e4ffea81c538610ea613a2475cca7a684913108c,39,20,2,10980,,,0,"TLS capability extension implementation for lbaas v2

Including extension and db model modifications
Including db model unit testing
Including alembic migration
Including usage of new common module for Barbican TLS containers API interaction

Change-Id: I7615cdd5eb8cc9733f5db62c687c04682563fecd
Implements: blueprint lbaas-ssl-termination
Co-Authored-By: Evgeny Fedoruk <evgenyf@radware.com>
Co-Authored-By: Doug Wiegley <dougw@a10networks.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/123495/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/models.py', 'neutron/services/loadbalancer/data_models.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/loadbalancer/constants.py', 'neutron/db/migration/alembic_migrations/versions/6815e9450v77_tls_extension.py', 'neutron/extensions/loadbalancerv2.py', 'neutron/db/loadbalancer/loadbalancer_dbv2.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py']",9,25ae8dee4f7ede8db85c089f4de9ba54564a0db2,bp/lbaas-ssl-termination,"import mock 'connection_limit', 'admin_state_up', 'default_tls_container_id', 'sni_container_ids') def test_create_listener_with_tls_no_default_container(self, **extras): listener_data = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': None, 'protocol_port': 443, 'admin_state_up': True, 'tenant_id': self._tenant_id, 'status': constants.DEFERRED } listener_data.update(extras) ctx = context.get_admin_context() self.assertRaises( loadbalancerv2.TLSDefaultContainerNotSpecified, self.plugin.create_listener, ctx, {'listener': listener_data}) def test_create_listener_with_tls_invalid_container(self, **extras): default_tls_container_id = uuidutils.generate_uuid() listener_data = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': default_tls_container_id, 'sni_container_ids': [], 'protocol_port': 443, 'admin_state_up': True, 'tenant_id': self._tenant_id, 'status': constants.DEFERRED } listener_data.update(extras) with mock.patch('neutron.common.barbican_utils.BarbicanUtils', autospec=True) as barbican_utils_mock: barbican_utils_mock.validateContainer.return_value = False ctx = context.get_admin_context() self.assertRaises(loadbalancerv2.TLSContainerInvalid, self.plugin.create_listener, ctx, {'listener': listener_data}) def test_create_listener_with_tls(self, **extras): default_tls_container_id = uuidutils.generate_uuid() sni_tls_container_id_1 = uuidutils.generate_uuid() sni_tls_container_id_2 = uuidutils.generate_uuid() expected = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': default_tls_container_id, 'sni_container_ids': [sni_tls_container_id_1, sni_tls_container_id_2] } extras['default_tls_container_id'] = default_tls_container_id extras['sni_container_ids'] = [sni_tls_container_id_1, sni_tls_container_id_2] with self.listener(protocol=lb_const.PROTOCOL_TERMINATED_HTTPS, **extras) as listener: self.assertEqual( dict((k, v) for k, v in listener['listener'].items() if k in expected), expected ) def test_update_listener_with_tls(self): default_tls_container_id = uuidutils.generate_uuid() sni_tls_container_id_1 = uuidutils.generate_uuid() sni_tls_container_id_2 = uuidutils.generate_uuid() sni_tls_container_id_3 = uuidutils.generate_uuid() sni_tls_container_id_4 = uuidutils.generate_uuid() sni_tls_container_id_5 = uuidutils.generate_uuid() listener_data = { 'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS, 'default_tls_container_id': default_tls_container_id, 'sni_container_ids': [sni_tls_container_id_1, sni_tls_container_id_2], 'protocol_port': 443, 'admin_state_up': True, 'tenant_id': self._tenant_id, } with mock.patch('neutron.common.barbican_utils.BarbicanUtils', autospec=True) as barbican_utils_mock: # Default container and two SNI containers # Test order and validation behavior. listener = self.plugin.create_listener(context.get_admin_context(), {'listener': listener_data}) self.assertEqual(listener['sni_container_ids'], [sni_tls_container_id_1, sni_tls_container_id_2]) calls = [mock.call(default_tls_container_id), mock.call(sni_tls_container_id_1), mock.call(sni_tls_container_id_2)] barbican_utils_mock.validateContainer.assert_has_calls( calls, any_order=True) barbican_utils_mock.reset_mock() # Default container and two other SNI containers # Test order and validation behavior. listener_data['sni_container_ids'] = [sni_tls_container_id_3, sni_tls_container_id_4] listener = self.plugin.update_listener(context.get_admin_context(), listener['id'], {'listener': listener_data}) self.assertEqual(listener['sni_container_ids'], [sni_tls_container_id_3, sni_tls_container_id_4]) calls = [mock.call(sni_tls_container_id_3), mock.call(sni_tls_container_id_4)] barbican_utils_mock.validateContainer.assert_has_calls( calls, any_order=True) barbican_utils_mock.reset_mock() # Default container, two old SNI containers ordered differently # and one new SNI container. # Test order and validation behavior. listener_data['sni_container_ids'] = [sni_tls_container_id_4, sni_tls_container_id_3, sni_tls_container_id_5] listener = self.plugin.update_listener(context.get_admin_context(), listener['id'], {'listener': listener_data}) self.assertEqual(listener['sni_container_ids'], [sni_tls_container_id_4, sni_tls_container_id_3, sni_tls_container_id_5]) calls = [mock.call(sni_tls_container_id_5)] barbican_utils_mock.validateContainer.assert_has_calls( calls, any_order=True) "," 'connection_limit', 'admin_state_up')",356,11
openstack%2Fsolum~master~Ie819da57d07b7213241757af9ea7c8d55a1e66b5,openstack/solum,master,Ie819da57d07b7213241757af9ea7c8d55a1e66b5,Clean up after test_language_packs_get_all Try 2 Closes-Bug: #1406647,MERGED,2014-12-30 22:17:12.000000000,2015-01-06 17:03:33.000000000,2015-01-06 17:03:32.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 9095}, {'_account_id': 10068}, {'_account_id': 14484}]","[{'number': 1, 'created': '2014-12-30 22:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4cd99bc0b796ba1748f6dbdf164651e0dedecb37', 'message': 'Clean up after test_language_packs_get_all\nCloses-Bug: #1406647\n\nChange-Id: Ie819da57d07b7213241757af9ea7c8d55a1e66b5\n'}, {'number': 2, 'created': '2014-12-31 00:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f9ceea57783ef4868efefd65ca7b09dfcf215b31', 'message': 'Clean up after test_language_packs_get_all\nTry 2\nCloses-Bug: #1406647\n\nChange-Id: Ie819da57d07b7213241757af9ea7c8d55a1e66b5\n'}, {'number': 3, 'created': '2015-01-06 04:37:50.000000000', 'files': ['functionaltests/api/v1/test_language_pack.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/4e13ef6f92a3930678126ef4fb0e2e70124ce375', 'message': 'Clean up after test_language_packs_get_all\nTry 2\nCloses-Bug: #1406647\n\nChange-Id: Ie819da57d07b7213241757af9ea7c8d55a1e66b5\n'}]",0,144530,4e13ef6f92a3930678126ef4fb0e2e70124ce375,23,6,3,14484,,,0,"Clean up after test_language_packs_get_all
Try 2
Closes-Bug: #1406647

Change-Id: Ie819da57d07b7213241757af9ea7c8d55a1e66b5
",git fetch https://review.opendev.org/openstack/solum refs/changes/30/144530/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/api/v1/test_language_pack.py'],1,4cd99bc0b796ba1748f6dbdf164651e0dedecb37,bug/1406647, self._delete_language_pack(uuid),,1,0
openstack%2Frequirements~master~I5d8d7a4bdbce16fa54e959d8f2cfec189235f6f4,openstack/requirements,master,I5d8d7a4bdbce16fa54e959d8f2cfec189235f6f4,"Revert ""Add a tox env to check requirements overlap""",ABANDONED,2014-12-17 01:34:32.000000000,2015-01-06 16:55:47.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-17 01:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/15f7c8be27c832b114768e36b0bd44701ae9dedf', 'message': 'Revert ""Add a tox env to check requirements overlap""\n\nThis reverts commit f3127601efc483f0949c8eb58d74d7f29caf8a66.\n\nThe job his was for was removed in https://review.openstack.org/#/c/142152/\n\nChange-Id: I5d8d7a4bdbce16fa54e959d8f2cfec189235f6f4\n'}, {'number': 2, 'created': '2014-12-17 01:35:27.000000000', 'files': ['tests/test_versions_overlap_parent.py', 'versions_overlap_parent.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/requirements/commit/04a61f1dda05bf66fbfaa8ea488ae847b718c072', 'message': 'Revert ""Add a tox env to check requirements overlap""\n\nThis reverts commit f3127601efc483f0949c8eb58d74d7f29caf8a66.\n\nThe job for this was for was removed in https://review.openstack.org/#/c/142152/\n\nChange-Id: I5d8d7a4bdbce16fa54e959d8f2cfec189235f6f4\n'}]",0,142296,04a61f1dda05bf66fbfaa8ea488ae847b718c072,3,1,2,6316,,,0,"Revert ""Add a tox env to check requirements overlap""

This reverts commit f3127601efc483f0949c8eb58d74d7f29caf8a66.

The job for this was for was removed in https://review.openstack.org/#/c/142152/

Change-Id: I5d8d7a4bdbce16fa54e959d8f2cfec189235f6f4
",git fetch https://review.opendev.org/openstack/requirements refs/changes/96/142296/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_versions_overlap_parent.py', 'versions_overlap_parent.py', 'tox.ini']",3,15f7c8be27c832b114768e36b0bd44701ae9dedf,bug/1326504,,[testenv:versions-overlap-parent] commands = python versions_overlap_parent.py ,0,258
openstack%2Foslo.i18n~master~Ib944a467598fa544e0a1fc7e64db57dacffa4892,openstack/oslo.i18n,master,Ib944a467598fa544e0a1fc7e64db57dacffa4892,Fix the link to the bug tracker in the README,MERGED,2015-01-06 15:17:00.000000000,2015-01-06 16:54:36.000000000,2015-01-06 16:54:36.000000000,"[{'_account_id': 3}, {'_account_id': 6601}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-01-06 15:17:00.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/0ce52c22b6929dcb0b5922ab226dbaae6c96dc81', 'message': 'Fix the link to the bug tracker in the README\n\nChange-Id: Ib944a467598fa544e0a1fc7e64db57dacffa4892\n'}]",0,145246,0ce52c22b6929dcb0b5922ab226dbaae6c96dc81,7,3,1,2472,,,0,"Fix the link to the bug tracker in the README

Change-Id: Ib944a467598fa544e0a1fc7e64db57dacffa4892
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/46/145246/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,0ce52c22b6929dcb0b5922ab226dbaae6c96dc81,fix-bug-tracker-link,* Bugs: http://bugs.launchpad.net/oslo.i18n,* Bugs: http://bugs.launchpad.net/oslo,1,1
openstack%2Ftrove~master~I7682fe240c5737438b084d813cf7ce80b4ecca9b,openstack/trove,master,I7682fe240c5737438b084d813cf7ce80b4ecca9b,Config Group Load Fails If DS Version Inactive,MERGED,2014-10-17 06:19:47.000000000,2015-01-06 16:49:14.000000000,2015-01-06 16:49:13.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 10139}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 10725}, {'_account_id': 13355}]","[{'number': 1, 'created': '2014-10-17 06:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3c5f508aaa3cacf17d12cc5dbf5af92d91d3580f', 'message': ""Config Group Load Fails If DS Version Inactive\n\ntrove-manage db_load_datastore_config_parameters will fail if\nthe datastore_version on which it's being run is marked as\ninactive (aka active is set to 0).\n\nthis is not correct, because it's completely reasonable to want\nto update/refresh a datastore_version's configuration-group's\nparameters even if it's inactive.\n\nexamples:\n- you're working on rolling out a new datastore_version, so\n  you have it marked as active=0 until the go-live date.\n- you've rolled out a new datastore_version and want to\n  mark the old version as inactive. instances built prior\n  to the inactivation are still on the old version, and\n  can still utilize their still-assigned configuration-groups,\n  hence the parameters should be updateable by the\n  administrator.\n\nChange-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b\nCloses-Bug: #1379563\n""}, {'number': 2, 'created': '2014-10-20 23:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cffbd6fa8ec309462f437e31b3a06168559e9b21', 'message': ""Config Group Load Fails If DS Version Inactive\n\ntrove-manage db_load_datastore_config_parameters will fail if\nthe datastore_version on which it's being run is marked as\ninactive (aka active is set to 0).\n\nthis is not correct, because it's completely reasonable to want\nto update/refresh a datastore_version's configuration-group's\nparameters even if it's inactive.\n\nexamples:\n- you're working on rolling out a new datastore_version, so\n  you have it marked as active=0 until the go-live date.\n- you've rolled out a new datastore_version and want to\n  mark the old version as inactive. instances built prior\n  to the inactivation are still on the old version, and\n  can still utilize their still-assigned configuration-groups,\n  hence the parameters should be updateable by the\n  administrator.\n\nChange-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b\nCloses-Bug: #1379563\n""}, {'number': 3, 'created': '2014-10-21 17:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f060292379998a9a5e411088df4ef959cd270d93', 'message': ""Config Group Load Fails If DS Version Inactive\n\ntrove-manage db_load_datastore_config_parameters will fail if\nthe datastore_version on which it's being run is marked as\ninactive (aka active is set to 0).\n\nthis is not correct, because it's completely reasonable to want\nto update/refresh a datastore_version's configuration-group's\nparameters even if it's inactive.\n\nexamples:\n- you're working on rolling out a new datastore_version, so\n  you have it marked as active=0 until the go-live date.\n- you've rolled out a new datastore_version and want to\n  mark the old version as inactive. instances built prior\n  to the inactivation are still on the old version, and\n  can still utilize their still-assigned configuration-groups,\n  hence the parameters should be updateable by the\n  administrator.\n\nChange-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b\nCloses-Bug: #1379563\n""}, {'number': 4, 'created': '2014-10-23 04:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/91d7efc761bfb83f20555168721c8f29dc689481', 'message': ""Config Group Load Fails If DS Version Inactive\n\ntrove-manage db_load_datastore_config_parameters will fail if\nthe datastore_version on which it's being run is marked as\ninactive (aka active is set to 0).\n\nthis is not correct, because it's completely reasonable to want\nto update/refresh a datastore_version's configuration-group's\nparameters even if it's inactive.\n\nexamples:\n- you're working on rolling out a new datastore_version, so\n  you have it marked as active=0 until the go-live date.\n- you've rolled out a new datastore_version and want to\n  mark the old version as inactive. instances built prior\n  to the inactivation are still on the old version, and\n  can still utilize their still-assigned configuration-groups,\n  hence the parameters should be updateable by the\n  administrator.\n\nChange-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b\nCloses-Bug: #1379563\n""}, {'number': 5, 'created': '2014-11-21 18:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e3e639cd8f7928f304505523a030fc1de111c137', 'message': ""Config Group Load Fails If DS Version Inactive\n\ntrove-manage db_load_datastore_config_parameters will fail if\nthe datastore_version on which it's being run is marked as\ninactive (aka active is set to 0).\n\nthis is not correct, because it's completely reasonable to want\nto update/refresh a datastore_version's configuration-group's\nparameters even if it's inactive.\n\nexamples:\n- you're working on rolling out a new datastore_version, so\n  you have it marked as active=0 until the go-live date.\n- you've rolled out a new datastore_version and want to\n  mark the old version as inactive. instances built prior\n  to the inactivation are still on the old version, and\n  can still utilize their still-assigned configuration-groups,\n  hence the parameters should be updateable by the\n  administrator.\n\nChange-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b\nCloses-Bug: #1379563\n""}, {'number': 6, 'created': '2014-12-02 18:47:23.000000000', 'files': ['trove/datastore/models.py', 'trove/configuration/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/7d26dfe906f3509c48fa7a14048e742c6d7268cb', 'message': ""Config Group Load Fails If DS Version Inactive\n\ntrove-manage db_load_datastore_config_parameters will fail if\nthe datastore_version on which it's being run is marked as\ninactive (aka active is set to 0).\n\nthis is not correct, because it's completely reasonable to want\nto update/refresh a datastore_version's configuration-group's\nparameters even if it's inactive.\n\nexamples:\n- you're working on rolling out a new datastore_version, so\n  you have it marked as active=0 until the go-live date.\n- you've rolled out a new datastore_version and want to\n  mark the old version as inactive. instances built prior\n  to the inactivation are still on the old version, and\n  can still utilize their still-assigned configuration-groups,\n  hence the parameters should be updateable by the\n  administrator.\n\nChange-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b\nCloses-Bug: #1379563\n""}]",2,129145,7d26dfe906f3509c48fa7a14048e742c6d7268cb,48,12,6,8214,,,0,"Config Group Load Fails If DS Version Inactive

trove-manage db_load_datastore_config_parameters will fail if
the datastore_version on which it's being run is marked as
inactive (aka active is set to 0).

this is not correct, because it's completely reasonable to want
to update/refresh a datastore_version's configuration-group's
parameters even if it's inactive.

examples:
- you're working on rolling out a new datastore_version, so
  you have it marked as active=0 until the go-live date.
- you've rolled out a new datastore_version and want to
  mark the old version as inactive. instances built prior
  to the inactivation are still on the old version, and
  can still utilize their still-assigned configuration-groups,
  hence the parameters should be updateable by the
  administrator.

Change-Id: I7682fe240c5737438b084d813cf7ce80b4ecca9b
Closes-Bug: #1379563
",git fetch https://review.opendev.org/openstack/trove refs/changes/45/129145/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/datastore/models.py', 'trove/configuration/models.py']",2,3c5f508aaa3cacf17d12cc5dbf5af92d91d3580f,bug/1379563," type=datastore, version=datastore_version, return_inactive=True)"," type=datastore, version=datastore_version)",3,3
openstack%2Fkolla~master~Ib83bf475cd2a21965071c13eec4456df5c332edd,openstack/kolla,master,Ib83bf475cd2a21965071c13eec4456df5c332edd,Add script to build all docker images in the correct order,MERGED,2015-01-05 02:09:06.000000000,2015-01-06 16:46:55.000000000,2015-01-06 16:46:55.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2015-01-05 02:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/821f43c2ae3c517b68a2b39bd1d464f17aa15617', 'message': 'Add script to build all docker images in the correct order\n\nThe script is a wrapper for the `build-docker-image` script and thus\nrespond to the same options. It also responds to two additional `--from`\nand `--to` options that allows building only images that have changed\nbetween the specified git revisions.\n\nExamples:\n\n    # Build all images contained in docker directory and push new release\n    build-all-docker-images --release --push\n\n    # Build only images modified in test-branch along with their children\n    build-all-docker-images --from master --to test-branch\n\nChange-Id: Ib83bf475cd2a21965071c13eec4456df5c332edd\n'}, {'number': 2, 'created': '2015-01-05 02:10:53.000000000', 'files': ['tools/build-all-docker-images'], 'web_link': 'https://opendev.org/openstack/kolla/commit/c84b119ec231d4c418bcf75d8de3cf2195dbdd74', 'message': 'Add script to build all docker images in the correct order\n\nThe script is a wrapper for the `build-docker-image` script and thus\nrespond to the same options. It also responds to two additional `--from`\nand `--to` options that allows building only images that have changed\nbetween the specified git revisions.\n\nExamples:\n\n    # Build all images contained in docker directory and push new release\n    build-all-docker-images --release --push\n\n    # Build only images modified in test-branch along with their children\n    build-all-docker-images --from master --to test-branch\n\nChange-Id: Ib83bf475cd2a21965071c13eec4456df5c332edd\n'}]",0,144909,c84b119ec231d4c418bcf75d8de3cf2195dbdd74,8,3,2,13039,,,0,"Add script to build all docker images in the correct order

The script is a wrapper for the `build-docker-image` script and thus
respond to the same options. It also responds to two additional `--from`
and `--to` options that allows building only images that have changed
between the specified git revisions.

Examples:

    # Build all images contained in docker directory and push new release
    build-all-docker-images --release --push

    # Build only images modified in test-branch along with their children
    build-all-docker-images --from master --to test-branch

Change-Id: Ib83bf475cd2a21965071c13eec4456df5c332edd
",git fetch https://review.opendev.org/openstack/kolla refs/changes/09/144909/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-all-docker-images'],1,821f43c2ae3c517b68a2b39bd1d464f17aa15617,build_all_script,"#!/usr/bin/env bash # Depends on bash 4 and gawk TOPDIR=$(git rev-parse --show-toplevel) DOCKERDIR=$TOPDIR/docker declare -A dependency declare -A img_dirs declare -A status function info { [[ -n $1 ]] && printf ""%s\n"" ""$1"" } function success { [[ -n $1 ]] && printf ""\033[00;32m%s\033[00m\n"" ""$1"" } function warn { [[ -n $1 ]] && printf ""\033[00;31m%s\033[00m\n"" ""$1"" } function set_defaults { PREFIX=fedora-rdo- NAMESPACE=kollaglue } function has_changed { local image=$1 # Rebuild everything unless given git revision # We don't really care about the order of the $FROM and $TO parameters, all # we need is the list of changed files between the revisions, or HEAD if # only one of them is specified [[ -z $FROM && -z $TO ]] || git diff --name-only $FROM $TO | grep -q ""${img_dirs[$image]#$TOPDIR/}"" } function requires_build { local image=$1 local dep=${dependency[$image]} # An image requires a built if it meets the following conditions: # - it has instructions to build the image # - it hasn't been processed yet # - its dependency was rebuilt or its build instruction was modified [[ ${img_dirs[$image]} && -z ${status[$image]} ]] && \ ([[ ${status[$dep]} == ""rebuilt"" ]] || has_changed $image) } function build_image { local dir=$1 if [[ -x ""$dir/build"" ]]; then printf ""\n"" info ""Building image in $dir"" if $dir/build $ARGS; then success ""Successfully built image in $dir"" status[$image]=""rebuilt"" else warn ""Failed to build image in $dir"" fi fi } function init_image { local img_dir=$1 set_defaults [ -f $TOPDIR/.buildconf ] && . $TOPDIR/.buildconf [ -f $img_dir/.buildconf ] && . $img_dir/.buildconf if [ ! -z $FORCE_NAMESPACE ]; then NAMESPACE=$FORCE_NAMESPACE fi local image=""${NAMESPACE:+${NAMESPACE}/}${PREFIX}${img_dir##*/}"" local base_image=$(cat $img_dir/Dockerfile | gawk 'match($0, /^\s*FROM\s+(\S+)/, matches) {print matches[1]}' ) img_dirs[$image]=$img_dir dependency[$image]=$base_image # Restore defaults to minimize risk of side effects set_defaults } function process_image { local image=$1 if [ ${dependency[$image]} ]; then process_image ${dependency[$image]} fi if requires_build $image; then build_image ${img_dirs[$image]} fi if [ -z ${status[$image]} ]; then status[$image]=""processed"" fi } function usage () { read -r -d '' HELP <<EOF A wrapper to build-docker-image that build all images in order. Options: --from <git-revision> --to <git-revision> $($TOPDIR/tools/build-docker-image --help) EOF printf ""%s\n"" ""${HELP/$TOPDIR\/tools\/build-docker-image/$0}"" } ARGS=$@ PARSED_ARGS=$(getopt -q -o hn: -l help,namespace:,from:,to: -- ""$@"") eval set -- ""$PARSED_ARGS"" while :; do case ""$1"" in (--help|-h) usage exit 0 ;; (--namespace|-n) shift FORCE_NAMESPACE=""$1"" ;; (--from) shift FROM=""$1"" ARGS=${ARGS/\-\-from*$FROM/} ;; (--to) shift TO=""$1"" ARGS=${ARGS/\-\-to*$TO/} ;; (--) break ;; esac shift done # Do a first pass to find images to build and their dependencies for dockerfile in $(find $DOCKERDIR -name Dockerfile); do init_image $(dirname $dockerfile) done # Process all images for image in ""${!img_dirs[@]}""; do process_image $image done # Report failed images for image in ""${!status[@]}""; do if [ -z ${status[$image]} ]; then warn ""Failed to process $image"" fi done ",,162,0
openstack%2Foslo.utils~master~I156035396b4f686589b6f7ddfbdb0c922b8d90a0,openstack/oslo.utils,master,I156035396b4f686589b6f7ddfbdb0c922b8d90a0,Add method is_valid_port in netutils,MERGED,2014-12-23 08:12:13.000000000,2015-01-06 16:40:10.000000000,2015-01-06 16:40:09.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9796}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-12-23 08:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4c44105c8cd9a80e4681f51881202f617ae6eb11', 'message': 'Add method is_valid_port in netutils\n\nGlance[1] and Neutron[2] need to check if a value is a valid port,\nso we place the common code in oslo.utils.\n\n[1] https://git.openstack.org/cgit/openstack/glance/tree/glance/common/utils.py#n550\n[2] https://git.openstack.org/cgit/openstack/neutron/tree/neutron/extensions/securitygroup.py#n142\n\nChange-Id: I156035396b4f686589b6f7ddfbdb0c922b8d90a0\n'}, {'number': 2, 'created': '2015-01-06 06:16:51.000000000', 'files': ['oslo/utils/netutils.py', 'tests/test_netutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/44f36e35ec47d9ad430676c41749ccd5c6eadad4', 'message': 'Add method is_valid_port in netutils\n\nGlance[1] and Neutron[2] need to check if a value is a valid port,\nso we place the common code in oslo.utils.\n\n[1] https://git.openstack.org/cgit/openstack/glance/tree/glance/common/utils.py#n550\n[2] https://git.openstack.org/cgit/openstack/neutron/tree/neutron/extensions/securitygroup.py#n142\n\nChange-Id: I156035396b4f686589b6f7ddfbdb0c922b8d90a0\n'}]",2,143617,44f36e35ec47d9ad430676c41749ccd5c6eadad4,13,5,2,9796,,,0,"Add method is_valid_port in netutils

Glance[1] and Neutron[2] need to check if a value is a valid port,
so we place the common code in oslo.utils.

[1] https://git.openstack.org/cgit/openstack/glance/tree/glance/common/utils.py#n550
[2] https://git.openstack.org/cgit/openstack/neutron/tree/neutron/extensions/securitygroup.py#n142

Change-Id: I156035396b4f686589b6f7ddfbdb0c922b8d90a0
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/17/143617/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/utils/netutils.py', 'tests/test_netutils.py']",2,4c44105c8cd9a80e4681f51881202f617ae6eb11,is_port_valid," def test_valid_port(self): valid_inputs = [1, '1', 2, '3', '5', 8, 13, 21, '80', '3246', '65535'] for input_str in valid_inputs: self.assertTrue(netutils.is_valid_port(input_str)) def test_valid_port_fail(self): invalid_inputs = ['-32768', '0', 0, '65536', 528491, '528491', '528.491', 'thirty-seven', None] for input_str in invalid_inputs: self.assertFalse(netutils.is_valid_port(input_str)) ",,25,0
openstack%2Ftaskflow~master~I5ca05c0ac6a6221157a737ba20814cfd63adf51e,openstack/taskflow,master,I5ca05c0ac6a6221157a737ba20814cfd63adf51e,Remove need to inherit/adjust netutils split,MERGED,2015-01-05 23:06:25.000000000,2015-01-06 16:39:52.000000000,2015-01-06 16:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-05 23:06:25.000000000', 'files': ['taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/69449ae301fd411722021b47197d0a7eda335cf7', 'message': 'Remove need to inherit/adjust netutils split\n\nThe code we had for adjusting the netutils urlsplit\nfunction to add in a params method/property is no\nlonger needed as that functionality is now pushed into\nthe oslo.utils repo/package where it can be maintained\nthere in a more proper manner instead; so we can now\nremove our adjustment code and just use the upstream\ncode instead.\n\nChange-Id: I5ca05c0ac6a6221157a737ba20814cfd63adf51e\n'}]",0,145087,69449ae301fd411722021b47197d0a7eda335cf7,7,4,1,1297,,,0,"Remove need to inherit/adjust netutils split

The code we had for adjusting the netutils urlsplit
function to add in a params method/property is no
longer needed as that functionality is now pushed into
the oslo.utils repo/package where it can be maintained
there in a more proper manner instead; so we can now
remove our adjustment code and just use the upstream
code instead.

Change-Id: I5ca05c0ac6a6221157a737ba20814cfd63adf51e
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/87/145087/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py']",2,69449ae301fd411722021b47197d0a7eda335cf7,," for (k, v) in six.iteritems(uri.params()): return netutils.urlsplit(uri)","from six.moves.urllib import parse as urlparse# FIXME(harlowja): This should be removed with the next version of oslo.utils # which now has this functionality built-in, until then we are deriving from # there base class and adding this functionality on... # # The change was merged @ https://review.openstack.org/#/c/118881/ class ModifiedSplitResult(netutils._ModifiedSplitResult): """"""A split result that exposes the query parameters as a dictionary."""""" @property def params(self): if self.query: return dict(urlparse.parse_qsl(self.query)) else: return {} for (k, v) in six.iteritems(uri.params): split = netutils.urlsplit(uri) return ModifiedSplitResult(scheme=split.scheme, fragment=split.fragment, path=split.path, netloc=split.netloc, query=split.query)",3,23
openstack%2Ftripleo-image-elements~master~If876710c293d7f48f2c6f80f4e49bbfa90b1e16c,openstack/tripleo-image-elements,master,If876710c293d7f48f2c6f80f4e49bbfa90b1e16c,Open port 16509 on compute nodes for Nova live migration,MERGED,2014-12-09 22:59:07.000000000,2015-01-06 16:26:25.000000000,2015-01-06 16:26:24.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6449}]","[{'number': 1, 'created': '2014-12-09 22:59:07.000000000', 'files': ['elements/nova-kvm/os-refresh-config/pre-configure.d/98-nova-iptables'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9e9ec3b851acc71f62d694aef476e4a34cd92b9f', 'message': 'Open port 16509 on compute nodes for Nova live migration\n\nNova live migration needs port 16509.\n\nChange-Id: If876710c293d7f48f2c6f80f4e49bbfa90b1e16c\n'}]",0,140516,9e9ec3b851acc71f62d694aef476e4a34cd92b9f,8,3,1,10290,,,0,"Open port 16509 on compute nodes for Nova live migration

Nova live migration needs port 16509.

Change-Id: If876710c293d7f48f2c6f80f4e49bbfa90b1e16c
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/16/140516/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/nova-kvm/os-refresh-config/pre-configure.d/98-nova-iptables'],1,9e9ec3b851acc71f62d694aef476e4a34cd92b9f,(detached,#!/bin/bash set -eu # nova live migration add-rule INPUT -p tcp --dport 16509 -j ACCEPT ,,5,0
openstack%2Fnova~master~I01e441a1c2a351fd19b9d85f1e02632645aa9d7c,openstack/nova,master,I01e441a1c2a351fd19b9d85f1e02632645aa9d7c,objects: remove NovaObjectDictCompat from Tag object,MERGED,2014-12-12 14:09:46.000000000,2015-01-06 16:22:39.000000000,2015-01-06 16:22:36.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 14:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a7d2d620cfdecf30b62d9751c4e5ddc36fa1ce5', 'message': 'objects: remove NovaObjectDictCompat from Tag object\n\nNothing using the Tag object relies on legacy dict item access,\nsince this is completely new code.\n\nChange-Id: I01e441a1c2a351fd19b9d85f1e02632645aa9d7c\n'}, {'number': 2, 'created': '2014-12-19 11:48:49.000000000', 'files': ['nova/objects/tag.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_tag.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7b1b8d9d04f4e9c0b82b12a61913b502b76e96b0', 'message': 'objects: remove NovaObjectDictCompat from Tag object\n\nNothing using the Tag object relies on legacy dict item access,\nsince this is completely new code.\n\nChange-Id: I01e441a1c2a351fd19b9d85f1e02632645aa9d7c\n'}]",0,141377,7b1b8d9d04f4e9c0b82b12a61913b502b76e96b0,35,12,2,1779,,,0,"objects: remove NovaObjectDictCompat from Tag object

Nothing using the Tag object relies on legacy dict item access,
since this is completely new code.

Change-Id: I01e441a1c2a351fd19b9d85f1e02632645aa9d7c
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/141377/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/tag.py'],1,9a7d2d620cfdecf30b62d9751c4e5ddc36fa1ce5,,class Tag(base.NovaObject):,"# TODO(berrange): Remove NovaObjectDictCompat class Tag(base.NovaObject, base.NovaObjectDictCompat):",1,3
openstack%2Fkeystone-specs~master~If28cd274d5104708c9a36d396acbde24a758512b,openstack/keystone-specs,master,If28cd274d5104708c9a36d396acbde24a758512b,Remove XML references from API documentation,MERGED,2014-12-16 22:58:15.000000000,2015-01-06 16:19:43.000000000,2015-01-06 16:19:41.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-12-16 22:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/45b773a2606372e6fbb7c0274274b28dfd5bc3da', 'message': 'Remove XML references from API documentation\n\nNow that XML support has been removed from Keystone, references to XML support\nin the API documentation should be removed as well.\n\nbp removed-as-of-kilo\n\nChange-Id: If28cd274d5104708c9a36d396acbde24a758512b\n'}, {'number': 2, 'created': '2015-01-05 17:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e9025aa427be1349a0f1619a1dd108050305b971', 'message': 'Remove XML references from API documentation\n\nNow that XML support has been removed from Keystone, references to XML support\nin the API documentation should be removed as well.\n\nbp removed-as-of-kilo\n\nChange-Id: If28cd274d5104708c9a36d396acbde24a758512b\n'}, {'number': 3, 'created': '2015-01-06 15:52:04.000000000', 'files': ['api/v2.0/identity-api-v2.0-request_and_response_formats.rst', 'api/v2.0/identity-api-v2.0-faults.rst', 'api/v2.0/identity-api-v2.0-versions.rst', 'api/v2.0/identity-api-v2.0-extensions.rst', 'api/v2.0/identity-api-v2.0-paginated_collections.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/7d731000e8be89cce42912c4e6c9537d7f28628b', 'message': 'Remove XML references from API documentation\n\nNow that XML support has been removed from Keystone, references to XML support\nin the API documentation should be removed as well.\n\nbp removed-as-of-kilo\n\nChange-Id: If28cd274d5104708c9a36d396acbde24a758512b\n'}]",15,142250,7d731000e8be89cce42912c4e6c9537d7f28628b,22,7,3,5046,,,0,"Remove XML references from API documentation

Now that XML support has been removed from Keystone, references to XML support
in the API documentation should be removed as well.

bp removed-as-of-kilo

Change-Id: If28cd274d5104708c9a36d396acbde24a758512b
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/50/142250/3 && git format-patch -1 --stdout FETCH_HEAD,"['api/v2.0/identity-api-v2.0-faults.rst', 'api/v2.0/identity-api-v2.0-request_and_response_formats.rst', 'api/v2.0/identity-api-v2.0-versions.rst', 'api/v2.0/identity-api-v2.0-extensions.rst', 'api/v2.0/identity-api-v2.0-paginated_collections.rst']",5,45b773a2606372e6fbb7c0274274b28dfd5bc3da,bp/removed-as-of-kilo,,"**Example: Tenant collection, first page: XML response** .. code-block:: xml <?xml version=""1.0"" encoding=""UTF-8""?> <tenants xmlns=""http://docs.openstack.org/identity/api/v2.0"" xmlns:atom=""http://www.w3.org/2005/Atom""> <tenant enabled=""true"" id=""1234"" name=""ACME Corp""> <description>A description...</description> </tenant> <atom:link rel=""next"" href=""http://identity.api.openstack.org/v2.0/tenants?limit=1&amp;marker=1234""/> </tenants> **Example: Tenant collection, second page: XML response** .. code-block:: xml <?xml version=""1.0"" encoding=""UTF-8""?> <tenants xmlns=""http://docs.openstack.org/identity/api/v2.0"" xmlns:atom=""http://www.w3.org/2005/Atom""> <tenant enabled=""true"" id=""3645"" name=""Iron Works""> <description>A description...</description> </tenant> <atom:link rel=""previous"" href=""http://identity.api.openstack.org/v2.0/tenants?limit=1""/> <atom:link rel=""next"" href=""http://identity.api.openstack.org/v2.0/tenants?limit=1&amp;marker=3645""/> </tenants> **Example: Tenant collection, last page: XML response** .. code-block:: xml <?xml version=""1.0"" encoding=""UTF-8""?> <tenants xmlns=""http://docs.openstack.org/identity/api/v2.0"" xmlns:atom=""http://www.w3.org/2005/Atom""> <tenant enabled=""true"" id=""9999"" name=""Bigz""> <description>A description...</description> </tenant> <atom:link rel=""previous"" href=""http://identity.api.openstack.org/v2.0/tenants?limit=1&amp;marker=1234""/> </tenants> **Example: Paginated roles in user: XML response** .. code-block:: xml <?xml version=""1.0"" encoding=""UTF-8""?> <user xmlns=""http://docs.openstack.org/identity/api/v2.0"" xmlns:atom=""http://www.w3.org/2005/Atom"" enabled=""true"" email=""john.smith@example.org"" username=""jqsmith"" id=""u1000""> <roles xmlns=""http://docs.openstack.org/identity/api/ext/role""> <role tenantId=""1234"" id=""Admin""/> <role tenantId=""1234"" id=""DBUser""/> <atom:link rel=""next"" href=""http://identity.api.openstack.org/v2.0/tenants/1234/users/u1000/groups?marker=Super"" /> </roles> </user> ",23,433
openstack%2Frally~master~I9c61c0a0d004cb564511633f4a457490c094805b,openstack/rally,master,I9c61c0a0d004cb564511633f4a457490c094805b,Python 3 fix '+' operand in dict_items,MERGED,2015-01-05 12:09:25.000000000,2015-01-06 16:19:38.000000000,2015-01-06 16:19:33.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8367}, {'_account_id': 9180}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2015-01-05 12:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b950a763308b222ccf97ebf2597d1f52ca3caca0', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is cast the dict_items you want to\nsum to list, then cast the result to a dict.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}, {'number': 2, 'created': '2015-01-05 13:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5767da13878913b58d3c88a1e031157b7faef046', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is cast the dict_items you want to\nsum to list, then cast the result to a dict.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}, {'number': 3, 'created': '2015-01-05 14:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ea48295e35130a8442271d97f2664ce3bd355394', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is using the update method in dict\nobject.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}, {'number': 4, 'created': '2015-01-06 10:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e71e7ceab56a9b1a768d8da391eafc076f5e5d79', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is using the update method in dict\nobject.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}, {'number': 5, 'created': '2015-01-06 10:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7544b7ce474d730d21f161934de9ff7a841bd23e', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is using the update method in dict\nobject.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}, {'number': 6, 'created': '2015-01-06 10:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/41344a6246fc4acd903542c5320c2866a59d5d43', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is using the update method in dict\nobject.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}, {'number': 7, 'created': '2015-01-06 11:01:58.000000000', 'files': ['rally/exceptions.py', 'rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/3208713581fb842513bedce46938b8f2ff6f4553', 'message': ""Python 3 fix '+' operand in dict_items\n\nIn Python 3, the dict.items() return a dict_items object, which\ndoes not support the + operand.\nThe way to make it compatible is using the update method in dict\nobject.\n\nChange-Id: I9c61c0a0d004cb564511633f4a457490c094805b\n""}]",8,144971,3208713581fb842513bedce46938b8f2ff6f4553,38,6,7,8367,,,0,"Python 3 fix '+' operand in dict_items

In Python 3, the dict.items() return a dict_items object, which
does not support the + operand.
The way to make it compatible is using the update method in dict
object.

Change-Id: I9c61c0a0d004cb564511633f4a457490c094805b
",git fetch https://review.opendev.org/openstack/rally refs/changes/71/144971/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/exceptions.py', 'rally/osclients.py']",2,b950a763308b222ccf97ebf2597d1f52ca3caca0,dict_sum, kw = dict(list(self.endpoint.to_dict().items()) + list(new_kw.items())), kw = dict(self.endpoint.to_dict().items() + new_kw.items()),3,2
openstack%2Ftripleo-image-elements~master~I2f3406cd09a2a513347593dfcfd3121d3de096c9,openstack/tripleo-image-elements,master,I2f3406cd09a2a513347593dfcfd3121d3de096c9,Secure MySQL clustering with SSL,MERGED,2014-11-18 14:24:45.000000000,2015-01-06 16:17:05.000000000,2015-01-06 16:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 10035}, {'_account_id': 10311}, {'_account_id': 11650}, {'_account_id': 14123}]","[{'number': 1, 'created': '2014-11-18 14:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/44cb6034f381337cebeab3a2330bc56b647821ff', 'message': 'Secure MySQL clustering with SSL\n\nAccept values through Heat for the contents of an X509 certificate and\nkey to be used in Galera clustering and write the values into files.\nSet the file owner and permissions to only allow mysql access to the\ncertificate/key pair. Configure Galera clustering to bind to the server\nip:4567 and use the provided certificate/key pair.\n\nThis is dependent on the associated change in tripleo-heat-templates\nto provide the certificate values.  If values are missing, the\nclustering will not be secured.\n\nChange-Id: I2f3406cd09a2a513347593dfcfd3121d3de096c9\n'}, {'number': 2, 'created': '2014-11-20 14:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/473ae0de63f4500f9d3bd2dcf5e6223705b282a9', 'message': 'Secure MySQL clustering with SSL\n\nAccept values through Heat for the contents of an X509 certificate and\nkey to be used in Galera clustering and write the values into files.\nSet the file owner and permissions to only allow mysql access to the\ncertificate/key pair. Configure Galera clustering to bind to the server\nip:4567 and use the provided certificate/key pair.\n\nThis is dependent on the associated change in tripleo-heat-templates\nto provide the certificate values.  If values are missing, the\nclustering will not be secured.\n\nTurning on/off secure clustering cannot be done without restarting every node cluster.\n\nChange-Id: I2f3406cd09a2a513347593dfcfd3121d3de096c9\n'}, {'number': 3, 'created': '2014-11-20 15:27:50.000000000', 'files': ['elements/mysql-common/os-refresh-config/post-configure.d/10-mysql-permissions', 'elements/mysql-common/os-apply-config/mnt/state/etc/mysql/conf.d/cluster.cnf', 'elements/mysql-common/os-apply-config/etc/ssl/mysql/from-heat.key', 'elements/mysql-common/os-apply-config/etc/ssl/mysql/from-heat.crt'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a075c14b614e0ddc5cdca6832220858fa2905cd8', 'message': 'Secure MySQL clustering with SSL\n\nAccept values through Heat for the contents of an X509 certificate and\nkey to be used in Galera clustering and write the values into files.\nSet the file owner and permissions to only allow mysql access to the\ncertificate/key pair. Configure Galera clustering to bind to the server\nip:4567 and use the provided certificate/key pair.\n\nThis is dependent on the associated change in tripleo-heat-templates\nto provide the certificate values.  If values are missing, the\nclustering will not be secured.\n\nTurning on/off secure clustering cannot be done without restarting every\nnode cluster.\n\nChange-Id: I2f3406cd09a2a513347593dfcfd3121d3de096c9\n'}]",5,135298,a075c14b614e0ddc5cdca6832220858fa2905cd8,28,8,3,11650,,,0,"Secure MySQL clustering with SSL

Accept values through Heat for the contents of an X509 certificate and
key to be used in Galera clustering and write the values into files.
Set the file owner and permissions to only allow mysql access to the
certificate/key pair. Configure Galera clustering to bind to the server
ip:4567 and use the provided certificate/key pair.

This is dependent on the associated change in tripleo-heat-templates
to provide the certificate values.  If values are missing, the
clustering will not be secured.

Turning on/off secure clustering cannot be done without restarting every
node cluster.

Change-Id: I2f3406cd09a2a513347593dfcfd3121d3de096c9
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/98/135298/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/mysql-common/os-refresh-config/post-configure.d/10-mysql-permissions', 'elements/mysql-common/os-apply-config/etc/ssl/mysql/from-heat.key', 'elements/mysql-common/os-apply-config/mnt/state/etc/mysql/conf.d/cluster.cnf', 'elements/mysql-common/os-apply-config/etc/ssl/mysql/from-heat.crt']",4,44cb6034f381337cebeab3a2330bc56b647821ff,tls-mysql,{{mysql.cluster_certificate}} ,,17,0
openstack%2Fhorizon~master~If80c46e3ac1b93e6da19e7d1b337a7089921c9d0,openstack/horizon,master,If80c46e3ac1b93e6da19e7d1b337a7089921c9d0,fix redirect for admin user password relogin,MERGED,2014-08-29 00:04:49.000000000,2015-01-06 16:16:47.000000000,2015-01-06 16:16:46.000000000,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 4978}, {'_account_id': 8090}, {'_account_id': 8674}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9647}, {'_account_id': 9981}, {'_account_id': 10442}, {'_account_id': 11592}, {'_account_id': 11880}, {'_account_id': 12355}, {'_account_id': 12606}, {'_account_id': 12826}, {'_account_id': 13086}, {'_account_id': 13161}, {'_account_id': 13785}]","[{'number': 1, 'created': '2014-08-29 00:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e6bae6b37e7d6506b147901b680f661600ac0178', 'message': ""fix redirect for admin user password relogin\n\nLogin as Admin, go to Identity > Users, change the Admin user's\npassword, you will automatically be logged out.  After logging in\nagain, you land on the 'Update User' panel. I expect to go to the\nSystem Overview panel (like when I change the user's password\nfrom Settings).\n\nChange-Id: If80c46e3ac1b93e6da19e7d1b337a7089921c9d0\nCloses-Bug: #1351511\n""}, {'number': 2, 'created': '2014-10-02 00:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3a3833e952e25e6c52bf6e418473d6d8b8596437', 'message': ""fix redirect for admin user password relogin\n\nLogin as Admin, go to Identity > Users, change the Admin user's\npassword, you will automatically be logged out.  After logging in\nagain, you land on the 'Update User' panel. I expect to go to the\nSystem Overview panel (like when I change the user's password\nfrom Settings).\n\nNote: logout_with_messages() is only used it 2 places\n\nChange-Id: If80c46e3ac1b93e6da19e7d1b337a7089921c9d0\nCloses-Bug: #1351511\n""}, {'number': 3, 'created': '2014-10-02 01:20:32.000000000', 'files': ['horizon/utils/functions.py', 'openstack_dashboard/api/keystone.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/59d4256bb1353784d195af5127adab7dc1ba05ac', 'message': ""fix redirect for admin user password relogin\n\nLogin as Admin, go to Identity > Users, change the Admin user's\npassword, you will automatically be logged out.  After logging in\nagain, you land on the 'Update User' panel. I expect to go to the\nSystem Overview panel (like when I change the user's password\nfrom Settings).\n\nChange-Id: If80c46e3ac1b93e6da19e7d1b337a7089921c9d0\nCloses-Bug: #1351511\n""}]",0,117656,59d4256bb1353784d195af5127adab7dc1ba05ac,35,19,3,9622,,,0,"fix redirect for admin user password relogin

Login as Admin, go to Identity > Users, change the Admin user's
password, you will automatically be logged out.  After logging in
again, you land on the 'Update User' panel. I expect to go to the
System Overview panel (like when I change the user's password
from Settings).

Change-Id: If80c46e3ac1b93e6da19e7d1b337a7089921c9d0
Closes-Bug: #1351511
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/117656/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/utils/functions.py'],1,e6bae6b37e7d6506b147901b680f661600ac0178,bug/1351511,"def logout_with_message(request, msg, redirect=False): if redirect: response = http.HttpResponseRedirect( '%s?next=%s' % (settings.LOGOUT_URL, request.path)) else: response = http.HttpResponseRedirect(settings.LOGOUT_URL)","def logout_with_message(request, msg): response = http.HttpResponseRedirect( '%s?next=%s' % (settings.LOGOUT_URL, request.path))",6,3
openstack%2Fceilometer~master~Ibef181ff7c884a51b44dc746160e2aeebf0ae353,openstack/ceilometer,master,Ibef181ff7c884a51b44dc746160e2aeebf0ae353,Add release notes URL for Juno,MERGED,2015-01-06 00:27:40.000000000,2015-01-06 16:16:39.000000000,2015-01-06 16:16:38.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 9562}]","[{'number': 1, 'created': '2015-01-06 00:27:40.000000000', 'files': ['doc/source/releasenotes/index.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be22533b3002f87e65c97227d210a3bc24c818a2', 'message': 'Add release notes URL for Juno\n\nChange-Id: Ibef181ff7c884a51b44dc746160e2aeebf0ae353\nSigned-off-by: Paul Belanger <paul.belanger@polybeacon.com>\n'}]",0,145101,be22533b3002f87e65c97227d210a3bc24c818a2,9,5,1,4162,,,0,"Add release notes URL for Juno

Change-Id: Ibef181ff7c884a51b44dc746160e2aeebf0ae353
Signed-off-by: Paul Belanger <paul.belanger@polybeacon.com>
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/01/145101/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/releasenotes/index.rst'],1,be22533b3002f87e65c97227d210a3bc24c818a2,temp/juno,* `Juno`_.. _Juno: https://wiki.openstack.org/wiki/ReleaseNotes/Juno#OpenStack_Telemetry_.28Ceilometer.29,,2,0
openstack%2Fkolla~master~I8426b5ec136d08b3a476beea3cb983089e08c401,openstack/kolla,master,I8426b5ec136d08b3a476beea3cb983089e08c401,Make build script respond to `-h` option,MERGED,2015-01-05 01:39:28.000000000,2015-01-06 16:11:54.000000000,2015-01-06 16:11:53.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2015-01-05 01:39:28.000000000', 'files': ['tools/build-docker-image'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ed493b84e0ba5ef856b7534268fdb8dbeaea6d6b', 'message': 'Make build script respond to `-h` option\n\nIt is usually considered good practice for a script to respond to both\nshort style `-h` and long style `--help` options to display help\nmessage.\n\nThis commits adds support for short style `-h` option.\n\nChange-Id: I8426b5ec136d08b3a476beea3cb983089e08c401\n'}]",0,144905,ed493b84e0ba5ef856b7534268fdb8dbeaea6d6b,7,3,1,13039,,,0,"Make build script respond to `-h` option

It is usually considered good practice for a script to respond to both
short style `-h` and long style `--help` options to display help
message.

This commits adds support for short style `-h` option.

Change-Id: I8426b5ec136d08b3a476beea3cb983089e08c401
",git fetch https://review.opendev.org/openstack/kolla refs/changes/05/144905/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-docker-image'],1,ed493b84e0ba5ef856b7534268fdb8dbeaea6d6b,h_for_help,"Usage: $0 [options]ARGS=$(getopt -o hn:t:pN -l help,namespace:,push,release,tag:,no-cache -- ""$@"") || { usage >&2; exit 2; } (--help|-h) usage","$0: usage: $0 [options]ARGS=$(getopt -o 'n:t:pN' -l help,namespace:,push,release,tag:,no-cache -- ""$@"") || { usage >&2; exit 2; } (--help) usage",3,3
openstack%2Fkolla~master~Id0e0c7f62d638fc2ee79f27c07677abf2902e087,openstack/kolla,master,Id0e0c7f62d638fc2ee79f27c07677abf2902e087,Base all images on kollaglue ones,MERGED,2015-01-05 01:22:53.000000000,2015-01-06 16:09:30.000000000,2015-01-06 16:09:30.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2015-01-05 01:22:53.000000000', 'files': ['docker/swift/swift-base/Dockerfile', 'docker/swift/swift-account/Dockerfile', 'docker/swift/swift-container/Dockerfile', 'docker/cinder/Dockerfile', 'docker/swift/swift-proxy-server/Dockerfile', 'docker/swift/swift-object/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/298ce72106ca1f3e94ff8e0db48685c739bcf81c', 'message': 'Base all images on kollaglue ones\n\nThe `kollaglue` Docker hub namespace was missing for some of the images.\n\nChange-Id: Id0e0c7f62d638fc2ee79f27c07677abf2902e087\n'}]",0,144903,298ce72106ca1f3e94ff8e0db48685c739bcf81c,7,3,1,13039,,,0,"Base all images on kollaglue ones

The `kollaglue` Docker hub namespace was missing for some of the images.

Change-Id: Id0e0c7f62d638fc2ee79f27c07677abf2902e087
",git fetch https://review.opendev.org/openstack/kolla refs/changes/03/144903/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/swift/swift-base/Dockerfile', 'docker/swift/swift-account/Dockerfile', 'docker/swift/swift-container/Dockerfile', 'docker/cinder/Dockerfile', 'docker/swift/swift-proxy-server/Dockerfile', 'docker/swift/swift-object/Dockerfile']",6,298ce72106ca1f3e94ff8e0db48685c739bcf81c,use_kollaglue_images,FROM kollaglue/fedora-rdo-base,FROM fedora-rdo-base,6,6
openstack%2Fkolla~master~Ia38101b6d4743b454dc2c8ba48d3b55af47ed53b,openstack/kolla,master,Ia38101b6d4743b454dc2c8ba48d3b55af47ed53b,Set higher precedence for .buildconf file in image directory,MERGED,2015-01-05 01:28:26.000000000,2015-01-06 16:06:40.000000000,2015-01-06 16:06:39.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2015-01-05 01:28:26.000000000', 'files': ['tools/build-docker-image'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e07d274a615d65efb88d166f1d5cd9e4ef411742', 'message': 'Set higher precedence for .buildconf file in image directory\n\nSource .buildconf file in $IMGDIR last in order to prevent silently\noverloading configuration by the less specific $TOPDIR/.buildconf.\n\nChange-Id: Ia38101b6d4743b454dc2c8ba48d3b55af47ed53b\n'}]",0,144904,e07d274a615d65efb88d166f1d5cd9e4ef411742,7,3,1,13039,,,0,"Set higher precedence for .buildconf file in image directory

Source .buildconf file in $IMGDIR last in order to prevent silently
overloading configuration by the less specific $TOPDIR/.buildconf.

Change-Id: Ia38101b6d4743b454dc2c8ba48d3b55af47ed53b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/04/144904/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-docker-image'],1,e07d274a615d65efb88d166f1d5cd9e4ef411742,buildconf_precedence,[ -f $IMGDIR/.buildconf ] && . $IMGDIR/.buildconf,[ -f $IMGDIR/.buildconf ] && . $IMGDIR/.buildconf,1,1
openstack%2Fsecurity-doc~master~I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b,openstack/security-doc,master,I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b,Edited diagram in the Security Guide,MERGED,2014-12-24 01:12:03.000000000,2015-01-06 16:06:32.000000000,2015-01-06 16:06:30.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2807}, {'_account_id': 6772}, {'_account_id': 10497}]","[{'number': 1, 'created': '2014-12-24 01:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/dfcbfc4117aafbdc34eb5b9e14813215f7842165', 'message': 'Edited diagram in the Security Guide\n\nChanged networking project name from quantum to neutron the overview diagram\n\nChange-Id: I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b\nbackport: none\nCloses-Bug: #1404447\n'}, {'number': 2, 'created': '2015-01-02 00:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bc3863fc4247c4120ae449d3cfbc03d6be204b61', 'message': 'Edited diagram in the Security Guide\n\nChanged networking project name from quantum to neutron the overview diagram\n\nChange-Id: I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b\nbackport: none\nCloses-Bug: #1404447\n'}, {'number': 3, 'created': '2015-01-02 01:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/87a673f817b821c29f9199409660520c08daa57f', 'message': 'Edited diagram in the Security Guide\n\nChanged networking project name from quantum to neutron the overview diagram\n\nChange-Id: I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b\nbackport: none\nCloses-Bug: #1404447\nCloses_Bug: #1405406\n'}, {'number': 4, 'created': '2015-01-02 01:53:59.000000000', 'files': ['security-guide/static/marketecture-diagram.png'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/968c0f186597e2856bac29c1c43b185d99e9bb2f', 'message': 'Edited diagram in the Security Guide\n\nChanged networking project name from quantum to neutron the overview diagram\n\nChange-Id: I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b\nbackport: none\nCloses-Bug: #1404447\nCloses-Bug: #1405406\n'}]",0,143754,968c0f186597e2856bac29c1c43b185d99e9bb2f,13,5,4,10705,,,0,"Edited diagram in the Security Guide

Changed networking project name from quantum to neutron the overview diagram

Change-Id: I43a9ec20c94ee7316d1a7f3ed1eacc8872a7ed3b
backport: none
Closes-Bug: #1404447
Closes-Bug: #1405406
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/54/143754/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/static/marketecture-diagram.png'],1,dfcbfc4117aafbdc34eb5b9e14813215f7842165,diagram_secguide/darren,,,0,0
openstack%2Fkolla~master~I849732147302eaf00d864d6b5093ff6ac006f496,openstack/kolla,master,I849732147302eaf00d864d6b5093ff6ac006f496,Lock Fedora-based image to specific versions,MERGED,2015-01-05 01:06:10.000000000,2015-01-06 16:03:22.000000000,2015-01-06 16:03:21.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2015-01-05 01:06:10.000000000', 'files': ['docker/fedora-rdo-base/Dockerfile', 'docker/hautoproxy/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8843f6ff5273bf8476144214d6ba20e89a612847', 'message': 'Lock Fedora-based image to specific versions\n\nThis prevents unexpected breakage on new Fedora release.\n\nFedora 20 is the last release known to work. Images based on Fedora 21\nare currently broken as they lack required packages such as iproute.\nSupport for Fedora 21 is on the way and will follow soon once all images\nhave been verified.\n\nChange-Id: I849732147302eaf00d864d6b5093ff6ac006f496\n'}]",0,144902,8843f6ff5273bf8476144214d6ba20e89a612847,7,3,1,13039,,,0,"Lock Fedora-based image to specific versions

This prevents unexpected breakage on new Fedora release.

Fedora 20 is the last release known to work. Images based on Fedora 21
are currently broken as they lack required packages such as iproute.
Support for Fedora 21 is on the way and will follow soon once all images
have been verified.

Change-Id: I849732147302eaf00d864d6b5093ff6ac006f496
",git fetch https://review.opendev.org/openstack/kolla refs/changes/02/144902/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/fedora-rdo-base/Dockerfile', 'docker/hautoproxy/Dockerfile']",2,8843f6ff5273bf8476144214d6ba20e89a612847,base_image_lock,FROM fedora:20,FROM fedora,2,2
openstack%2Fceilometer~master~I83f0c89737c19eced870544a82b5e6ca593345f2,openstack/ceilometer,master,I83f0c89737c19eced870544a82b5e6ca593345f2,Fix release notes URL for Icehouse,MERGED,2015-01-06 00:20:43.000000000,2015-01-06 15:59:46.000000000,2015-01-06 15:59:45.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 9562}]","[{'number': 1, 'created': '2015-01-06 00:20:43.000000000', 'files': ['doc/source/releasenotes/index.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/42589a2dcc43655a003968af641909383a3d3635', 'message': 'Fix release notes URL for Icehouse\n\nChange-Id: I83f0c89737c19eced870544a82b5e6ca593345f2\nSigned-off-by: Paul Belanger <paul.belanger@polybeacon.com>\n'}]",0,145097,42589a2dcc43655a003968af641909383a3d3635,9,5,1,4162,,,0,"Fix release notes URL for Icehouse

Change-Id: I83f0c89737c19eced870544a82b5e6ca593345f2
Signed-off-by: Paul Belanger <paul.belanger@polybeacon.com>
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/97/145097/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/releasenotes/index.rst'],1,42589a2dcc43655a003968af641909383a3d3635,temp/releasenotes,.. _IceHouse: https://wiki.openstack.org/wiki/ReleaseNotes/Icehouse#OpenStack_Telemetry_.28Ceilometer.29,.. _IceHouse: https://wiki.openstack.org/wiki/ReleaseNotes/Icehouse#Ceilometer,1,1
openstack%2Fironic-python-agent~master~I32fa8f90a6292229bd23eec6d648fab617e59ec3,openstack/ironic-python-agent,master,I32fa8f90a6292229bd23eec6d648fab617e59ec3,Skip failing execute tests when using /tmp noexec,MERGED,2014-12-29 12:21:47.000000000,2015-01-06 15:57:17.000000000,2015-01-06 15:57:16.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-12-29 12:21:47.000000000', 'files': ['ironic_python_agent/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fa0e710a40b2362928a9a78e860d72cd20697ffd', 'message': 'Skip failing execute tests when using /tmp noexec\n\ntest_retry_on_failure and test_no_retry_on_success from\nExecuteTestCase are failing when running system with /tmp noexec.\nThese tests should be skipped in this case.\n\nRelated-bug: #1359463\nChange-Id: I32fa8f90a6292229bd23eec6d648fab617e59ec3\n'}]",0,144294,fa0e710a40b2362928a9a78e860d72cd20697ffd,13,5,1,12356,,,0,"Skip failing execute tests when using /tmp noexec

test_retry_on_failure and test_no_retry_on_success from
ExecuteTestCase are failing when running system with /tmp noexec.
These tests should be skipped in this case.

Related-bug: #1359463
Change-Id: I32fa8f90a6292229bd23eec6d648fab617e59ec3
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/94/144294/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/tests/utils.py'],1,fa0e710a40b2362928a9a78e860d72cd20697ffd,bug/1359463,"import errno try: self.assertRaises(processutils.ProcessExecutionError, utils.execute, tmpfilename, tmpfilename2, attempts=10, process_input='foo', delay_on_retry=False) except OSError as e: if e.errno == errno.EACCES: self.skipTest(""Permissions error detected. "" ""Are you running with a noexec /tmp?"") else: raise try: utils.execute(tmpfilename, tmpfilename2, process_input='foo', attempts=2) except OSError as e: if e.errno == errno.EACCES: self.skipTest(""Permissions error detected. "" ""Are you running with a noexec /tmp?"") else: raise"," self.assertRaises(processutils.ProcessExecutionError, utils.execute, tmpfilename, tmpfilename2, attempts=10, process_input='foo', delay_on_retry=False) utils.execute(tmpfilename, tmpfilename2, process_input='foo', attempts=2)",24,9
openstack%2Fmagnum~master~I98f7ab2eab7ac9e68c4e4a313a61f7d39b7596b2,openstack/magnum,master,I98f7ab2eab7ac9e68c4e4a313a61f7d39b7596b2,Implements k8s resource creation/updating with data,MERGED,2015-01-06 08:13:24.000000000,2015-01-06 15:56:41.000000000,2015-01-06 15:56:40.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-06 08:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/666eabe3ccb43505c7e460cb3e6d721a1df7cc1a', 'message': 'Implements k8s resource creation/updating with data\n\nNow kube_utils.py supports creation/updating from k8s resource data.\nUser will be able to updload pod/service/replication_controller data to\ncreate or update resource.\n\nChange-Id: I98f7ab2eab7ac9e68c4e4a313a61f7d39b7596b2\n'}, {'number': 2, 'created': '2015-01-06 08:18:11.000000000', 'files': ['magnum/conductor/handlers/common/kube_utils.py', 'magnum/tests/conductor/handlers/common/__init__.py', 'magnum/tests/conductor/handlers/common/test_kube_utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9ff6b93e087974b05fbdf7b68ab4e136b23e3188', 'message': 'Implements k8s resource creation/updating with data\n\nNow kube_utils.py supports creation/updating from k8s resource data.\nUser will be able to updload pod/service/replication_controller data to\ncreate or update resource.\n\nChange-Id: I98f7ab2eab7ac9e68c4e4a313a61f7d39b7596b2\n'}]",4,145161,9ff6b93e087974b05fbdf7b68ab4e136b23e3188,9,3,2,12385,,,0,"Implements k8s resource creation/updating with data

Now kube_utils.py supports creation/updating from k8s resource data.
User will be able to updload pod/service/replication_controller data to
create or update resource.

Change-Id: I98f7ab2eab7ac9e68c4e4a313a61f7d39b7596b2
",git fetch https://review.opendev.org/openstack/magnum refs/changes/61/145161/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/common/kube_utils.py', 'magnum/tests/conductor/handlers/common/__init__.py', 'magnum/tests/conductor/handlers/common/test_kube_utils.py']",3,666eabe3ccb43505c7e460cb3e6d721a1df7cc1a,impl-pod-create,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from magnum.conductor.handlers.common import kube_utils from magnum import objects from magnum.tests import base import mock from mock import patch class TestKubeUtils(base.BaseTestCase): def setUp(self): super(TestKubeUtils, self).setUp() def test_extract_resource_type(self): expected_resource_type = 'bay' bay = objects.Bay({}) actual_type = kube_utils._extract_resource_type(bay) self.assertEquals(expected_resource_type, actual_type) @patch('magnum.conductor.handlers.common.kube_utils._extract_resource_type') def test_extract_resource_data_with_data(self, mock_extract_resource_type): expected_data = 'expected_data' mock_extract_resource_type.return_value = 'mock_type' mock_resource = mock.MagicMock() mock_resource.mock_type_data = expected_data actual_data = kube_utils._extract_resource_data(mock_resource) self.assertEquals(expected_data, actual_data) @patch('magnum.conductor.handlers.common.kube_utils._extract_resource_type') def test_extract_resource_definition_url(self, mock_extract_resource_type): expected_data = 'expected_url' mock_extract_resource_type.return_value = 'mock_type' mock_resource = mock.MagicMock() mock_resource.mock_type_definition_url = expected_data actual_data = kube_utils._extract_resource_definition_url(mock_resource) self.assertEquals(expected_data, actual_data) @patch('magnum.conductor.handlers.common.kube_utils._k8s_create_with_data') @patch('magnum.conductor.handlers.common.kube_utils._extract_resource_data') @patch('magnum.conductor.handlers.common.kube_utils.' '_extract_resource_definition_url') def test_k8s_create_data(self, mock_definition_url, mock_data, mock_create_with_data): expected_data = 'data' master_address = 'master_address' mock_data.return_value = expected_data mock_definition_url.return_value = None mock_resource = mock.MagicMock() kube_utils._k8s_create(master_address, mock_resource) mock_create_with_data.assert_called_once_with(master_address, expected_data) @patch('magnum.conductor.handlers.common.kube_utils._k8s_create_with_path') @patch('magnum.conductor.handlers.common.kube_utils._extract_resource_data') @patch('magnum.conductor.handlers.common.kube_utils.' '_extract_resource_definition_url') def test_k8s_create_url(self, mock_definition_url, mock_data, mock_create_with_path): expected_url = 'url' master_address = 'master_address' mock_data.return_value = None mock_definition_url.return_value = expected_url mock_resource = mock.MagicMock() kube_utils._k8s_create(master_address, mock_resource) mock_create_with_path.assert_called_once_with(master_address, expected_url) @patch('magnum.openstack.common.utils.trycmd') def test_k8s_create_with_path(self, mock_trycmd): expected_master_address = 'master_address' expected_pod_file = 'pod_file' expected_command = [ 'kubectl', 'create', '-s', expected_master_address, '-f', expected_pod_file ] kube_utils._k8s_create_with_path(expected_master_address, expected_pod_file) mock_trycmd.assert_called_once_with(*expected_command) @patch('magnum.conductor.handlers.common.kube_utils._k8s_create_with_path') @patch('tempfile.NamedTemporaryFile') def test_k8s_create_with_data(self, mock_named_tempfile, mock_k8s_create): expected_master_address = 'master_address' expected_data = 'resource_data' expected_filename = 'resource_file' mock_file = mock.MagicMock() mock_file.name = expected_filename mock_named_tempfile.return_value.__enter__.return_value = mock_file kube_utils._k8s_create_with_data(expected_master_address, expected_data) mock_file.write.assert_called_once_with(expected_data) mock_k8s_create.assert_called_once_with(expected_master_address, expected_filename) @patch('magnum.conductor.handlers.common.kube_utils._k8s_update_with_data') @patch('magnum.conductor.handlers.common.kube_utils._extract_resource_data') @patch('magnum.conductor.handlers.common.kube_utils.' '_extract_resource_definition_url') def test_k8s_update_data(self, mock_definition_url, mock_data, mock_update_with_data): expected_data = 'data' master_address = 'master_address' mock_data.return_value = expected_data mock_definition_url.return_value = None mock_resource = mock.MagicMock() kube_utils._k8s_update(master_address, mock_resource) mock_update_with_data.assert_called_once_with(master_address, expected_data) @patch('magnum.conductor.handlers.common.kube_utils._k8s_update_with_path') @patch('magnum.conductor.handlers.common.kube_utils._extract_resource_data') @patch('magnum.conductor.handlers.common.kube_utils.' '_extract_resource_definition_url') def test_k8s_update_url(self, mock_definition_url, mock_data, mock_update_with_path): expected_url = 'url' master_address = 'master_address' mock_data.return_value = None mock_definition_url.return_value = expected_url mock_resource = mock.MagicMock() kube_utils._k8s_update(master_address, mock_resource) mock_update_with_path.assert_called_once_with(master_address, expected_url) @patch('magnum.openstack.common.utils.trycmd') def test_k8s_update_with_path(self, mock_trycmd): expected_master_address = 'master_address' expected_pod_file = 'pod_file' expected_command = [ 'kubectl', 'update', '-s', expected_master_address, '-f', expected_pod_file ] kube_utils._k8s_update_with_path(expected_master_address, expected_pod_file) mock_trycmd.assert_called_once_with(*expected_command) @patch('magnum.conductor.handlers.common.kube_utils._k8s_update_with_path') @patch('tempfile.NamedTemporaryFile') def test_k8s_update_with_data(self, mock_named_tempfile, mock_k8s_update): expected_master_address = 'master_address' expected_data = 'resource_data' expected_filename = 'resource_file' mock_file = mock.MagicMock() mock_file.name = expected_filename mock_named_tempfile.return_value.__enter__.return_value = mock_file kube_utils._k8s_update_with_data(expected_master_address, expected_data) mock_file.write.assert_called_once_with(expected_data) mock_k8s_update.assert_called_once_with(expected_master_address, expected_filename)",,270,65
openstack%2Fmagnum~master~Ie065abeef3c65ea429b799a932fe39d868fabcbf,openstack/magnum,master,Ie065abeef3c65ea429b799a932fe39d868fabcbf,Add master endpoint support to kube_utils.py,MERGED,2015-01-06 05:49:11.000000000,2015-01-06 15:50:46.000000000,2015-01-06 15:50:44.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-06 05:49:11.000000000', 'files': ['magnum/conductor/handlers/common/kube_utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/be136bbd8e5c31997c9c4da77bdb1e9d91feecdb', 'message': 'Add master endpoint support to kube_utils.py\n\nkubeutils.py support k8s master endpoint url to connect remote k8s cluster.\nIn this change, some method signatures are refactored for future works.\n\nChange-Id: Ie065abeef3c65ea429b799a932fe39d868fabcbf\n'}]",0,145132,be136bbd8e5c31997c9c4da77bdb1e9d91feecdb,7,3,1,12385,,,0,"Add master endpoint support to kube_utils.py

kubeutils.py support k8s master endpoint url to connect remote k8s cluster.
In this change, some method signatures are refactored for future works.

Change-Id: Ie065abeef3c65ea429b799a932fe39d868fabcbf
",git fetch https://review.opendev.org/openstack/magnum refs/changes/32/145132/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/common/kube_utils.py'],1,be136bbd8e5c31997c9c4da77bdb1e9d91feecdb,impl-pod-create," def service_create(self, master_address, service): out, err = utils.trycmd('kubectl', 'create', '-s', master_address, '-f', service.service_definition_url) def service_update(self, master_address, service): out, err = utils.trycmd('kubectl', 'update', '-s', master_address, '-f', service.service_definition_url) '-s', master_address, def service_list(self, master_address): out = utils.execute('kubectl', 'get', 'services', '-s', master_address,) def service_delete(self, master_address, uuid): out, err = utils.trycmd('kubectl', 'delete', 'service', uuid, '-s', master_address) def service_get(self, master_address, uuid): out = utils.execute('kubectl', 'get', 'service', uuid, '-s', master_address) def service_show(self, master_address, uuid): out = utils.execute('kubectl', 'describe', 'service', uuid, '-s', master_address) def pod_create(self, master_address, contents): out, err = utils.trycmd('kubectl', 'create', '-s', master_address, '-f', contents.pod_definition_url) '-s', master_address, def pod_update(self, master_address, contents): out, err = utils.trycmd('kubectl', 'update', '-s', master_address, '-f', contents.pod_definition_url) '-s', master_address, def pod_list(self, master_address): out = utils.execute('kubectl', 'get', 'pods', '-s', master_address) def pod_delete(self, master_address, uuid): out, err = utils.trycmd('kubectl', 'delete', 'pod', uuid, '-s', master_address,) def pod_get(self, master_address, uuid): out = utils.execute('kubectl', 'get', 'pod', uuid, '-s', master_address) def pod_show(self, master_address, uuid): out = utils.execute('kubectl', 'describe', 'pod', uuid, '-s', master_address) def rc_create(self, master_address, contents): out, err = utils.trycmd('kubectl', 'create', '-s', master_address, '-f', contents.rc_definition_url) '-s', master_address, def rc_update(self, master_address, contents): out, err = utils.trycmd('kubectl', 'update', '-s', master_address, '-f', contents.rc_definition_url) '-s', master_address, def rc_delete(self, master_address, uuid): out, err = utils.trycmd('kubectl', 'delete', 'rc', uuid, '-s', master_address)"," # TODO(pkilambi): Add server endpoint config @staticmethod def service_create(service): out, err = utils.trycmd('kubectl', 'create', '-f', service.service_definition_url) @staticmethod def service_update(service): out, err = utils.trycmd('kubectl', 'update', '-f', service.service_definition_url) @staticmethod def service_list(): out = utils.execute('kubectl', 'get', 'services') @staticmethod def service_delete(uuid): out, err = utils.trycmd('kubectl', 'delete', 'service', uuid) @staticmethod def service_get(uuid): out = utils.execute('kubectl', 'get', 'service', uuid) @staticmethod def service_show(uuid): out = utils.execute('kubectl', 'describe', 'service', uuid) @staticmethod def pod_create(contents): out, err = utils.trycmd('kubectl', 'create', '-f', contents.pod_definition_url) @staticmethod def pod_update(contents): out, err = utils.trycmd('kubectl', 'update', '-f', contents.pod_definition_url) @staticmethod def pod_list(): out = utils.execute('kubectl', 'get', 'pods') @staticmethod def pod_delete(uuid): out, err = utils.trycmd('kubectl', 'delete', 'pod', uuid) @staticmethod def pod_get(uuid): out = utils.execute('kubectl', 'get', 'pod', uuid) @staticmethod def pod_show(uuid): out = utils.execute('kubectl', 'describe', 'pod', uuid) @staticmethod def rc_create(contents): out, err = utils.trycmd('kubectl', 'create', '-f', contents.rc_definition_url) @staticmethod def rc_update(contents): out, err = utils.trycmd('kubectl', 'update', '-f', contents.rc_definition_url) @staticmethod def rc_delete(uuid): out, err = utils.trycmd('kubectl', 'delete', 'rc', uuid)",55,52
openstack%2Fopenstack-manuals~master~I2ae271039788f8f138dc6c999a17cae36686bfce,openstack/openstack-manuals,master,I2ae271039788f8f138dc6c999a17cae36686bfce,Added deprecation notice for the RBD driver configuration option,MERGED,2015-01-02 06:26:17.000000000,2015-01-06 15:45:13.000000000,2015-01-06 15:45:12.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7923}, {'_account_id': 10705}, {'_account_id': 10897}]","[{'number': 1, 'created': '2015-01-02 06:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1596eaf8f3907bff4833e42dffaf3e19062cbcf3', 'message': 'Added deprecation notice for the RBD driver configuration option\n\nIn the RBD driver section, added a note about volume_tmp_dir option being deprecated from the rbd driver\nand replaced by  image_conversion_dir\n\nChange-Id: I2ae271039788f8f138dc6c999a17cae36686bfce\nbackport: none\nPartial-Bug: #1375490\n'}, {'number': 2, 'created': '2015-01-02 09:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f9afc6229c6fcc8b00fbbde6bed49f0e35825d88', 'message': 'Added deprecation notice for the RBD driver configuration option\n\nIn the RBD driver section, added a note about volume_tmp_dir option being deprecated from the rbd driver\nand replaced by  image_conversion_dir\n\nChange-Id: I2ae271039788f8f138dc6c999a17cae36686bfce\nbackport: none\nPartial-Bug: #1375490\n'}, {'number': 3, 'created': '2015-01-05 00:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0bc166128adb3bf9b01c9bb725edfec53f01c250', 'message': 'Added deprecation notice for the RBD driver configuration option\n\nIn the RBD driver section, added a note about volume_tmp_dir option being deprecated from the rbd driver\nand replaced by  image_conversion_dir\n\nChange-Id: I2ae271039788f8f138dc6c999a17cae36686bfce\nbackport: none\nPartial-Bug: #1406183\n'}, {'number': 4, 'created': '2015-01-05 23:17:08.000000000', 'files': ['doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d5a812f4b7e28a0f2b74262f7c37fc80b9499eb5', 'message': 'Added deprecation notice for the RBD driver configuration option\n\nIn the RBD driver section, added a note about volume_tmp_dir option being deprecated from the rbd driver\nand replaced by  image_conversion_dir\n\nChange-Id: I2ae271039788f8f138dc6c999a17cae36686bfce\nbackport: none\nPartial-Bug: #1406183\n'}]",2,144713,d5a812f4b7e28a0f2b74262f7c37fc80b9499eb5,21,8,4,10705,,,0,"Added deprecation notice for the RBD driver configuration option

In the RBD driver section, added a note about volume_tmp_dir option being deprecated from the rbd driver
and replaced by  image_conversion_dir

Change-Id: I2ae271039788f8f138dc6c999a17cae36686bfce
backport: none
Partial-Bug: #1406183
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/144713/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml'],1,1596eaf8f3907bff4833e42dffaf3e19062cbcf3,rbd_configref/darren, <note> <title>Deprecation notice</title> <para>The <literal>volume_tmp_dir<literal> option has been deprecated and replaced by <literal>image_conversion_dir</literal>.</para> </note>,,5,0
openstack%2Fopenstack-manuals~stable%2Fjuno~I66ac33052dc8b3c7d43bef09e7d96d4e8e14920b,openstack/openstack-manuals,stable/juno,I66ac33052dc8b3c7d43bef09e7d96d4e8e14920b,Fixed the document bug for huawei storage drivers,MERGED,2015-01-06 07:40:58.000000000,2015-01-06 15:45:05.000000000,2015-01-06 15:45:04.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2015-01-06 07:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/aa7babf926eb78aca7a0a954c326577c8812f357', 'message': 'Fixed the document bug for huawei storage drivers\n\nUpdate document for huawei storage drivers that have been merged in juno.\nThe following content will be amended:\n*The name of our driver have been changed from HVS to 18000;\n*Removed the configuration for Dorado.\n\nChange-Id: I66ac33052dc8b3c7d43bef09e7d96d4e8e14920b\nCloses-Bug: #1406227\n'}, {'number': 2, 'created': '2015-01-06 09:51:56.000000000', 'files': ['doc/config-reference/block-storage/drivers/huawei-storage-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/162990f0ab383ccad93517c14fa839dd246eb18f', 'message': 'Fixed the document bug for huawei storage drivers\n\nUpdate document for huawei storage drivers that have been merged in juno.\nThe following content will be amended:\n*The name of our driver have been changed from HVS to 18000;\n*Removed the configuration for Dorado.\n\nChange-Id: I66ac33052dc8b3c7d43bef09e7d96d4e8e14920b\nCloses-Bug: #1406227\n'}]",0,145157,162990f0ab383ccad93517c14fa839dd246eb18f,10,4,2,13203,,,0,"Fixed the document bug for huawei storage drivers

Update document for huawei storage drivers that have been merged in juno.
The following content will be amended:
*The name of our driver have been changed from HVS to 18000;
*Removed the configuration for Dorado.

Change-Id: I66ac33052dc8b3c7d43bef09e7d96d4e8e14920b
Closes-Bug: #1406227
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/57/145157/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/huawei-storage-driver.xml'],1,aa7babf926eb78aca7a0a954c326577c8812f357,juno-bug/1406227," series unified storage and OceanStor 18000 high-end storage to provide block storage services for OpenStack.</para> <para> OceanStor 18000 supports these operations: </para> <itemizedlist> <title>Configure Block Storage nodes</title> &lt;Host OSType=""Linux"" HostIP=""x.x.x.x, x.x.x.x""/> <para>The driver configuration file of OceanStor 18000 is shown as follows:</para> &lt;Product>18000&lt;/Product> &lt;RestURL>https://x.x.x.x:8088/deviceManager/rest/&lt;/RestURL> &lt;Host OSType=""Linux"" HostIP=""x.x.x.x, x.x.x.x""/> <title>Note for Fibre Channel driver configuration</title> <programlisting>enabled_backends = t_iscsi, 18000_iscsi[18000_iscsi]cinder_huawei_conf_file = /etc/cinder/cinder_huawei_conf_18000_iscsi.xml volume_backend_name = Huawei18000ISCSIDriver</programlisting> <para>Type of a storage product. Valid values are <literal>T</literal>or <literal>18000</literal>.</para> required for the 18000)</td> (not required for the 18000)</para> <td><option>RestURL</option></td> for the 18000)</td> required for the 18000.</para> <para>Name of a storage pool that you want to use.</para> <title>Note for the configuration</title> (The 18000 driver allows configuration of only one storage pool.)</para> <listitem> <para>The driver does not support the iSCSI multipath scenarios.</para> </listitem>"," series unified storage, OceanStor Dorado high-performance storage, and OceanStor HVS high-end storage to provide block storage services for OpenStack.</para> <para> OceanStor Dorado5100 supports these operations: </para> <itemizedlist> <listitem> <para>Create, delete, attach, and detach volumes.</para> </listitem> <listitem> <para>Create, list, and delete volume snapshots.</para> </listitem> <listitem> <para>Copy an image to a volume.</para> </listitem> <listitem> <para>Copy a volume to an image.</para> </listitem> </itemizedlist> <para> OceanStor Dorado2100 G2 supports these operations: </para> <itemizedlist> <listitem> <para>Create, delete, attach, and detach volumes.</para> </listitem> <listitem> <para>Copy an image to a volume.</para> </listitem> <listitem> <para>Copy a volume to an image.</para> </listitem> </itemizedlist> <para> OceanStor HVS supports these operations: </para> <itemizedlist> <title>Configure Cinder nodes</title> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> <para>The driver configuration file of OceanStor Dorado5100 is shown as follows:</para> <programlisting>&lt;?xml version='1.0' encoding='UTF-8'?> &lt;config> &lt;Storage> &lt;Product>Dorado&lt;/Product> &lt;Protocol>iSCSI&lt;/Protocol> &lt;ControllerIP0>x.x.x.x&lt;/ControllerIP0> &lt;ControllerIP1>x.x.x.x&lt;/ControllerIP1> &lt;UserName>xxxxxxxx&lt;/UserName> &lt;UserPassword>xxxxxxxx&lt;/UserPassword> &lt;/Storage> &lt;LUN> &lt;StripUnitSize>64&lt;/StripUnitSize> &lt;WriteType>1&lt;/WriteType> &lt;MirrorSwitch>1&lt;/MirrorSwitch> &lt;StoragePool Name=""xxxxxxxx""/> &lt;StoragePool Name=""xxxxxxxx""/> &lt;/LUN> &lt;iSCSI> &lt;DefaultTargetIP>x.x.x.x&lt;/DefaultTargetIP> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;/iSCSI> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> &lt;/config></programlisting> <para>The driver configuration file of OceanStor Dorado2100 G2 is shown as follows:</para> <programlisting>&lt;?xml version='1.0' encoding='UTF-8'?> &lt;config> &lt;Storage> &lt;Product>Dorado&lt;/Product> &lt;Protocol>iSCSI&lt;/Protocol> &lt;ControllerIP0>x.x.x.x&lt;/ControllerIP0> &lt;ControllerIP1>x.x.x.x&lt;/ControllerIP1> &lt;UserName>xxxxxxxx&lt;/UserName> &lt;UserPassword>xxxxxxxx&lt;/UserPassword> &lt;/Storage> &lt;LUN> &lt;LUNType>Thick&lt;/LUNType> &lt;WriteType>1&lt;/WriteType> &lt;MirrorSwitch>1&lt;/MirrorSwitch> &lt;/LUN> &lt;iSCSI> &lt;DefaultTargetIP>x.x.x.x&lt;/DefaultTargetIP> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;/iSCSI> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> &lt;/config></programlisting> <para>The driver configuration file of OceanStor HVS is shown as follows:</para> &lt;Product>HVS&lt;/Product> &lt;HVSURL>https://x.x.x.x:8088/deviceManager/rest/&lt;/HVSURL> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> <programlisting>enabled_backends = t_iscsi, dorado5100_iscsi[dorado5100_iscsi]cinder_huawei_conf_file = /etc/cinder/cinder_huawei_conf_dorado5100_iscsi.xml volume_backend_name = HuaweiDorado5100ISCSIDriver</programlisting> <para>OceanStor HVS storage system supports the QoS function. You must create a QoS policy for the HVS storage system and create the volume type to enable QoS as follows:</para> <programlisting>Create volume type: QoS_high cinder type-create QoS_high Configure extra_specs for QoS_high: cinder type-key QoS_high set capabilities:QoS_support=""&lt;is> True"" drivers:flow_strategy=OpenStack_QoS_high drivers:io_priority=high</programlisting> <note> <para><option>OpenStack_QoS_high</option> is a QoS policy created by a user for the HVS storage system. <option>QoS_high</option> is the self-defined volume type. Set the <option>io_priority</option> option to <literal>high</literal>, <literal>normal</literal>, or <literal>low</literal>.</para> </note> <para>OceanStor HVS storage system supports the SmartTier function. SmartTier has three tiers. You can create the volume type to enable SmartTier as follows:</para> <programlisting>Create volume type: Tier_high cinder type-create Tier_high Configure extra_specs for Tier_high: cinder type-key Tier_high set capabilities:Tier_support=""&lt;is> True"" drivers:distribute_policy=high drivers:transfer_strategy=high</programlisting> <note> <para><option>distribute_policy</option> and <option>transfer_strategy</option> can only be set to <literal>high</literal>, <literal>normal</literal>, or <literal>low</literal>.</para> </note> <para>Type of a storage product. Valid values are <literal>T</literal>, <literal>Dorado</literal>, or <literal>HVS</literal>.</para> required for the HVS)</td> (not required for the HVS)</para> <td><option>HVSURL</option></td> for the HVS)</td> required for the HVS.</para> <para>Name of a storage pool that you want to use. Not required for the Dorado2100 G2.</para> (HVS allows configuration of only one storage pool.)</para>",30,143
openstack%2Fkolla~master~I12b88b856dca150087261f86c674012dcc1b4816,openstack/kolla,master,I12b88b856dca150087261f86c674012dcc1b4816,Update the README to reflect new additions to kolla,MERGED,2015-01-06 15:29:16.000000000,2015-01-06 15:44:34.000000000,2015-01-06 15:44:34.000000000,"[{'_account_id': 3}, {'_account_id': 2834}]","[{'number': 1, 'created': '2015-01-06 15:29:16.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4112ab2239791b953b34b6167b3ff0b472159dc6', 'message': 'Update the README to reflect new additions to kolla\n\nAdded the new containers we are supporting.\nKubernetes has updated and kubecfg was replaced with kubectl.\n\nChange-Id: I12b88b856dca150087261f86c674012dcc1b4816\n'}]",0,145249,4112ab2239791b953b34b6167b3ff0b472159dc6,6,2,1,10419,,,0,"Update the README to reflect new additions to kolla

Added the new containers we are supporting.
Kubernetes has updated and kubecfg was replaced with kubectl.

Change-Id: I12b88b856dca150087261f86c674012dcc1b4816
",git fetch https://review.opendev.org/openstack/kolla refs/changes/49/145249/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,4112ab2239791b953b34b6167b3ff0b472159dc6,,* Neutron * Mongodb * Ceilometer * Zaqar * Horizon$ kubectl get pods,$ kubecfg list pods,6,1
openstack%2Fswift~feature%2Fec~I6e9ec5fa1f7ce56ba3211034090dd908e079f91d,openstack/swift,feature/ec,I6e9ec5fa1f7ce56ba3211034090dd908e079f91d,Build up reconstructor with correct node selection,MERGED,2014-10-17 19:18:28.000000000,2015-01-06 15:43:32.000000000,2015-01-06 15:43:30.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 5189}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7485}, {'_account_id': 10100}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-17 19:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c936c6af105d48d80ce1b2c7d498135a7079ceba', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}, {'number': 2, 'created': '2014-11-18 23:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/98b7dc63411534fc0bef31d1f334b2e707fc398c', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}, {'number': 3, 'created': '2014-12-07 17:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ad97486c69bad11c9896da90006164dffe667a53', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}, {'number': 4, 'created': '2014-12-09 20:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/60e2ea62a4e335688fbad0973f52a2a97a8ddf1c', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}, {'number': 5, 'created': '2015-01-05 18:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/93fb9dacf4167742fdced6aaee7979ec5b1803c0', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}, {'number': 6, 'created': '2015-01-05 19:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/36a2f2464cee5433217c8b7113d1b0283c9ea758', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}, {'number': 7, 'created': '2015-01-05 20:06:42.000000000', 'files': ['swift/obj/reconstructor.py', 'test/unit/obj/test_reconstructor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4feca7f0991a2fe7aa248b0e9540a030a8d1cad7', 'message': 'Build up reconstructor with correct node selection\n\nThe reconstructor does not operate on the full\nnode list for any given partition, only on its\nleft and right partners.  This is an incremental\nchange to the ongoing WIP on the reconstructor.\n\nblueprint ec-reconstructor\nChange-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d\n'}]",4,129361,4feca7f0991a2fe7aa248b0e9540a030a8d1cad7,37,11,7,7479,,,0,"Build up reconstructor with correct node selection

The reconstructor does not operate on the full
node list for any given partition, only on its
left and right partners.  This is an incremental
change to the ongoing WIP on the reconstructor.

blueprint ec-reconstructor
Change-Id: I6e9ec5fa1f7ce56ba3211034090dd908e079f91d
",git fetch https://review.opendev.org/openstack/swift refs/changes/61/129361/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/saio/swift/object-server/4.conf', 'swift/obj/reconstructor.py', 'doc/saio/swift/object-server/3.conf', 'doc/saio/swift/object-server/2.conf', 'doc/saio/swift/object-server/1.conf', 'test/unit/obj/test_reconstructor.py']",6,c936c6af105d48d80ce1b2c7d498135a7079ceba,bp/ec-reconstructor,"import unittest import os import cPickle as pickle import tempfile from contextlib import closing from gzip import GzipFile from shutil import rmtree from test.unit import FakeLogger, patch_policies from swift.common import utils from swift.obj import diskfile, reconstructor as object_reconstructor from swift.common import ring from swift.common.storage_policy import StoragePolicy, POLICIES, \ REPL_POLICY def _create_test_rings(path): testgz = os.path.join(path, 'object.ring.gz') intended_replica2part2dev_id = [ [0, 1, 2, 3, 4, 5, 6], [1, 2, 3, 0, 5, 6, 4], [2, 3, 0, 1, 6, 4, 5] ] intended_devs = [ {'id': 0, 'device': 'sda', 'zone': 0, 'ip': '127.0.0.0', 'port': 6000}, {'id': 1, 'device': 'sda', 'zone': 1, 'ip': '127.0.0.1', 'port': 6000}, {'id': 2, 'device': 'sda', 'zone': 2, 'ip': '127.0.0.2', 'port': 6000}, {'id': 3, 'device': 'sda', 'zone': 4, 'ip': '127.0.0.3', 'port': 6000}, {'id': 4, 'device': 'sda', 'zone': 5, 'ip': '127.0.0.4', 'port': 6000}, {'id': 5, 'device': 'sda', 'zone': 6, 'ip': 'fe80::202:b3ff:fe1e:8329', 'port': 6000}, {'id': 6, 'device': 'sda', 'zone': 7, 'ip': '2001:0db8:85a3:0000:0000:8a2e:0370:7334', 'port': 6000}, ] intended_part_shift = 30 with closing(GzipFile(testgz, 'wb')) as f: pickle.dump( ring.RingData(intended_replica2part2dev_id, intended_devs, intended_part_shift), f) testgz = os.path.join(path, 'object-1.ring.gz') with closing(GzipFile(testgz, 'wb')) as f: pickle.dump( ring.RingData(intended_replica2part2dev_id, intended_devs, intended_part_shift), f) return @patch_policies([ StoragePolicy.from_conf( REPL_POLICY, {'idx': 0, 'name': 'zero', 'is_default': False}), StoragePolicy.from_conf( REPL_POLICY, {'idx': 1, 'name': 'one', 'is_default': True}) ]) class TestObjectReconstructor(unittest.TestCase): def setUp(self): utils.HASH_PATH_SUFFIX = 'endcap' utils.HASH_PATH_PREFIX = '' self.testdir = tempfile.mkdtemp() self.devices = os.path.join(self.testdir, 'node') rmtree(self.testdir, ignore_errors=1) os.mkdir(self.testdir) os.mkdir(self.devices) os.mkdir(os.path.join(self.devices, 'sda')) self.objects = os.path.join(self.devices, 'sda', diskfile.get_data_dir(0)) self.objects_1 = os.path.join(self.devices, 'sda', diskfile.get_data_dir(1)) os.mkdir(self.objects) os.mkdir(self.objects_1) self.parts = {} self.parts_1 = {} self.part_nums = ['0', '1', '2', '3'] for part in self.part_nums: self.parts[part] = os.path.join(self.objects, part) os.mkdir(self.parts[part]) self.parts_1[part] = os.path.join(self.objects_1, part) os.mkdir(self.parts_1[part]) _create_test_rings(self.testdir) self.conf = dict( swift_dir=self.testdir, devices=self.devices, mount_check='false', timeout='300', stats_interval='1') self.reconstructor = \ object_reconstructor.ObjectReconstructor(self.conf) self.reconstructor.logger = FakeLogger() self.df_mgr = diskfile.DiskFileManager(self.conf, self.reconstructor.logger) def tearDown(self): rmtree(self.testdir, ignore_errors=1) def test_get_partners(self): # both of the expected values below are exhaustive possible results # from get_part nodes given the polices and dev lists defined in # our custom test ring. We confirm every combination returns # the expected values # format: [(devid in question), (part_nodes for the given part), ...] expected_handoffs = \ [(0, [1, 2, 3]), (1, [2, 3, 0]), (2, [3, 0, 1]), (3, [0, 1, 2]), (4, [0, 1, 2]), (4, [1, 2, 3]), (4, [2, 3, 0]), (4, [3, 0, 1]), (5, [0, 1, 2]), (5, [1, 2, 3]), (5, [2, 3, 0]), (5, [3, 0, 1]), (6, [0, 1, 2]), (6, [1, 2, 3]), (6, [2, 3, 0]), (6, [3, 0, 1]), (0, [1, 2, 3]), (1, [2, 3, 0]), (2, [3, 0, 1]), (3, [0, 1, 2]), (4, [0, 1, 2]), (4, [1, 2, 3]), (4, [2, 3, 0]), (4, [3, 0, 1]), (5, [0, 1, 2]), (5, [1, 2, 3]), (5, [2, 3, 0]), (5, [3, 0, 1]), (6, [0, 1, 2]), (6, [1, 2, 3]), (6, [2, 3, 0]), (6, [3, 0, 1])] # format: [(devid in question), (part_nodes for the given part), # left id, right id...] expected_partners = \ [(0, [0, 1, 2], 2, 1), (0, [2, 3, 0], 3, 2), (0, [3, 0, 1], 3, 1), (1, [0, 1, 2], 0, 2), (1, [1, 2, 3], 3, 2), (1, [3, 0, 1], 0, 3), (2, [0, 1, 2], 1, 0), (2, [1, 2, 3], 1, 3), (2, [2, 3, 0], 0, 3), (3, [1, 2, 3], 2, 1), (3, [2, 3, 0], 2, 0), (3, [3, 0, 1], 1, 0), (0, [0, 1, 2], 2, 1), (0, [2, 3, 0], 3, 2), (0, [3, 0, 1], 3, 1), (1, [0, 1, 2], 0, 2), (1, [1, 2, 3], 3, 2), (1, [3, 0, 1], 0, 3), (2, [0, 1, 2], 1, 0), (2, [1, 2, 3], 1, 3), (2, [2, 3, 0], 0, 3), (3, [1, 2, 3], 2, 1), (3, [2, 3, 0], 2, 0), (3, [3, 0, 1], 1, 0)] got_handoffs = [] got_partners = [] for pol in POLICIES: obj_ring = self.reconstructor.get_object_ring(pol.idx) for local_dev in obj_ring.devs: for part_num in self.part_nums: part_nodes = obj_ring.get_part_nodes(int(part_num)) ids = [] for node in part_nodes: ids.append(node['id']) handoff, partners = self.reconstructor._get_partners( local_dev['id'], obj_ring, part_num) if handoff is False: left = partners[0]['id'] right = partners[1]['id'] got_partners.append((local_dev['id'], ids, left, right)) else: got_handoffs.append((local_dev['id'], ids)) self.assertEquals(expected_handoffs, got_handoffs) self.assertEquals(expected_partners, got_partners) if __name__ == '__main__': unittest.main()",,224,27
openstack%2Fopenstack-manuals~stable%2Ficehouse~I05bbe35953afa8b660b77c09f00c904c22e2740b,openstack/openstack-manuals,stable/icehouse,I05bbe35953afa8b660b77c09f00c904c22e2740b,Fixed the document bug for huawei storage drivers,MERGED,2015-01-06 07:29:26.000000000,2015-01-06 15:41:33.000000000,2015-01-06 15:41:32.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2015-01-06 07:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cfa0d1d86493ac827cc90b460dad6eb20990d546', 'message': 'Fixed the document bug for huawei storage drivers\n\nUpdate document for huawei storage drivers that have been merged in icehouse.\nThe following content will be amended:\n*The name of our driver have been changed from HVS to 18000;\n*Removed the configuration for Dorado.\n\nChange-Id: I05bbe35953afa8b660b77c09f00c904c22e2740b\nCloses-Bug: #1406226\n'}, {'number': 2, 'created': '2015-01-06 09:55:19.000000000', 'files': ['doc/config-reference/block-storage/drivers/huawei-storage-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/233c8098bbdc5bc83bbd74403650feb6610f4b95', 'message': 'Fixed the document bug for huawei storage drivers\n\nUpdate document for huawei storage drivers that have been merged in icehouse.\nThe following content will be amended:\n*The name of our driver have been changed from HVS to 18000;\n*Removed the configuration for Dorado.\n\nChange-Id: I05bbe35953afa8b660b77c09f00c904c22e2740b\nCloses-Bug: #1406226\n'}]",0,145154,233c8098bbdc5bc83bbd74403650feb6610f4b95,10,4,2,13203,,,0,"Fixed the document bug for huawei storage drivers

Update document for huawei storage drivers that have been merged in icehouse.
The following content will be amended:
*The name of our driver have been changed from HVS to 18000;
*Removed the configuration for Dorado.

Change-Id: I05bbe35953afa8b660b77c09f00c904c22e2740b
Closes-Bug: #1406226
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/54/145154/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/huawei-storage-driver.xml'],1,cfa0d1d86493ac827cc90b460dad6eb20990d546,icehouse-bug/1406226," series unified storage and OceanStor 18000 high-end storage to provide block storage services for OpenStack.</para> <para>OceanStor T series unified storage supports these operations: </para> <itemizedlist> <listitem> <para>Create, delete, attach, and detach volumes.</para> </listitem> <listitem> <para>Create, list, and delete volume snapshots.</para> </listitem> <listitem> <para>Create a volume from a snapshot.</para> </listitem> <listitem> <para>Copy an image to a volume.</para> </listitem> <listitem> <para>Copy a volume to an image.</para> </listitem> <listitem> <para>Clone a volume.</para> </listitem> </itemizedlist> <para> OceanStor 18000 supports these operations: </para> <itemizedlist> <listitem> <para>Create, delete, attach, and detach volumes.</para> </listitem> <listitem> <para>Create, list, and delete volume snapshots.</para> </listitem> <listitem> <para>Copy an image to a volume.</para> </listitem> <listitem> <para>Copy a volume to an image.</para> </listitem> <listitem> <para>Create a volume from a snapshot.</para> </listitem> <listitem> <para>Clone a volume.</para> </listitem> </itemizedlist> <title>Configure Block Storage nodes</title> &lt;Host OSType=""Linux"" HostIP=""x.x.x.x, x.x.x.x""/> <para>The driver configuration file of OceanStor 18000 is shown as follows:</para> &lt;Product>18000&lt;/Product> &lt;RestURL>https://x.x.x.x:8088/deviceManager/rest/&lt;/RestURL> &lt;Host OSType=""Linux"" HostIP=""x.x.x.x, x.x.x.x""/> <title>Note for Fibre Channel driver configuration</title> <programlisting>enabled_backends = t_iscsi, 18000_iscsi[18000_iscsi]cinder_huawei_conf_file = /etc/cinder/cinder_huawei_conf_18000_iscsi.xml volume_backend_name = Huawei18000ISCSIDriver</programlisting> <para>Type of a storage product. Valid values are <literal>T</literal>or <literal>18000</literal>.</para> required for the 18000)</td> (not required for the 18000)</para> <td><option>RestURL</option></td> for the 18000)</td> required for the 18000.</para> <para>Name of a storage pool that you want to use.</para> <title>Note for the configuration</title> (The 18000 driver allows configuration of only one storage pool.)</para> <listitem> <para>The driver does not support the iSCSI multipath scenarios.</para> </listitem>"," series unified storage, OceanStor Dorado high-performance storage, and OceanStor HVS high-end storage to provide block storage services for OpenStack.</para> <para>OceanStor T series unified storage supports the following operations:<itemizedlist> <listitem> <para>Create volume</para> </listitem> <listitem> <para>Delete volume</para> </listitem> <listitem> <para>Attach volume</para> </listitem> <listitem> <para>Detach volume</para> </listitem> <listitem> <para>Create snapshot</para> </listitem> <listitem> <para>Delete snapshot</para> </listitem> <listitem> <para>Create volume from snapshot</para> </listitem> <listitem> <para>Create clone volume</para> </listitem> <listitem> <para>Copy image to volume</para> </listitem> <listitem> <para>Copy volume to image</para> </listitem> </itemizedlist>OceanStor Dorado5100 supports the following operations:<itemizedlist> <listitem> <para>Create volume</para> </listitem> <listitem> <para>Delete volume</para> </listitem> <listitem> <para>Attach volume</para> </listitem> <listitem> <para>Detach volume</para> </listitem> <listitem> <para>Create snapshot</para> </listitem> <listitem> <para>Delete snapshot</para> </listitem> <listitem> <para>Copy image to volume</para> </listitem> <listitem> <para>Copy volume to image</para> </listitem> </itemizedlist>OceanStor Dorado2100 G2 supports the following operations:<itemizedlist> <listitem> <para>Create volume</para> </listitem> <listitem> <para>Delete volume</para> </listitem> <listitem> <para>Attach volume</para> </listitem> <listitem> <para>Detach volume</para> </listitem> <listitem> <para>Copy image to volume</para> </listitem> <listitem> <para>Copy volume to image</para> </listitem> </itemizedlist>OceanStor HVS supports the following operations:<itemizedlist> <listitem> <para>Create volume</para> </listitem> <listitem> <para>Delete volume</para> </listitem> <listitem> <para>Attach volume</para> </listitem> <listitem> <para>Detach volume</para> </listitem> <listitem> <para>Create snapshot</para> </listitem> <listitem> <para>Delete snapshot</para> </listitem> <listitem> <para>Create volume from snapshot</para> </listitem> <listitem> <para>Create clone volume</para> </listitem> <listitem> <para>Copy image to volume</para> </listitem> <listitem> <para>Copy volume to image</para> </listitem> </itemizedlist></para> <title>Configure Cinder nodes</title> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> <para>The driver configuration file of OceanStor Dorado5100 is shown as follows:</para> <programlisting>&lt;?xml version='1.0' encoding='UTF-8'?> &lt;config> &lt;Storage> &lt;Product>Dorado&lt;/Product> &lt;Protocol>iSCSI&lt;/Protocol> &lt;ControllerIP0>x.x.x.x&lt;/ControllerIP0> &lt;ControllerIP1>x.x.x.x&lt;/ControllerIP1> &lt;UserName>xxxxxxxx&lt;/UserName> &lt;UserPassword>xxxxxxxx&lt;/UserPassword> &lt;/Storage> &lt;LUN> &lt;StripUnitSize>64&lt;/StripUnitSize> &lt;WriteType>1&lt;/WriteType> &lt;MirrorSwitch>1&lt;/MirrorSwitch> &lt;StoragePool Name=""xxxxxxxx""/> &lt;StoragePool Name=""xxxxxxxx""/> &lt;/LUN> &lt;iSCSI> &lt;DefaultTargetIP>x.x.x.x&lt;/DefaultTargetIP> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;/iSCSI> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> &lt;/config></programlisting> <para>The driver configuration file of OceanStor Dorado2100 G2 is shown as follows:</para> <programlisting>&lt;?xml version='1.0' encoding='UTF-8'?> &lt;config> &lt;Storage> &lt;Product>Dorado&lt;/Product> &lt;Protocol>iSCSI&lt;/Protocol> &lt;ControllerIP0>x.x.x.x&lt;/ControllerIP0> &lt;ControllerIP1>x.x.x.x&lt;/ControllerIP1> &lt;UserName>xxxxxxxx&lt;/UserName> &lt;UserPassword>xxxxxxxx&lt;/UserPassword> &lt;/Storage> &lt;LUN> &lt;LUNType>Thick&lt;/LUNType> &lt;WriteType>1&lt;/WriteType> &lt;MirrorSwitch>1&lt;/MirrorSwitch> &lt;/LUN> &lt;iSCSI> &lt;DefaultTargetIP>x.x.x.x&lt;/DefaultTargetIP> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;Initiator Name=""xxxxxxxx"" TargetIP=""x.x.x.x""/> &lt;/iSCSI> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> &lt;/config></programlisting> <para>The driver configuration file of OceanStor HVS is shown as follows:</para> &lt;Product>HVS&lt;/Product> &lt;HVSURL>https://x.x.x.x:8088/deviceManager/rest/&lt;/HVSURL> &lt;Host OSType=”Linux” HostIP=”x.x.x.x, x.x.x.x”/> <programlisting>enabled_backends = t_iscsi, dorado5100_iscsi[dorado5100_iscsi]cinder_huawei_conf_file = /etc/cinder/cinder_huawei_conf_dorado5100_iscsi.xml volume_backend_name = HuaweiDorado5100ISCSIDriver</programlisting> <para>OceanStor HVS storage system supports the QoS function. You must create a QoS policy for the HVS storage system and create the volume type to enable QoS as follows:</para> <programlisting>Create volume type: QoS_high cinder type-create QoS_high Configure extra_specs for QoS_high: cinder type-key QoS_high set capabilities:QoS_support=""&lt;is> True"" drivers:flow_strategy=OpenStack_QoS_high drivers:io_priority=high</programlisting> <note> <para><option>OpenStack_QoS_high</option> is a QoS policy created by a user for the HVS storage system. <option>QoS_high</option> is the self-defined volume type. Set the <option>io_priority</option> option to <literal>high</literal>, <literal>normal</literal>, or <literal>low</literal>.</para> </note> <para>OceanStor HVS storage system supports the SmartTier function. SmartTier has three tiers. You can create the volume type to enable SmartTier as follows:</para> <programlisting>Create volume type: Tier_high cinder type-create Tier_high Configure extra_specs for Tier_high: cinder type-key Tier_high set capabilities:Tier_support=""&lt;is> True"" drivers:distribute_policy=high drivers:transfer_strategy=high</programlisting> <note> <para><option>distribute_policy</option> and <option>transfer_strategy</option> can only be set to <literal>high</literal>, <literal>normal</literal>, or <literal>low</literal>.</para> </note> <para>Type of a storage product. Valid values are <literal>T</literal>, <literal>Dorado</literal>, or <literal>HVS</literal>.</para> required for the HVS)</td> (not required for the HVS)</para> <td><option>HVSURL</option></td> for the HVS)</td> required for the HVS.</para> <para>Name of a storage pool that you want to use. Not required for the Dorado2100 G2.</para> (HVS allows configuration of only one storage pool.)</para>",72,216
openstack%2Fmonasca-notification~master~Ie9616d8629112fc5f1f1576951a3cbe3b99218b0,openstack/monasca-notification,master,Ie9616d8629112fc5f1f1576951a3cbe3b99218b0,Added pagerduty support to notification_processor,MERGED,2014-12-19 17:53:40.000000000,2015-01-06 15:36:29.000000000,2015-01-06 15:36:28.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14273}]","[{'number': 1, 'created': '2014-12-19 17:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/25b8ebbfd819a60186598008ad93b402cf5bea4f', 'message': 'Added pagerduty support to notification_processor\n\nChange-Id: Ie9616d8629112fc5f1f1576951a3cbe3b99218b0\n'}, {'number': 2, 'created': '2014-12-19 19:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/fdd1635272d1700db6fcddedc50cbbec1ec70882', 'message': 'Added pagerduty support to notification_processor\n\nChange-Id: Ie9616d8629112fc5f1f1576951a3cbe3b99218b0\n'}, {'number': 3, 'created': '2014-12-19 23:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/13f2cf07e0867b926e861523f32c30c0a69f5a80', 'message': 'Added pagerduty support to notification_processor\n\nRefactored the tests to make pagerduty functionality more clear\n\nChange-Id: Ie9616d8629112fc5f1f1576951a3cbe3b99218b0\n'}, {'number': 4, 'created': '2015-01-06 00:23:48.000000000', 'files': ['monasca_notification/processors/notification_processor.py', 'notification.yaml', 'monasca_notification/main.py', 'tests/test_notification_processor.py'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/45a2411ebbc1c1d21cc6aea3946c7983dfb50466', 'message': 'Added pagerduty support to notification_processor\n\nRefactored the tests to make pagerduty functionality more clear\n\nChange-Id: Ie9616d8629112fc5f1f1576951a3cbe3b99218b0\n'}]",4,143147,45a2411ebbc1c1d21cc6aea3946c7983dfb50466,18,5,4,14273,,,0,"Added pagerduty support to notification_processor

Refactored the tests to make pagerduty functionality more clear

Change-Id: Ie9616d8629112fc5f1f1576951a3cbe3b99218b0
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/47/143147/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_notification/processors/notification_processor.py', 'notification.yaml', 'monasca_notification/main.py', 'tests/test_notification_processor.py']",4,25b8ebbfd819a60186598008ad93b402cf5bea4f,,"import json self.pagerduty_config = {'timeout': 50, 'key': 'foobar'} self.webhook_config, self.pagerduty_config)) self.log_queue.put(url) self.log_queue.put(data) self.log_queue.put(headers) def _http_post_400(self, url, data, headers, **kwargs): r = requestsResponse(400) return r def _http_post_403(self, url, data, headers, **kwargs): r = requestsResponse(403) return r def _http_post_500(self, url, data, headers, **kwargs): r = requestsResponse(500) return r def _http_post_504(self, url, data, headers, **kwargs): r = requestsResponse(504) return r url = self.log_queue.get(timeout=3) data = self.log_queue.get(timeout=3) headers = self.log_queue.get(timeout=3) self.assertEqual(url, ""me@here.com"") self.assertEqual(data, {'alarm_id': '0'}) self.assertEqual(headers, {'content-type': 'application/json'}) def test_pagerduty_good_response(self): """"""pagerduty good message """""" self.http_func = self._http_post_200 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('pagerduty', 0, 1, 'pagerduty notification', 'ABCDEF', alarm_dict) self._start_processor() self.notification_queue.put([notification]) url = self.log_queue.get(timeout=3) data = self.log_queue.get(timeout=3) headers = self.log_queue.get(timeout=3) self.assertEqual( url, 'https://events.pagerduty.com/generic/2010-04-15/create_event.json') headers = dict(headers) self.assertEqual(headers['content-type'], 'application/json') data = dict(json.loads(data)) self.assertEqual(data['service_key'], 'ABCDEF') self.assertEqual(data['event_type'], 'trigger') self.assertEqual(data['description'], 'I am alarming!') self.assertEqual(data['client'], 'Monasca') self.assertEqual(data['client_url'], '') details = dict(data['details']) self.assertEqual(details['alarm_id'], '0') self.assertEqual(details['alarm_name'], 'test Alarm') self.assertEqual(details['current'], 'ALARM') self.assertEqual(details['message'], 'I am alarming!') self.assertTrue(self.log_queue.empty()) self.processor.terminate() def test_pagerduty_400(self): """"""pagerduty 400 """""" self.http_func = self._http_post_400 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('pagerduty', 0, 1, 'pagerduty notification', 'ABCDEF', alarm_dict) self._start_processor() self.notification_queue.put([notification]) log_msg = self.log_queue.get(timeout=3) self.assertRegexpMatches(log_msg, ""Error with pagerduty request."") self.assertRegexpMatches(log_msg, ""key=<ABCDEF>"") self.assertRegexpMatches(log_msg, ""response=400"") self.assertTrue(self.log_queue.empty()) self.processor.terminate() def test_pagerduty_403(self): """"""pagerduty 403 """""" self.http_func = self._http_post_403 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('pagerduty', 0, 1, 'pagerduty notification', 'ABCDEF', alarm_dict) self._start_processor() self.notification_queue.put([notification]) log_msg = self.log_queue.get(timeout=3) self.assertRegexpMatches(log_msg, ""Error with pagerduty request."") self.assertRegexpMatches(log_msg, ""key=<ABCDEF>"") self.assertRegexpMatches(log_msg, ""response=403"") self.assertTrue(self.log_queue.empty()) self.processor.terminate() def test_pagerduty_500(self): """"""pagerduty 500 """""" self.http_func = self._http_post_500 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('pagerduty', 0, 1, 'pagerduty notification', 'ABCDEF', alarm_dict) self._start_processor() self.notification_queue.put([notification]) log_msg = self.log_queue.get(timeout=3) self.assertRegexpMatches(log_msg, ""Error with pagerduty request."") self.assertRegexpMatches(log_msg, ""key=<ABCDEF>"") self.assertRegexpMatches(log_msg, ""response=500"") self.assertTrue(self.log_queue.empty()) self.processor.terminate() def test_pagerduty_504(self): """"""pagerduty 504 """""" self.http_func = self._http_post_504 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('pagerduty', 0, 1, 'pagerduty notification', 'ABCDEF', alarm_dict) self._start_processor() self.notification_queue.put([notification]) log_msg = self.log_queue.get(timeout=3) self.assertRegexpMatches(log_msg, ""Error with pagerduty request."") self.assertRegexpMatches(log_msg, ""key=<ABCDEF>"") self.assertRegexpMatches(log_msg, ""response=504"") self.assertTrue(self.log_queue.empty()) self.processor.terminate() def test_pagerduty_exception(self): """"""pagerduty exception """""" self.http_func = self._http_post_exception metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('pagerduty', 0, 1, 'pagerduty notification', 'ABCDEF', alarm_dict) self._start_processor() self.notification_queue.put([notification]) log_msg = self.log_queue.get(timeout=3) self.assertEqual(log_msg, ""timeout 50"") log_msg = self.log_queue.get(timeout=3) self.assertRegexpMatches(log_msg, ""Exception on pagerduty request"") self.assertRegexpMatches(log_msg, ""key=<ABCDEF>"") self.assertRegexpMatches( log_msg, ""exception=<class 'requests.exceptions.Timeout'>"") self.assertRaises(requests.exceptions.Timeout) self.assertTrue(self.log_queue.empty()) self.processor.terminate()"," self.webhook_config)) self.log_queue.put(""%s %s %s"" % (url, data, headers)) log_msg = self.log_queue.get(timeout=3) self.assertRegexpMatches(log_msg, ""me@here.com"") self.assertRegexpMatches(log_msg, ""alarm_id.: '0'"") self.assertRegexpMatches(log_msg, ""content-type.: .application/json"")",357,12
openstack%2Fnova~master~Ic331d8a8a9e7b7236f4a8f89a9c28c31d71dd9cd,openstack/nova,master,Ic331d8a8a9e7b7236f4a8f89a9c28c31d71dd9cd,VMware: ensure that configdrive file is accessible after resize,ABANDONED,2015-01-02 09:20:24.000000000,2015-01-06 15:25:50.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-02 09:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcd171d68e0b1b0107aac186689a79aae4a4340e', 'message': 'VMware: ensure that configdrive file is accessible after resize\n\nWhen a instance is resized the VM is clone. The cloning does not\ncopy the config drive. This break if the instance is on a host that\ndoes not have access to the original datastore.\n\nCloses-bug: #1407050\n\nChange-Id: Ic331d8a8a9e7b7236f4a8f89a9c28c31d71dd9cd\n'}, {'number': 2, 'created': '2015-01-04 13:34:32.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/fake.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/unit/virt/vmwareapi/test_ds_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e01dfec2d1722521054f0e3bf49c5b120dc04db6', 'message': 'VMware: ensure that configdrive file is accessible after resize\n\nWhen a instance is resized the VM is clone. The cloning does not\ncopy the config drive. This break if the instance is on a host that\ndoes not have access to the original datastore.\n\nCloses-bug: #1407050\n\nChange-Id: Ic331d8a8a9e7b7236f4a8f89a9c28c31d71dd9cd\n'}]",0,144726,e01dfec2d1722521054f0e3bf49c5b120dc04db6,14,7,2,1653,,,0,"VMware: ensure that configdrive file is accessible after resize

When a instance is resized the VM is clone. The cloning does not
copy the config drive. This break if the instance is on a host that
does not have access to the original datastore.

Closes-bug: #1407050

Change-Id: Ic331d8a8a9e7b7236f4a8f89a9c28c31d71dd9cd
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/144726/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/vm_util.py']",2,fcd171d68e0b1b0107aac186689a79aae4a4340e,resize-with-cfg-drive-3,"def get_filebacked_devices(session, vm_ref, instance): """"""Gets all devices that have file backings."""""" hardware_devices = session._call_method(vim_util, ""get_dynamic_property"", vm_ref, ""VirtualMachine"", ""config.hardware.device"") if hardware_devices.__class__.__name__ == ""ArrayOfVirtualDevice"": hardware_devices = hardware_devices.VirtualDevice uuid = instance.uuid adapter_type_dict = {} virtual_disks = [] cdroms = [] vmdk_controller_key = None for device in hardware_devices: if device.__class__.__name__ == ""VirtualDisk"": if device.backing.__class__.__name__ == \ ""VirtualDiskFlatVer2BackingInfo"": if uuid: if uuid in device.backing.fileName: file_path = device.backing.fileName else: file_path = device.backing.fileName vmdk_controller_key = device.controllerKey if getattr(device.backing, 'thinProvisioned', False): disk_type = ""thin"" else: if getattr(device.backing, 'eagerlyScrub', False): disk_type = ""eagerZeroedThick"" else: disk_type = constants.DEFAULT_DISK_TYPE virtual_disks.append((file_path, disk_type, device)) elif device.__class__.__name__ == ""VirtualLsiLogicController"": adapter_type_dict[device.key] = constants.DEFAULT_ADAPTER_TYPE elif device.__class__.__name__ == ""VirtualBusLogicController"": adapter_type_dict[device.key] = constants.ADAPTER_TYPE_BUSLOGIC elif device.__class__.__name__ == ""VirtualIDEController"": adapter_type_dict[device.key] = constants.ADAPTER_TYPE_IDE elif device.__class__.__name__ == ""VirtualLsiLogicSASController"": adapter_type_dict[device.key] = constants.ADAPTER_TYPE_LSILOGICSAS elif device.__class__.__name__ == ""ParaVirtualSCSIController"": adapter_type_dict[device.key] = constants.ADAPTER_TYPE_PARAVIRTUAL elif device.__class__.__name__ == ""VirtualCdrom"": if device.backing.__class__.__name__ == \ ""VirtualCdromIsoBackingInfo"": cdroms.append((device.backing.fileName, device.backing.datastore, device)) adapter_type = adapter_type_dict.get(vmdk_controller_key, """") return {'disks': virtual_disks, 'adapter_type': adapter_type, 'cdroms': cdroms} task_info = session._wait_for_task(vm_clone_task) return task_info.result def detach_device_from_vm(session, vm_ref, device, destroy_disk=False): """"""Detach device from VM by reconfiguration."""""" client_factory = session.vim.client.factory detach_config_spec = get_vmdk_detach_config_spec( client_factory, device, destroy_disk) reconfigure_vm(session, vm_ref, detach_config_spec)", session._wait_for_task(vm_clone_task),124,3
openstack%2Fnova~master~Ib6f2f46e8eb9c445eb22c676fb17f6a1f1d68144,openstack/nova,master,Ib6f2f46e8eb9c445eb22c676fb17f6a1f1d68144,VMware: fix root disk resize bug,ABANDONED,2015-01-04 14:54:38.000000000,2015-01-06 15:25:16.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6983}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-04 14:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/788d656f35a9dde9827aba901beae635492c71f8', 'message': 'VMware: fix root disk resize bug\n\nCommit 7ae506a4b1829fbd8cbecc0a6b267f76230face7 did not\nuse the correct datatsore for resizing the root disk. This worked\ndue to the fact that all of the datastores are in the same\ndatacenter.\n\nChange-Id: Ib6f2f46e8eb9c445eb22c676fb17f6a1f1d68144\nCloses-bug: #1407438\n'}, {'number': 2, 'created': '2015-01-05 09:03:46.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a078bbce81e3caf0b4e27967cbc9dc95eea89b4f', 'message': 'VMware: fix root disk resize bug\n\nCommit 7ae506a4b1829fbd8cbecc0a6b267f76230face7 did not\nuse the correct datatsore for resizing the root disk. This worked\ndue to the fact that all of the datastores are in the same\ndatacenter.\n\nThe patch also moves the resize code to the correct place where\nwe can use the flavor instead of extracting it from the instance.\n\nChange-Id: Ib6f2f46e8eb9c445eb22c676fb17f6a1f1d68144\nCloses-bug: #1407438\n'}]",0,144888,a078bbce81e3caf0b4e27967cbc9dc95eea89b4f,12,7,2,1653,,,0,"VMware: fix root disk resize bug

Commit 7ae506a4b1829fbd8cbecc0a6b267f76230face7 did not
use the correct datatsore for resizing the root disk. This worked
due to the fact that all of the datastores are in the same
datacenter.

The patch also moves the resize code to the correct place where
we can use the flavor instead of extracting it from the instance.

Change-Id: Ib6f2f46e8eb9c445eb22c676fb17f6a1f1d68144
Closes-bug: #1407438
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/144888/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/vm_util.py']",4,788d656f35a9dde9827aba901beae635492c71f8,resize-disk-4," if hardware_devices.__class__.__name__ == ""ArrayOfVirtualDevice"": hardware_devices = hardware_devices.VirtualDevice uuid = instance['uuid'] vmdk_file_path = None vmdk_datastore = None for device in hardware_devices: if device.__class__.__name__ == ""VirtualDisk"": if device.backing.__class__.__name__ == \ ""VirtualDiskFlatVer2BackingInfo"": if uuid: if uuid in device.backing.fileName: return (device.backing.fileName, device.backing.datastore) else: vmdk_file_path = device.backing.fileName vmdk_datastore = device.backing.datastore return (vmdk_file_path, vmdk_datastore)"," (vmdk_path, adapter_type, disk_type) = get_vmdk_path_and_adapter_type( hardware_devices, uuid=instance['uuid']) return vmdk_path",33,13
openstack%2Fstevedore~master~I24cbc49ee8c2ed80599307a296225587c37448f5,openstack/stevedore,master,I24cbc49ee8c2ed80599307a296225587c37448f5,ignore .testrepository directory created by testr,MERGED,2015-01-05 20:13:20.000000000,2015-01-06 15:16:56.000000000,2015-01-06 15:16:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-01-05 20:13:20.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/stevedore/commit/549fa835508716e0e657fd276b480ff68e0ab954', 'message': 'ignore .testrepository directory created by testr\n\nChange-Id: I24cbc49ee8c2ed80599307a296225587c37448f5\n'}]",0,145044,549fa835508716e0e657fd276b480ff68e0ab954,8,3,1,2472,,,0,"ignore .testrepository directory created by testr

Change-Id: I24cbc49ee8c2ed80599307a296225587c37448f5
",git fetch https://review.opendev.org/openstack/stevedore refs/changes/44/145044/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,549fa835508716e0e657fd276b480ff68e0ab954,bug/1407778,/.testrepository/,,1,0
openstack%2Fstevedore~master~Iab5f03a08d11697604e8876a9ad674ac91617a3c,openstack/stevedore,master,Iab5f03a08d11697604e8876a9ad674ac91617a3c,clean up default environments run by tox,MERGED,2015-01-05 20:13:20.000000000,2015-01-06 15:16:49.000000000,2015-01-06 15:16:49.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-01-05 20:13:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/stevedore/commit/554bd471d5f206345286c2120927eca921219f4a', 'message': 'clean up default environments run by tox\n\nChange-Id: Iab5f03a08d11697604e8876a9ad674ac91617a3c\n'}]",0,145043,554bd471d5f206345286c2120927eca921219f4a,8,3,1,2472,,,0,"clean up default environments run by tox

Change-Id: Iab5f03a08d11697604e8876a9ad674ac91617a3c
",git fetch https://review.opendev.org/openstack/stevedore refs/changes/43/145043/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,554bd471d5f206345286c2120927eca921219f4a,bug/1407778,"envlist = py33,py34,py26,py27,pypy,pep8,docs","envlist = py26,py27,py32,py33,py34,pypy,pep8,docs",1,1
openstack%2Fnova-specs~master~Ibbab7cb29911d52b57c467c6bfbc5876d1102e79,openstack/nova-specs,master,Ibbab7cb29911d52b57c467c6bfbc5876d1102e79,Online Schema Changes,MERGED,2014-06-25 14:47:51.000000000,2015-01-06 15:11:00.000000000,2015-01-06 15:10:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9060}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-06-25 14:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5cbf1dc44d52622383c35ebb04a389a343e6bb6e', 'message': 'Online Schema Changes\n\nMake database migrations execute online when possible. This will allow\noperators to reduce the amount of downtime currently required during\ndeploys by running most database schema changes while services are\nrunning.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 2, 'created': '2014-06-25 14:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1c5e5216f04e28064004a9b6aef198f008388e4a', 'message': 'Online Schema Changes\n\nMake database migrations execute online when possible. This will allow\noperators to reduce the amount of downtime currently required during\ndeploys by running most database schema changes while services are\nrunning.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 3, 'created': '2014-06-26 15:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4d53158c992666fe8c59c3e77137e806c00a15cc', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 4, 'created': '2014-07-08 14:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2dde10373fbfdf686974a72054e332a37136d89a', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 5, 'created': '2014-07-08 15:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/108e18d09e8b239c1c9ed9df2ef45c6bded20ee9', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 6, 'created': '2014-11-17 16:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b466fbc6eded27066a2f910138f27b1aa1bf5400', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 7, 'created': '2014-11-25 19:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b0b56109e3e0de1181b428340ac03107220db43b', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 8, 'created': '2014-12-12 02:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d92924937b5f4b6d37b65f476af671274df5978b', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}, {'number': 9, 'created': '2014-12-15 17:32:54.000000000', 'files': ['specs/kilo/approved/online-schema-changes.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d39c87cc9a84077126213ab3c4432d74f121382f', 'message': 'Online Schema Changes\n\nMake schema changes execute online (ie while services are running) when\nsafely and semantically possible. This will allow operators to reduce the\namount of downtime currently required during deploys by running most\ndatabase schema changes when services are running.\n\nChange-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79\n'}]",56,102545,d39c87cc9a84077126213ab3c4432d74f121382f,75,14,9,100,,,0,"Online Schema Changes

Make schema changes execute online (ie while services are running) when
safely and semantically possible. This will allow operators to reduce the
amount of downtime currently required during deploys by running most
database schema changes when services are running.

Change-Id: Ibbab7cb29911d52b57c467c6bfbc5876d1102e79
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/45/102545/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/online-schema-changes.rst'],1,5cbf1dc44d52622383c35ebb04a389a343e6bb6e,online-schema-changes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================== Online Schema Changes ===================== https://blueprints.launchpad.net/nova/+spec/online-schema-changes Make database migrations execute online when possible. This will allow operators to reduce the amount of downtime currently required during deploys by running most database schema changes while services are running. Problem description =================== * Database migrations are not required to be compatible with running code which forces them to be run when offline. * Database migrations have historically been a source of lengthy downtime during deployments. Proposed change =============== Migrations would be split into three phases: # Expand. This would apply changes that are backward compatible with old running code. # Migrate. This would apply changes that are necessary to be run offline. # Contract. This would apply changes that are backward compatible with new running code. A subset of schema changes will have DDL automatically generated by comparing the running database schema against the model defined in nova/db/sqlalchemy/model.py Schema changes that will be automatically performed during expand: - Table creates - Column additions - Non-Unique Index additions Schema changes that will be automatically performed during migrate: - Unique Index additions/removals - Foreign Key additions/removals - Column nullability - Column server default Schema changes that will be automatically performed during contract: - Table drops - Column drops - Non-Unique Index drops The rest will continue to be explictly handled by migrations via sqlalchemy-migrate. Alembic will be used for it's DDL generating module. This will not change the tool used for writing migrations. The expand and contract phases are intended to be run while services are running. This limits the schema changes to those which are backwards compatible with the code running. The migrate phase has some schema changes that are autogenerated. This phase is intended to be run offline, but some schema changes are difficult to automate. An example would be column type changes. Since the Cactus release, the only schema change that wasn't possible to easily automate in testing was the 'deleted' column type change. Each of the 'expand', 'migrate' and 'contract' phases would verify the previous phases were executed before continuing. The existing 'db sync' command would be reimplemented to run the 'expand' 'migrate' and 'contract' phases. This would provide a backwards compatible and simpler way to upgrade the database for those that don't wish to run migrations online. A new '--dryrun' argument would print, instead of execute, each generated DDL statement. This could be used by database administrators to see what states would be executed. These can be optionally executed by hand if desired. Also, a 'compare' command to 'nova-manage db' would show the differences between the running schema and the model in an easier to read format. Alternatives ------------ Splitting the existing single stream of migrations into three separate streams of migrations. This would require changes to sqlalchemy-migrate or alembic to be able to manage separate streams of migrations. Data model impact ----------------- The existing model needs to be brought in line with changes migrations make. These are limited to a handful of cases: - PostgreSQL index name limitations - PostgreSQL Enum type naming - MySQL index length restrictions - Foreign key names REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- The new tool provides a means of viewing differences between the current schema and the model. The expand and contract phases are optional. If not explicitly run otherwise, the existing call to 'nova-manage db sync' would execute all necessary schema changes, as is the existing behavior. Performance Impact ------------------ Running online DDL changes can affect the performance of a running system. This is optional and is only done when the user explicitly requests it. Other deployer impact --------------------- Those deployers that want to take advantage of the online schema changes will need to run the 'expand', 'migrate' and 'contract' commands at the appropriate steps in their deployment process. Deployers that have made local schema changes (extra indexes, columns, tables, etc) will need to update the model to ensure those additions aren't dropped during the contract phase. Developer impact ---------------- Keeping the model updated with database migrations will be much more important. A new unit test will enforce this. Implementation ============== Assignee(s) ----------- Primary assignee: johannes.erdfelt Other contributors: None Work Items ---------- - Bring model into line with existing migrations - Implement schema synchronizer - Implement new 'expand', 'migrate', 'contract' and 'compare' database commands Dependencies ============ The schema synchronizer is implemented on top of alembic for its DDL generating functionality. This is already in the OpenStack global requirements list, but will be a new addition for Nova. Testing ======= No tempest tests will be added since tempest does not do any upgrade testing. turbo-hipster will be leveraged to ensure that each of the expand, migrate and contract phases operate correctly on production database snapshots. Documentation Impact ==================== Documentation will need to be updated to include the new 'expand', 'migrate', 'contract' and 'compare' commands to 'nova-manage db'. Release Notes will need to be updated to warn that the model will need to be updated with local schema changes. References ========== https://etherpad.openstack.org/p/juno-nova-live-upgrade ",,223,0
openstack-attic%2Fimage-api~master~I7bb2d1a7f42bfacd2f9def9370b73c1257ae51fa,openstack-attic/image-api,master,I7bb2d1a7f42bfacd2f9def9370b73c1257ae51fa,fixed the command to install maven on fedora,MERGED,2015-01-03 19:33:50.000000000,2015-01-06 15:01:47.000000000,2015-01-06 15:01:47.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2015-01-03 19:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/289039f0f3a7c8a4551686cc50f11086459c020a', 'message': 'fixed the command to install maven on fedora\n\nChange-Id: I7bb2d1a7f42bfacd2f9def9370b73c1257ae51fa\n'}, {'number': 2, 'created': '2015-01-04 04:24:20.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/8ace697bf5a13c4012f86d2c4b3929bbeaef9cf0', 'message': 'fixed the command to install maven on fedora\n\nChange-Id: I7bb2d1a7f42bfacd2f9def9370b73c1257ae51fa\n'}]",0,144845,8ace697bf5a13c4012f86d2c4b3929bbeaef9cf0,9,3,2,14474,,,0,"fixed the command to install maven on fedora

Change-Id: I7bb2d1a7f42bfacd2f9def9370b73c1257ae51fa
",git fetch https://review.opendev.org/openstack-attic/image-api refs/changes/45/144845/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,289039f0f3a7c8a4551686cc50f11086459c020a,typo, yum install maven, yum install maven3,1,1
openstack%2Fapi-site~master~I1bf3b9d95b526c49628bb7dc715f47dcdcd4152b,openstack/api-site,master,I1bf3b9d95b526c49628bb7dc715f47dcdcd4152b,Fix wrong description of uuid and port parameters,MERGED,2015-01-02 07:29:20.000000000,2015-01-06 14:58:47.000000000,2015-01-06 14:58:45.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 10705}]","[{'number': 1, 'created': '2015-01-02 07:29:20.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/common.ent', 'api-ref/src/wadls/volume-api/src/v1/common.ent', 'api-ref/src/wadls/volume-api/src/v2/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/396e8cb08a96ca62f2cdf649533e20f541502261', 'message': 'Fix wrong description of uuid and port parameters\n\nThe current description of the uuid and port paramaters for server create state\nthat uuid is for nova-network and port is for neutron. In reality, uuid is for\nthe network uuid and port is for specifying an already existing port-id.\n\nChange-Id: I1bf3b9d95b526c49628bb7dc715f47dcdcd4152b\nCloses-Bug: #1407031\n'}]",0,144717,396e8cb08a96ca62f2cdf649533e20f541502261,8,4,1,14119,,,0,"Fix wrong description of uuid and port parameters

The current description of the uuid and port paramaters for server create state
that uuid is for nova-network and port is for neutron. In reality, uuid is for
the network uuid and port is for specifying an already existing port-id.

Change-Id: I1bf3b9d95b526c49628bb7dc715f47dcdcd4152b
Closes-Bug: #1407031
",git fetch https://review.opendev.org/openstack/api-site refs/changes/17/144717/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2/common.ent', 'api-ref/src/wadls/volume-api/src/v1/common.ent', 'api-ref/src/wadls/volume-api/src/v2/common.ent']",3,396e8cb08a96ca62f2cdf649533e20f541502261,bug/1407031," xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> for a network, specify the UUID of the network in the <code>uuid</code> attribute in a <code>networks</code> object.</para> for an already existing port, specify the port-id in the <code>port</code> attribute in xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> for a network, specify the UUID of the network in the <code>uuid</code> attribute in a <code>networks</code> object. Required if you omit the <code>port</code> attribute.</para> xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> for an already existing port, specify the port-id in the <code>port</code> attribute in"," xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> for a <code>nova-network</code> network, specify the UUID in the <code>uuid</code> attribute in a <code>networks</code> object.</para> for a <code>neutron</code> network, specify the UUID in the <code>port</code> attribute in xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> for a <code>nova-network</code> network, specify the UUID in the <code>uuid</code> attribute in a <code>networks</code> object. Required if you omit the <code>port</code> attribute.</para> xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> for a <code>neutron</code> network, specify the UUID in the <code>port</code> attribute in",45,51
openstack%2Fapi-site~master~Iea72123879654bd187828cf746c5c9b14b84038d,openstack/api-site,master,Iea72123879654bd187828cf746c5c9b14b84038d,Fix a wrong response code in Neutron API Reference,MERGED,2015-01-06 05:27:13.000000000,2015-01-06 14:51:32.000000000,2015-01-06 14:51:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 8878}, {'_account_id': 10068}]","[{'number': 1, 'created': '2015-01-06 05:27:13.000000000', 'files': ['api-ref/src/wadls/netconn-api/src/os-subnets.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/b932e699f7122d72b6992534f78bca7d87eaf3a6', 'message': 'Fix a wrong response code in Neutron API Reference\n\nFix the response code for ""update subnet"" in Neutron API Reference\nfrom 201 to 200.\n\nChange-Id: Iea72123879654bd187828cf746c5c9b14b84038d\nCloses-Bug: #1405720\n'}]",0,145129,b932e699f7122d72b6992534f78bca7d87eaf3a6,10,5,1,14154,,,0,"Fix a wrong response code in Neutron API Reference

Fix the response code for ""update subnet"" in Neutron API Reference
from 201 to 200.

Change-Id: Iea72123879654bd187828cf746c5c9b14b84038d
Closes-Bug: #1405720
",git fetch https://review.opendev.org/openstack/api-site refs/changes/29/145129/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/netconn-api/src/os-subnets.wadl'],1,b932e699f7122d72b6992534f78bca7d87eaf3a6,bug/1405720," <response status=""200""> &subnetListParameters; <representation"," <response status=""201""> &subnetListParameters; <representation",1,1
openstack%2Fnova~master~If023bfa766f67288699c17f5b5daabdc24d03ea2,openstack/nova,master,If023bfa766f67288699c17f5b5daabdc24d03ea2,hardware: fix numa topology from image meta data,MERGED,2014-12-22 10:20:13.000000000,2015-01-06 14:45:12.000000000,2015-01-06 14:45:08.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 7730}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11647}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-12-22 10:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/722a5db8315791fc8cb3ac4e586d90372bcfcbb8', 'message': 'hardware: fix numa topology from image meta data\n\nThe behavior of the method numa_get_constraints is to get a dict or\nimage properties to determine whether a NUMA topology has been defined\nin the image.\nWe currently pass to this method the object image or sometimes only\nproperties of the image.\n\nWe should always pass the object image.\n\nChange-Id: If023bfa766f67288699c17f5b5daabdc24d03ea2\nCloses-Bug: #1404839\n'}, {'number': 2, 'created': '2014-12-22 13:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f282efb3107d33f9a216054c9a59015bd3a380d1', 'message': 'hardware: fix numa topology from image meta data\n\nThe behavior of the method numa_get_constraints is to get a dict or\nimage properties to determine whether a NUMA topology has been defined\nin the image.\nWe currently pass to this method the object image or sometimes only\nproperties of the image.\n\nWe should always pass the object image.\n\nChange-Id: If023bfa766f67288699c17f5b5daabdc24d03ea2\nCloses-Bug: #1404839\n'}, {'number': 3, 'created': '2015-01-05 09:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ced666f92c47bae6629956ded90d8a95c9f85d82', 'message': 'hardware: fix numa topology from image meta data\n\nThe behavior of the method numa_get_constraints is to get a dict or\nimage properties to determine whether a NUMA topology has been defined\nin the image.\nWe currently pass to this method a dict of image information or sometimes only\na dict of properties of the image.\n\nWe should always pass the dict of image information\n\nChange-Id: If023bfa766f67288699c17f5b5daabdc24d03ea2\nCloses-Bug: #1404839\n'}, {'number': 4, 'created': '2015-01-05 16:30:42.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aab3709d6fd57159ba5aef09d7f55beb9da68404', 'message': 'hardware: fix numa topology from image meta data\n\nThe behavior of the method numa_get_constraints is to get a dict of\nimage properties to determine whether a NUMA topology has been defined\nin the image.\nWe currently pass to this method a dict of image information or sometimes only\na dict of properties of the image.\n\nWe should always pass the dict of image information\n\nChange-Id: If023bfa766f67288699c17f5b5daabdc24d03ea2\nCloses-Bug: #1404839'}]",9,143417,aab3709d6fd57159ba5aef09d7f55beb9da68404,42,13,4,7730,,,0,"hardware: fix numa topology from image meta data

The behavior of the method numa_get_constraints is to get a dict of
image properties to determine whether a NUMA topology has been defined
in the image.
We currently pass to this method a dict of image information or sometimes only
a dict of properties of the image.

We should always pass the dict of image information

Change-Id: If023bfa766f67288699c17f5b5daabdc24d03ea2
Closes-Bug: #1404839",git fetch https://review.opendev.org/openstack/nova refs/changes/17/143417/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/compute/api.py']",3,722a5db8315791fc8cb3ac4e586d90372bcfcbb8,bug/1404839," instance_type, boot_meta)"," instance_type, boot_meta.get('properties', {}))",11,3
openstack%2Frally~master~Icc42e220ac3f15ae6c838a4698b3c9578177513c,openstack/rally,master,Icc42e220ac3f15ae6c838a4698b3c9578177513c,Fix py3k issues,MERGED,2014-12-11 21:01:03.000000000,2015-01-06 14:36:57.000000000,2015-01-06 14:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8367}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-11 21:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fc5b34dfd98fb19cef000a68d2ac5a00a34efd26', 'message': 'DO NOT MERGE: test verify job\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 2, 'created': '2014-12-11 22:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/07fab94e09973686c9f4a674e289a695ad605f68', 'message': 'DO NOT MERGE: test verify job\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 3, 'created': '2014-12-11 23:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7cd1cb3175eefe29fc9f8b7330da9bf8767a619e', 'message': 'DO NOT MERGE: test verify job\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 4, 'created': '2014-12-16 14:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0dfa2830b44dbb3802bb19f6d84054b381138df2', 'message': 'DO NOT MERGE: try to launch unit tests in Py3 env\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 5, 'created': '2014-12-19 14:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8a71c28a52c7864a42fdb2af15427e2fc114fef5', 'message': 'DO NOT MERGE: try to launch unit tests in Py3 env\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 6, 'created': '2014-12-19 14:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d93d739d89338192e9a07c83d27d505a8bd6d785', 'message': 'DO NOT MERGE: try to launch unit tests in Py3 env\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 7, 'created': '2014-12-19 16:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a8f7979262c4c2a59662c85c65b9e47d90bdd5c0', 'message': 'DO NOT MERGE: try to launch unit tests in Py3 env\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 8, 'created': '2015-01-04 23:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/81aad51f1a05649fd2a25963f744d6bb3d0c2009', 'message': 'Fix py3k issue: module urllib2\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 9, 'created': '2015-01-05 00:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6224504e6ab585adebe963d067c6731c02983c3e', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3\n   (it was renamed to \'__code__\'), so check of python version with proper\n   code added to \'tests.unit/test_docstrings\' module.\n\nTests, which are successfully finished in Python 34:\n tests.unit.aas\n tests.unit.db\n tests.unit.doc\n tests.unit.fixtures\n tests.unit.objects\n tests.unit.orchestrator\n tests.unit.rally_jobs\n tests.unit.ui\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 10, 'created': '2015-01-05 01:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1417a80899faf34e87dd2b4fceb2d1166e46784b', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3\n   (it was renamed to \'__code__\'), so check of python version with proper\n   code added to \'tests.unit/test_docstrings\' module.\n\nAlso, [testenv:py34] section added to tox.ini while. tox -epy34 will run only\nthose test, which are successfully finished in Python 34.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 11, 'created': '2015-01-05 10:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5a39dc7cde2b2bb290e0a86370606b9658fc67a3', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3\n   (it was renamed to \'__code__\'), so check of python version with proper\n   code added to \'tests.unit/test_docstrings\' module.\n\nAlso, [testenv:py34] section added to tox.ini while. tox -epy34 will run only\nthose test, which are successfully finished in Python 34.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 12, 'created': '2015-01-05 11:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2b815ad528a5bcc66935e43205647672027db3ef', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3\n   (it was renamed to \'__code__\'), so check of python version with proper\n   code added to \'tests.unit/test_docstrings\' module.\n\nAlso, [testenv:py34] section added to tox.ini while. tox -epy34 will run only\nthose test, which are successfully finished in Python 34.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 13, 'created': '2015-01-05 13:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/87f7794bfe668389a31f352a8a5b66c633c44e62', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3\n   (it was renamed to \'__code__\'), so check of python version with proper\n   code added to \'tests.unit/test_docstrings\' module.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 14, 'created': '2015-01-05 16:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6a354650c87957cf68e4ce924b3533d985a59183', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3, but\n   \'__code__\' attribute exist in both Python 2 and Python 3\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 15, 'created': '2015-01-05 16:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3430f407dc7f4b554f95774fe9697dfe0d3f7aee', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3, but\n   \'__code__\' attribute exist in both Python 2 and Python 3\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 16, 'created': '2015-01-05 22:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2dcdb4e45e4b5d7f0a3658ae5c9d512621d0dfff', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3, but\n   \'__code__\' attribute exist in both Python 2 and Python 3\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 17, 'created': '2015-01-06 10:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4719afc61d70f815f91c47dc8ab4b6430224a48e', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3, but\n   \'__code__\' attribute exist in both Python 2 and Python 3\n\nAlso, 3 tests are broken due to new release(1.6.0) of oslo.config, so we\nneed to skip them to unblock our gates until new version of oslo.config will\nbe released with appropriate fix.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 18, 'created': '2015-01-06 10:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a47dfe3c323d1fa3e4ab9fded8864550d2370684', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3, but\n   \'__code__\' attribute exist in both Python 2 and Python 3\n\nAlso, 3 tests are broken due to new release(1.6.0) of oslo.config, so we\nneed to skip them to unblock our gates until new version of oslo.config will\nbe released with appropriate fix.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 19, 'created': '2015-01-06 10:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0f12970e4611b281a257afcb87481d94dcab6876', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3\n   (it was renamed to \'__code__\'), so check of python version with proper\n   code added to \'tests.unit/test_docstrings\' module.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}, {'number': 20, 'created': '2015-01-06 11:01:37.000000000', 'files': ['tests/hacking/checks.py', 'tests/unit/benchmark/context/sahara/test_sahara_edp.py', 'rally/deploy/serverprovider/providers/openstack.py', 'tests/unit/test_docstrings.py', 'rally/benchmark/engine.py', 'tests/unit/common/test_utils.py', 'rally/benchmark/context/sahara/sahara_edp.py', 'tests/unit/benchmark/context/test_images.py', 'tests/unit/cmd/test_cliutils.py', 'tests/unit/deploy/serverprovider/providers/test_openstack.py', 'rally/common/utils.py', 'rally/cmd/envutils.py', 'tests/hacking/README.rst', 'tests/unit/benchmark/context/cleanup/test_resources.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/0f7c504bee032817ba20870bd231e7d076d5eb74', 'message': 'Fix py3k issues\n\n1) Module urllib2 is missed in Python 3, so it should be replaced by other\n   http lib. ""requests"" is good library for such stuff, which supports both\n   Python 2.* and Python 3.*\n\n2) Function \'rally.common.utils.parse_docstring\' uses built-in function\n   \'filter\'. This function returns different types in Python 2.* and\n   Python 3.*. Since results are used as a list, \'filter\' should be replaced\n   by list comprehension.\n\n3) Extend H330 hacking rule to chech \'dict.iterkeys()\', \'dict.itervalues()\'\n   and \'dict.iterlist()\'. Also, fixed all places, which are failed in terms\n   of this rule.\n\n4) Function object does not have \'func_code\' attribute in Python 3, but\n   \'__code__\' attribute exist in both Python 2 and Python 3\n\nAlso, 3 tests are broken due to new release(1.6.0) of oslo.config, so we\nneed to skip them to unblock our gates until new version of oslo.config will\nbe released with appropriate fix.\n\nCloses-Bug: #1405919\n\nChange-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c\n'}]",8,141163,0f7c504bee032817ba20870bd231e7d076d5eb74,65,5,20,9545,,,0,"Fix py3k issues

1) Module urllib2 is missed in Python 3, so it should be replaced by other
   http lib. ""requests"" is good library for such stuff, which supports both
   Python 2.* and Python 3.*

2) Function 'rally.common.utils.parse_docstring' uses built-in function
   'filter'. This function returns different types in Python 2.* and
   Python 3.*. Since results are used as a list, 'filter' should be replaced
   by list comprehension.

3) Extend H330 hacking rule to chech 'dict.iterkeys()', 'dict.itervalues()'
   and 'dict.iterlist()'. Also, fixed all places, which are failed in terms
   of this rule.

4) Function object does not have 'func_code' attribute in Python 3, but
   '__code__' attribute exist in both Python 2 and Python 3

Also, 3 tests are broken due to new release(1.6.0) of oslo.config, so we
need to skip them to unblock our gates until new version of oslo.config will
be released with appropriate fix.

Closes-Bug: #1405919

Change-Id: Icc42e220ac3f15ae6c838a4698b3c9578177513c
",git fetch https://review.opendev.org/openstack/rally refs/changes/63/141163/20 && git format-patch -1 --stdout FETCH_HEAD,['tests/ci/rally-verify.sh'],1,fc5b34dfd98fb19cef000a68d2ac5a00a34efd26,py3," rally --rally-debug verify compare --uuid-1 ""wrong_uuid"" --uuid-2 ${VERIFICATIONS[2]} --${OUTPUT_FORMAT} --output-file ${OUTPUT_FILE}", rally --rally-debug verify compare --uuid-1 ${VERIFICATIONS[1]} --uuid-2 ${VERIFICATIONS[2]} --${OUTPUT_FORMAT} --output-file ${OUTPUT_FILE},1,1
openstack%2Fneutron~master~I5d936c6e73033e8b6500110015b5e777ecca6381,openstack/neutron,master,I5d936c6e73033e8b6500110015b5e777ecca6381,Refactor common l2pop DB code into single method,ABANDONED,2014-12-11 17:42:51.000000000,2015-01-06 14:11:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 7921}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 17:42:51.000000000', 'files': ['neutron/plugins/ml2/drivers/l2pop/db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/868052b174ca59247d72be6cf75cd4573185f9a8', 'message': 'Refactor common l2pop DB code into single method\n\nOn the DB layer the queries used to fetch DVR and non DVR port details\nare almost the same, so extracted the logic to a common method that gets\nthe model to query as an argument, and the filtering for the DVR ports\nis still done in the DVR method.\n\nChange-Id: I5d936c6e73033e8b6500110015b5e777ecca6381\n'}]",1,141113,868052b174ca59247d72be6cf75cd4573185f9a8,22,19,1,7921,,,0,"Refactor common l2pop DB code into single method

On the DB layer the queries used to fetch DVR and non DVR port details
are almost the same, so extracted the logic to a common method that gets
the model to query as an argument, and the filtering for the DVR ports
is still done in the DVR method.

Change-Id: I5d936c6e73033e8b6500110015b5e777ecca6381
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/141113/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/l2pop/db.py'],1,868052b174ca59247d72be6cf75cd4573185f9a8,bug/1365476," def get_network_ports(self, session, network_id, port_binding_model=ml2_models.PortBinding): with session.begin(subtransactions=True): query = session.query(port_binding_model, port_binding_model.host) query = self.get_network_ports(session, network_id, ml2_models.DVRPortBinding) return query.filter(models_v2.Port.device_owner == const.DEVICE_OWNER_DVR_INTERFACE)"," def get_network_ports(self, session, network_id): with session.begin(subtransactions=True): query = session.query(ml2_models.PortBinding, ml2_models.PortBinding.host) with session.begin(subtransactions=True): query = session.query(ml2_models.DVRPortBinding, agents_db.Agent) query = query.join(agents_db.Agent, agents_db.Agent.host == ml2_models.DVRPortBinding.host) query = query.join(models_v2.Port) query = query.filter(models_v2.Port.network_id == network_id, models_v2.Port.admin_state_up == sql.true(), models_v2.Port.device_owner == const.DEVICE_OWNER_DVR_INTERFACE, agents_db.Agent.agent_type.in_( l2_const.SUPPORTED_AGENT_TYPES)) return query",9,17
openstack%2Fopenstack-ansible~master~Ib3d9e86b6434f686eba1cbea08b5ee8a8cb74a50,openstack/openstack-ansible,master,Ib3d9e86b6434f686eba1cbea08b5ee8a8cb74a50,Fix newline issue in sshd_config,ABANDONED,2015-01-06 11:42:06.000000000,2015-01-06 14:10:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-06 11:42:06.000000000', 'files': ['rpc_deployment/roles/common/tasks/ssh_config.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7fd5ca3823b5788009548d5e28f487fde9de5c02', 'message': 'Fix newline issue in sshd_config\n\nhttps://review.openstack.org/#/c/143151/ introduced a problem where\nunder certain circumstances MaxSessions 500 would be appended to the\nlast line of sshd_config rather than added as a new line.\n\nThis patch fixes that. It also means that in normal situations an extra\nnew line is inserted, but that is inconsequential.\n\nChange-Id: Ib3d9e86b6434f686eba1cbea08b5ee8a8cb74a50\nCloses-Bug: #1404343\n'}]",0,145205,7fd5ca3823b5788009548d5e28f487fde9de5c02,6,4,1,7217,,,0,"Fix newline issue in sshd_config

https://review.openstack.org/#/c/143151/ introduced a problem where
under certain circumstances MaxSessions 500 would be appended to the
last line of sshd_config rather than added as a new line.

This patch fixes that. It also means that in normal situations an extra
new line is inserted, but that is inconsequential.

Change-Id: Ib3d9e86b6434f686eba1cbea08b5ee8a8cb74a50
Closes-Bug: #1404343
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/05/145205/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/common/tasks/ssh_config.yml'],1,7fd5ca3823b5788009548d5e28f487fde9de5c02,bug/1404343," line: ""\nMaxSessions 500"" line: ""\nMaxStartups 500"""," line: ""MaxSessions 500"" line: ""MaxStartups 500""",2,2
openstack%2Fneutron~master~I58c43328f0512de25720871fc51c79f074493cdf,openstack/neutron,master,I58c43328f0512de25720871fc51c79f074493cdf,print error when no match mapping found in check_segment_for_agent,MERGED,2014-12-29 05:38:34.000000000,2015-01-06 14:00:35.000000000,2015-01-06 13:53:18.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7962}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 11114}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-29 05:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55cc02abc61096019dd38dd27a2584a671290372', 'message': 'print error when no match mapping found in check_segment_for_agent\n\nerror print when no match PHYSICAL_NETWORK mapping found in function\ncheck_segment_for_agent for ovs mechanism driver\n\nChange-Id: I58c43328f0512de25720871fc51c79f074493cdf\nCloses-Bug: #1404962\n'}, {'number': 2, 'created': '2014-12-29 06:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a849140abc975cbb9daaa8320877e40b16af6860', 'message': 'print error when no match mapping found in check_segment_for_agent\n\nerror print when no match PHYSICAL_NETWORK mapping found in function\ncheck_segment_for_agent for ovs mechanism driver\n\nChange-Id: I58c43328f0512de25720871fc51c79f074493cdf\nCloses-Bug: #1404962\n'}, {'number': 3, 'created': '2014-12-30 02:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/132bf577cf2fac2c233d90bcf6f07a80dd8d5f09', 'message': 'print error when no match mapping found in check_segment_for_agent\n\nerror print when no match PHYSICAL_NETWORK mapping found in function\ncheck_segment_for_agent for OVS and linuxbridge mechanism driver.\n\nChange-Id: I58c43328f0512de25720871fc51c79f074493cdf\nCloses-Bug: #1404962\n'}, {'number': 4, 'created': '2015-01-06 02:41:11.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_linuxbridge.py', 'neutron/plugins/ml2/drivers/mech_openvswitch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a04fa671209343009887575fdda9c8a3a7d23ba0', 'message': 'print error when no match mapping found in check_segment_for_agent\n\nerror print when no match PHYSICAL_NETWORK mapping found in function\ncheck_segment_for_agent for OVS and linuxbridge mechanism driver.\n\nChange-Id: I58c43328f0512de25720871fc51c79f074493cdf\nCloses-Bug: #1404962\n'}]",8,144257,a04fa671209343009887575fdda9c8a3a7d23ba0,70,23,4,11114,,,0,"print error when no match mapping found in check_segment_for_agent

error print when no match PHYSICAL_NETWORK mapping found in function
check_segment_for_agent for OVS and linuxbridge mechanism driver.

Change-Id: I58c43328f0512de25720871fc51c79f074493cdf
Closes-Bug: #1404962
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/144257/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/mech_openvswitch.py'],1,55cc02abc61096019dd38dd27a2584a671290372,bug/1404962," ret = segment[api.PHYSICAL_NETWORK] in mappings if not ret: LOG.error(""Failed to find %s in mappings %s"", segment[api.PHYSICAL_NETWORK], mappings) return ret", return segment[api.PHYSICAL_NETWORK] in mappings,5,1
openstack%2Fheat~master~Ib3bd706fa0103db4363563b6b9882a98cf75cff5,openstack/heat,master,Ib3bd706fa0103db4363563b6b9882a98cf75cff5,Remove MutableDict realization,MERGED,2015-01-05 14:17:41.000000000,2015-01-06 13:53:54.000000000,2015-01-06 13:53:53.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-05 14:17:41.000000000', 'files': ['heat/db/sqlalchemy/mutable.py', 'heat/db/sqlalchemy/types.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5bfcb627ac980379fc9d7a178f0462a8934bce80', 'message': ""Remove MutableDict realization\n\nWe already use SQLAlchemy 0.9.7 so we can use MutableDict from\nSQLAlchemy directly and remove it's realization from Heat code\n\nChange-Id: Ib3bd706fa0103db4363563b6b9882a98cf75cff5\n""}]",0,144987,5bfcb627ac980379fc9d7a178f0462a8934bce80,11,5,1,7491,,,0,"Remove MutableDict realization

We already use SQLAlchemy 0.9.7 so we can use MutableDict from
SQLAlchemy directly and remove it's realization from Heat code

Change-Id: Ib3bd706fa0103db4363563b6b9882a98cf75cff5
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/144987/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/sqlalchemy/mutable.py', 'heat/db/sqlalchemy/types.py']",2,5bfcb627ac980379fc9d7a178f0462a8934bce80,remove-mutabledict,from sqlalchemy.ext import mutablemutable.MutableDict.associate_with(LongText) mutable.MutableDict.associate_with(Json),def associate_with(sqltype): # TODO(leizhang) When we removed sqlalchemy 0.7 dependence # we can import MutableDict directly and remove ./mutable.py try: from sqlalchemy.ext import mutable mutable.MutableDict.associate_with(Json) except ImportError: from heat.db.sqlalchemy import mutable mutable.MutableDict.associate_with(Json) associate_with(LongText) associate_with(Json),3,75
openstack%2Fheat~master~I6d95df203b556c8ec2088d40a446427f7087b9a7,openstack/heat,master,I6d95df203b556c8ec2088d40a446427f7087b9a7,Use oslo.config generator,MERGED,2014-12-17 11:02:54.000000000,2015-01-06 13:53:44.000000000,2015-01-06 13:53:43.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6983}, {'_account_id': 7385}, {'_account_id': 7770}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8537}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-17 11:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7b4407cc1efd3ba067bda8783bbd33f4bb7cdcd2', 'message': 'Use oslo.config generator\n\nReplace usage of old incubator configuration generator by the\noslo.config tool.\n\ntools/config/generate_sample.sh has been replaced by tox -egenconfig.\n\nheat_integrationtests/generate_sample.sh has been replaced by\noslo-config-generator\n--config-file=heat_integrationtests/config-generator.conf\n\nChange-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7\n'}, {'number': 2, 'created': '2014-12-17 13:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7d32e16dbba6177a592ea0cc4ccd498916ee9073', 'message': 'Use oslo.config generator\n\nReplace usage of old incubator configuration generator by the\noslo.config tool.\n\ntools/config/generate_sample.sh has been replaced by tox -egenconfig.\n\nheat_integrationtests/generate_sample.sh has been replaced by\noslo-config-generator\n--config-file=heat_integrationtests/config-generator.conf\n\nChange-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7\n'}, {'number': 3, 'created': '2014-12-19 21:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e349acadf87628dbe6e52215eb0d37a0d3d6e32', 'message': 'Use oslo.config generator\n\nReplace usage of old incubator configuration generator by the\noslo.config tool.\n\ntools/config/generate_sample.sh has been replaced by tox -egenconfig.\n\nheat_integrationtests/generate_sample.sh has been replaced by\noslo-config-generator\n--config-file=heat_integrationtests/config-generator.conf\n\nChange-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7\n'}, {'number': 4, 'created': '2014-12-25 16:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed9e39526a340c96f0954b16064449a3fb4278d9', 'message': 'Use oslo.config generator\n\nReplace usage of old incubator configuration generator by the\noslo.config tool.\n\ntools/config/generate_sample.sh has been replaced by tox -egenconfig.\n\nheat_integrationtests/generate_sample.sh has been replaced by\noslo-config-generator\n--config-file=heat_integrationtests/config-generator.conf\n\nChange-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7\n'}, {'number': 5, 'created': '2014-12-31 12:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e0b05260ae1b6aaa5f61bd4741e779853847775f', 'message': 'Use oslo.config generator\n\nReplace usage of old incubator configuration generator by the\noslo.config tool.\n\ntools/config/generate_sample.sh has been replaced by tox -egenconfig.\n\nheat_integrationtests/generate_sample.sh has been replaced by\noslo-config-generator\n--config-file=heat_integrationtests/config-generator.conf\n\nChange-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7\n'}, {'number': 6, 'created': '2015-01-02 12:14:50.000000000', 'files': ['heat/openstack/common/importutils.py', 'heat/openstack/common/config/__init__.py', 'heat/common/crypt.py', 'heat/engine/resources/__init__.py', 'heat_integrationtests/generate_sample.sh', 'tools/config/generate_sample.sh', 'heat_integrationtests/common/config.py', 'tools/config/oslo.config.generator.rc', 'heat_integrationtests/heat_integrationtests.conf.sample', 'heat/engine/notification/__init__.py', 'heat/api/aws/ec2token.py', 'heat/api/middleware/ssl.py', 'heat/openstack/common/config/generator.py', 'config-generator.conf', 'heat/common/heat_keystoneclient.py', 'openstack-common.conf', 'setup.cfg', 'tox.ini', 'heat/engine/clients/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ec6ff6f670a333ff3b3867e784a9c324b9a891ff', 'message': 'Use oslo.config generator\n\nReplace usage of old incubator configuration generator by the\noslo.config tool.\n\ntools/config/generate_sample.sh has been replaced by tox -egenconfig.\n\nheat_integrationtests/generate_sample.sh has been replaced by\noslo-config-generator\n--config-file=heat_integrationtests/config-generator.conf\n\nChange-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7\n'}]",0,142418,ec6ff6f670a333ff3b3867e784a9c324b9a891ff,50,10,6,7385,,,0,"Use oslo.config generator

Replace usage of old incubator configuration generator by the
oslo.config tool.

tools/config/generate_sample.sh has been replaced by tox -egenconfig.

heat_integrationtests/generate_sample.sh has been replaced by
oslo-config-generator
--config-file=heat_integrationtests/config-generator.conf

Change-Id: I6d95df203b556c8ec2088d40a446427f7087b9a7
",git fetch https://review.opendev.org/openstack/heat refs/changes/18/142418/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/config/__init__.py', 'heat/common/wsgi.py', 'heat_integrationtests/generate_sample.sh', 'tools/config/generate_sample.sh', 'heat_integrationtests/common/config.py', 'tools/config/oslo.config.generator.rc', 'heat_integrationtests/heat_integrationtests.conf.sample', 'heat/openstack/common/config/generator.py', 'config-generator.conf', 'openstack-common.conf', 'setup.cfg', 'tox.ini', 'heat/common/config.py']",13,7b4407cc1efd3ba067bda8783bbd33f4bb7cdcd2,oslo-config-generator," from heat.engine.resources import loadbalancer yield None, loadbalancer.loadbalancer_opts from heat.common import crypt yield None, crypt.auth_opts from heat.common import heat_keystoneclient yield None, heat_keystoneclient.keystone_opts from heat.engine import clients yield None, clients.cloud_opts from heat.engine import notification yield None, notification.notifier_opts",,79,547
openstack%2Fheat~master~Ib67c55f010613c8edb913bb264d3cc4a7315d847,openstack/heat,master,Ib67c55f010613c8edb913bb264d3cc4a7315d847,Gracefully fail to delete nonempty S3 Bucket,MERGED,2015-01-02 17:23:06.000000000,2015-01-06 13:53:32.000000000,2015-01-06 13:53:31.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-02 17:23:06.000000000', 'files': ['heat/engine/resources/s3.py', 'heat/tests/test_s3.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3eda66271314c327668272f902e0cafe9e4f1428', 'message': 'Gracefully fail to delete nonempty S3 Bucket\n\nThe AWS::S3::Bucket resource is susceptible to bug #1406263\nas it is backed by the same Swift container - on deleting non empty\ncontainer it produces incomprehensible truncated message.\n\nThis patch uses the same logic as it is now in OS::Swift::Container\nresource, making the reason of failure clear. The error message is made\nto resemble the error produced by this resource on real AWS\nin the same usage scenario.\n\nChange-Id: Ib67c55f010613c8edb913bb264d3cc4a7315d847\nRelated-Bug: #1406263\n'}]",0,144779,3eda66271314c327668272f902e0cafe9e4f1428,14,5,1,9542,,,0,"Gracefully fail to delete nonempty S3 Bucket

The AWS::S3::Bucket resource is susceptible to bug #1406263
as it is backed by the same Swift container - on deleting non empty
container it produces incomprehensible truncated message.

This patch uses the same logic as it is now in OS::Swift::Container
resource, making the reason of failure clear. The error message is made
to resemble the error produced by this resource on real AWS
in the same usage scenario.

Change-Id: Ib67c55f010613c8edb913bb264d3cc4a7315d847
Related-Bug: #1406263
",git fetch https://review.opendev.org/openstack/heat refs/changes/79/144779/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/s3.py', 'heat/tests/test_s3.py']",2,3eda66271314c327668272f902e0cafe9e4f1428,bug/1406263,"import six self.m.StubOutWithMock(sc.Connection, 'get_container') def test_delete_conflict_not_empty(self): container_name = utils.PhysName('test_stack', 'test_resource') sc.Connection.put_container( container_name, {'X-Container-Write': 'test_tenant:test_username', 'X-Container-Read': 'test_tenant:test_username'}).AndReturn(None) sc.Connection.delete_container(container_name).AndRaise( sc.ClientException('Not empty', http_status=409)) sc.Connection.get_container(container_name).AndReturn( ({'name': container_name}, [{'name': 'test_object'}])) self.m.ReplayAll() t = template_format.parse(swift_template) stack = utils.parse_stack(t) rsrc = self.create_resource(t, stack, 'S3Bucket') deleter = scheduler.TaskRunner(rsrc.delete) ex = self.assertRaises(exception.ResourceFailure, deleter) self.assertIn(""ResourceActionNotSupported: The bucket "" ""you tried to delete is not empty"", six.text_type(ex)) self.m.VerifyAll() def test_delete_conflict_empty(self): container_name = utils.PhysName('test_stack', 'test_resource') sc.Connection.put_container( container_name, {'X-Container-Write': 'test_tenant:test_username', 'X-Container-Read': 'test_tenant:test_username'}).AndReturn(None) sc.Connection.delete_container(container_name).AndRaise( sc.ClientException('Conflict', http_status=409)) sc.Connection.get_container(container_name).AndReturn( ({'name': container_name}, [])) self.m.ReplayAll() t = template_format.parse(swift_template) stack = utils.parse_stack(t) rsrc = self.create_resource(t, stack, 'S3Bucket') deleter = scheduler.TaskRunner(rsrc.delete) ex = self.assertRaises(exception.ResourceFailure, deleter) self.assertIn(""Conflict"", six.text_type(ex)) self.m.VerifyAll() ",,52,1
openstack%2Fneutron~master~I2287e5348aab82e39cf1b6e2884d08237a09b06d,openstack/neutron,master,I2287e5348aab82e39cf1b6e2884d08237a09b06d,Fix neutron hang for IPv6 allocation pool update,MERGED,2014-12-15 11:15:14.000000000,2015-01-06 13:53:06.000000000,2015-01-06 13:53:04.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6671}, {'_account_id': 6685}, {'_account_id': 7183}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10370}, {'_account_id': 10692}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-15 11:15:14.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b38f1bfa7b4f662182f552530b43301b214baa8d', 'message': 'Fix neutron hang for IPv6 allocation pool update\n\nWhile rebuilding IPAllocationPools, Neutron is using netaddr.iter_iprange\n(a generator that produces IPAddress objects). For an IPv6 subnet, this is\na costly operation and is causing Neutron Server to hang. This patch\naddresses the issue by replacing netaddr.iter_iprange with netaddr.IPRange\nwhich provides the same functionality while calculating the IPSets.\n\nCloses-Bug: #1401751\nChange-Id: I2287e5348aab82e39cf1b6e2884d08237a09b06d\n'}]",0,141770,b38f1bfa7b4f662182f552530b43301b214baa8d,54,34,1,10257,,,0,"Fix neutron hang for IPv6 allocation pool update

While rebuilding IPAllocationPools, Neutron is using netaddr.iter_iprange
(a generator that produces IPAddress objects). For an IPv6 subnet, this is
a costly operation and is causing Neutron Server to hang. This patch
addresses the issue by replacing netaddr.iter_iprange with netaddr.IPRange
which provides the same functionality while calculating the IPSets.

Closes-Bug: #1401751
Change-Id: I2287e5348aab82e39cf1b6e2884d08237a09b06d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/141770/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py']",2,b38f1bfa7b4f662182f552530b43301b214baa8d,bug/1401751," poolset = netaddr.IPSet(netaddr.IPRange(pool['first_ip'], pool['last_ip']))"," poolset = netaddr.IPSet(netaddr.iter_iprange(pool['first_ip'], pool['last_ip']))",58,22
openstack%2Fneutron~master~Ibde56a2eb32eed468defdd02a44cc3360ce82e53,openstack/neutron,master,Ibde56a2eb32eed468defdd02a44cc3360ce82e53,Removed spurious check for ip version,MERGED,2014-12-16 17:47:00.000000000,2015-01-06 13:52:51.000000000,2015-01-06 13:52:49.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 1561}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-16 17:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7d8cce13e55791486ee69bbfbcebf369dd05f07', 'message': 'Removed spurious check for ip version\n\nWe may assume that _add_ingress_ra_rule() receives only RA (=IPv6)\nports, so no need to check IP version one more time.\n\nThe corresponding IP version filter is already applied in\n_select_ra_ips_for_network_ids().\n\nChange-Id: Ibde56a2eb32eed468defdd02a44cc3360ce82e53\n'}, {'number': 2, 'created': '2015-01-05 11:22:05.000000000', 'files': ['neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ffa793b27c4370876dabf64e8b6ab79a73302b19', 'message': 'Removed spurious check for ip version\n\nWe may assume that _add_ingress_ra_rule() receives only RA (=IPv6)\nports, so no need to check IP version one more time.\n\nThe corresponding IP version filter is already applied in\n_select_ra_ips_for_network_ids().\n\nChange-Id: Ibde56a2eb32eed468defdd02a44cc3360ce82e53\n'}]",0,142168,ffa793b27c4370876dabf64e8b6ab79a73302b19,57,28,2,9656,,,0,"Removed spurious check for ip version

We may assume that _add_ingress_ra_rule() receives only RA (=IPv6)
ports, so no need to check IP version one more time.

The corresponding IP version filter is already applied in
_select_ra_ips_for_network_ids().

Change-Id: Ibde56a2eb32eed468defdd02a44cc3360ce82e53
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/142168/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_rpc_base.py'],1,a7d8cce13e55791486ee69bbfbcebf369dd05f07,ra-rules-not-set,, if not netaddr.IPAddress(ra_ip).version == 6: return ,0,3
openstack%2Fdevstack-gate~master~Ib539ef5eab697fee642eb0be42f2ff4b41c95687,openstack/devstack-gate,master,Ib539ef5eab697fee642eb0be42f2ff4b41c95687,Add a new hook for gathering extra logs,ABANDONED,2015-01-05 22:50:43.000000000,2015-01-06 13:23:01.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6133}]","[{'number': 1, 'created': '2015-01-05 22:50:43.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/660dc39af66f82264f0ff9d2a64070cdb29e7828', 'message': 'Add a new hook for gathering extra logs\n\npost_test_hook is only run when $GATE_RETVAL is 0, so when\nthe gate_hook fails, we need another hook similar to post_test_hook\nwhich can be used to gather logs. There are 32 existing post_test_hook(s)\ncurrently and it would be impossible to predict their behavior if\nwe try to reuse the post_test_hook by ignoring GATE_RETVAL as was done\nin Id9a6aa72a8dee69cf1e73789281fd63385cfe12c\n\nChange-Id: Ib539ef5eab697fee642eb0be42f2ff4b41c95687\n'}]",0,145079,660dc39af66f82264f0ff9d2a64070cdb29e7828,6,3,1,5638,,,0,"Add a new hook for gathering extra logs

post_test_hook is only run when $GATE_RETVAL is 0, so when
the gate_hook fails, we need another hook similar to post_test_hook
which can be used to gather logs. There are 32 existing post_test_hook(s)
currently and it would be impossible to predict their behavior if
we try to reuse the post_test_hook by ignoring GATE_RETVAL as was done
in Id9a6aa72a8dee69cf1e73789281fd63385cfe12c

Change-Id: Ib539ef5eab697fee642eb0be42f2ff4b41c95687
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/79/145079/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,660dc39af66f82264f0ff9d2a64070cdb29e7828,,"# Run gather extra logs hook if we have one if function_exists ""gather_extra_logs_hook""; then echo ""Running gather_extra_logs_hook"" xtrace=$(set +o | grep xtrace) set -o xtrace tsfilter gather_extra_logs_hook | tee $WORKSPACE/devstack-gate-gather-extra-logs-hook.txt sudo mv $WORKSPACE/devstack-gate-gather-extra-logs-hook.txt $BASE/logs/ $xtrace fi ",,10,0
openstack%2Fcinder~master~I2fbbdf2a9d9c97ce511d9dfbbeca8b51e5213c0d,openstack/cinder,master,I2fbbdf2a9d9c97ce511d9dfbbeca8b51e5213c0d,Move 3 Fujitsu ETERNUS DX related file,ABANDONED,2014-12-26 13:08:46.000000000,2015-01-06 13:21:49.000000000,,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9043}, {'_account_id': 10674}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-12-26 13:08:46.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e65dc56dff5e888bedbfa67cda03cf35ce9f98c', 'message': ""Move 3 Fujitsu ETERNUS DX related file\n\nSince there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.volume.drivers,\nI make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.\n\nCloses-Bug #1402349\nhttps://bugs.launchpad.net/cinder/+bug/1402349\n\nChange-Id: I2fbbdf2a9d9c97ce511d9dfbbeca8b51e5213c0d\n""}]",0,144140,4e65dc56dff5e888bedbfa67cda03cf35ce9f98c,13,12,1,10674,,,0,"Move 3 Fujitsu ETERNUS DX related file

Since there are three volume driver files relating to Fujitsu ETERNUS DX in cinder.volume.drivers,
I make 'fujitsu' directory at cinder.volume.drivers and I move these files to the directory.

Closes-Bug #1402349
https://bugs.launchpad.net/cinder/+bug/1402349

Change-Id: I2fbbdf2a9d9c97ce511d9dfbbeca8b51e5213c0d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/40/144140/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,4e65dc56dff5e888bedbfa67cda03cf35ce9f98c,bug/1402349," 'cinder.volume.drivers.huawei.huawei_18000.Huawei18000FCDriver', 'cinder.volume.drivers.fujitsu_eternus_dx_fc.FJDXFCDriver': 'cinder.volume.drivers.fujitsu.fujitsu_eternus_dx_fc.FJDXFCDriver', 'cinder.volume.drivers.fujitsu_eternus_dx_iscsi.FJDXISCSIDriver': 'cinder.volume.drivers.fujitsu.fujitsu_eternus_dx_iscsi.FJDXISCSIDriver', }"," 'cinder.volume.drivers.huawei.huawei_18000.Huawei18000FCDriver', }",5,1
openstack%2Fneutron~master~I09ad929902509018fe7183a15b784601c36b6196,openstack/neutron,master,I09ad929902509018fe7183a15b784601c36b6196,"Enable the ""not-callable"" pylint check",MERGED,2014-12-23 00:48:46.000000000,2015-01-06 13:20:16.000000000,2015-01-06 13:20:14.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-23 00:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/77a54013e58d53e64d3008d9c64ecb3df617ce0b', 'message': 'Enable the ""not-callable"" pylint check\n\nThis change enables the ""not-callable"" pylint check, after disabling a\nfew cases where the alert triggers but the usage was intended (defining\ndecorators).\n\nA real syntax error was also caught in vmware advanced services plugin -\nfixed in a separate change.\n\nChange-Id: I09ad929902509018fe7183a15b784601c36b6196\nRelated-Bug: #1356224\n'}, {'number': 2, 'created': '2014-12-30 01:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae3e8b9ef8821ec1ca4eace553cb3f21f2b6058d', 'message': 'Enable the ""not-callable"" pylint check\n\nThis check catches attempts to call variables that pylint believes are\nnot functions.  A trivial example would be:\n\n    # Trivial example caught by this check:\n    foo = dict()\n    print foo(\'bar\')  # <- oops, meant foo[\'bar\']\n\nThis change enables the ""not-callable"" pylint check, after disabling a\nfew cases where the alert triggers but the usage was intended (defining\ndecorators).\n\nChange-Id: I09ad929902509018fe7183a15b784601c36b6196\nRelated-Bug: #1356224\n'}, {'number': 3, 'created': '2014-12-31 04:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/79d9304ab8698c2e2825b64d1751f8bacbfcf53c', 'message': 'Enable the ""not-callable"" pylint check\n\nThis check catches attempts to call variables that pylint believes are\nnot functions.  A trivial example would be:\n\n    # Trivial example caught by this check:\n    foo = dict()\n    print foo(\'bar\')  # <- oops, meant foo[\'bar\']\n\nThis change enables the ""not-callable"" pylint check, after disabling a\nfew cases where the alert triggers but the usage was intended (defining\ndecorators).\n\nChange-Id: I09ad929902509018fe7183a15b784601c36b6196\nRelated-Bug: #1356224\n'}, {'number': 4, 'created': '2014-12-31 04:34:09.000000000', 'files': ['.pylintrc', 'neutron/agent/securitygroups_rpc.py', 'neutron/plugins/ml2/drivers/cisco/apic/mechanism_apic.py', 'neutron/services/l3_router/l3_apic.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/73c9a5fc7c0ed9758af28e7061428544b2475af0', 'message': 'Enable the ""not-callable"" pylint check\n\nThis check catches attempts to call variables that pylint believes are\nnot functions.  A trivial example would be:\n\n    # Trivial example caught by this check:\n    foo = dict()\n    print foo(\'bar\')  # <- oops, meant foo[\'bar\']\n\nThis change enables the ""not-callable"" pylint check, after disabling a\nfew cases where the alert triggers but the usage was intended (defining\ndecorators).\n\nChange-Id: I09ad929902509018fe7183a15b784601c36b6196\nRelated-Bug: #1356224\n'}]",9,143576,73c9a5fc7c0ed9758af28e7061428544b2475af0,75,22,4,11279,,,0,"Enable the ""not-callable"" pylint check

This check catches attempts to call variables that pylint believes are
not functions.  A trivial example would be:

    # Trivial example caught by this check:
    foo = dict()
    print foo('bar')  # <- oops, meant foo['bar']

This change enables the ""not-callable"" pylint check, after disabling a
few cases where the alert triggers but the usage was intended (defining
decorators).

Change-Id: I09ad929902509018fe7183a15b784601c36b6196
Related-Bug: #1356224
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/143576/2 && git format-patch -1 --stdout FETCH_HEAD,"['.pylintrc', 'neutron/agent/securitygroups_rpc.py', 'neutron/plugins/ml2/drivers/cisco/apic/mechanism_apic.py', 'neutron/services/l3_router/l3_apic.py']",4,77a54013e58d53e64d3008d9c64ecb3df617ce0b,bug/1356224, # pylint: disable=not-callable,,3,1
