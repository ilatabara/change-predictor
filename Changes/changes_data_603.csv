id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fbarbican~master~Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7,openstack/barbican,master,Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7,[WIP] Implement OVO [6],ABANDONED,2017-09-05 15:32:05.000000000,2017-12-14 06:36:45.000000000,,"[{'_account_id': 3}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-05 15:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/adb8aaec91137f1d79ce3a3a97df8cea166ea2f7', 'message': '[WIP] Implemente OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 2, 'created': '2017-09-05 16:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0b9f246145bd08e5a4a5289145a61d71a3c1fa60', 'message': '[WIP] Implemente OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 3, 'created': '2017-09-06 03:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/14f8039652ead9f8fd9d85738c57e877176e4a3b', 'message': '[WIP] Implemente OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 4, 'created': '2017-09-07 06:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/382f270f6e43c97d1d6af440c3a250e47c5210c4', 'message': '[WIP] Implemente OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 5, 'created': '2017-09-07 06:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6228331052fb01dedc949957cf954b17d5d28423', 'message': '[WIP] Implement OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 6, 'created': '2017-09-21 06:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/dff1b3b7e72ceeccb352e4b0cd2e7bfc8d61ca75', 'message': '[WIP] Implement OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 7, 'created': '2017-09-22 10:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/cf4473818002f79e4310393b2efcd83de86c2e44', 'message': '[WIP] Implement OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 8, 'created': '2017-11-27 06:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fd169ff08d7cedd77b36b2425939e8829d8805f0', 'message': '[WIP] Implement OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 9, 'created': '2017-11-27 07:14:18.000000000', 'files': ['barbican/api/controllers/secretmeta.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e600c96dfe4467734f5e03158746bf63285c5e9b', 'message': '[WIP] Implement OVO [6]\n\n- Change api/controllers/secretmeta.py to use OVO instead.\n\nChange-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}]",0,500890,e600c96dfe4467734f5e03158746bf63285c5e9b,16,2,9,19554,,,0,"[WIP] Implement OVO [6]

- Change api/controllers/secretmeta.py to use OVO instead.

Change-Id: Ic59ebb6db16431a3f49fad8c7c29f00c313b44c7
Co-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>
Partial-Implements: blueprint rolling-upgrade
",git fetch https://review.opendev.org/openstack/barbican refs/changes/90/500890/9 && git format-patch -1 --stdout FETCH_HEAD,['barbican/api/controllers/secretmeta.py'],1,adb8aaec91137f1d79ce3a3a97df8cea166ea2f7,bp/rolling-upgrade,"from barbican import objects resp = objects.SecretUserMetadatum.get_metadata_for_secret( self.secret.id) objects.SecretUserMetadatum.create_replace_user_metadata( self.secret.id, data) metadata = objects.SecretUserMetadatum.get_metadata_for_secret( self.secret.id) objects.SecretUserMetadatum.create_replace_user_metadatum( self.secret.id, key, value) metadata = objects.SecretUserMetadatum.get_metadata_for_secret( self.secret.id) metadata = objects.SecretUserMetadatum.get_metadata_for_secret( self.secret.id) objects.SecretUserMetadatum.create_replace_user_metadatum( self.secret.id, key, value) objects.SecretUserMetadatum.delete_metadatum( self.secret.id, remainder)","from barbican.model import repositories as repo self.secret_repo = repo.get_secret_repository() self.user_meta_repo = repo.get_secret_user_meta_repository() resp = self.user_meta_repo.get_metadata_for_secret(self.secret.id) self.user_meta_repo.create_replace_user_metadata(self.secret.id, data) metadata = self.user_meta_repo.get_metadata_for_secret(self.secret.id) self.user_meta_repo.create_replace_user_metadatum(self.secret.id, key, value) self.user_meta_repo = repo.get_secret_user_meta_repository() metadata = self.user_meta_repo.get_metadata_for_secret(self.secret.id) metadata = self.user_meta_repo.get_metadata_for_secret(self.secret.id) self.user_meta_repo.create_replace_user_metadatum(self.secret.id, key, value) self.user_meta_repo.delete_metadatum(self.secret.id, remainder)",17,17
openstack%2Fbarbican~master~I8fce8c378a616629c7ff712fab56baf3c7da52b8,openstack/barbican,master,I8fce8c378a616629c7ff712fab56baf3c7da52b8,[WIP] Implement OVO [7],ABANDONED,2017-09-05 15:41:55.000000000,2017-12-14 06:36:36.000000000,,"[{'_account_id': 3}, {'_account_id': 19741}, {'_account_id': 22348}, {'_account_id': 22406}]","[{'number': 1, 'created': '2017-09-05 15:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e8f84cac689a48ff59f33832880429de69bd227b', 'message': '[WIP] Implemente OVO [6]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 2, 'created': '2017-09-05 15:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d8ccbf9f9cdd34c4706244dc253d38aa7d498294', 'message': '[WIP] Implemente OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 3, 'created': '2017-09-05 15:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7611943cc0414c0c17f9f9ef15b9b885e66960e8', 'message': '[WIP] Implemente OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 4, 'created': '2017-09-05 16:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/bf5757040a14804b3894c0386f2bd1eaa25b830d', 'message': '[WIP] Implemente OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 5, 'created': '2017-09-06 03:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/90f727013b3491632f02ceeaccb975c29565cfe3', 'message': '[WIP] Implemente OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 6, 'created': '2017-09-07 07:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/605a3756e10bdf33861db871996f984c1dfb835f', 'message': '[WIP] Implemente OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 7, 'created': '2017-09-07 07:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e00b883781484a4cbaf4b134d7ba4e3fb13bccbd', 'message': '[WIP] Implement OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 8, 'created': '2017-09-21 06:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/912deed64071223a1d2dc02a8dca1ff5c0b5cf44', 'message': '[WIP] Implement OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 9, 'created': '2017-09-22 10:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/cc1d66ff3c5f11149c273686a71fcd6c23370555', 'message': '[WIP] Implement OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 10, 'created': '2017-11-27 06:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4834edb875f3a1ce9b6519f0f76f88023d35adf7', 'message': '[WIP] Implement OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}, {'number': 11, 'created': '2017-11-27 07:14:31.000000000', 'files': ['barbican/common/quota.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e449010c75bb4d0fb54897de53c7f2ae5e513822', 'message': '[WIP] Implement OVO [7]\n\n- Change api/controllers/quotas.py to use OVO instead.\n\nChange-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8\nCo-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>\nPartial-Implements: blueprint rolling-upgrade\n'}]",0,500896,e449010c75bb4d0fb54897de53c7f2ae5e513822,18,4,11,19554,,,0,"[WIP] Implement OVO [7]

- Change api/controllers/quotas.py to use OVO instead.

Change-Id: I8fce8c378a616629c7ff712fab56baf3c7da52b8
Co-Authored-By: Kien Nguyen <kiennt@vn.fujitsu.com>
Partial-Implements: blueprint rolling-upgrade
",git fetch https://review.opendev.org/openstack/barbican refs/changes/96/500896/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/objects/project_quotas.py', 'barbican/objects/__init__.py', 'barbican/common/quota.py']",3,e8f84cac689a48ff59f33832880429de69bd227b,bp/rolling-upgrade,from barbican import objects self.repo = objects.ProjectQuotas(), self.repo = repo.get_project_quotas_repository(),111,1
openstack%2Fproject-config~master~Id6efface74405dedc2096c30545df4cb2c1cc256,openstack/project-config,master,Id6efface74405dedc2096c30545df4cb2c1cc256,Add stable/jewel to IRC bot,MERGED,2017-12-13 21:08:26.000000000,2017-12-14 06:28:11.000000000,2017-12-14 06:28:11.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 21:08:26.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/094fcbd35bdcb862e243a4316bf2ae2f15c752e9', 'message': 'Add stable/jewel to IRC bot\n\nWe want notifications on puppet-ceph stable/jewel patches.\n\nChange-Id: Id6efface74405dedc2096c30545df4cb2c1cc256\n'}]",0,527785,094fcbd35bdcb862e243a4316bf2ae2f15c752e9,8,4,1,3153,,,0,"Add stable/jewel to IRC bot

We want notifications on puppet-ceph stable/jewel patches.

Change-Id: Id6efface74405dedc2096c30545df4cb2c1cc256
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/527785/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,094fcbd35bdcb862e243a4316bf2ae2f15c752e9,irc/puppet-ceph, - stable/jewel,,1,0
openstack%2Fzaqar~master~I32f27e9e6faefcba688467bbc1b87ce253cd74b0,openstack/zaqar,master,I32f27e9e6faefcba688467bbc1b87ce253cd74b0,Support delayed queues for swift,MERGED,2017-10-18 08:37:10.000000000,2017-12-14 06:24:09.000000000,2017-12-14 06:24:09.000000000,"[{'_account_id': 6484}, {'_account_id': 15054}, {'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}]","[{'number': 1, 'created': '2017-10-18 08:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4477b99418d8bfe436d3ae6189a50a545628b85e', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 2, 'created': '2017-10-18 10:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/da8ac574efd33d39571c23b57f031f37f45160b9', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 3, 'created': '2017-10-18 11:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/17e8f9ab3c551c0a9f85140145c294084587ab91', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 4, 'created': '2017-10-19 06:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c7e0ebeed937d27c8fca7b14e8e9e048133dbbe4', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 5, 'created': '2017-10-19 07:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/03cae7b0b80c5c554d7bc73d5e11df2b1d0bc860', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 6, 'created': '2017-10-19 12:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f859162c46e144897fe63933d46338fed07ef1aa', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 7, 'created': '2017-10-20 02:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4d1d033e75a3f0f0f38d4921b53810baf498da07', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 8, 'created': '2017-10-20 04:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/288dca66bde458d30d070880d3feef6e818e6f38', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 9, 'created': '2017-10-20 07:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ea6ca27c64c170ab862fbaf030e4551de0bcc927', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 10, 'created': '2017-10-20 16:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/52dce5f452085eeb5ce46575f349f33e4529d2af', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 11, 'created': '2017-10-21 04:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/76ece1dca84b86497fa291a733ccdabcbadb7513', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 12, 'created': '2017-10-23 02:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1e6b4f2ba80b89f32337375137b526cddd55bf80', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 13, 'created': '2017-10-27 08:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3a46b25ae0972861fcb8fb20b78c14ac482306e3', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 14, 'created': '2017-10-28 08:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4761ea46ac59d8be18116a44bb85dfe84c9d938b', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 15, 'created': '2017-11-02 07:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f5bcbc368922a704365854427b8192ab044b5699', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 16, 'created': '2017-11-10 07:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f96d18ec600223ff9a63b1b778ec96e76e645016', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 17, 'created': '2017-11-17 10:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/47546f116db6f82a70ddea7cfd39cade83efc4a3', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}, {'number': 18, 'created': '2017-12-04 01:51:17.000000000', 'files': ['zaqar/storage/swift/messages.py', 'zaqar/storage/swift/claims.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bde1f5cd6a1bf9715ecc46e3546fab7d6226258e', 'message': 'Support delayed queues for swift\n\nImplement blueprint delayed-queues\n\nChange-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0\n'}]",0,512970,bde1f5cd6a1bf9715ecc46e3546fab7d6226258e,45,5,18,14203,,,0,"Support delayed queues for swift

Implement blueprint delayed-queues

Change-Id: I32f27e9e6faefcba688467bbc1b87ce253cd74b0
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/70/512970/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/swift/messages.py', 'zaqar/storage/swift/claims.py']",2,4477b99418d8bfe436d3ae6189a50a545628b85e,bp/delayed-queues," include_claimed=False, include_delayed=False)", include_claimed=False),15,5
openstack%2Fwatcher~master~I877d5886259e482089ed0f9944d97bb99f375824,openstack/watcher,master,I877d5886259e482089ed0f9944d97bb99f375824,'get_volume_type_by_backendname' returns a list,MERGED,2017-11-27 07:29:46.000000000,2017-12-14 06:18:04.000000000,2017-12-14 06:18:03.000000000,"[{'_account_id': 5477}, {'_account_id': 13111}, {'_account_id': 19457}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 24501}]","[{'number': 1, 'created': '2017-11-27 07:29:46.000000000', 'files': ['watcher/tests/decision_engine/model/notification/test_cinder_notifications.py', 'watcher/tests/common/test_cinder_helper.py', 'watcher/tests/decision_engine/model/test_element.py', 'watcher/decision_engine/model/element/node.py', 'watcher/tests/decision_engine/model/faker_cluster_state.py', 'watcher/common/cinder_helper.py', 'watcher/decision_engine/model/model_root.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/fa31341bbb1b4f9077eab89600e9be006a58b921', 'message': ""'get_volume_type_by_backendname' returns a list\n\nStorage pool can have many volume types,\n'get_volume_type_by_backendname' should return a list of types.\n\nCloses-Bug: #1733257\nChange-Id: I877d5886259e482089ed0f9944d97bb99f375824\n""}]",0,523040,fa31341bbb1b4f9077eab89600e9be006a58b921,9,6,1,21692,,,0,"'get_volume_type_by_backendname' returns a list

Storage pool can have many volume types,
'get_volume_type_by_backendname' should return a list of types.

Closes-Bug: #1733257
Change-Id: I877d5886259e482089ed0f9944d97bb99f375824
",git fetch https://review.opendev.org/openstack/watcher refs/changes/40/523040/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/decision_engine/model/notification/test_cinder_notifications.py', 'watcher/tests/common/test_cinder_helper.py', 'watcher/tests/decision_engine/model/test_element.py', 'watcher/decision_engine/model/element/node.py', 'watcher/tests/decision_engine/model/faker_cluster_state.py', 'watcher/common/cinder_helper.py', 'watcher/decision_engine/model/model_root.py']",7,fa31341bbb1b4f9077eab89600e9be006a58b921,bug/1733257," ndata = {} for attr, val in cn.items(): ndata[attr] = val volume_type = ndata.get('volume_type') if volume_type: ndata['volume_type'] = [volume_type] node = element.StorageNode(**ndata)", node = element.StorageNode(**cn.attrib),19,15
openstack%2Floci~master~Id12e1a19c6c98bbd3a2a477cb76fe92427c05d1d,openstack/loci,master,Id12e1a19c6c98bbd3a2a477cb76fe92427c05d1d,Build PYPI_PACKAGES in requirements,ABANDONED,2017-12-01 23:56:51.000000000,2017-12-14 05:42:08.000000000,,"[{'_account_id': 14119}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-01 23:56:51.000000000', 'files': ['scripts/requirements.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/9922c8aa343e9fc84f919f9d684f3a81db5dd964', 'message': 'Build PYPI_PACKAGES in requirements\n\nChange-Id: Id12e1a19c6c98bbd3a2a477cb76fe92427c05d1d\n'}]",0,524769,9922c8aa343e9fc84f919f9d684f3a81db5dd964,4,2,1,14119,,,0,"Build PYPI_PACKAGES in requirements

Change-Id: Id12e1a19c6c98bbd3a2a477cb76fe92427c05d1d
",git fetch https://review.opendev.org/openstack/loci refs/changes/69/524769/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/requirements.sh'],1,9922c8aa343e9fc84f919f9d684f3a81db5dd964,build_additional_packages,# NOTE(SamYaple): Handle packages not in upper-constriants additional_packages=(git+https://github.com/openstack-infra/bindep@24427065c5f30047ac80370be0a390e7f417ce34 uwsgi) echo ${PYPI_PACKAGES} ${additional_packages} | xargs -n1 | split -l1 -a 4,"# NOTE(SamYaple): Handle packages not in upper-constriants and not in PyPI as # native whls additional_packages=(git+https://github.com/openstack-infra/bindep@24427065c5f30047ac80370be0a390e7f417ce34 uwsgi) echo ""${additional_packages[@]}"" | xargs -n1 -P20 pip wheel --wheel-dir / -c /upper-constraints.txt | tee -a /tmp/wheels.txt",4,4
openstack%2Frpm-packaging~master~Ia34ef579822aa274e18550928dc7c309c482c386,openstack/rpm-packaging,master,Ia34ef579822aa274e18550928dc7c309c482c386,Update castellan to 0.16.0,MERGED,2017-12-04 14:13:33.000000000,2017-12-14 05:40:11.000000000,2017-12-14 05:40:11.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-04 14:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e1c55df58cd184dbbeffdc4143f2545eabaa62cb', 'message': 'Update castellan to 0.16.0\n\nDepends-on: Idcd85d09c3adb4fae9ad8a37cc52fe225bd74540\nChange-Id: Ia34ef579822aa274e18550928dc7c309c482c386\n'}, {'number': 2, 'created': '2017-12-11 06:53:41.000000000', 'files': ['openstack/castellan/castellan.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b1fce4c07b1d34b7024faaebe7c774e0183de0d0', 'message': 'Update castellan to 0.16.0\n\nDepends-on: Idcd85d09c3adb4fae9ad8a37cc52fe225bd74540\nChange-Id: Ia34ef579822aa274e18550928dc7c309c482c386\n'}]",0,525207,b1fce4c07b1d34b7024faaebe7c774e0183de0d0,15,5,2,17130,,,0,"Update castellan to 0.16.0

Depends-on: Idcd85d09c3adb4fae9ad8a37cc52fe225bd74540
Change-Id: Ia34ef579822aa274e18550928dc7c309c482c386
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/07/525207/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/castellan/castellan.spec.j2'],1,e1c55df58cd184dbbeffdc4143f2545eabaa62cb,update-castellan,Version: 0.16.0,Version: 0.15.1,1,1
openstack%2Fwatcher~master~I1599a86a2ba7d3af755fb1412a5e38516c736957,openstack/watcher,master,I1599a86a2ba7d3af755fb1412a5e38516c736957,Fix 'unable to exclude instance',MERGED,2017-12-08 06:20:54.000000000,2017-12-14 05:38:34.000000000,2017-12-14 05:38:34.000000000,"[{'_account_id': 13111}, {'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 24501}]","[{'number': 1, 'created': '2017-12-08 06:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/34cd7f7d9e71e109cb06b651c8e500ad166d7773', 'message': ""Fix 'unable to exclude instance'\n\nChange-Id: I1599a86a2ba7d3af755fb1412a5e38516c736957\nCloses-Bug: #1736129\n""}, {'number': 2, 'created': '2017-12-08 06:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/896c1ea47e7632538e90b3aa01eb2babd619083f', 'message': ""Fix 'unable to exclude instance'\n\nChange-Id: I1599a86a2ba7d3af755fb1412a5e38516c736957\nCloses-Bug: #1736129\n""}, {'number': 3, 'created': '2017-12-12 10:29:38.000000000', 'files': ['watcher/tests/decision_engine/scope/fake_scopes.py', 'watcher/decision_engine/scope/compute.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/be56441e555e457777ab5c6edb59791644ceb52b', 'message': ""Fix 'unable to exclude instance'\n\nChange-Id: I1599a86a2ba7d3af755fb1412a5e38516c736957\nCloses-Bug: #1736129\n""}]",2,526601,be56441e555e457777ab5c6edb59791644ceb52b,17,6,3,19457,,,0,"Fix 'unable to exclude instance'

Change-Id: I1599a86a2ba7d3af755fb1412a5e38516c736957
Closes-Bug: #1736129
",git fetch https://review.opendev.org/openstack/watcher refs/changes/01/526601/2 && git format-patch -1 --stdout FETCH_HEAD,['watcher/decision_engine/scope/compute.py'],1,34cd7f7d9e71e109cb06b651c8e500ad166d7773,bug/1736129, compute_scope = [] for scope in self.scope: compute_scope = scope.get('compute') if not compute_scope: for rule in compute_scope:, if not self.scope: for rule in self.scope:,7,3
openstack%2Fopenstack-helm-infra~master~I617c18b0c7cda8947d415dc5c4a29936fd925f14,openstack/openstack-helm-infra,master,I617c18b0c7cda8947d415dc5c4a29936fd925f14,[WIP] Adding job to cleanup RBAC remnants,ABANDONED,2017-12-02 15:39:20.000000000,2017-12-14 04:35:24.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-02 15:39:20.000000000', 'files': ['helm-toolkit/templates/snippets/_kubernetes_rbac_cleanup.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1a0fbe53723ccd333d5310f4a2e807c20f562e6b', 'message': '[WIP] Adding job to cleanup RBAC remnants\n\nThis patch set adds in a helm-toolkit snippet to clean up any\nRBAC-related artifacts when the helm chart is deleted.\n\nChange-Id: I617c18b0c7cda8947d415dc5c4a29936fd925f14\n'}]",0,524880,1a0fbe53723ccd333d5310f4a2e807c20f562e6b,3,1,1,20466,,,0,"[WIP] Adding job to cleanup RBAC remnants

This patch set adds in a helm-toolkit snippet to clean up any
RBAC-related artifacts when the helm chart is deleted.

Change-Id: I617c18b0c7cda8947d415dc5c4a29936fd925f14
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/80/524880/1 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/snippets/_kubernetes_rbac_cleanup.tpl'],1,1a0fbe53723ccd333d5310f4a2e807c20f562e6b,rbac-cleanup,"{{/* Copyright 2017 The Openstack-Helm Authors. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} {{- define ""helm-toolkit.snippets.kubernetes_rbac_cleanup"" -}} {{- $envAll := index . 0 -}} {{- $image := index . 1 -}} {{- $component := $envAll.Release.Name -}} {{- $imageTag := index $envAll.Values.images.tags $image -}} --- apiVersion: batch/v1 kind: Job metadata: name: {{ $component }}-rbac-cleanup labels: release: {{ $component | quote }} annotations: helm.sh/hook: pre-delete helm.sh/hook-delete-policy: hook-succeeded spec: template: metadata: name: {{ $componet }}-rbac-cleanup labels: release: {{ $component | quote }} spec: restartPolicy: OnFailure containers: - name: rbac-serviceaccount-cleanup image: {{ $imageTag | quote }} restartPolicy: OnFailure command: - ./kubectl - delete - serviceaccount - --ignore-not-found=true - service-account-entrypoint-{{ $component }} - name: rbac-secret-cleanup image: {{ $imageTag | quote }} restartPolicy: OnFailure command: - ./kubectl - delete - secret - --ignore-not-found=true - secret-entrypoint-{{ $component }} - name: rbac-clusterrole-cleanup image: {{ $imageTag | quote }} restartPolicy: OnFailure command: - ./kubectl - delete - clusterrole - --ignore-not-found=true - cluster-role-entrypoint-{{ $component }} - name: rbac-role-cleanup image: {{ $imageTag | quote }} restartPolicy: OnFailure command: - ./kubectl - delete - role - --ignore-not-found=true - role-entrypoint-{{ $component }} - name: rbac-clusterrolebinding-cleanup image: {{ $imageTag | quote }} restartPolicy: OnFailure command: - ./kubectl - delete - clusterrolebinding - --ignore-not-found=true - cluster-role-binding-entrypoint-{{ $component }} {{- end -}} ",,86,0
openstack%2Fcongress~master~Id9a05a4dcb694b42bf68295bab655435b177f4d1,openstack/congress,master,Id9a05a4dcb694b42bf68295bab655435b177f4d1,Replace LOG.warn with LOG.warning,ABANDONED,2017-12-08 04:27:49.000000000,2017-12-14 04:31:32.000000000,,"[{'_account_id': 11278}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 04:27:49.000000000', 'files': ['thirdparty/antlr3-antlr-3.5/runtime/Python/setup.py', 'thirdparty/antlr3-antlr-3.5/runtime/Python3/ez_setup.py', 'thirdparty/antlr3-antlr-3.5/runtime/Python3/setup.py', 'thirdparty/antlr3-antlr-3.5/runtime/Python/ez_setup.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/33cef79a93f62afdc40f78bab3bc6e8feb1f9e1d', 'message': 'Replace LOG.warn with LOG.warning\n\nlogging.warn is deprecated in Python 3 [1].\n\n[1] https://docs.python.org/3/library/logging.html#logging.warning\n\nChange-Id: Id9a05a4dcb694b42bf68295bab655435b177f4d1\n'}]",0,526593,33cef79a93f62afdc40f78bab3bc6e8feb1f9e1d,4,2,1,25695,,,0,"Replace LOG.warn with LOG.warning

logging.warn is deprecated in Python 3 [1].

[1] https://docs.python.org/3/library/logging.html#logging.warning

Change-Id: Id9a05a4dcb694b42bf68295bab655435b177f4d1
",git fetch https://review.opendev.org/openstack/congress refs/changes/93/526593/1 && git format-patch -1 --stdout FETCH_HEAD,"['thirdparty/antlr3-antlr-3.5/runtime/Python/setup.py', 'thirdparty/antlr3-antlr-3.5/runtime/Python3/ez_setup.py', 'thirdparty/antlr3-antlr-3.5/runtime/Python3/setup.py', 'thirdparty/antlr3-antlr-3.5/runtime/Python/ez_setup.py']",4,33cef79a93f62afdc40f78bab3bc6e8feb1f9e1d,," log.warning("""""" log.warning(""Downloading %s"", url)"," log.warn("""""" log.warn(""Downloading %s"", url)",40,40
openstack%2Frequirements~master~Id457f8bf302f15ad082ab8381c1ccd894352f8aa,openstack/requirements,master,Id457f8bf302f15ad082ab8381c1ccd894352f8aa,Update protobuf 3.5.0 to post1,ABANDONED,2017-11-23 00:51:20.000000000,2017-12-14 04:27:43.000000000,,"[{'_account_id': 2243}, {'_account_id': 2417}, {'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 9003}, {'_account_id': 12898}, {'_account_id': 13252}, {'_account_id': 13404}, {'_account_id': 14288}, {'_account_id': 14885}, {'_account_id': 16258}, {'_account_id': 17920}, {'_account_id': 20035}, {'_account_id': 22348}, {'_account_id': 23630}, {'_account_id': 26310}]","[{'number': 1, 'created': '2017-11-23 00:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/921dbc7360aade4f51c6809869d4cdc77744b8d6', 'message': ""Update protobuf 3.5.0 to post1\n\nNoticed stack failures due to protobuf==3.5.0 not found.  It seems\nthere was a problem with the package and it no longer exists on\npypi.\n\nThere's a post1 version up, and modifying constraints to point to\nthat instead seems to fix up the issue.\n\nChange-Id: Id457f8bf302f15ad082ab8381c1ccd894352f8aa\n""}, {'number': 2, 'created': '2017-11-23 13:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c9e5d4f07e801f42c9def80c693af76444ed5acb', 'message': ""Update protobuf 3.5.0 to post1\n\nNoticed stack failures due to protobuf==3.5.0 not found.  It seems\nthere was a problem with the package and it no longer exists on\npypi.\n\nThere's a post1 version up, and modifying constraints to point to\nthat instead seems to fix up the issue.\n\nCloses-Bug: #1734009\n\nChange-Id: Id457f8bf302f15ad082ab8381c1ccd894352f8aa\n""}, {'number': 3, 'created': '2017-11-23 18:45:22.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/85105f6c35613d9e7703840b635cb236c0da242a', 'message': ""Update protobuf 3.5.0 to post1\n\nNoticed stack failures due to protobuf==3.5.0 not found.  It seems\nthere was a problem with the package and it no longer exists on\npypi.\n\nThere's a post1 version up, and modifying constraints to point to\nthat instead seems to fix up the issue.\n\nCloses-Bug: #1734009\n\nChange-Id: Id457f8bf302f15ad082ab8381c1ccd894352f8aa\n""}]",0,522412,85105f6c35613d9e7703840b635cb236c0da242a,29,16,3,2243,,,0,"Update protobuf 3.5.0 to post1

Noticed stack failures due to protobuf==3.5.0 not found.  It seems
there was a problem with the package and it no longer exists on
pypi.

There's a post1 version up, and modifying constraints to point to
that instead seems to fix up the issue.

Closes-Bug: #1734009

Change-Id: Id457f8bf302f15ad082ab8381c1ccd894352f8aa
",git fetch https://review.opendev.org/openstack/requirements refs/changes/12/522412/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,921dbc7360aade4f51c6809869d4cdc77744b8d6,protobuf_3.5.0_nle,protobuf===3.5.0.post1,protobuf===3.5.0,1,1
openstack%2Fneutron~master~Iff5b21d85c49a05b02e148ed0361412ad59fe437,openstack/neutron,master,Iff5b21d85c49a05b02e148ed0361412ad59fe437,l3_db: flush session before retrieving a new copy of the object,ABANDONED,2017-12-11 09:32:30.000000000,2017-12-14 04:19:56.000000000,,"[{'_account_id': 1131}, {'_account_id': 6854}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 09:32:30.000000000', 'files': ['neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca3b08c7e0b3a9031bf890f9253afa5da1ace379', 'message': 'l3_db: flush session before retrieving a new copy of the object\n\nCloses-Bug: #1737503\nChange-Id: Iff5b21d85c49a05b02e148ed0361412ad59fe437\n'}]",0,527032,ca3b08c7e0b3a9031bf890f9253afa5da1ace379,6,5,1,6854,,,0,"l3_db: flush session before retrieving a new copy of the object

Closes-Bug: #1737503
Change-Id: Iff5b21d85c49a05b02e148ed0361412ad59fe437
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/527032/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,ca3b08c7e0b3a9031bf890f9253afa5da1ace379,bug/1737503, context.session.flush(),,1,0
openstack%2Fpuppet-ceph~stable%2Fjewel~I2983de1448ce4e4bbbfffb970a1d0f082854d879,openstack/puppet-ceph,stable/jewel,I2983de1448ce4e4bbbfffb970a1d0f082854d879,Make sure pg_num is updated before pgp_num.,MERGED,2017-11-07 13:06:12.000000000,2017-12-14 04:01:21.000000000,2017-12-14 04:01:21.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-07 13:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/238cbde4207c72022b7ea2632de316fd393ee039', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 2, 'created': '2017-11-08 15:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/095fafae52537b4dc034cad574b1ea6385b5b135', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 3, 'created': '2017-11-08 16:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/f901392e613639e3f4aca9d6a0a7889c1ca4c318', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 4, 'created': '2017-11-08 17:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/ec7138645e69039469328e9dd8e7203dd5fa7378', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 5, 'created': '2017-12-13 16:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/64984e42d6ab3e63e6017c52e5ad5a324a5becd1', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 6, 'created': '2017-12-13 18:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/f84beba987fab0339de40c33a79a153a347169f0', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 7, 'created': '2017-12-13 18:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/48cd7ef5fe977ad7ac6af342ea255bae92b81b86', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}, {'number': 8, 'created': '2017-12-13 22:39:04.000000000', 'files': ['manifests/pool.pp', 'spec/defines/ceph_pool_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/95c72410d8aa9e07ecc7207dd03f4e6070901ae7', 'message': 'Make sure pg_num is updated before pgp_num.\n\nWe need to order the change because pgp makes a check on the pg\nnumber.\n\nCloses-Bug: #1730457\n\nChange-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879\n(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)\n'}]",0,518325,95c72410d8aa9e07ecc7207dd03f4e6070901ae7,33,6,8,6796,,,0,"Make sure pg_num is updated before pgp_num.

We need to order the change because pgp makes a check on the pg
number.

Closes-Bug: #1730457

Change-Id: I2983de1448ce4e4bbbfffb970a1d0f082854d879
(cherry picked from commit 7a366f92a53cc9015d3aaeab86e36c3d1649cf79)
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/25/518325/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/pool.pp', 'spec/defines/ceph_pool_spec.rb']",2,238cbde4207c72022b7ea2632de316fd393ee039,bug/1730457, ).that_requires('Exec[set-volumes-pg_num]'), ),2,2
openstack%2Fhorizon~master~I546b1d8f797e45fabca21e2d7df8fd2112ab1764,openstack/horizon,master,I546b1d8f797e45fabca21e2d7df8fd2112ab1764,Sync glance policy,MERGED,2017-12-13 11:22:16.000000000,2017-12-14 03:51:23.000000000,2017-12-14 03:51:23.000000000,"[{'_account_id': 8648}, {'_account_id': 11885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 11:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7455ce16ea9e83454790f14dfcc6372fe1fd06c1', 'message': 'Sync glance policy\n\nBased on glance commit 38e6c025173ffbd9de651ff5d15b39f709f3a13\n\nChange-Id: I546b1d8f797e45fabca21e2d7df8fd2112ab1764\n'}, {'number': 2, 'created': '2017-12-13 12:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2dd2a7dc41db9e6194d6f67482fd738e6aea83f4', 'message': 'Sync glance policy\n\nBased on glance commit 38e6c025173ffbd9de651ff5d15b39f709f3a13\n\nChange-Id: I546b1d8f797e45fabca21e2d7df8fd2112ab1764\n'}, {'number': 3, 'created': '2017-12-13 16:03:40.000000000', 'files': ['openstack_dashboard/conf/glance_policy.json'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ebaf633c1fd647095f8e689f904f6e2c610e064a', 'message': 'Sync glance policy\n\nBased on glance commit 38e6c025173ffbd9de651ff5d15b39f709f3a13\n\nChange-Id: I546b1d8f797e45fabca21e2d7df8fd2112ab1764\n'}]",0,527667,ebaf633c1fd647095f8e689f904f6e2c610e064a,11,3,3,841,,,0,"Sync glance policy

Based on glance commit 38e6c025173ffbd9de651ff5d15b39f709f3a13

Change-Id: I546b1d8f797e45fabca21e2d7df8fd2112ab1764
",git fetch https://review.opendev.org/openstack/horizon refs/changes/67/527667/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/conf/glance_policy.json'],1,7455ce16ea9e83454790f14dfcc6372fe1fd06c1,policy-file-update," ""communitize_image"": """", ""get_task"": """", ""get_tasks"": """", ""add_task"": """", ""modify_task"": """", ""tasks_api_access"": ""role:admin"","," ""get_task"": ""role:admin"", ""get_tasks"": ""role:admin"", ""add_task"": ""role:admin"", ""modify_task"": ""role:admin"",",6,4
openstack%2Fhorizon~master~Ic9e054a0e5015d60cfc966e70409a3016719ae11,openstack/horizon,master,Ic9e054a0e5015d60cfc966e70409a3016719ae11,python3: long does not exist in python 3,MERGED,2017-12-12 06:55:02.000000000,2017-12-14 03:51:21.000000000,2017-12-14 03:51:21.000000000,"[{'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 11885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 06:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e4e7d4ff89eb9f9ccf3eb3b121775389689856cd', 'message': ""python3: long does not exist in python 3\n\nIn Python 2 there are two integer types 'int' and 'float',\nbut in Python 3 'int' handles all integers.\nIn python 2, future.builtins.int provides python3-compatible int.\n\nblueprint django2-support\nChange-Id: Ic9e054a0e5015d60cfc966e70409a3016719ae11\n""}, {'number': 2, 'created': '2017-12-12 10:56:34.000000000', 'files': ['openstack_dashboard/dashboards/admin/images/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/365df575ae7febf386cf80e2ccdf7ddc8604e291', 'message': ""python3: long does not exist in python 3\n\nIn Python 2 there are two integer types 'int' and 'float',\nbut in Python 3 'int' handles all integers.\n\nblueprint django2-support\nChange-Id: Ic9e054a0e5015d60cfc966e70409a3016719ae11\n""}]",0,527319,365df575ae7febf386cf80e2ccdf7ddc8604e291,10,4,2,841,,,0,"python3: long does not exist in python 3

In Python 2 there are two integer types 'int' and 'float',
but in Python 3 'int' handles all integers.

blueprint django2-support
Change-Id: Ic9e054a0e5015d60cfc966e70409a3016719ae11
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/527319/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/images/views.py'],1,e4e7d4ff89eb9f9ccf3eb3b121775389689856cd,bp/django2-support,import sixif six.PY2: from future.builtins import int filter_string = int(float(filter_string) * (units.Mi)), filter_string = long(float(filter_string) * (units.Mi)),5,1
openstack%2Fhorizon~master~Id079fa38c0ac0e79666fa7c5469afd58bf5228d3,openstack/horizon,master,Id079fa38c0ac0e79666fa7c5469afd58bf5228d3,Add text download service,MERGED,2017-11-15 09:18:43.000000000,2017-12-14 03:42:40.000000000,2017-12-14 03:42:40.000000000,"[{'_account_id': 11885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-15 09:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e304eab8c465043240053e1256188123f588d509', 'message': 'Add text download service\n\nTo add functionality for text download within client-side,\nthis patch adds text-download.service.\nThis service realize to download text file from text contents and file name\nwithin  only browser.\nThis function will be used for download key pair after its creation.\n\nChange-Id: Id079fa38c0ac0e79666fa7c5469afd58bf5228d3\n'}, {'number': 2, 'created': '2017-12-01 06:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cf5eb43937d403a753f984aa9a8125bf2c7d62c1', 'message': 'Add text download service\n\nTo add functionality for text download within client-side,\nthis patch adds text-download.service.\nThis service realize to download text file from text contents and file name\nwithin  only browser.\nThis function will be used for download key pair after its creation.\n\nChange-Id: Id079fa38c0ac0e79666fa7c5469afd58bf5228d3\n'}, {'number': 3, 'created': '2017-12-13 04:41:46.000000000', 'files': ['horizon/static/framework/util/file/text-download.service.js', 'horizon/static/framework/util/file/text-download.service.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7dac18b3192853a98a688ae2514bd6a284a0162b', 'message': 'Add text download service\n\nTo add functionality for text download within client-side,\nthis patch adds text-download.service.\nThis service realize to download text file from text contents and file name\nwithin  only browser.\nThis function will be used for download key pair after its creation.\n\nChange-Id: Id079fa38c0ac0e79666fa7c5469afd58bf5228d3\n'}]",0,520018,7dac18b3192853a98a688ae2514bd6a284a0162b,10,2,3,16352,,,0,"Add text download service

To add functionality for text download within client-side,
this patch adds text-download.service.
This service realize to download text file from text contents and file name
within  only browser.
This function will be used for download key pair after its creation.

Change-Id: Id079fa38c0ac0e79666fa7c5469afd58bf5228d3
",git fetch https://review.opendev.org/openstack/horizon refs/changes/18/520018/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/util/file/text-download.service.js', 'horizon/static/framework/util/file/text-download.service.spec.js']",2,e304eab8c465043240053e1256188123f588d509,download-text,"/* * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function() { 'use strict'; describe('textDownloadService', function() { var $scope, textDownload; beforeEach(module('horizon.framework.util.file')); beforeEach(inject(function($injector) { textDownload = $injector.get('horizon.framework.util.file.text-download'); $scope = $injector.get('$rootScope'); })); it('should return promise and it resolve filename after starting download file', function() { var promise = textDownload.downloadTextFile('content', 'download_file_name.txt'); $scope.$apply(); promise.then(function(contents) { expect(contents).toEqual('download_file_name.txt'); }); }); }); })(); ",,100,0
openstack%2Ftripleo-ci~master~Id515c14dcdc0ccf991574ab2245710e307cdb82d,openstack/tripleo-ci,master,Id515c14dcdc0ccf991574ab2245710e307cdb82d,DNM: test containers update,ABANDONED,2017-10-11 08:12:44.000000000,2017-12-14 03:31:29.000000000,,"[{'_account_id': 3}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-10-11 08:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1578d5f63ab64b8e95ae6381e2b7f76c4f939822', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}, {'number': 2, 'created': '2017-10-12 07:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2e9adbbff76fc8eedc046fdf9d6855290697e22c', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}, {'number': 3, 'created': '2017-10-18 08:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b679927a15a578cec1a317cd3dcfc3933c357435', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}, {'number': 4, 'created': '2017-10-24 10:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2d28807868e9d0534f4527db523258cc3fb422fd', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}, {'number': 5, 'created': '2017-10-25 12:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e1277a575c2841daafbb086611d386c3ff347de5', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}, {'number': 6, 'created': '2017-10-26 07:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d0f6a9066b8dff4e0b27e7841ebdd6190286263c', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}, {'number': 7, 'created': '2017-11-12 14:04:33.000000000', 'files': ['toci-quickstart/config/testenv/multinode.yml', 'toci-quickstart/config/testenv/ovb.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7b19a7aa1aaefb0cd389aa59c9bad42c65bcafea', 'message': 'DNM: test containers update\n\nChange-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d\nDepends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb\n'}]",0,511175,7b19a7aa1aaefb0cd389aa59c9bad42c65bcafea,53,5,7,10969,,,0,"DNM: test containers update

Change-Id: Id515c14dcdc0ccf991574ab2245710e307cdb82d
Depends-On: I7fc3a83c95a76fe5005eeb084ad044fee9084bdb
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/75/511175/3 && git format-patch -1 --stdout FETCH_HEAD,"['toci-quickstart/config/testenv/multinode.yml', 'toci-quickstart/config/testenv/ovb.yml']",2,1578d5f63ab64b8e95ae6381e2b7f76c4f939822,containers-update,update_containers: true,,2,0
openstack%2Ftempest~master~Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce,openstack/tempest,master,Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce,Add update groups types API endpoint to volumes v3 library,MERGED,2017-11-20 18:59:23.000000000,2017-12-14 03:24:07.000000000,2017-12-14 03:24:07.000000000,"[{'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23081}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-11-20 18:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e20d54d9fd4d7f60d767c670b653b31117e55308', 'message': 'Add update groups types API endpoint to volumes v3 library\n\nThis PS adds update group types API to v3 ``group_types_client``\nlibrary; min_microversion of this API is 3.11 [0].\n\nIncluded in this PS:\n\n* Update group types API to group_types_client\n* Unit tests for update API\n* API test for update API\n\n[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11\n\nChange-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce\n'}, {'number': 2, 'created': '2017-11-20 19:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bf3183b723e8148f446c4b7a13672863d7509d33', 'message': 'Add update groups types API endpoint to volumes v3 library\n\nThis PS adds update group types API to v3 ``group_types_client``\nlibrary; min_microversion of this API is 3.11 [0].\n\nIncluded in this PS:\n\n* Update group types API to group_types_client\n* Unit tests for update API\n* API test for update API\n\n[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11\n\nChange-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce\n'}, {'number': 3, 'created': '2017-11-20 21:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/926151bb04d9b603db88300247c496e869692f05', 'message': 'Add update groups types API endpoint to volumes v3 library\n\nThis PS adds update group types API to v3 ``group_types_client``\nlibrary; min_microversion of this API is 3.11 [0].\n\nIncluded in this PS:\n\n* Update group types API to group_types_client\n* Unit tests for update API\n* API test for update API\n\n[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11\n\nChange-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce\n'}, {'number': 4, 'created': '2017-11-21 00:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d07c73e7e0f6914e18696c57f5f6c3d24ecb02ef', 'message': 'Add update groups types API endpoint to volumes v3 library\n\nThis PS adds update group types API to v3 ``group_types_client``\nlibrary; min_microversion of this API is 3.11 [0].\n\nIncluded in this PS:\n\n* Update group types API to group_types_client\n* Unit tests for update API\n* API test for update API\n\n[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11\n\nChange-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce\n'}, {'number': 5, 'created': '2017-11-26 23:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/235cad4b6fb786e2c28f974e5cd88d0b55f0cd9e', 'message': 'Add update groups types API endpoint to volumes v3 library\n\nThis PS adds update group types API to v3 ``group_types_client``\nlibrary; min_microversion of this API is 3.11 [0].\n\nIncluded in this PS:\n\n* Update group types API to group_types_client\n* Unit tests for update API\n* API test for update API\n\n[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11\n\nChange-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce\n'}, {'number': 6, 'created': '2017-12-13 17:26:50.000000000', 'files': ['tempest/api/volume/admin/test_group_types.py', 'releasenotes/notes/add-update-api-to-group-types-client-09c06ccdf80d5003.yaml', 'tempest/lib/services/volume/v3/group_types_client.py', 'tempest/tests/lib/services/volume/v3/test_group_types_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a2f69f11a786565be6d9aa46e09190f2cd0dbf76', 'message': 'Add update groups types API endpoint to volumes v3 library\n\nThis PS adds update group types API to v3 ``group_types_client``\nlibrary; min_microversion of this API is 3.11 [0].\n\nIncluded in this PS:\n\n* Update group types API to group_types_client\n* Unit tests for update API\n* API test for update API\n\n[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11\n\nChange-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce\n'}]",8,521634,a2f69f11a786565be6d9aa46e09190f2cd0dbf76,35,6,6,23186,,,0,"Add update groups types API endpoint to volumes v3 library

This PS adds update group types API to v3 ``group_types_client``
library; min_microversion of this API is 3.11 [0].

Included in this PS:

* Update group types API to group_types_client
* Unit tests for update API
* API test for update API

[0] https://docs.openstack.org/cinder/latest/contributor/api_microversion_history.html#id11

Change-Id: Ie3834c1a4b3ebd1463cdaacc86cd21b7be9fa3ce
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/521634/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-update-backup-api-to-group-types-client-09c06ccdf80d5003.yaml', 'tempest/api/volume/admin/test_group_types.py', 'tempest/lib/services/volume/v3/group_types_client.py', 'tempest/tests/lib/services/volume/v3/test_group_types_client.py']",4,e20d54d9fd4d7f60d767c670b653b31117e55308,group-type-update,"import copy def _test_update_group_types(self, bytes_body=False): resp_body = copy.deepcopy(self.FAKE_INFO_GROUP_TYPE) resp_body['group_type'].pop('created_at') self.check_service_client_function( self.client.update_group_type, 'tempest.lib.common.rest_client.RestClient.put', resp_body, bytes_body, group_type_id=""3fbbcccf-d058-4502-8844-6feeffdf4cb5"", name='updated-group-type-name') def test_update_group_types_with_str_body(self): self._test_update_group_types() def test_update_group_types_with_bytes_body(self): self._test_update_group_types(bytes_body=True)",,51,1
openstack%2Ftripleo-heat-templates~stable%2Fpike~I7abdfdd55e38da80768c907863fa06429debf9cd,openstack/tripleo-heat-templates,stable/pike,I7abdfdd55e38da80768c907863fa06429debf9cd,Add missing keystone_domain_config,MERGED,2017-12-13 18:47:50.000000000,2017-12-14 03:22:29.000000000,2017-12-14 03:22:29.000000000,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 9098}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-13 18:47:50.000000000', 'files': ['docker/services/keystone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61a08ce56f40a65de07c477e677d9f4972b52c38', 'message': 'Add missing keystone_domain_config\n\nWhen configuring the keystone LDAP integration we need to write out\ndomain configuration items using the keystone_domain_config provider.\nSince this tag was missed in the docker conversion, the configuration\nwas not actually available in the docker container.\n\nChange-Id: I7abdfdd55e38da80768c907863fa06429debf9cd\nCloses-Bug: #1737799\n(cherry picked from commit 40530c0e8c1bd28244db947309fe5b19010d3f4e)\n'}]",0,527758,61a08ce56f40a65de07c477e677d9f4972b52c38,8,7,1,11589,,,0,"Add missing keystone_domain_config

When configuring the keystone LDAP integration we need to write out
domain configuration items using the keystone_domain_config provider.
Since this tag was missed in the docker conversion, the configuration
was not actually available in the docker container.

Change-Id: I7abdfdd55e38da80768c907863fa06429debf9cd
Closes-Bug: #1737799
(cherry picked from commit 40530c0e8c1bd28244db947309fe5b19010d3f4e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/527758/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/keystone.yaml'],1,61a08ce56f40a65de07c477e677d9f4972b52c38,bug/1737799," puppet_tags: keystone_config,keystone_domain_config", puppet_tags: keystone_config,1,1
openstack%2Ftripleo-validations~master~I316e7613cc3f3c045c338f2145475538ab78ebfa,openstack/tripleo-validations,master,I316e7613cc3f3c045c338f2145475538ab78ebfa,Get rid of star imports,MERGED,2017-10-26 00:01:25.000000000,2017-12-14 03:22:28.000000000,2017-12-14 03:22:27.000000000,"[{'_account_id': 3153}, {'_account_id': 9317}, {'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-26 00:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5e872f2a83abc77cd37f6598f0fa3475380bb39a', 'message': 'Get rid of start imports\n\nChange-Id: I316e7613cc3f3c045c338f2145475538ab78ebfa\n'}, {'number': 2, 'created': '2017-10-26 00:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/df02ea9c68702422240973f9aae14297f72c455e', 'message': 'Get rid of star imports\n\nChange-Id: I316e7613cc3f3c045c338f2145475538ab78ebfa\n'}, {'number': 3, 'created': '2017-12-10 19:04:59.000000000', 'files': ['validations/library/warn.py', 'validations/library/overcloudrc.py', 'validations/library/haproxy_conf.py', 'validations/library/undercloud_conf.py', 'validations/library/pacemaker.py', 'README.rst', 'validations/library/icmp_ping.py', 'validations/library/ip_range.py', 'validations/library/hiera.py', 'validations/library/advanced_format.py', 'validations/library/ini.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/207afad421eff051928f4bea620ec62a5a324acd', 'message': 'Get rid of star imports\n\nChange-Id: I316e7613cc3f3c045c338f2145475538ab78ebfa\n'}]",0,515229,207afad421eff051928f4bea620ec62a5a324acd,21,5,3,9317,,,0,"Get rid of star imports

Change-Id: I316e7613cc3f3c045c338f2145475538ab78ebfa
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/29/515229/1 && git format-patch -1 --stdout FETCH_HEAD,"['validations/library/warn.py', 'validations/library/haproxy_conf.py', 'validations/library/overcloudrc.py', 'validations/library/pacemaker.py', 'validations/library/undercloud_conf.py', 'validations/library/icmp_ping.py', 'validations/library/ip_range.py', 'validations/library/hiera.py', 'validations/library/advanced_format.py', 'validations/library/ini.py']",10,5e872f2a83abc77cd37f6598f0fa3475380bb39a,star-imports,from ansible.module_utils.basic import AnsibleModule,from ansible.module_utils.basic import * # NOQA,10,10
openstack%2Ftripleo-validations~stable%2Fpike~Ieddbb4c87d88888f78d494ff670db907bce4fd78,openstack/tripleo-validations,stable/pike,Ieddbb4c87d88888f78d494ff670db907bce4fd78,Add env var for custom ssh user,MERGED,2017-12-11 09:32:17.000000000,2017-12-14 03:22:27.000000000,2017-12-14 03:22:26.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 9317}, {'_account_id': 13039}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 09:32:17.000000000', 'files': ['releasenotes/notes/configurable-ssh-user-840a9ef5416675e9.yaml', 'scripts/tripleo-ansible-inventory'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/9209c8e088a8ce0aef7b458477e27a6559939e43', 'message': ""Add env var for custom ssh user\n\nW/o an env var, a dynamic inventory can't be invoked for a custom\nuser. Ansible uses the same ANSIBLE_SSH_USER so the value will\nbe aligned to both.\n\nRelated-bug: #1734298\n\nChange-Id: Ieddbb4c87d88888f78d494ff670db907bce4fd78\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit fde797ca14b194f588a46256c809729c2ef0135d)\n""}]",0,527031,9209c8e088a8ce0aef7b458477e27a6559939e43,8,6,1,11491,,,0,"Add env var for custom ssh user

W/o an env var, a dynamic inventory can't be invoked for a custom
user. Ansible uses the same ANSIBLE_SSH_USER so the value will
be aligned to both.

Related-bug: #1734298

Change-Id: Ieddbb4c87d88888f78d494ff670db907bce4fd78
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit fde797ca14b194f588a46256c809729c2ef0135d)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/31/527031/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/configurable-ssh-user-840a9ef5416675e9.yaml', 'scripts/tripleo-ansible-inventory']",2,9209c8e088a8ce0aef7b458477e27a6559939e43,bug/1734298-stable/pike," cfg.StrOpt('ansible_ssh_user', default=os.environ.get('ANSIBLE_SSH_USER', 'heat-admin')),"," cfg.StrOpt('ansible_ssh_user', default='heat-admin'),",4,1
openstack%2Ftripleo-common~master~Id8706f61df717bbe614aade659ff13b857e7f9dd,openstack/tripleo-common,master,Id8706f61df717bbe614aade659ff13b857e7f9dd,Create config-download dir in tripleo-bootstrap role,MERGED,2017-12-12 18:12:56.000000000,2017-12-14 03:22:25.000000000,2017-12-14 03:22:25.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 18:12:56.000000000', 'files': ['tripleo_common/templates/deployments.yaml', 'roles/tripleo-bootstrap/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/00136d8107142129cc81ac9717bd4d4ee546c552', 'message': 'Create config-download dir in tripleo-bootstrap role\n\nInstead of creating the /var/lib/heat-config/tripleo-config-download\ndirectory before every individual server deployment, we should just do\nit one time. Move the task to the new tripleo-bootstrap role which is\nrun at the beginning before any deployments.\n\nChange-Id: Id8706f61df717bbe614aade659ff13b857e7f9dd\nCloses-Bug: #1737801\n'}]",0,527488,00136d8107142129cc81ac9717bd4d4ee546c552,11,4,1,7144,,,0,"Create config-download dir in tripleo-bootstrap role

Instead of creating the /var/lib/heat-config/tripleo-config-download
directory before every individual server deployment, we should just do
it one time. Move the task to the new tripleo-bootstrap role which is
run at the beginning before any deployments.

Change-Id: Id8706f61df717bbe614aade659ff13b857e7f9dd
Closes-Bug: #1737801
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/88/527488/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/templates/deployments.yaml', 'roles/tripleo-bootstrap/tasks/main.yml']",2,00136d8107142129cc81ac9717bd4d4ee546c552,bug/1737801, - name: Create /var/lib/heat-config/tripleo-config-download directory for deployment data file: path: /var/lib/heat-config/tripleo-config-download state: directory become: true,,6,6
openstack%2Ftripleo-heat-templates~master~I7283d25260c1501964c240c89dd4f658d5c14a3b,openstack/tripleo-heat-templates,master,I7283d25260c1501964c240c89dd4f658d5c14a3b,Add -c for clean_templates,MERGED,2017-12-05 20:57:23.000000000,2017-12-14 03:22:24.000000000,2017-12-14 03:22:24.000000000,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-05 20:57:23.000000000', 'files': ['tools/process-templates.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/34b7a81f07841ae884fbeb6cc31d23f79bd7cb3d', 'message': 'Add -c for clean_templates\n\nAdd a new option to process-templates.py that will clean the working\ntemplate directory of any generated template files.\n\nChange-Id: I7283d25260c1501964c240c89dd4f658d5c14a3b\n'}]",0,525753,34b7a81f07841ae884fbeb6cc31d23f79bd7cb3d,17,4,1,7144,,,0,"Add -c for clean_templates

Add a new option to process-templates.py that will clean the working
template directory of any generated template files.

Change-Id: I7283d25260c1501964c240c89dd4f658d5c14a3b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/525753/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/process-templates.py'],1,34b7a81f07841ae884fbeb6cc31d23f79bd7cb3d,," parser.add_argument('-c', '--clean', action='store_true', help=(""""""clean the templates dir by deleting """""" """"""generated templates""""""))def clean_templates(base_path, role_data_path, network_data_path): def delete(f): if os.path.exists(f): print(""Deleting %s"" % f) os.unlink(f) for root, dirs, files in os.walk(base_path): for f in files: if f.endswith('.j2.yaml'): rendered_path = os.path.join( root, '%s.yaml' % f.split('.j2.yaml')[0]) delete(rendered_path) with open(network_data_path) as network_data_file: network_data = yaml.safe_load(network_data_file) for network in network_data: network_path = os.path.join( 'network', '%s.yaml' % network['name_lower']) network_from_pool_path = os.path.join( 'network', '%s_from_pool.yaml' % network['name_lower']) network_v6_path = os.path.join( 'network', '%s_v6.yaml' % network['name_lower']) network_from_pool_v6_path = os.path.join( 'network', '%s_from_pool_v6.yaml' % network['name_lower']) ports_path = os.path.join( 'network', 'ports', '%s.yaml' % network['name_lower']) ports_from_pool_path = os.path.join( 'network', 'ports', '%s_from_pool.yaml' % network['name_lower']) ports_v6_path = os.path.join( 'network', 'ports', '%s_v6.yaml' % network['name_lower']) ports_from_pool_v6_path = os.path.join( 'network', 'ports', '%s_from_pool_v6.yaml' % network['name_lower']) delete(network_path) delete(network_from_pool_path) delete(network_v6_path) delete(network_from_pool_v6_path) delete(ports_path) delete(ports_from_pool_path) delete(ports_v6_path) delete(ports_from_pool_v6_path) with open(role_data_path) as role_data_file: role_data = yaml.safe_load(role_data_file) for role in role_data: role_path = os.path.join( 'puppet', '%s-role.yaml' % role['name'].lower()) host_config_and_reboot_path = os.path.join( 'extraconfig', 'pre_network', '%s-host_config_and_reboot.yaml' % role['name'].lower()) delete(role_path) delete(host_config_and_reboot_path) if opts.clean: clean_templates(opts.base_path, role_data_path, network_data_path) else: process_templates(opts.base_path, role_data_path, opts.output_dir, network_data_path, (not opts.safe))","process_templates(opts.base_path, role_data_path, opts.output_dir, network_data_path, (not opts.safe))",66,2
openstack%2Ftripleo-heat-templates~master~Ie486473d001b10a23374b55369431b4c2bb85419,openstack/tripleo-heat-templates,master,Ie486473d001b10a23374b55369431b4c2bb85419,Set barbican to be configured in step 3,MERGED,2017-12-11 20:38:21.000000000,2017-12-14 03:22:22.000000000,2017-12-14 03:22:22.000000000,"[{'_account_id': 3153}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-11 20:38:21.000000000', 'files': ['docker/services/barbican-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a0c7f5580ff9a2f2cdd1e3500865b821a1067312', 'message': 'Set barbican to be configured in step 3\n\nBarbican is set to be configured in step 3 after keystone.\nThis allows other services (like swift) to use barbican to store\nand retrieve configuration secrets.\n\nChange-Id: Ie486473d001b10a23374b55369431b4c2bb85419\n'}]",0,527234,a0c7f5580ff9a2f2cdd1e3500865b821a1067312,20,6,1,9914,,,0,"Set barbican to be configured in step 3

Barbican is set to be configured in step 3 after keystone.
This allows other services (like swift) to use barbican to store
and retrieve configuration secrets.

Change-Id: Ie486473d001b10a23374b55369431b4c2bb85419
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/34/527234/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/barbican-api.yaml'],1,a0c7f5580ff9a2f2cdd1e3500865b821a1067312,add_parameters_for_barbican_keystone_listener, barbican_api: # NOTE(alee): Barbican should start after keystone processes start_order: 5 start_order: 6 start_order: 7, step_4: barbican_api: start_order: 0 start_order: 1 start_order: 2,4,4
openstack%2Ftripleo-heat-templates~master~I8ce02ab1425e891b6608363250910bf1f57914fc,openstack/tripleo-heat-templates,master,I8ce02ab1425e891b6608363250910bf1f57914fc,"Revert ""Add upgrade task to run gnocchi upgrade""",MERGED,2017-12-13 14:53:39.000000000,2017-12-14 03:22:21.000000000,2017-12-14 03:22:21.000000000,"[{'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-13 14:53:39.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/11e2cf07c5845d1e27f90d343f2689e75e728946', 'message': 'Revert ""Add upgrade task to run gnocchi upgrade""\n\nThis reverts commit 60925faefc58d76adf3914f96c636ca2a5b8c783.\n\nThe issue still occurs with this.\n\nAlso gnocchi-upgrade should have already run in step4: https://github.com/openstack/puppet-tripleo/blob/a3275836431c1cff8cb7bae1aef561f0f6b40d8d/manifests/profile/base/gnocchi/api.pp#L92\n\nChange-Id: I8ce02ab1425e891b6608363250910bf1f57914fc\n'}]",0,527705,11e2cf07c5845d1e27f90d343f2689e75e728946,8,7,1,2813,,,0,"Revert ""Add upgrade task to run gnocchi upgrade""

This reverts commit 60925faefc58d76adf3914f96c636ca2a5b8c783.

The issue still occurs with this.

Also gnocchi-upgrade should have already run in step4: https://github.com/openstack/puppet-tripleo/blob/a3275836431c1cff8cb7bae1aef561f0f6b40d8d/manifests/profile/base/gnocchi/api.pp#L92

Change-Id: I8ce02ab1425e891b6608363250910bf1f57914fc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/05/527705/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-api.yaml'],1,11e2cf07c5845d1e27f90d343f2689e75e728946,bug/1724328,, - name: get bootstrap nodeid tags: common command: hiera bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact tags: common set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Setup gnocchi db during upgrade tags: step5 command: gnocchi-upgrade when: is_bootstrap_node,0,11
openstack%2Ftripleo-heat-templates~stable%2Fpike~I8cd2945c17c67949fccce02caa670f7779d2b02b,openstack/tripleo-heat-templates,stable/pike,I8cd2945c17c67949fccce02caa670f7779d2b02b,"Revert ""Add upgrade task to run gnocchi upgrade""",MERGED,2017-12-13 14:50:49.000000000,2017-12-14 03:22:19.000000000,2017-12-14 03:22:19.000000000,"[{'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-13 14:50:49.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7eed3bde4cfc558fdf2da2d4e3ec571236e53983', 'message': 'Revert ""Add upgrade task to run gnocchi upgrade""\n\nThis reverts commit aab7bdd6fbab0158cf2b57a63b4422cd3156beed.\n\nChange-Id: I8cd2945c17c67949fccce02caa670f7779d2b02b\n'}]",0,527703,7eed3bde4cfc558fdf2da2d4e3ec571236e53983,8,6,1,2813,,,0,"Revert ""Add upgrade task to run gnocchi upgrade""

This reverts commit aab7bdd6fbab0158cf2b57a63b4422cd3156beed.

Change-Id: I8cd2945c17c67949fccce02caa670f7779d2b02b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/527703/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-api.yaml'],1,7eed3bde4cfc558fdf2da2d4e3ec571236e53983,bug/1724328,, - name: get bootstrap nodeid tags: common command: hiera bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact tags: common set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Setup gnocchi db during upgrade tags: step5 command: gnocchi-upgrade when: is_bootstrap_node,0,11
openstack%2Fnova~master~I70b11dd489d222be3d70733355bfe7966df556aa,openstack/nova,master,I70b11dd489d222be3d70733355bfe7966df556aa,Change RPC for select_destinations(),MERGED,2017-10-31 14:59:08.000000000,2017-12-14 03:22:11.000000000,2017-12-13 19:27:37.000000000,"[{'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 6125}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-31 14:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a80dea6717427accad6d582962e85016122c7afd', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 2, 'created': '2017-10-31 17:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/052564bf8508d065efd8c1b4e925a209f923c88a', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 3, 'created': '2017-10-31 21:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0b51a2779d025ee5334535f1d515742d3a56dcf', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 4, 'created': '2017-11-01 13:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed14eca03bba6e40b8ce2be89a23f6c4780caabf', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 5, 'created': '2017-11-01 23:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f77642fdb33b1d85752d1f5af5e387a887de5a5c', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 6, 'created': '2017-11-02 15:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb6174b7dc8667a88265c7463cda2a404ca15a29', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 7, 'created': '2017-11-02 16:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb9518c8520887c63d4aea1ae87cbed0da8d7f2c', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 8, 'created': '2017-11-02 21:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0a4dc7f62a158e2a07659e15285bd8ad9af795e', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 9, 'created': '2017-11-03 16:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e15d7f711ded5f6f519395f7a3df965dd684021', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 10, 'created': '2017-11-15 23:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5e9f995e6bf9186dee28ccab5d6f752835a79df', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 11, 'created': '2017-11-16 15:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d89053f4236a515b5658e2a05aa5135808633a6', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 12, 'created': '2017-11-16 16:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc6f645c0c085ad398e8fd2cfecf8c33ec32fce5', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 13, 'created': '2017-11-16 22:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6691cb6d775bb4860152426ee322360c3f763ca', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 14, 'created': '2017-11-17 20:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1026e35d8703b13fc0e0158b0321b25e1fc1177a', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 15, 'created': '2017-11-28 17:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d74815757223915f52e8538dbe77f966f609615b', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 16, 'created': '2017-11-28 18:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/067a6587baddc51845f73859649841346f4115ed', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 17, 'created': '2017-12-04 17:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e40c791dc28bd056031a25e8c59b8464c7ef9c2', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 18, 'created': '2017-12-05 16:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/544f50c34517355f1d530dd5a6d70f8d9f367c26', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 19, 'created': '2017-12-06 18:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38eb20a54d7d0c5ecd22438c404faa1d72e02d6d', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 20, 'created': '2017-12-07 15:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/362390800af789a3cc3936f191c28bc987811d60', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 21, 'created': '2017-12-08 16:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15313fe1b8cd812453f049bac0e4b6c0b43a15ca', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 22, 'created': '2017-12-11 14:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f982e4a9cb1923144eaa58354c567818a700e311', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 23, 'created': '2017-12-11 19:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07cbf39bec4114e0f17f91bc00239b821ddb3fc5', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 24, 'created': '2017-12-11 22:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ce9b49ce47e109d372cf33fd6f401929e3bed68', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}, {'number': 25, 'created': '2017-12-12 03:07:59.000000000', 'files': ['nova/scheduler/manager.py', 'nova/objects/request_spec.py', 'nova/tests/unit/conductor/tasks/test_migrate.py', 'nova/scheduler/utils.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/tasks/migrate.py', 'nova/conductor/manager.py', 'nova/conductor/tasks/live_migrate.py', 'nova/compute/rpcapi.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca716ce4dd512e864886998a24e111e7d6e05848', 'message': 'Change RPC for select_destinations()\n\nThis changes the RPC call for select_destinations() as made by the\nconductor. The previous patch added the logic on the scheduler side;\nthis patch changes the conductor side to use the two new parameters that\nflag the new behaviors for Selection objects and alternate hosts.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: I70b11dd489d222be3d70733355bfe7966df556aa\n'}]",38,516707,ca716ce4dd512e864886998a24e111e7d6e05848,301,18,25,1063,,,0,"Change RPC for select_destinations()

This changes the RPC call for select_destinations() as made by the
conductor. The previous patch added the logic on the scheduler side;
this patch changes the conductor side to use the two new parameters that
flag the new behaviors for Selection objects and alternate hosts.

Blueprint: return-alternate-hosts

Change-Id: I70b11dd489d222be3d70733355bfe7966df556aa
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/516707/19 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/tasks/test_migrate.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/tasks/migrate.py', 'nova/conductor/manager.py', 'nova/conductor/tasks/live_migrate.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py']",6,a80dea6717427accad6d582962e85016122c7afd,bp/return-alternate-hosts,"fake_selection1 = objects.Selection(service_host=""host1"", nodename=""node1"", cell_uuid=uuids.cell) fake_selection2 = objects.Selection(service_host=""host2"", nodename=""node2"", cell_uuid=uuids.cell) self.context, self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn( [[fake_selection1]]) select_dest.return_value = [[fake_selection1]] [self.instance.uuid], return_objects=True, return_alternates=False) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection1]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection1]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection2]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection1]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection2]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection1]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection2]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndReturn([[fake_selection1]]) self.fake_spec, [self.instance.uuid], return_objects=True, return_alternates=False).AndRaise( exception.NoValidHost(reason=""""))"," self.context, self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host1', 'nodename': 'node1'}]) select_dest.return_value = [{'host': 'host1', 'nodename': 'node1'}] [self.instance.uuid]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host1', 'nodename': 'node1'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host1', 'nodename': 'node1'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host2', 'nodename': 'node2'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host1', 'nodename': 'node1'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host2', 'nodename': 'node2'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host1', 'nodename': 'node1'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host2', 'nodename': 'node2'}]) self.fake_spec, [self.instance.uuid]).AndReturn( [{'host': 'host1', 'nodename': 'node1'}]) self.fake_spec, [self.instance.uuid]).AndRaise( exception.NoValidHost(reason=""""))",196,204
openstack%2Fneutron~master~Ic54b6f422f10aed9fd1c62f756fc6beb392387b9,openstack/neutron,master,Ic54b6f422f10aed9fd1c62f756fc6beb392387b9,test_l3_agent_scheduler: convert from RouterL3AgentBinding model to OVO,MERGED,2017-12-06 21:07:24.000000000,2017-12-14 03:16:51.000000000,2017-12-14 03:16:51.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 15471}, {'_account_id': 22348}, {'_account_id': 25903}, {'_account_id': 26072}]","[{'number': 1, 'created': '2017-12-06 21:07:24.000000000', 'files': ['neutron/tests/unit/scheduler/test_l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/00a24377379e261e948503b4b6ea575d7beced02', 'message': 'test_l3_agent_scheduler: convert from RouterL3AgentBinding model to OVO\n\nChange-Id: Ic54b6f422f10aed9fd1c62f756fc6beb392387b9\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n'}]",0,526196,00a24377379e261e948503b4b6ea575d7beced02,25,9,1,9656,,,0,"test_l3_agent_scheduler: convert from RouterL3AgentBinding model to OVO

Change-Id: Ic54b6f422f10aed9fd1c62f756fc6beb392387b9
Partially-Implements: blueprint adopt-oslo-versioned-objects-for-db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/526196/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/scheduler/test_l3_agent_scheduler.py'],1,00a24377379e261e948503b4b6ea575d7beced02,bp/adopt-oslo-versioned-objects-for-db," results = rb_obj.RouterL3AgentBinding.get_objects(ctx, router_id=rid) args = {'router_id': router_id} if l3_agent_id: args['l3_agent_id'] = l3_agent_id if binding_index: args['binding_index'] = binding_index return rb_obj.RouterL3AgentBinding.get_objects(context, **args) bindings = self.get_router_l3_agent_binding( self.assertEqual(1, len(bindings)) bindings[0].delete() router['id']) self.assertEqual(1, len(bindings))","from neutron.db.models import l3agent as rb_model session = ctx.session db = rb_model.RouterL3AgentBinding results = (session.query(db).filter_by(router_id=rid).all()) model = rb_model.RouterL3AgentBinding query = context.session.query(model) query = query.filter(model.router_id == router_id) if l3_agent_id: query = query.filter(model.l3_agent_id == l3_agent_id) if binding_index: query = query.filter(model.binding_index == binding_index) return query binding = self.get_router_l3_agent_binding( self.assertEqual(1, binding.count()) with self.adminContext.session.begin(): self.adminContext.session.delete(binding.first()) router['id']).all() self.assertEqual(1, bindings.count())",10,16
openstack%2Fpuppet-nova~master~I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d,openstack/puppet-nova,master,I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d,Add glance image signature verification parameter,MERGED,2017-12-07 21:21:30.000000000,2017-12-14 03:14:23.000000000,2017-12-14 03:14:23.000000000,"[{'_account_id': 1004}, {'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23811}]","[{'number': 1, 'created': '2017-12-07 21:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5c103d917c0efd472a84f2baa9fce61391cc0977', 'message': 'Add glance image signature verification parameter\n\nChange-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}, {'number': 2, 'created': '2017-12-07 23:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/56c500dc5c03b8dd9240914373427c9d19714235', 'message': 'Add glance image signature verification parameter\n\nChange-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}, {'number': 3, 'created': '2017-12-08 00:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f1f3abf350a038eb478ee17e289512fe38b19731', 'message': 'Add glance image signature verification parameter\n\nChange-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}, {'number': 4, 'created': '2017-12-11 15:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/283cade225b2c35821266f2c6569968923fd7b50', 'message': 'Add glance image signature verification parameter\n\nChange-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}, {'number': 5, 'created': '2017-12-11 17:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/937449d1cb2809ce1e4b5e8436befd35c3f5de0d', 'message': 'Add glance image signature verification parameter\n\nChange-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}, {'number': 6, 'created': '2017-12-12 18:42:29.000000000', 'files': ['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add-glance-image-verification-parameter-456df02dd26552d3.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f5673206811a3779ebf629d1fef504d67a07baf2', 'message': 'Add glance image signature verification parameter\n\nChange-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}]",1,526514,f5673206811a3779ebf629d1fef504d67a07baf2,29,7,6,9914,,,0,"Add glance image signature verification parameter

Change-Id: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/14/526514/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/nova_init_spec.rb']",2,5c103d917c0efd472a84f2baa9fce61391cc0977,add_image_signature_verification_option, is_expected.to contain_nova_config('glance/verify_glance_signatures').with_value('<SERVICE_DEFAULT>') is_expected.to_not contain_nova_config('glance/verify_glance_signatures') context 'with glance image verification enabled' do let :params do { :verify_glance_signatures => true } end it 'configures image service with image signature verification' do is_expected.to contain_nova_config('DEFAULT/image_service').with_value('nova.image.glance.GlanceImageService') is_expected.to contain_nova_config('glance/api_servers').with_value('http://localhost:9292') is_expected.to contain_nova_config('glance/verify_glance_signatures').with_value(true) end end ,,20,0
openstack%2Fneutron~master~Ifabcba978fb2b5ea1dca3ab6407a5f7eb38c6b8b,openstack/neutron,master,Ifabcba978fb2b5ea1dca3ab6407a5f7eb38c6b8b,test_l3_agent_scheduler: convert from Agent model to OVO,MERGED,2017-12-06 20:46:23.000000000,2017-12-14 03:11:51.000000000,2017-12-14 03:11:50.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 15471}, {'_account_id': 22348}, {'_account_id': 25903}, {'_account_id': 26072}]","[{'number': 1, 'created': '2017-12-06 20:46:23.000000000', 'files': ['neutron/tests/unit/scheduler/test_l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/046a39097f1a0f0fa169e75b7dc831b045f3f93b', 'message': 'test_l3_agent_scheduler: convert from Agent model to OVO\n\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n\nChange-Id: Ifabcba978fb2b5ea1dca3ab6407a5f7eb38c6b8b\n'}]",0,526183,046a39097f1a0f0fa169e75b7dc831b045f3f93b,26,9,1,9656,,,0,"test_l3_agent_scheduler: convert from Agent model to OVO

Partially-Implements: blueprint adopt-oslo-versioned-objects-for-db

Change-Id: Ifabcba978fb2b5ea1dca3ab6407a5f7eb38c6b8b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/526183/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/scheduler/test_l3_agent_scheduler.py'],1,046a39097f1a0f0fa169e75b7dc831b045f3f93b,bp/adopt-oslo-versioned-objects-for-db,"from neutron.objects import agent as agent_obj agent = agent_obj.Agent(mock.ANY, id=uuidutils.generate_uuid()) agent = agent_obj.Agent(mock.ANY, id=uuidutils.generate_uuid()) agent.id) agent = agent_obj.Agent(mock.ANY, id=uuidutils.generate_uuid()) agent = agent_obj.Agent(mock.ANY, id=uuidutils.generate_uuid()) agent_obj.Agent.update_objects( self.adminContext, {'admin_state_up': False})",from neutron.db.models import agent as agent_model agent = agent_model.Agent(id='foo_agent') agent = agent_model.Agent(id='foo_agent') 'foo_agent') agent = agent_model.Agent() agent = agent_model.Agent() for agent in self.adminContext.session.query( agent_model.Agent).all(): agent.admin_state_up = False,8,9
openstack%2Ftripleo-ci~master~I9ffc961f4d32bed88de34bd14297992578b9b37e,openstack/tripleo-ci,master,I9ffc961f4d32bed88de34bd14297992578b9b37e,DNM: test image build,ABANDONED,2017-11-01 17:21:59.000000000,2017-12-14 02:50:35.000000000,,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-01 17:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/74903e91996d99528c8664e9553dd1d1d359921f', 'message': 'DNM: test image build\n\nChange-Id: I9ffc961f4d32bed88de34bd14297992578b9b37e\nDepends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508\nDepends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f\n'}, {'number': 2, 'created': '2017-11-12 14:21:48.000000000', 'files': ['scripts/getthelogs'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/59a8570c6b9762438293a38c5f7e4adb87d5bbbe', 'message': 'DNM: test image build\n\nChange-Id: I9ffc961f4d32bed88de34bd14297992578b9b37e\nDepends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508\nDepends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f\n'}]",0,517059,59a8570c6b9762438293a38c5f7e4adb87d5bbbe,12,3,2,10969,,,0,"DNM: test image build

Change-Id: I9ffc961f4d32bed88de34bd14297992578b9b37e
Depends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508
Depends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/59/517059/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/getthelogs'],1,74903e91996d99528c8664e9553dd1d1d359921f,test1,# test,,1,1
openstack%2Ftripleo-ci~master~I0d9f4d3625c2bb24bf139648e7bb6b215217e7e1,openstack/tripleo-ci,master,I0d9f4d3625c2bb24bf139648e7bb6b215217e7e1,DNM: test changes for extras playbook,ABANDONED,2017-11-13 12:34:16.000000000,2017-12-14 02:50:22.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-13 12:34:16.000000000', 'files': ['toci-quickstart/config/testenv/multinode.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bdda884a69802097f487e856660f29c493407062', 'message': 'DNM: test changes for extras playbook\n\nChange-Id: I0d9f4d3625c2bb24bf139648e7bb6b215217e7e1\nDepends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508\nDepends-On: I4464587cc8e00d63212d52d322a659385ad259fe\nDepends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f\n'}]",0,519332,bdda884a69802097f487e856660f29c493407062,5,2,1,10969,,,0,"DNM: test changes for extras playbook

Change-Id: I0d9f4d3625c2bb24bf139648e7bb6b215217e7e1
Depends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508
Depends-On: I4464587cc8e00d63212d52d322a659385ad259fe
Depends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/32/519332/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/testenv/multinode.yml'],1,bdda884a69802097f487e856660f29c493407062,testchange,#######,,1,0
openstack%2Ftripleo-ci~master~I65e119732bbe877f8f36dc2975bb87013a3900b9,openstack/tripleo-ci,master,I65e119732bbe877f8f36dc2975bb87013a3900b9,DNM: test ci with image build,ABANDONED,2017-12-11 10:31:02.000000000,2017-12-14 02:42:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 10:31:02.000000000', 'files': ['toci_gate_test-oooq.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/17852ac752d3d245432df93d1bea998d9abd9ec3', 'message': 'DNM: test ci with image build\n\nnothing here\n\nChange-Id: I65e119732bbe877f8f36dc2975bb87013a3900b9\nDepends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508\nDepends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f\nDepends-on: I4464587cc8e00d63212d52d322a659385ad259fe\n'}]",0,527055,17852ac752d3d245432df93d1bea998d9abd9ec3,5,2,1,10969,,,0,"DNM: test ci with image build

nothing here

Change-Id: I65e119732bbe877f8f36dc2975bb87013a3900b9
Depends-On: I3ed261e3660426e62ed608bc1bc7923f3912a508
Depends-On: Ie2489b2b51605b6e185371f37676e0d9cd66a04f
Depends-on: I4464587cc8e00d63212d52d322a659385ad259fe
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/55/527055/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test-oooq.sh'],1,17852ac752d3d245432df93d1bea998d9abd9ec3,tesci1,# test,,1,0
openstack%2Fneutron~stable%2Fpike~I7c3c4654f183b317647a28d599a538fe460db68f,openstack/neutron,stable/pike,I7c3c4654f183b317647a28d599a538fe460db68f,Move segment deletion back to PRECOMMIT_DELETE,MERGED,2017-12-06 15:46:04.000000000,2017-12-14 02:41:00.000000000,2017-12-14 02:41:00.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 22348}, {'_account_id': 23317}]","[{'number': 1, 'created': '2017-12-06 15:46:04.000000000', 'files': ['neutron/services/segments/db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/extensions/test_segment.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9dff53ce65e44a75d953ed9b6c6859184b0995a8', 'message': 'Move segment deletion back to PRECOMMIT_DELETE\n\nThis essentially reverts commit 12d24abba75ab3b926edbac389437bacc23914dd.\n\nMaking the callback _delete_segments_for_network respond to\nBEFORE_DELETE network event has created some bugs. In one of them,\nit is not possible to delete a routed network, because the segments\ncannot be deleted due to the fact that the associated subnets still\nexist.\n\nMaking _delete_segments_for_network respond to PRECOMMIT_DELETE\nintroduces a StaleDataError with the standard attributes of the\ndeleted segments. To work around that, network_db is expired and\nread again after notifying the PRECOMMIT_DELETE event in\ndelete_network in the DB core plug-in.\n\nThis also fixes an issue where we could delete the segment ID\nof the l3-ha network when deleting a router, leaving all other\nrouters non-functioning.  Moving this to PRECOMMIT_DELETE fixes\nit since it is done after we have checked that the network is\nnot in use and can be deleted.\n\nCloses-Bug: #1697324\nCloses-Bug: #1732543\n\nChange-Id: I7c3c4654f183b317647a28d599a538fe460db68f\n'}]",0,526102,9dff53ce65e44a75d953ed9b6c6859184b0995a8,20,8,1,1131,,,0,"Move segment deletion back to PRECOMMIT_DELETE

This essentially reverts commit 12d24abba75ab3b926edbac389437bacc23914dd.

Making the callback _delete_segments_for_network respond to
BEFORE_DELETE network event has created some bugs. In one of them,
it is not possible to delete a routed network, because the segments
cannot be deleted due to the fact that the associated subnets still
exist.

Making _delete_segments_for_network respond to PRECOMMIT_DELETE
introduces a StaleDataError with the standard attributes of the
deleted segments. To work around that, network_db is expired and
read again after notifying the PRECOMMIT_DELETE event in
delete_network in the DB core plug-in.

This also fixes an issue where we could delete the segment ID
of the l3-ha network when deleting a router, leaving all other
routers non-functioning.  Moving this to PRECOMMIT_DELETE fixes
it since it is done after we have checked that the network is
not in use and can be deleted.

Closes-Bug: #1697324
Closes-Bug: #1732543

Change-Id: I7c3c4654f183b317647a28d599a538fe460db68f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/526102/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/segments/db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/extensions/test_segment.py']",3,9dff53ce65e44a75d953ed9b6c6859184b0995a8,bug/1675910-stable/pike," def test_segment_notification_on_delete_network(self): with mock.patch.object(db, '_delete_segments_for_network') as dsn: db.subscribe() with self.network() as network: network = network['network'] self._delete('networks', network['id']) dsn.assert_called_with(resources.NETWORK, events.PRECOMMIT_DELETE, mock.ANY, context=mock.ANY, network_id=mock.ANY) ",,18,1
openstack%2Ftripleo-ci~master~I793d30da39f0021b8e3f1ae78f97484e3c60d274,openstack/tripleo-ci,master,I793d30da39f0021b8e3f1ae78f97484e3c60d274,WIP: test containers with ssl,ABANDONED,2017-09-14 15:56:53.000000000,2017-12-14 02:38:13.000000000,,"[{'_account_id': 3}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-09-14 15:56:53.000000000', 'files': ['toci-quickstart/playbooks/ovb.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ef6e099685b8f4dc261e0faf21d66c558e93fa8e', 'message': 'WIP: test containers with ssl\n\nChange-Id: I793d30da39f0021b8e3f1ae78f97484e3c60d274\nDepends-On: I32cd049bbf8ab69b79649031a4eddc042f871cb7\n'}]",0,504095,ef6e099685b8f4dc261e0faf21d66c558e93fa8e,19,5,1,10969,,,0,"WIP: test containers with ssl

Change-Id: I793d30da39f0021b8e3f1ae78f97484e3c60d274
Depends-On: I32cd049bbf8ab69b79649031a4eddc042f871cb7
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/95/504095/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/playbooks/ovb.yml'],1,ef6e099685b8f4dc261e0faf21d66c558e93fa8e,contssl,#test,,1,0
openstack%2Ftripleo-quickstart~master~I32cd049bbf8ab69b79649031a4eddc042f871cb7,openstack/tripleo-quickstart,master,I32cd049bbf8ab69b79649031a4eddc042f871cb7,DONT MERGE: test containers with SSL,ABANDONED,2017-09-14 15:55:50.000000000,2017-12-14 02:37:50.000000000,,"[{'_account_id': 3}, {'_account_id': 10873}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-09-14 15:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b373dc2d6ce4f6e1cddf7f3ebc3236e46d963147', 'message': 'DONT MERGE: test containers with SSL\n\nnothing here\n\nChange-Id: I32cd049bbf8ab69b79649031a4eddc042f871cb7\n'}, {'number': 2, 'created': '2017-09-24 16:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/44d95ccbdec7703a06a5fdf768b2d07b72a2c8da', 'message': 'DONT MERGE: test containers with SSL\n\nnothing here\n\nChange-Id: I32cd049bbf8ab69b79649031a4eddc042f871cb7\n'}, {'number': 3, 'created': '2017-09-24 20:40:28.000000000', 'files': ['config/general_config/featureset022.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a0044b8be92bb0934c3fb6948559a673f5280205', 'message': 'DONT MERGE: test containers with SSL\n\nnothing here\n\nChange-Id: I32cd049bbf8ab69b79649031a4eddc042f871cb7\nDepends-On: I90699ab92166c40ff6447060cb86fc2090aa3e7c\n'}]",0,504093,a0044b8be92bb0934c3fb6948559a673f5280205,28,6,3,10969,,,0,"DONT MERGE: test containers with SSL

nothing here

Change-Id: I32cd049bbf8ab69b79649031a4eddc042f871cb7
Depends-On: I90699ab92166c40ff6447060cb86fc2090aa3e7c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/93/504093/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset022.yml'],1,b373dc2d6ce4f6e1cddf7f3ebc3236e46d963147,contssl,ssl_overcloud: true,ssl_overcloud: false,1,1
openstack%2Ftripleo-ci~master~I8dc12f8b4642f3c775e57c801c912b5b4b8fbcea,openstack/tripleo-ci,master,I8dc12f8b4642f3c775e57c801c912b5b4b8fbcea,DNM: test newton jobs,ABANDONED,2017-11-21 13:52:13.000000000,2017-12-14 02:34:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-11-21 13:52:13.000000000', 'files': ['toci-quickstart/config/testenv/ovb-rdocloud.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a4a59af888b6a32e1f07b7c6da185b92f7cb88bd', 'message': 'DNM: test newton jobs\n\nChange-Id: I8dc12f8b4642f3c775e57c801c912b5b4b8fbcea\nDepends-On: I5504349391e9d1d5ddef31eac86976bccf93d6b3\n'}]",0,521850,a4a59af888b6a32e1f07b7c6da185b92f7cb88bd,4,1,1,10969,,,0,"DNM: test newton jobs

Change-Id: I8dc12f8b4642f3c775e57c801c912b5b4b8fbcea
Depends-On: I5504349391e9d1d5ddef31eac86976bccf93d6b3
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/50/521850/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/testenv/ovb-rdocloud.yml'],1,a4a59af888b6a32e1f07b7c6da185b92f7cb88bd,testnewton,# test,,1,0
openstack%2Fmistral~master~If47672f54e7158c9fd8f144ed69588ebed05511a,openstack/mistral,master,If47672f54e7158c9fd8f144ed69588ebed05511a,Remove the __init__ method from the test action,MERGED,2017-10-18 14:59:45.000000000,2017-12-14 02:34:12.000000000,2017-12-14 02:34:12.000000000,"[{'_account_id': 7065}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 17645}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 23317}]","[{'number': 1, 'created': '2017-10-18 14:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e1f7faf2378360de95a021d91fe4764c6e3229aa', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 2, 'created': '2017-10-18 15:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f8714829ac8a81bbe40de4b3001b224b894a9def', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 3, 'created': '2017-10-24 14:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ad0e537071f904eaa9a834c792bc24b2ed6a9a54', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 4, 'created': '2017-10-27 11:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fc6bcda895f7dbb496a4cf80f4f1fe9bf1998326', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 5, 'created': '2017-10-30 09:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a0640b5e6d0030792524f7211e1d1a1a98601086', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 6, 'created': '2017-11-03 08:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6ede6b0861cb6933b13938c21f3ef8347120adc2', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 7, 'created': '2017-11-06 10:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8bb75f0b1b75160939e51b697c35f6458021ccab', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 8, 'created': '2017-11-08 18:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ebdf19beed1f21cbc12fcda1aa0b76954c492183', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 9, 'created': '2017-11-09 09:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/62904f3ed91b3067ef91875e4d4dfe5df455f428', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 10, 'created': '2017-11-16 08:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1cffcfd1424d1b664fdefc41f074e2a74ff1a242', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 11, 'created': '2017-11-20 09:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bf25bd8802fa71c578ea3947ba2d58224c8478bb', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 12, 'created': '2017-11-27 11:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/60c25916e27cd7c97acd63224e5cd8a51836d789', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 13, 'created': '2017-11-29 11:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c84f7f1f4c71f376c27222ee58913a66573e3325', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 14, 'created': '2017-12-04 15:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bab387ee002fcfd9547aa090362ddec2fd9e0a12', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 15, 'created': '2017-12-05 10:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f8bb8d10520ae96e81ca4214abe5adf0a28566e1', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 16, 'created': '2017-12-05 14:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bc71687eb610a93e57c491d8dc19f191db4dc89f', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 17, 'created': '2017-12-07 15:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f3ebb42dbe7e9061cb3b702e16d953054747919b', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 18, 'created': '2017-12-11 22:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fa4d110968b01b3234b31301ac40d664187320c5', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}, {'number': 19, 'created': '2017-12-13 22:33:44.000000000', 'files': ['mistral/tests/unit/engine/test_action_context.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/fa5988e56ead2e4f5a676ed72186cd09b44312ac', 'message': 'Remove the __init__ method from the test action\n\nThis wont be needed once mistral-lib provides one.\n\nChange-Id: If47672f54e7158c9fd8f144ed69588ebed05511a\nDepends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e\n'}]",0,513061,fa5988e56ead2e4f5a676ed72186cd09b44312ac,65,9,19,9712,,,0,"Remove the __init__ method from the test action

This wont be needed once mistral-lib provides one.

Change-Id: If47672f54e7158c9fd8f144ed69588ebed05511a
Depends-On: I7cf9fdc9446462c7f5010d0ba8b307b05656704e
",git fetch https://review.opendev.org/openstack/mistral refs/changes/61/513061/6 && git format-patch -1 --stdout FETCH_HEAD,['mistral/tests/unit/engine/test_action_context.py'],1,e1f7faf2378360de95a021d91fe4764c6e3229aa,bug/1718353,, def __init__(self): pass ,0,3
openstack%2Ftripleo-heat-templates~stable%2Focata~I6bcad48e6d3c8e3001270f2dcc2f3425da1510d0,openstack/tripleo-heat-templates,stable/ocata,I6bcad48e6d3c8e3001270f2dcc2f3425da1510d0,"Revert ""Add upgrade task to run gnocchi upgrade""",MERGED,2017-12-13 14:50:19.000000000,2017-12-14 02:20:01.000000000,2017-12-14 02:20:01.000000000,"[{'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-13 14:50:19.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5ae96c21c7883bd949d70233af9750a8dabe0e7d', 'message': 'Revert ""Add upgrade task to run gnocchi upgrade""\n\nThis reverts commit 771189e91d50fd28d2be44d9b003ff061482b90d.\n\nChange-Id: I6bcad48e6d3c8e3001270f2dcc2f3425da1510d0\n'}]",0,527702,5ae96c21c7883bd949d70233af9750a8dabe0e7d,8,6,1,2813,,,0,"Revert ""Add upgrade task to run gnocchi upgrade""

This reverts commit 771189e91d50fd28d2be44d9b003ff061482b90d.

Change-Id: I6bcad48e6d3c8e3001270f2dcc2f3425da1510d0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/527702/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-api.yaml'],1,5ae96c21c7883bd949d70233af9750a8dabe0e7d,bug/1724328,, - name: get bootstrap nodeid tags: common command: hiera bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact tags: common set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Setup gnocchi db during upgrade tags: step5 command: gnocchi-upgrade when: is_bootstrap_node,0,11
openstack%2Fpuppet-tripleo~master~If3dffde5e0db8f7607a9708d36d54d1600fe5da8,openstack/puppet-tripleo,master,If3dffde5e0db8f7607a9708d36d54d1600fe5da8,Add neutron base profile to OVN metadata agent,MERGED,2017-12-12 17:56:39.000000000,2017-12-14 02:20:00.000000000,2017-12-14 02:20:00.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-12-12 17:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/aabc866ab68810fe7496d98762ee15fffe0d9614', 'message': 'Add logging config to OVN metadata agent\n\nThis patch is including ::neutron::logging in OVN metadata agent\nfile. This will ensure that proper logging configuration is\ngenerated for this service.\n\nChange-Id: If3dffde5e0db8f7607a9708d36d54d1600fe5da8\n'}, {'number': 2, 'created': '2017-12-13 14:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2f8a73023860df50095ff962b686be8151a0fb10', 'message': 'Add logging config to OVN metadata agent\n\nThis patch is including ::neutron::logging in OVN metadata agent\nfile. This will ensure that proper logging configuration is\ngenerated for this service.\n\nChange-Id: If3dffde5e0db8f7607a9708d36d54d1600fe5da8\n'}, {'number': 3, 'created': '2017-12-13 14:41:36.000000000', 'files': ['manifests/profile/base/neutron/ovn_metadata.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a97cc29b149b8c7539aabe9bed5762796095432a', 'message': 'Add neutron base profile to OVN metadata agent\n\nThis patch is including neutron base profile in OVN metadata agent\nfile. This will ensure that neutron configuration is also applied\nfor this service.\n\nChange-Id: If3dffde5e0db8f7607a9708d36d54d1600fe5da8\n'}]",2,527482,a97cc29b149b8c7539aabe9bed5762796095432a,16,6,3,23804,,,0,"Add neutron base profile to OVN metadata agent

This patch is including neutron base profile in OVN metadata agent
file. This will ensure that neutron configuration is also applied
for this service.

Change-Id: If3dffde5e0db8f7607a9708d36d54d1600fe5da8
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/82/527482/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/neutron/ovn_metadata.pp'],1,aabc866ab68810fe7496d98762ee15fffe0d9614,ovn-metadata-agent, include ::neutron::logging,,1,0
openstack%2Fneutron-vpnaas-dashboard~stable%2Fpike~I3d2b391fba9be6290eb245924014134fbdde717a,openstack/neutron-vpnaas-dashboard,stable/pike,I3d2b391fba9be6290eb245924014134fbdde717a,Align tox_install.sh with other projects,MERGED,2017-11-23 18:44:44.000000000,2017-12-14 01:59:07.000000000,2017-12-14 01:59:07.000000000,"[{'_account_id': 2}, {'_account_id': 841}, {'_account_id': 6547}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 18:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas-dashboard/commit/c93e433278e308c7f7fbb41a1a8e354a6cf78e6c', 'message': 'Align tox_install.sh with other projects\n\nThe tox_install.sh here behaves a bit differently than the others, which\nis causing some problems when trying to rework some of the shared gate jobs.\n\nAlign it to the form used in other repos.\n\nChange-Id: I3d2b391fba9be6290eb245924014134fbdde717a\n(cherry picked from commit d9ce89b640a057aae9c4a86389baca8ac18ef63f)\n'}, {'number': 2, 'created': '2017-12-13 16:11:20.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas-dashboard/commit/77a585cf55a4cb7b0f0f7e18885d18b3ca369412', 'message': 'Align tox_install.sh with other projects\n\nThe tox_install.sh here behaves a bit differently than the others, which\nis causing some problems when trying to rework some of the shared gate jobs.\n\nAlign it to the form used in other repos.\n\nChange-Id: I3d2b391fba9be6290eb245924014134fbdde717a\n(cherry picked from commit d9ce89b640a057aae9c4a86389baca8ac18ef63f)\n'}]",1,522636,77a585cf55a4cb7b0f0f7e18885d18b3ca369412,15,5,2,6547,,,0,"Align tox_install.sh with other projects

The tox_install.sh here behaves a bit differently than the others, which
is causing some problems when trying to rework some of the shared gate jobs.

Align it to the form used in other repos.

Change-Id: I3d2b391fba9be6290eb245924014134fbdde717a
(cherry picked from commit d9ce89b640a057aae9c4a86389baca8ac18ef63f)
",git fetch https://review.opendev.org/openstack/neutron-vpnaas-dashboard refs/changes/36/522636/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,c93e433278e308c7f7fbb41a1a8e354a6cf78e6c,pike/backport/522343,"exclude = .venv,.git,.tox,dist,*lib/python*,*egg,build,node_modules,.tmp"," os:openstack/horizon:horizonexclude = .venv,.git,.tox,dist,*lib/python*,*egg,build,node_modules",53,77
openstack%2Fkarbor~master~Ib32a9d8fd28275d8a2a89ae436506c395671262c,openstack/karbor,master,Ib32a9d8fd28275d8a2a89ae436506c395671262c,Add jsonschema validation for karbor restores API,MERGED,2017-12-12 14:11:37.000000000,2017-12-14 01:52:40.000000000,2017-12-14 01:52:40.000000000,"[{'_account_id': 17151}, {'_account_id': 21224}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/d41f07f919cb0f7989285e05bdd6d4e269d1433e', 'message': 'Add jsonschema validation for karbor restores API\n\nChange-Id: Ib32a9d8fd28275d8a2a89ae436506c395671262c\nPartial-Implements: bp karbor-json-schema-validation\n'}, {'number': 2, 'created': '2017-12-13 03:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/9f1a8a340477e4c7ed6242f74691e448f2296256', 'message': 'Add jsonschema validation for karbor restores API\n\nChange-Id: Ib32a9d8fd28275d8a2a89ae436506c395671262c\nPartial-Implements: bp karbor-json-schema-validation\n'}, {'number': 3, 'created': '2017-12-13 07:47:57.000000000', 'files': ['karbor/api/schemas/restores.py', 'karbor/tests/unit/api/v1/test_restores.py', 'karbor/api/v1/restores.py', 'karbor/services/protection/clients/cinder.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/c5ae53d58c50ef54e8dd24145add4cd9c7fbd48a', 'message': 'Add jsonschema validation for karbor restores API\n\nChange-Id: Ib32a9d8fd28275d8a2a89ae436506c395671262c\nPartial-Implements: bp karbor-json-schema-validation\n'}]",0,527408,c5ae53d58c50ef54e8dd24145add4cd9c7fbd48a,12,3,3,17151,,,0,"Add jsonschema validation for karbor restores API

Change-Id: Ib32a9d8fd28275d8a2a89ae436506c395671262c
Partial-Implements: bp karbor-json-schema-validation
",git fetch https://review.opendev.org/openstack/karbor refs/changes/08/527408/3 && git format-patch -1 --stdout FETCH_HEAD,"['karbor/api/schemas/restores.py', 'karbor/tests/unit/api/v1/test_restores.py', 'karbor/api/v1/restores.py']",3,d41f07f919cb0f7989285e05bdd6d4e269d1433e,bp/karbor-json-schema-validation,from karbor.api.schemas import restores as restore_schema from karbor.api import validation @validation.schema(restore_schema.create),,52,15
openstack%2Fnova~master~Ifc01dbf98545104c998ab96f65ff8623a6db0f28,openstack/nova,master,Ifc01dbf98545104c998ab96f65ff8623a6db0f28,Implement new attach Cinder flow,MERGED,2016-06-16 00:29:04.000000000,2017-12-14 01:41:34.000000000,2017-12-09 03:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9562}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 11536}, {'_account_id': 11904}, {'_account_id': 12408}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15905}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17292}, {'_account_id': 17386}, {'_account_id': 17920}, {'_account_id': 17922}, {'_account_id': 19741}, {'_account_id': 19930}, {'_account_id': 20040}, {'_account_id': 21784}, {'_account_id': 22348}, {'_account_id': 22752}, {'_account_id': 23317}, {'_account_id': 23498}, {'_account_id': 26490}, {'_account_id': 26515}, {'_account_id': 26576}]","[{'number': 1, 'created': '2016-06-16 00:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae46dab0c753213bbac17efb3cd26f72b39cc5ec', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 2, 'created': '2016-06-20 17:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf915b4274034947b6addd5671b8e4952b485ca4', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 3, 'created': '2016-06-20 21:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9020bfec47da2fabfc5f99db967a2ca879129dd4', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 4, 'created': '2016-06-20 23:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08a6d1787a18f75ba55517b579e22cd478153cdd', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 5, 'created': '2016-08-06 22:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9d3cfcc9031b93a56d2c8b6b2fad54b2863c116', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 6, 'created': '2016-08-26 23:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/053ac4645624cd9c76a377031fb0f3030f1bdcbf', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 7, 'created': '2016-09-27 22:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86d004330868f9c169022399805d196f7dee6813', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 8, 'created': '2016-09-28 21:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff314bad667f8498d212064dce428806392027af', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 9, 'created': '2016-10-02 18:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51c05dd36588f85555296a045b906b66c6c4ef42', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 10, 'created': '2016-10-07 22:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6382accfc8b9e31393e7f40b0c46034b4c2042e', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I90d54257862e1815a03ca8750040f7e4e6f35c0b\nDepends-On: Ib4d229778b9f691ae86fca50059cca4c0958fcf8\n'}, {'number': 11, 'created': '2017-01-05 19:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e135a83744789168dcf0543885176d13041db1f0', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: Ie15233c99d91de67279b56d27a5508c5ea98d769\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 12, 'created': '2017-01-06 20:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca9350016136096a103eb3a91b1510ee91cc18c8', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: Ie15233c99d91de67279b56d27a5508c5ea98d769\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 13, 'created': '2017-01-22 10:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca11656f6feee02d4ddbeb797b6796741b09f145', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: Ie15233c99d91de67279b56d27a5508c5ea98d769\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 14, 'created': '2017-01-22 19:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04e548322e3d1ea0faad850f925a52f9cae5a49d', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 15, 'created': '2017-01-23 20:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/429a17f905f5ff1578fb558113061ec516fa90f3', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 16, 'created': '2017-01-23 20:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb2b0fc930bfb57e3536d3e9ba4204d367c96d97', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 17, 'created': '2017-01-23 22:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/685f1deefd010f6a2ca88cce99d9d15247481d94', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 18, 'created': '2017-01-24 09:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6797f5c841418b3a0d6e666b4f49ca7bb8a08ec5', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n  * Some unit tests are failing due to the hardcoded cinderclient microversion\n    when initiating the Client.\n  * Tests are currently using the old flow as opposed to being updated to the\n    new one except one functional test, where there\'s some issue with mocking\n  * The \'connection_info\' data structure needs some rethinking as the new\n    Cinder flow removes the nested dict structure with the \'data\' section in it\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 19, 'created': '2017-01-24 09:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8276415c101dbb04d900efc3cecb668c14e345c', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n  * Some unit tests are failing due to the hardcoded cinderclient microversion\n    when initiating the Client.\n  * Tests are currently using the old flow as opposed to being updated to the\n    new one except one functional test, where there\'s some issue with mocking\n  * The \'connection_info\' data structure needs some rethinking as the new\n    Cinder flow removes the nested dict structure with the \'data\' section in it\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 20, 'created': '2017-01-27 10:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb756da1cc0c0f761a51858f8865e27d2d758b7a', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n  * Some unit tests are failing due to the hardcoded cinderclient microversion\n    when initiating the Client.\n  * Tests are currently using the old flow as opposed to being updated to the\n    new one except one functional test, where there\'s some issue with mocking\n  * The \'connection_info\' data structure needs some rethinking as the new\n    Cinder flow removes the nested dict structure with the \'data\' section in it\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 21, 'created': '2017-01-29 15:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffe263d0799e2e942f6c452055f98ba1ab2aba89', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n  * Some unit tests are failing due to the hardcoded cinderclient microversion\n    when initiating the Client.\n  * Tests are currently using the old flow as opposed to being updated to the\n    new one except one functional test, where there\'s some issue with mocking\n  * The \'connection_info\' data structure needs some rethinking as the new\n    Cinder flow removes the nested dict structure with the \'data\' section in it\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 22, 'created': '2017-01-29 15:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6508f899f9ddfec847eaccca6851355980e745f', 'message': 'Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\n\nnova volume-attach works with the new Cinder API, no errors in the logs\nand the volume is shown as attached on both sides. Using the old flow\nfor detach detaches the volume. Other operations are not manually tested.\n\nTODO:\n  Figure out what\'s up with the brick/privsep error on unshelve\n  Figure out data structure of \'connection_info\' as now it\'s modified\non the driver level and that should not be correct...\n\nLots of details to address here, but this is a quick POC\nto show a new workflow using Cinder create/remove attachment.\n\nGoal of this patch was just to make this work for the standard\nattach/detach path.  Still has a few places that need updated,\nalso we\'ll want to add some things on Cinder\'s side like a\nrefresh connection_info (rather than calling initialize_connection).\n\nCurrently we still use reserve etc, but we consolidate\ninitialize_connection and attach calls into a single\n""create_attachment"" call.\n\nSame with terminate and destach, we combine those into a single\n""remove_attachment"" call.\n\nThings that need to be done:\n* Clearly there are quite a few places we still need to update (or we can leave\nthem calling the old mechanism).  The good thing about this approach is it\'s\nnot a BigBang change, we can keep using old methods at the same time.\n\n* Take a look at the cleanup of connections (ie rm /dev/disk-by-path) and\n  use either the return from list_attachments, or remove_attachment to\n  determine if/when we should delete that connection (think multi-attach)\n\n* API micro-versioning?\n\n* Unit tests of course\n  * Some unit tests are failing due to the hardcoded cinderclient microversion\n    when initiating the Client.\n  * Tests are currently using the old flow as opposed to being updated to the\n    new one except one functional test, where there\'s some issue with mocking\n  * The \'connection_info\' data structure needs some rethinking as the new\n    Cinder flow removes the nested dict structure with the \'data\' section in it\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\nDepends-On: I2c463f0910b6c9e37502869b7ec33073f12939f1\n'}, {'number': 23, 'created': '2017-01-31 23:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db16cefac93f465823156cb69be9901f860cd7b1', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 24, 'created': '2017-02-01 00:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2a3b64b33b6515e2062c1bb84eee48ff2f4538d', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 25, 'created': '2017-02-01 16:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/172fe5c0ca0d77ff70a9722478971c5f048b6a59', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 26, 'created': '2017-02-24 16:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df9ba58e6508e4b3acc22c5c7c5a90fe849f486d', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 27, 'created': '2017-02-24 16:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1a9320cccfdcff9ff29999765dfd6fea5e0bcb1', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 28, 'created': '2017-02-24 17:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43e47c25b5464a84e73aa66c879d68de3c74ca54', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 29, 'created': '2017-02-25 21:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2865139f994b14d21fe029a14146b9669873257c', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 30, 'created': '2017-02-25 21:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b72d9a15e9a76a925034acf904f5fb11c91f7fd', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 31, 'created': '2017-02-25 21:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f61a8176294693dbc41e7e01c329b5282ee96ac', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 32, 'created': '2017-02-25 23:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a39a87436c04cd16503b802288f18ac59ca6351', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 33, 'created': '2017-02-26 00:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2dbfdf8e45c03538077707047cf103439f5043ea', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 34, 'created': '2017-02-26 18:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de95c628a39a188bdb1f8680fb91e912ae2c6881', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 35, 'created': '2017-02-27 01:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5b9bd8c34bd785652db7d2425c0aaf63483fd3c', 'message': ""Implement new attach/detach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach/detach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 36, 'created': '2017-04-26 15:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37f4e46b5c329ab1863c3b215251f8a99cbf5655', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 37, 'created': '2017-05-24 22:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a87bc581de45c2fdc45befb87c4f36a162561117', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 38, 'created': '2017-05-25 01:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d74d21a997b743817bebac4028bb2791e0624931', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nReset on this effort, the modified/updated changes have landed in\nCinder, so this adds a great big rebase, and gets at least the base\ncase of attach working with the new Cinder API's.\n\nIt's still some really ugly code, and there's a lot of details to be\ndealt with, but we can start moving forward again I think.\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 39, 'created': '2017-05-25 23:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/359b102d986f1154c3113eae4d3b8d42977b1e12', 'message': 'WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 40, 'created': '2017-05-26 18:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b370f389da8a00ceaed04aaae3deeb39be030ee', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 41, 'created': '2017-05-26 18:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52705aa6bfe0dc778e2448baeac6bc26ac083eff', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 42, 'created': '2017-05-26 19:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d1fbae5d2caac463a42f26b4fef9569722afbfc', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 43, 'created': '2017-05-30 15:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edc2aa5b1fe6a6d5b4be31cacd920601af5093c3', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 44, 'created': '2017-05-30 16:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d3ecfe485654051fe42c154135d89b9fbb3937c', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 45, 'created': '2017-06-01 17:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d24cb9c23b121184bff05f503be15ede7882afb0', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 46, 'created': '2017-06-02 00:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a9465d2c8d42390c10e2de61c34e5d6480eb2cd', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 47, 'created': '2017-06-08 14:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c26b2b3b6a3d070bb3040454c4a02e624d253415', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 48, 'created': '2017-06-09 03:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b521e7db391a98fcec369aa3d9552e38a5b0dd21', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 49, 'created': '2017-06-09 18:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebe267929bc92e2b4f211ba3c838cd62feab24db', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 50, 'created': '2017-06-12 23:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/729b353a33d1a9d366e8bb18833bd5c2f3afb76d', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 51, 'created': '2017-06-15 16:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27f36ac23056a0d324cdcddc477954f5fa8dd883', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 52, 'created': '2017-06-22 08:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43ca28571ceb71150edd745068f4bef45357d28c', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 53, 'created': '2017-06-22 08:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46406f172839520be9857d00554339623f7d5978', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 54, 'created': '2017-06-22 12:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a19b1b1d34a51b4bf91e55d14dc77ed9beeddf5e', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 55, 'created': '2017-06-22 15:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a5cdbea0e069b1e973591e832e64901a3c2cc06', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 56, 'created': '2017-06-22 22:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9bcda6ff854b8eddf7432d920e5f839beea3135', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 57, 'created': '2017-06-23 05:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fba5cf4267f61a5ad9f9133bbb6123fc9ab77991', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 58, 'created': '2017-06-23 12:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa34ffc7cefa9bd7d3d42f1742ed01119aa0b6a0', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 59, 'created': '2017-06-23 16:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56333d7609c05f992c9e5b03bd945e9d4af30225', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 60, 'created': '2017-06-23 18:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18114f86cccd9c36001d07592510da078a6f629e', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I66999e999f7d307edb25f62ef31730b4f90be0d3\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 61, 'created': '2017-06-26 16:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0103c8058cd5cfe1c53d8d9bb9afc714688e711e', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I66999e999f7d307edb25f62ef31730b4f90be0d3\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 62, 'created': '2017-06-26 16:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1d9fa39b714c9ad82056a4e5b635d851cb756a6', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I66999e999f7d307edb25f62ef31730b4f90be0d3\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 63, 'created': '2017-06-26 18:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3b9ddc13fd986a9eb31c3139e15ce43425184ca', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I66999e999f7d307edb25f62ef31730b4f90be0d3\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 64, 'created': '2017-06-27 20:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56400e2991e996270f650e545a6764eda75631e3', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I66999e999f7d307edb25f62ef31730b4f90be0d3\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 65, 'created': '2017-06-27 22:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66800db636f4704b0aed20206911e631afdbb899', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I66999e999f7d307edb25f62ef31730b4f90be0d3\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 66, 'created': '2017-06-27 23:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a553b61ea86410c2024ddd10bb3c61b41d564d39', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 67, 'created': '2017-06-28 06:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d124a41d50a0e5626f088cf6333c71246e658117', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 68, 'created': '2017-06-28 15:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ba5dd816fb33e1a007abe9164bdfb93abd5e886', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 69, 'created': '2017-06-28 20:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/620e1bcc7033c32ae9bd9e692d8183d1c15c36e5', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 70, 'created': '2017-06-28 22:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d807e43cada7fe921a3097e84944e34317ee8e81', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 71, 'created': '2017-06-29 07:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/040abe33c00cbc83ab914a6d363c7dc83da1bd72', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 72, 'created': '2017-06-29 10:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78e2432c273eca4f7e0d5ff61f789d28c0c015d8', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 73, 'created': '2017-06-29 13:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/064ebaf8f9651eaf557df713e09162693f208559', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 74, 'created': '2017-06-29 19:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d30a40528bfed8787b6725c3bced3f0360b396d', 'message': ""WIP/POC Implement new attach Cinder flow\n\n***************** WIP/POC ********************\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).\n\nTested this using V3 and V2 for the base secondary attach\ncases.\n\nI'd like to propose again that we consider a new API call\nat least for detach.  Rather than calling the old\n`nova volume-detach <instance> <volume>` we should\nconsider moving straight to a `nova attachment-delete <attachment-id>`.\n\nWe'll want this for multi-attach anyway (if we want to simplify things),\nand we should also consider the same thing for attachment as well.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 75, 'created': '2017-06-29 23:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fe42e8426a36ceeee37dedd2694e8abce91401b', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 76, 'created': '2017-06-30 19:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/853ffa0f86faba8ab132731340e82a1b40260b3b', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 77, 'created': '2017-06-30 19:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/497a1542e0fbf93e6adf5976698e64d7970ef57d', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 78, 'created': '2017-06-30 19:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ed4bf56221f143ca57666c16d6ecacbda7f309a', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 79, 'created': '2017-07-03 13:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed47704798d44487915dbca342705c75a93e246d', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 80, 'created': '2017-07-03 13:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7145a654f920bd2d982eba5c706fc95aca066c8', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 81, 'created': '2017-07-03 15:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/206f05bcd74cf1b737031a5dd9f24988a43532d0', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 82, 'created': '2017-07-03 22:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39ca5b7f1570a505c75946af9a3f82ed31113e62', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 83, 'created': '2017-07-04 11:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37245355acfc6f8e511ed64bd888a14000c2bdde', 'message': 'WIP/POC Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using cinders new Attach API.\n\nThis requires the os-brick patch to cast lun-id to int\n(should merge shortly).  All Tempest tests with the\nexeption of live-migrate should be passing now once\nthe os-brick and tempest changes are merged.  It would\nbe great to get those landed and do some fresh testing.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n'}, {'number': 84, 'created': '2017-07-04 21:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad8443918baad57826f989b1002cd5ddca026221', 'message': ""Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using Cinder's new Attach API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 85, 'created': '2017-07-04 21:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25add0fe2cbfddbf2696654dda9b1f3635112beb', 'message': ""Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using Cinder's new Attach API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 86, 'created': '2017-07-05 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0ef8f795390b36337823311eb85bc85062fc6c8', 'message': ""Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using Cinder's new Attach API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 87, 'created': '2017-07-07 05:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47e786bec56683d195f03129375c7fcc247ac093', 'message': ""Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using Cinder's new Attach API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 88, 'created': '2017-07-07 07:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/552ee3564fe9b89ec7d337426172889d1d18d29f', 'message': ""Implement new attach Cinder flow\n\nAdd implementation of the standard secondary volume\nattachment using Cinder's new Attach API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 89, 'created': '2017-07-07 17:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ff098303c45d7376131e080a884912b177f20ad', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 90, 'created': '2017-07-08 00:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a04ca7881a24cb0762f93b73fe079b8cb19588b8', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 91, 'created': '2017-07-08 16:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ed4a03bcff42246a68f05046bc235045b431fbc', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 92, 'created': '2017-07-20 14:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bcf6f7151a287ebaa895cc148ec6ff4acf4f1ac6', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 93, 'created': '2017-07-20 15:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cd8af5f20727cf6573f94a5fc3eaf1db74d8f93', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 94, 'created': '2017-07-20 16:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8fcce8cf935f69dd16b0c60e455ae9747adb5a7', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 95, 'created': '2017-07-20 18:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/29d326f255c0e6e655fffa50951026dc7e8e4060', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 96, 'created': '2017-07-20 22:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45bf1a844b8870ee5f6155475fc0374378c47b87', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 97, 'created': '2017-07-21 09:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8c09f1776fc902fe135f78aaddcb680435c1f53', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 98, 'created': '2017-07-21 18:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9705be4438cadfd23e44e42872c2e67b9ca5d365', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 99, 'created': '2017-07-21 18:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b0a44e051f8b5a11496fafa0a29152c6343ecb0', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 100, 'created': '2017-07-21 20:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3c9e07c7c5f0ec058dea38f1bc5c31d6610296a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 101, 'created': '2017-07-22 17:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/724e15a64c6708609bc8cb73c1e84bc58ec2cbc4', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 102, 'created': '2017-07-23 13:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d4db8c07cae80849be7cafb0de0e494ada28a4c', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 103, 'created': '2017-07-23 17:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfec32e4a4c87d2e10c2623c49a446996a3e9deb', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 104, 'created': '2017-07-24 09:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a09f5f0ccc4ab854683b13634c06fcfb092bd19e', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 105, 'created': '2017-07-25 21:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/036db832cfee43b9620b70bf0bcf6a4097dae1ab', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 106, 'created': '2017-07-26 01:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fef071b087bb40aca3c9193990d50b0df6d9af42', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 107, 'created': '2017-08-01 13:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6402a8b949828045023a2abbe7389015d5c12d22', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 108, 'created': '2017-08-01 19:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a8ffe172686d273f3773edd65a0a6695e93a304', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 109, 'created': '2017-08-01 19:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19e8c0773c7a20983fb829b3805b1956aca3a501', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 110, 'created': '2017-08-02 14:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13d7a8ea200ed71ba60852ce9503c7e2e70b2dad', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\nDepends-On: I9acf6dc84c32b25bfe3254eb0f97248736498d32\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 111, 'created': '2017-08-02 16:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb56dcb8f09c6ea3c52491c25693e0a4d2f9d1a0', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\nDepends-On: I9acf6dc84c32b25bfe3254eb0f97248736498d32\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 112, 'created': '2017-08-02 16:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9a74a5748fc69201eced564a13ecd6cd31c8821', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 113, 'created': '2017-08-02 16:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80eb1774d5dffa8b3562445df2ac7d2354c4a2ba', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\nDepends-On: I9acf6dc84c32b25bfe3254eb0f97248736498d32\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 114, 'created': '2017-08-12 18:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/210e7c65826426a8d9654935c44b8912d3ff67dc', 'message': ""WIP - Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 115, 'created': '2017-08-12 18:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68dc8d99cdc3af82fe93993633bc12d645cac02c', 'message': ""WIP - Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 116, 'created': '2017-08-13 18:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/382b407a43437652af34242183bc15fe8f067c37', 'message': ""WIP - Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 117, 'created': '2017-08-14 14:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10e35918f3c1aad5fa81b9786bf093c76229ed82', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 118, 'created': '2017-08-15 15:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15ac128ee929f885a6180c39605942f784374c67', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 119, 'created': '2017-08-15 22:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6462abb449c272b2737fba96406150e6cb1420ab', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 120, 'created': '2017-08-16 16:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e7b30a7b1c29e3b63cc1da8a296e70e4891fbd8', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 121, 'created': '2017-08-16 16:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8238c7eeee230d04dbe95f2459fac1959a8dc45b', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.27\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 122, 'created': '2017-08-16 21:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb954579f5145f0dd607455cb44ae8c44f00f76f', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 123, 'created': '2017-08-16 21:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a67092d34592404027b275c5438906cad693fb1', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 124, 'created': '2017-08-17 12:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2c419fc9ab913a2a6622dc6249a64afbf960f02', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.27 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 125, 'created': '2017-08-17 12:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90e343192a2ebdadc7d56e92c2488bb32c474f2a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 126, 'created': '2017-08-17 17:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a130329bde8db9442bd7abe6707b5c231604333', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 127, 'created': '2017-08-30 14:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70554834975d3d1312022cef79aebfbd491dc68e', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 128, 'created': '2017-08-30 15:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bfdcbdd29f85c65c0f3b88a7409de087e801d63', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 129, 'created': '2017-09-04 06:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7112272a09da60c75d9720f5a45b262a9849efb1', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 130, 'created': '2017-09-05 15:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6d43381c24254cfe548df5b73e6c63ea7f64a70', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 131, 'created': '2017-09-05 16:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2f1c06e7000fe6db88a44d03b086d4fc70c9f78', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: Ia84f4325ddb0080521241ace26f89d1161db9dca\nDepends-On: Ib448f0548739cd42edf03eab07f305b3ac184d8f\nDepends-On: I880157c72d40024f9a4aa4f288d583d1f1468641\nDepends-On: Ica4d718b3de31c31da047f07c5154b242e122596\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ic94741bced43fc1094b44711adb6eb2f74176b16\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 132, 'created': '2017-09-06 19:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/949726ef37d344cc6f8af1295d09a39b00771245', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 133, 'created': '2017-09-07 03:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bbc14e0afa640334611d1f3dbe76ac02f76b2ce', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 134, 'created': '2017-09-07 22:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b5438de6aed9423403726ea1763bd301f5e7bed', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 135, 'created': '2017-09-07 22:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37081c08d4506a63c8b675eb53c9267ca2854bb8', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 136, 'created': '2017-09-13 03:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55edec6acb9202f0808f074e74a5d5ebcdd3872b', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 137, 'created': '2017-09-14 22:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02f9671129f87e3cd58e52c58867f09205afe668', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 138, 'created': '2017-09-15 17:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4bda75388281162af5b6f6fd72787af708a73b8', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I8062897bd3d4fe20de9a5660eac6fec856cc3c1e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 139, 'created': '2017-09-16 17:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4cc5177304ba3c794d5004fd24ad48f5504170f', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 140, 'created': '2017-09-16 19:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/87217cce1f1643d141224649f09b284fa7a1712a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 141, 'created': '2017-09-16 19:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0c79fa0018c1094a4e9e875f774424795f641f0', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 142, 'created': '2017-10-10 07:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45e5651fef7a185543e26d0f42f4630a508d849a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 143, 'created': '2017-10-10 08:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4db01e578894e35d038ef296a0cb0511b1c4456', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 144, 'created': '2017-10-10 09:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba7b2390a43917dbf0bc79e5d93aea984fd12066', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 145, 'created': '2017-10-11 15:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b193074d3103a9b53a2504ae22ae0b2a5ca8760', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 146, 'created': '2017-10-17 14:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa203dcb02642c86be8c76045aae070237b43387', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 147, 'created': '2017-10-20 16:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11149e29bce35463049f5fdd91a50afd618f97c2', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 148, 'created': '2017-10-20 19:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aed1a263ab491d75004a711f545fe470fcb2c844', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 149, 'created': '2017-11-20 23:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b5940c34aaebeab683c5db9dcea0598b111f269', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 150, 'created': '2017-11-21 15:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/192133c04b11befed48e431c20de852811d8dd98', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 151, 'created': '2017-11-22 03:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7663a9eafacb4c4834538334e74fcaca058587e4', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 152, 'created': '2017-11-22 07:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/727fd990e316c9cc8d6a7042dfaf4e51f3fed992', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 153, 'created': '2017-11-22 09:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a99c61fe47e2880212c191cd51fed9e539adbaba', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\n\nDepends-On: I0bfb11296430dfffe9b091ae7c3a793617bd9d0d\nDepends-On: Ibe5dbdc4644ec812f0435f59319666fc336c195a\nDepends-On: I5545d0807626b353ca723ab1f125fd1f94bcef2e\n\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 154, 'created': '2017-11-23 02:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b55af53ab08ae714ec2769ca54c95c855d6c0b7d', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 155, 'created': '2017-11-23 05:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db64e26e4b2629b259dc0e0360a2e8fdf20f6adc', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 156, 'created': '2017-11-23 12:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0594de9dac469122bede17f014cc9ea81e0aa17', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 157, 'created': '2017-11-23 12:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d15badaa1a1799b8a99f173261cfcf67a976efa', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 158, 'created': '2017-11-23 12:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7d6c33259b3309e9ee8b059b3571e190b1c7681', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 159, 'created': '2017-11-23 19:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b7d151e8d7bd67481a432583b0eb86cc6485b8a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 160, 'created': '2017-11-23 20:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2952cc8174d228398572e7cc635011e00381fba2', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 161, 'created': '2017-11-23 20:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59d190b656579ccdd753a15e43c4253011584449', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 162, 'created': '2017-11-24 05:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3edacba45deea8aaa7bf4f8e586cefaae6dd6dfc', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 163, 'created': '2017-11-24 07:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4dd6063edc4e1484bc581aba9888999e04b73c0a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 164, 'created': '2017-11-30 17:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7124183f99fc972911afdbcd8666e73fb9d7b320', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 165, 'created': '2017-12-01 08:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/507e58841f89de9b99209de7af4d2788783ba1ed', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 166, 'created': '2017-12-02 15:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/725cd1c4e923f6d86b486edf31fae8e65d827c3a', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 167, 'created': '2017-12-05 14:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3b1d3863b5faee997e272e55b80f9bc176c5989', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 168, 'created': '2017-12-05 15:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95809446f766d1ea8428bdea129d184e6fe085ac', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 169, 'created': '2017-12-05 15:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71ed107f366a0025dc3a9bc2a401c2b1f65442ba', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 170, 'created': '2017-12-05 20:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccd0044d219176475adf6255e817a432785b6774', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 171, 'created': '2017-12-05 23:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90e23b3e6c76b79c44866003b428ec8823fabd0d', 'message': ""WIP: Implement new attach Cinder flow\n\nTODO: need to split out the block_device.py changes\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 172, 'created': '2017-12-05 23:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c97e71f2b688d0649676abf5c60dc28cc5e4d8b', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 173, 'created': '2017-12-06 20:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7130d6e9af73f0823baa9aab2e3ca9d92ceaffe', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 174, 'created': '2017-12-06 21:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c4e6fc40f6ea425d616bc4bd5388ab63efef5d4', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 175, 'created': '2017-12-07 02:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f6562ffb9c01453f6e6b83cf4c8b314c7cc062d', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}, {'number': 176, 'created': '2017-12-07 15:33:19.000000000', 'files': ['releasenotes/notes/bp-cinder-new-attach-apis-eca854e27a255e3e.yaml', 'nova/objects/service.py', 'nova/volume/cinder.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1732947.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/fixtures.py', 'nova/tests/functional/regressions/test_bug_1675570.py', 'nova/tests/functional/api_sample_tests/test_volumes.py', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d70d6adf9c902f0a9f1735ef90d992cbc0dcb46', 'message': ""Implement new attach Cinder flow\n\nThis change integrates support of the Cinder 3.44\nvolume attachment API.\n\nThe patch bumps the compute service version to\ncheck whether all the compute nodes are upgraded to the\nversion that can handle attach and detach with the new\nflow.\n\nTo enable the new flow we also need the 3.44 or higher\nmicroversion from Cinder. We check that in the API and\nif it's not available we fall back to the old\nattach/detach flow.\n\nCo-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>\n\nPartially Implements: blueprint cinder-new-attach-apis\nChange-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28\n""}]",489,330285,6d70d6adf9c902f0a9f1735ef90d992cbc0dcb46,1874,48,176,2243,,,0,"Implement new attach Cinder flow

This change integrates support of the Cinder 3.44
volume attachment API.

The patch bumps the compute service version to
check whether all the compute nodes are upgraded to the
version that can handle attach and detach with the new
flow.

To enable the new flow we also need the 3.44 or higher
microversion from Cinder. We check that in the API and
if it's not available we fall back to the old
attach/detach flow.

Co-Authored-By: Ildiko Vancsa <ildiko.vancsa@gmail.com>

Partially Implements: blueprint cinder-new-attach-apis
Change-Id: Ifc01dbf98545104c998ab96f65ff8623a6db0f28
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/330285/83 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/volume/cinder.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/virt/block_device.py']",5,ae46dab0c753213bbac17efb3cd26f72b39cc5ec,bp/multi-attach-volume," def _cleanup_failed_attach(self, context, volume_api, volume_id, connector, instance_uuid, mount_device): try: volume_api.remove_attachment(context, volume_id, connector, instance_uuid, mount_device) except Exception: # TODO(jdg): Might need to be more selective, but we expect to have # cases like 'AttachmentNotFound', that's ok, we just want to make # sure we clean up anyting from a failed attach on the Cinder side # and put the volume back in a usable state. pass try: attach_info = volume_api.create_attachment(context, volume_id, connector, instance.uuid, self['mount_device']) except Exception: with excutils.save_and_reraise_exception(): self._cleanup_failed_attach(context, volume_id, volume_api, connector, instance.uuid, self['mount_device']) if 'serial' not in attach_info: attach_info['serial'] = self.volume_id self._preserve_multipath_id(attach_info) context, volume_api, volume_id, attach_info) context, attach_info, instance, self._cleanup_failed_attach(context, volume_api, volume_id, connector, instance.uuid, self['mount_device']) self['connection_info'] = attach_info # TODO(jdg): Add a refresh_connection_info on the Cinder side and # remove this hacked call to initialize_connection"," connection_info = volume_api.initialize_connection(context, volume_id, connector) if 'serial' not in connection_info: connection_info['serial'] = self.volume_id self._preserve_multipath_id(connection_info) context, volume_api, volume_id, connection_info) context, connection_info, instance, volume_api.terminate_connection(context, volume_id, connector) self['connection_info'] = connection_info if self.volume_size is None: self.volume_size = volume.get('size') mode = 'rw' if 'data' in connection_info: mode = connection_info['data'].get('access_mode', 'rw') if volume['attach_status'] == ""detached"": # NOTE(mriedem): save our current state so connection_info is in # the database before the volume status goes to 'in-use' because # after that we can detach and connection_info is required for # detach. self.save() try: volume_api.attach(context, volume_id, instance.uuid, self['mount_device'], mode=mode) except Exception: with excutils.save_and_reraise_exception(): if do_driver_attach: try: virt_driver.detach_volume(connection_info, instance, self['mount_device'], encryption=encryption) except Exception: LOG.warning(_LW(""Driver failed to detach volume "" ""%(volume_id)s at %(mount_point)s.""), {'volume_id': volume_id, 'mount_point': self['mount_device']}, exc_info=True, context=context, instance=instance) volume_api.terminate_connection(context, volume_id, connector) # Cinder-volume might have completed volume attach. So # we should detach the volume. If the attach did not # happen, the detach request will be ignored. volume_api.detach(context, volume_id)",124,56
openstack%2Fzun~master~I091a05078001c7e649afdaf21505e1ed2614da6b,openstack/zun,master,I091a05078001c7e649afdaf21505e1ed2614da6b,Apply security group when attach network,MERGED,2017-12-12 11:02:20.000000000,2017-12-14 01:36:30.000000000,2017-12-14 01:36:30.000000000,"[{'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 12860}, {'_account_id': 17812}, {'_account_id': 22348}, {'_account_id': 22406}, {'_account_id': 23317}, {'_account_id': 25660}]","[{'number': 1, 'created': '2017-12-12 11:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/0ec9e329118a58541faf373fa5572fbcc9de5118', 'message': ""Apply security group when attach network\n\nFix bug: when attach new network on a container which has add\na security group before, security group doesn't apply\non new port.\n\nChange-Id: I091a05078001c7e649afdaf21505e1ed2614da6b\n""}, {'number': 2, 'created': '2017-12-13 02:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8021f8b24b62e6343d3eb620573286f496981528', 'message': ""Apply security group when attach network\n\nFix bug: when attach new network on a container which has add\na security group before, security group doesn't apply\non new port.\n\nChange-Id: I091a05078001c7e649afdaf21505e1ed2614da6b\nCloses-bug: bug/527369\n""}, {'number': 3, 'created': '2017-12-13 06:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/e5f852113a92a85e8747616dbd3e1d83303c640c', 'message': ""Apply security group when attach network\n\nWhen attach new network on a container which has add\na security group before, security group doesn't apply\non new port.\n\nChange-Id: I091a05078001c7e649afdaf21505e1ed2614da6b\nCloses-bug: bug/1737693\n""}, {'number': 4, 'created': '2017-12-13 06:33:26.000000000', 'files': ['zun/container/docker/driver.py', 'zun/tests/unit/container/docker/test_docker_driver.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/7fb703a03ea7f99c7d4536081cf99dedffb2b813', 'message': ""Apply security group when attach network\n\nWhen attach new network on a container which has add\na security group before, security group doesn't apply\non new port.\n\nChange-Id: I091a05078001c7e649afdaf21505e1ed2614da6b\nCloses-bug: #1737693\n""}]",4,527369,7fb703a03ea7f99c7d4536081cf99dedffb2b813,18,8,4,17812,,,0,"Apply security group when attach network

When attach new network on a container which has add
a security group before, security group doesn't apply
on new port.

Change-Id: I091a05078001c7e649afdaf21505e1ed2614da6b
Closes-bug: #1737693
",git fetch https://review.opendev.org/openstack/zun refs/changes/69/527369/4 && git format-patch -1 --stdout FETCH_HEAD,"['zun/container/docker/driver.py', 'zun/tests/unit/container/docker/test_docker_driver.py']",2,0ec9e329118a58541faf373fa5572fbcc9de5118,bug/1737693," @mock.patch('zun.common.utils.get_security_group_ids') @mock.patch('zun.network.kuryr_network.KuryrNetwork' '.connect_container_to_network') @mock.patch('zun.network.kuryr_network.KuryrNetwork' '.disconnect_container_from_network') @mock.patch('zun.network.kuryr_network.KuryrNetwork' '.list_networks') def test_network_attach_with_security_group(self, mock_list, mock_disconnect, mock_connect, mock_get_sec_group_id): test_sec_group_id = '84e3a4c1-c8cd-46b1-a0d9-c8c35f6a32a4' mock_container = mock.MagicMock() mock_container.security_groups = ['test_sec_group'] mock_list.return_value = {'network': 'network'} mock_get_sec_group_id.return_value = test_sec_group_id requested_network = [{'network': 'network', 'port': '', 'v4-fixed-ip': '', 'v6-fixed-ip': ''}] self.driver.network_attach(self.context, mock_container, 'network') mock_connect.assert_called_once_with(mock_container, 'network-fake_project', requested_network[0], security_groups=test_sec_group_id) ",,31,1
openstack%2Fkolla~master~I72d1d1c10cbc4c5fe0907e395b6d7c969353dff8,openstack/kolla,master,I72d1d1c10cbc4c5fe0907e395b6d7c969353dff8,debian: use stretch-backports by default,MERGED,2017-12-13 15:55:25.000000000,2017-12-14 01:03:50.000000000,2017-12-14 01:03:49.000000000,"[{'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-12-13 15:55:25.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/288289a7ca71f02964087a1923d6296d1a121773', 'message': 'debian: use stretch-backports by default\n\nFor some images (like rabbitmq) we may need packages from\nstretch-backports repository.\n\nEnabling backports does not mean that we use those packages - they have\nto be specified by hand.\n\nChange-Id: I72d1d1c10cbc4c5fe0907e395b6d7c969353dff8\n'}]",0,527726,288289a7ca71f02964087a1923d6296d1a121773,12,4,1,24072,,,0,"debian: use stretch-backports by default

For some images (like rabbitmq) we may need packages from
stretch-backports repository.

Enabling backports does not mean that we use those packages - they have
to be specified by hand.

Change-Id: I72d1d1c10cbc4c5fe0907e395b6d7c969353dff8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/26/527726/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,288289a7ca71f02964087a1923d6296d1a121773,to-merge/debian-backports," 'debian': 'stretch-backports', 'debian': 'stretch-backports',"," 'debian': 'stretch', 'debian': 'stretch',",2,2
openstack%2Fnova~master~Ic7dd6480a4b250ae6529d94ee0386b5e95b0ca04,openstack/nova,master,Ic7dd6480a4b250ae6529d94ee0386b5e95b0ca04,Add instance action db and obj pagination support.,MERGED,2017-12-07 14:49:24.000000000,2017-12-14 00:59:01.000000000,2017-12-14 00:59:01.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 20722}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-12-07 14:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e251190d743b2f3f0e10343ba19a13cd93f2495', 'message': 'Add instance action db and obj pagination support.\n\nThis will be used by instance action pagination API.\n\nAdd limit/marker/filters support to get_by_instance_uuid of\nInstanceActionList object, also add limit/marker/filters support to\nactions_get method of db.\n\nPart of blueprint pagination-add-changes-since-for-instance-action-list\n\nChange-Id: Ic7dd6480a4b250ae6529d94ee0386b5e95b0ca04\n'}, {'number': 2, 'created': '2017-12-08 01:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b81c86caf958e13f79348391c42008307691dc93', 'message': 'Add instance action db and obj pagination support.\n\nThis will be used by instance action pagination API.\n\nAdd limit/marker/filters support to get_by_instance_uuid of\nInstanceActionList object, also add limit/marker/filters support to\nactions_get method of db.\n\nPart of blueprint pagination-add-changes-since-for-instance-action-list\n\nChange-Id: Ic7dd6480a4b250ae6529d94ee0386b5e95b0ca04\n'}, {'number': 3, 'created': '2017-12-11 16:02:01.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_instance_actions.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_instance_action.py', 'nova/tests/functional/api_sample_tests/test_instance_actions.py', 'nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py', 'nova/objects/instance_action.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1950537a53c8dcb4d98cf71708c071eda1d954c2', 'message': 'Add instance action db and obj pagination support.\n\nThis will be used by instance action pagination API.\n\nAdd limit/marker/filters support to get_by_instance_uuid of\nInstanceActionList object, also add limit/marker/filters support to\nactions_get method of db.\n\nPart of blueprint pagination-add-changes-since-for-instance-action-list\n\nChange-Id: Ic7dd6480a4b250ae6529d94ee0386b5e95b0ca04\n'}]",3,526422,1950537a53c8dcb4d98cf71708c071eda1d954c2,87,15,3,20722,,,0,"Add instance action db and obj pagination support.

This will be used by instance action pagination API.

Add limit/marker/filters support to get_by_instance_uuid of
InstanceActionList object, also add limit/marker/filters support to
actions_get method of db.

Part of blueprint pagination-add-changes-since-for-instance-action-list

Change-Id: Ic7dd6480a4b250ae6529d94ee0386b5e95b0ca04
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/526422/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_instance_action.py', 'nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py', 'nova/objects/instance_action.py']",6,1e251190d743b2f3f0e10343ba19a13cd93f2495,bp/pagination-add-changes-since-for-instance-action-list," # Version 1.1: get_by_instance_uuid added pagination and filters support VERSION = '1.1' def get_by_instance_uuid(cls, context, instance_uuid, limit=None, marker=None, filters=None): db_actions = db.actions_get( context, instance_uuid, limit, marker, filters)"," # InstanceAction <= version 1.1 VERSION = '1.0' def get_by_instance_uuid(cls, context, instance_uuid): db_actions = db.actions_get(context, instance_uuid)",95,15
openstack%2Fzaqar~master~I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b,openstack/zaqar,master,I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b,Support delayed queues for redis,MERGED,2017-10-18 06:27:26.000000000,2017-12-14 00:58:50.000000000,2017-12-14 00:58:50.000000000,"[{'_account_id': 6484}, {'_account_id': 15054}, {'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}]","[{'number': 1, 'created': '2017-10-18 06:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e15058117fad8f2735bd821fa00e6e4c28d4f117', 'message': 'Support delayed queues for redis\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 2, 'created': '2017-10-18 06:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bcbf6d902ecfbc5db600430f6d6448cb8a243a52', 'message': 'Support delayed queues for redis\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 3, 'created': '2017-10-18 07:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c01d487402b3a05beeeaa0521dd3fc15309f93f6', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 4, 'created': '2017-10-18 08:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/47169152a48056139271927d5c0e49c29c6f6a53', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 5, 'created': '2017-10-18 11:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/44a35895d3cbe15e2bcd1faba8fab0b24374c649', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 6, 'created': '2017-10-19 06:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/de3ddfe08526a532e19a7cbd3b8ddb48bb0ab576', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 7, 'created': '2017-10-19 07:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/532ae3c1ccc00527fc9768b3c048025823fc9407', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 8, 'created': '2017-10-19 12:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d8313ffafe629f1405e328e43b9a041faf9d1d86', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 9, 'created': '2017-10-20 02:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e6b61e53d811c25e88f4a9bae24a1309e6d1310c', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 10, 'created': '2017-10-20 04:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6996d70f372adc89de74c3d31cbe01e5aed5fc39', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 11, 'created': '2017-10-20 07:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c1706e82781fd0b9e08e713e6bfa954fe0be6a90', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 12, 'created': '2017-10-20 16:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0d8a69bf2a1ddbe2f5f5404a5f39c5069ba0f492', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 13, 'created': '2017-10-21 04:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/af8726d6769d9be5fcd046bbc7b1e9bf4594439c', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 14, 'created': '2017-10-23 02:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/db4802feec1bc417078193123776641bf63af50d', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 15, 'created': '2017-10-27 08:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0cc47fac43b6e804fa95a32dad04f631cc15bd6e', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 16, 'created': '2017-10-28 08:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d48d92fde647f324db1b1a9189ce5a664fa53eca', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 17, 'created': '2017-11-02 07:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ce3dae760738e5e5082814c42f17b1fe129906d2', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 18, 'created': '2017-11-10 07:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/13556063dc6cd29cce903e4ac606e10e35369832', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 19, 'created': '2017-11-17 10:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/adf8f7df7a6da30a3a7fb73e2f37eead9812c47f', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}, {'number': 20, 'created': '2017-12-04 01:51:17.000000000', 'files': ['zaqar/storage/redis/utils.py', 'zaqar/storage/redis/models.py', 'zaqar/storage/redis/messages.py', 'zaqar/storage/redis/scripts/claim_messages.lua'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8b071a46bb9557a5743e98bc4cc4776714cd1020', 'message': 'Support delayed queues for redis\n\nImplement blueprint delayed-queues\n\nChange-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b\n'}]",0,512939,8b071a46bb9557a5743e98bc4cc4776714cd1020,42,5,20,14203,,,0,"Support delayed queues for redis

Implement blueprint delayed-queues

Change-Id: I6ee18df2c02ab11985ba4c35f8cbf815c4123a8b
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/39/512939/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/redis/utils.py', 'zaqar/storage/redis/models.py', 'zaqar/storage/redis/messages.py', 'zaqar/storage/redis/scripts/claim_messages.lua']",4,e15058117fad8f2735bd821fa00e6e4c28d4f117,bp/delayed-queues," local msg = redis.call('HMGET', mid, 'c', 'c.e', 'd.e') elseif (msg[1] == '' or tonumber(msg[2]) <= now) and tonumber(msg[3]) <= now then -- NOTE(cdyangzhenyu): If the message's delay time has not -- expired, the message can not be claimed."," local msg = redis.call('HMGET', mid, 'c', 'c.e') elseif msg[1] == '' or tonumber(msg[2]) <= now then",37,6
openstack%2Fopenstack-ansible-ops~master~I49c33b9e4e107990f2abb418b859fd280ba91107,openstack/openstack-ansible-ops,master,I49c33b9e4e107990f2abb418b859fd280ba91107,Allows for the VMs preseed mirror to be overridden,MERGED,2017-12-13 22:39:23.000000000,2017-12-14 00:53:02.000000000,2017-12-14 00:53:02.000000000,"[{'_account_id': 290}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 22:39:23.000000000', 'files': ['multi-node-aio/playbooks/pxe/debian/compute.preseed.j2', 'multi-node-aio/playbooks/pxe/debian/mnaio.preseed.j2', 'multi-node-aio/README.rst', 'multi-node-aio/build.sh', 'multi-node-aio/playbooks/pxe/debian/infra.preseed.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/e3a1d1fcb97f95810e925eaad61ff3bc3ddcff29', 'message': 'Allows for the VMs preseed mirror to be overridden\n\nIn the case the upstream mirror might be down or there might be a\nfaster mirror available, this allows you to specify the desired\nUbuntu mirror and base directory.\n\nChange-Id: I49c33b9e4e107990f2abb418b859fd280ba91107\n'}]",0,527802,e3a1d1fcb97f95810e925eaad61ff3bc3ddcff29,8,3,1,290,,,0,"Allows for the VMs preseed mirror to be overridden

In the case the upstream mirror might be down or there might be a
faster mirror available, this allows you to specify the desired
Ubuntu mirror and base directory.

Change-Id: I49c33b9e4e107990f2abb418b859fd280ba91107
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/02/527802/1 && git format-patch -1 --stdout FETCH_HEAD,"['multi-node-aio/playbooks/pxe/debian/compute.preseed.j2', 'multi-node-aio/playbooks/pxe/debian/mnaio.preseed.j2', 'multi-node-aio/README.rst', 'multi-node-aio/build.sh', 'multi-node-aio/playbooks/pxe/debian/infra.preseed.j2']",5,e3a1d1fcb97f95810e925eaad61ff3bc3ddcff29,change_default_mirror,d-i mirror/http/proxy string {{ default_ubuntu_mirror_proxy }} d-i mirror/http/hostname string {{ default_ubuntu_mirror_hostname }} d-i mirror/http/directory string {{ default_ubuntu_mirror_directory }},d-i mirror/http/proxy string d-i mirror/http/hostname string archive.ubuntu.com d-i mirror/http/directory string /ubuntu,16,9
openstack%2Fnova~master~I75a827b759b59773c08ffc6b1e3e54d6189b5853,openstack/nova,master,I75a827b759b59773c08ffc6b1e3e54d6189b5853,Update Instance action's updated_at when action event updated.,MERGED,2017-09-26 10:34:23.000000000,2017-12-14 00:29:48.000000000,2017-12-14 00:29:48.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16289}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 17920}, {'_account_id': 20722}, {'_account_id': 21279}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 23630}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-09-26 10:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02f08b6640ca3a745204d4e5fec3bebc7c30dc7d', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nRelated-Bug: 1719561\n""}, {'number': 2, 'created': '2017-09-26 10:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fedc9f28ce512426198350c596986c1a35ce1588', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nRelated-Bug: 1719561\n""}, {'number': 3, 'created': '2017-09-26 12:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85bbeab7c30cc0ae4503363f0636091d0bd2116f', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nRelated-Bug: 1719561\n""}, {'number': 4, 'created': '2017-09-26 12:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb7a22555066b4973829cb46b017a8a4471ad1d2', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nRelated-Bug: 1719561\n""}, {'number': 5, 'created': '2017-09-26 13:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/feeb7e0cc967bd2973bc9ceb4d7a3d96e5a8aa07', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nRelated-Bug: 1719561\n""}, {'number': 6, 'created': '2017-09-27 06:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6465c2c5701a498d0dc968ce248a42e585fa5af0', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 7, 'created': '2017-09-27 12:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8720b9b02bcd8eeb78005c83676f13f73d7be0f', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 8, 'created': '2017-10-09 03:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e6eb1e910031fffa44ddb5684d8c400964295c9', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 9, 'created': '2017-10-09 09:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9bc54d62ef75939e34104ba649fc4f8d940a535', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 10, 'created': '2017-10-16 01:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13d588d621c17c025e11da88d1b60942d3856093', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 11, 'created': '2017-11-15 06:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b908e0cb22d914cf09ab17c8356824809672274', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 12, 'created': '2017-11-17 01:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b269fb92f526d30320b90ebf8016c4a1e18771e2', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 14, 'created': '2017-11-30 10:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6cbfa2dba3947b592949d3c7f3437e338a477903', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: 1719561\n""}, {'number': 15, 'created': '2017-12-04 02:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0faad21bd5581dc1bd80da9ed769bfd96b76bc19', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: #1719561\n""}, {'number': 16, 'created': '2017-12-11 16:02:01.000000000', 'files': ['nova/tests/unit/objects/test_instance_action.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py', 'nova/objects/instance_action.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1a4ae60e1b48efb3d80cd36a285eda7ef5620f12', 'message': ""Update Instance action's updated_at when action event updated.\n\nWhen we do some operation on instances, will record some\ninstance action(such as 'create') in 'instance_actions' table,\nand some sub-event will record(such as\ncompute__do_build_and_run_instance) in 'instance_actions_events'\ntable.\n\nwe need update the instance action's updated_at when instance\naction events are created and instance action created or finished.\n\nChange-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853\nCloses-Bug: #1719561\n""}]",31,507473,1a4ae60e1b48efb3d80cd36a285eda7ef5620f12,368,29,15,20722,,,0,"Update Instance action's updated_at when action event updated.

When we do some operation on instances, will record some
instance action(such as 'create') in 'instance_actions' table,
and some sub-event will record(such as
compute__do_build_and_run_instance) in 'instance_actions_events'
table.

we need update the instance action's updated_at when instance
action events are created and instance action created or finished.

Change-Id: I75a827b759b59773c08ffc6b1e3e54d6189b5853
Closes-Bug: #1719561
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/507473/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_instance_action.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py', 'nova/objects/instance_action.py']",4,02f08b6640ca3a745204d4e5fec3bebc7c30dc7d,bp/pagination-add-changes-since-for-instance-action-list," 'start_time': context.timestamp, 'updated_at': context.timestamp} uctnow = timeutils.utcnow() 'finish_time': uctnow, 'updated_at': uctnow}", 'start_time': context.timestamp} 'finish_time': timeutils.utcnow()},46,2
openstack%2Fpuppet-openstack-integration~stable%2Fpike~Ie11af4944178fa057a189f4e0c7e4809dc694b86,openstack/puppet-openstack-integration,stable/pike,Ie11af4944178fa057a189f4e0c7e4809dc694b86,pike/zuul: run required jobs for stable/jewel as well,MERGED,2017-12-13 17:19:16.000000000,2017-12-14 00:21:26.000000000,2017-12-14 00:21:26.000000000,"[{'_account_id': 1}, {'_account_id': 14985}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 17:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/34c4865a6049aa185db66779cb8b26ec8c75f3c7', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}, {'number': 2, 'created': '2017-12-13 18:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/809928103198e91dd63dc4b00850c0fe6946ded7', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}, {'number': 3, 'created': '2017-12-13 18:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c12b5ca2c623cb6e0627246d147fc9a797e7e71b', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}, {'number': 4, 'created': '2017-12-13 18:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/f6a5a084e43320d86dfde38b05f712bbc4d88a91', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}, {'number': 5, 'created': '2017-12-13 21:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/409c056d8e9799ce5d22ac1299961ee9639c6d63', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}, {'number': 6, 'created': '2017-12-13 21:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/88399934ad6096b3ad3465824a1091133d62ce23', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}, {'number': 7, 'created': '2017-12-13 21:06:56.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/e7318871f197c4fe51d8608fa071bcc9527c3732', 'message': 'pike/zuul: run required jobs for stable/jewel as well\n\nChange-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86\n'}]",1,527747,e7318871f197c4fe51d8608fa071bcc9527c3732,15,4,7,3153,,,0,"pike/zuul: run required jobs for stable/jewel as well

Change-Id: Ie11af4944178fa057a189f4e0c7e4809dc694b86
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/47/527747/5 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,34c4865a6049aa185db66779cb8b26ec8c75f3c7,ceph/jewel, branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$ branches: ^stable/(jewel|pike).*$, branches: ^(?!stable/newton).*$ branches: ^(?!stable/newton).*$,16,2
openstack%2Fopenstack-helm-infra~master~I11dbad19d1f881c398a4b4dcd0c0eab23fccf278,openstack/openstack-helm-infra,master,I11dbad19d1f881c398a4b4dcd0c0eab23fccf278,Add missing prometheus and alertmanager resources,MERGED,2017-12-02 00:32:23.000000000,2017-12-14 00:20:52.000000000,2017-12-14 00:20:52.000000000,"[{'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-02 00:32:23.000000000', 'files': ['alertmanager/values.yaml', 'prometheus/templates/pod-helm-tests.yaml', 'prometheus/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5fae0f2880e66227132979f2dacc1fe7bdd468e6', 'message': 'Add missing prometheus and alertmanager resources\n\nAlertmanager and prometheus were missing entries for job\nresources in values.yaml. Also added resources to the prometheus\nhelm test template\n\nChange-Id: I11dbad19d1f881c398a4b4dcd0c0eab23fccf278\n'}]",0,524772,5fae0f2880e66227132979f2dacc1fe7bdd468e6,7,3,1,17591,,,0,"Add missing prometheus and alertmanager resources

Alertmanager and prometheus were missing entries for job
resources in values.yaml. Also added resources to the prometheus
helm test template

Change-Id: I11dbad19d1f881c398a4b4dcd0c0eab23fccf278
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/72/524772/1 && git format-patch -1 --stdout FETCH_HEAD,"['alertmanager/values.yaml', 'prometheus/templates/pod-helm-tests.yaml', 'prometheus/values.yaml']",3,5fae0f2880e66227132979f2dacc1fe7bdd468e6,add_job_resources," jobs: image_repo_sync: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" tests: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m""",,36,11
openstack%2Fopenstack-helm~master~I99a102f24c4a8ba18a0bba873e9f752368bea594,openstack/openstack-helm,master,I99a102f24c4a8ba18a0bba873e9f752368bea594,Ceph: luminous fixes,MERGED,2017-09-26 17:00:47.000000000,2017-12-14 00:13:31.000000000,2017-12-13 23:24:44.000000000,"[{'_account_id': 3}, {'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 18476}, {'_account_id': 20443}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26201}, {'_account_id': 26509}, {'_account_id': 27160}]","[{'number': 1, 'created': '2017-09-26 17:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/19d68a2087501d115c13dfc941ba8531fde95b93', 'message': 'Ceph: luminous init osd\n\nCeph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 2, 'created': '2017-09-26 17:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/895e49bac8ebe3e7790c0364e3f3df3f41505364', 'message': 'Ceph: luminous init osd\n\nCeph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 3, 'created': '2017-09-28 14:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/63e644ae9bddf9a4f7cc820c35a47782f35bd5a7', 'message': 'Ceph: luminous init osd\n\nCeph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 4, 'created': '2017-09-28 14:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/583ddf38aa4d5f98ef0946e10f26cf2af89240ec', 'message': 'Ceph: luminous init osd\n\nCeph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 5, 'created': '2017-09-28 14:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/749a05a5af1fcc29ce1c192b76674bce3923bff8', 'message': 'Ceph: luminous init osd\n\nCeph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 6, 'created': '2017-09-28 15:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/02e09ac6da69ce3ea86892b51f243329a7ce0378', 'message': 'Ceph: luminous init osd\n\nCeph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 7, 'created': '2017-10-12 14:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/03033a2e756f3861bd4f6ad6c5db68076a0a6139', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 8, 'created': '2017-10-12 18:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/63dfa5813e56f7842fd0a55d8eb4a6f73828ffad', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 9, 'created': '2017-10-17 13:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3797bc4af1ce1783ad44365404438d3f1cc61d17', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 10, 'created': '2017-10-17 14:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b4cf200fcc6ec76d6651a7311f64b6d6c45e42e6', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 11, 'created': '2017-10-17 17:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/47028e787bf3f9502809e3ef04e153d6ccdacf62', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 12, 'created': '2017-10-18 14:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2c0ff6b1c2e63fc5bed8604fc3528538897842d0', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 13, 'created': '2017-10-18 15:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c94ec6b3e547ea6d938a18d418eaec159c6d95ed', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 14, 'created': '2017-10-18 18:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1bfff963f91bfae9e5b0fa252ccf4792576f8dc6', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 15, 'created': '2017-11-16 23:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8d0079ca3e6ffba92c8d353cee51d404db532197', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 16, 'created': '2017-11-21 17:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e8f5b338ac6198cb9a8e37abb517329ed247b050', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 17, 'created': '2017-11-22 22:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0161da0639013c8a8f356c667723e4f78d315bc4', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 18, 'created': '2017-12-12 19:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/41faa86f1f4f1d1b10764545c9fa09e958b81ae4', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\n'}, {'number': 19, 'created': '2017-12-13 00:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/86f049ac028198e58f3e81d2833e1e663f01af0c', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\nDepends-On: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\n'}, {'number': 20, 'created': '2017-12-13 17:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/97238745568517e3857a6d4e6cf1b2597045fe96', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\nDepends-On: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\n'}, {'number': 21, 'created': '2017-12-13 18:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e8ee83bd21b702c023b3bbd6518f8f7c05e3b730', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\nDepends-On: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\n'}, {'number': 22, 'created': '2017-12-13 19:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ed5468c11a39ba485090c885f3ef12ba6cfc60b6', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\nDepends-On: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\n'}, {'number': 23, 'created': '2017-12-13 20:52:42.000000000', 'files': ['ceph/templates/bin/_variables_entrypoint.sh.tpl', 'ceph/templates/bin/_osd_directory.sh.tpl', 'ceph/templates/bin/_start_rgw.sh.tpl', 'ceph/templates/job-keyring.yaml', 'ceph/templates/deployment-mgr.yaml', 'Makefile', 'ceph/templates/service-mgr.yaml', 'ceph/templates/job-rbd-pool.yaml', 'ceph/values.yaml', 'ceph/templates/bin/_start_mgr.sh.tpl', 'ceph/templates/configmap-bin.yaml', 'glance/values.yaml', 'tools/gate/launch-osh/common.sh', 'doc/source/install/multinode.rst', 'ceph/templates/bin/_ceph_rbd_pool.sh.tpl', 'gnocchi/values.yaml', 'ceph/templates/daemonset-osd.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/eed43b85249a458098896e742441bb9968213e92', 'message': 'Ceph: luminous fixes\n\ninit osd: Ceph luminous release init osd differently. This fix detects\nceph releases and use the right process to init osd directory\nmgr: Set mgr daemonset that is in Luminous\n\nChange-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594\nSigned-off-by: Huamin Chen <hchen@redhat.com>\nDepends-On: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\n'}]",1,507628,eed43b85249a458098896e742441bb9968213e92,100,11,23,26509,,,0,"Ceph: luminous fixes

init osd: Ceph luminous release init osd differently. This fix detects
ceph releases and use the right process to init osd directory
mgr: Set mgr daemonset that is in Luminous

Change-Id: I99a102f24c4a8ba18a0bba873e9f752368bea594
Signed-off-by: Huamin Chen <hchen@redhat.com>
Depends-On: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/28/507628/23 && git format-patch -1 --stdout FETCH_HEAD,['ceph/templates/bin/_osd_directory.sh.tpl'],1,19d68a2087501d115c13dfc941ba8531fde95b93,luminous-mgr-improvements,"function osd_directory_luminous { if [[ ! -d /var/lib/ceph/osd ]]; then log ""ERROR- could not find the osd directory, did you bind mount the OSD data directory?"" log ""ERROR- use -v <host_osd_data_dir>:/var/lib/ceph/osd"" exit 1 fi # check if anything is present, if not, create an osd and its directory if [[ -n ""$(find /var/lib/ceph/osd -prune -empty)"" ]]; then log ""Creating osd"" UUID=$(uuidgen) OSD_SECRET=$(ceph-authtool --gen-print-key) OSD_ID=$(echo ""{\""cephx_secret\"": \""${OSD_SECRET}\""}"" | ceph osd new ${UUID} -i - -n client.bootstrap-osd -k ""$OSD_BOOTSTRAP_KEYRING"") if is_integer ""$OSD_ID""; then log ""OSD created with ID: ${OSD_ID}"" else log ""OSD creation failed: ${OSD_ID}"" exit 1 fi OSD_PATH=$(get_osd_path ""$OSD_ID"") # create the folder and own it mkdir -p ""$OSD_PATH"" chown ""${CHOWN_OPT[@]}"" ceph. ""$OSD_PATH"" log ""created folder $OSD_PATH"" # write the secret to the osd keyring file ceph-authtool --create-keyring ${OSD_PATH}/keyring --name osd.${OSD_ID} --add-key ${OSD_SECRET} # init data directory ceph-osd -i ${OSD_ID} --mkfs --osd-uuid ${UUID} fi # create the directory and an empty Procfile mkdir -p /etc/forego/""${CLUSTER}"" echo """" > /etc/forego/""${CLUSTER}""/Procfile for OSD_ID in $(find /var/lib/ceph/osd -maxdepth 1 -name ""${CLUSTER}*"" | sed 's/.*-//'); do OSD_PATH=$(get_osd_path ""$OSD_ID"") OSD_KEYRING=""$OSD_PATH/keyring"" if [ -n ""${JOURNAL_DIR}"" ]; then OSD_J=""${JOURNAL_DIR}/journal.${OSD_ID}"" chown ""${CHOWN_OPT[@]}"" -R ceph. ""${JOURNAL_DIR}"" else if [ -n ""${JOURNAL}"" ]; then OSD_J=${JOURNAL} chown ""${CHOWN_OPT[@]}"" -R ceph. ""$(dirname ""${JOURNAL_DIR}"")"" else OSD_J=${OSD_PATH}/journal fi fi echo ""${CLUSTER}-${OSD_ID}: /usr/bin/ceph-osd ${CLI_OPTS[*]} -f -i ${OSD_ID} --osd-journal ${OSD_J} -k $OSD_KEYRING"" | tee -a /etc/forego/""${CLUSTER}""/Procfile done log ""SUCCESS"" source osd_common.sh start_forego } function osd_directory_jewel { function osd_directory { local test_luminous=$(ceph -v | egrep -q ""12.2|luminous""; echo $?) if [[ ${test_luminous} -eq 0 ]]; then osd_directory_luminous else osd_directory_jewel fi }",function osd_directory {,68,1
openstack%2Fironic-inspector~stable%2Fpike~I6ef94a75fc9e1939c46b2939d01478c5a11621c1,openstack/ironic-inspector,stable/pike,I6ef94a75fc9e1939c46b2939d01478c5a11621c1,zuul: Clean up zuul files,MERGED,2017-11-28 15:49:53.000000000,2017-12-13 23:53:35.000000000,2017-12-13 23:53:35.000000000,"[{'_account_id': 6618}, {'_account_id': 11655}, {'_account_id': 14760}, {'_account_id': 18653}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-28 15:49:53.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/legacy-ironic-inspector-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/a6ea9806bb313f9f9b687d02deb28aee4304eb09', 'message': ""zuul: Clean up zuul files\n\nChanges to legacy-ironic-inspector-jobs.yaml:\n  * Create two base jobs:\n    * 'ironic-inspector-tox-func-base'\n    * 'ironic-inspector-dsvm-base'\n  * Put 'irrelevant-files' section into the new base jobs\n  * Have 'requirements.txt' no longer be ignored for DSVM jobs\n  * Simplify 'required-projects' sections by removing projects that\n    are already pulled in by the 'legacy-dsvm-base' job.\n\nChanges to project.yaml:\n  * Move 'irrelevant-files' section from project.yaml to\n    legacy-ironic-inspector-jobs.yaml\n  * Remove 'branches' section from project.yaml as it is not needed.\n  * Sort the jobs list\n\nChange-Id: I6ef94a75fc9e1939c46b2939d01478c5a11621c1\n(cherry picked from commit 4404b7a99f7ec6c8cb4bd8cbe79679b414d02e5c)\n""}]",0,523446,a6ea9806bb313f9f9b687d02deb28aee4304eb09,17,5,1,6618,,,0,"zuul: Clean up zuul files

Changes to legacy-ironic-inspector-jobs.yaml:
  * Create two base jobs:
    * 'ironic-inspector-tox-func-base'
    * 'ironic-inspector-dsvm-base'
  * Put 'irrelevant-files' section into the new base jobs
  * Have 'requirements.txt' no longer be ignored for DSVM jobs
  * Simplify 'required-projects' sections by removing projects that
    are already pulled in by the 'legacy-dsvm-base' job.

Changes to project.yaml:
  * Move 'irrelevant-files' section from project.yaml to
    legacy-ironic-inspector-jobs.yaml
  * Remove 'branches' section from project.yaml as it is not needed.
  * Sort the jobs list

Change-Id: I6ef94a75fc9e1939c46b2939d01478c5a11621c1
(cherry picked from commit 4404b7a99f7ec6c8cb4bd8cbe79679b414d02e5c)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/46/523446/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/legacy-ironic-inspector-jobs.yaml']",2,a6ea9806bb313f9f9b687d02deb28aee4304eb09,,# 'func' jobs - job: name: ironic-inspector-tox-func-base parent: legacy-base required-projects: - openstack/requirements irrelevant-files: - ^.*\.rst$ - ^doc/.*$ parent: ironic-inspector-tox-func-base parent: ironic-inspector-tox-func-base # DSVM jobs - job: name: ironic-inspector-dsvm-base parent: legacy-dsvm-base required-projects: - openstack/ironic - openstack/ironic-inspector - openstack/ironic-lib - openstack/ironic-python-agent - openstack/pyghmi - openstack/python-ironic-inspector-client - openstack/python-ironicclient - openstack/virtualbmc irrelevant-files: - ^test-requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^ironic_inspector/test/(?!.*tempest).*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tox.ini$ parent: ironic-inspector-dsvm-base parent: ironic-inspector-dsvm-base, parent: legacy-base required-projects: - openstack/requirements parent: legacy-base required-projects: - openstack/requirements parent: legacy-dsvm-base - openstack-infra/devstack-gate - openstack/ironic - openstack/ironic-inspector - openstack/ironic-lib - openstack/ironic-python-agent - openstack/pyghmi - openstack/python-ironic-inspector-client - openstack/python-ironicclient - openstack/virtualbmc parent: legacy-dsvm-base required-projects: - openstack-infra/devstack-gate - openstack/ironic - openstack/ironic-inspector - openstack/ironic-lib - openstack/ironic-python-agent - openstack/pyghmi - openstack/python-ironic-inspector-client - openstack/python-ironicclient - openstack/tempest - openstack/virtualbmc,45,99
openstack%2Ftripleo-quickstart~master~I159ca055db5e5279a70c43998f46773318406922,openstack/tripleo-quickstart,master,I159ca055db5e5279a70c43998f46773318406922,Change volume encryption test to use barbican_tempest test,MERGED,2017-12-08 21:45:00.000000000,2017-12-13 23:49:10.000000000,2017-12-13 23:49:10.000000000,"[{'_account_id': 3153}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-12-08 21:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ccb04e6b2c9902eb1656799037d6401af407d7de', 'message': 'Change volume encryption test to use barbican_tempest test\n\nThe original volume encryption tests create images using\nimages that are not signed.  These images are not booted when\nimage signing is enabled, causign the tests to fail.\n\nThe new tests are more current, and are maintained by the Barbican\nteam.\n\nChange-Id: I159ca055db5e5279a70c43998f46773318406922\n'}, {'number': 2, 'created': '2017-12-09 07:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8382de11bc48c126d32b27bcd1d81afa8bc5e265', 'message': 'Change volume encryption test to use barbican_tempest test\n\nThe original volume encryption tests create images using\nimages that are not signed.  These images are not booted when\nimage signing is enabled, causign the tests to fail.\n\nThe new tests are more current, and are maintained by the Barbican\nteam.\n\nChange-Id: I159ca055db5e5279a70c43998f46773318406922\n'}, {'number': 3, 'created': '2017-12-11 15:28:17.000000000', 'files': ['config/general_config/featureset006.yml', 'config/general_config/featureset017.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/60b6e49ed40d124668993c04d48443dbcba9e6df', 'message': 'Change volume encryption test to use barbican_tempest test\n\nThe original volume encryption tests create images using\nimages that are not signed.  These images are not booted when\nimage signing is enabled, causing the tests to fail.\n\nThe new tests are more current, and are maintained by the Barbican\nteam.\n\nChange-Id: I159ca055db5e5279a70c43998f46773318406922\nDepends-On: I2cad0b81eeab07785dfd4bb66e582d359504b0aa\n'}]",0,526784,60b6e49ed40d124668993c04d48443dbcba9e6df,27,7,3,9914,,,0,"Change volume encryption test to use barbican_tempest test

The original volume encryption tests create images using
images that are not signed.  These images are not booted when
image signing is enabled, causing the tests to fail.

The new tests are more current, and are maintained by the Barbican
team.

Change-Id: I159ca055db5e5279a70c43998f46773318406922
Depends-On: I2cad0b81eeab07785dfd4bb66e582d359504b0aa
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/84/526784/2 && git format-patch -1 --stdout FETCH_HEAD,"['config/general_config/featureset006.yml', 'config/general_config/featureset017.yml']",2,ccb04e6b2c9902eb1656799037d6401af407d7de,use_barbican_tempest_volume_test_instead, - 'barbican_tempest_plugin.tests.scenario.test_volume_encryption.VolumeEncryptionTest', - 'tempest.scenario.test_encrypted_cinder_volumes.TestEncryptedCinderVolumes',2,2
openstack%2Ftripleo-heat-templates~master~I8e432b3500fc0e65154c34b292d05ff8c19c45d6,openstack/tripleo-heat-templates,master,I8e432b3500fc0e65154c34b292d05ff8c19c45d6,Autogenerate the barbican simple crypto KEK,MERGED,2017-12-12 20:40:05.000000000,2017-12-13 23:49:09.000000000,2017-12-13 23:49:09.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 20:40:05.000000000', 'files': ['ci/environments/scenario002-multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ec6a94bd79a404bb62a36fd834cd40767e0a9a0e', 'message': 'Autogenerate the barbican simple crypto KEK\n\nCode recently merged in tripleo-common to autogenerate the simple\ncrypto KEK.  Can therefore not specify it in scenario002.\n\nChange-Id: I8e432b3500fc0e65154c34b292d05ff8c19c45d6\n'}]",0,527512,ec6a94bd79a404bb62a36fd834cd40767e0a9a0e,8,4,1,9914,,,0,"Autogenerate the barbican simple crypto KEK

Code recently merged in tripleo-common to autogenerate the simple
crypto KEK.  Can therefore not specify it in scenario002.

Change-Id: I8e432b3500fc0e65154c34b292d05ff8c19c45d6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/527512/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario002-multinode-containers.yaml'],1,ec6a94bd79a404bb62a36fd834cd40767e0a9a0e,autogen_barbican_kek,," # For now, we hardcode it but soon it'll be generated in tripleo-common BarbicanSimpleCryptoKek: dGhpcnR5X3R3b19ieXRlX2tleWJsYWhibGFoYmxhaGg=",0,2
openstack%2Fpuppet-tripleo~master~I2ed6e328a9a4915844f699784dd87dc99078fb23,openstack/puppet-tripleo,master,I2ed6e328a9a4915844f699784dd87dc99078fb23,gnocchi: ensure upgrade run after swift setup,MERGED,2017-12-13 15:10:29.000000000,2017-12-13 23:49:08.000000000,2017-12-13 23:49:08.000000000,"[{'_account_id': 2813}, {'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-13 15:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0deb4efeb502da50ed86f447ac042861aac5a2ca', 'message': 'gnocchi: ensure upgrade run after swift setup\n\nThe orignal fix have create an dependencies on an Class, so\nit does work and fail silencly.\n\nThis changes it to the Anchor.\n\nChange-Id: I2ed6e328a9a4915844f699784dd87dc99078fb23\nCloses-bug: #1724328\n'}, {'number': 2, 'created': '2017-12-13 15:27:29.000000000', 'files': ['manifests/profile/base/gnocchi/api.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1c49fbe08d1f764975ce8ef952b055ad25effd65', 'message': 'gnocchi: ensure upgrade run after swift setup\n\nThe orignal fix have create an dependencies on an Class, so\nit does work and fail silencly.\n\nThis changes it to the Anchor.\n\nChange-Id: I2ed6e328a9a4915844f699784dd87dc99078fb23\nCloses-bug: #1724328\n'}]",3,527709,1c49fbe08d1f764975ce8ef952b055ad25effd65,13,5,2,2813,,,0,"gnocchi: ensure upgrade run after swift setup

The orignal fix have create an dependencies on an Class, so
it does work and fail silencly.

This changes it to the Anchor.

Change-Id: I2ed6e328a9a4915844f699784dd87dc99078fb23
Closes-bug: #1724328
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/09/527709/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/gnocchi/api.pp'],1,0deb4efeb502da50ed86f447ac042861aac5a2ca,bug/1724328, Anchor<| title == 'swift::service::end' |> ~> Anchor['gnocchi::dbsync::end'], Anchor<| title == 'swift::service::end' |> ~> Class['Gnocchi::db::sync'],1,1
openstack%2Fpuppet-tripleo~master~If53d632ab458b0c04a8b7211194c18ebc8978d23,openstack/puppet-tripleo,master,If53d632ab458b0c04a8b7211194c18ebc8978d23,Add unit tests for tripleo::firewall::service_rules,MERGED,2017-12-08 03:35:49.000000000,2017-12-13 23:30:13.000000000,2017-12-13 23:30:13.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26828}]","[{'number': 1, 'created': '2017-12-08 03:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/974e667457ac43fe838e3127b7742b7ae0b4642b', 'message': 'Added unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}, {'number': 2, 'created': '2017-12-08 03:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1e34c93837a2422984a731519fbd21986ab11d2d', 'message': 'Add unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}, {'number': 3, 'created': '2017-12-10 09:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2165a0ce1ab6f3bde5eae8ba93e5ea7074c09631', 'message': 'Add unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}, {'number': 4, 'created': '2017-12-10 09:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/480e6ab91ca9acb706c9566bd130190b982dab56', 'message': 'Add unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}, {'number': 5, 'created': '2017-12-12 05:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5808ca53c8ba6b027e24d655bccb55ae7debad71', 'message': 'Add unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}, {'number': 6, 'created': '2017-12-12 08:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/3fd798b01308c29c06bb3b831ffe97a1d34bf036', 'message': 'Add unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}, {'number': 7, 'created': '2017-12-13 06:22:55.000000000', 'files': ['releasenotes/notes/firewall-service-rules-6586a2c138dfe338.yaml', 'spec/defines/tripleo_firewall_service_rules_spec.rb', 'spec/fixtures/hieradata/default.yaml', 'manifests/firewall/service_rules.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/41f9b0d3cf549657e18ebedbadaf3558403d4e21', 'message': 'Add unit tests for tripleo::firewall::service_rules\n\nIn order to get a proper unit test suits, we need to change the\nseparator from the ""dot"" to ""double-semicolons"".\n\nThe ""."" is a reserved character in YAML for hashes. In puppet world,\nwe commonly use ""::"".\n\nUnit tests don\'t work if we let the ""dot"" separator, and apparently it\'s\nan intended outcome with that kind of syntax.\n\nFact it\'s working in the deploy process is kind of black magic (see the\ntripleo::haproxy::service_endpoints resource for example). And the ""dot""\ncreates something weird, as all other resources are using the standard\ndouble-semicolon.\n\nChange-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23\nCloses-Bug: 1737086\n'}]",2,526589,41f9b0d3cf549657e18ebedbadaf3558403d4e21,36,7,7,26828,,,0,"Add unit tests for tripleo::firewall::service_rules

In order to get a proper unit test suits, we need to change the
separator from the ""dot"" to ""double-semicolons"".

The ""."" is a reserved character in YAML for hashes. In puppet world,
we commonly use ""::"".

Unit tests don't work if we let the ""dot"" separator, and apparently it's
an intended outcome with that kind of syntax.

Fact it's working in the deploy process is kind of black magic (see the
tripleo::haproxy::service_endpoints resource for example). And the ""dot""
creates something weird, as all other resources are using the standard
double-semicolon.

Change-Id: If53d632ab458b0c04a8b7211194c18ebc8978d23
Closes-Bug: 1737086
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/89/526589/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/tripleo_firewall_service_rules_spec.rb', 'spec/fixtures/hieradata/default.yaml', 'manifests/firewall/service_rules.pp']",3,974e667457ac43fe838e3127b7742b7ae0b4642b,bug/1737086," $service_firewall_rules = hiera( ""tripleo::${underscore_name}::firewall_rules"", hiera(""tripleo.${underscore_name}.firewall_rules"" ,{}) ) create_resources('tripleo::firewall::rule', $service_firewall_rules)"," $service_firewall_rules = hiera(""tripleo.${underscore_name}.firewall_rules"", {}) if !empty($service_firewall_rules) { create_resources('tripleo::firewall::rule', $service_firewall_rules) } ",54,6
openstack%2Fpuppet-octavia~master~Ic6cf523809e390df0263e26d5879c06986688cfa,openstack/puppet-octavia,master,Ic6cf523809e390df0263e26d5879c06986688cfa,Allow disabling SSH access to amphora,MERGED,2017-12-12 16:17:59.000000000,2017-12-13 23:25:15.000000000,2017-12-13 23:25:15.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 25899}]","[{'number': 1, 'created': '2017-12-12 16:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/60e346f8f5837563101a7be7823aebccf0924d62', 'message': 'Empty string for amp_ssh_key_name translates to unset\n\nSetting a default value for the amp_ssh_key_name forces deploying\noctavia with ssh key access to amphorae enabled and requires creation\nof the ssh key pair in nova. Translating an empty string to\n$::os_service_default allows users to workaround the issue.\n\nChange-Id: Ic6cf523809e390df0263e26d5879c06986688cfa\n'}, {'number': 2, 'created': '2017-12-12 19:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/4a017bedeb38bbeefde8b8c57a49d3e7aee27cbb', 'message': 'Allow disabling SSH access to amphora\n\nThis patch provides a mechanism for disabling configuration\nof the SSH key name for accessing amphora.\n\nChange-Id: Ic6cf523809e390df0263e26d5879c06986688cfa\n'}, {'number': 3, 'created': '2017-12-13 12:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/656a968d3d1585a1a78626dfba28814bfb706bd4', 'message': 'Allow disabling SSH access to amphora\n\nThis patch provides a mechanism for disabling configuration\nof the SSH key name for accessing amphora.\n\nChange-Id: Ic6cf523809e390df0263e26d5879c06986688cfa\n'}, {'number': 4, 'created': '2017-12-13 14:29:50.000000000', 'files': ['manifests/worker.pp', 'spec/classes/octavia_worker_spec.rb', 'releasenotes/notes/add-enable-ssh-access-param-1f2454d898b9b59b.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/8626d273222158d5f60a41735d6951976a96e45f', 'message': 'Allow disabling SSH access to amphora\n\nThis patch provides a mechanism for disabling configuration\nof the SSH key name for accessing amphora.\n\nChange-Id: Ic6cf523809e390df0263e26d5879c06986688cfa\n'}]",2,527449,8626d273222158d5f60a41735d6951976a96e45f,13,4,4,6681,,,0,"Allow disabling SSH access to amphora

This patch provides a mechanism for disabling configuration
of the SSH key name for accessing amphora.

Change-Id: Ic6cf523809e390df0263e26d5879c06986688cfa
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/49/527449/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/worker.pp', 'spec/classes/octavia_worker_spec.rb']",2,60e346f8f5837563101a7be7823aebccf0924d62,, context 'with empty ssh key name' do before do params.merge!({ :amp_ssh_key_name => '' }) end it 'configures octavia-worker service' do is_expected.to contain_octavia_config('controller_worker/amp_ssh_key_name').with_value('<SERVICE DEFAULT>') end end ,,17,1
openstack%2Fneutron-tempest-plugin~master~I2a3fba5ef62a0d8ec2f2641a8fb9867f73fc5938,openstack/neutron-tempest-plugin,master,I2a3fba5ef62a0d8ec2f2641a8fb9867f73fc5938,test_floating_ips_admin_actions: clean up floating ip,MERGED,2017-12-12 21:20:22.000000000,2017-12-13 23:24:53.000000000,2017-12-13 23:24:53.000000000,"[{'_account_id': 1131}, {'_account_id': 8655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 21:20:22.000000000', 'files': ['neutron_tempest_plugin/api/admin/test_floating_ips_admin_actions.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/c356fcad7f2260d891bd4952a0f67a0467ab7950', 'message': 'test_floating_ips_admin_actions: clean up floating ip\n\nOtherwise, if you execute the test over and over, all IP addresses are\neventually depleted.\n\nChange-Id: I2a3fba5ef62a0d8ec2f2641a8fb9867f73fc5938\n'}]",1,527523,c356fcad7f2260d891bd4952a0f67a0467ab7950,7,3,1,9656,,,0,"test_floating_ips_admin_actions: clean up floating ip

Otherwise, if you execute the test over and over, all IP addresses are
eventually depleted.

Change-Id: I2a3fba5ef62a0d8ec2f2641a8fb9867f73fc5938
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/23/527523/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/api/admin/test_floating_ips_admin_actions.py'],1,c356fcad7f2260d891bd4952a0f67a0467ab7950,," self.addCleanup(self.client.delete_floatingip, floating_ip['id'])",,1,0
openstack%2Fopenstack-ansible-galera_server~master~I429814f05f45a3886500e48d514e13424d46020e,openstack/openstack-ansible-galera_server,master,I429814f05f45a3886500e48d514e13424d46020e,Remove the galera_ssl_address variable,MERGED,2017-12-13 20:37:46.000000000,2017-12-13 23:23:50.000000000,2017-12-13 23:23:50.000000000,"[{'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 20:37:46.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/e54d5816377f14111d1dd4e856290260864fb208', 'message': ""Remove the galera_ssl_address variable\n\nReplace 'galera_ssl_address' with 'galera_address'. This has the benefit\nof being automatically wired by the integrated repo to correctly use a\nVIP address.\n\nChange-Id: I429814f05f45a3886500e48d514e13424d46020e\n""}]",0,527779,e54d5816377f14111d1dd4e856290260864fb208,7,3,1,14805,,,0,"Remove the galera_ssl_address variable

Replace 'galera_ssl_address' with 'galera_address'. This has the benefit
of being automatically wired by the integrated repo to correctly use a
VIP address.

Change-Id: I429814f05f45a3886500e48d514e13424d46020e
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/79/527779/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,e54d5816377f14111d1dd4e856290260864fb208,remove_galera_ssl_address,"galera_ssl_self_signed_subject: ""/C=US/ST=Texas/L=San Antonio/O=IT/CN={{ galera_address }}""galera_address: ""{{ ansible_host }}""","galera_ssl_self_signed_subject: ""/C=US/ST=Texas/L=San Antonio/O=IT/CN={{ galera_ssl_address }}""galera_ssl_address: ""{{ ansible_host }}""",2,2
openstack%2Fcliff~stable%2Fpike~Iefdf10245a64e58fa6b5d8174a09fb90f18c81a8,openstack/cliff,stable/pike,Iefdf10245a64e58fa6b5d8174a09fb90f18c81a8,Fix PEP8 in gate,MERGED,2017-12-06 13:53:11.000000000,2017-12-13 23:11:29.000000000,2017-12-13 23:11:29.000000000,"[{'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 13:53:11.000000000', 'files': ['cliff/tests/test_help.py', 'cliff/tests/test_formatters_table.py'], 'web_link': 'https://opendev.org/openstack/cliff/commit/5a5c0101bc401ac0b63b97204e0b5f2c2b9f59f0', 'message': ""Fix PEP8 in gate\n\nZuul openstack-tox-pep8 failed due to several errors [1]\n- Use bare except.\n- Use ambiguous variable name 'l'. As pycodestyle doc [2] mentioned,\n'Never use the characters 'l', 'O', or 'I' as variable names.'.\n\n[1] http://logs.openstack.org/96/477396/3/gate/openstack-tox-pep8/f851c2d/ara/result/57b145af-a103-4982-9e9c-7c93c21b32df/\n[2] https://pep8.readthedocs.io/en/latest/_modules/pycodestyle.html\n\nChange-Id: Iefdf10245a64e58fa6b5d8174a09fb90f18c81a8\n(cherry picked from commit cc7179c9185a18f135c1f4f20f8880252f53b02f)\n""}]",0,526071,5a5c0101bc401ac0b63b97204e0b5f2c2b9f59f0,11,3,1,4978,,,0,"Fix PEP8 in gate

Zuul openstack-tox-pep8 failed due to several errors [1]
- Use bare except.
- Use ambiguous variable name 'l'. As pycodestyle doc [2] mentioned,
'Never use the characters 'l', 'O', or 'I' as variable names.'.

[1] http://logs.openstack.org/96/477396/3/gate/openstack-tox-pep8/f851c2d/ara/result/57b145af-a103-4982-9e9c-7c93c21b32df/
[2] https://pep8.readthedocs.io/en/latest/_modules/pycodestyle.html

Change-Id: Iefdf10245a64e58fa6b5d8174a09fb90f18c81a8
(cherry picked from commit cc7179c9185a18f135c1f4f20f8880252f53b02f)
",git fetch https://review.opendev.org/openstack/cliff refs/changes/71/526071/1 && git format-patch -1 --stdout FETCH_HEAD,"['cliff/tests/test_help.py', 'cliff/tests/test_formatters_table.py']",2,5a5c0101bc401ac0b63b97204e0b5f2c2b9f59f0,fix-pep8-stable/pike," width = tw.return_value = 80 self._expected_mv[width], width = tw.return_value = 50 self.assertEqual(self._expected_mv[width], actual) self.assertEqual(width, len(actual.splitlines()[0])) width = tw.return_value = 45 self.assertEqual(self._expected_mv[width], actual) self.assertEqual(width, len(actual.splitlines()[0])) width = tw.return_value = 40 self.assertEqual(self._expected_mv[width], actual) self.assertEqual(width, len(actual.splitlines()[0])) width = tw.return_value = 10 self.assertEqual(self._expected_mv[width], actual)"," l = tw.return_value = 80 self._expected_mv[l], l = tw.return_value = 50 self.assertEqual(self._expected_mv[l], actual) self.assertEqual(l, len(actual.splitlines()[0])) l = tw.return_value = 45 self.assertEqual(self._expected_mv[l], actual) self.assertEqual(l, len(actual.splitlines()[0])) l = tw.return_value = 40 self.assertEqual(self._expected_mv[l], actual) self.assertEqual(l, len(actual.splitlines()[0])) l = tw.return_value = 10 self.assertEqual(self._expected_mv[l], actual)",14,14
openstack%2Fswift~master~I385fb44b7b8b4307c4686f850ed011b66b90c656,openstack/swift,master,I385fb44b7b8b4307c4686f850ed011b66b90c656,Use symlink in container-sync internal client pipeline,ABANDONED,2017-12-11 15:27:16.000000000,2017-12-13 23:06:56.000000000,,"[{'_account_id': 1179}, {'_account_id': 4608}, {'_account_id': 13052}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 15:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f1d86c6f93525c4de2e6f4b6c5810240df95b66', 'message': 'Use symlink in container-sync internal client pipeline\n\nRather than leaking symlink implementation details into the container\nsync daemon, use the symlink middleware to map the internal sysmeta\nresponse header to client headers.\n\nThis requires the container-sync internal client pipeline to be\nexplicitly configured with symlink middleware. This is similar to the\nexisting requirement to include encryption middlewares in the pipeline\nif encryption is enabled.\n\nAdds support for query params to InternalClient.get_object\n\nChange-Id: I385fb44b7b8b4307c4686f850ed011b66b90c656\n'}, {'number': 2, 'created': '2017-12-12 05:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/33d5f45ddeae92c4e6be76166a5dd77d7c4bb77b', 'message': 'Use symlink in container-sync internal client pipeline\n\nRather than leaking symlink implementation details into the container\nsync daemon, use the symlink middleware to map the internal sysmeta\nresponse header to client headers.\n\nThis requires the container-sync internal client pipeline to be\nexplicitly configured with symlink middleware. This is similar to the\nexisting requirement to include encryption middlewares in the pipeline\nif encryption is enabled.\n\nAdds support for query params to InternalClient.get_object\n\nChange-Id: I385fb44b7b8b4307c4686f850ed011b66b90c656\n'}, {'number': 3, 'created': '2017-12-13 10:13:42.000000000', 'files': ['swift/common/middleware/symlink.py', 'swift/container/sync.py', 'test/unit/common/test_internal_client.py', 'doc/source/overview_container_sync.rst', 'test/unit/container/test_sync.py', 'swift/common/internal_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/742d62638db138ebb59f1aea6cab5330e9d5de9c', 'message': 'Use symlink in container-sync internal client pipeline\n\nRather than leaking symlink implementation details into the container\nsync daemon, use the symlink middleware to map the internal sysmeta\nresponse header to client headers.\n\nThis requires the container-sync internal client pipeline to be\nexplicitly configured with symlink middleware. This is similar to the\nexisting requirement to include encryption middlewares in the pipeline\nif encryption is enabled.\n\nAdds support for query params to InternalClient.get_object\n\nChange-Id: I385fb44b7b8b4307c4686f850ed011b66b90c656\n'}]",6,527126,742d62638db138ebb59f1aea6cab5330e9d5de9c,13,4,3,7847,,,0,"Use symlink in container-sync internal client pipeline

Rather than leaking symlink implementation details into the container
sync daemon, use the symlink middleware to map the internal sysmeta
response header to client headers.

This requires the container-sync internal client pipeline to be
explicitly configured with symlink middleware. This is similar to the
existing requirement to include encryption middlewares in the pipeline
if encryption is enabled.

Adds support for query params to InternalClient.get_object

Change-Id: I385fb44b7b8b4307c4686f850ed011b66b90c656
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/527126/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/symlink.py', 'swift/container/sync.py', 'test/unit/common/test_internal_client.py', 'doc/source/overview_container_sync.rst', 'test/unit/container/test_sync.py', 'swift/common/internal_client.py']",6,5f1d86c6f93525c4de2e6f4b6c5810240df95b66,symlink_api-patch44," self, method, path, headers, acceptable_statuses, body_file=None, params=None): :param params: A dict of params to be set in request query string, defaults to None. if params: req.params = params acceptable_statuses=(2,), params=None): Gets an object. :param account: The object's account. :param container: The object's container. :param obj: The object name. :param headers: Headers to send with request, defaults to empty dict. :param acceptable_statuses: List of status for valid responses, defaults to (2,). :param params: A dict of params to be set in request query string, defaults to None. :raises UnexpectedResponse: Exception raised when requests fail to get a response with an acceptable status :raises Exception: Exception is raised when code fails in an unexpected way. :returns: A 3-tuple (status, headers, iterator of object body) resp = self.make_request( 'GET', path, headers, acceptable_statuses, params=params) :param headers: Headers to send with request, defaults to empty dict."," self, method, path, headers, acceptable_statuses, body_file=None): acceptable_statuses=(2,)): Returns a 3-tuple (status, headers, iterator of object body) resp = self.make_request('GET', path, headers, acceptable_statuses) :param headers: Headers to send with request, defaults ot empty dict.",134,55
openstack%2Fansible-role-redhat-subscription~master~Id99efebe81814ebe028f2952c2fcc89699f4e023,openstack/ansible-role-redhat-subscription,master,Id99efebe81814ebe028f2952c2fcc89699f4e023,Remove travis.yml,MERGED,2017-12-13 22:40:30.000000000,2017-12-13 23:05:23.000000000,2017-12-13 23:05:23.000000000,"[{'_account_id': 22348}, {'_account_id': 27253}]","[{'number': 1, 'created': '2017-12-13 22:40:30.000000000', 'files': ['.travis.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/ff0ed4a10e7fd1eb0738b090cf2f458298775270', 'message': ""Remove travis.yml\n\nWe don't need this file anymore, since we run testing with Zuul in\nOpenStack Infrastructure now.\n\nChange-Id: Id99efebe81814ebe028f2952c2fcc89699f4e023\n""}]",0,527803,ff0ed4a10e7fd1eb0738b090cf2f458298775270,6,2,1,3153,,,0,"Remove travis.yml

We don't need this file anymore, since we run testing with Zuul in
OpenStack Infrastructure now.

Change-Id: Id99efebe81814ebe028f2952c2fcc89699f4e023
",git fetch https://review.opendev.org/openstack/ansible-role-redhat-subscription refs/changes/03/527803/1 && git format-patch -1 --stdout FETCH_HEAD,['.travis.yml'],1,ff0ed4a10e7fd1eb0738b090cf2f458298775270,cleanup,,"--- language: python python: ""2.7"" sudo: required dist: trusty # Install ansible addons: apt: packages: - python-pip install: # Install ansible - pip install ansible # Check ansible version - ansible --version # Create ansible.cfg with correct roles_path - printf '[defaults]\nroles_path=../' >ansible.cfg script: # Basic role syntax check - ansible-playbook tests/test.yml -i tests/inventory --syntax-check notifications: webhooks: https://galaxy.ansible.com/api/v1/notifications/ ",0,29
openstack%2Fopenstack-ansible~master~Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e,openstack/openstack-ansible,master,Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e,Add networking-sfc repo to repo_packages,MERGED,2017-12-04 17:39:57.000000000,2017-12-13 22:57:47.000000000,2017-12-13 22:57:47.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}, {'_account_id': 25505}]","[{'number': 1, 'created': '2017-12-04 17:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/20342991eb4dde7f53d1851227eb7011b5c05dc4', 'message': 'Add networking-sfc repo to repo_packages\n\nTo complete https://review.openstack.org/#/c/510909/ we need to add a pointer\nto the neutron networking-sfc project\n\nChange-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e\n'}, {'number': 2, 'created': '2017-12-09 10:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6c1ea27b2925a2719f9e1d7bb00fac9dcdc24d20', 'message': 'Add networking-sfc repo to repo_packages\n\nTo complete https://review.openstack.org/#/c/510909/ we need to add a pointer\nto the neutron networking-sfc project\n\nChange-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e\n'}, {'number': 3, 'created': '2017-12-10 09:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6efc47b18abba8712c1ca95d92d305a89431816c', 'message': 'Add networking-sfc repo to repo_packages\n\nTo complete https://review.openstack.org/#/c/510909/ we need to add a pointer\nto the neutron networking-sfc project\n\nChange-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e\n'}, {'number': 4, 'created': '2017-12-10 10:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cc6d0b2378abd528b7c65d4382d1a2b17d151b52', 'message': 'Add networking-sfc repo to repo_packages\n\nTo complete https://review.openstack.org/#/c/510909/ we need to add a pointer\nto the neutron networking-sfc project\n\nChange-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e\n'}, {'number': 5, 'created': '2017-12-12 08:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/302383fcf58fc84cd68d485be573b6d70692b6bb', 'message': 'Add networking-sfc repo to repo_packages\n\nTo complete https://review.openstack.org/#/c/510909/ we need to add a pointer\nto the neutron networking-sfc project\n\nChange-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e\n'}, {'number': 6, 'created': '2017-12-13 10:19:20.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c170e0c82854830f06f2578716e0200081142534', 'message': 'Add networking-sfc repo to repo_packages\n\nTo complete https://review.openstack.org/#/c/510909/ we need to add a pointer\nto the neutron networking-sfc project\n\nChange-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e\n'}]",2,525264,c170e0c82854830f06f2578716e0200081142534,66,9,6,21883,,,0,"Add networking-sfc repo to repo_packages

To complete https://review.openstack.org/#/c/510909/ we need to add a pointer
to the neutron networking-sfc project

Change-Id: Ib8405b37ad1b59ed7347e40cbc1d2e9627dc3a2e
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/64/525264/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/opendaylight.yml'],1,20342991eb4dde7f53d1851227eb7011b5c05dc4,," networking_sfc_git_repo: https://git.openstack.org/openstack/networking-sfc networking_sfc_git_install_branch: 580faa9bf1a01fd62cb9d0fe4a1c9fd0c40b50b1 # HEAD of ""master"" as of 14.10.2017 networking_sfc_project_group: neutron_all",,4,0
openstack%2Fopenstack-zuul-jobs~master~I8cc72bc8abfdcfa41b30428ac09badbaee72ebcd,openstack/openstack-zuul-jobs,master,I8cc72bc8abfdcfa41b30428ac09badbaee72ebcd,"Revert ""Partial Revert ""Remove now obsolete npm jobs""""",MERGED,2017-11-16 07:58:37.000000000,2017-12-13 22:52:31.000000000,2017-12-13 22:52:31.000000000,"[{'_account_id': 841}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-16 07:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/604965049c24108d14af9433e7ffc62fc4058302', 'message': 'Revert ""Partial Revert ""Remove now obsolete npm jobs""""\n\nThis reverts commit ae8af0c891cc58ea1b60783f64eab14d7c1bb1f0.\n\nnpm-run-test job has been fixed and we can consume it.\n\nDepends-On: I40b7d019551c227e4b8a0e11366b1ce448d5bbed\nChange-Id: I8cc72bc8abfdcfa41b30428ac09badbaee72ebcd\n'}, {'number': 2, 'created': '2017-12-03 20:02:26.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/nodejs4-npm-run-test/post.yaml', 'zuul.d/project-templates.yaml', 'playbooks/legacy/nodejs6-npm-run-test/run.yaml', 'playbooks/legacy/nodejs6-npm-run-test/post.yaml', 'playbooks/legacy/nodejs4-npm-run-test/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/fc08286f7ff44230f0edc4e128860c054017a73f', 'message': 'Revert ""Partial Revert ""Remove now obsolete npm jobs""""\n\nThis reverts commit ae8af0c891cc58ea1b60783f64eab14d7c1bb1f0.\n\nnpm-run-test job has been fixed and we can consume it.\n\nDepends-On: I40b7d019551c227e4b8a0e11366b1ce448d5bbed\nChange-Id: I8cc72bc8abfdcfa41b30428ac09badbaee72ebcd\n'}]",0,520338,fc08286f7ff44230f0edc4e128860c054017a73f,10,4,2,841,,,0,"Revert ""Partial Revert ""Remove now obsolete npm jobs""""

This reverts commit ae8af0c891cc58ea1b60783f64eab14d7c1bb1f0.

npm-run-test job has been fixed and we can consume it.

Depends-On: I40b7d019551c227e4b8a0e11366b1ce448d5bbed
Change-Id: I8cc72bc8abfdcfa41b30428ac09badbaee72ebcd
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/38/520338/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/nodejs4-npm-run-test/post.yaml', 'zuul.d/project-templates.yaml', 'playbooks/legacy/nodejs6-npm-run-test/run.yaml', 'playbooks/legacy/nodejs6-npm-run-test/post.yaml', 'playbooks/legacy/nodejs4-npm-run-test/run.yaml']",6,604965049c24108d14af9433e7ffc62fc4058302,520338,,"- hosts: all name: Autoconverted job legacy-nodejs4-npm-run-test from old job gate-{name}-nodejs4-npm-run-test tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ git://git.openstack.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: /usr/local/jenkins/slave_scripts/install-distro-packages.sh chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -u set -e set -x # Prerequisites sudo apt-get update sudo apt-get install -y apt-transport-https lsb-release curl DISTRO=$(lsb_release -c -s) # Install via nodesource curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | sudo apt-key add - echo ""deb https://deb.nodesource.com/node_4.x $DISTRO main"" | sudo tee /etc/apt/sources.list.d/nodesource.list echo ""deb-src https://deb.nodesource.com/node_4.x $DISTRO main"" | sudo tee -a /etc/apt/sources.list.d/nodesource.list sudo apt-get update sudo apt-get install -y nodejs # Output to the log for debugging sake. node --version npm --version executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | sudo apt-get update sudo apt-get install -y xvfb chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | sudo apt-get update sudo apt-get install -y chromium-browser chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | sudo apt-get update sudo apt-get install -y firefox dbus chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | DIMENSIONS='1280x1024x24' /usr/bin/Xvfb :99 -screen 0 ${DIMENSIONS} -ac +extension GLX +render -noreset 2>&1 > /dev/null & chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -u set -e set -x export DISPLAY=:99 npm install --verbose # Try running as a standard lifecycle script, otherwise try custom. npm_lifecycle_phases=""publish install version test stop start restart pack"" if [[ $npm_lifecycle_phases =~ (^| )test($| ) ]]; then npm test --verbose else npm run test --verbose fi # If no shrinkwrap exists, generate it. if [ ! -f ./npm-shrinkwrap.json ]; then npm prune # https://github.com/npm/npm/issues/6298 npm shrinkwrap fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | OUT=`git ls-files --other --exclude-standard --directory` if [ -z ""$OUT"" ]; then echo ""No extra files created during test."" exit 0 else echo ""The following un-ignored files were created during the test:"" echo ""$OUT"" exit 0 # TODO: change to 1 to fail tests. fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",12,423
openstack%2Fos-brick~stable%2Fpike~I9f52f89b8466d03699cfd5c0e32c672c934cd6fb,openstack/os-brick,stable/pike,I9f52f89b8466d03699cfd5c0e32c672c934cd6fb,Make close on cryptsetup volumes idempotent,MERGED,2017-12-12 18:28:55.000000000,2017-12-13 22:49:42.000000000,2017-12-13 22:49:42.000000000,"[{'_account_id': 4523}, {'_account_id': 4690}, {'_account_id': 9555}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 18:28:55.000000000', 'files': ['os_brick/tests/encryptors/test_cryptsetup.py', 'os_brick/encryptors/cryptsetup.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/eed0228da5f955cecae67dc4ffb3dc4cc7b06bbc', 'message': ""Make close on cryptsetup volumes idempotent\n\nWhen recovering from the failure of a compute host, Nova can call\nclose on an encryptor whose state Nova can't be certain of, but which\nhasn't been created. This change makes the close operation idempotent,\nwhich allows recovery to be more robust.\n\nRelated-bug: #1724573\nChange-Id: I9f52f89b8466d03699cfd5c0e32c672c934cd6fb\n(cherry picked from commit cedf281c7349daeec3ad85f12c75a47b1caf55ad)\n""}]",0,527491,eed0228da5f955cecae67dc4ffb3dc4cc7b06bbc,15,6,1,4690,,,0,"Make close on cryptsetup volumes idempotent

When recovering from the failure of a compute host, Nova can call
close on an encryptor whose state Nova can't be certain of, but which
hasn't been created. This change makes the close operation idempotent,
which allows recovery to be more robust.

Related-bug: #1724573
Change-Id: I9f52f89b8466d03699cfd5c0e32c672c934cd6fb
(cherry picked from commit cedf281c7349daeec3ad85f12c75a47b1caf55ad)
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/91/527491/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/encryptors/test_cryptsetup.py', 'os_brick/encryptors/cryptsetup.py']",2,eed0228da5f955cecae67dc4ffb3dc4cc7b06bbc,bug/1724573," # NOTE(mdbooth): remove will return 4 (wrong device specified) if # the device doesn't exist. We assume here that the caller hasn't # specified the wrong device, and that it doesn't exist because it # isn't open. We don't fail in this case in order to make this # operation idempotent. run_as_root=True, check_exit_code=[0, 4],"," # cryptsetup returns 4 when attempting to destroy a non-active # dm-crypt device. We are going to ignore this error code to make # nova deleting that instance successfully. run_as_root=True, check_exit_code=True,",8,6
openstack%2Fneutron~master~I656ba3b82df6acd2555735093127ca59f7042d44,openstack/neutron,master,I656ba3b82df6acd2555735093127ca59f7042d44,Update the documentation links,MERGED,2017-11-24 06:32:16.000000000,2017-12-13 22:48:29.000000000,2017-12-13 22:48:29.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 7249}, {'_account_id': 9732}, {'_account_id': 11628}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 21430}, {'_account_id': 22348}, {'_account_id': 24209}, {'_account_id': 25564}]","[{'number': 1, 'created': '2017-11-24 06:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fff06b01f9566562a1d6a72bf0bb300114fe53e', 'message': 'Update the doc link\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 2, 'created': '2017-11-24 06:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ed0fb01e07399bb98f7927e44dda89d3a3624af', 'message': 'Update the doc link\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 3, 'created': '2017-11-25 01:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f9d5606c5b4a96ba419f3ed05d25f05f5c29ca7f', 'message': 'Update the doc link\n\nThese document links which starts with “admin-guide“ has been out of\ntime. Fix them to be friendly to new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 4, 'created': '2017-11-28 02:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70cbe3b6bfd63c1e184b9d5a5890ecf39a6ba409', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" are outdated.\nFix them to be friendly to new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 5, 'created': '2017-11-28 09:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad2d348e37f56854cdb70b788541b409106cdb1a', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" are outdated.\nFix them to be friendly to new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 6, 'created': '2017-11-29 02:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6d1c8cb52372ce0af0c68a42324e375f71e52be', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 7, 'created': '2017-11-29 02:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cabb8d6fb559b046c23d09dd5614d5c31c3fad6a', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 8, 'created': '2017-11-30 02:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09ab61046e96c9643d5d5f6941b5f674c9e72cca', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 9, 'created': '2017-11-30 02:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7088ed2fbe8cb3fb6dc96d6c46789dfc87ba3b32', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 10, 'created': '2017-12-07 08:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/921c6bbefb508d55894ff7aabbcf38a250d81a06', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 11, 'created': '2017-12-07 08:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff2e83b4137075e37c1387c8f11a7d85bd7ea0a5', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 12, 'created': '2017-12-07 14:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3af6fa49b1f96c746a9d5d2c404ea880c8da65cc', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 13, 'created': '2017-12-07 22:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a08e55485a8030c5e84e0fa6c03b6822709d3fc', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}, {'number': 14, 'created': '2017-12-13 10:50:00.000000000', 'files': ['doc/source/admin/config-lbaas.rst', 'doc/source/admin/intro-basic-networking.rst', 'doc/source/feature_classification/general_feature_support_matrix.ini', 'doc/source/contributor/internals/linuxbridge_agent.rst', 'doc/source/install/overview.rst', 'doc/source/admin/config-auto-allocation.rst', 'releasenotes/notes/add-availability-zone-4440cf00be7c54ba.yaml', 'doc/source/admin/config-ovs-dpdk.rst', 'doc/source/contributor/internals/layer3.rst', 'doc/source/admin/config-sriov.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1f05504ede2be60a6f6ce08b8d3c86f711030da', 'message': 'Update the documentation links\n\nThe documentation links which start with ""admin-guide"" and\n""networking-guide"" are outdated. Fix them to be friendly\nto new contributors.\n\nChange-Id: I656ba3b82df6acd2555735093127ca59f7042d44\n'}]",51,522718,b1f05504ede2be60a6f6ce08b8d3c86f711030da,65,12,14,24209,,,0,"Update the documentation links

The documentation links which start with ""admin-guide"" and
""networking-guide"" are outdated. Fix them to be friendly
to new contributors.

Change-Id: I656ba3b82df6acd2555735093127ca59f7042d44
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/522718/9 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/config-lbaas.rst', 'doc/source/admin/intro-basic-networking.rst', 'doc/source/install/overview.rst', 'doc/source/admin/config-auto-allocation.rst', 'doc/source/admin/config-ovs-dpdk.rst', 'doc/source/contributor/internals/layer3.rst', 'doc/source/admin/config-sriov.rst']",7,6fff06b01f9566562a1d6a72bf0bb300114fe53e,doc-migration, <https://docs.openstack.org/nova/latest/admin/pci-passthrough.html#configure-nova-api-controller>`__., <https://docs.openstack.org/admin-guide/compute-pci-passthrough.html#configure-nova-api-controller>`__.,10,10
openstack%2Fkeystonemiddleware~master~I456239842d139074cc38cfd620bb88561bb4d0d7,openstack/keystonemiddleware,master,I456239842d139074cc38cfd620bb88561bb4d0d7,rel-note and doc for lazy loading of oslo_cache,MERGED,2017-12-13 11:01:42.000000000,2017-12-13 22:47:11.000000000,2017-12-13 22:47:11.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 11:01:42.000000000', 'files': ['releasenotes/notes/bug-1737115-fa3d41e3d3cd7177.yaml', 'keystonemiddleware/auth_token/_cache.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/a08bc44e041228d075f2edacf30510064147d0fb', 'message': 'rel-note and doc for lazy loading of oslo_cache\n\nIn continuation of I00e953abb3e835a94353fe458100c96e8e9c095a,\nthis change adds the release note and documentation.\n\nRelated-bug #1737115\n\nChange-Id: I456239842d139074cc38cfd620bb88561bb4d0d7\n'}]",0,527665,a08bc44e041228d075f2edacf30510064147d0fb,6,3,1,2813,,,0,"rel-note and doc for lazy loading of oslo_cache

In continuation of I00e953abb3e835a94353fe458100c96e8e9c095a,
this change adds the release note and documentation.

Related-bug #1737115

Change-Id: I456239842d139074cc38cfd620bb88561bb4d0d7
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/65/527665/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1737115-fa3d41e3d3cd7177.yaml', 'keystonemiddleware/auth_token/_cache.py']",2,a08bc44e041228d075f2edacf30510064147d0fb,bug/1737115," # NOTE(sileht): This will import python-memcached, we don't want # it as hard dependency, so lazy load it.",,8,0
openstack%2Fkeystonemiddleware~master~I00e953abb3e835a94353fe458100c96e8e9c095a,openstack/keystonemiddleware,master,I00e953abb3e835a94353fe458100c96e8e9c095a,lazy loading of oslo_cache,MERGED,2017-12-12 17:22:44.000000000,2017-12-13 22:47:10.000000000,2017-12-13 22:47:10.000000000,"[{'_account_id': 1669}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 7191}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-12-12 17:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/332d8683127661d070efa59ed1c42d67ea6d284a', 'message': 'lazy loading of oslo_cache\n\nNow, we depend on oslo.cache [1], and use the private/internal\nmemcache_pool code of the lib, making oslo.cache failing to import\ninstead of just log an error about missing requirement for selected\ndrivers at runtime.\n\nThis change restores the previous behavior by lazy loading the module.\n\nChange-Id: I00e953abb3e835a94353fe458100c96e8e9c095a\n'}, {'number': 2, 'created': '2017-12-12 18:05:51.000000000', 'files': ['keystonemiddleware/auth_token/_cache.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/35fa0e1da1b96a40aa2aa6dd2be378e4155a22ba', 'message': 'lazy loading of oslo_cache\n\nNow, we depend on oslo.cache [1], and use the private/internal\nmemcache_pool code of the lib, making oslo.cache failing to import\ninstead of just log an error about missing requirement for selected\ndrivers at runtime.\n\nThis change restores the previous behavior by lazy loading the module.\n\n[1] 9d8e2836fe7fca186e0380d8a532540ff5cc5215\n\nChange-Id: I00e953abb3e835a94353fe458100c96e8e9c095a\nCloses-bug: #1737115\n'}]",1,527466,35fa0e1da1b96a40aa2aa6dd2be378e4155a22ba,12,7,2,2813,,,0,"lazy loading of oslo_cache

Now, we depend on oslo.cache [1], and use the private/internal
memcache_pool code of the lib, making oslo.cache failing to import
instead of just log an error about missing requirement for selected
drivers at runtime.

This change restores the previous behavior by lazy loading the module.

[1] 9d8e2836fe7fca186e0380d8a532540ff5cc5215

Change-Id: I00e953abb3e835a94353fe458100c96e8e9c095a
Closes-bug: #1737115
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/66/527466/2 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token/_cache.py'],1,332d8683127661d070efa59ed1c42d67ea6d284a,bug/1737115," from oslo_cache import _memcache_pool self._pool = _memcache_pool.MemcacheClientPool(memcache_servers, **kwargs)","from oslo_cache import _memcache_pool as memcache_pool self._pool = memcache_pool.MemcacheClientPool(memcache_servers, **kwargs)",3,3
openstack%2Fopenstack-ansible~stable%2Fpike~I3037249ff847cc805ac83f71e7df5943efe7eb25,openstack/openstack-ansible,stable/pike,I3037249ff847cc805ac83f71e7df5943efe7eb25,Fix automatic log copying in Zuul runs,MERGED,2017-12-13 14:50:11.000000000,2017-12-13 22:38:47.000000000,2017-12-13 22:38:47.000000000,"[{'_account_id': 538}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-13 14:50:11.000000000', 'files': ['scripts/gate-check-commit.sh', 'scripts/test-log-collect.sh', 'scripts/scripts-library.sh', 'zuul.d/jobs.yaml', 'zuul.d/playbooks/post.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/43ae60f7157a6671b562cde9bf543c9fb5e8b40d', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n(cherry picked from commit 3850e3d1a1b606c3794ef372951b0a768eae3082)\n'}]",0,527701,43ae60f7157a6671b562cde9bf543c9fb5e8b40d,8,4,1,6816,,,0,"Fix automatic log copying in Zuul runs

Key off an environment variable, ""ZUUL_PROJECT"", instead of the
existence of /etc/nodepool, when determining whether to do a log
copy into the workspace at the end of the job.

Change-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25
(cherry picked from commit 3850e3d1a1b606c3794ef372951b0a768eae3082)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/01/527701/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'scripts/test-log-collect.sh', 'zuul.d/jobs.yaml', 'zuul.d/playbooks/post.yml']",5,43ae60f7157a6671b562cde9bf543c9fb5e8b40d,ci-logs-fix-stable/pike,"--- # Copyright 2017, Logan Vig <logan2211@gmail.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - hosts: all tasks: - name: Run log collection script command: scripts/test-log-collect.sh become: yes become_user: root args: chdir: ""src/{{ zuul.project.canonical_name }}"" environment: # ZUUL_PROJECT is used by the log collection functions to enable # log collection configuration specific to OpenStack CI ZUUL_PROJECT: ""{{ zuul.project.short_name }}"" - name: Copy logs back to the executor synchronize: src: ""src/{{ zuul.project.canonical_name }}/logs"" dest: ""{{ zuul.executor.log_root }}"" mode: pull ",,70,9
openstack%2Fopenstack-ansible~stable%2Fpike~I74ef40ce36256dacbd373fd22372f48b6bf276b4,openstack/openstack-ansible,stable/pike,I74ef40ce36256dacbd373fd22372f48b6bf276b4,Reduce console output in gate jobs,MERGED,2017-12-13 09:32:09.000000000,2017-12-13 22:38:46.000000000,2017-12-13 22:38:46.000000000,"[{'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-13 09:32:09.000000000', 'files': ['scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0c911ed8b57f855678f005c27f0ed525eb33ed80', 'message': 'Reduce console output in gate jobs\n\nThis patch brings over the rsync command from the\nopenstack-ansible-tests repository and reduces the\nconsole log output.\n\nChange-Id: I74ef40ce36256dacbd373fd22372f48b6bf276b4\n(cherry picked from commit e795415993fd0959ccfc7c4cd150899990c38bef)\n'}]",0,527648,0c911ed8b57f855678f005c27f0ed525eb33ed80,8,4,1,6816,,,0,"Reduce console output in gate jobs

This patch brings over the rsync command from the
openstack-ansible-tests repository and reduces the
console log output.

Change-Id: I74ef40ce36256dacbd373fd22372f48b6bf276b4
(cherry picked from commit e795415993fd0959ccfc7c4cd150899990c38bef)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/48/527648/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,0c911ed8b57f855678f005c27f0ed525eb33ed80,reduce-console-output-stable/pike," RSYNC_CMD=""rsync --archive --safe-links --ignore-errors --quiet --no-perms --no-owner --no-group"" ${RSYNC_CMD} /var/log/ ""${GATE_LOG_DIR}/host"" || true ${RSYNC_CMD} /openstack/log/ ""${GATE_LOG_DIR}/openstack"" || true"," rsync --archive --verbose --safe-links --ignore-errors /var/log/ ""${GATE_LOG_DIR}/host"" || true rsync --archive --verbose --safe-links --ignore-errors /openstack/log/ ""${GATE_LOG_DIR}/openstack"" || true",3,2
openstack%2Fproject-config~master~I35d9f02c1bda1da95c8a60d6bc12b04061d37692,openstack/project-config,master,I35d9f02c1bda1da95c8a60d6bc12b04061d37692,Add tarball job to ansible-role-rhsm,MERGED,2017-12-13 22:12:48.000000000,2017-12-13 22:35:29.000000000,2017-12-13 22:35:29.000000000,"[{'_account_id': 1004}, {'_account_id': 3153}, {'_account_id': 4162}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 22:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f10bc9fe90f3bb39815cc31f5af52bdcff5d6d5c', 'message': 'Add tarball job to ansible-role-rhsm\n\nChange-Id: I35d9f02c1bda1da95c8a60d6bc12b04061d37692\n'}, {'number': 2, 'created': '2017-12-13 22:25:40.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1a4394d5ad6718db435f1ad05f8d606d4f803ff9', 'message': 'Add tarball job to ansible-role-rhsm\n\nChange-Id: I35d9f02c1bda1da95c8a60d6bc12b04061d37692\n'}]",2,527797,1a4394d5ad6718db435f1ad05f8d606d4f803ff9,14,5,2,3153,,,0,"Add tarball job to ansible-role-rhsm

Change-Id: I35d9f02c1bda1da95c8a60d6bc12b04061d37692
",git fetch https://review.opendev.org/openstack/project-config refs/changes/97/527797/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,f10bc9fe90f3bb39815cc31f5af52bdcff5d6d5c,ansibllleeeee, post: jobs: - publish-openstack-python-tarball,,3,0
openstack%2Fneutron~master~I36c2defa9c988f12507f482c7f2402ec898ff36c,openstack/neutron,master,I36c2defa9c988f12507f482c7f2402ec898ff36c,Updated from global requirements,MERGED,2017-11-29 09:05:26.000000000,2017-12-13 22:21:38.000000000,2017-12-13 22:21:38.000000000,"[{'_account_id': 841}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-29 09:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2cc3ee418e7019fe8718bfd3f772ca584e6b7b50', 'message': 'Updated from global requirements\n\nChange-Id: I36c2defa9c988f12507f482c7f2402ec898ff36c\n'}, {'number': 2, 'created': '2017-12-05 03:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/328cdf4721ad9a3dbe4595e6226aa64ea6f8a240', 'message': 'Updated from global requirements\n\nChange-Id: I36c2defa9c988f12507f482c7f2402ec898ff36c\n'}, {'number': 3, 'created': '2017-12-07 13:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01392055535d58b387fda9b64f6a970885370051', 'message': 'Updated from global requirements\n\nChange-Id: I36c2defa9c988f12507f482c7f2402ec898ff36c\n'}, {'number': 4, 'created': '2017-12-07 13:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08b79c83927dc572602118cca1b39c917c69d9de', 'message': 'Updated from global requirements\n\nChange-Id: I36c2defa9c988f12507f482c7f2402ec898ff36c\n'}, {'number': 5, 'created': '2017-12-10 07:20:53.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d080adf975a6f588170af64f2c47a72690546e06', 'message': 'Updated from global requirements\n\nChange-Id: I36c2defa9c988f12507f482c7f2402ec898ff36c\n'}]",0,523760,d080adf975a6f588170af64f2c47a72690546e06,22,5,5,11131,,,0,"Updated from global requirements

Change-Id: I36c2defa9c988f12507f482c7f2402ec898ff36c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/523760/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2cc3ee418e7019fe8718bfd3f772ca584e6b7b50,openstack/requirements,oslo.config>=5.1.0 # Apache-2.0,oslo.config>=4.6.0 # Apache-2.0,1,1
openstack%2Fneutron~master~Ie9876064da989842576eeb30804b6a991d4d2937,openstack/neutron,master,Ie9876064da989842576eeb30804b6a991d4d2937,Switch to use _get_subnet_object in neutrondb_ipam driver,MERGED,2017-12-12 12:44:25.000000000,2017-12-13 22:11:23.000000000,2017-12-13 22:11:23.000000000,"[{'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 7249}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 22348}, {'_account_id': 25903}]","[{'number': 1, 'created': '2017-12-12 12:44:25.000000000', 'files': ['neutron/ipam/drivers/neutrondb_ipam/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a8a1262cfea2ff4051d1b063b327b4567ae943d', 'message': 'Switch to use _get_subnet_object in neutrondb_ipam driver\n\nInstead of using old _get_subnet() method new method\n_get_subnet_object() will now be used in neutrondb_ipam\ndriver and because of that it will use Subnet OVO object.\n\nChange-Id: Ie9876064da989842576eeb30804b6a991d4d2937\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n'}]",0,527392,9a8a1262cfea2ff4051d1b063b327b4567ae943d,14,12,1,11975,,,0,"Switch to use _get_subnet_object in neutrondb_ipam driver

Instead of using old _get_subnet() method new method
_get_subnet_object() will now be used in neutrondb_ipam
driver and because of that it will use Subnet OVO object.

Change-Id: Ie9876064da989842576eeb30804b6a991d4d2937
Partially-Implements: blueprint adopt-oslo-versioned-objects-for-db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/527392/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/ipam/drivers/neutrondb_ipam/driver.py'],1,9a8a1262cfea2ff4051d1b063b327b4567ae943d,bp/adopt-oslo-versioned-objects-for-db," neutron_subnet_obj = cls._fetch_subnet(ctx, neutron_subnet_id) cidr=neutron_subnet_obj.cidr, gateway_ip=neutron_subnet_obj.gateway_ip, tenant_id=neutron_subnet_obj.tenant_id, return plugin._get_subnet_object(context, id)"," neutron_subnet = cls._fetch_subnet(ctx, neutron_subnet_id) cidr=neutron_subnet['cidr'], gateway_ip=neutron_subnet['gateway_ip'], tenant_id=neutron_subnet['tenant_id'], return plugin._get_subnet(context, id)",5,5
openstack%2Fansible-role-redhat-subscription~master~Ibe4042308606e7ca2334f214d5b6bca006633adb,openstack/ansible-role-redhat-subscription,master,Ibe4042308606e7ca2334f214d5b6bca006633adb,Initial commit,MERGED,2017-12-13 02:23:50.000000000,2017-12-13 22:01:36.000000000,2017-12-13 22:01:36.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16774}, {'_account_id': 22348}, {'_account_id': 27253}]","[{'number': 1, 'created': '2017-12-13 02:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/72d13cea4d8fee9a0d7b6b709b513e0390e468ec', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* LICENSE\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements\n)\n\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 2, 'created': '2017-12-13 02:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/d5f12b721467a5ada7bcf750cf0d4657b646d2c9', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* LICENSE\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements\n)\n\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 3, 'created': '2017-12-13 02:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/36e0fd1b6941a22495983ba12ae47c80fe2ea6a1', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* LICENSE\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements\n)\n\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 4, 'created': '2017-12-13 05:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/94d8390ca5a679e7279155f81dbece5dcedfd58c', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* LICENSE\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 5, 'created': '2017-12-13 14:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/2363570323be2fb5eb1ba5c595e93eb56d67b4ac', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 6, 'created': '2017-12-13 16:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/8a1b93ba58dbdddd7a59c05c88c46e98266138c3', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 7, 'created': '2017-12-13 17:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/a9e23394a97ceeca1b35510fadffe7fa458501b5', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 8, 'created': '2017-12-13 18:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/27bd1dbe2148b2c44a31f4e65eecdfa8f629d302', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* release notes (managed by reno)\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 9, 'created': '2017-12-13 18:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/bc6440fb89074d683083fc29df5973be7f7fd9e2', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 10, 'created': '2017-12-13 18:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/8156db2fc1818a3ed8c223dbd993fb11ed155e6f', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 11, 'created': '2017-12-13 19:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/01788e12df7218ee7a2fdb6f6679492a4e43d049', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 12, 'created': '2017-12-13 19:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/79128f098200a9c1a6598c7873ac8010b53bd8ac', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 13, 'created': '2017-12-13 19:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/952a3ba9e98d8ad8023b531dbc4129e53e8dc00f', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n* Fix some pep8 errors\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 14, 'created': '2017-12-13 19:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/73afc0ff910587b7ddc4067e3c634e823884fe2f', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n* Fix some pep8 errors\n* CI scripts\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}, {'number': 15, 'created': '2017-12-13 20:53:11.000000000', 'files': ['.gitignore', '.gitreview', 'test-requirements.txt', 'setup.py', 'tests/test.yml', 'ansible.cfg', 'ci-scripts/ansible-lint.sh', 'ansible-requirements.txt', 'requirements.txt', 'library/redhat_repos.py', 'setup.cfg', 'LICENSE', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/93aa321a662bd152d442f05a6bfa5763a37a5444', 'message': 'Initial commit\n\n* .gitignore\n* .gitreview\n* Re-licensing to Apache 2.0\n* ansible-requirements\n* python dependencies (tox, setup, requirements)\n* Fix some pep8 errors\n* CI scripts\n\nDepends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\nChange-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb\n'}]",1,527561,93aa321a662bd152d442f05a6bfa5763a37a5444,40,5,15,3153,,,0,"Initial commit

* .gitignore
* .gitreview
* Re-licensing to Apache 2.0
* ansible-requirements
* python dependencies (tox, setup, requirements)
* Fix some pep8 errors
* CI scripts

Depends-On: Ief06ef2fde45851df0c9cea4764dfe38c1777e46
Change-Id: Ibe4042308606e7ca2334f214d5b6bca006633adb
",git fetch https://review.opendev.org/openstack/ansible-role-redhat-subscription refs/changes/61/527561/5 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview', 'test-requirements.txt', 'setup.py', 'releasenotes/source/index.rst', 'releasenotes/source/_static/.gitignore', 'ansible-requirements.txt', 'releasenotes/source/unreleased.rst', 'requirements.txt', 'releasenotes/notes/releasenotes-56f6c4138b4e8d1d.yaml', 'setup.cfg', 'LICENSE', 'tox.ini', 'releasenotes/source/conf.py']",14,72d13cea4d8fee9a0d7b6b709b513e0390e468ec,init,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. #sys.path.insert(0, os.path.abspath('.')) # -- General configuration ------------------------------------------------ # If your documentation needs a minimal Sphinx version, state it here. #needs_sphinx = '1.0' # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom # ones. extensions = [ 'openstackdocstheme', 'reno.sphinxext', ] # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. #source_encoding = 'utf-8-sig' # The master toctree document. master_doc = 'index' # General information about the project. project = u'ansible-role-redhat-subscription Release Notes' copyright = u'2017, OpenStack Developers' # The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The full version, including alpha/beta/rc tags. release = '' # The short X.Y version. version = '' # The full version, including alpha/beta/rc tags. # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. #language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: #today = '' # Else, today_fmt is used as the format for a strftime call. #today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. #default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. #add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). #add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. #show_authors = False # The name of the Pygments (syntax highlighting) style to use. pygments_style = 'sphinx' # A list of ignored prefixes for module index sorting. #modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. #keep_warnings = False # -- Options for HTML output ---------------------------------------------- # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. html_theme = 'openstackdocs' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. #html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. #html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". #html_title = None # A shorter title for the navigation bar. Default is the same as html_title. #html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. #html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. #html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. #html_extra_path = [] # If not '', a 'Last updated on:' timestamp is inserted at every page bottom, # using the given strftime format. #html_last_updated_fmt = '%b %d, %Y' # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. #html_use_smartypants = True # Custom sidebar templates, maps document names to template names. #html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. #html_additional_pages = {} # If false, no module index is generated. #html_domain_indices = True # If false, no index is generated. #html_use_index = True # If true, the index is split into individual pages for each letter. #html_split_index = False # If true, links to the reST sources are added to the pages. #html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. #html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. #html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. #html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). #html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'ansible-role-redhat-subscriptionReleaseNotesdoc' # -- Options for LaTeX output --------------------------------------------- latex_elements = { # The paper size ('letterpaper' or 'a4paper'). #'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). #'pointsize': '10pt', # Additional stuff for the LaTeX preamble. #'preamble': '', } # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'ansible-role-redhat-subscriptionReleaseNotes.tex', u'ansible-role-redhat-subscription Release Notes Documentation', u'2016, OpenStack Developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. #latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. #latex_use_parts = False # If true, show page references after internal links. #latex_show_pagerefs = False # If true, show URL addresses after external links. #latex_show_urls = False # Documents to append as an appendix to all manuals. #latex_appendices = [] # If false, no module index is generated. #latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'ansible-role-redhat-subscriptionreleasenotes', u'ansible-role-redhat-subscription Release Notes Documentation', [u'2016, OpenStack Developers'], 1) ] # If true, show URL addresses after external links. #man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'ansible-role-redhat-subscriptionReleaseNotes', u'ansible-role-redhat-subscription Release Notes Documentation', u'2016, OpenStack Developers', 'ansible-role-redhat-subscriptionReleaseNotes', 'One line description of project.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. #texinfo_appendices = [] # If false, no module index is generated. #texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. #texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. #texinfo_no_detailmenu = False # -- Options for Internationalization output ------------------------------ locale_dirs = ['locale/'] # openstackdocstheme options repository_name = 'openstack/ansible-role-redhat-subscription' bug_project = 'tripleo' bug_tag = 'documentation' ",,726,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I85d05cead304249c9e6a6fa84a3d5b2a0c36110f,openstack/openstack-ansible-lxc_hosts,master,I85d05cead304249c9e6a6fa84a3d5b2a0c36110f,"Revert ""Add the systemd-networkd to centos 7 installations""",MERGED,2017-12-13 21:02:34.000000000,2017-12-13 21:48:59.000000000,2017-12-13 21:48:59.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 21:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f0bbdf9682d829367c959be44aae5978b6cb0cbc', 'message': 'Revert ""Add the systemd-networkd to centos 7 installations""\n\nThis reverts commit 6c953712108415f9ba4bbae4a2ebd8dcea568b32.\n\nChange-Id: I85d05cead304249c9e6a6fa84a3d5b2a0c36110f\n'}, {'number': 2, 'created': '2017-12-13 21:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c670526b40837d0305eae40c761db085b45ad165', 'message': 'Revert ""Add the systemd-networkd to centos 7 installations""\n\nWhen systemd-networkd and old sysv init scripts are\nmanaging networking, the LXC container stop times out\nand causes deployments to fail.\n\nThis reverts commit 6c953712108415f9ba4bbae4a2ebd8dcea568b32.\n\nChange-Id: I85d05cead304249c9e6a6fa84a3d5b2a0c36110f\n'}, {'number': 3, 'created': '2017-12-13 21:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0ca724f0a7c35fad4de6791372ff4b03706e2a4b', 'message': 'Revert ""Add the systemd-networkd to centos 7 installations""\n\nThis reverts commit 6c953712108415f9ba4bbae4a2ebd8dcea568b32.\n\nChange-Id: I85d05cead304249c9e6a6fa84a3d5b2a0c36110f\n'}, {'number': 4, 'created': '2017-12-13 21:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/82b13af33cba2760e246737292cdfb05b9a8447b', 'message': 'Revert ""Add the systemd-networkd to centos 7 installations""\n\nWhen systemd-networkd and old sysv init scripts are\nmanaging networking, the LXC container stop times out\nand causes deployments to fail.\n\nThis reverts commit 6c953712108415f9ba4bbae4a2ebd8dcea568b32.\nThis reverts commit 84ac3442e542aeedf1396c88e0387b4ea1548eb1.\n\nChange-Id: I85d05cead304249c9e6a6fa84a3d5b2a0c36110f\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2017-12-13 21:09:11.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/6b529de0315fe6cd12f6e78c00a5f2f2d3a01e28', 'message': 'Revert ""Add the systemd-networkd to centos 7 installations""\n\nWhen systemd-networkd and old sysv init scripts are\nmanaging networking, the LXC container stop times out\nand causes deployments to fail.\n\nThis reverts commit 6c953712108415f9ba4bbae4a2ebd8dcea568b32.\nThis reverts commit 84ac3442e542aeedf1396c88e0387b4ea1548eb1.\n\nChange-Id: I85d05cead304249c9e6a6fa84a3d5b2a0c36110f\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",2,527783,6b529de0315fe6cd12f6e78c00a5f2f2d3a01e28,16,5,5,7353,,,0,"Revert ""Add the systemd-networkd to centos 7 installations""

When systemd-networkd and old sysv init scripts are
managing networking, the LXC container stop times out
and causes deployments to fail.

This reverts commit 6c953712108415f9ba4bbae4a2ebd8dcea568b32.
This reverts commit 84ac3442e542aeedf1396c88e0387b4ea1548eb1.

Change-Id: I85d05cead304249c9e6a6fa84a3d5b2a0c36110f
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/83/527783/4 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,f0bbdf9682d829367c959be44aae5978b6cb0cbc,,, - systemd-networkd,0,1
openstack%2Fos-loganalyze~master~Ie5428066e6c185de2bd25e2e84823393c6b87d02,openstack/os-loganalyze,master,Ie5428066e6c185de2bd25e2e84823393c6b87d02,Handle screen-placement-api,MERGED,2017-11-13 19:36:59.000000000,2017-12-13 21:40:41.000000000,2017-12-13 21:40:41.000000000,"[{'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6873}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-13 19:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/939f7f9b41f0f7f582f4eea0ca834a0f8cf9315d', 'message': 'Handle screen-placement-api\n\nSince Pike the placement-api logs show up under\nscreen-placement-api since placement-api is run\nusing uwsgi rather than Apache.\n\nChange-Id: Ie5428066e6c185de2bd25e2e84823393c6b87d02\n'}, {'number': 2, 'created': '2017-11-13 19:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/24be71bf7719a78384fccf87b0e6a04d353ef3f6', 'message': 'Handle screen-placement-api\n\nSince Pike the placement-api logs show up under\nscreen-placement-api since placement-api is run\nusing uwsgi rather than Apache.\n\nChange-Id: Ie5428066e6c185de2bd25e2e84823393c6b87d02\n'}, {'number': 3, 'created': '2017-12-13 15:21:03.000000000', 'files': ['os_loganalyze/filter.py'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/33ee1b89b855c1abdda25a2b253c20c4568a5828', 'message': 'Handle screen-placement-api\n\nSince Pike the placement-api logs show up under\nscreen-placement-api since placement-api is run\nusing uwsgi rather than Apache.\n\nChange-Id: Ie5428066e6c185de2bd25e2e84823393c6b87d02\n'}]",3,519458,33ee1b89b855c1abdda25a2b253c20c4568a5828,16,5,3,6873,,,0,"Handle screen-placement-api

Since Pike the placement-api logs show up under
screen-placement-api since placement-api is run
using uwsgi rather than Apache.

Change-Id: Ie5428066e6c185de2bd25e2e84823393c6b87d02
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/58/519458/1 && git format-patch -1 --stdout FETCH_HEAD,['os_loganalyze/filter.py'],1,939f7f9b41f0f7f582f4eea0ca834a0f8cf9315d,bug/1731668, r'((screen-)?(n-|c-|g-|h-|ir-|ironic-|m-|o-|placement-api|', r'((screen-)?(n-|c-|g-|h-|ir-|ironic-|m-|o-|',1,1
openstack%2Fpython-brick-cinderclient-ext~stable%2Fpike~I2085cc3969f93a0444532b43dd3b6f87e62d20aa,openstack/python-brick-cinderclient-ext,stable/pike,I2085cc3969f93a0444532b43dd3b6f87e62d20aa,Update UPPER_CONSTRAINTS_FILE for stable/pike,MERGED,2017-07-28 21:06:19.000000000,2017-12-13 21:34:23.000000000,2017-12-13 21:34:23.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-07-28 21:06:19.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/59c895e7892395877f03b3040cac89233d31d33c', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/pike\n\nChange-Id: I2085cc3969f93a0444532b43dd3b6f87e62d20aa\n'}]",0,488749,59c895e7892395877f03b3040cac89233d31d33c,12,4,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/pike

Change-Id: I2085cc3969f93a0444532b43dd3b6f87e62d20aa
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/49/488749/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,59c895e7892395877f03b3040cac89233d31d33c,create-pike,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/pike} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Freleases~master~Ie666a55e3dcebe7b4486977a35989f3d41ef72ef,openstack/releases,master,Ie666a55e3dcebe7b4486977a35989f3d41ef72ef,Release python-openstackclient 3.13.0,MERGED,2017-12-13 20:40:08.000000000,2017-12-13 21:26:46.000000000,2017-12-13 21:26:46.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 20:40:08.000000000', 'files': ['deliverables/queens/python-openstackclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/66f9ad1aa8769c241723cdce8f94ab8a72f8f6c4', 'message': 'Release python-openstackclient 3.13.0\n\nChange-Id: Ie666a55e3dcebe7b4486977a35989f3d41ef72ef\n'}]",0,527781,66f9ad1aa8769c241723cdce8f94ab8a72f8f6c4,6,2,1,970,,,0,"Release python-openstackclient 3.13.0

Change-Id: Ie666a55e3dcebe7b4486977a35989f3d41ef72ef
",git fetch https://review.opendev.org/openstack/releases refs/changes/81/527781/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/python-openstackclient.yaml'],1,66f9ad1aa8769c241723cdce8f94ab8a72f8f6c4,osc-3.13.0,releases: - version: 3.13.0 projects: - repo: openstack/python-openstackclient hash: 8c5f7555698491c3a0b44fe6c3fee50d0189f2d6,,5,0
openstack%2Freleases~master~Icf7e892dfcc0965686be5666019e99175e6dd259,openstack/releases,master,Icf7e892dfcc0965686be5666019e99175e6dd259,Release osc-lib 1.8.0,MERGED,2017-12-13 20:39:44.000000000,2017-12-13 21:24:09.000000000,2017-12-13 21:24:09.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 20:39:44.000000000', 'files': ['deliverables/queens/osc-lib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6fb569b4aadabe72f04f7aa6b3d929a5473f1c0b', 'message': 'Release osc-lib 1.8.0\n\nChange-Id: Icf7e892dfcc0965686be5666019e99175e6dd259\n'}]",0,527780,6fb569b4aadabe72f04f7aa6b3d929a5473f1c0b,6,2,1,970,,,0,"Release osc-lib 1.8.0

Change-Id: Icf7e892dfcc0965686be5666019e99175e6dd259
",git fetch https://review.opendev.org/openstack/releases refs/changes/80/527780/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/osc-lib.yaml'],1,6fb569b4aadabe72f04f7aa6b3d929a5473f1c0b,osc-lib-1.8.0,releases: - projects: - hash: a8e71b0565e94cdd47d0550ada2555dca45a85d5 repo: openstack/osc-lib version: 1.8.0,,5,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I8726b46f4058bb67709246785c7a61278eb64fab,openstack/openstack-ansible-lxc_hosts,master,I8726b46f4058bb67709246785c7a61278eb64fab,Create and use a local LXC RPM repo,MERGED,2017-12-08 17:11:57.000000000,2017-12-13 21:16:05.000000000,2017-12-13 18:16:06.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-08 17:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/993b2f91a13f8c48df2b99c40ac583dd3a5d65ec', 'message': '[TEST] Try making a local LXC RPM repo\n\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n'}, {'number': 2, 'created': '2017-12-08 17:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/89399cdf00700239f3cca8b494a2c4778d9de33e', 'message': '[TEST] Try making a local LXC RPM repo\n\nThis patch changes how CentOS hosts use the thm-lxc2.0 COPR repo.\nEach host syncs down the repository, makes a local repo, and then\ninstalls from that repository.\n\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n'}, {'number': 3, 'created': '2017-12-08 20:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/5b7b27af693e1c6122d1c84bb39f11fe85f4be18', 'message': 'Create and use a local LXC RPM repo\n\nThis patch changes how CentOS hosts use the thm-lxc2.0 COPR repo.\nEach host syncs down the repository, makes a local repo, and then\ninstalls from that repository.\n\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n'}, {'number': 4, 'created': '2017-12-11 17:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d0bf09f19591aa6de57e52cccaf399ef6e9fe495', 'message': ""Create and use a local LXC RPM repo\n\nCentOS deployments require a special COPR repository for modern LXC\npackages. The COPR repository isn't mirrored at this time and this\ncauses failed gate tests and production deployments.\n\nThe role now syncs the LXC packages down from COPR to each host and\nbuilds a local LXC package repository in `/opt/thm-lxc2.0`. This\ngreatly reduces the amount of times that packages must be downloaded\nfrom the COPR server during deployments, which will reduce failures\nuntil the packages can be hosted with a more reliable source.\n\nIn addition, this should speed up playbook runs since ``yum`` can\ncheck a locally-hosted repository instead of a remote repository\nwith availability and performance challenges.\n\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n""}, {'number': 5, 'created': '2017-12-12 17:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/8f96e05d97478496ae943d624ae0dff5f119bcb3', 'message': ""Create and use a local LXC RPM repo\n\nCentOS deployments require a special COPR repository for modern LXC\npackages. The COPR repository isn't mirrored at this time and this\ncauses failed gate tests and production deployments.\n\nThe role now syncs the LXC packages down from COPR to each host and\nbuilds a local LXC package repository in `/opt/thm-lxc2.0`. This\ngreatly reduces the amount of times that packages must be downloaded\nfrom the COPR server during deployments, which will reduce failures\nuntil the packages can be hosted with a more reliable source.\n\nIn addition, this should speed up playbook runs since ``yum`` can\ncheck a locally-hosted repository instead of a remote repository\nwith availability and performance challenges.\n\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n""}, {'number': 6, 'created': '2017-12-12 17:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/5127d57e9460689fc7660c7fe195e88bc89025a1', 'message': ""Create and use a local LXC RPM repo\n\nCentOS deployments require a special COPR repository for modern LXC\npackages. The COPR repository isn't mirrored at this time and this\ncauses failed gate tests and production deployments.\n\nThe role now syncs the LXC packages down from COPR to each host and\nbuilds a local LXC package repository in `/opt/thm-lxc2.0`. This\ngreatly reduces the amount of times that packages must be downloaded\nfrom the COPR server during deployments, which will reduce failures\nuntil the packages can be hosted with a more reliable source.\n\nIn addition, this should speed up playbook runs since ``yum`` can\ncheck a locally-hosted repository instead of a remote repository\nwith availability and performance challenges.\n\nPartial-Bug: 1730380\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n""}, {'number': 7, 'created': '2017-12-13 13:31:30.000000000', 'files': ['releasenotes/notes/centos-local-lxc-package-mirror-843e1ceac2469547.yaml', 'vars/redhat-7.yml', 'tasks/lxc_install_yum.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/499eb6fe2167fcf4c5c1687e828c39c896b2c618', 'message': ""Create and use a local LXC RPM repo\n\nCentOS deployments require a special COPR repository for modern LXC\npackages. The COPR repository isn't mirrored at this time and this\ncauses failed gate tests and production deployments.\n\nThe role now syncs the LXC packages down from COPR to each host and\nbuilds a local LXC package repository in `/opt/thm-lxc2.0`. This\ngreatly reduces the amount of times that packages must be downloaded\nfrom the COPR server during deployments, which will reduce failures\nuntil the packages can be hosted with a more reliable source.\n\nIn addition, this should speed up playbook runs since ``yum`` can\ncheck a locally-hosted repository instead of a remote repository\nwith availability and performance challenges.\n\nPartial-Bug: 1730380\nChange-Id: I8726b46f4058bb67709246785c7a61278eb64fab\n""}]",5,526739,499eb6fe2167fcf4c5c1687e828c39c896b2c618,29,6,7,538,,,0,"Create and use a local LXC RPM repo

CentOS deployments require a special COPR repository for modern LXC
packages. The COPR repository isn't mirrored at this time and this
causes failed gate tests and production deployments.

The role now syncs the LXC packages down from COPR to each host and
builds a local LXC package repository in `/opt/thm-lxc2.0`. This
greatly reduces the amount of times that packages must be downloaded
from the COPR server during deployments, which will reduce failures
until the packages can be hosted with a more reliable source.

In addition, this should speed up playbook runs since ``yum`` can
check a locally-hosted repository instead of a remote repository
with availability and performance challenges.

Partial-Bug: 1730380
Change-Id: I8726b46f4058bb67709246785c7a61278eb64fab
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/39/526739/6 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_install_yum.yml'],1,993b2f91a13f8c48df2b99c40ac583dd3a5d65ec,bug/1730380,"- name: Ensure createrepo package is installed yum: name: createrepo state: latest - name: Deploy upstream COPR yum repo for LXC 2.0 enabled: no gpgcheck: yes gpgkey: ""{{ lxc_centos_package_key }}"" repo_gpgcheck: no priority: 50 state: present - name: Deploy local COPR yum repo for LXC 2.0 yum_repository: name: thm-lxc2.0-local description: ""Local repository for LXC 2.0 packages on CentOS 7"" baseurl: ""file:///opt/thm-lxc2.0"" enabled: no- name: Sync the remote COPR repository down to the host command: reposync --repoid=thm-lxc2.0 --download_path=/tmp/ - name: Create a local yum repository command: createrepo /tmp/thm-lxc2.0 - name: Sync the repository into place command: rsync -a --delete /tmp/thm-lxc2.0/ /opt/thm-lxc2.0/ - name: Ensure the local repository is enabled command: yum-config-manager --enable thm-lxc2.0-local ",- name: Deploy COPR yum repo for LXC 2.0 enabled: yes,31,2
openstack%2Fnova~master~Ia89eeb6725459c35369e8f790f68ad9180bd3aba,openstack/nova,master,Ia89eeb6725459c35369e8f790f68ad9180bd3aba,Deprecate file injection,MERGED,2017-11-21 22:05:58.000000000,2017-12-13 21:08:27.000000000,2017-12-13 21:08:26.000000000,"[{'_account_id': 7}, {'_account_id': 6125}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-21 22:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab31b0a7de01308b4c63ed2a09bc28b3f04a4c46', 'message': 'WIP: Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 2, 'created': '2017-11-22 16:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/734eddf30f65a41588a3d178efa928459b777b24', 'message': 'WIP: Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 3, 'created': '2017-11-22 18:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6756d94a393d3ab8a052a36d384ad0b96f524b68', 'message': 'WIP: Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 4, 'created': '2017-11-22 20:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/830ce77a670855f71634fb6feac25cb7559e458c', 'message': 'WIP: Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 5, 'created': '2017-11-23 00:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/048b0d62f3db8cadd196caf582f0fcfb632492d0', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 6, 'created': '2017-11-23 15:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f45a66a9c6d98f57383ef87f074a6bd1bf61cd1', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 7, 'created': '2017-11-24 16:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0f8d47812f2c98ac015c85632f5ef7dce4c84af', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 8, 'created': '2017-11-27 23:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17f57e2bb002c2268f7be77e2a0960a9321fd17b', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 9, 'created': '2017-12-01 00:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e628e33ac0ecf3f5cb7799fbb500ea190e9fd144', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 10, 'created': '2017-12-01 14:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65d7154b3bcb7f5c74a61cbbf8bccf8158c829af', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 11, 'created': '2017-12-07 13:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8964318bfd824d717e904f7a3819bc498c23e238', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 12, 'created': '2017-12-08 15:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1195e9b9d2f421aa93d5412b0a2ae574af908d5c', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 13, 'created': '2017-12-11 16:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cb9f198ba0096b879a15be33742b52f53081d92', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}, {'number': 14, 'created': '2017-12-12 14:22:41.000000000', 'files': ['api-ref/source/parameters.yaml', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/user-quotas-update-post-req.json.tpl', 'doc/api_samples/os-quota-class-sets/v2.57/quota-classes-update-post-resp.json', 'doc/api_samples/servers/v2.57/server-action-rebuild.json', 'doc/api_samples/versions/versions-get-resp.json', 'nova/tests/functional/api_sample_tests/test_limits.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/user-quotas-show-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.57/quotas-show-get-resp.json', 'doc/api_samples/os-quota-sets/v2.57/quotas-show-detail-get-resp.json', 'doc/api_samples/os-quota-sets/v2.57/quotas-show-defaults-get-resp.json', 'doc/api_samples/versions/v21-version-get-resp.json', 'releasenotes/notes/bp-deprecate-file-injection-feaf490524d10b3d.yaml', 'nova/api/openstack/compute/quota_sets.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/user-quotas-update-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/limits/v2.57/limit-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.57/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-class-sets/v2.57/quota-classes-update-post-resp.json.tpl', 'doc/api_samples/os-quota-class-sets/v2.57/quota-classes-show-get-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-update-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_servers.py', 'nova/api/openstack/compute/limits.py', 'doc/api_samples/os-quota-sets/v2.57/user-quotas-update-post-resp.json', 'nova/tests/functional/api_sample_tests/test_quota_sets.py', 'doc/api_samples/servers/v2.57/server-action-rebuild-resp.json', 'nova/tests/functional/api_sample_tests/test_quota_classes.py', 'nova/api/openstack/compute/schemas/quota_sets.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-class-sets/v2.57/quota-classes-update-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-update-post-req.json.tpl', 'doc/api_samples/os-quota-sets/v2.57/quotas-update-force-post-resp.json', 'nova/api/openstack/compute/schemas/quota_classes.py', 'nova/api/openstack/compute/views/limits.py', 'doc/api_samples/os-quota-sets/v2.57/user-quotas-update-post-req.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-show-detail-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.57/server-create-req.json.tpl', 'nova/api/openstack/api_version_request.py', 'nova/api/openstack/compute/quota_classes.py', 'api-ref/source/servers-actions.inc', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-update-force-post-req.json.tpl', 'doc/api_samples/os-quota-class-sets/v2.57/quota-classes-update-post-req.json', 'nova/tests/unit/api/openstack/compute/test_serversV21.py', 'doc/api_samples/limits/v2.57/limit-get-resp.json', 'nova/api/openstack/compute/rest_api_version_history.rst', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-show-defaults-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.57/server-create-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-class-sets/v2.57/quota-classes-show-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.57/quotas-update-force-post-req.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-show-get-resp.json.tpl', 'nova/tests/unit/api/openstack/compute/test_quota_classes.py', 'doc/api_samples/servers/v2.57/server-create-req.json', 'nova/tests/unit/api/openstack/compute/test_quotas.py', 'nova/api/openstack/compute/servers.py', 'doc/api_samples/os-quota-sets/v2.57/quotas-update-post-req.json', 'nova/api/openstack/compute/schemas/servers.py', 'doc/api_samples/os-quota-sets/v2.57/user-quotas-show-get-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.57/quotas-update-force-post-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.57/quotas-update-post-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.57/server-action-rebuild.json.tpl', 'api-ref/source/servers.inc', 'doc/api_samples/servers/v2.57/server-create-resp.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/126c3d4c78d937888213979272534e1cb706a4d4', 'message': 'Deprecate file injection\n\nThis microversion makes the following changes:\n\n1. Deprecates personality files from POST /servers and the rebuild\n   server action APIs.\n2. Adds the ability to pass new user_data to the rebuild server\n   action API.\n3. Personality / file injection related limits and quota resources\n   are removed from the limits, os-quota-sets and os-quota-class-sets\n   APIs.\n\nImplements blueprint deprecate-file-injection\n\nChange-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba\n'}]",25,522027,126c3d4c78d937888213979272534e1cb706a4d4,198,20,14,6873,,,0,"Deprecate file injection

This microversion makes the following changes:

1. Deprecates personality files from POST /servers and the rebuild
   server action APIs.
2. Adds the ability to pass new user_data to the rebuild server
   action API.
3. Personality / file injection related limits and quota resources
   are removed from the limits, os-quota-sets and os-quota-class-sets
   APIs.

Implements blueprint deprecate-file-injection

Change-Id: Ia89eeb6725459c35369e8f790f68ad9180bd3aba
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/522027/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'doc/api_samples/os-quota-sets/v2.56/user-quotas-update-post-resp.json', 'doc/api_samples/os-quota-sets/v2.56/quotas-update-post-req.json', 'doc/api_samples/versions/versions-get-resp.json', 'nova/tests/functional/api_sample_tests/test_limits.py', 'doc/api_samples/os-quota-sets/v2.56/quotas-update-force-post-req.json', 'nova/tests/unit/api/openstack/compute/test_limits.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-update-post-req.json.tpl', 'doc/api_samples/os-quota-sets/v2.56/quotas-show-detail-get-resp.json', 'doc/api_samples/versions/v21-version-get-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-update-force-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-show-defaults-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-class-sets/v2.56/quota-classes-update-post-req.json.tpl', 'releasenotes/notes/bp-deprecate-file-injection-feaf490524d10b3d.yaml', 'nova/api/openstack/compute/quota_sets.py', 'doc/api_samples/os-quota-sets/v2.56/quotas-show-defaults-get-resp.json', 'doc/api_samples/os-quota-sets/v2.56/quotas-update-post-resp.json', 'doc/api_samples/limits/v2.56/limit-get-resp.json', 'doc/api_samples/os-quota-class-sets/v2.56/quota-classes-update-post-req.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/user-quotas-update-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/test_quota_sets.py', 'nova/tests/functional/api_sample_tests/test_quota_classes.py', 'nova/api/openstack/compute/schemas/quota_sets.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-show-get-resp.json.tpl', 'nova/api/openstack/compute/schemas/quota_classes.py', 'nova/api/openstack/compute/views/limits.py', 'nova/api/openstack/api_version_request.py', 'nova/api/openstack/compute/quota_classes.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-class-sets/v2.56/quota-classes-update-post-resp.json.tpl', 'api-ref/source/servers-actions.inc', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-update-force-resp.json.tpl', 'nova/api/openstack/compute/rest_api_version_history.rst', 'nova/tests/functional/api_sample_tests/api_samples/limits/v2.56/limit-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.56/quotas-update-force-post-resp.json', 'nova/compute/api.py', 'doc/api_samples/os-quota-sets/v2.56/user-quotas-update-post-req.json', 'doc/api_samples/os-quota-sets/v2.56/quotas-show-get-resp.json', 'doc/api_samples/os-quota-sets/v2.56/user-quotas-show-get-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/user-quotas-update-post-resp.json.tpl', 'doc/api_samples/os-quota-class-sets/v2.56/quota-classes-update-post-resp.json', 'nova/tests/unit/api/openstack/compute/test_quota_classes.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-class-sets/v2.56/quota-classes-show-get-resp.json.tpl', 'nova/tests/unit/api/openstack/compute/test_quotas.py', 'nova/api/openstack/compute/servers.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/user-quotas-show-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-update-post-resp.json.tpl', 'doc/api_samples/os-quota-class-sets/v2.56/quota-classes-show-get-resp.json', 'nova/api/openstack/compute/schemas/servers.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-show-detail-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.56/quotas-update-force-post-resp.json.tpl', 'api-ref/source/servers.inc']",51,ab31b0a7de01308b4c63ed2a09bc28b3f04a4c46,bp/deprecate-file-injection,.. note:: The use of personality files is deprecated starting with the 2.56 microversion. Use ``metadata`` and ``user_data`` to customize a server instance. ,,745,45
openstack%2Fopenstack-ansible-lxc_hosts~master~Ia1f8f3589d70c50813f85d0b1fe037225971bf6c,openstack/openstack-ansible-lxc_hosts,master,Ia1f8f3589d70c50813f85d0b1fe037225971bf6c,Add the systemd-networkd to centos 7 installations,MERGED,2017-11-28 08:53:02.000000000,2017-12-13 21:02:34.000000000,2017-11-28 13:46:36.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-28 08:53:02.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/6c953712108415f9ba4bbae4a2ebd8dcea568b32', 'message': ""Add the systemd-networkd to centos 7 installations\n\nThis adds the systemd-networkd package to the base image for centos 7.\nThis is being done so we're able to use unify container networking using\nsystemd built-ins instead of having to manage unique network scripts\nacross distros.\n\nChange-Id: Ia1f8f3589d70c50813f85d0b1fe037225971bf6c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,523352,6c953712108415f9ba4bbae4a2ebd8dcea568b32,8,3,1,7353,,,0,"Add the systemd-networkd to centos 7 installations

This adds the systemd-networkd package to the base image for centos 7.
This is being done so we're able to use unify container networking using
systemd built-ins instead of having to manage unique network scripts
across distros.

Change-Id: Ia1f8f3589d70c50813f85d0b1fe037225971bf6c
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/52/523352/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,6c953712108415f9ba4bbae4a2ebd8dcea568b32,, - systemd-networkd,,1,0
openstack%2Fopenstack-ansible-galera_server~master~Ifaa820e703110d7363095cf745ee3076fa263758,openstack/openstack-ansible-galera_server,master,Ifaa820e703110d7363095cf745ee3076fa263758,Update default paths of SSL cert files,MERGED,2017-12-13 16:54:14.000000000,2017-12-13 20:31:00.000000000,2017-12-13 20:31:00.000000000,"[{'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 16:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/55887221184eb7062b052b08f75ed03bb92b903b', 'message': ""Update default paths of SSL cert files\n\nThe default paths of SSL cert files has been changed to '/etc/ssl/certs'\nto align with most other OpenStack-Ansible roles, and to match the\ndefault location the the galera_client checks for an existing cert\ndistributing them to clients.\n\nThe default path for private key files remains '/etc/mysql/ssl'.\n\nChange-Id: Ifaa820e703110d7363095cf745ee3076fa263758\n""}, {'number': 2, 'created': '2017-12-13 17:12:13.000000000', 'files': ['tasks/galera_ssl_self_signed.yml', 'tasks/galera_ssl.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/6d1941336ee794767352fed56af6aab5c7737304', 'message': ""Update default paths of SSL cert files\n\nThe default paths of SSL cert files has been changed to '/etc/ssl/certs'\nto align with most other OpenStack-Ansible roles, and to match the\ndefault location the the galera_client checks for an existing cert\ndistributing them to clients.\n\nThe default path for private key files remains '/etc/mysql/ssl'.\n\nIf any of these files changes it should trigger a restart of mysql.\n\nChange-Id: Ifaa820e703110d7363095cf745ee3076fa263758\n""}]",0,527740,6d1941336ee794767352fed56af6aab5c7737304,10,4,2,14805,,,0,"Update default paths of SSL cert files

The default paths of SSL cert files has been changed to '/etc/ssl/certs'
to align with most other OpenStack-Ansible roles, and to match the
default location the the galera_client checks for an existing cert
distributing them to clients.

The default path for private key files remains '/etc/mysql/ssl'.

If any of these files changes it should trigger a restart of mysql.

Change-Id: Ifaa820e703110d7363095cf745ee3076fa263758
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/40/527740/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_ssl_self_signed.yml', 'defaults/main.yml']",2,55887221184eb7062b052b08f75ed03bb92b903b,default-ssl-paths,galera_ssl_cert: /etc/ssl/certs/galera.pemgalera_ssl_ca_cert: /etc/ssl/certs/galera-ca.pem,galera_ssl_cert: /etc/mysql/ssl/galera.pemgalera_ssl_ca_cert: /etc/mysql/ssl/galera-ca.pem,4,4
openstack%2Fopenstack-helm-infra~master~I17359df62a720cbd0b3ff79b1d642f99b3e81b3f,openstack/openstack-helm-infra,master,I17359df62a720cbd0b3ff79b1d642f99b3e81b3f,Enable ceph-mgr label on nodes to support luminous,MERGED,2017-12-13 00:45:35.000000000,2017-12-13 20:25:19.000000000,2017-12-13 20:25:19.000000000,"[{'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-13 00:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/abeb651bf153713e727a3933a22bbb2e5d6f7d8c', 'message': 'Enable ceph-mgr label on nodes to support luminous upgrade\n\nChange-Id: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\nSigned-off-by: Ganesh Maharaj Mahalingam <ganesh.mahalingam@intel.com>\n'}, {'number': 2, 'created': '2017-12-13 17:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7654936da6f921e480e513ebe0d39d9c3499f54e', 'message': 'Enable ceph-mgr label on nodes to support luminous upgrade\n\nChange-Id: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\nSigned-off-by: Ganesh Maharaj Mahalingam <ganesh.mahalingam@intel.com>\n'}, {'number': 3, 'created': '2017-12-13 18:09:37.000000000', 'files': ['tools/gate/playbooks/vars.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b3e63a9b474c4318aa69dcf305e7bc58454b0145', 'message': 'Enable ceph-mgr label on nodes to support luminous\n\nChange-Id: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f\nSigned-off-by: Ganesh Maharaj Mahalingam <ganesh.mahalingam@intel.com>\n'}]",1,527552,b3e63a9b474c4318aa69dcf305e7bc58454b0145,11,3,3,18476,,,0,"Enable ceph-mgr label on nodes to support luminous

Change-Id: I17359df62a720cbd0b3ff79b1d642f99b3e81b3f
Signed-off-by: Ganesh Maharaj Mahalingam <ganesh.mahalingam@intel.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/52/527552/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/gate/playbooks/vars.yaml'],1,abeb651bf153713e727a3933a22bbb2e5d6f7d8c,ceph-mgr-luminous-patch1, - name: ceph-mgr value: enabled,,2,0
openstack%2Fneutron~master~I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc,openstack/neutron,master,I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc,Allow port create/update by shared nw owners,MERGED,2017-02-13 05:41:02.000000000,2017-12-13 20:19:00.000000000,2017-12-13 20:19:00.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 6635}, {'_account_id': 6876}, {'_account_id': 7787}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17776}, {'_account_id': 19339}, {'_account_id': 20330}, {'_account_id': 22348}, {'_account_id': 27373}]","[{'number': 1, 'created': '2017-02-13 05:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8925665e97c2de1c423889afdf2dfaf6c4a68f03', 'message': 'DNM:Allow port creation/updation by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared ( tenant is not the owner but has\nnetwork shared via RBAC ) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which the tenant requires.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 2, 'created': '2017-02-13 10:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c60cba6dee8d310fd8cd41739a0b06ecb89b528', 'message': 'Allow port creation/updation by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared ( tenant is not the owner but has\nnetwork shared via RBAC ) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which the tenant requires.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 3, 'created': '2017-02-13 19:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d050183fd85cfbe3dec4124a8f40eeb89d0e4d66', 'message': 'Allow port creation/updation by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared ( tenant is not the owner but has\nnetwork shared via RBAC ) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which the tenant requires.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 4, 'created': '2017-02-14 17:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1db8fe59cc595cee5262c86c168ba8c18314ae1b', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared ( tenant is not the owner but has\nnetwork shared via RBAC ) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which the tenant requires.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 5, 'created': '2017-02-22 14:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60874d1034beccfa3f8bb18c2bf1d2d6d6b8f2f1', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared ( tenant is not the owner but has\nnetwork shared via RBAC ) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which the tenant requires.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 6, 'created': '2017-03-01 02:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99479317b59b8cfb67b3719e211aedd52bc6a964', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 7, 'created': '2017-03-06 10:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63e824c4cb4466944c490854bfe804ce00ff54ab', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 8, 'created': '2017-03-06 14:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48835689b71e90ab686572d1877c63af2127bd6e', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 9, 'created': '2017-03-20 07:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1b98de3f31bb9b5c073f8f6f88faf44140cebdd6', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 10, 'created': '2017-03-20 08:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cdd5425fa75427668aa186d27fdb90ff0078a92', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 11, 'created': '2017-03-27 07:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f4ec09f0162783a0757ae21c5efde064895903da', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 12, 'created': '2017-03-30 08:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04342b97d9f3e43cb5d02b8cb4f5075f7ff71d09', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 13, 'created': '2017-07-20 06:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efde5d5d10725b1e6672af8e869228d02e1809b6', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 14, 'created': '2017-08-05 03:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b695c92df4c29935bab07cea356ad90dcf3ea3f5', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 15, 'created': '2017-09-15 03:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0008028191499a97f801240cefdaf38d311e4e67', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 16, 'created': '2017-11-17 03:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e1d2a52f81f548cd919a2b008eb6f0a12aa3f18', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 17, 'created': '2017-11-17 06:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06643ea3c6598e0162a7ffc27a790b8ba0339cc5', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\n\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 18, 'created': '2017-11-20 04:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b474f67faa0836baf8be871aabb4aa2d91258c8e', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\nTempest test in [1]\n\n[1]: https://review.openstack.org/521413\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 19, 'created': '2017-11-21 03:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8eabddd76f5e8d201618d0b1334607669f4029ed', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\nTempest test in [1]\n\n[1]: https://review.openstack.org/521413\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 20, 'created': '2017-12-11 15:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2fc6e4696dfdf41ec3d5cbaa4dac8c61d0d37b19', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\nTempest test in [1]\n\n[1]: https://review.openstack.org/521413\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 21, 'created': '2017-12-11 15:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0d46c78404672bea64549b9ff59e4ecd9fe4c2a', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\na subnet which is actually a part of a shared network, owned by\nanother tenant.\nTempest test in [1]\n\n[1]: https://review.openstack.org/521413\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}, {'number': 22, 'created': '2017-12-12 04:27:21.000000000', 'files': ['etc/policy.json', 'neutron/tests/etc/policy.json', 'releasenotes/notes/allow_port_create_update_shared_owners-2a57b1c72d91ace2.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8236e83deced9af84ae0e5128c76acfa753093cc', 'message': 'Allow port create/update by shared nw owners\n\nCurrently if a new port is created by a tenant with whom\nthe network is shared (tenant is not the owner but has\nnetwork shared via RBAC) , the port is allocated on the default\nsubnet. This patch allows the tenant to create/update a port on\nany subnet which is actually a part of a shared network, owned by\nanother tenant.\nTempest test in [1]\n\n[1]: https://review.openstack.org/521413\nChange-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc\nCloses-Bug: #1543756\n'}]",37,432850,8236e83deced9af84ae0e5128c76acfa753093cc,208,23,22,17776,,,0,"Allow port create/update by shared nw owners

Currently if a new port is created by a tenant with whom
the network is shared (tenant is not the owner but has
network shared via RBAC) , the port is allocated on the default
subnet. This patch allows the tenant to create/update a port on
any subnet which is actually a part of a shared network, owned by
another tenant.
Tempest test in [1]

[1]: https://review.openstack.org/521413
Change-Id: I1046f6b13e68b1e274cc8f62f5b30aa5f8d71cdc
Closes-Bug: #1543756
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/432850/4 && git format-patch -1 --stdout FETCH_HEAD,['etc/policy.json'],1,8925665e97c2de1c423889afdf2dfaf6c4a68f03,bug/1543756," ""create_port:fixed_ips:ip_address"": ""rule:context_is_advsvc or rule:admin_or_network_owner"", ""create_port:fixed_ips:subnet_id"": ""rule:context_is_advsvc or rule:admin_or_network_owner rule:shared"", ""update_port:fixed_ips:ip_address"": ""rule:context_is_advsvc or rule:admin_or_network_owner"", ""update_port:fixed_ips:subnet_id"": ""rule:context_is_advsvc or rule:admin_or_network_owner or rule:shared"","," ""create_port:fixed_ips"": ""rule:context_is_advsvc or rule:admin_or_network_owner"", ""update_port:fixed_ips"": ""rule:context_is_advsvc or rule:admin_or_network_owner"",",4,2
openstack%2Fnova~master~I4253cffca3dbf558c875eed7e77711a31e9e3406,openstack/nova,master,I4253cffca3dbf558c875eed7e77711a31e9e3406,Re-use existing ComputeNode on ironic rebalance,MERGED,2017-09-29 16:10:07.000000000,2017-12-13 20:01:59.000000000,2017-12-13 13:41:10.000000000,"[{'_account_id': 7}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 6062}, {'_account_id': 6637}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 20035}, {'_account_id': 22348}, {'_account_id': 23419}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26490}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-09-29 16:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee0a5310c7fbfde58947a9d820c8fcad3147f8f9', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute services dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexiting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement error out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nCloses-Bug: #1714248\n\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 2, 'created': '2017-10-03 13:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e7590b1e6670549961d3ac0136680c3d184d0b7', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nCloses-Bug: #1714248\n\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 3, 'created': '2017-10-03 13:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5e2760faee3f079cd51f0ddeb0fc900a7bcb259', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nCloses-Bug: #1714248\n\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 4, 'created': '2017-11-03 17:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83e49408e8f4ccbdcdfc773811ff5b384ee8dbcc', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nThere are functional test changes to ensure the fake driver reports\na different hypervisor hostname between the first and second fake\ncompute service that is being run. NOTE: still need more work to get\nthose API Samples tests passing :(\n\nCloses-Bug: #1714248\n\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 5, 'created': '2017-11-06 10:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f9fc6bd4330de731ebbb62b010f16fbe3051af2', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nThere are functional test changes to ensure the fake driver reports\na different hypervisor hostname between the first and second fake\ncompute service that is being started. Also included are the matching\ndocs api-samples changes.\n\nCloses-Bug: #1714248\n\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 6, 'created': '2017-12-11 12:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e766581147a5c6fb5f3dc2ea84be93a251ecda3', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nThere are functional test changes to ensure the fake driver reports\na different hypervisor hostname between the first and second fake\ncompute service that is being started. Also included are the matching\ndocs api-samples changes.\n\nCloses-Bug: #1714248\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 7, 'created': '2017-12-11 18:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/122bcc875e39115942ad9720e65adb25471c98cd', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nCloses-Bug: #1714248\nCo-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}, {'number': 8, 'created': '2017-12-11 21:24:07.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/virt/fake.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/virt/driver.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e3c5e22d1fde7ca916a8cc364f335fba8a3a798f', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nCloses-Bug: #1714248\nCo-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>\nChange-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}]",27,508555,e3c5e22d1fde7ca916a8cc364f335fba8a3a798f,140,27,8,782,,,0,"Re-use existing ComputeNode on ironic rebalance

When a nova-compute service dies that is one of several ironic based
nova-compute services running, a node rebalance occurs to ensure there
is still an active nova-compute service dealing with requests for the
given instance that is running.

Today, when this occurs, we create a new ComputeNode entry. This change
alters that logic to detect the case of the ironic node rebalance and in
that case we re-use the existing ComputeNode entry, simply updating the
host field to match the new host it has been rebalanced onto.

Previously we hit problems with placement when we get a new
ComputeNode.uuid for the same ironic_node.uuid. This reusing of the
existing entry keeps the ComputeNode.uuid the same when the rebalance of
the ComputeNode occurs.

Without keeping the same ComputeNode.uuid placement errors out with a 409
because we attempt to create a ResourceProvider that has the same name
as an existing ResourceProvdier. Had that worked, we would have noticed
the race that occurs after we create the ResourceProvider but before we
add back the existing allocations for existing instances. Keeping the
ComputeNode.uuid the same means we simply look up the existing
ResourceProvider in placement, avoiding all this pain and tears.

Closes-Bug: #1714248
Co-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>
Change-Id: I4253cffca3dbf558c875eed7e77711a31e9e3406
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/508555/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/compute_node.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/tests/functional/db/test_compute_node.py', 'nova/db/api.py', 'nova/compute/resource_tracker.py', 'nova/db/sqlalchemy/api.py']",6,ee0a5310c7fbfde58947a9d820c8fcad3147f8f9,bug/1714248,"@pick_context_manager_reader def compute_node_get_all_by_nodename(context, nodename): results = _compute_node_fetchall(context, {""hypervisor_hostname"": nodename}) if not results: raise exception.ComputeHostNotFound(host=nodename) return results ",,152,1
openstack%2Freleases~master~If6647d771f5736c826d79340927725e3472d52e3,openstack/releases,master,If6647d771f5736c826d79340927725e3472d52e3,Release Designate Dashboard 6.0.0.0b2,MERGED,2017-12-12 16:24:18.000000000,2017-12-13 19:58:13.000000000,2017-12-13 19:58:13.000000000,"[{'_account_id': 8099}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 16:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/a8be59a38439f571ae542f9c01f1f326c943111b', 'message': 'Release Designate Dashboard 6.0.0.0b2\n\nChange-Id: If6647d771f5736c826d79340927725e3472d52e3\n'}, {'number': 2, 'created': '2017-12-13 00:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/bc1206efbc29989f04b5d7b6440ec8a2cb1f3856', 'message': 'Release Designate Dashboard 6.0.0.0b2\n\nChange-Id: If6647d771f5736c826d79340927725e3472d52e3\n'}, {'number': 3, 'created': '2017-12-13 10:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/04f1cd5b01251b3e9de1da7ccd3f29df76b6b04e', 'message': 'Release Designate Dashboard 6.0.0.0b2\n\nChange-Id: If6647d771f5736c826d79340927725e3472d52e3\n'}, {'number': 4, 'created': '2017-12-13 19:40:32.000000000', 'files': ['deliverables/queens/designate-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/03882d4f69c2ba0638fcbd9dcfe4ac028dd72adb', 'message': 'Release Designate Dashboard 6.0.0.0b2\n\nChange-Id: If6647d771f5736c826d79340927725e3472d52e3\n'}]",0,527453,03882d4f69c2ba0638fcbd9dcfe4ac028dd72adb,13,3,4,8099,,,0,"Release Designate Dashboard 6.0.0.0b2

Change-Id: If6647d771f5736c826d79340927725e3472d52e3
",git fetch https://review.opendev.org/openstack/releases refs/changes/53/527453/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/designate-dashboard.yaml'],1,a8be59a38439f571ae542f9c01f1f326c943111b,designate-dashboard-q2, - version: 6.0.0.0b1 projects: - repo: openstack/designate-dashboard hash: 642edf494b0f12e05de69b98a4a9fd618950ba4f,,4,0
openstack%2Freleases~master~Idbb427c2aa4dfe19842312213da21fe72c4b2e5f,openstack/releases,master,Idbb427c2aa4dfe19842312213da21fe72c4b2e5f,Release Designate 6.0.0.0b2,MERGED,2017-12-12 16:22:28.000000000,2017-12-13 19:52:54.000000000,2017-12-13 19:52:54.000000000,"[{'_account_id': 8099}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 16:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b2d8fe5a10149bd7416885b4f2c02b3c3de9cda3', 'message': 'Release Designate 6.0.0.0b2\n\nChange-Id: Idbb427c2aa4dfe19842312213da21fe72c4b2e5f\n'}, {'number': 2, 'created': '2017-12-13 00:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7ac5674cc3882dd10f96ff2924152b0e3eaa5b43', 'message': 'Release Designate 6.0.0.0b2\n\nChange-Id: Idbb427c2aa4dfe19842312213da21fe72c4b2e5f\n'}, {'number': 3, 'created': '2017-12-13 00:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b8bc987c619011f5ef4a588c33bb020b07f095c3', 'message': 'Release Designate 6.0.0.0b2\n\nChange-Id: Idbb427c2aa4dfe19842312213da21fe72c4b2e5f\n'}, {'number': 4, 'created': '2017-12-13 00:45:24.000000000', 'files': ['deliverables/queens/designate.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/869e9a350596e4ec2bbaa9c7f0edf43859af24d0', 'message': 'Release Designate 6.0.0.0b2\n\nChange-Id: Idbb427c2aa4dfe19842312213da21fe72c4b2e5f\n'}]",1,527452,869e9a350596e4ec2bbaa9c7f0edf43859af24d0,14,3,4,8099,,,0,"Release Designate 6.0.0.0b2

Change-Id: Idbb427c2aa4dfe19842312213da21fe72c4b2e5f
",git fetch https://review.opendev.org/openstack/releases refs/changes/52/527452/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/designate.yaml'],1,b2d8fe5a10149bd7416885b4f2c02b3c3de9cda3,designate-q2,release-notes: https://docs.openstack.org/releasenotes/designate/unreleased.html - version: 6.0.0.0b2 projects: - repo: openstack/designate hash: 3e0dbc7892e309f9df5846cb977e90a6fc2e2b8d ,,6,0
openstack%2Fpuppet-neutron~stable%2Fnewton~Ie15567e74ff7c623a6c080ba23bb91452309558e,openstack/puppet-neutron,stable/newton,Ie15567e74ff7c623a6c080ba23bb91452309558e,Cisco: Remove ping test for Nexus switches,MERGED,2017-12-11 23:42:05.000000000,2017-12-13 19:47:33.000000000,2017-12-13 19:47:33.000000000,"[{'_account_id': 3153}, {'_account_id': 6697}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 23:42:05.000000000', 'files': ['manifests/plugins/ml2/cisco/nexus_creds.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8bdf73fb96e8aee40f7b01ac6aeba0e86dd4eb1a', 'message': 'Cisco: Remove ping test for Nexus switches\n\nRemoving the ping test to the Nexus TORs because this is\ncausing Overcloud deploy to fail. The iptables rules block\nall traffic at this point preventing the pings from going\nthrough. Also, health check for the Nexus TORs is best\nperformed in ansible or during plugin initialization.\n\nChange-Id: Ie15567e74ff7c623a6c080ba23bb91452309558e\nCloses-bug: #1733401\n(cherry picked from commit 245f272c780b4067d6e004b3788bd16c6ee41aba)\n'}]",0,527268,8bdf73fb96e8aee40f7b01ac6aeba0e86dd4eb1a,8,4,1,3153,,,0,"Cisco: Remove ping test for Nexus switches

Removing the ping test to the Nexus TORs because this is
causing Overcloud deploy to fail. The iptables rules block
all traffic at this point preventing the pings from going
through. Also, health check for the Nexus TORs is best
performed in ansible or during plugin initialization.

Change-Id: Ie15567e74ff7c623a6c080ba23bb91452309558e
Closes-bug: #1733401
(cherry picked from commit 245f272c780b4067d6e004b3788bd16c6ee41aba)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/68/527268/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2/cisco/nexus_creds.pp'],1,8bdf73fb96e8aee40f7b01ac6aeba0e86dd4eb1a,bug/1733401-stable/newton,," $check_known_hosts = ""/bin/cat /var/lib/neutron/.ssh/known_hosts | /bin/grep ${ip_address}"" # Test to make sure switch is reachable before ssh-keyscan. # - ssh-keyscan timeouts fail silently so use ping to # report connectivity failures. exec {""ping_test_${name}"": unless => $check_known_hosts, command => ""/usr/bin/ping -c 1 ${ip_address}"", user => 'neutron' } exec {""nexus_creds_${name}"": unless => $check_known_hosts, command => ""/usr/bin/ssh-keyscan -t rsa ${ip_address} >> /var/lib/neutron/.ssh/known_hosts"", user => 'neutron', require => [Exec[""ping_test_${name}""], Anchor['neutron::config::end']] }",0,18
openstack%2Fpuppet-neutron~stable%2Focata~Ie15567e74ff7c623a6c080ba23bb91452309558e,openstack/puppet-neutron,stable/ocata,Ie15567e74ff7c623a6c080ba23bb91452309558e,Cisco: Remove ping test for Nexus switches,MERGED,2017-12-11 23:41:57.000000000,2017-12-13 19:47:32.000000000,2017-12-13 19:47:32.000000000,"[{'_account_id': 3153}, {'_account_id': 6697}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 23:41:57.000000000', 'files': ['manifests/plugins/ml2/cisco/nexus_creds.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/04e5c12ad589b99fb568318ad62136f74d0e87f4', 'message': 'Cisco: Remove ping test for Nexus switches\n\nRemoving the ping test to the Nexus TORs because this is\ncausing Overcloud deploy to fail. The iptables rules block\nall traffic at this point preventing the pings from going\nthrough. Also, health check for the Nexus TORs is best\nperformed in ansible or during plugin initialization.\n\nChange-Id: Ie15567e74ff7c623a6c080ba23bb91452309558e\nCloses-bug: #1733401\n(cherry picked from commit 245f272c780b4067d6e004b3788bd16c6ee41aba)\n'}]",0,527267,04e5c12ad589b99fb568318ad62136f74d0e87f4,8,4,1,3153,,,0,"Cisco: Remove ping test for Nexus switches

Removing the ping test to the Nexus TORs because this is
causing Overcloud deploy to fail. The iptables rules block
all traffic at this point preventing the pings from going
through. Also, health check for the Nexus TORs is best
performed in ansible or during plugin initialization.

Change-Id: Ie15567e74ff7c623a6c080ba23bb91452309558e
Closes-bug: #1733401
(cherry picked from commit 245f272c780b4067d6e004b3788bd16c6ee41aba)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/67/527267/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2/cisco/nexus_creds.pp'],1,04e5c12ad589b99fb568318ad62136f74d0e87f4,bug/1733401-stable/ocata,," $check_known_hosts = ""/bin/cat /var/lib/neutron/.ssh/known_hosts | /bin/grep ${ip_address}"" # Test to make sure switch is reachable before ssh-keyscan. # - ssh-keyscan timeouts fail silently so use ping to # report connectivity failures. exec {""ping_test_${name}"": unless => $check_known_hosts, command => ""/usr/bin/ping -c 1 ${ip_address}"", user => 'neutron' } exec {""nexus_creds_${name}"": unless => $check_known_hosts, command => ""/usr/bin/ssh-keyscan -t rsa ${ip_address} >> /var/lib/neutron/.ssh/known_hosts"", user => 'neutron', require => [Exec[""ping_test_${name}""], Anchor['neutron::config::end']] }",0,18
openstack%2Fpuppet-neutron~stable%2Fpike~Ie15567e74ff7c623a6c080ba23bb91452309558e,openstack/puppet-neutron,stable/pike,Ie15567e74ff7c623a6c080ba23bb91452309558e,Cisco: Remove ping test for Nexus switches,MERGED,2017-12-11 23:41:48.000000000,2017-12-13 19:47:32.000000000,2017-12-13 19:47:32.000000000,"[{'_account_id': 3153}, {'_account_id': 6697}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 23:41:48.000000000', 'files': ['manifests/plugins/ml2/cisco/nexus_creds.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f0d9e837460068b1d0bdab11245bd4c15a0dbf08', 'message': 'Cisco: Remove ping test for Nexus switches\n\nRemoving the ping test to the Nexus TORs because this is\ncausing Overcloud deploy to fail. The iptables rules block\nall traffic at this point preventing the pings from going\nthrough. Also, health check for the Nexus TORs is best\nperformed in ansible or during plugin initialization.\n\nChange-Id: Ie15567e74ff7c623a6c080ba23bb91452309558e\nCloses-bug: #1733401\n(cherry picked from commit 245f272c780b4067d6e004b3788bd16c6ee41aba)\n'}]",0,527266,f0d9e837460068b1d0bdab11245bd4c15a0dbf08,8,4,1,3153,,,0,"Cisco: Remove ping test for Nexus switches

Removing the ping test to the Nexus TORs because this is
causing Overcloud deploy to fail. The iptables rules block
all traffic at this point preventing the pings from going
through. Also, health check for the Nexus TORs is best
performed in ansible or during plugin initialization.

Change-Id: Ie15567e74ff7c623a6c080ba23bb91452309558e
Closes-bug: #1733401
(cherry picked from commit 245f272c780b4067d6e004b3788bd16c6ee41aba)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/66/527266/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2/cisco/nexus_creds.pp'],1,f0d9e837460068b1d0bdab11245bd4c15a0dbf08,bug/1733401-stable/pike,," $check_known_hosts = ""/bin/cat /var/lib/neutron/.ssh/known_hosts | /bin/grep ${ip_address}"" # Test to make sure switch is reachable before ssh-keyscan. # - ssh-keyscan timeouts fail silently so use ping to # report connectivity failures. exec {""ping_test_${name}"": unless => $check_known_hosts, command => ""/usr/bin/ping -c 1 ${ip_address}"", user => 'neutron' } exec {""nexus_creds_${name}"": unless => $check_known_hosts, command => ""/usr/bin/ssh-keyscan -t rsa ${ip_address} >> /var/lib/neutron/.ssh/known_hosts"", user => 'neutron', require => [Exec[""ping_test_${name}""], Anchor['neutron::config::end']] }",0,18
openstack%2Fopenstack-helm-infra~master~I016e6512fb21182a8be9e3de1e4a2da59a20fb36,openstack/openstack-helm-infra,master,I016e6512fb21182a8be9e3de1e4a2da59a20fb36,Support IP addresses as hosts within keystone_endpoint_uri_lookup,MERGED,2017-12-12 00:55:23.000000000,2017-12-13 19:45:09.000000000,2017-12-13 19:45:09.000000000,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-12 00:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a02c6fb61dc963b341a1d234da447ac7bf501256', 'message': 'Support IP addresses as hosts within keystone_endpoint_uri_lookup\n\nChange-Id: I016e6512fb21182a8be9e3de1e4a2da59a20fb36\n'}, {'number': 2, 'created': '2017-12-12 00:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a8d92cbb841523fa9cfa75c940e0007cf32a9884', 'message': 'Support IP addresses as hosts within keystone_endpoint_uri_lookup\n\nThis allows the keystone endpoint uri lookup function to\navoid adding a FQDN suffix to an IP address based host\nentry.\n\nChange-Id: I016e6512fb21182a8be9e3de1e4a2da59a20fb36\n'}, {'number': 3, 'created': '2017-12-13 16:45:48.000000000', 'files': ['helm-toolkit/templates/endpoints/_keystone_endpoint_uri_lookup.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1af212c0ab95f45dc1c9de59af74a1ecdb429fc1', 'message': 'Support IP addresses as hosts within keystone_endpoint_uri_lookup\n\nThis allows the keystone endpoint uri lookup function to\navoid adding a FQDN suffix to an IP address based host\nentry.\n\nChange-Id: I016e6512fb21182a8be9e3de1e4a2da59a20fb36\n'}]",0,527279,1af212c0ab95f45dc1c9de59af74a1ecdb429fc1,13,3,3,7769,,,0,"Support IP addresses as hosts within keystone_endpoint_uri_lookup

This allows the keystone endpoint uri lookup function to
avoid adding a FQDN suffix to an IP address based host
entry.

Change-Id: I016e6512fb21182a8be9e3de1e4a2da59a20fb36
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/79/527279/2 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/endpoints/_keystone_endpoint_uri_lookup.tpl'],1,a02c6fb61dc963b341a1d234da447ac7bf501256,,"{{- if regexMatch ""[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+"" $endpointHost }} {{- printf ""%s://%s:%1.f%s"" $endpointScheme $endpointHost $endpointPort $endpointPath -}} {{- else -}} {{- $endpointFqdnHostname := index .host_fqdn_override $endpoint | default .host_fqdn_override.default | default $endpointClusterHostname }} {{- printf ""%s://%s:%1.f%s"" $endpointScheme $endpointFqdnHostname $endpointPort $endpointPath -}} {{- end -}}","{{- $endpointHostname := index .host_fqdn_override $endpoint | default .host_fqdn_override.default | default $endpointClusterHostname }} {{- printf ""%s://%s:%1.f%s"" $endpointScheme $endpointHostname $endpointPort $endpointPath -}}",6,2
openstack%2Fneutron~master~I02fe64bf817b47970e4e073f48ea8dea53bdd4f5,openstack/neutron,master,I02fe64bf817b47970e4e073f48ea8dea53bdd4f5,[Fullstack] Additional log of tcpdump stderr output,MERGED,2017-12-12 08:36:51.000000000,2017-12-13 19:33:30.000000000,2017-12-13 19:33:30.000000000,"[{'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 08:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/287019dd8d79fa4705713da8b9abc9a4812fe1fd', 'message': '[Fullstack] Additional log of tcpdump stderr output\n\nThis patch adds additional logging of tcpdump stderr output in\nDSCP marking packets tests.\nIt is required to figure out why those tests are failing sometimes.\n\nChange-Id: I02fe64bf817b47970e4e073f48ea8dea53bdd4f5\nRelated-Bug: #1733649\n'}, {'number': 2, 'created': '2017-12-12 09:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6476d4794f9b9facfdf0864170ce9e76dca1bde', 'message': '[Fullstack] Additional log of tcpdump stderr output\n\nThis patch adds additional logging of tcpdump stderr output in\nDSCP marking packets tests.\nIt is required to figure out why those tests are failing sometimes.\n\nChange-Id: I02fe64bf817b47970e4e073f48ea8dea53bdd4f5\nRelated-Bug: #1733649\n'}, {'number': 3, 'created': '2017-12-13 09:51:00.000000000', 'files': ['neutron/tests/common/agents/l2_extensions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d5247bc4ce0ea4d4d171fb9abb792f5f826e964', 'message': '[Fullstack] Additional log of tcpdump stderr output\n\nThis patch adds additional logging of tcpdump stderr output in\nDSCP marking packets tests.\nIt is required to figure out why those tests are failing sometimes.\n\nChange-Id: I02fe64bf817b47970e4e073f48ea8dea53bdd4f5\nRelated-Bug: #1733649\n'}]",1,527341,7d5247bc4ce0ea4d4d171fb9abb792f5f826e964,17,8,3,11975,,,0,"[Fullstack] Additional log of tcpdump stderr output

This patch adds additional logging of tcpdump stderr output in
DSCP marking packets tests.
It is required to figure out why those tests are failing sometimes.

Change-Id: I02fe64bf817b47970e4e073f48ea8dea53bdd4f5
Related-Bug: #1733649
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/527341/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/common/agents/l2_extensions.py'],1,287019dd8d79fa4705713da8b9abc9a4812fe1fd,bug/1733649," # TODO(slaweq): Debug logging added to help troubleshooting bug # https://bugs.launchpad.net/neutron/+bug/1733649 # once it will be closed this log can be removed LOG.debug(""Tcpdump error output"") for line in tcpdump_async.iter_stderr(): LOG.debug(""Line: %s"" % line)",,6,0
openstack%2Fcinder~master~I8f1f8ad6a6e0898c88af85d9e9ce0f08d7488176,openstack/cinder,master,I8f1f8ad6a6e0898c88af85d9e9ce0f08d7488176,"Hey Matt, check this out",ABANDONED,2017-11-17 21:59:18.000000000,2017-12-13 19:30:55.000000000,,"[{'_account_id': 5196}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24502}, {'_account_id': 24863}]","[{'number': 1, 'created': '2017-11-17 21:59:18.000000000', 'files': ['cinder/tests/unit/test_exception.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/60160dc2da6bf5ccd2e484f45cf4af41085237f3', 'message': ""Hey Matt, check this out\n\nReproduces a test failure that we've seen since switching to\nstestr reliably by running:\n\ntox -e py35 cinder.tests.unit.test_exception.ExceptionTestCase.test_exceptions_raise\n\nThis is a difference from before, which would seem to indicate\nsomething in stestr is not handling large log output the same\nas it used to be handled.\n\nChange-Id: I8f1f8ad6a6e0898c88af85d9e9ce0f08d7488176\n""}]",0,521201,60160dc2da6bf5ccd2e484f45cf4af41085237f3,12,11,1,11904,,,0,"Hey Matt, check this out

Reproduces a test failure that we've seen since switching to
stestr reliably by running:

tox -e py35 cinder.tests.unit.test_exception.ExceptionTestCase.test_exceptions_raise

This is a difference from before, which would seem to indicate
something in stestr is not handling large log output the same
as it used to be handled.

Change-Id: I8f1f8ad6a6e0898c88af85d9e9ce0f08d7488176
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/521201/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/test_exception.py'],1,60160dc2da6bf5ccd2e484f45cf4af41085237f3,stestr_test," for i in range(10): for name in dir(exception): exc = getattr(exception, name) if isinstance(exc, type): self.assertRaises(exc, self._raise_exc, exc)"," for name in dir(exception): exc = getattr(exception, name) if isinstance(exc, type): self.assertRaises(exc, self._raise_exc, exc)",5,4
openstack%2Ftripleo-heat-templates~master~Ib973765343dc1bf97b95c8aea3234916fa7a519a,openstack/tripleo-heat-templates,master,Ib973765343dc1bf97b95c8aea3234916fa7a519a,Add Novacontrol role,MERGED,2017-12-07 20:13:20.000000000,2017-12-13 19:28:06.000000000,2017-12-13 19:28:06.000000000,"[{'_account_id': 8042}, {'_account_id': 8956}, {'_account_id': 10068}, {'_account_id': 10135}, {'_account_id': 10459}, {'_account_id': 14985}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2017-12-07 20:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13a49c0e64f2f6b74eee30326a83affac0def253', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nWe propose to add the 'Novacontrol' role to this topology in order to\nrun nova control services on their own.\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}, {'number': 2, 'created': '2017-12-08 11:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/324a21cb20f13175799ea09d360aa0189fb163c8', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nWe propose to add the 'Novacontrol' role to this topology in order to\nrun nova control services on their own.\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}, {'number': 3, 'created': '2017-12-08 13:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a2f05b2799965e943f8fe38fb6cdcc8d1af9d27', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nWe propose to add the 'Novacontrol' role to this topology in order to\nrun nova control services on their own.\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}, {'number': 4, 'created': '2017-12-08 15:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1a118440bae2b3d4ae945cbb2468b771894f23fe', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nWe propose to add the 'Novacontrol' role to this topology in order to\nrun nova control services on their own.\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}, {'number': 5, 'created': '2017-12-08 15:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe715f888205918c0a9b042f5a7581ab06be1d5a', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nThe proposed 'Novacontrol' role extends this topology by another subset\nof controller services running on standalone node.  Since the\n'ControllerOpenstack' role is already being actively used for testing\nthe standalone Database-Messaging-Networker topology, this patch also\nintroduces the 'ControllerAllStandalone' role to define complementary\ncontroller node for the extended standalone topology:\n\n * ControllerAllStandalone\n * Database\n * Messaging\n * Networker\n * Novacontrol\n\nThe patch also introduces the 'ControllerNovaStandalone' role for the\ncomplementary controller node to the minimal nova standalone topology:\n\n * ControllerNovaStandalone\n * Novacontrol\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}, {'number': 6, 'created': '2017-12-08 16:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e17c64f1f406b33dbe47201fcb3c8e5c53ca8298', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nThe proposed 'Novacontrol' role extends this topology by another subset\nof controller services running on standalone node.  Since the\n'ControllerOpenstack' role is already being actively used for testing\nthe standalone Database-Messaging-Networker topology, this patch also\nintroduces the 'ControllerAllStandalone' role to define complementary\ncontroller node for the extended standalone topology:\n\n * ControllerAllStandalone\n * Database\n * Messaging\n * Networker\n * Novacontrol\n\nThe patch also introduces the 'ControllerNovaStandalone' role for the\ncomplementary controller node to the minimal nova standalone topology:\n\n * ControllerNovaStandalone\n * Novacontrol\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}, {'number': 7, 'created': '2017-12-12 14:51:09.000000000', 'files': ['roles/ControllerAllNovaStandalone.yaml', 'roles/ControllerNovaStandalone.yaml', 'roles/Novacontrol.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a59be61478afe59898badeb3d379e3d23571039e', 'message': ""Add Novacontrol role\n\nThe following services (referred to as 'nova control services'):\n\n * NovaApi\n * NovaConductor\n * NovaConsoleauth\n * NovaMetadata\n * NovaPlacement\n * NovaVncProxy\n * Ec2Api\n\nshould run on separate node according to the recent version of the\nstandalone role topology that is officially supported by Red Hat\nOpenStack Platform.  TripleO Heat Templates already do contain a\nstandalone topology defined by the combination of the following THT\nroles:\n\n * ControllerOpenstack\n * Database\n * Messaging\n * Networker\n\nThe proposed 'Novacontrol' role extends this topology by another subset\nof controller services running on standalone node.  Since the\n'ControllerOpenstack' role is already being actively used for testing\nthe standalone Database-Messaging-Networker topology, this patch also\nintroduces the 'ControllerAllNovaStandalone' role to define\ncomplementary controller node for the extended standalone topology:\n\n * ControllerAllNovaStandalone\n * Database\n * Messaging\n * Networker\n * Novacontrol\n\nThe patch also introduces the 'ControllerNovaStandalone' role for the\ncomplementary controller node to the minimal nova standalone topology:\n\n * ControllerNovaStandalone\n * Novacontrol\n\nChange-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a\n""}]",10,526501,a59be61478afe59898badeb3d379e3d23571039e,42,10,7,8956,,,0,"Add Novacontrol role

The following services (referred to as 'nova control services'):

 * NovaApi
 * NovaConductor
 * NovaConsoleauth
 * NovaMetadata
 * NovaPlacement
 * NovaVncProxy
 * Ec2Api

should run on separate node according to the recent version of the
standalone role topology that is officially supported by Red Hat
OpenStack Platform.  TripleO Heat Templates already do contain a
standalone topology defined by the combination of the following THT
roles:

 * ControllerOpenstack
 * Database
 * Messaging
 * Networker

The proposed 'Novacontrol' role extends this topology by another subset
of controller services running on standalone node.  Since the
'ControllerOpenstack' role is already being actively used for testing
the standalone Database-Messaging-Networker topology, this patch also
introduces the 'ControllerAllNovaStandalone' role to define
complementary controller node for the extended standalone topology:

 * ControllerAllNovaStandalone
 * Database
 * Messaging
 * Networker
 * Novacontrol

The patch also introduces the 'ControllerNovaStandalone' role for the
complementary controller node to the minimal nova standalone topology:

 * ControllerNovaStandalone
 * Novacontrol

Change-Id: Ib973765343dc1bf97b95c8aea3234916fa7a519a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/01/526501/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/Novacontrol.yaml', 'roles/ControllerOpenstack.yaml']",2,13a49c0e64f2f6b74eee30326a83affac0def253,novacontrol," Controller role that does not contain the nova-control, database, messaging and networking components. Use in combination with the Novacontrol, Database, Messaging and Networker roles."," Controller role that does not contain the database, messaging and networking components. Use in combination with the Database, Messaging and Networker roles. - OS::TripleO::Services::Ec2Api - OS::TripleO::Services::NovaApi - OS::TripleO::Services::NovaConductor - OS::TripleO::Services::NovaConsoleauth - OS::TripleO::Services::NovaMetadata - OS::TripleO::Services::NovaPlacement - OS::TripleO::Services::NovaScheduler - OS::TripleO::Services::NovaVncProxy",43,11
openstack%2Ftripleo-upgrade~master~I015baa41a51d812dcc65ce9fc5c870f203bc93db,openstack/tripleo-upgrade,master,I015baa41a51d812dcc65ce9fc5c870f203bc93db,Add the option to launch workload after composable upgrade step,MERGED,2017-12-12 15:47:53.000000000,2017-12-13 19:28:04.000000000,2017-12-13 19:28:04.000000000,"[{'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 18851}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': ['infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tasks/upgrade/main.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/4fca939b11fb798e4edbd4362210d71a29551267', 'message': 'Add the option to launch workload after composable upgrade step\n\nThis change adds the option to launch workload after the major\nupgrade composable step was completed. This serves as a sanity\ncheck for validating that the overcloud is functional in an\nintermediary step of the upgrade process.\n\nChange-Id: I015baa41a51d812dcc65ce9fc5c870f203bc93db\n'}]",0,527434,4fca939b11fb798e4edbd4362210d71a29551267,9,7,1,26343,,,0,"Add the option to launch workload after composable upgrade step

This change adds the option to launch workload after the major
upgrade composable step was completed. This serves as a sanity
check for validating that the overcloud is functional in an
intermediary step of the upgrade process.

Change-Id: I015baa41a51d812dcc65ce9fc5c870f203bc93db
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/34/527434/1 && git format-patch -1 --stdout FETCH_HEAD,"['infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tasks/upgrade/main.yml', 'defaults/main.yml']",4,4fca939b11fb798e4edbd4362210d71a29551267,merge_tripleo-upgrade,workload_launch_post_composable_upgrade: false,,15,0
openstack%2Ftripleo-upgrade~master~If29c237d8a8e0f644d36c1e839b813d7f18a677f,openstack/tripleo-upgrade,master,If29c237d8a8e0f644d36c1e839b813d7f18a677f,Assign new network and description attribute to Monitor role,MERGED,2017-12-12 15:47:53.000000000,2017-12-13 19:28:03.000000000,2017-12-13 19:28:03.000000000,"[{'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 18851}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': ['tasks/upgrade/convert_roles_data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/dce676bdc93f597ac9fc5fbb1662c1399e25d147', 'message': 'Assign new network and description attribute to Monitor role\n\nThis change adds the networks and description attributes for the\nCeph Monitor role to roles_data during upgrade.\n\nChange-Id: If29c237d8a8e0f644d36c1e839b813d7f18a677f\n'}]",0,527433,dce676bdc93f597ac9fc5fbb1662c1399e25d147,9,7,1,26343,,,0,"Assign new network and description attribute to Monitor role

This change adds the networks and description attributes for the
Ceph Monitor role to roles_data during upgrade.

Change-Id: If29c237d8a8e0f644d36c1e839b813d7f18a677f
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/33/527433/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/upgrade/convert_roles_data.yaml'],1,dce676bdc93f597ac9fc5fbb1662c1399e25d147,merge_tripleo-upgrade," - name: Assigns new attributes to Monitor role replace: dest: '{{ custom_roles_file.stdout }}' regexp: '^(- name: Monitor.*)' replace: ""{{ item }}"" with_items: - '\1\n networks:\n - Storage' - '\1\n description: |\n Ceph Monitor role' ",,9,0
openstack%2Ftripleo-upgrade~master~I5f398e114cd929621b4e24742c4f1d2376a2ac8e,openstack/tripleo-upgrade,master,I5f398e114cd929621b4e24742c4f1d2376a2ac8e,Add support for upgrading HCI environments,MERGED,2017-12-12 15:47:53.000000000,2017-12-13 19:28:02.000000000,2017-12-13 19:28:02.000000000,"[{'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 18851}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': ['templates/upgrade_hci.yaml.j2', 'infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tasks/upgrade/create-upgrade-scripts.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/270e429816cb5fab7a44dbfe182b2c5008b70f01', 'message': 'Add support for upgrading HCI environments\n\nIn case of HCI deployments the upgrade workflow slightly differs\nand we need to keep using puppet ceph during the major upgrade\ncomposable step. This change adds the required changes to accomodate\nthis. For reference:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1511494#c3\n\nChange-Id: I5f398e114cd929621b4e24742c4f1d2376a2ac8e\n'}]",0,527432,270e429816cb5fab7a44dbfe182b2c5008b70f01,9,7,1,26343,,,0,"Add support for upgrading HCI environments

In case of HCI deployments the upgrade workflow slightly differs
and we need to keep using puppet ceph during the major upgrade
composable step. This change adds the required changes to accomodate
this. For reference:
https://bugzilla.redhat.com/show_bug.cgi?id=1511494#c3

Change-Id: I5f398e114cd929621b4e24742c4f1d2376a2ac8e
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/32/527432/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/upgrade_hci.yaml.j2', 'infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tasks/upgrade/create-upgrade-scripts.yaml', 'defaults/main.yml']",5,270e429816cb5fab7a44dbfe182b2c5008b70f01,merge_tripleo-upgrade, # Enable HCI upgrade upgrade_hci: false,,30,0
openstack%2Ftripleo-upgrade~master~I52dc779aee3f9f08f0cf61a1b79a9f4eaff1bac3,openstack/tripleo-upgrade,master,I52dc779aee3f9f08f0cf61a1b79a9f4eaff1bac3,[UPDATES] Start minor update with controller nodes.,MERGED,2017-12-12 15:47:53.000000000,2017-12-13 19:28:01.000000000,2017-12-13 19:28:01.000000000,"[{'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': ['tasks/update/create-update-scripts.yaml', 'templates/overcloud_update.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/6a1831dc8a20342568d195d49ce492a818a43285', 'message': ""[UPDATES] Start minor update with controller nodes.\n\nAdjust role's name to be executed first during update.\nSet 'force: true' for template tasks creating update scripts.\n\nChange-Id: I52dc779aee3f9f08f0cf61a1b79a9f4eaff1bac3\n""}]",0,527431,6a1831dc8a20342568d195d49ce492a818a43285,10,7,1,26343,,,0,"[UPDATES] Start minor update with controller nodes.

Adjust role's name to be executed first during update.
Set 'force: true' for template tasks creating update scripts.

Change-Id: I52dc779aee3f9f08f0cf61a1b79a9f4eaff1bac3
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/31/527431/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/update/create-update-scripts.yaml', 'templates/overcloud_update.sh.j2']",2,6a1831dc8a20342568d195d49ce492a818a43285,merge_tripleo-upgrade,"{% set tmp_role_name = item.split('-', 1)[-1] %} echo ""Runing update of {{ tmp_role_name }}"" openstack overcloud update stack --nodes {{ tmp_role_name }} 2>&1","echo ""Runing update of {{ item }}"" openstack overcloud update stack --nodes {{ item }} 2>&1",8,3
openstack%2Ftripleo-upgrade~master~Ia0570a44139c6ef3845ddff19e3d80e54603a59b,openstack/tripleo-upgrade,master,Ia0570a44139c6ef3845ddff19e3d80e54603a59b,Add the option to remove packages during upgrade,MERGED,2017-12-12 15:47:53.000000000,2017-12-13 19:28:00.000000000,2017-12-13 19:28:00.000000000,"[{'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 18851}, {'_account_id': 20775}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': ['templates/remove-packages.yaml.j2', 'infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tasks/upgrade/create-upgrade-scripts.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/464058d0d243bd572c02d5b07eaf46af3dec9a50', 'message': 'Add the option to remove packages during upgrade\n\nThis change adds the option to remove the rpm packages for services\nwhich are migrated to containers during the upgrade as described in\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1470041\n\nChange-Id: Ia0570a44139c6ef3845ddff19e3d80e54603a59b\n'}]",0,527430,464058d0d243bd572c02d5b07eaf46af3dec9a50,13,9,1,26343,,,0,"Add the option to remove packages during upgrade

This change adds the option to remove the rpm packages for services
which are migrated to containers during the upgrade as described in
https://bugzilla.redhat.com/show_bug.cgi?id=1470041

Change-Id: Ia0570a44139c6ef3845ddff19e3d80e54603a59b
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/30/527430/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/remove-packages.yaml.j2', 'infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tasks/upgrade/create-upgrade-scripts.yaml', 'defaults/main.yml']",5,464058d0d243bd572c02d5b07eaf46af3dec9a50,merge_tripleo-upgrade, # Remove packages which get migrated to containers during upgrade upgrade_remove_rpm: false,,21,0
openstack%2Fnova~stable%2Focata~I9b0d8e8d4b3ab2cb3d578c22fa259e0e7c0d325b,openstack/nova,stable/ocata,I9b0d8e8d4b3ab2cb3d578c22fa259e0e7c0d325b,fix nova accepting invalid availability zone name with ':',MERGED,2017-10-04 22:11:47.000000000,2017-12-13 19:27:51.000000000,2017-12-13 19:27:51.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 12898}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 25625}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-04 22:11:47.000000000', 'files': ['api-ref/source/parameters.yaml', 'nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/validation/validators.py', 'releasenotes/notes/bug-1695861-ebc8a0aa7a87f7e0.yaml', 'doc/source/aggregates.rst', 'nova/api/validation/parameter_types.py', 'nova/api/openstack/compute/schemas/aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c53df19bd4535c5a95cd1aa7e50f49e128f83b95', 'message': ""fix nova accepting invalid availability zone name with ':'\n\nNova has a legacy hack to allow admins to specify hosts via an\navailability zone using az:host:node. That means ':' cannot be\nincluded in the name of an availability zone itself.\n\nHowever, the aggregate API accepts requests which have\navailability zone names including ':'.\n\nThis patch checks the availabilty zone name when aggregate is\ncreated or updated and raises an error if it contains ':'.\n\nChange-Id: I9b0d8e8d4b3ab2cb3d578c22fa259e0e7c0d325b\nCloses-Bug: #1695861\n(cherry picked from commit 38b25397e805dcf7a995666049713304fe4f1af1)\n(cherry picked from commit a33634e5558b20e4bd496fe476f6ceb1a2ba79f6)\n""}]",0,509659,c53df19bd4535c5a95cd1aa7e50f49e128f83b95,26,12,1,6873,,,0,"fix nova accepting invalid availability zone name with ':'

Nova has a legacy hack to allow admins to specify hosts via an
availability zone using az:host:node. That means ':' cannot be
included in the name of an availability zone itself.

However, the aggregate API accepts requests which have
availability zone names including ':'.

This patch checks the availabilty zone name when aggregate is
created or updated and raises an error if it contains ':'.

Change-Id: I9b0d8e8d4b3ab2cb3d578c22fa259e0e7c0d325b
Closes-Bug: #1695861
(cherry picked from commit 38b25397e805dcf7a995666049713304fe4f1af1)
(cherry picked from commit a33634e5558b20e4bd496fe476f6ceb1a2ba79f6)
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/509659/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/validation/validators.py', 'releasenotes/notes/bug-1695861-ebc8a0aa7a87f7e0.yaml', 'doc/source/aggregates.rst', 'nova/api/validation/parameter_types.py', 'nova/api/openstack/compute/schemas/aggregates.py']",7,c53df19bd4535c5a95cd1aa7e50f49e128f83b95,bug/1695861,"availability_zone = {'oneOf': [parameter_types.az_name, {'type': 'null'}]} availability_zone_with_leading_trailing_spaces = { 'oneOf': [parameter_types.az_name_with_leading_trailing_spaces,","availability_zone = {'oneOf': [parameter_types.name, {'type': 'null'}]} availability_zone_with_leading_trailing_spaces = { 'oneOf': [parameter_types.name_with_leading_trailing_spaces,",88,3
openstack%2Fnova~master~Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed,openstack/nova,master,Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed,Move the claim_resources method to scheduler utils,MERGED,2017-10-11 23:52:31.000000000,2017-12-13 19:27:43.000000000,2017-12-13 19:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 11604}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 23630}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-11 23:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81a7c8a6b8db27df09ab2bd15c775ed1080b7b11', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originall in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a more common\nlocation.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 2, 'created': '2017-10-12 21:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3fca249e42210035465e1a1fdc7f749d62b538c', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originall in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a more common\nlocation.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 3, 'created': '2017-10-17 00:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4ddb2b63d1a984d48868f59ffd75bfd6500d65a', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originall in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a more common\nlocation.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 4, 'created': '2017-10-17 15:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b86daf4daabbafcd8bbdb595c284a11e26b1d8c4', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 5, 'created': '2017-10-17 22:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/625bd538d3a04beb5a1ae92a5a4ddf1a5987797e', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 6, 'created': '2017-10-18 21:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5bd9b1f4c62cd1e2c8641907bcf5395252aa9b2', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 7, 'created': '2017-10-20 20:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc8897afa91ccb4092a83ad497ef76b76fcbc54c', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 8, 'created': '2017-10-21 03:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54c971d264cf6e6e3dfe6fbd7359e363ff52acdb', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 9, 'created': '2017-10-21 13:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66451ee4db7b4e12f1185d285e40e7b5e6ca1111', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 10, 'created': '2017-10-24 15:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/451f0e6df3b4cecf69487e99a842b7070bb5c529', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 11, 'created': '2017-10-26 17:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0678157aaaed56e5535906ecef3514de0d6d73ae', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 12, 'created': '2017-10-26 20:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7abd4a0372c7b35bb644958fe3714637787dbbcf', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 13, 'created': '2017-10-27 17:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42758c6d61efd7b1854a9de95c269a6db77ec95a', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 14, 'created': '2017-10-31 14:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1043abb8497fe9af089826c538639fa76d4b4da3', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 15, 'created': '2017-10-31 17:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/846a4ac00b1bd03cf49f53465636850449d3c4ff', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 16, 'created': '2017-10-31 21:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d87336750457beea85abc1257ca5eed2ee1d8c3', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 17, 'created': '2017-11-01 13:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7fa8b8f0b87ecfa42e4e0dc51b932b8cee77402', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 18, 'created': '2017-11-01 23:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2166a73e1ca08086be9014200a59dbff834bc559', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 19, 'created': '2017-11-02 15:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59dd3172550cec5955f6e9e648872c9909f4864e', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 20, 'created': '2017-11-02 16:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83b32b2689d588abc21c0ae9f342ffe2b38fe996', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 21, 'created': '2017-11-02 21:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a4db733af50234b90b607bb20eb610565f3c5d4', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 22, 'created': '2017-11-03 16:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e38c003b5088ccea54429b0efc3955e44957207e', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 23, 'created': '2017-11-15 23:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7769c90e0b51c36c30804e41b24d7157ec4a611e', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 24, 'created': '2017-11-16 15:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ab7e1773f40d9a8bdd6a7956320d3c15065c617', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 25, 'created': '2017-11-16 16:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3b2478b896a3f35f95fbf82261fbddd68369169', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 26, 'created': '2017-11-16 22:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d87be3f0c4f8b9d571343ad9418fdc2d5ece1f0', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 27, 'created': '2017-11-17 20:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa22869bfa8565477776642938addc7e3ac4fe97', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 28, 'created': '2017-11-28 17:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cdab776a716db61dbc16267714224b3c53f7bb6', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 29, 'created': '2017-11-28 18:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/396dbd9a8fc4d846b628195f1c9a39e1b5a5bd07', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 30, 'created': '2017-12-04 17:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6e5d7a7dee658c88af303fb02ba7a02ca088217', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 31, 'created': '2017-12-05 16:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9632131b697b95967402163c007d5a17edd9b4c0', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 32, 'created': '2017-12-06 18:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/383e4f78abef91cd9bfd0c321e50a730462dd7c8', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 33, 'created': '2017-12-07 15:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/701c3e5ef30fdeefe5d18911958568fd3bb999b4', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 34, 'created': '2017-12-08 16:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/075ea815ad00802bef8549f3983d31260b451353', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 35, 'created': '2017-12-11 14:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6477547b8aefa9ce799bdabd31c12b4056486a7a', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 36, 'created': '2017-12-11 19:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bebbc6f08be4e6821d76979ac48faac5f4d21a6', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 37, 'created': '2017-12-11 22:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0f0da21052b57a7bd59655b6879af3adc11bf19', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}, {'number': 38, 'created': '2017-12-12 03:07:59.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_utils.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/98f47224aa5474080bd8f44f0fa195057554a1c5', 'message': 'Move the claim_resources method to scheduler utils\n\nThis method was originally in the filter_scheduler, but as it will need\nto be called by the conductor too, it should be moved to a common location.\n\nBlueprint: return-alternate-hosts\n\nChange-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed\n'}]",14,511357,98f47224aa5474080bd8f44f0fa195057554a1c5,413,21,38,1063,,,0,"Move the claim_resources method to scheduler utils

This method was originally in the filter_scheduler, but as it will need
to be called by the conductor too, it should be moved to a common location.

Blueprint: return-alternate-hosts

Change-Id: Ia6e008a680fdd373fc4a9beb98fdf5f8fbb582ed
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/511357/38 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_utils.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py']",4,81a7c8a6b8db27df09ab2bd15c775ed1080b7b11,bp/return-alternate-hosts," @mock.patch('nova.scheduler.utils.claim_resources') # And ensure we never called claim_resources() @mock.patch('nova.scheduler.utils.claim_resources') # And ensure we never called claim_resources() @mock.patch('nova.scheduler.utils.claim_resources') alloc_reqs_by_rp_uuid = {uuids.cn1: [fake_alloc]} mock_claim.assert_called_once_with(ctx.elevated.return_value, self.placement_client, spec_obj, uuids.instance, alloc_reqs_by_rp_uuid[uuids.cn1][0], version=None) @mock.patch('nova.scheduler.utils.claim_resources') uuids.cn1: [{""allocations"": mock.sentinel.alloc_req}], mock_claim.assert_called_once_with(ctx.elevated.return_value, self.placement_client, spec_obj, uuids.instance, alloc_reqs_by_rp_uuid[uuids.cn1][0], version=fake_version) @mock.patch('nova.scheduler.utils.claim_resources') alloc_reqs_by_rp_uuid = {uuids.cn1: [fake_alloc]} @mock.patch('nova.scheduler.utils.claim_resources') uuids.cn1: [{""allocations"": ""fake_cn1_alloc""}], uuids.cn2: [{""allocations"": ""fake_cn2_alloc""}], # Check that we called claim_resources() for both the first and second mock.call(ctx.elevated.return_value, self.placement_client, spec_obj, uuids.instance0, alloc_reqs_by_rp_uuid[uuids.cn2][0], version=None), mock.call(ctx.elevated.return_value, self.placement_client, spec_obj, uuids.instance1, alloc_reqs_by_rp_uuid[uuids.cn1][0], version=None), @mock.patch('nova.scheduler.utils.claim_resources') alloc_reqs[hs.uuid] = [{}] @mock.patch('nova.scheduler.utils.claim_resources') alloc_reqs[hs.uuid] = [{}] @mock.patch('nova.scheduler.utils.claim_resources') alloc_reqs[hs.uuid] = [{}]"," @mock.patch('nova.scheduler.filter_scheduler.FilterScheduler.' '_claim_resources') # And ensure we never called _claim_resources() @mock.patch('nova.scheduler.filter_scheduler.FilterScheduler.' '_claim_resources') # And ensure we never called _claim_resources() @mock.patch('nova.scheduler.filter_scheduler.FilterScheduler.' '_claim_resources') alloc_reqs_by_rp_uuid = {uuids.cn1: fake_alloc} mock_claim.assert_called_once_with(ctx.elevated.return_value, spec_obj, uuids.instance, alloc_reqs_by_rp_uuid[uuids.cn1], version=None) @mock.patch('nova.scheduler.filter_scheduler.FilterScheduler.' '_claim_resources') uuids.cn1: {""allocations"": [mock.sentinel.alloc_req]}, mock_claim.assert_called_once_with(ctx.elevated.return_value, spec_obj, uuids.instance, alloc_reqs_by_rp_uuid[uuids.cn1], version=fake_version) @mock.patch('nova.scheduler.filter_scheduler.FilterScheduler.' '_claim_resources') alloc_reqs_by_rp_uuid = {uuids.cn1: fake_alloc} @mock.patch('nova.scheduler.filter_scheduler.FilterScheduler.' '_claim_resources') uuids.cn1: {""allocations"": [""fake_cn1_alloc""]}, uuids.cn2: {""allocations"": [""fake_cn2_alloc""]}, # Check that we called _claim_resources() for both the first and second mock.call(ctx.elevated.return_value, spec_obj, uuids.instance0, alloc_reqs_by_rp_uuid[uuids.cn2], version=None), mock.call(ctx.elevated.return_value, spec_obj, uuids.instance1, alloc_reqs_by_rp_uuid[uuids.cn1], version=None), def test_claim_resources(self): """"""Tests that when _schedule() calls _claim_resources(), that we appropriately call the placement client to claim resources for the instance. """""" ctx = mock.Mock(user_id=uuids.user_id) spec_obj = mock.Mock(project_id=uuids.project_id) instance_uuid = uuids.instance alloc_reqs = [mock.sentinel.alloc_req] res = self.driver._claim_resources(ctx, spec_obj, instance_uuid, alloc_reqs) pc = self.placement_client pc.claim_resources.return_value = True pc.claim_resources.assert_called_once_with(uuids.instance, mock.sentinel.alloc_req, uuids.project_id, uuids.user_id, version=None) self.assertTrue(res) @mock.patch(""nova.scheduler.filter_scheduler.FilterScheduler."" ""_claim_resources"") alloc_reqs[hs.uuid] = {} @mock.patch(""nova.scheduler.filter_scheduler.FilterScheduler."" ""_claim_resources"") alloc_reqs[hs.uuid] = {} @mock.patch(""nova.scheduler.filter_scheduler.FilterScheduler."" ""_claim_resources"") alloc_reqs[hs.uuid] = {}",97,105
openstack%2Ftripleo-common~master~I5f988b003ed9600a530868dedc911a4f1333e730,openstack/tripleo-common,master,I5f988b003ed9600a530868dedc911a4f1333e730,Correct the container name confusion in the swift rings workflow,MERGED,2017-12-07 17:14:10.000000000,2017-12-13 19:22:34.000000000,2017-12-13 19:22:34.000000000,"[{'_account_id': 4328}, {'_account_id': 4978}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-07 17:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ecd4f5a3ac9d8392065640e081182c23251d758e', 'message': 'Correct the container name confusion in the swift rings workflow\n\nThe create_swift_rings_backup_container_plan workflow switches between\nusing the overcloud swift container and the overcloud-swift-rings\ncontainer (if given the input ""overcloud""). This patch determines the\ncontainer name in one place and updates all uses.\n\nWhile refactoring it also removes the duplication of the\nswift-rings.tar.gz file name.\n\nCloses-Bug: #1736998\nChange-Id: I5f988b003ed9600a530868dedc911a4f1333e730\n'}, {'number': 2, 'created': '2017-12-08 11:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0005a9d08b196409cda1a579227086c10129248e', 'message': 'Correct the container name confusion in the swift rings workflow\n\nThe create_swift_rings_backup_container_plan workflow switches between\nusing the overcloud swift container and the overcloud-swift-rings\ncontainer (if given the input ""overcloud""). This patch determines the\ncontainer name in one place and updates all uses.\n\nWhile refactoring it also removes the duplication of the\nswift-rings.tar.gz file name.\n\nCloses-Bug: #1736998\nChange-Id: I5f988b003ed9600a530868dedc911a4f1333e730\n'}, {'number': 3, 'created': '2017-12-11 10:28:14.000000000', 'files': ['workbooks/swift_rings_backup.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4ad2410d68c535d7833797028e3107489f7f37cb', 'message': 'Correct the container name confusion in the swift rings workflow\n\nThe create_swift_rings_backup_container_plan workflow switches between\nusing the overcloud swift container and the overcloud-swift-rings\ncontainer (if given the input ""overcloud""). This patch determines the\ncontainer name in one place and updates all uses.\n\nWhile refactoring it also removes the duplication of the\nswift-rings.tar.gz file name.\n\nCloses-Bug: #1736998\nChange-Id: I5f988b003ed9600a530868dedc911a4f1333e730\n'}]",2,526462,4ad2410d68c535d7833797028e3107489f7f37cb,21,7,3,9712,,,0,"Correct the container name confusion in the swift rings workflow

The create_swift_rings_backup_container_plan workflow switches between
using the overcloud swift container and the overcloud-swift-rings
container (if given the input ""overcloud""). This patch determines the
container name in one place and updates all uses.

While refactoring it also removes the duplication of the
swift-rings.tar.gz file name.

Closes-Bug: #1736998
Change-Id: I5f988b003ed9600a530868dedc911a4f1333e730
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/62/526462/2 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/swift_rings_backup.yaml'],1,ecd4f5a3ac9d8392065640e081182c23251d758e,bug/1736998," swift_rings_container: publish: swift_rings_container: ""<% $.container %>-swift-rings"" swift_rings_tar: ""swift-rings.tar.gz"" on-complete: check_container check_container: action: swift.head_container container=<% $.swift_rings_container %> action: tripleo.plan.create_container container=<% $.swift_rings_container %> container: <% $.swift_rings_container %> obj: <% $.swift_rings_tar %> container: <% $.swift_rings_container %> container: <% $.swift_rings_container %> obj: <% $.swift_rings_tar %> container: <% $.swift_rings_container %>"," check_container: action: swift.head_container container=<% $.container %> action: tripleo.plan.create_container container=""<% $.container %>-swift-rings"" container: ""<% $.container %>-swift-rings"" obj: ""swift-rings.tar.gz"" container: <% $.container %> container: ""<% $.container %>-swift-rings"" obj: ""swift-rings.tar.gz"" container: <% $.container %>",15,8
openstack%2Fpanko~master~Ie4e516bad59b40a5e22264b32956d132f0bdd4fc,openstack/panko,master,Ie4e516bad59b40a5e22264b32956d132f0bdd4fc,Block keystonemiddleware for temporary,MERGED,2017-12-13 07:00:20.000000000,2017-12-13 19:22:34.000000000,2017-12-13 09:40:14.000000000,"[{'_account_id': 2813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 07:00:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/panko/commit/cb41192b8a207979735296201cd06eaa63ca332a', 'message': 'Block keystonemiddleware for temporary\n\nChange-Id: Ie4e516bad59b40a5e22264b32956d132f0bdd4fc\nRelated-bug: #1737115\n'}]",0,527604,cb41192b8a207979735296201cd06eaa63ca332a,8,2,1,22752,,,0,"Block keystonemiddleware for temporary

Change-Id: Ie4e516bad59b40a5e22264b32956d132f0bdd4fc
Related-bug: #1737115
",git fetch https://review.opendev.org/openstack/panko refs/changes/04/527604/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cb41192b8a207979735296201cd06eaa63ca332a,bug/1737115,"keystonemiddleware!=4.1.0,!=4.19.0,>=4.0.0 # Apache-2.0","keystonemiddleware!=4.1.0,>=4.0.0 # Apache-2.0",1,1
openstack%2Ftripleo-quickstart-extras~master~I140ea62b91dfa9c10d40cf6cb896bc627d35f9bc,openstack/tripleo-quickstart-extras,master,I140ea62b91dfa9c10d40cf6cb896bc627d35f9bc,Make sure we don’t use delorean-current for release != master.,MERGED,2017-12-09 08:23:54.000000000,2017-12-13 19:22:33.000000000,2017-12-13 19:22:33.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 11090}, {'_account_id': 16515}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-09 08:23:54.000000000', 'files': ['roles/overcloud-upgrade/templates/overcloud-repo-tripleo-ci.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4ecea2589b217ff4bdec2267181e833a79615f07', 'message': 'Make sure we don’t use delorean-current for release != master.\n\nWe don’t want delorean-current for ""to-pike"" upgrade testing.\n\nChange-Id: I140ea62b91dfa9c10d40cf6cb896bc627d35f9bc\n'}]",0,526830,4ecea2589b217ff4bdec2267181e833a79615f07,15,9,1,8297,,,0,"Make sure we don’t use delorean-current for release != master.

We don’t want delorean-current for ""to-pike"" upgrade testing.

Change-Id: I140ea62b91dfa9c10d40cf6cb896bc627d35f9bc
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/30/526830/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-upgrade/templates/overcloud-repo-tripleo-ci.yaml.j2'],1,4ecea2589b217ff4bdec2267181e833a79615f07,,{% if target_upgrade_version == 'master' %}{% endif %},,2,1
openstack%2Ftripleo-validations~master~Ib570c3f8a21dc0a2af2373f3481f48623f05d852,openstack/tripleo-validations,master,Ib570c3f8a21dc0a2af2373f3481f48623f05d852,Explicitly set default to 0 for quiet argument in validate-files script,MERGED,2017-10-19 13:39:20.000000000,2017-12-13 19:10:22.000000000,2017-12-13 19:10:22.000000000,"[{'_account_id': 4978}, {'_account_id': 8449}, {'_account_id': 9317}, {'_account_id': 11491}, {'_account_id': 13039}, {'_account_id': 17888}, {'_account_id': 20970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-19 13:39:20.000000000', 'files': ['tools/validate-files.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/dbe4c85400b5a4b67538e03b88b1f69e0161c54a', 'message': ""Explicitly set default to 0 for quiet argument in validate-files script\n\nDue to a bug in python3 which sets default to None for 'count' actions,\nand the fact that Fedora now uses python3 as default, running the pep8\nportion of the tests would fail on Fedora.\n\nChange-Id: Ib570c3f8a21dc0a2af2373f3481f48623f05d852\n""}]",0,513386,dbe4c85400b5a4b67538e03b88b1f69e0161c54a,29,8,1,9317,,,0,"Explicitly set default to 0 for quiet argument in validate-files script

Due to a bug in python3 which sets default to None for 'count' actions,
and the fact that Fedora now uses python3 as default, running the pep8
portion of the tests would fail on Fedora.

Change-Id: Ib570c3f8a21dc0a2af2373f3481f48623f05d852
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/86/513386/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/validate-files.py'],1,dbe4c85400b5a4b67538e03b88b1f69e0161c54a,fix_validate_files," # TODO(akrivoka): Python3 sets this default to None instead # of 0. Remove this when this bug is fixed in Python3. default=0,",,3,0
openstack%2Finstack-undercloud~master~I987a15326fd6c462cbfc84815ef4ea8efc9c870a,openstack/instack-undercloud,master,I987a15326fd6c462cbfc84815ef4ea8efc9c870a,Remove usage of ironic::drivers::ipmi::retry_timeout,MERGED,2017-12-04 14:27:11.000000000,2017-12-13 18:54:20.000000000,2017-12-13 18:54:19.000000000,"[{'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-04 14:27:11.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/c4d33554c04b603abad1da21aecafab5dbf6e613', 'message': 'Remove usage of ironic::drivers::ipmi::retry_timeout\n\nThis parameter is deprecated. The replacement parameter has a bigger\ndefault value of 60 seconds, which we probably should use (the previous\none had a default of 10).\n\nChange-Id: I987a15326fd6c462cbfc84815ef4ea8efc9c870a\n'}]",0,525214,c4d33554c04b603abad1da21aecafab5dbf6e613,27,6,1,10239,,,0,"Remove usage of ironic::drivers::ipmi::retry_timeout

This parameter is deprecated. The replacement parameter has a bigger
default value of 60 seconds, which we probably should use (the previous
one had a default of 10).

Change-Id: I987a15326fd6c462cbfc84815ef4ea8efc9c870a
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/14/525214/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,c4d33554c04b603abad1da21aecafab5dbf6e613,retry_timeout,,ironic::drivers::ipmi::retry_timeout: 15,0,1
openstack%2Fpuppet-tripleo~master~I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1,openstack/puppet-tripleo,master,I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1,Add support for switchdev mode in SR-IOV,MERGED,2017-09-25 13:30:01.000000000,2017-12-13 18:54:20.000000000,2017-12-13 18:54:20.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 8871}, {'_account_id': 12171}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24654}, {'_account_id': 25241}, {'_account_id': 26682}]","[{'number': 1, 'created': '2017-09-25 13:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4b35318884fc1dbdf76377f7abf63d41fdb3761d', 'message': 'Support switchdev mode beside legacy mode in ovs\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 2, 'created': '2017-09-25 13:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a339dd65b56c0058b1ed36f4b80e76b1ae2e1c5b', 'message': 'Support switchdev mode beside legacy mode in ovs\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 3, 'created': '2017-09-26 08:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b2f45ec1b043570f5c90e0a8c518aafcb528d021', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 4, 'created': '2017-09-26 08:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8dcf088396e956ce082d17945637b4c0161c6eb6', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 5, 'created': '2017-09-26 10:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5a283ad33a995a4cf8cd7f08381becb7e63fea9e', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 6, 'created': '2017-10-01 10:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/06025bd76ffc13d5068bd3b0f365b02a38d9e6f6', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 7, 'created': '2017-10-01 11:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/829bc5d0ff6f0eeaaedd1acdff394ef675fa2632', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 8, 'created': '2017-10-02 13:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1ee66f207381058310d045b0b4d9c83a3de8ace6', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 9, 'created': '2017-10-24 18:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a30d3194858f1a168f3b7ef99953d6797581b711', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 10, 'created': '2017-11-04 17:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f9cd2191a4c2eb2e003257e3e7df9d477195728a', 'message': 'Add support for switchdev mode in SR-IOV\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 11, 'created': '2017-11-12 14:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/51ff09e4a16eccf434f8d0241251694d590b8c0b', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 12, 'created': '2017-11-12 14:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/85793a0775d85135c0404fe48dbc83fbc2d0d448', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 13, 'created': '2017-11-13 06:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/39703da8f94e92f534a447c40496462978fc7b69', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 14, 'created': '2017-11-13 07:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d0be7d7731c4f8e9bcc8718704dd978bcef7c534', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 15, 'created': '2017-11-19 09:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/cede80eb6d52c9921f4d954f9221fc2e3cc1d9f5', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 16, 'created': '2017-11-21 14:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/186c2331d61a22255c7912fbe12fd173d360dd8b', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}, {'number': 17, 'created': '2017-12-12 14:58:43.000000000', 'files': ['templates/switchdev/switchdev.epp', 'lib/puppet/provider/sriov_vf_config/numvfs.rb', 'manifests/host/sriov/numvfs_persistence.pp', 'releasenotes/notes/ovs-hw-offload-89a49899af3b9892.yaml', 'lib/puppet/type/sriov_vf_config.rb', 'spec/unit/provider/sriov_vf_config/numvfs_spec.rb', 'manifests/host/sriov.pp', 'spec/defines/tripleo_host_sriov_numvfs_persistence_spec.rb', 'spec/unit/type/sriov_vf_config_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e5c563290cbd0c12056169403043aef41246e353', 'message': 'Add support for switchdev mode in SR-IOV\n\nIn Kernel 4.10 supports changing SR-IOV to switchdev mode.\nThis mode allows to create VFs represontors which can manage\nthe SR-IOV VFs from the hypervsior.\n\nThis patch extends the tripleo::host::sriov::number_of_vf to\n<physical_network>:<number_of_vfs>:<sriov_mode>,\nwhere sriov_mode accepts legacy or switchdev.\nif sriov_mode is not specified we default to legacy.\n\nChange-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1\n'}]",20,507100,e5c563290cbd0c12056169403043aef41246e353,102,13,17,25241,,,0,"Add support for switchdev mode in SR-IOV

In Kernel 4.10 supports changing SR-IOV to switchdev mode.
This mode allows to create VFs represontors which can manage
the SR-IOV VFs from the hypervsior.

This patch extends the tripleo::host::sriov::number_of_vf to
<physical_network>:<number_of_vfs>:<sriov_mode>,
where sriov_mode accepts legacy or switchdev.
if sriov_mode is not specified we default to legacy.

Change-Id: I578f956f2a8c6ee29a9d1ff38ee51765bcab05c1
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/00/507100/15 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/sriov_vf_config/numvfs.rb', 'lib/puppet/type/sriov_vf_config.rb', 'spec/unit/provider/sriov_vf_config/numvfs_spec.rb', 'spec/unit/type/sriov_vf_config_spec.rb']",4,4b35318884fc1dbdf76377f7abf63d41fdb3761d,bp/triplo-ovs-hw-offload," it 'should allow name to be passed' do expect{Puppet::Type.type(:sriov_vf_config).new( :name => 'eth0:10:legacy', :ensure => 'present' )}.not_to raise_error end it 'should allow name to be passed' do expect{Puppet::Type.type(:sriov_vf_config).new( :name => 'eth0:10:switchdev', :ensure => 'present' )}.not_to raise_error end it 'should throw error for invalid format for ovs mode' do expect{Puppet::Type.type(:sriov_vf_config).new( :name => 'eth0:10:None', :ensure => 'present' )}.to raise_error(Puppet::ResourceError) end it 'should throw error for invalid format without ovs mode' do expect{Puppet::Type.type(:sriov_vf_config).new( :name => 'eth0:10:', :ensure => 'present' )}.to raise_error(Puppet::ResourceError) end ",,136,4
openstack%2Ftripleo-quickstart-extras~master~I5e779f48a02c5389cebf84e9d3899250d63cace8,openstack/tripleo-quickstart-extras,master,I5e779f48a02c5389cebf84e9d3899250d63cace8,"Always use overcloudrc, it is now v3 by default",MERGED,2017-11-28 11:39:07.000000000,2017-12-13 18:54:19.000000000,2017-12-13 18:54:19.000000000,"[{'_account_id': 3153}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-11-28 11:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/68cc4750c062e95fd7090e328fed5b594bafe1df', 'message': 'Always use overcloudrc, it is now v3 by default\n\nThe v3 file is going to be removed as it is no longer needed.\n\nNeeded-By: I3612c58c356f8955bd44655cf5aacc20be532cbc\nChange-Id: I5e779f48a02c5389cebf84e9d3899250d63cace8\n'}, {'number': 2, 'created': '2017-11-28 11:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6720daa4da6b1c08d4f0cb0fc1ee2569f8731d11', 'message': 'Always use overcloudrc, it is now v3 by default\n\nThe v3 file is going to be removed as it is no longer needed.\n\nRelated-Bug: #1733640\nNeeded-By: I3612c58c356f8955bd44655cf5aacc20be532cbc\nChange-Id: I5e779f48a02c5389cebf84e9d3899250d63cace8\n'}, {'number': 3, 'created': '2017-12-08 12:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/59d8aafb5de1947f4df386918d19629c3724a8d9', 'message': 'Always use overcloudrc, it is now v3 by default\n\nThe v3 file is going to be removed as it is no longer needed.\n\nRelated-Bug: #1733640\nNeeded-By: I3612c58c356f8955bd44655cf5aacc20be532cbc\nChange-Id: I5e779f48a02c5389cebf84e9d3899250d63cace8\n'}, {'number': 4, 'created': '2017-12-09 10:02:52.000000000', 'files': ['roles/overcloud-deploy/templates/overcloud-deploy-post.sh.j2', 'roles/validate-tempest/templates/configure-tempest.sh.j2', 'roles/validate-simple/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7a5701d14f9bf5dc5f10b8fd78c4bb3f7f775b3a', 'message': 'Always use overcloudrc, it is now v3 by default\n\nThe v3 file is going to be removed as it is no longer needed.\n\nRelated-Bug: #1733640\nNeeded-By: I3612c58c356f8955bd44655cf5aacc20be532cbc\nChange-Id: I5e779f48a02c5389cebf84e9d3899250d63cace8\n'}]",0,523393,7a5701d14f9bf5dc5f10b8fd78c4bb3f7f775b3a,33,10,4,9712,,,0,"Always use overcloudrc, it is now v3 by default

The v3 file is going to be removed as it is no longer needed.

Related-Bug: #1733640
Needed-By: I3612c58c356f8955bd44655cf5aacc20be532cbc
Change-Id: I5e779f48a02c5389cebf84e9d3899250d63cace8
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/93/523393/4 && git format-patch -1 --stdout FETCH_HEAD,"['roles/overcloud-deploy/templates/overcloud-deploy-post.sh.j2', 'roles/validate-tempest/templates/configure-tempest.sh.j2', 'roles/validate-simple/defaults/main.yml']",3,68cc4750c062e95fd7090e328fed5b594bafe1df,bug/1733640,," {% if release in ['newton', 'ocata', 'pike'] -%} {%- else -%} overcloudrc.v3 {%- endif -%}",0,14
openstack%2Frpm-packaging~master~Ib7ef58fd9c224c7febf75ef9bbaee7c03848dda5,openstack/rpm-packaging,master,Ib7ef58fd9c224c7febf75ef9bbaee7c03848dda5,Update oslo.policy to 1.32.1,MERGED,2017-12-11 16:36:36.000000000,2017-12-13 18:53:15.000000000,2017-12-13 18:53:15.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 16:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/90ab5230d93b807ceabea5fca12c2a25e712df5a', 'message': 'Update oslo.policy to 1.32.1\n\nChange-Id: Ib7ef58fd9c224c7febf75ef9bbaee7c03848dda5\n'}, {'number': 2, 'created': '2017-12-12 15:12:02.000000000', 'files': ['openstack/oslo.policy/oslo.policy.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/99295dfa614b6d9499a110150c3f1c14987de697', 'message': 'Update oslo.policy to 1.32.1\n\nDepends-on: Iedf927cae5c51a5c21893cd64718df0f6011701d\nChange-Id: Ib7ef58fd9c224c7febf75ef9bbaee7c03848dda5\n'}]",0,527154,99295dfa614b6d9499a110150c3f1c14987de697,13,6,2,17130,,,0,"Update oslo.policy to 1.32.1

Depends-on: Iedf927cae5c51a5c21893cd64718df0f6011701d
Change-Id: Ib7ef58fd9c224c7febf75ef9bbaee7c03848dda5
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/54/527154/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.policy/oslo.policy.spec.j2'],1,90ab5230d93b807ceabea5fca12c2a25e712df5a,oslo-policy,{% set upstream_version = upstream_version('1.32.1') %},{% set upstream_version = upstream_version('1.32.0') %},1,1
openstack%2Fpuppet-ceph~stable%2Fjewel~I3de82d07b638a8b8a9a59f95b08aa4926e7891e2,openstack/puppet-ceph,stable/jewel,I3de82d07b638a8b8a9a59f95b08aa4926e7891e2,Jewel CI testing,ABANDONED,2017-12-13 16:15:58.000000000,2017-12-13 18:31:35.000000000,,[{'_account_id': 3153}],"[{'number': 1, 'created': '2017-12-13 16:15:58.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/8fb1e061fea6e54123b2fe6d36a5e0835443edd6', 'message': 'Jewel CI testing\n\nChange-Id: I3de82d07b638a8b8a9a59f95b08aa4926e7891e2\n'}]",0,527731,8fb1e061fea6e54123b2fe6d36a5e0835443edd6,3,1,1,3153,,,0,"Jewel CI testing

Change-Id: I3de82d07b638a8b8a9a59f95b08aa4926e7891e2
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/31/527731/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,8fb1e061fea6e54123b2fe6d36a5e0835443edd6,test,#,,1,0
openstack%2Fproject-config~master~I8dbc25c8a0de61ef72d53b58cf8aae3e91f41442,openstack/project-config,master,I8dbc25c8a0de61ef72d53b58cf8aae3e91f41442,Retire puppet-apps_site (3/3),MERGED,2017-12-10 19:41:39.000000000,2017-12-13 18:13:35.000000000,2017-12-13 18:13:35.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-10 19:41:39.000000000', 'files': ['zuul.d/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack-infra/puppet-apps_site.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7619bc6eeeab5016e7759ca938d7f889280a8cf5', 'message': 'Retire puppet-apps_site (3/3)\n\nMark repository as read-only.\n\nDepends-On: I802957611fccf66a6cd74cb7e9a35c74cc875a8c\nChange-Id: I8dbc25c8a0de61ef72d53b58cf8aae3e91f41442\n'}]",0,526945,7619bc6eeeab5016e7759ca938d7f889280a8cf5,8,3,1,6547,,,0,"Retire puppet-apps_site (3/3)

Mark repository as read-only.

Depends-On: I802957611fccf66a6cd74cb7e9a35c74cc875a8c
Change-Id: I8dbc25c8a0de61ef72d53b58cf8aae3e91f41442
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/526945/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul.d/projects.yaml', 'gerrit/acls/openstack-infra/puppet-apps_site.config']",3,7619bc6eeeab5016e7759ca938d7f889280a8cf5,infra-xenial,,"[access ""refs/heads/*""] abandon = group puppet-apps_site-core label-Code-Review = -2..+2 group puppet-apps_site-core label-Workflow = -1..+1 group puppet-apps_site-core [access ""refs/tags/*""] pushSignedTag = group puppet-apps_site-release [receive] requireChangeId = true [submit] mergeContent = true ",2,23
openstack%2Frequirements~master~I20950b32b73a528d57007451cd81dcc7efa3215b,openstack/requirements,master,I20950b32b73a528d57007451cd81dcc7efa3215b,Fix bindep.txt for xenial,MERGED,2017-12-13 14:23:11.000000000,2017-12-13 18:12:47.000000000,2017-12-13 18:12:47.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 14:23:11.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/44be84e89784d0874f31d2c961a8def6f05bd87d', 'message': ""Fix bindep.txt for xenial\n\nDue to a typo pkg-config wasn't installed, which caused\nthe propose-updates job to fail\n\nChange-Id: I20950b32b73a528d57007451cd81dcc7efa3215b\n""}]",0,527693,44be84e89784d0874f31d2c961a8def6f05bd87d,7,3,1,6593,,,0,"Fix bindep.txt for xenial

Due to a typo pkg-config wasn't installed, which caused
the propose-updates job to fail

Change-Id: I20950b32b73a528d57007451cd81dcc7efa3215b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/527693/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,44be84e89784d0874f31d2c961a8def6f05bd87d,,pkg-config [platform:dpkg],pkg-config [platform:dkpg],1,1
openstack%2Fkeystone~master~I3d41c022835bc43e5bf46d1d522dfcdcc0a8922e,openstack/keystone,master,I3d41c022835bc43e5bf46d1d522dfcdcc0a8922e,Remove extra parameter for token auth,MERGED,2017-12-11 08:55:01.000000000,2017-12-13 18:12:43.000000000,2017-12-13 18:12:43.000000000,"[{'_account_id': 5046}, {'_account_id': 15054}, {'_account_id': 16465}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 08:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/05fa8ee23893a26066caf6ac9f7616979de2acc8', 'message': 'Remove extra parameter for token auth\n\nThe /v3/auth/token API\'s response body doesn\'t contain\nextra at all.\nThis patch remove the ""extra"" from api-ref to avoid misleading.\n\nChange-Id: I3d41c022835bc43e5bf46d1d522dfcdcc0a8922e\n'}, {'number': 2, 'created': '2017-12-11 08:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8321efcb66a51db298814a36429fe108285e88b7', 'message': 'Remove extra parameter for token auth\n\nThe /v3/auth/token API\'s response body doesn\'t contain\nextra at all.\nThis patch remove the ""extra"" from api-ref to avoid misleading.\n\nChange-Id: I3d41c022835bc43e5bf46d1d522dfcdcc0a8922e\n'}, {'number': 3, 'created': '2017-12-11 09:08:57.000000000', 'files': ['api-ref/source/v3/samples/admin/auth-password-project-scoped-response.json', 'api-ref/source/v3/samples/admin/auth-token-unscoped-response.json', 'api-ref/source/v3/samples/admin/auth-password-unscoped-response.json', 'api-ref/source/v3/samples/admin/auth-password-explicit-unscoped-response.json', 'api-ref/source/v3/parameters.yaml', 'api-ref/source/v3/authenticate-v3.inc', 'api-ref/source/v3/samples/admin/auth-token-scoped-response.json'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3cc3986a89723c483ee55d6c383b54cb973336f2', 'message': 'Remove extra parameter for token auth\n\nThe /v3/auth/token API\'s response body doesn\'t contain\nextra at all.\nIt has been removed here: https://review.openstack.org/#/c/249480/\n\nThis patch remove the ""extra"" from api-ref to avoid misleading.\n\nChange-Id: I3d41c022835bc43e5bf46d1d522dfcdcc0a8922e\n'}]",2,527018,3cc3986a89723c483ee55d6c383b54cb973336f2,11,5,3,15054,,,0,"Remove extra parameter for token auth

The /v3/auth/token API's response body doesn't contain
extra at all.
It has been removed here: https://review.openstack.org/#/c/249480/

This patch remove the ""extra"" from api-ref to avoid misleading.

Change-Id: I3d41c022835bc43e5bf46d1d522dfcdcc0a8922e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/18/527018/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3/authenticate-v3.inc', 'api-ref/source/v3/parameters.yaml']",2,05fa8ee23893a26066caf6ac9f7616979de2acc8,remove_extra,,"extras: description: | A set of metadata key and value pairs, if any. in: body required: true type: object",0,10
openstack%2Fneutron~master~I436353690839281ca7e13eaf792249306b71dd4b,openstack/neutron,master,I436353690839281ca7e13eaf792249306b71dd4b,Honor both floating_ip_address and subnet_id when creating FIP,MERGED,2017-11-21 03:54:07.000000000,2017-12-13 18:12:40.000000000,2017-12-13 18:12:40.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 15309}, {'_account_id': 17776}, {'_account_id': 22348}, {'_account_id': 25564}, {'_account_id': 27366}]","[{'number': 1, 'created': '2017-11-21 03:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/96b3120fbff5b87ad4064c4f8a4bd0ac03f6f4ed', 'message': ""Add floating_ip_address and subnet_id while creating fip port\n\nIf user both specify floating-ip-address and subnet in CLI, we\nwill always chosen the subnet creating fip port.\n\nThis patch add floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address not in the subnet,\nwill raise InvalidIpForSubnet exception.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 2, 'created': '2017-11-21 10:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c84674f7b974299e71a9bc629fa3e75f6885b62a', 'message': ""Add floating_ip_address and subnet_id while creating fip port\n\nIf user specifies floating-ip-address and subnet, we\nwill always chose the subnet creating fip port.\n\nThis patch add floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 3, 'created': '2017-11-21 10:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d2f872ee9390887458410dd38ecb5dd8b43a7c2', 'message': ""Add floating_ip_address and subnet_id while creating fip port\n\nIf user specifies floating-ip-address and subnet, we\nwill always chose the subnet creating fip port.\n\nThis patch add floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 4, 'created': '2017-12-04 05:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e7dd7110f069cba55788f251aeea87bc5b2ed8d', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIf user specifies floating-ip-address and subnet, we\nwill always choose the subnet creating fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 5, 'created': '2017-12-05 06:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f747aeb6d103c402e6fd07311b17bd40beec29ef', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIf user specifies floating-ip-address and subnet, we\nwill always choose the subnet creating fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fix a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 6, 'created': '2017-12-07 01:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9203ba22cf98ae52d3444b507a8462399d2ccfd', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIn the current code, if user specifies floating-ip-address\nand subnet, we only process the subnet when creating\nthe fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fixs a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 7, 'created': '2017-12-12 01:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5f0ac99441e0ed51ccd00224afb910e755bfb36', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIn the current code, if user specifies floating-ip-address\nand subnet, we only process the subnet when creating\nthe fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fixes a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 8, 'created': '2017-12-12 05:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f94d4b9461d5366d4339fbfa6e7ed4b67a7fe53b', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIn the current code, if user specifies floating-ip-address\nand subnet, we only process the subnet when creating\nthe fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fixes a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 9, 'created': '2017-12-12 11:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db84a182e002f8fd8486b3c7bf7db5b34589e7c6', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIn the current code, if user specifies floating-ip-address\nand subnet, we only process the subnet when creating\nthe fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fixes a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 10, 'created': '2017-12-13 05:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ac3c8aedc682646131da9744e7f52cd6ea84bf3', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIn the current code, if user specifies floating-ip-address\nand subnet, we only process the subnet when creating\nthe fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fixes a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}, {'number': 11, 'created': '2017-12-13 09:27:20.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py', 'neutron/tests/functional/services/l3_router/test_l3_dvr_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/088e317cd2dd8488feb29a4fa6600227d1810479', 'message': ""Honor both floating_ip_address and subnet_id when creating FIP\n\nIn the current code, if user specifies floating-ip-address\nand subnet, we only process the subnet when creating\nthe fip port.\n\nThis patch adds floating_ip_address and subnet_id to\nfip port's fixed_ips, if floating_ip_address is not in the subnet,\nInvalidIpForSubnet exception will be raised.\n\nThis patch also fixes a default value error in tests.\n\nChange-Id: I436353690839281ca7e13eaf792249306b71dd4b\nCloses-Bug: #1732890\n""}]",56,521707,088e317cd2dd8488feb29a4fa6600227d1810479,97,14,11,12860,,,0,"Honor both floating_ip_address and subnet_id when creating FIP

In the current code, if user specifies floating-ip-address
and subnet, we only process the subnet when creating
the fip port.

This patch adds floating_ip_address and subnet_id to
fip port's fixed_ips, if floating_ip_address is not in the subnet,
InvalidIpForSubnet exception will be raised.

This patch also fixes a default value error in tests.

Change-Id: I436353690839281ca7e13eaf792249306b71dd4b
Closes-Bug: #1732890
",git fetch https://review.opendev.org/openstack/neutron refs/changes/07/521707/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,96b3120fbff5b87ad4064c4f8a4bd0ac03f6f4ed,bug/1732890," if fip.get('subnet_id') and fip.get('floating_ip_address'): port['fixed_ips'] = [ {'ip_address': fip['floating_ip_address'], 'subnet_id': fip['subnet_id']}] elif fip.get('floating_ip_address'): elif fip.get('subnet_id'):", if fip.get('floating_ip_address'): if fip.get('subnet_id'):,35,2
openstack%2Fopenstack-zuul-jobs~master~Ic251346f3a2ec51e49ca07417e9ba84ec1d3a4af,openstack/openstack-zuul-jobs,master,Ic251346f3a2ec51e49ca07417e9ba84ec1d3a4af,base/multinode rename #3: Remove old jobs,MERGED,2017-12-07 22:56:06.000000000,2017-12-13 18:09:57.000000000,2017-12-13 18:09:57.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 22:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/5d1712156c7a81bc4db1bcd7c93aa8ddc283d20e', 'message': ""base/multinode rename #3: Remove old jobs\n\nWe want to rename the base and multinode integration jobs in order\nto make sure they are not mistaken by users trying to test their\nprojects. These jobs are not meant to be used outside of integration\ntesting the playbooks and roles found in project-config, zuul-jobs and\nopenstack-zuul-jobs.\n\nThis is part one of three in renaming the base and multinode\nintegration jobs. We need to:\n1) Add new jobs in openstack-zuul-jobs\n2) Make project-config use the new job names\n3) Remove old jobs                            <-- We're here\n\nDepends-On: I4ef44e64a03cc3089e02343de506e0a6fd85a55c\nChange-Id: Ic251346f3a2ec51e49ca07417e9ba84ec1d3a4af\n""}, {'number': 2, 'created': '2017-12-07 23:06:16.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ab9a91dcdefcb73fe73e07c8ea5a53b10e865086', 'message': ""base/multinode rename #3: Remove old jobs\n\nWe want to rename the base and multinode integration jobs in order\nto make sure they are not mistaken by users trying to test their\nprojects. These jobs are not meant to be used outside of integration\ntesting the playbooks and roles found in project-config, zuul-jobs and\nopenstack-zuul-jobs.\n\nThis is part three of three in renaming the base and multinode\nintegration jobs. We need to:\n1) Add new jobs in openstack-zuul-jobs\n2) Make project-config use the new job names\n3) Remove old jobs                            <-- We're here\n\nDepends-On: I4ef44e64a03cc3089e02343de506e0a6fd85a55c\nChange-Id: Ic251346f3a2ec51e49ca07417e9ba84ec1d3a4af\n""}]",0,526536,ab9a91dcdefcb73fe73e07c8ea5a53b10e865086,13,3,2,9061,,,0,"base/multinode rename #3: Remove old jobs

We want to rename the base and multinode integration jobs in order
to make sure they are not mistaken by users trying to test their
projects. These jobs are not meant to be used outside of integration
testing the playbooks and roles found in project-config, zuul-jobs and
openstack-zuul-jobs.

This is part three of three in renaming the base and multinode
integration jobs. We need to:
1) Add new jobs in openstack-zuul-jobs
2) Make project-config use the new job names
3) Remove old jobs                            <-- We're here

Depends-On: I4ef44e64a03cc3089e02343de506e0a6fd85a55c
Change-Id: Ic251346f3a2ec51e49ca07417e9ba84ec1d3a4af
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/36/526536/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,5d1712156c7a81bc4db1bcd7c93aa8ddc283d20e,base-rename,, name: base-integration description: | Runs roles that are included by default in the 'base' job in order to prevent regressions. parent: base-minimal required-projects: - openstack-infra/project-config roles: - zuul: openstack-infra/zuul-jobs run: tests/base.yaml files: - ^roles/configure-mirror/.* - ^roles/configure-unbound/.* - ^roles/emit-job-header/.* - ^roles/fetch-zuul-cloner/.* - ^roles/mirror-info/.* - ^roles/set-zuul-log-path-fact/.* - ^roles/use-cached-repos/.* - ^tests/.* - job: name: base-integration-centos-7 parent: base-integration nodeset: centos-7 - job: name: base-integration-debian-jessie parent: base-integration nodeset: debian-jessie - job: name: base-integration-fedora-26 parent: base-integration nodeset: fedora-26 - job: name: base-integration-opensuse423 parent: base-integration nodeset: opensuse-423 - job: name: base-integration-ubuntu-trusty parent: base-integration nodeset: ubuntu-trusty - job: name: base-integration-ubuntu-xenial parent: base-integration nodeset: ubuntu-xenial - job: name: multinode-integration description: | Runs roles that are included by default in the 'multinode' job in order to prevent regressions. parent: base-minimal vars: ara_generate_html: true required-projects: - openstack-infra/project-config roles: - zuul: openstack-infra/zuul-jobs run: tests/multinode.yaml files: - ^roles/configure-mirror/.* - ^roles/configure-unbound/.* - ^roles/emit-job-header/.* - ^roles/fetch-zuul-cloner/.* - ^roles/mirror-info/.* - ^roles/set-zuul-log-path-fact/.* - ^roles/use-cached-repos/.* - ^roles/multi-node-bridge/.* - ^roles/multi-node-firewall/.* - ^roles/multi-node-hosts-file/.* - ^roles/multi-node-known-hosts/.* - ^tests/.* - job: name: multinode-integration-centos-7 parent: multinode-integration nodeset: nodes: - name: primary label: centos-7 - name: secondary label: centos-7 groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: multinode-integration-debian-jessie parent: multinode-integration nodeset: nodes: - name: primary label: debian-jessie - name: secondary label: debian-jessie groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: multinode-integration-fedora-26 parent: multinode-integration nodeset: nodes: - name: primary label: fedora-26 - name: secondary label: fedora-26 groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: multinode-integration-opensuse423 parent: multinode-integration nodeset: nodes: - name: primary label: opensuse-423 - name: secondary label: opensuse-423 groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: multinode-integration-ubuntu-trusty parent: multinode-integration nodeset: nodes: - name: primary label: ubuntu-trusty - name: secondary label: ubuntu-trusty groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: multinode-integration-ubuntu-xenial parent: multinode-integration nodeset: nodes: - name: primary label: ubuntu-xenial - name: secondary label: ubuntu-xenial groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job:,0,180
openstack%2Foctavia-dashboard~master~Iaa40cb8cc4cbcc92a3f3252f808c66a30c8f41b3,openstack/octavia-dashboard,master,Iaa40cb8cc4cbcc92a3f3252f808c66a30c8f41b3,Imported Translations from Zanata,MERGED,2017-12-06 06:54:25.000000000,2017-12-13 18:08:15.000000000,2017-12-13 18:08:15.000000000,"[{'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 06:54:25.000000000', 'files': ['octavia_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'octavia_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/8ff16bdd9a21dd38db7865e8d9f6385661b234d9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iaa40cb8cc4cbcc92a3f3252f808c66a30c8f41b3\n'}]",0,525908,8ff16bdd9a21dd38db7865e8d9f6385661b234d9,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iaa40cb8cc4cbcc92a3f3252f808c66a30c8f41b3
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/08/525908/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'octavia_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po']",2,8ff16bdd9a21dd38db7865e8d9f6385661b234d9,zanata/translations,"# Ian Y. Choi <ianyrchoi@gmail.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: octavia-dashboard 1.0.0.0b2.dev18\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2017-11-27 23:15+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-12-06 12:29+0000\n"" ""Last-Translator: Ian Y. Choi <ianyrchoi@gmail.com>\n"" ""Language-Team: Korean (South Korea)\n"" ""Language: ko-KR\n"" ""X-Generator: Zanata 3.9.6\n"" ""Plural-Forms: nplurals=1; plural=0\n"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""%(ip)s..."" msgstr ""%(ip)s..."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Expected status codes:</strong>\n"" "" The expected HTTP status codes to get from a successful health check. Must "" ""be a single number,\n"" "" a comma separated list of numbers, or a range (two numbers separated by a "" ""hyphen)."" msgstr """" ""<strong>예상 상태 코드:</strong>\n"" "" 상태 체크가 성공했을 때 수신하게 되는 HTTP 상태 코드입니다. 단일 숫자이어"" ""야 하고,\n"" "" 쉼표로 구분된 숫자 리스트이거나 두 개의 숫자가 하이픈으로 구별된 범주이어"" ""야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>HTTP method:</strong>\n"" "" The HTTP method used to perform the health check."" msgstr """" ""<strong>HTTP 메소드:</strong>\n"" "" 상태 체크를 수행하기 위한 HTTP 메소드."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>IP address:</strong>\n"" "" If an IP address is provided it must be a well-formed IPv4 or IPv6 "" ""address. The system will\n"" "" attempt to assign the provided IP address to the load balancer. If an IP "" ""address is not provided\n"" "" then one will be allocated for you."" msgstr """" ""<strong>IP 주소:</strong>\n"" "" IP 주소가 제공된 경우 올바른 형식의 IPv4나 IPv6 주소여야 합니다. 시스템은\n"" "" 제공된 IP 주소를 로드 밸런서에게 할당하려고 시도합니다. 만약 IP 주소가 제공"" ""되지 않으면\n"" "" 하나가 할당될 것입니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>IP address:</strong>\n"" "" The IP address of the member to receive traffic from the load balancer. "" ""Must be a well-formed\n"" "" IPv4 or IPv6 address."" msgstr """" ""<strong>IP 주소:</strong>\n"" "" 로드 밸런서에서 트래픽을 받는 멤버의 IP 주소입니다. 양식에 맞는 \n"" "" IPv4나 IPv6 주소이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Interval:</strong>\n"" "" The interval between health checks. Must be greater than or equal to the "" ""timeout."" msgstr """" ""<strong>간격:</strong>\n"" "" 상태 체크 사이의 간격. 타임아웃 이상이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Method:</strong>\n"" "" The load balancer algorithm that distributes traffic to the pool members.\n"" "" <ul>\n"" "" <li>\n"" "" LEAST_CONNECTIONS: Allocates requests to the instance with the least "" ""number of active\n"" "" connections.\n"" "" </li>\n"" "" <li>\n"" "" ROUND_ROBIN: Rotates requests evenly between multiple instances.\n"" "" </li>\n"" "" <li>\n"" "" SOURCE_IP: Requests from a unique source IP address are consistently "" ""directed to the same instance.\n"" "" </li>\n"" "" </ul>"" msgstr """" ""<strong>메소드:</strong>\n"" "" 풀 멤버에게 트래픽을 분배시키는 로드 밸런서 알고리즘.\n"" "" <ul>\n"" "" <li>\n"" "" LEAST_CONNECTIONS: 활성화된 연결 개수가 가장 적은 인스턴스에게 요청내역"" ""을 할당.\n"" "" </li>\n"" "" <li>\n"" "" ROUND_ROBIN: 여러 인스턴스에게 요청 내역을 균등하게 배분합니다.\n"" "" </li>\n"" "" <li>\n"" "" SOURCE_IP: 특정 출발지 IP에서의 요청은 동일한 인스턴스에게 배분되도록 "" ""유지됩니다.\n"" "" </li>\n"" "" </ul>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Port:</strong>\n"" "" The port on which the front end listens. Must be an integer from 1 to "" ""65535."" msgstr """" ""<strong>포트:</strong>\n"" "" 프런트 엔드에서 listen하는 포트. 1에서 65535 사이의 정수여야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Port:</strong>\n"" "" The port on which the member listens for traffic. Must be a number from 1 "" ""to 65535."" msgstr """" ""<strong>포트:</strong>\n"" "" 트래픽을 수신하는 멤버의 포트 번호입니다. 포트 번호는 1 ~ 65535 사이 숫자이"" ""어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Protocol:</strong>\n"" "" The protocol for which the front end listens. The TERMINATED_HTTPS "" ""protocol is only available if\n"" "" the key-manager service is enabled and you have authority to list "" ""certificate containers and\n"" "" secrets."" msgstr """" ""<strong>프로토콜:</strong>\n"" "" 프런트 엔드에서 수신하는 프로토콜. TERMINATED_HTTPS 프로토콜은\n"" "" key-manager 서비스가 활성화되고 인증서 컨테이너와 비밀을 리스트할 수 있"" ""는 \n"" "" 권한이 있어야 이용이 가능합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Retries:</strong>\n"" "" The number of allowed connection failures before marking the member as "" ""inactive. Must be a\n"" "" number from 1 to 10."" msgstr """" ""<strong>재시도: </strong>\n"" "" 재시도 횟수를 초과하여 연결이 실패하면 멤버는 비활성화 되고, 재시도 횟수"" ""는\n"" "" 1에서 10까지의 숫자이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Subnet:</strong>\n"" "" The network on which to allocate the load balancer's IP address."" msgstr """" ""<strong>서브넷:</strong>\n"" "" 로드 밸런서의 IP 주소를 할당하는 네트워크"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Subnet:</strong>\n"" "" The network which contains the IP address of the member."" msgstr """" ""<strong>서브넷:</strong>\n"" "" 멤버의 IP 주소를 포함하고 있는 네트워크입니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Timeout:</strong>\n"" "" The time after which a health check times out. Must be a number greater "" ""than or equal to 0\n"" "" and less than or equal to the interval."" msgstr """" ""<strong>타임아웃:</strong>\n"" "" 상태 체크 시간이 종료되는 시간. 0 이상의 숫자이어야 하고\n"" "" 타임아웃 값은 상태 체크 간격 이하이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>URL path:</strong>\n"" "" The target of the health check HTTP request to the member. Must be a valid "" ""URL path."" msgstr """" ""<strong>URL 경로:</strong>\n"" "" 상태 체크하기 위해 멤버에게 HTTP 요청하는 대상. 유효한 URL 경로이어야 합니"" ""다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""<strong>Weight:</strong>\n"" "" The weight of a member determines the portion of requests or connections "" ""it services compared\n"" "" to the other members of the pool. A higher weight means it will receive "" ""more traffic. Must be\n"" "" a number from 1 to 256."" msgstr """" ""<strong>가중치:</strong>\n"" "" 멤버의 가중치는 풀의 다른 멤버와 비교하여 요청이나 연결의\n"" "" 양을 결정합니다. 가중치가 높을수록 더 많은 트래픽을 받게 됩니다.\n"" "" 가중치는 숫자 1과 256사이여야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""A new health monitor is being created."" msgstr ""새로운 상태 모니터가 생성되고 있습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""A new listener is being created."" msgstr ""새로운 리스너를 생성하고 있습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""A new load balancer is being created."" msgstr ""새로운 로드 밸런서를 생성하고 있습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""A new pool is being created."" msgstr ""새로운 풀이 생성되고 있습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""A pool represents a group of members over which the load balancing will be "" ""applied."" msgstr ""풀은 로드 밸런싱이 적용되는 멤버의 그룹을 나타냅니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Actions"" msgstr ""작업"" # auto translated by TM merge from project: murano-dashboard, version: master, DocId: muranodashboard/locale/django msgid ""Active"" msgstr ""활성"" # auto translated by TM merge from project: horizon, version: master, DocId: horizon/locale/djangojs msgid ""Add"" msgstr ""추가"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Add external member"" msgstr ""외부 멤버 추가"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Add members to the load balancer pool."" msgstr ""로드 밸런서 풀에 멤버를 추가합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Add/Remove Pool Members"" msgstr ""풀 맴버 추가/삭제"" # auto translated by TM merge from project: searchlight-ui, version: stable-ocata, DocId: searchlight_ui/locale/djangojs msgid ""Address"" msgstr ""주소"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Admin State Up"" msgstr ""관리자 업 상태"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Allocated Members"" msgstr ""할당된 멤버"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""An error occurred. Please try again later."" msgstr ""오류가 발생했습니다. 나중에 다시 시도하십시오."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Associate"" msgstr ""연결"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Associate Floating IP"" msgstr ""Floating IP 연결"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Associate Floating IP Address"" msgstr ""Floating IP 주소와 연결"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Associating floating IP with load balancer."" msgstr ""Floating IP와 로드 밸런서 연결"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Available Instances"" msgstr ""사용 가능한 인스턴스"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Back"" msgstr ""뒤로"" # auto translated by TM merge from project: magnum-ui, version: master, DocId: magnum_ui/locale/djangojs msgid ""Cancel"" msgstr ""취소"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Certificate Name"" msgstr ""인증서 이름"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Confirm Delete Health Monitor"" msgstr ""상태 모니터 삭제 확인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Confirm Delete Listeners"" msgstr ""리스너 삭제 확인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Confirm Delete Load Balancers"" msgstr ""로드 밸런서 삭제 확인"" msgid ""Confirm Delete Member"" msgstr ""멤버 삭제 확인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Confirm Delete Pool"" msgstr ""풀 삭제 확인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Confirm Disassociate Floating IP Address"" msgstr ""Floating IP 주소 연결 해제 확인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Connection Limit"" msgstr ""연결 제한"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Create Health Monitor"" msgstr ""상태 모니터 생성"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Create Listener"" msgstr ""리스너 생성"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Create Load Balancer"" msgstr ""로드 밸런서 생성"" # auto translated by TM merge from project: zaqar-ui, version: stable-ocata, DocId: zaqar_ui/locale/djangojs msgid ""Create Pool"" msgstr ""풀 생성"" # auto translated by TM merge from project: manila-ui, version: master, DocId: manila_ui/locale/django msgid ""Created At"" msgstr ""생성 시점"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Default Pool ID"" msgstr ""기본 풀 ID"" # auto translated by TM merge from project: horizon, version: master, DocId: openstack_dashboard/locale/djangojs msgid ""Degraded"" msgstr ""감소됨"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delay"" msgstr ""지연"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delete Health Monitor"" msgstr ""상태 모니터 삭제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delete Listener"" msgstr ""리스너 삭제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delete Listeners"" msgstr ""리스너 삭제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delete Load Balancer"" msgstr ""로드 밸런서 삭제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delete Load Balancers"" msgstr ""로드 밸런서 삭제"" msgid ""Delete Member"" msgstr ""멤버 삭제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Delete Pool"" msgstr ""풀 삭제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Deleted health monitor: %s."" msgstr ""상태 모니터 %s를 삭제하였습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Deleted listeners: %s."" msgstr ""삭제된 리스너 : %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Deleted load balancers: %s."" msgstr ""삭제된 로드 밸런서: %s."" #, python-format msgid ""Deleted member: %s."" msgstr ""삭제된 멤버: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Deleted pool: %s."" msgstr ""삭제된 풀: %s."" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Description"" msgstr ""설명"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Disassociate"" msgstr ""연결 해제"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Disassociate Floating IP"" msgstr ""Floating IP 연결 해제"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Disassociated floating IP address from load balancer: %s."" msgstr ""로드 밸런서에서 Floating IP 주소가 연결 해제됨 : %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Each port that listens for traffic on a particular load balancer is "" ""configured separately and\n"" "" tied to the load balancer. Multiple listeners can be associated with the "" ""same load balancer but\n"" "" each must use a unique port."" msgstr """" ""특정 로드 밸런서의 트래픽을 수신하는 리스너의 각 포트는 별도로 설정되고\n"" "" 로드 밸런서에 연결됩니다. 여러 리스너는 동일한 로드 밸런서에 연결될 수 있지"" ""만\n"" "" 각각 유일한 포트를 사용해야 합니다."" # auto translated by TM merge from project: openstack-user-survey, version: openstack-user-survey, DocId: survey_ui msgid ""Edit"" msgstr ""편집"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Error"" msgstr ""에러"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Expected Codes"" msgstr ""예상 코드"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Expected status codes"" msgstr ""예상된 상태 코드"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Expiration Date"" msgstr ""만기 일자"" # auto translated by TM merge from project: searchlight-ui, version: master, DocId: searchlight_ui/locale/djangojs msgid ""Floating IP Address"" msgstr ""Floating IP 주소"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Floating IP address or pool\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""Floating IP 주소 또는 풀\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: openstack-manuals, version: stable-ocata, DocId: doc/networking-guide/source/locale/networking-guide msgid ""Floating IP addresses"" msgstr ""Floating IP 주소"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Floating IP pools"" msgstr ""Floating IP 풀"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""HTTP Method"" msgstr ""HTTP 메서드"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""HTTP method"" msgstr ""HTTP 메소드"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Health Monitor ID"" msgstr ""상태 모니터 ID"" # auto translated by TM merge from project: zaqar-ui, version: master, DocId: zaqar_ui/locale/djangojs msgid ""ID"" msgstr ""ID"" # auto translated by TM merge from project: tripleo-ui, version: master, DocId: i18n/messages msgid ""IP Address"" msgstr ""IP 주소"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""IP Address\n"" "" <span class=\""hz-icon-required fa fa-asterisk\"" ng-show=\""ctrl."" ""tableData.displayedAllocated.length > 0\"">\n"" "" </span>\n"" "" \n"" "" Subnet\n"" "" <span class=\""hz-icon-required fa fa-asterisk\"" ng-show=\""ctrl."" ""tableData.displayedAllocated.length > 0\"">\n"" "" </span>\n"" "" <th class=\""rsp-p1\"">\n"" "" Port\n"" "" <span class=\""hz-icon-required fa fa-asterisk\"" ng-show=\""ctrl."" ""tableData.displayedAllocated.length > 0\"">\n"" "" </span>\n"" "" Weight</th>\n"" "" <th class=\""actions_column\""></th>"" msgstr """" ""IP 주소\n"" "" <span class=\""hz-icon-required fa fa-asterisk\"" ng-show=\""ctrl."" ""tableData.displayedAllocated.length > 0\"">\n"" "" </span>\n"" "" \n"" "" 서브넷\n"" "" <span class=\""hz-icon-required fa fa-asterisk\"" ng-show=\""ctrl."" ""tableData.displayedAllocated.length > 0\"">\n"" "" </span>\n"" "" <th class=\""rsp-p1\"">\n"" "" 포트\n"" "" <span class=\""hz-icon-required fa fa-asterisk\"" ng-show=\""ctrl."" ""tableData.displayedAllocated.length > 0\"">\n"" "" </span>\n"" "" 가중치</th>\n"" "" <th class=\""actions_column\""></th>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""IP Addresses (%(count)s)"" msgstr ""IP 주소 (%(count)s)"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""IP address"" msgstr ""IP 주소"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""If the listener uses the TERMINATED_HTTPS protocol, then one or more SSL "" ""certificates must\n"" "" be selected. The first certificate will be the default."" msgstr """" ""만약 리스너가 TERMINATED_HTTPS 프로토콜을 사용한다면, 하나 이상의 SSL 인증서"" ""가 \n"" ""선택되어야 합니다. 첫 인증서는 기본값이 됩니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Inactive"" msgstr ""비활성"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Interval (sec)\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""간격 (초)\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Least Connections"" msgstr ""최소 연결"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Listener %(index)s"" msgstr ""리스너 %(index)s"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Listener 1"" msgstr ""리스너 1"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Listener Details"" msgstr ""리스너 세부정보"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Listener ID"" msgstr ""리스너 ID"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Listeners"" msgstr ""리스너"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Load Balancer %(index)s"" msgstr ""로드 밸런서 %(index)s"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Load Balancer Algorithm"" msgstr ""로드 밸런서 알고리즘"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Load Balancer Details"" msgstr ""로드 밸런서 세부정보"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Load Balancer ID"" msgstr ""로드 밸런서 ID"" # auto translated by TM merge from project: octavia-dashboard, version: master, DocId: octavia_dashboard/locale/django msgid ""Load Balancers"" msgstr ""로드 밸런서"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Loading"" msgstr ""불러오는 중"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Max Retries"" msgstr ""최대 재시도"" msgid ""Max Retries Down"" msgstr ""최대 재시도 다운"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Member ID"" msgstr ""맴버 ID"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Members"" msgstr ""멤버"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Members are the actual IP addresses that will receive traffic from the load "" ""balancer. Each\n"" "" member must have a unique combination of IP address and port."" msgstr """" ""멤버는 로드 밸런서에서 트래픽을 받게 되는 실제 IP 주소입니다.\n"" "" 각 멤버는 유일한 IP 주소와 포트의 조합을 가지고 있어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Method\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""메소드\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgid ""Monitor Address"" msgstr ""모니터 주소"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Monitor Details"" msgstr ""모니터 세부 정보"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Monitor ID"" msgstr ""모니터 ID"" msgid ""Monitor Port"" msgstr ""모니터 포트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Monitor type\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""모니터 타입\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Name"" msgstr ""이름"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""No available certificates"" msgstr ""이용 가능한 인증서가 없음"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""No available instances"" msgstr ""사용 가능한 인스턴스가 없음"" # auto translated by TM merge from project: horizon, version: master, DocId: openstack_dashboard/locale/djangojs msgid ""No items to display."" msgstr ""표시할 항목이 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""No members have been allocated"" msgstr ""할당된 멤버가 없음"" # auto translated by TM merge from project: horizon, version: master, DocId: openstack_dashboard/locale/djangojs msgid ""None"" msgstr ""없음"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Offline"" msgstr ""오프라인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Online"" msgstr ""온라인"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Operating Status"" msgstr ""운영 상태"" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Overview"" msgstr ""개요"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Pending Create"" msgstr ""생성 대기중"" # auto translated by TM merge from project: horizon, version: master-old-keepforstatistics, DocId: openstack_dashboard/locale/djangojs msgid ""Pending Delete"" msgstr ""삭제 대기중"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Pending Update"" msgstr ""업데이트 대기중"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Pool 1"" msgstr ""풀 1"" # auto translated by TM merge from project: horizon, version: stable-mitaka, DocId: openstack_dashboard/locale/django msgid ""Pool Details"" msgstr ""풀 세부 정보"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Pool ID"" msgstr ""풀 ID"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Pool Members"" msgstr ""풀 맴버"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Port"" msgstr ""포트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Port\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""포트\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Port ID"" msgstr ""포트 ID"" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Project ID"" msgstr ""프로젝트 ID"" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Protocol"" msgstr ""프로토콜"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Protocol\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""프로토콜\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Protocol Port"" msgstr ""프로토콜 포트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Provide the details for the health monitor."" msgstr ""상태 모니터의 세부 사항을 제공하십시오."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Provide the details for the listener."" msgstr ""리스너에 대한 자세한 정보를 제공하십시오."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Provide the details for the load balancer."" msgstr ""로드 밸런서에 대한 자세한 정보를 제공하십시오."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Provide the details for the pool."" msgstr ""풀에 대한 세부 사항을 제공하십시오."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Provider"" msgstr ""프로바이더"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Provisioning Status"" msgstr ""프로비저닝 상태"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Remove"" msgstr ""제거"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Retries\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""재시도\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Round Robin"" msgstr ""라운드 로빈"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""SSL Certificates"" msgstr ""SSL 인증서"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Select a floating IP address to associate with the load balancer or a "" ""floating IP pool in which to allocate a new floating IP address."" msgstr """" ""로드밸런서나 Floating IP 풀과 연결하기 위하여 Floating IP 주소를 선택합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Select certificates from the available certificates below"" msgstr ""아래의 이용 가능한 인증서 중에서 선택"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Select one or more SSL certificates for the listener."" msgstr ""리스너에 대한 하나 이상의 SSL 인증서를 선택하십시오."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Session Persistence"" msgstr ""세션 지속성"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Source IP"" msgstr ""소스 IP"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Subnet\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""서브넷\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Subnet ID"" msgstr ""서브넷 ID"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""The Available Instances table contains existing compute instances that can "" ""be added as members\n"" "" of the pool. Use the \""Add external member\"" button to add a member not "" ""found in the Available\n"" "" Instances table."" msgstr """" ""사용 가능한 인스턴스 테이블에는 풀의 멤버로 추가될 수 있고 존재하는 컴퓨트 인"" ""스턴스가 \n"" "" 포함되어 있습니다. 사용 가능한 인스턴스 테이블에 없는 멤버를 추가하기 위하"" ""여 \n"" "" \""외부 멤버 추가\"" 버튼을 사용하시오"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The IP address is not valid."" msgstr ""IP 주소가 유효하지 않습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The URL path is not valid."" msgstr ""URL 경로가 유효하지 않습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The expected status code is not valid."" msgstr ""예상된 상태 코드가 유효하지 않습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""The following health monitor could not be deleted: %s."" msgstr ""다음 상태 모니터는 삭제할 수 없습니다: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""The following listeners could not be deleted, possibly due to existing "" ""pools: %s."" msgstr ""기존 풀 미삭제 등의 이유로 다음 리스너는 삭제할 수 없습니다: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""The following listeners will not be deleted due to existing pools: %s."" msgstr ""다음 리스너는 기존 풀 때문에 삭제되지 않습니다: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""The following load balancers are pending and cannot be deleted: %s."" msgstr ""다음 로드 밸런서는 보류 중이며 삭제할 수 없습니다: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""The following load balancers could not be deleted, possibly due to existing "" ""listeners: %s."" msgstr """" ""기존 리스너가 존재하는 등의 이유로 다음 로드 밸런서는 삭제될 수 없습니다: %s."" #, python-format msgid ""The following member could not be deleted: %s."" msgstr ""다음 멤버는 삭제할 수 없습니다: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""The following pool could not be deleted: %s."" msgstr ""다음 풀은 삭제할 수 없습니다: %s."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The health check interval must be greater than or equal to the timeout."" msgstr ""상태 체크 간격은 타임아웃 값 이상이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The health monitor has been updated."" msgstr ""상태 모니터가 업데이트 되었습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""The health monitor is used to determine the health of your pool members. "" ""Health checks\n"" "" routinely run against each member within the pool and the result of the "" ""health check is used\n"" "" to determine if the member receives new connections. Each pool can only "" ""have one health\n"" "" monitor."" msgstr """" ""상태 모니터는 풀 멤버의 상태를 결정하는 데 사용됩니다. 상태 체크는\n"" "" 풀 내의 각 멤버에 대해 주기적으로 실행하고, 상태 체크 결과로 \n"" "" 멤버가 새 연결을 받을 수 있는지를 결정합니다. 각 풀은 하나의 상태 모니터"" ""만 \n"" "" 가질 수 있습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The listener has been updated."" msgstr ""리스너가 업데이트 되었습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The load balancer has been updated."" msgstr ""로드 밸런서가 업데이트 되었습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""The load balancer occupies a neutron network port and has an IP address "" ""assigned from a subnet."" msgstr """" ""로드 밸런서는 뉴트론 네트워크 포트를 사용하고 서브넷에서 할당된 IP를 가집니"" ""다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The max retry count must be a number between 1 and 10."" msgstr ""최대 재시도 횟수는 1 ~ 10 사이입니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The pool has been updated."" msgstr ""풀이 업데이트 되었습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The pool members have been updated."" msgstr ""풀 멤버가 업데이트 되었습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The port must be a number between 1 and 65535."" msgstr ""포트 번호는 1 ~ 65535 사이 숫자이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""The port must be unique among all listeners attached to this load balancer."" msgstr ""이 로드 밸런서에 연결되는 모든 리스너에서 포트는 유일해야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The timeout must be a number greater than or equal to 0."" msgstr ""타임아웃 시간은 0 이상이어야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""The weight must be a number between 1 and 256."" msgstr ""가중치는 반드시 숫자 1과 256사이여야 합니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Timeout"" msgstr ""제한시간"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Timeout (sec)\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""타임아웃 (초)\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Type"" msgstr ""유형"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""URL Path"" msgstr ""URL 경로"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""URL path"" msgstr ""URL 경로"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to create health monitor."" msgstr ""상태 모니터를 생성할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to create listener."" msgstr ""리스너를 생성할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to create load balancer."" msgstr ""로드 밸런서를 생성할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to create pool."" msgstr ""풀을 생성할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to delete health monitor."" msgstr ""상태 모니터를 삭제할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to delete listener."" msgstr ""리스너를 삭제할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to delete load balancer."" msgstr ""로드 밸런서를 삭제할 수 없습니다."" msgid ""Unable to delete member."" msgstr ""멤버를 삭제할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to delete pool."" msgstr ""풀을 삭제할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid ""Unable to disassociate floating IP address from load balancer: %s."" msgstr ""다음 로드 밸런서에서 Floating IP를 연결 해제 할 수 없습니다: %s"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve SSL certificates."" msgstr ""SSL 인증을 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve health monitor."" msgstr ""상태 모니터를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve listener."" msgstr ""리스너를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve listeners."" msgstr ""리스너를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve load balancer."" msgstr ""로드 밸런서를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve load balancers."" msgstr ""로드 밸런서를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve member."" msgstr ""멤버를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve members."" msgstr ""멤버를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve pool."" msgstr ""풀을 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to retrieve secrets."" msgstr ""비밀키를 가져올 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to update health monitor."" msgstr ""상태 모니터를 업데이트할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to update listener."" msgstr ""리스너를 업데이트할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to update load balancer."" msgstr ""로드 밸런서를 업데이트할 수 없습니다. "" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to update member list."" msgstr ""멤버 목록을 업데이트할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to update member."" msgstr ""멤버를 업데이트할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Unable to update pool."" msgstr ""풀을 업데이트할 수 없습니다."" # auto translated by TM merge from project: zun-ui, version: master, DocId: zun_ui/locale/djangojs msgid ""Update"" msgstr ""업데이트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Update Health Monitor"" msgstr ""상태 모니터 업데이트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Update Listener"" msgstr ""리스너 업데이트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid ""Update Load Balancer"" msgstr ""로드 밸런서 업데이트"" # auto translated by TM merge from project: zaqar-ui, version: stable-ocata, DocId: zaqar_ui/locale/djangojs msgid ""Update Pool"" msgstr ""풀 업데이트"" # auto translated by TM merge from project: manila-ui, version: master, DocId: manila_ui/locale/django msgid ""Updated At"" msgstr ""업데이트"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Use the key-manager service to create any certificate containers before "" ""creating the listener.\n"" "" The following documentation provides information on how to create a "" ""certificate container:\n"" "" <ul>\n"" "" <li>\n"" "" <a target=\""_blank\"" href=\""http://developer.openstack.org/api-guide/"" ""key-manager/containers.html#certificate-containers\"">\n"" "" Key Manager API Guide: Creating a Certificate Container\n"" "" </a>\n"" "" </li>\n"" "" <li>\n"" "" <a target=\""_blank\"" href=\""http://docs.openstack.org/cli-reference/"" ""barbican.html\"">\n"" "" Key Manager Service Command-Line Client\n"" "" </a>\n"" "" </li>\n"" "" </ul>"" msgstr """" ""리스너를 생성하기 전에 인증서 컨테이너를 만들기 위하여 키 관리자 서비스를 사"" ""용하시오. \n"" "" 다음 문서에서는 인증서 컨테이너를 만드는 방법에 대한 정보를 제공합니다.\n"" "" <ul>\n"" "" <li>\n"" "" <a target=\""_blank\"" href=\""http://developer.openstack.org/api-guide/"" ""key-manager/containers.html#certificate-containers\"">\n"" "" 키 관리자 API 가이드: 인증서 컨테이너 생성하기\n"" "" </a>\n"" "" </li>\n"" "" <li>\n"" "" <a target=\""_blank\"" href=\""http://docs.openstack.org/cli-reference/"" ""barbican.html\"">\n"" "" 키 매니저 서비스 명령줄 클라이언트\n"" "" </a>\n"" "" </li>\n"" "" </ul>"" # auto translated by TM merge from project: zaqar-ui, version: master, DocId: zaqar_ui/locale/djangojs msgid ""Weight"" msgstr ""가중치"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: master, DocId: neutron_lbaas_dashboard/locale/djangojs msgid """" ""Weight\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" msgstr """" ""가중치\n"" "" <span class=\""hz-icon-required fa fa-asterisk\""></span>"" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""You are about to disassociate the floating IP address from load balancer \""%s"" ""\"". Please confirm."" msgstr """" ""Floating IP 주소를 로드 밸런서 \""%s\""에서 연결 해제하려고 합니다. 확인해주세"" ""요. "" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted health "" ""monitors are not recoverable."" msgstr """" ""\""%s\""을(를) 선택했습니다. 선택 내역을 확인하십시오. 삭제된 상태 모니터는 복"" ""구할 수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted listeners "" ""are not recoverable."" msgstr """" ""\""%s\""을(를) 선택했습니다. 선택 내역을 확인하십시오. 삭제한 리스너는 복구할 "" ""수 없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted load "" ""balancers are not recoverable."" msgstr """" ""\""%s\""를 선택했습니다. 선택 내역을 확인하십시오. 삭제한 로드 밸런서는 복구되"" ""지 않습니다."" #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted members are "" ""not recoverable."" msgstr """" ""\""%s\""을(를) 선택했습니다. 선택 내역을 확인하십시오. 삭제된 멤버는 복구할 수 "" ""없습니다."" # auto translated by TM merge from project: neutron-lbaas-dashboard, version: stable-ocata, DocId: neutron_lbaas_dashboard/locale/djangojs #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted pools are "" ""not recoverable."" msgstr """" ""\""%s\""을(를) 선택했습니다. 선택 내역을 확인하십시오. 삭제된 풀은 복구할 수 없"" ""습니다."" ",,1253,264
openstack%2Fkolla-ansible~master~I6c353a02a86cd76b2a2e7bd67801a95dd2b04d4f,openstack/kolla-ansible,master,I6c353a02a86cd76b2a2e7bd67801a95dd2b04d4f,Add note about checking if all the hostnames are resolvable,MERGED,2017-11-29 11:26:42.000000000,2017-12-13 18:01:33.000000000,2017-12-13 18:01:33.000000000,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 19779}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-29 11:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fc14884fd2dc333b7659813dd24fab2d9da2e782', 'message': 'Add content about checking if all the hostnames are resolvable\n\nChange-Id: I6c353a02a86cd76b2a2e7bd67801a95dd2b04d4f\nCloses-Bug: #1559809\n'}, {'number': 2, 'created': '2017-11-29 11:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2f8834cc0d770956c444e78f67c66b3391ccc520', 'message': 'Add note about checking if all the hostnames are resolvable\n\nChange-Id: I6c353a02a86cd76b2a2e7bd67801a95dd2b04d4f\nCloses-Bug: #1559809\n'}, {'number': 3, 'created': '2017-12-01 07:52:51.000000000', 'files': ['doc/source/user/multinode.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ceb8d1c2acb0c01ce29b96aa33a33c4e0171c753', 'message': 'Add note about checking if all the hostnames are resolvable\n\nChange-Id: I6c353a02a86cd76b2a2e7bd67801a95dd2b04d4f\nCloses-Bug: #1559809\n'}]",5,523846,ceb8d1c2acb0c01ce29b96aa33a33c4e0171c753,15,5,3,19779,,,0,"Add note about checking if all the hostnames are resolvable

Change-Id: I6c353a02a86cd76b2a2e7bd67801a95dd2b04d4f
Closes-Bug: #1559809
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/46/523846/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/multinode.rst'],1,fc14884fd2dc333b7659813dd24fab2d9da2e782,bug/1559809,".. note:: Rabbitmq can't work with IPs, make sure that all rabbit cluster hosts can resolve each others hostnames before running the deployment. ",,5,0
openstack%2Fkolla-ansible~master~I8a3678955ecf5f769da7090fe5dad68e027c102b,openstack/kolla-ansible,master,I8a3678955ecf5f769da7090fe5dad68e027c102b,Change listen for mdns,MERGED,2017-11-13 10:29:18.000000000,2017-12-13 18:01:32.000000000,2017-12-13 18:01:32.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 20663}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-13 10:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3953ed640a9f0153ba394435ca445f7736381408', 'message': 'The service listening port of MDNS can be override by dns_interface. If so, the pool conf use the wrong IP for join mdns service.\n\nChange-Id: I8a3678955ecf5f769da7090fe5dad68e027c102b\n'}, {'number': 2, 'created': '2017-11-13 10:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2a0200fc4b02b81f14a07abfdd1af803951f3581', 'message': 'The service listening port of MDNS can be override by dns_interface.\nIf so, the pool conf use the wrong IP for join mdns service.\n\nChange-Id: I8a3678955ecf5f769da7090fe5dad68e027c102b\n'}, {'number': 3, 'created': '2017-11-13 14:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3e2252b93975b9713f9fa18e5ea1edf262aed20f', 'message': 'Change listen for mdns\n\nThe service listening port of MDNS can be override by dns_interface.\nIf so, the pool conf use the wrong IP for join mdns service.\n\nChange-Id: I8a3678955ecf5f769da7090fe5dad68e027c102b\n'}, {'number': 4, 'created': '2017-11-21 15:04:38.000000000', 'files': ['releasenotes/notes/add-designate-bind-mdns-123e79587bb06072.yaml', 'ansible/roles/designate/templates/pools.yaml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c2d150d6be20d3be70a81c401f2385e3345721ab', 'message': 'Change listen for mdns\n\nThe service listening port of MDNS can be override by dns_interface.\nIf so, the pool conf use the wrong IP for join mdns service.\n\nChange-Id: I8a3678955ecf5f769da7090fe5dad68e027c102b\n'}]",0,519302,c2d150d6be20d3be70a81c401f2385e3345721ab,15,5,4,18368,,,0,"Change listen for mdns

The service listening port of MDNS can be override by dns_interface.
If so, the pool conf use the wrong IP for join mdns service.

Change-Id: I8a3678955ecf5f769da7090fe5dad68e027c102b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/02/519302/4 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/designate/templates/pools.yaml.j2'],1,3953ed640a9f0153ba394435ca445f7736381408,mdns_listen_pools, - host: {{ hostvars[mdns_host]['ansible_' + hostvars[mdns_host]['dns_interface']]['ipv4']['address'] }} port: {{ designate_mdns_port }} - host: {{ hostvars[mdns_host]['ansible_' + hostvars[mdns_host]['dns_interface']]['ipv4']['address'] }} port: {{ designate_mdns_port }}, - host: {{ hostvars[mdns_host]['ansible_' + hostvars[mdns_host]['api_interface']]['ipv4']['address'] }} port: 5354 - host: {{ hostvars[mdns_host]['ansible_' + hostvars[mdns_host]['api_interface']]['ipv4']['address'] }} port: 5354,4,4
openstack%2Fkolla~master~Ia0e103790bfbff078308acfe300fe66b7c50ebf5,openstack/kolla,master,Ia0e103790bfbff078308acfe300fe66b7c50ebf5,Set ES_SKIP_SET_KERNEL_PARAMETERS in elasticsearch image,MERGED,2017-09-29 09:32:58.000000000,2017-12-13 17:59:49.000000000,2017-12-13 17:59:49.000000000,"[{'_account_id': 167}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-29 09:32:58.000000000', 'files': ['docker/elasticsearch/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/682bfd2b4a70535019acea449efab5cd1a33f21a', 'message': 'Set ES_SKIP_SET_KERNEL_PARAMETERS in elasticsearch image\n\nOn systemd-based distributions, the installation scripts will attempt to set\nkernel parameters (e.g., vm.max_map_count); you can skip this by setting the\nenvironment variable ES_SKIP_SET_KERNEL_PARAMETERS to true.\n\nChange-Id: Ia0e103790bfbff078308acfe300fe66b7c50ebf5\n'}]",0,508468,682bfd2b4a70535019acea449efab5cd1a33f21a,13,5,1,167,,,0,"Set ES_SKIP_SET_KERNEL_PARAMETERS in elasticsearch image

On systemd-based distributions, the installation scripts will attempt to set
kernel parameters (e.g., vm.max_map_count); you can skip this by setting the
environment variable ES_SKIP_SET_KERNEL_PARAMETERS to true.

Change-Id: Ia0e103790bfbff078308acfe300fe66b7c50ebf5
",git fetch https://review.opendev.org/openstack/kolla refs/changes/68/508468/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/elasticsearch/Dockerfile.j2'],1,682bfd2b4a70535019acea449efab5cd1a33f21a,ES_SKIP_SET_KERNEL_PARAMETERS,ENV ES_SKIP_SET_KERNEL_PARAMETERS true ,,2,0
openstack%2Fkolla-ansible~master~I6b6114e85a4df82458c441f471929513c2526c23,openstack/kolla-ansible,master,I6b6114e85a4df82458c441f471929513c2526c23,Restart services after a change in the external ceph configuration,MERGED,2017-09-27 15:01:47.000000000,2017-12-13 17:58:43.000000000,2017-12-13 17:58:43.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 22348}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-09-27 15:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a82023566b80bbe7fef0927477b7728d1a1661d4', 'message': 'Restart services after a change in the external ceph configuration\n\nChange-Id: I6b6114e85a4df82458c441f471929513c2526c23\n'}, {'number': 2, 'created': '2017-10-09 07:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6bd75ce71ed5ac8ec16b92f1f1f1e775817dc213', 'message': 'Restart services after a change in the external ceph configuration\n\nChange-Id: I6b6114e85a4df82458c441f471929513c2526c23\n'}, {'number': 3, 'created': '2017-10-27 07:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/60fbfa61419bba5c1cedf6237bd5dd9bedf42310', 'message': 'Restart services after a change in the external ceph configuration\n\nChange-Id: I6b6114e85a4df82458c441f471929513c2526c23\n'}, {'number': 4, 'created': '2017-11-02 07:43:56.000000000', 'files': ['ansible/roles/gnocchi/tasks/external_ceph.yml', 'ansible/roles/nova/tasks/external_ceph.yml', 'ansible/roles/cinder/tasks/external_ceph.yml', 'ansible/roles/glance/tasks/external_ceph.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6039ad46f9c5fa24b27e698effce072f25049960', 'message': 'Restart services after a change in the external ceph configuration\n\nChange-Id: I6b6114e85a4df82458c441f471929513c2526c23\n'}]",0,507888,6039ad46f9c5fa24b27e698effce072f25049960,14,5,4,167,,,0,"Restart services after a change in the external ceph configuration

Change-Id: I6b6114e85a4df82458c441f471929513c2526c23
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/88/507888/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/gnocchi/tasks/external_ceph.yml', 'ansible/roles/nova/tasks/external_ceph.yml', 'ansible/roles/cinder/tasks/external_ceph.yml', 'ansible/roles/glance/tasks/external_ceph.yml']",4,a82023566b80bbe7fef0927477b7728d1a1661d4,restart-after-external-ceph-change, notify: - Restart glance-api container,,27,0
openstack%2Fkolla-ansible~master~If33dfff2b42b23eff7ec2230c9b0c5a4c010072e,openstack/kolla-ansible,master,If33dfff2b42b23eff7ec2230c9b0c5a4c010072e,Increased mariadb and kibana timeouts,MERGED,2017-12-12 20:34:05.000000000,2017-12-13 17:58:06.000000000,2017-12-13 17:58:06.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 20:34:05.000000000', 'files': ['ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/mariadb/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f27d89aa0934c11fd0946617a919ae55a8308c3a', 'message': ""Increased mariadb and kibana timeouts\n\nIn some deployment scenarios the current timeouts\nfor mariadb bootstrap and kibana registration with\nelasticsearch have been found to be too short. These\ntimeout increases shouldn't introduce any deployment\nslowdown in current environment and eliminate\ndeployment failures in environments with slower\nsystems.\n\nChange-Id: If33dfff2b42b23eff7ec2230c9b0c5a4c010072e\n""}]",0,527511,f27d89aa0934c11fd0946617a919ae55a8308c3a,7,3,1,16520,,,0,"Increased mariadb and kibana timeouts

In some deployment scenarios the current timeouts
for mariadb bootstrap and kibana registration with
elasticsearch have been found to be too short. These
timeout increases shouldn't introduce any deployment
slowdown in current environment and eliminate
deployment failures in environments with slower
systems.

Change-Id: If33dfff2b42b23eff7ec2230c9b0c5a4c010072e
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/11/527511/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/mariadb/defaults/main.yml']",2,f27d89aa0934c11fd0946617a919ae55a8308c3a,timeout_increase,database_max_timeout: 120,database_max_timeout: 60,2,2
openstack%2Fkolla-ansible~master~I203db11955189971640fcf8470e7a326d591b296,openstack/kolla-ansible,master,I203db11955189971640fcf8470e7a326d591b296,Update the job title of checking if Murano packages exists,MERGED,2017-12-12 06:52:47.000000000,2017-12-13 17:58:06.000000000,2017-12-13 17:58:06.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 19779}, {'_account_id': 20663}, {'_account_id': 22348}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-12-12 06:52:47.000000000', 'files': ['ansible/roles/murano/tasks/start.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fa9d696440fca4fe6bcb2ad3dcc8b46684aebfa1', 'message': 'Update the job title of checking if Murano packages exists\n\nCloses-Bug: #1734019\nChange-Id: I203db11955189971640fcf8470e7a326d591b296\n'}]",0,527317,fa9d696440fca4fe6bcb2ad3dcc8b46684aebfa1,11,7,1,19779,,,0,"Update the job title of checking if Murano packages exists

Closes-Bug: #1734019
Change-Id: I203db11955189971640fcf8470e7a326d591b296
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/17/527317/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/murano/tasks/start.yml'],1,fa9d696440fca4fe6bcb2ad3dcc8b46684aebfa1,bug/1734019,- name: Checking if Murano core and applications library packages exist,- name: Checking if Murano core library package exists,1,1
openstack%2Fkolla-ansible~master~Id7df0b74a44753cd90359fd79caafd7acce9adb8,openstack/kolla-ansible,master,Id7df0b74a44753cd90359fd79caafd7acce9adb8,Update the service_token_roles_required to True for watcher,MERGED,2017-11-01 12:25:42.000000000,2017-12-13 17:58:05.000000000,2017-12-13 17:58:05.000000000,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 23825}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-11-01 12:25:42.000000000', 'files': ['ansible/roles/watcher/templates/watcher.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/232ef11a9d42ce4b5d5fa1ccb68aafe61934d249', 'message': 'Update the service_token_roles_required to True for watcher\n\nAuthToken middleware is set with\nkeystone_authtoken.service_token_roles_required set to False.\nThis is backwards compatible but deprecated behaviour.\nThis patch set it to True.\n\nChange-Id: Id7df0b74a44753cd90359fd79caafd7acce9adb8\n'}]",0,516974,232ef11a9d42ce4b5d5fa1ccb68aafe61934d249,9,5,1,22165,,,0,"Update the service_token_roles_required to True for watcher

AuthToken middleware is set with
keystone_authtoken.service_token_roles_required set to False.
This is backwards compatible but deprecated behaviour.
This patch set it to True.

Change-Id: Id7df0b74a44753cd90359fd79caafd7acce9adb8
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/74/516974/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/watcher/templates/watcher.conf.j2'],1,232ef11a9d42ce4b5d5fa1ccb68aafe61934d249,,service_token_roles_required = True,,1,0
openstack%2Fkolla-ansible~master~Iedbf39c621f3c0237f9b9934492b12c600f2c4d3,openstack/kolla-ansible,master,Iedbf39c621f3c0237f9b9934492b12c600f2c4d3,automate ovs datapath configuration,MERGED,2017-08-15 15:17:30.000000000,2017-12-13 17:58:03.000000000,2017-12-13 17:58:03.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11604}, {'_account_id': 19316}, {'_account_id': 20205}, {'_account_id': 21103}, {'_account_id': 22348}, {'_account_id': 23046}, {'_account_id': 24441}, {'_account_id': 25945}, {'_account_id': 26203}, {'_account_id': 26553}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-08-15 15:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/07e937b107fda9f608035bdaf46af6129c695ba4', 'message': 'automate ovs datapath configuration\n\n- This change automates generation of\n  the datapath_type paramater in the ml2_conf.ini\n- If enable_ovs_dpdk is no the datapath type\n  will be system else it will be netdev which maintains\n  the current default behaviour when dpdk is not enabled.\n\nChange-Id: Iedbf39c621f3c0237f9b9934492b12c600f2c4d3\npartial-implementes: bp/ovs-dpdk\n'}, {'number': 2, 'created': '2017-08-16 16:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f518af4c68a161266cb55d8ca3cedb8d7d6359ef', 'message': 'automate ovs datapath configuration\n\n- This change automates generation of\n  the datapath_type paramater in the ml2_conf.ini\n- If enable_ovs_dpdk is no the datapath type\n  will be system else it will be netdev which maintains\n  the current default behaviour when dpdk is not enabled.\n\nChange-Id: Iedbf39c621f3c0237f9b9934492b12c600f2c4d3\npartial-implementes: bp/ovs-dpdk\n'}, {'number': 3, 'created': '2017-08-30 19:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/764e5e669770ace5eefdfcf55bdcf6c2cd0a4d36', 'message': 'automate ovs datapath configuration\n\n- This change automates generation of\n  the datapath_type paramater in the ml2_conf.ini\n- If enable_ovs_dpdk is no the datapath type\n  will be system else it will be netdev which maintains\n  the current default behaviour when dpdk is not enabled.\n\nChange-Id: Iedbf39c621f3c0237f9b9934492b12c600f2c4d3\npartial-implementes: bp/ovs-dpdk\n'}, {'number': 4, 'created': '2017-11-10 17:18:13.000000000', 'files': ['ansible/roles/neutron/templates/ml2_conf.ini.j2', 'ansible/group_vars/all.yml', 'ansible/roles/ovs-dpdk/defaults/main.yml', 'doc/source/reference/networking-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7eb24fa377b9285766bd9a536dfd2b95af342bbe', 'message': 'automate ovs datapath configuration\n\n- This change automates generation of\n  the datapath_type paramater in the ml2_conf.ini\n- If enable_ovs_dpdk is no the datapath type\n  will be system else it will be netdev which maintains\n  the current default behaviour when dpdk is not enabled.\n\nChange-Id: Iedbf39c621f3c0237f9b9934492b12c600f2c4d3\npartial-implementes: bp/ovs-dpdk\n'}]",3,493916,7eb24fa377b9285766bd9a536dfd2b95af342bbe,24,13,4,11604,,,0,"automate ovs datapath configuration

- This change automates generation of
  the datapath_type paramater in the ml2_conf.ini
- If enable_ovs_dpdk is no the datapath type
  will be system else it will be netdev which maintains
  the current default behaviour when dpdk is not enabled.

Change-Id: Iedbf39c621f3c0237f9b9934492b12c600f2c4d3
partial-implementes: bp/ovs-dpdk
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/16/493916/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide.rst', 'ansible/roles/neutron/templates/ml2_conf.ini.j2', 'ansible/group_vars/all.yml', 'ansible/roles/ovs-dpdk/defaults/main.yml']",4,07e937b107fda9f608035bdaf46af6129c695ba4,bp/ovs-dpdk,,"ovs_datapath: ""netdev""",3,17
openstack%2Fkolla-ansible~master~I3e96a4a76b44ffb558b9a41cde16e66a8d0fab1a,openstack/kolla-ansible,master,I3e96a4a76b44ffb558b9a41cde16e66a8d0fab1a,Set bash as shell when executing mariadb recovery task,MERGED,2017-11-27 18:10:01.000000000,2017-12-13 17:58:02.000000000,2017-12-13 17:58:02.000000000,"[{'_account_id': 7488}, {'_account_id': 9414}, {'_account_id': 11105}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-11-27 18:10:01.000000000', 'files': ['ansible/roles/mariadb/tasks/recover_cluster.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6f64549e1bf54af55072a5992d1011b28fa6ca22', 'message': ""Set bash as shell when executing mariadb recovery task\n\nAdded 'executable' argument to the shell action in the\n'Comparing seqno value' task in the cluster recovery playbook.\n\nChange-Id: I3e96a4a76b44ffb558b9a41cde16e66a8d0fab1a\nCloses-Bug: #1729603\n""}]",0,523180,6f64549e1bf54af55072a5992d1011b28fa6ca22,11,6,1,27300,,,0,"Set bash as shell when executing mariadb recovery task

Added 'executable' argument to the shell action in the
'Comparing seqno value' task in the cluster recovery playbook.

Change-Id: I3e96a4a76b44ffb558b9a41cde16e66a8d0fab1a
Closes-Bug: #1729603
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/80/523180/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/mariadb/tasks/recover_cluster.yml'],1,6f64549e1bf54af55072a5992d1011b28fa6ca22,bug/1729603, args: executable: /bin/bash,,2,0
openstack%2Fkolla-ansible~stable%2Fpike~I025037cf48596450e6479ab7ff6425c48ac73aad,openstack/kolla-ansible,stable/pike,I025037cf48596450e6479ab7ff6425c48ac73aad,Fix ansible running issue on Debian,MERGED,2017-11-15 12:22:53.000000000,2017-12-13 17:58:02.000000000,2017-12-13 17:58:02.000000000,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22997}, {'_account_id': 23825}]","[{'number': 1, 'created': '2017-11-15 12:22:53.000000000', 'files': ['ansible/roles/ceph/tasks/bootstrap_osds.yml', 'ansible/roles/ceph/tasks/start_osds.yml', 'ansible/roles/swift/tasks/check.yml', 'ansible/roles/ceph/tasks/reconfigure.yml', 'ansible/roles/swift/tasks/start.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/628569afe535693ea743526e92894daf2fb90bb1', 'message': ""Fix ansible running issue on Debian\n\nWhen deploying on debian, it reports error:\nstat /usr/bin/ansible: no such file or directory\n\nThat's because on Debian and Ubuntu pip install ansible to\n/usr/local/bin/ansible, whereas on CentOS the location is\n/usr/bin/ansible.\n\nChange to ansible to handle both cases.\n\nCloses-Bug: #1729216\nDepends-On: I2b57403128bc103148ae696c219df52590214adc\n\nChange-Id: I025037cf48596450e6479ab7ff6425c48ac73aad\nSigned-off-by: Xinliang Liu <xinliang.liu@linaro.org>\n""}]",0,520059,628569afe535693ea743526e92894daf2fb90bb1,10,5,1,24072,,,0,"Fix ansible running issue on Debian

When deploying on debian, it reports error:
stat /usr/bin/ansible: no such file or directory

That's because on Debian and Ubuntu pip install ansible to
/usr/local/bin/ansible, whereas on CentOS the location is
/usr/bin/ansible.

Change to ansible to handle both cases.

Closes-Bug: #1729216
Depends-On: I2b57403128bc103148ae696c219df52590214adc

Change-Id: I025037cf48596450e6479ab7ff6425c48ac73aad
Signed-off-by: Xinliang Liu <xinliang.liu@linaro.org>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/59/520059/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ceph/tasks/bootstrap_osds.yml', 'ansible/roles/ceph/tasks/start_osds.yml', 'ansible/roles/swift/tasks/check.yml', 'ansible/roles/ceph/tasks/reconfigure.yml', 'ansible/roles/swift/tasks/start.yml']",5,628569afe535693ea743526e92894daf2fb90bb1,bug/1729216, command: docker exec -t kolla_toolbox sudo -E ansible localhost, command: docker exec -t kolla_toolbox sudo -E /usr/bin/ansible localhost,6,6
openstack%2Fmistral~master~Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0,openstack/mistral,master,Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0,Use the new action context in MistralHTTPAction,MERGED,2017-11-16 08:59:00.000000000,2017-12-13 17:54:22.000000000,2017-12-13 17:54:22.000000000,"[{'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 23630}]","[{'number': 1, 'created': '2017-11-16 08:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b768175bdcda90c13e1913de18127aac1b2b1caa', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 2, 'created': '2017-11-20 09:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fe3c7bd1977da41a0eb240c3131e2e5cf79acd9a', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 3, 'created': '2017-11-27 11:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fc9477355f9b925bfdd473e6fa7b3fa8cc0d4feb', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 4, 'created': '2017-11-29 11:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e53a5c11454b71d151146c6ab74fae65dbd36983', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 5, 'created': '2017-12-04 15:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f2d26e8fd5741342b17dd6fb2807f2e16752e4b0', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 6, 'created': '2017-12-05 10:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ca8cc65c1c76553135f36567e20171d3921ff9ea', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 7, 'created': '2017-12-05 14:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bd6ce388ed591d56c6dd6fdd8fe6242fa735bfe6', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 8, 'created': '2017-12-07 15:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/60a8847196f0552c7561b0b0942b4f8c3ac7836b', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}, {'number': 9, 'created': '2017-12-11 22:43:03.000000000', 'files': ['mistral/services/action_manager.py', 'mistral/tests/unit/engine/test_action_context.py', 'mistral/tests/unit/engine/test_adhoc_actions.py', 'mistral/engine/actions.py', 'mistral/actions/std_actions.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/f9457b8cc608f4ae355c1219d214057e02668f35', 'message': 'Use the new action context in MistralHTTPAction\n\nThis move allows us to remove the previous method for injecting\ncontext information into actions. It was only used by the\nMistralHTTPAction.\n\nRelated-Bug: #1718353\nCo-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>\nChange-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0\n'}]",3,520348,f9457b8cc608f4ae355c1219d214057e02668f35,34,7,9,9712,,,0,"Use the new action context in MistralHTTPAction

This move allows us to remove the previous method for injecting
context information into actions. It was only used by the
MistralHTTPAction.

Related-Bug: #1718353
Co-Authored-By: Renat Akhmerov <renat.akhmerov@gmail.com>
Change-Id: Ie5c39d35e5848accb24f1cd15e88a4a2dd4b69c0
",git fetch https://review.opendev.org/openstack/mistral refs/changes/48/520348/4 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/services/action_manager.py', 'mistral/tests/unit/engine/test_action_context.py', 'mistral/tests/unit/engine/test_adhoc_actions.py', 'mistral/engine/actions.py', 'mistral/actions/std_actions.py']",5,b768175bdcda90c13e1913de18127aac1b2b1caa,bug/1718353," def run(self, context): self.headers = self.headers or {} exec_ctx = context.execution self.headers.update({ 'Mistral-Workflow-Name': exec_ctx.workflow_name, 'Mistral-Workflow-Execution-Id': exec_ctx.workflow_execution_id, 'Mistral-Task-Id': exec_ctx.task_id, 'Mistral-Action-Execution-Id': exec_ctx.action_execution_id, 'Mistral-Callback-URL': exec_ctx.callback_url, super(MistralHTTPAction, self).run(context)"," def __init__(self, action_context, url, method=""GET"", params=None, body=None, headers=None, cookies=None, auth=None, timeout=None, allow_redirects=None, proxies=None, verify=None): actx = action_context headers = headers or {} headers.update({ 'Mistral-Workflow-Name': actx.get('workflow_name'), 'Mistral-Workflow-Execution-Id': actx.get('workflow_execution_id'), 'Mistral-Task-Id': actx.get('task_id'), 'Mistral-Action-Execution-Id': actx.get('action_execution_id'), 'Mistral-Callback-URL': actx.get('callback_url'), super(MistralHTTPAction, self).__init__( url, method, params, body, headers, cookies, auth, timeout, allow_redirects, proxies, verify, )",98,288
openstack%2Fmistral~master~I660ec2fe00e9f524292957560548447e517332fc,openstack/mistral,master,I660ec2fe00e9f524292957560548447e517332fc,Fix inconsistencies when setting policy values,MERGED,2017-11-09 02:19:34.000000000,2017-12-13 17:54:21.000000000,2017-12-13 17:54:21.000000000,"[{'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-09 02:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/89246c7dfb2abdc8f9b3be2d9473335180ea204a', 'message': ""Fix inconsistencies when setting policy values\n\nThis patch fixes inconsistencies between two ways of setting policy\nvalues: as a variable and directly in workflow definition as a constant.\n\nInconsistency #1:\nFor policies 'wait-before', 'wait-after', 'retry', 'timeout', 'concurrency'\nthere is a difference on how they are executed if value is 0.\nIf the value is hardcoded in workflow, the policies are omitted [1],\nbut if a user defines them as a variable, then the policies are applied.\n\nInconsistency #2:\nPolicy values in workflow definitions cannot be negative numbers (validated\nby schema) [2], but if a user sets them as variables it's okay [3]. It\nhappens because the schemas are different for both cases.\n\n[1] https://github.com/openstack/mistral/blob/master/mistral/engine/policies.py#L83\n[2] https://github.com/openstack/mistral/blob/master/mistral/lang/v2/policies.py#L27\n[3] https://github.com/openstack/mistral/blob/master/mistral/engine/policies.py#L161\n\nChange-Id: I660ec2fe00e9f524292957560548447e517332fc\nCloses-bug: #1731100\n""}, {'number': 2, 'created': '2017-12-13 11:13:12.000000000', 'files': ['mistral/tests/unit/engine/test_policies.py', 'mistral/engine/policies.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/4283998694e314ecb0ead9c16d022204e2cbaa7c', 'message': ""Fix inconsistencies when setting policy values\n\nThis patch fixes inconsistencies between two ways of setting policy\nvalues: as a variable and directly in workflow definition as a constant.\n\nInconsistency #1:\nFor policies 'wait-before', 'wait-after', 'retry', 'timeout', 'concurrency'\nthere is a difference on how they are executed if value is 0.\nIf the value is hardcoded in workflow, the policies are omitted [1],\nbut if a user defines them as a variable, then the policies are applied.\n\nInconsistency #2:\nPolicy values in workflow definitions cannot be negative numbers (validated\nby schema) [2], but if a user sets them as variables it's okay [3]. It\nhappens because the schemas are different for both cases.\n\n[1] https://github.com/openstack/mistral/blob/master/mistral/engine/policies.py#L83\n[2] https://github.com/openstack/mistral/blob/master/mistral/lang/v2/policies.py#L27\n[3] https://github.com/openstack/mistral/blob/master/mistral/engine/policies.py#L161\n\nChange-Id: I660ec2fe00e9f524292957560548447e517332fc\nCloses-bug: #1731100\n""}]",4,518641,4283998694e314ecb0ead9c16d022204e2cbaa7c,18,5,2,11391,,,0,"Fix inconsistencies when setting policy values

This patch fixes inconsistencies between two ways of setting policy
values: as a variable and directly in workflow definition as a constant.

Inconsistency #1:
For policies 'wait-before', 'wait-after', 'retry', 'timeout', 'concurrency'
there is a difference on how they are executed if value is 0.
If the value is hardcoded in workflow, the policies are omitted [1],
but if a user defines them as a variable, then the policies are applied.

Inconsistency #2:
Policy values in workflow definitions cannot be negative numbers (validated
by schema) [2], but if a user sets them as variables it's okay [3]. It
happens because the schemas are different for both cases.

[1] https://github.com/openstack/mistral/blob/master/mistral/engine/policies.py#L83
[2] https://github.com/openstack/mistral/blob/master/mistral/lang/v2/policies.py#L27
[3] https://github.com/openstack/mistral/blob/master/mistral/engine/policies.py#L161

Change-Id: I660ec2fe00e9f524292957560548447e517332fc
Closes-bug: #1731100
",git fetch https://review.opendev.org/openstack/mistral refs/changes/41/518641/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine/test_policies.py', 'mistral/engine/policies.py']",2,89246c7dfb2abdc8f9b3be2d9473335180ea204a,bug/1731100," if isinstance(wait_before, six.string_types) or wait_before > 0: if isinstance(wait_after, six.string_types) or wait_after > 0: if isinstance(timeout_policy, six.string_types) or timeout_policy > 0: ""delay"": { ""type"": ""integer"", ""minimum"": 0 } # No need to wait for a task if delay is 0 if self.delay == 0: return ""delay"": { ""type"": ""integer"", ""minimum"": 0 } # No need to postpone a task if delay is 0 if self.delay == 0: return ""delay"": { ""type"": ""integer"", ""minimum"": 0 }, ""count"": { ""type"": ""integer"", ""minimum"": 0 }, # There is nothing to repeat if self.count == 0: return ""delay"": { ""type"": ""integer"", ""minimum"": 0 } # No timeout if delay is 0 if self.delay == 0: return ""concurrency"": { ""type"": ""integer"", ""minimum"": 0 } if self.concurrency == 0: return "," if (isinstance(wait_before, six.string_types) or wait_before > 0): if (isinstance(wait_after, six.string_types) or wait_after > 0): if (isinstance(timeout_policy, six.string_types) or timeout_policy > 0): ""delay"": {""type"": ""integer""} ""delay"": {""type"": ""integer""} ""delay"": {""type"": ""integer""}, ""count"": {""type"": ""integer""} ""delay"": {""type"": ""integer""} ""concurrency"": {""type"": ""integer""},",466,28
openstack%2Fnetworking-l2gw~master~I3651081299113dcafb99bd383422d961a5fe46ff,openstack/networking-l2gw,master,I3651081299113dcafb99bd383422d961a5fe46ff,Add UT cases for L2GW Update,MERGED,2017-12-13 09:43:28.000000000,2017-12-13 17:51:27.000000000,2017-12-13 17:51:27.000000000,"[{'_account_id': 1653}, {'_account_id': 8313}, {'_account_id': 9656}, {'_account_id': 21626}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 09:43:28.000000000', 'files': ['networking_l2gw/services/l2gateway/service_drivers/rpc_l2gw.py', 'networking_l2gw/tests/unit/services/l2gateway/service_drivers/test_rpc_l2gw.py'], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/fe3f52a2766fae3269c3d933fbc8b0f781911632', 'message': 'Add UT cases for L2GW Update\n\nAdd UT cases for L2GW Update in RPC driver\n\nChange-Id: I3651081299113dcafb99bd383422d961a5fe46ff\nSigned-off-by: Peng Liu <pliu@redhat.com>\n'}]",0,527649,fe3f52a2766fae3269c3d933fbc8b0f781911632,7,5,1,21747,,,0,"Add UT cases for L2GW Update

Add UT cases for L2GW Update in RPC driver

Change-Id: I3651081299113dcafb99bd383422d961a5fe46ff
Signed-off-by: Peng Liu <pliu@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-l2gw refs/changes/49/527649/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_l2gw/services/l2gateway/service_drivers/rpc_l2gw.py', 'networking_l2gw/tests/unit/services/l2gateway/service_drivers/test_rpc_l2gw.py']",2,fe3f52a2766fae3269c3d933fbc8b0f781911632,add-ut," def test_validate_gateway_for_update_with_invalid_device(self): self.db_context = ctx.get_admin_context() fake_l2gw_dict = {""l2_gateway"": {""name"": ""fake_name"", ""devices"": [{""interfaces"": [{""name"": ""port1"", ""segmentation_id"": [ ""111""]}], ""device_name"": ""device_name""}]}} with mock.patch.object(db, 'get_physical_switch_by_name', return_value=None): self.assertRaises(l2gw_exc.L2GatewayDeviceNotFound, self.plugin._validate_gateway_for_update, self.db_context, fake_l2gw_dict) def test_validate_gateway_for_update_with_invalid_port(self): self.db_context = ctx.get_admin_context() fake_l2gw_dict = {""l2_gateway"": {""name"": ""fake_name"", ""devices"": [{""interfaces"": [{""name"": ""port1"", ""segmentation_id"": [ ""111""]}], ""device_name"": ""device_name""}]}} fake_physical_switch = {'uuid': 'fake_id', 'name': 'fake_device_name', 'tunnel_ip': 'fake_tunnel_ip', 'ovsdb_identifier': 'fake_ovsdb_id', 'switch_fault_status': None} with mock.patch.object(db, 'get_physical_switch_by_name', return_value=fake_physical_switch), \ mock.patch.object(db, 'get_physical_port_by_name_and_ps', return_value=None): self.assertRaises(l2gw_exc.L2GatewayPhysicalPortNotFound, self.plugin._validate_gateway_for_update, self.db_context, fake_l2gw_dict) def test_update_l2_gateway(self): self.db_context = ctx.get_admin_context() fake_l2gw_dict = {'id': 'fake_l2gw_id', 'tenant_id': 'fake_tenant_id', ""name"": ""fake_l2gw_name"", ""devices"": [{""interfaces"": [{""name"": ""port1"", ""segmentation_id"": [""111""]}], ""device_name"": ""fake_device_name"", 'id': 'fake_device_id'}]} fake_l2gw_id = 'fake_l2gw_id' fake_device_dict = {'devices': [{'device_name': 'fake_device', 'interfaces': [{'name': 'fake_interface'}]}]} fake_device_list = [fake_device_dict] fake_conn_dict = {'l2_gateway_id': 'fake_l2gw_id', 'ovsdb_identifier': 'fake_ovsdb_id', 'network_id': 'fake_network_id'} fake_conn_list = [fake_conn_dict] fake_vlan_dict = {'vlan': 100, 'logical_switch_uuid': 'fake_uuid'} fake_physical_port = ovsdb_schema.PhysicalPort( uuid='fake_uuid', name='fake_interface_name', phys_switch_id='fake_uuid', vlan_binding_dicts=None, port_fault_status=None) fake_phys_port_dict = fake_physical_port.__dict__ fake_phys_port_dict['vlan_bindings'] = [fake_vlan_dict] fake_port_list = [fake_phys_port_dict] ovsdb_id = 'fake_ovsdb_id' logical_switch = {'uuid': 'fake_id'} with mock.patch.object(self.service_plugin, '_admin_check', return_value=True) as admin_check, \ mock.patch.object(self.plugin, '_validate_gateway_for_update') as validate_gateway, \ mock.patch.object(self.service_plugin, 'get_l2gateway_devices_by_gateway_id', return_value=fake_device_list) as device_list, \ mock.patch.object(self.service_plugin, '_get_l2_gateway_connections', return_value=fake_conn_list) as conn_list, \ mock.patch.object(self.plugin, '_process_port_list', return_value=(ovsdb_id, logical_switch, fake_port_list)) as port_list: self.plugin.update_l2_gateway( self.db_context, fake_l2gw_id, fake_l2gw_dict) admin_check.assert_called_with(self.db_context, 'UPDATE') self.assertTrue(validate_gateway.called) device_list.assert_called_with(self.db_context, 'fake_l2gw_id') conn_list.assert_called_with(self.db_context) port_list.assert_called_with( self.db_context, fake_device_dict, fake_conn_dict, ""UPDATE"") self.assertEqual(self.plugin.port_dict_before_update, fake_port_list) def test_update_l2_gateway_postcommit_with_add_port(self): self.db_context = ctx.get_admin_context() fake_l2gw_dict = {'id': 'fake_l2gw_id', 'tenant_id': 'fake_tenant_id', ""name"": ""fake_l2gw_name"", ""devices"": [{""interfaces"": [{""name"": ""port1"", ""segmentation_id"": [""111""]}], ""device_name"": ""fake_device_name"", 'id': 'fake_device_id'}]} fake_device_dict = {'devices': [{'device_name': 'fake_device_name', 'interfaces': [{'name': 'port1'}]}]} fake_device_list = [fake_device_dict] fake_conn_dict = {'l2_gateway_id': 'fake_l2gw_id', 'ovsdb_identifier': 'fake_ovsdb_id', 'network_id': 'fake_network_id'} fake_conn_list = [fake_conn_dict] fake_vlan_dict = {'vlan': 100, 'logical_switch_uuid': 'fake_ls_id'} fake_physical_port_1 = ovsdb_schema.PhysicalPort( uuid='fake_uuid_1', name='fake_interface_name_1', phys_switch_id='fake_uuid_1', vlan_binding_dicts=None, port_fault_status=None) fake_physical_port_2 = ovsdb_schema.PhysicalPort( uuid='fake_uuid_2', name='fake_interface_name_2', phys_switch_id='fake_uuid_2', vlan_binding_dicts=None, port_fault_status=None) fake_phys_port_dict_1 = fake_physical_port_1.__dict__ fake_phys_port_dict_1['vlan_bindings'] = [fake_vlan_dict] fake_phys_port_dict_2 = fake_physical_port_2.__dict__ fake_phys_port_dict_2['vlan_bindings'] = [fake_vlan_dict] fake_port_list_before_update = [fake_phys_port_dict_1] fake_port_list_after_update = [fake_phys_port_dict_1, fake_phys_port_dict_2] port_list_add = [fake_phys_port_dict_2] fake_port = {'device_owner': 'fake_owner', 'network_id': 'fake_network_id', 'mac_address': 'fake_mac', 'ip_address': 'fake_ip', 'allowed_address_pairs': [{'ip_address': 'fake_ip', 'mac_address': 'fake_mac'}]} fake_port_list = [fake_port] ovsdb_id = 'fake_ovsdb_id' logical_switch = {'uuid': 'fake_ls_id'} fake_ls_dict = {'logical_switch_name': 'fake_network_id', 'ovsdb_identifier': 'fake_ovsdb_id'} fake_pl_dict = {'uuid': 'fake_uuid', 'dst_ip': 'fake_ip1', 'ovsdb_identifier': 'fake_ovsdb_id', 'macs': [fake_port]} mac_dict = {'fake_ip1': fake_pl_dict['macs']} fake_pl_list = [fake_pl_dict] with mock.patch.object(self.plugin, 'port_dict_before_update', fake_port_list_before_update), \ mock.patch.object(self.service_plugin, '_admin_check', return_value=True) as admin_check, \ mock.patch.object(self.service_plugin, 'get_l2gateway_devices_by_gateway_id', return_value=fake_device_list) as device_list, \ mock.patch.object(self.service_plugin, '_get_l2_gateway_connections', return_value=fake_conn_list) as conn_list, \ mock.patch.object(self.plugin, '_process_port_list', return_value=(ovsdb_id, logical_switch, fake_port_list_after_update)) as port_list, \ mock.patch.object(self.plugin, '_get_logical_switch_dict', return_value=fake_ls_dict) as get_ls, \ mock.patch.object(self.plugin, '_get_port_details', return_value=fake_port_list) as get_port, \ mock.patch.object(self.plugin, '_get_ip_details', return_value=('fake_ip1', 'fake_ip2')) as get_ip, \ mock.patch.object(self.plugin, '_get_dict', return_value=mock.ANY) as get_dict, \ mock.patch.object(db, 'get_ucast_mac_remote_by_mac_and_ls') as get_ucast_mac, \ mock.patch.object(self.plugin, '_get_locator_list', return_value=fake_pl_list) as get_pl, \ mock.patch.object(self.plugin.agent_rpc, 'update_connection_to_gateway') as update_rpc: self.plugin.update_l2_gateway_postcommit(self.db_context, fake_l2gw_dict) admin_check.assert_called_with(self.db_context, 'UPDATE') device_list.assert_called_with(self.db_context, 'fake_l2gw_id') conn_list.assert_called_with(self.db_context) port_list.assert_called_with( self.db_context, fake_device_dict, fake_conn_dict, ""UPDATE"") get_ls.assert_called_with(self.db_context, logical_switch, fake_conn_dict) get_port.assert_called_with(self.db_context, 'fake_network_id') self.assertTrue(get_ip.called) self.assertTrue(get_dict.called) self.assertEqual(get_ucast_mac.call_count, 2) self.assertTrue(get_pl.called) update_rpc.assert_called_with(self.db_context, ovsdb_id, fake_ls_dict, fake_pl_list, mac_dict, port_list_add, 'CREATE') def test_update_l2_gateway_postcommit_with_del_port(self): self.db_context = ctx.get_admin_context() fake_l2gw_dict = {'id': 'fake_l2gw_id', 'tenant_id': 'fake_tenant_id', ""name"": ""fake_l2gw_name"", ""devices"": [{""interfaces"": [{""name"": ""port1"", ""segmentation_id"": [""111""]}], ""device_name"": ""fake_device_name"", 'id': 'fake_device_id'}]} fake_device_dict = {'devices': [{'device_name': 'fake_device_name', 'interfaces': [{'name': 'port1'}]}]} fake_device_list = [fake_device_dict] fake_conn_dict = {'l2_gateway_id': 'fake_l2gw_id', 'ovsdb_identifier': 'fake_ovsdb_id', 'network_id': 'fake_network_id'} fake_conn_list = [fake_conn_dict] fake_vlan_dict = {'vlan': 100, 'logical_switch_uuid': 'fake_ls_id'} fake_physical_port_1 = ovsdb_schema.PhysicalPort( uuid='fake_uuid_1', name='fake_interface_name_1', phys_switch_id='fake_uuid_1', vlan_binding_dicts=None, port_fault_status=None) fake_physical_port_2 = ovsdb_schema.PhysicalPort( uuid='fake_uuid_2', name='fake_interface_name_2', phys_switch_id='fake_uuid_2', vlan_binding_dicts=None, port_fault_status=None) fake_phys_port_dict_1 = fake_physical_port_1.__dict__ fake_phys_port_dict_1['vlan_bindings'] = [fake_vlan_dict] fake_phys_port_dict_2 = fake_physical_port_2.__dict__ fake_phys_port_dict_2['vlan_bindings'] = [fake_vlan_dict] fake_port_list_before_update = [fake_phys_port_dict_1, fake_phys_port_dict_2] fake_port_list_after_update = [fake_phys_port_dict_1] port_list_del = [fake_phys_port_dict_2] ovsdb_id = 'fake_ovsdb_id' logical_switch = {'uuid': 'fake_ls_id'} fake_ls_dict = {'logical_switch_name': 'fake_network_id', 'ovsdb_identifier': 'fake_ovsdb_id'} mac_dict = {} fake_pl_list = [] with mock.patch.object(self.plugin, 'port_dict_before_update', fake_port_list_before_update), \ mock.patch.object(self.service_plugin, '_admin_check', return_value=True) as admin_check, \ mock.patch.object(self.service_plugin, 'get_l2gateway_devices_by_gateway_id', return_value=fake_device_list) as device_list, \ mock.patch.object(self.service_plugin, '_get_l2_gateway_connections', return_value=fake_conn_list) as conn_list, \ mock.patch.object(self.plugin, '_process_port_list', return_value=(ovsdb_id, logical_switch, fake_port_list_after_update)) as port_list, \ mock.patch.object(self.plugin, '_get_logical_switch_dict', return_value=fake_ls_dict) as get_ls, \ mock.patch.object(self.plugin.agent_rpc, 'update_connection_to_gateway') as update_rpc: self.plugin.update_l2_gateway_postcommit(self.db_context, fake_l2gw_dict) admin_check.assert_called_with(self.db_context, 'UPDATE') device_list.assert_called_with(self.db_context, 'fake_l2gw_id') conn_list.assert_called_with(self.db_context) port_list.assert_called_with( self.db_context, fake_device_dict, fake_conn_dict, ""UPDATE"") get_ls.assert_called_with(self.db_context, logical_switch, fake_conn_dict) update_rpc.assert_called_with(self.db_context, ovsdb_id, fake_ls_dict, fake_pl_list, mac_dict, port_list_del, 'DELETE')",,294,0
openstack%2Fkolla-ansible~master~I6dd2a8fcce83cba8a9a79b1c302d6b1ef4305144,openstack/kolla-ansible,master,I6dd2a8fcce83cba8a9a79b1c302d6b1ef4305144,Add a missing conditional check to the common config task,MERGED,2017-11-28 01:16:54.000000000,2017-12-13 17:50:20.000000000,2017-12-13 17:50:20.000000000,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-28 01:16:54.000000000', 'files': ['ansible/roles/common/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/502597498267f0c33f4e4fba528530054f67ee37', 'message': 'Add a missing conditional check to the common config task\n\nThe owner and permission check for config directories\nshould be executed only when the service is enabled.\n\nChange-Id: I6dd2a8fcce83cba8a9a79b1c302d6b1ef4305144\nCloses-Bug: #1734789\n'}]",0,523260,502597498267f0c33f4e4fba528530054f67ee37,8,3,1,26299,,,0,"Add a missing conditional check to the common config task

The owner and permission check for config directories
should be executed only when the service is enabled.

Change-Id: I6dd2a8fcce83cba8a9a79b1c302d6b1ef4305144
Closes-Bug: #1734789
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/60/523260/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/tasks/config.yml'],1,502597498267f0c33f4e4fba528530054f67ee37,bug/1734789," path: ""{{ node_config_directory }}/{{ item.key }}"" when: - item.value.enabled | bool - item.key != ""kolla-toolbox"" with_dict: ""{{ common_services }}"""," path: ""{{ node_config_directory }}/{{ item }}"" with_items: - ""fluentd"" - ""cron""",5,4
openstack%2Fkolla-ansible~master~I942c813b8ea8052aab57d2248805bec75ffa5ec6,openstack/kolla-ansible,master,I942c813b8ea8052aab57d2248805bec75ffa5ec6,Optimize the tasks format for ovs-dpdk,MERGED,2017-12-01 15:44:15.000000000,2017-12-13 17:50:19.000000000,2017-12-13 17:50:19.000000000,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-01 15:44:15.000000000', 'files': ['ansible/roles/ovs-dpdk/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b0b434d847608db60a74047cd3cd5554139869a1', 'message': 'Optimize the tasks format for ovs-dpdk\n\nremove the unnecessary blank line\n\nChange-Id: I942c813b8ea8052aab57d2248805bec75ffa5ec6\n'}]",0,524650,b0b434d847608db60a74047cd3cd5554139869a1,7,3,1,22165,,,0,"Optimize the tasks format for ovs-dpdk

remove the unnecessary blank line

Change-Id: I942c813b8ea8052aab57d2248805bec75ffa5ec6
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/50/524650/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ovs-dpdk/handlers/main.yml'],1,b0b434d847608db60a74047cd3cd5554139869a1,,,,0,2
openstack%2Fkolla-ansible~master~I1c94c45701fda5430b5d5a88c719db13d1956b11,openstack/kolla-ansible,master,I1c94c45701fda5430b5d5a88c719db13d1956b11,Move Cinder backend passwords to passwords.yml,MERGED,2017-11-21 11:33:05.000000000,2017-12-13 17:45:43.000000000,2017-12-13 17:45:42.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 9414}, {'_account_id': 13671}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23825}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-11-21 11:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/86a507579c65465210343b9add5366c5d3b4a4f1', 'message': 'Move Cinder backend passwords to passwords.yml\n\nMove Hitachi NAS and Oracle ZFSSA passwords\nto /etc/kolla/passwords.yml\n\nChange-Id: I1c94c45701fda5430b5d5a88c719db13d1956b11\nCloses-Bug: #1733565\n'}, {'number': 2, 'created': '2017-12-06 12:30:56.000000000', 'files': ['ansible/roles/cinder/defaults/main.yml', 'doc/source/reference/cinder-guide-hnas.rst', 'releasenotes/notes/move-storage-passwords-09b5afc839284321.yaml', 'etc/kolla/passwords.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4829ed2c87ac89ed3415b0dff94e7a8be4be80ca', 'message': 'Move Cinder backend passwords to passwords.yml\n\nMove Hitachi NAS and Oracle ZFSSA passwords\nto /etc/kolla/passwords.yml\n\nChange-Id: I1c94c45701fda5430b5d5a88c719db13d1956b11\nCloses-Bug: #1733565\n'}]",0,521817,4829ed2c87ac89ed3415b0dff94e7a8be4be80ca,17,9,2,13671,,,0,"Move Cinder backend passwords to passwords.yml

Move Hitachi NAS and Oracle ZFSSA passwords
to /etc/kolla/passwords.yml

Change-Id: I1c94c45701fda5430b5d5a88c719db13d1956b11
Closes-Bug: #1733565
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/17/521817/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/cinder/defaults/main.yml', 'etc/kolla/passwords.yml']",2,86a507579c65465210343b9add5366c5d3b4a4f1,bug/1733565,##################### # Hitachi NAS support ##################### hnas_iscsi_password: hnas_nfs_password: ###################### # Oracle ZFSSA support ###################### zfssa_iscsi_password: ,,11,3
openstack%2Fkolla~stable%2Focata~Ie0f99f470a419c57865eb8b0a14e465ae228c799,openstack/kolla,stable/ocata,Ie0f99f470a419c57865eb8b0a14e465ae228c799,Use separate publish jobs in periodic pipeline,MERGED,2017-12-13 02:29:01.000000000,2017-12-13 17:42:06.000000000,2017-12-13 17:42:06.000000000,"[{'_account_id': 10787}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-12-13 02:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/92900849f1f90849f49a4a41573297e3100e09f6', 'message': 'Use separate publish jobs in periodic pipeline\n\nThe secrets can not be inherited.\n\nChange-Id: Ie0f99f470a419c57865eb8b0a14e465ae228c799\n(cherry picked from commit e6036f52ed50c90e18c686267a400c1c633e3a88)\n(cherry picked from commit d3c20be74f4b603ab904e72d1b655e2534454ebb)\n'}, {'number': 2, 'created': '2017-12-13 05:01:51.000000000', 'files': ['.zuul.yaml', 'tests/playbooks/publish.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/35db3c8e0bd71573c463a92cafdfd0c674c70e58', 'message': 'Use separate publish jobs in periodic pipeline\n\nThe secrets can not be inherited.\n\nChange-Id: Ie0f99f470a419c57865eb8b0a14e465ae228c799\n(cherry picked from commit e6036f52ed50c90e18c686267a400c1c633e3a88)\n(cherry picked from commit d3c20be74f4b603ab904e72d1b655e2534454ebb)\n'}]",0,527563,35db3c8e0bd71573c463a92cafdfd0c674c70e58,9,3,2,7488,,,0,"Use separate publish jobs in periodic pipeline

The secrets can not be inherited.

Change-Id: Ie0f99f470a419c57865eb8b0a14e465ae228c799
(cherry picked from commit e6036f52ed50c90e18c686267a400c1c633e3a88)
(cherry picked from commit d3c20be74f4b603ab904e72d1b655e2534454ebb)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/63/527563/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tests/playbooks/publish.yml']",2,92900849f1f90849f49a4a41573297e3100e09f6,,, when: - publisher when: - publisher,60,34
openstack%2Fos-client-config~master~I760104d4a94f67da4677e1ecf8f47150605d4d33,openstack/os-client-config,master,I760104d4a94f67da4677e1ecf8f47150605d4d33,Updated from global requirements,MERGED,2017-11-16 11:20:01.000000000,2017-12-13 17:34:56.000000000,2017-12-13 17:34:56.000000000,"[{'_account_id': 970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-16 11:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/ce6cd6975f07bf8bdfbf7c5484eea5276272c1d4', 'message': 'Updated from global requirements\n\nChange-Id: I760104d4a94f67da4677e1ecf8f47150605d4d33\n'}, {'number': 2, 'created': '2017-12-05 03:26:22.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/eca5f69f11290c6a5e4e80899c222554aee51032', 'message': 'Updated from global requirements\n\nChange-Id: I760104d4a94f67da4677e1ecf8f47150605d4d33\n'}]",0,520472,eca5f69f11290c6a5e4e80899c222554aee51032,14,2,2,11131,,,0,"Updated from global requirements

Change-Id: I760104d4a94f67da4677e1ecf8f47150605d4d33
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/72/520472/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ce6cd6975f07bf8bdfbf7c5484eea5276272c1d4,openstack/requirements,extras>=1.0.0 # MITpython-subunit>=1.0.0 # Apache-2.0/BSDtesttools>=2.2.0 # MIT,extras>=0.0.3 # MITpython-subunit>=0.0.18 # Apache-2.0/BSDtesttools>=1.4.0 # MIT,3,3
openstack%2Fironic-python-agent~master~I27e3311accf3a113a48a73df372ed46ff50c7e22,openstack/ironic-python-agent,master,I27e3311accf3a113a48a73df372ed46ff50c7e22,Include IPA Version during heartbeat,MERGED,2016-09-02 10:51:16.000000000,2017-12-13 17:18:25.000000000,2017-12-13 17:18:24.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 7080}, {'_account_id': 8871}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13295}, {'_account_id': 20522}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 26340}]","[{'number': 1, 'created': '2016-09-02 10:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0555e2f475a6a227bbb4567eeaf852980345a775', 'message': 'Include IPA Version during node lookup\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node lookup parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 2, 'created': '2016-09-02 11:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fc7b309273e8611698ffc55712e097becaac9630', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 3, 'created': '2016-09-02 12:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d377c5459b1a40b73dc1d8a80e21cc7f9e4ef415', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 4, 'created': '2016-09-05 10:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/3ec1859b4f79a3ec47de82260e370455fc6df882', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 5, 'created': '2016-09-07 11:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e81ecafe2caef4644a0a1a4d3a421d0801832796', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 6, 'created': '2016-10-19 13:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c94e4dbcdc9c27baf588d8e7cd4d5a845034bf71', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 7, 'created': '2016-10-19 15:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/abbf91e29ba865e0d2e4591770372f93d09010fa', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 8, 'created': '2017-03-29 13:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ccd23fa5b8130ea5d810fc621a3a9478b8086495', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 9, 'created': '2017-06-12 13:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/688541b02463bb6e4ff3449ae0651b8e451ae8c3', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 10, 'created': '2017-06-12 15:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1f57b96906c9bb9e3b34da24201d8d48d97bea83', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 11, 'created': '2017-06-19 14:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/175c29530380cd0a7b8ec158a93f4d5a0e2edc55', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 12, 'created': '2017-07-10 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/695546b2a43b918e0ee5b9c7fa6a457a274504f4', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 13, 'created': '2017-07-24 16:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/00bb0a283ee1e2650dcb4820aeadc4fcef0ee049', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 14, 'created': '2017-11-28 15:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0382c10b5447bf8364d0fbf6e6a2e92a9408f756', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\n'}, {'number': 15, 'created': '2017-11-29 10:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/627a98658be37ef5dd7ee1c2b1584c455c8e78e0', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\nDepends-On: I400adba5d908b657751a83971811e8586f46c673\n'}, {'number': 16, 'created': '2017-12-06 13:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fd76823654d471a475e88ee08bf92f53d781d1bf', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\nDepends-On: I400adba5d908b657751a83971811e8586f46c673\n'}, {'number': 17, 'created': '2017-12-06 15:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5407bc96f8ef87bc73df6e4d3c71e0c8bb21ebdd', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\nDepends-On: I400adba5d908b657751a83971811e8586f46c673\n'}, {'number': 18, 'created': '2017-12-07 12:16:16.000000000', 'files': ['ironic_python_agent/tests/unit/test_ironic_api_client.py', 'releasenotes/notes/start_passing_agent_version_to_ironic-6fa8670ae0e7eb38.yaml', 'ironic_python_agent/ironic_api_client.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/903ec3ff125663ad749748dd438860ef3489e711', 'message': 'Include IPA Version during heartbeat\n\nIn order for Ironic to know what parameters can be sent to IPA commands,\nIronic needs to know which version of IPA it is talking to.  This patch\nadds a new node heartbeat parameter agent_version which will carry the IPA\nversion information to Ironic.\n\nChange-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22\nPartial-Bug: #1602265\nDepends-On: I400adba5d908b657751a83971811e8586f46c673\n'}]",46,364834,903ec3ff125663ad749748dd438860ef3489e711,80,13,18,6637,,,0,"Include IPA Version during heartbeat

In order for Ironic to know what parameters can be sent to IPA commands,
Ironic needs to know which version of IPA it is talking to.  This patch
adds a new node heartbeat parameter agent_version which will carry the IPA
version information to Ironic.

Change-Id: I27e3311accf3a113a48a73df372ed46ff50c7e22
Partial-Bug: #1602265
Depends-On: I400adba5d908b657751a83971811e8586f46c673
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/34/364834/18 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/test_ironic_api_client.py', 'ironic_python_agent/ironic_api_client.py']",2,0555e2f475a6a227bbb4567eeaf852980345a775,bug/1602265,"from ironic_python_agent import version if iface.mac_address), 'agent_version': str(version.version_info)", if iface.mac_address),7,3
openstack%2Fcharms.ceph~master~I799f87fe2178ed7d3e44f14e2fa0683f917d2f0d,openstack/charms.ceph,master,I799f87fe2178ed7d3e44f14e2fa0683f917d2f0d,Add support for object_prefix permissions,MERGED,2017-12-13 13:55:24.000000000,2017-12-13 17:16:32.000000000,2017-12-13 17:16:32.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 13:55:24.000000000', 'files': ['ceph/broker.py', 'unit_tests/test_broker.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/d94dc3e7b93ed013497b0d1329480e55fd7dc077', 'message': 'Add support for object_prefix permissions\n\nThe grammer for ceph osd capabilities shows that permissions can\nbe applied to a pool or to a object_prefix:\n\nmatch   := [pool[=]<poolname> | object_prefix <prefix>]\n\nThis patch adds support for requesting object_prefix permissions on\na given set of prefixes.\n\nhttp://docs.ceph.com/docs/firefly/man/8/ceph-authtool/#osd-capabilities\n\nPartial-Bug: #1696073\n\nChange-Id: I799f87fe2178ed7d3e44f14e2fa0683f917d2f0d\n'}]",0,527690,d94dc3e7b93ed013497b0d1329480e55fd7dc077,6,2,1,12549,,,0,"Add support for object_prefix permissions

The grammer for ceph osd capabilities shows that permissions can
be applied to a pool or to a object_prefix:

match   := [pool[=]<poolname> | object_prefix <prefix>]

This patch adds support for requesting object_prefix permissions on
a given set of prefixes.

http://docs.ceph.com/docs/firefly/man/8/ceph-authtool/#osd-capabilities

Partial-Bug: #1696073

Change-Id: I799f87fe2178ed7d3e44f14e2fa0683f917d2f0d
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/90/527690/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph/broker.py', 'unit_tests/test_broker.py']",2,d94dc3e7b93ed013497b0d1329480e55fd7dc077,bug/1696073," @patch.object(ceph.broker, 'save_service') @patch.object(ceph.broker, 'save_group') @patch.object(ceph.broker, 'monitor_key_get') @patch.object(ceph.broker, 'update_service_permissions') def test_handle_add_permissions_to_key_obj_prefs(self, mock_update_serv_perms, mock_monitor_key_get, mock_save_group, mock_save_service): mkey = { 'cephx.services.glance': ('{""groups"": {}, ""group_names"": ' '{""rwx"": [""images""]}}'), 'cephx.groups.images': ('{""services"": [""glance"", ""cinder-ceph"", ' '""nova-compute""], ""pools"": [""glance""]}')} mock_monitor_key_get.side_effect = lambda service, key: mkey[key] expect_service_name = u'glance' expected_group = { u'services': [ u'glance', u'cinder-ceph', u'nova-compute'], u'pools': [u'glance']} expect_service_obj = { u'groups': { u'images': expected_group}, u'group_names': { u'rwx': [u'images']}, u'object_prefix_perms': { u'rwx': [u'rbd_children'], u'r': ['another']}} expect_group_namespace = None ceph.broker.handle_add_permissions_to_key( request={ u'namespace': None, u'group-permission': u'rwx', u'group': u'images', u'name': u'glance', u'object-prefix-permissions': { u'rwx': [u'rbd_children'], u'r': ['another']}, u'op': u'add-permissions-to-key'}, service='admin') mock_save_group.assert_called_once_with( group=expected_group, group_name='images') mock_save_service.assert_called_once_with( service=expect_service_obj, service_name=expect_service_name) mock_update_serv_perms.assert_called_once_with( expect_service_name, expect_service_obj, expect_group_namespace) def test_pool_permission_list_for_service_obj_pref(self): expected_group = { u'services': [ u'glance', u'cinder-ceph', u'nova-compute'], u'pools': [u'glance']} expect_service_obj = { u'groups': { u'images': expected_group}, u'group_names': { u'rwx': [u'images']}, u'object_prefix_perms': { u'rwx': [u'rbd_children'], u'r': ['another']}} self.assertEqual(ceph.broker.pool_permission_list_for_service( expect_service_obj), [ 'mon', 'allow r', 'osd', ('allow rwx pool=glance, ' 'allow r object_prefix another, ' 'allow rwx object_prefix rbd_children')]) def test_pool_permission_list_for_glance(self): expected_group = { u'services': [ u'glance', u'cinder-ceph', u'nova-compute'], u'pools': [u'glance']} expect_service_obj = { u'groups': { u'images': expected_group}, u'group_names': { u'rwx': [u'images']}, u'object_prefix_perms': { u'class-read': [u'rbd_children']}} self.assertEqual(ceph.broker.pool_permission_list_for_service( expect_service_obj), [ 'mon', 'allow r', 'osd', ('allow rwx pool=glance, ' 'allow class-read object_prefix rbd_children')])",,107,1
openstack%2Fkolla-ansible~master~Id2079c5a491ef8691e7ad8846a5fec99e49ec4ba,openstack/kolla-ansible,master,Id2079c5a491ef8691e7ad8846a5fec99e49ec4ba,RFC: disable haproxy http mode,MERGED,2017-11-29 13:46:26.000000000,2017-12-13 17:15:56.000000000,2017-12-13 17:15:56.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 11221}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-29 13:46:26.000000000', 'files': ['ansible/roles/haproxy/templates/haproxy.cfg.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bba80acc8b78ab3a34d61b3d0b496551e5a9258e', 'message': 'RFC: disable haproxy http mode\n\nIn some cases the http mode in haproxy causes issues with api calls\n(We exeperienced this in production between horizon and neutron)\n\nSee:\nhttps://ask.openstack.org/en/question/57958/keystone-through-haproxy/\n\nChange-Id: Id2079c5a491ef8691e7ad8846a5fec99e49ec4ba\n'}]",0,523876,bba80acc8b78ab3a34d61b3d0b496551e5a9258e,9,4,1,11221,,,0,"RFC: disable haproxy http mode

In some cases the http mode in haproxy causes issues with api calls
(We exeperienced this in production between horizon and neutron)

See:
https://ask.openstack.org/en/question/57958/keystone-through-haproxy/

Change-Id: Id2079c5a491ef8691e7ad8846a5fec99e49ec4ba
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/523876/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/haproxy/templates/haproxy.cfg.j2'],1,bba80acc8b78ab3a34d61b3d0b496551e5a9258e,,, mode http,0,1
openstack%2Fopenstack-ansible-repo_server~master~I397c67a4b0166ad9f42a186f5c7137571772693a,openstack/openstack-ansible-repo_server,master,I397c67a4b0166ad9f42a186f5c7137571772693a,Remove sylinked git cache functionality,MERGED,2017-11-21 08:01:59.000000000,2017-12-13 17:14:47.000000000,2017-12-13 17:14:47.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-11-21 08:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/71870b22ba0362c01793f50933a35f9f9ffd4b07', 'message': 'Remove sylinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available,\nbut the cache will be synchronised into the container\ninstead of using bind mounts and symlinks.\n\nThis cuts down the complexity of the implementation.\n\nChange-Id: I397c67a4b0166ad9f42a186f5c7137571772693a\nDepends-On: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}, {'number': 2, 'created': '2017-11-21 08:08:53.000000000', 'files': ['tasks/repo_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/9c1859c7f98c16a6f5d480b542a986df01fd499b', 'message': 'Remove sylinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available,\nbut the cache will be synchronised into the container\ninstead of using bind mounts and symlinks.\n\nThis cuts down the complexity of the implementation.\n\nChange-Id: I397c67a4b0166ad9f42a186f5c7137571772693a\nDepends-On: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}]",1,521750,9c1859c7f98c16a6f5d480b542a986df01fd499b,13,6,2,6816,,,0,"Remove sylinked git cache functionality

Prior to zuul v3 there was a cache of all git repositories
on the host, and this functionality used a bind-mount and
symlinks to pull the cache into the repo server as a way
to cut time taken and reduce errors due to git cloning.

The cache is no longer there, so the functionality which
implements the symlink and bind-mount is being removed.

The ability to make use of a git cache is still available,
but the cache will be synchronised into the container
instead of using bind mounts and symlinks.

This cuts down the complexity of the implementation.

Change-Id: I397c67a4b0166ad9f42a186f5c7137571772693a
Depends-On: Id95ad2f01b52222a07cb0775026d941ab86cd9ab
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/50/521750/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/repo_pre_install.yml'],1,71870b22ba0362c01793f50933a35f9f9ffd4b07,git-cache," - path: ""{{ repo_git_cache_dir }}""","- name: Check if the git folder exists already stat: path: ""{{ repo_git_cache_dir }}"" register: _git_folder - name: Git service data folder setup file: path: ""{{ (_git_folder.stat.exists and _git_folder.stat.islnk) | ternary(_git_folder.stat.lnk_source, repo_git_cache_dir) }}"" state: ""directory"" owner: ""{{ repo_service_user_name }}"" group: ""{{ repo_service_group_name }}"" recurse: true ",1,13
openstack%2Fopenstack-ansible-galera_server~stable%2Focata~Ie1b3b9724dd33de1d90634166e585ecceb1f4c96,openstack/openstack-ansible-galera_server,stable/ocata,Ie1b3b9724dd33de1d90634166e585ecceb1f4c96,Implement a proper WSREP check for galera,MERGED,2017-12-13 12:22:56.000000000,2017-12-13 17:14:23.000000000,2017-12-13 17:14:23.000000000,"[{'_account_id': 538}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-13 12:22:56.000000000', 'files': ['vars/redhat-7.yml', 'templates/clustercheck.j2', 'tasks/galera_post_install.yml', 'handlers/main.yml', 'releasenotes/notes/clustecheck-9311d05fb32f13b3.yaml', 'vars/ubuntu-16.04.yml', 'templates/mysqlchk.j2', 'defaults/main.yml', 'releasenotes/notes/new_healthcheck-9e559565745defd0.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/515ab131fa27b7e66f75abb4c886b5b57ca9d41b', 'message': ""Implement a proper WSREP check for galera\n\nThe galera cluster rely on WSREP for cluster consistency. While the\ndefault MySQL monitor will allow us to know when the database node is\nminimally functional it does not provide the ability to query the node\nstate allowing loadbalancers, operators, and deployers to know a node\nis healthy prior to being allowed to accept connections. This change\nimplements the checkcluster script as provided by the fine folks at\nPercona. The implementation of this check follows the guild-lines noted\nhere [0]. With this in-place, we'll be able to convert our haproxy check\nfor the galera cluster nodes to use an HTTP check on port 9200 instead\nof the default MySQL login which will provide for a more robust and\nfault tolerant cluster.\n\n[0] https://www.percona.com/doc/percona-xtradb-cluster/LATEST/howtos/virt_sandbox.html\n\nCombined backport of:\n- https://review.openstack.org/520665\n- https://review.openstack.org/523850\n\nConflicts:\n>------handlers/main.yml\n>------tests/test-galera-server-functional.yml\n>------vars/suse-42.yml\n\nCloses-Bug: #1665667\nChange-Id: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit ed739a5243b59596455b3488471c8cd81c15acf5)\n""}]",0,527679,515ab131fa27b7e66f75abb4c886b5b57ca9d41b,7,3,1,6816,,,0,"Implement a proper WSREP check for galera

The galera cluster rely on WSREP for cluster consistency. While the
default MySQL monitor will allow us to know when the database node is
minimally functional it does not provide the ability to query the node
state allowing loadbalancers, operators, and deployers to know a node
is healthy prior to being allowed to accept connections. This change
implements the checkcluster script as provided by the fine folks at
Percona. The implementation of this check follows the guild-lines noted
here [0]. With this in-place, we'll be able to convert our haproxy check
for the galera cluster nodes to use an HTTP check on port 9200 instead
of the default MySQL login which will provide for a more robust and
fault tolerant cluster.

[0] https://www.percona.com/doc/percona-xtradb-cluster/LATEST/howtos/virt_sandbox.html

Combined backport of:
- https://review.openstack.org/520665
- https://review.openstack.org/523850

Conflicts:
>------handlers/main.yml
>------tests/test-galera-server-functional.yml
>------vars/suse-42.yml

Closes-Bug: #1665667
Change-Id: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit ed739a5243b59596455b3488471c8cd81c15acf5)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/79/527679/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'templates/clustercheck.j2', 'tasks/galera_post_install.yml', 'handlers/main.yml', 'releasenotes/notes/clustecheck-9311d05fb32f13b3.yaml', 'vars/ubuntu-16.04.yml', 'templates/mysqlchk.j2', 'defaults/main.yml', 'releasenotes/notes/new_healthcheck-9e559565745defd0.yaml']",9,515ab131fa27b7e66f75abb4c886b5b57ca9d41b,bug/1665667,"--- features: - | Galera healthcheck has been improved, and relies on an xinetd service. By default, the service is unaccessible (filtered with the no_access directive). You can override the directive by setting any xinetd valid value to ``galera_monitoring_allowed_source``. ",,191,0
openstack%2Fos-brick~stable%2Fpike~I31d72357c89db53a147c2d986a28c9c6870efad0,openstack/os-brick,stable/pike,I31d72357c89db53a147c2d986a28c9c6870efad0,Make close on luks volumes idempotent,MERGED,2017-12-12 18:28:55.000000000,2017-12-13 17:06:07.000000000,2017-12-13 17:06:07.000000000,"[{'_account_id': 4523}, {'_account_id': 4690}, {'_account_id': 9555}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 18:28:55.000000000', 'files': ['os_brick/encryptors/luks.py', 'os_brick/tests/encryptors/test_luks.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/63b881f6f08653091898cc7fd5fe1e23149390ba', 'message': ""Make close on luks volumes idempotent\n\nWhen recovering from the failure of a compute host, Nova can call\nclose on an encryptor whose state Nova can't be certain of, but which\nhasn't been created. This change makes the close operation idempotent,\nwhich allows recovery to be more robust.\n\nRelated-bug: #1724573\nChange-Id: I31d72357c89db53a147c2d986a28c9c6870efad0\n(cherry picked from commit 657ba453753581e88270b4253869b00a43b7715e)\n""}]",0,527490,63b881f6f08653091898cc7fd5fe1e23149390ba,10,6,1,4690,,,0,"Make close on luks volumes idempotent

When recovering from the failure of a compute host, Nova can call
close on an encryptor whose state Nova can't be certain of, but which
hasn't been created. This change makes the close operation idempotent,
which allows recovery to be more robust.

Related-bug: #1724573
Change-Id: I31d72357c89db53a147c2d986a28c9c6870efad0
(cherry picked from commit 657ba453753581e88270b4253869b00a43b7715e)
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/90/527490/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/encryptors/luks.py', 'os_brick/tests/encryptors/test_luks.py']",2,63b881f6f08653091898cc7fd5fe1e23149390ba,bug/1724573," attempts=3, run_as_root=True, check_exit_code=[0, 4]), attempts=3, run_as_root=True, check_exit_code=[0, 4]), check_exit_code=[0, 4], attempts=3), check_exit_code=[0, 4], attempts=3),"," attempts=3, run_as_root=True, check_exit_code=True), attempts=3, run_as_root=True, check_exit_code=True), check_exit_code=True, attempts=3), check_exit_code=True, attempts=3),",10,5
openstack%2Fpython-novaclient~master~I4bc564e548876ef4d3b30e736c0055f19c062319,openstack/python-novaclient,master,I4bc564e548876ef4d3b30e736c0055f19c062319,Optimize jobs run on novaclient,MERGED,2017-12-13 00:43:42.000000000,2017-12-13 17:05:47.000000000,2017-12-13 17:05:47.000000000,"[{'_account_id': 679}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 00:43:42.000000000', 'files': ['playbooks/legacy/novaclient-dsvm-functional-identity-v3-only/run.yaml', '.zuul.yaml', 'playbooks/legacy/novaclient-dsvm-functional-identity-v3-only/post.yaml', 'playbooks/legacy/novaclient-dsvm-functional/run.yaml', 'playbooks/legacy/novaclient-dsvm-functional/post.yaml'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ee2221f0526c4a6bed431229e363c740d07b8ee9', 'message': ""Optimize jobs run on novaclient\n\nnovaclient run 2 jobs for functional tests\n- novaclient-dsvm-functional-identity-v3-only\t(non-voting)\n- novaclient-dsvm-functional-neutron\n\nThese 2 were added when neturon and identity v3 were not default\nin devstack. Now both run as default and we do not separate job\nto run.\n\nThis commit does below changes:\n- delete the 'novaclient-dsvm-functional-neutron'\n- In 'novaclient-dsvm-functional-identity-v3-only'\n  - make 'novaclient-dsvm-functional-identity-v3-only' as voting\n  - cleanup some 'if' condition which are hardcoded true now\n  - rename 'novaclient-dsvm-functional-identity-v3-only' to 'novaclient-dsvm-functional'\n\nNOTE: this not going to backport to stable branch as they seems running\nidentity v2 and v3 in those jobs. Let's keep the same setup there.\n\nChange-Id: I4bc564e548876ef4d3b30e736c0055f19c062319\n""}]",2,527550,ee2221f0526c4a6bed431229e363c740d07b8ee9,8,5,1,8556,,,0,"Optimize jobs run on novaclient

novaclient run 2 jobs for functional tests
- novaclient-dsvm-functional-identity-v3-only	(non-voting)
- novaclient-dsvm-functional-neutron

These 2 were added when neturon and identity v3 were not default
in devstack. Now both run as default and we do not separate job
to run.

This commit does below changes:
- delete the 'novaclient-dsvm-functional-neutron'
- In 'novaclient-dsvm-functional-identity-v3-only'
  - make 'novaclient-dsvm-functional-identity-v3-only' as voting
  - cleanup some 'if' condition which are hardcoded true now
  - rename 'novaclient-dsvm-functional-identity-v3-only' to 'novaclient-dsvm-functional'

NOTE: this not going to backport to stable branch as they seems running
identity v2 and v3 in those jobs. Let's keep the same setup there.

Change-Id: I4bc564e548876ef4d3b30e736c0055f19c062319
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/50/527550/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/novaclient-dsvm-functional-identity-v3-only/run.yaml', '.zuul.yaml', 'playbooks/legacy/novaclient-dsvm-functional-identity-v3-only/post.yaml', 'playbooks/legacy/novaclient-dsvm-functional/run.yaml', 'playbooks/legacy/novaclient-dsvm-functional/post.yaml']",5,ee2221f0526c4a6bed431229e363c740d07b8ee9,,,,6,164
openstack%2Fnetworking-l2gw-tempest-plugin~master~Ic860e0e26250f84edc9ce40f92a230867acb6ed7,openstack/networking-l2gw-tempest-plugin,master,Ic860e0e26250f84edc9ce40f92a230867acb6ed7,Add a basic tempest job for the plugin,MERGED,2017-12-13 14:36:28.000000000,2017-12-13 17:02:06.000000000,2017-12-13 17:02:06.000000000,"[{'_account_id': 21626}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 14:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw-tempest-plugin/commit/038718f32b092572be6e44501526a0f63bcdf50d', 'message': 'Add a basic tempest job for the plugin\n\nNative Zuul v3 job.\n\nChange-Id: Ic860e0e26250f84edc9ce40f92a230867acb6ed7\n'}, {'number': 2, 'created': '2017-12-13 14:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw-tempest-plugin/commit/92e808efa1195e252141f7e555e1ebb78d7c2a37', 'message': 'Add a basic tempest job for the plugin\n\nNative Zuul v3 job.\n\nChange-Id: Ic860e0e26250f84edc9ce40f92a230867acb6ed7\n'}, {'number': 3, 'created': '2017-12-13 15:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw-tempest-plugin/commit/c9c4019a198c3dae215097ae4ea1b38e1c7435a2', 'message': 'Add a basic tempest job for the plugin\n\nNative Zuul v3 job.\n\nChange-Id: Ic860e0e26250f84edc9ce40f92a230867acb6ed7\n'}, {'number': 4, 'created': '2017-12-13 15:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw-tempest-plugin/commit/c7e4ff240cb4b3cc17dca3651a314ecc7fc9c37d', 'message': 'Add a basic tempest job for the plugin\n\nNative Zuul v3 job.\n\nChange-Id: Ic860e0e26250f84edc9ce40f92a230867acb6ed7\n'}, {'number': 5, 'created': '2017-12-13 15:31:32.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-l2gw-tempest-plugin/commit/334b680ce07b9e06e6d608f306a1b1dc1615f6dd', 'message': 'Add a basic tempest job for the plugin\n\nNative Zuul v3 job.\n\nChange-Id: Ic860e0e26250f84edc9ce40f92a230867acb6ed7\n'}]",1,527698,334b680ce07b9e06e6d608f306a1b1dc1615f6dd,13,2,5,10459,,,0,"Add a basic tempest job for the plugin

Native Zuul v3 job.

Change-Id: Ic860e0e26250f84edc9ce40f92a230867acb6ed7
",git fetch https://review.opendev.org/openstack/networking-l2gw-tempest-plugin refs/changes/98/527698/4 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,038718f32b092572be6e44501526a0f63bcdf50d,fix_plugin,- project: name: openstack/networking-l2gw-tempest-plugin check: jobs: - networking-l2gw-tempest gate: jobs: - networking-l2gw-tempest - job: name: networking-l2gw-tempest description: | Run Tempest tests from the newtorking-l2gw Tempest plugin parent: devstack-tempest required-projects: - openstack/networking-l2gw - openstack/networking-l2gw-tempest-plugin vars: tempest_test_regex: 'networking_l2gw_tempest_plugin' tox_venvlist: 'all' devstack_localrc: NETWORKING_L2GW_SERVICE_DRIVER: 'L2GW:l2gw:networking_l2gw.services.l2gateway.service_drivers.L2gwDriver:default' TEMPEST_PLUGINS: '/opt/stack/neutron-tempest-plugin /opt/stack/networking-l2gw-tempest-plugin' devstack_plugins: networing-l2gw: 'git://git.openstack.org/openstack/networking-l2gw' devstack_services: l2gw-plugin: true irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tox.ini$ ,,34,0
openstack%2Fceilometer~stable%2Focata~Ibea7049f9fca0783b9ecf54a75bccbc27aef2187,openstack/ceilometer,stable/ocata,Ibea7049f9fca0783b9ecf54a75bccbc27aef2187,Exclude keystonemiddleware 4.19.0,MERGED,2017-12-08 18:27:07.000000000,2017-12-13 17:01:48.000000000,2017-12-13 17:01:48.000000000,"[{'_account_id': 6537}, {'_account_id': 10311}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 18:27:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6385f71437abfb2d21b762fdf057b8077bd3dbbe', 'message': 'Exclude keystonemiddleware 4.19.0\n\nkeystonemiddleware 4.19.0 introduced a dependency on memcache and\npulled in dogpile.cache and oslo.cache, causing gate failures.\nFuture versions of keystonemiddleware should be fixed by\ncommit 0c5070a035ca2eea200c5a7ab6b40375498463ac in that repo.\n\nNote that in Queens and beyond the requirement for keystonemiddleware\nhas been removed from Ceilometer, so this fix cannot be placed on\nthe master branch.\n\nChange-Id: Ibea7049f9fca0783b9ecf54a75bccbc27aef2187\n'}]",0,526749,6385f71437abfb2d21b762fdf057b8077bd3dbbe,8,3,1,10311,,,0,"Exclude keystonemiddleware 4.19.0

keystonemiddleware 4.19.0 introduced a dependency on memcache and
pulled in dogpile.cache and oslo.cache, causing gate failures.
Future versions of keystonemiddleware should be fixed by
commit 0c5070a035ca2eea200c5a7ab6b40375498463ac in that repo.

Note that in Queens and beyond the requirement for keystonemiddleware
has been removed from Ceilometer, so this fix cannot be placed on
the master branch.

Change-Id: Ibea7049f9fca0783b9ecf54a75bccbc27aef2187
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/49/526749/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6385f71437abfb2d21b762fdf057b8077bd3dbbe,,"keystonemiddleware!=4.19.0,!=4.1.0,>=4.0.0 # Apache-2.0","keystonemiddleware!=4.1.0,>=4.0.0 # Apache-2.0",1,1
openstack%2Frpm-packaging~master~I50554e9c58815df294c3466342bbd4cc8b4520f6,openstack/rpm-packaging,master,I50554e9c58815df294c3466342bbd4cc8b4520f6,Update python-heatclient to 1.13.0,MERGED,2017-12-07 08:23:00.000000000,2017-12-13 17:01:46.000000000,2017-12-13 17:01:46.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-07 08:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e4658908242476cd15326d19741068d5b37997c8', 'message': 'Update python-heatclient to 1.13.0\n\nChange-Id: I50554e9c58815df294c3466342bbd4cc8b4520f6\n'}, {'number': 2, 'created': '2017-12-07 16:35:06.000000000', 'files': ['openstack/python-heatclient/python-heatclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d96199b9467f3758d0861cb6caee659903c95772', 'message': 'Update python-heatclient to 1.13.0\n\nDepends-on: I006443ad7fa0df4adfc2945ee8fffdc4235c2603\nChange-Id: I50554e9c58815df294c3466342bbd4cc8b4520f6\n'}]",0,526310,d96199b9467f3758d0861cb6caee659903c95772,16,6,2,17130,,,0,"Update python-heatclient to 1.13.0

Depends-on: I006443ad7fa0df4adfc2945ee8fffdc4235c2603
Change-Id: I50554e9c58815df294c3466342bbd4cc8b4520f6
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/10/526310/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-heatclient/python-heatclient.spec.j2'],1,e4658908242476cd15326d19741068d5b37997c8,python-heatclient,Version: 1.13.0,Version: 1.12.0,1,1
openstack%2Frpm-packaging~master~Ic92069440080f5d83d8646c69d79a8f76a4c5ee1,openstack/rpm-packaging,master,Ic92069440080f5d83d8646c69d79a8f76a4c5ee1,Update python-senlinclient to 1.5.0,MERGED,2017-12-07 16:33:13.000000000,2017-12-13 17:01:45.000000000,2017-12-13 17:01:45.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-07 16:33:13.000000000', 'files': ['openstack/python-senlinclient/python-senlinclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/11d0d6072c978967f3a538a8f3660bf142878cc0', 'message': 'Update python-senlinclient to 1.5.0\n\nDepends-on: I6f2078ce198d0d896162e7c8ccfb900f1bfdd518\nChange-Id: Ic92069440080f5d83d8646c69d79a8f76a4c5ee1\n'}]",0,526454,11d0d6072c978967f3a538a8f3660bf142878cc0,12,6,1,17130,,,0,"Update python-senlinclient to 1.5.0

Depends-on: I6f2078ce198d0d896162e7c8ccfb900f1bfdd518
Change-Id: Ic92069440080f5d83d8646c69d79a8f76a4c5ee1
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/54/526454/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-senlinclient/python-senlinclient.spec.j2'],1,11d0d6072c978967f3a538a8f3660bf142878cc0,python-senlinclient,Version: 1.5.0,Version: 1.4.0,1,1
openstack%2Fnetworking-ovn~stable%2Fpike~Ic3c97a67bc51033bbb274322cbe787f8767064b3,openstack/networking-ovn,stable/pike,Ic3c97a67bc51033bbb274322cbe787f8767064b3,Zuul: add file extension to playbook path,ABANDONED,2017-12-13 10:25:06.000000000,2017-12-13 16:57:37.000000000,,"[{'_account_id': 1}, {'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 10:25:06.000000000', 'files': ['zuul.d/legacy-networking-ovn-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0a92d74926b606af80c74317719bc692f4bbfd44', 'message': 'Zuul: add file extension to playbook path\n\nZuul now supports including the file extension on the playbook path\nand omitting the extension is now deprecrated.  Update references\nto include the extension.\n\nConflicts:\n    zuul.d/legacy-networking-ovn-jobs.yaml\n\nChange-Id: Ic3c97a67bc51033bbb274322cbe787f8767064b3\n(cherry picked from commit 14887c799695cebc3d8d7c686db37733bba839d7)\n'}]",0,527662,0a92d74926b606af80c74317719bc692f4bbfd44,6,3,1,23804,,,0,"Zuul: add file extension to playbook path

Zuul now supports including the file extension on the playbook path
and omitting the extension is now deprecrated.  Update references
to include the extension.

Conflicts:
    zuul.d/legacy-networking-ovn-jobs.yaml

Change-Id: Ic3c97a67bc51033bbb274322cbe787f8767064b3
(cherry picked from commit 14887c799695cebc3d8d7c686db37733bba839d7)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/62/527662/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/legacy-networking-ovn-jobs.yaml'],1,0a92d74926b606af80c74317719bc692f4bbfd44,zuulv3-paths, run: playbooks/legacy/grenade-dsvm-networking-ovn/run.yaml post-run: playbooks/legacy/grenade-dsvm-networking-ovn/post.yaml run: playbooks/legacy/install-dsvm-networking-ovn-kuryr/run.yaml post-run: playbooks/legacy/install-dsvm-networking-ovn-kuryr/post.yaml run: playbooks/legacy/networking-ovn-dsvm-functional/run.yaml post-run: playbooks/legacy/networking-ovn-dsvm-functional/post.yaml run: playbooks/legacy/networking-ovn-dsvm-functional-py35/run.yaml post-run: playbooks/legacy/networking-ovn-dsvm-functional-py35/post.yaml run: playbooks/legacy/rally-dsvm-networking-ovn/run.yaml post-run: playbooks/legacy/rally-dsvm-networking-ovn/post.yaml run: playbooks/legacy/tempest-dsvm-networking-ovn-multinode/run.yaml post-run: playbooks/legacy/tempest-dsvm-networking-ovn-multinode/post.yaml run: playbooks/legacy/tempest-dsvm-networking-ovn-neutron-api-ovs-release/run.yaml post-run: playbooks/legacy/tempest-dsvm-networking-ovn-neutron-api-ovs-release/post.yaml run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master/run.yaml post-run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master/post.yaml run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master-python3/run.yaml post-run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master-python3/post.yaml run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-release/run.yaml post-run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-release/post.yaml, run: playbooks/legacy/grenade-dsvm-networking-ovn/run post-run: playbooks/legacy/grenade-dsvm-networking-ovn/post run: playbooks/legacy/install-dsvm-networking-ovn-kuryr/run post-run: playbooks/legacy/install-dsvm-networking-ovn-kuryr/post run: playbooks/legacy/networking-ovn-dsvm-functional/run post-run: playbooks/legacy/networking-ovn-dsvm-functional/post run: playbooks/legacy/networking-ovn-dsvm-functional-py35/run post-run: playbooks/legacy/networking-ovn-dsvm-functional-py35/post run: playbooks/legacy/rally-dsvm-networking-ovn/run post-run: playbooks/legacy/rally-dsvm-networking-ovn/post run: playbooks/legacy/tempest-dsvm-networking-ovn-multinode/run post-run: playbooks/legacy/tempest-dsvm-networking-ovn-multinode/post run: playbooks/legacy/tempest-dsvm-networking-ovn-neutron-api-ovs-release/run post-run: playbooks/legacy/tempest-dsvm-networking-ovn-neutron-api-ovs-release/post run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master/run post-run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master/post run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master-python3/run post-run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-master-python3/post run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-release/run post-run: playbooks/legacy/tempest-dsvm-networking-ovn-ovs-release/post,20,20
openstack%2Fsahara-image-elements~master~Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027,openstack/sahara-image-elements,master,Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027,Adding Spark 2.2.0,MERGED,2017-12-06 18:11:14.000000000,2017-12-13 16:54:32.000000000,2017-12-13 16:54:32.000000000,"[{'_account_id': 7213}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 22689}, {'_account_id': 23078}]","[{'number': 1, 'created': '2017-12-06 18:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/40a16ca7eec2874813bf5db02955080cd55c7fe0', 'message': 'Adding Spark 2.2.0\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 2, 'created': '2017-12-07 18:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/6b8793cc82a008d1ca79a4b425ff944d257030b4', 'message': 'Adding Spark 2.2\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 3, 'created': '2017-12-07 19:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/684f44f46251bc2130e5e9de24e69294cad63526', 'message': 'Adding Spark 2.2\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 4, 'created': '2017-12-07 19:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/b296e759158ef2c26e0d3c42a83dc54d27773999', 'message': 'Adding Spark 2.2.0\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 5, 'created': '2017-12-08 02:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/2ffb09025569c04b888c0f7b7de74dda22f2c9ba', 'message': 'Adding Spark 2.2.0\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 6, 'created': '2017-12-08 09:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/12e48e89751e0c50a6b6acb42ae019649aa3b7fc', 'message': 'Adding Spark 2.2.0\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 7, 'created': '2017-12-13 12:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/55cdab44710c3b64a45cfe4cdb86424c8d3f023b', 'message': 'Adding Spark 2.2.0\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}, {'number': 8, 'created': '2017-12-13 12:56:01.000000000', 'files': ['diskimage-create/README.rst', 'elements/spark/root.d/50-download-spark', 'diskimage-create/diskimage-create.sh'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/05085a81dbfbde23ba16334bf60119e8a73ff431', 'message': 'Adding Spark 2.2.0\n\nAdding newest version of spark.\n\nChange-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027\n'}]",2,526135,05085a81dbfbde23ba16334bf60119e8a73ff431,27,6,8,8932,,,0,"Adding Spark 2.2.0

Adding newest version of spark.

Change-Id: Ib2894d5d93d3ecfd17e0fb1eba4d687a97406027
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/35/526135/8 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage-create/README.rst', 'diskimage-create/diskimage-create.sh']",2,40a16ca7eec2874813bf5db02955080cd55c7fe0,sparkv220,"DIB_DEFAULT_SPARK_VERSION=""2.2.0"" echo "" [-s 1.3.1|1.6.0|2.1.0|2.2.0]"" ""1.3.1"" | ""1.6.0"" | ""2.1.0"" | ""2.2.0"");;########################### # Images for Spark plugin # ########################### export DIB_RELEASE=${DIB_RELEASE:-xenial}","DIB_DEFAULT_SPARK_VERSION=""2.1.0"" echo "" [-s 1.3.1|1.6.0|2.1.0]"" ""1.3.1"" | ""1.6.0"" | ""2.1.0"");;########################## # Image for Spark plugin # ########################## export DIB_RELEASE=${DIB_RELEASE:-trusty}",9,9
openstack%2Fnova~master~Ibf9aa3f522e87c026d5a7ad9c398c13752a29fef,openstack/nova,master,Ibf9aa3f522e87c026d5a7ad9c398c13752a29fef,trivial: more suitable log in set_admin_password,MERGED,2017-12-08 04:13:56.000000000,2017-12-13 16:53:43.000000000,2017-12-13 07:18:44.000000000,"[{'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 19944}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-12-08 04:13:56.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca1a929eaf698a8c74424705654437e8d93ac952', 'message': 'trivial: more suitable log in set_admin_password\n\nWe support to change passwd of both Windows and Linux.\nSo ""Admin password"" is preferable to ""Root password""\nin the log.\n\nChange-Id: Ibf9aa3f522e87c026d5a7ad9c398c13752a29fef\nSigned-off-by: Chen Hanxiao <chenhx@certusnet.com.cn>\n'}]",0,526592,ca1a929eaf698a8c74424705654437e8d93ac952,32,16,1,19944,,,0,"trivial: more suitable log in set_admin_password

We support to change passwd of both Windows and Linux.
So ""Admin password"" is preferable to ""Root password""
in the log.

Change-Id: Ibf9aa3f522e87c026d5a7ad9c398c13752a29fef
Signed-off-by: Chen Hanxiao <chenhx@certusnet.com.cn>
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/526592/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,ca1a929eaf698a8c74424705654437e8d93ac952,trivial_set_admin_pass_log," LOG.info(""Admin password set"", instance=instance)"," LOG.info(""Root password set"", instance=instance)",1,1
openstack%2Frpm-packaging~master~I6fb6e1933231b560ae429ac67b2eccca2f52141a,openstack/rpm-packaging,master,I6fb6e1933231b560ae429ac67b2eccca2f52141a,Update monasca-common to 2.5.0,MERGED,2017-12-07 13:32:23.000000000,2017-12-13 16:53:13.000000000,2017-12-13 16:53:13.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-07 13:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/cf4a0516a3f7c37abc693bbed7ae024b096aef76', 'message': 'Update monasca-common to 2.5.0\n\nChange-Id: I6fb6e1933231b560ae429ac67b2eccca2f52141a\n'}, {'number': 2, 'created': '2017-12-07 16:33:57.000000000', 'files': ['openstack/monasca-common/monasca-common.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9dfbeb141a8e772c39016a0d44e632542f3fd61e', 'message': 'Update monasca-common to 2.5.0\n\nDepends-on: I73272fc96a8f19921629a299bfd03bdf1197826e\nChange-Id: I6fb6e1933231b560ae429ac67b2eccca2f52141a\n'}]",0,526381,9dfbeb141a8e772c39016a0d44e632542f3fd61e,17,6,2,17130,,,0,"Update monasca-common to 2.5.0

Depends-on: I73272fc96a8f19921629a299bfd03bdf1197826e
Change-Id: I6fb6e1933231b560ae429ac67b2eccca2f52141a
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/81/526381/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-common/monasca-common.spec.j2'],1,cf4a0516a3f7c37abc693bbed7ae024b096aef76,monasca-common,{% set upstream_version = upstream_version('2.5.0') %},{% set upstream_version = upstream_version('2.4.0') %},1,1
openstack%2Frpm-packaging~master~Iace5e12b59d7e9b8a82febf7030b318747770592,openstack/rpm-packaging,master,Iace5e12b59d7e9b8a82febf7030b318747770592,Update oslo.concurrency to 3.24.0,MERGED,2017-12-11 16:28:39.000000000,2017-12-13 16:52:39.000000000,2017-12-13 16:52:39.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 16:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/db5264bb37453e45ad841a32a2f6af9b5b13b888', 'message': 'Update oslo.concurrency to 3.24.0\n\nChange-Id: Iace5e12b59d7e9b8a82febf7030b318747770592\n'}, {'number': 2, 'created': '2017-12-12 15:06:39.000000000', 'files': ['openstack/oslo.concurrency/oslo.concurrency.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/485cbb162acff9eaa895bcb76a0d42f39bea36aa', 'message': 'Update oslo.concurrency to 3.24.0\n\nDepends-on: Ib8d848fdcebfe3ec9d3c2c2d9a3b89a4d052d2de\nChange-Id: Iace5e12b59d7e9b8a82febf7030b318747770592\n'}]",0,527151,485cbb162acff9eaa895bcb76a0d42f39bea36aa,13,6,2,17130,,,0,"Update oslo.concurrency to 3.24.0

Depends-on: Ib8d848fdcebfe3ec9d3c2c2d9a3b89a4d052d2de
Change-Id: Iace5e12b59d7e9b8a82febf7030b318747770592
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/51/527151/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.concurrency/oslo.concurrency.spec.j2'],1,db5264bb37453e45ad841a32a2f6af9b5b13b888,oslo-concurrency,{% set upstream_version = upstream_version('3.24.0') %},{% set upstream_version = upstream_version('3.23.0') %},1,1
openstack%2Frpm-packaging~master~I8d3cb27484c1cd3e2651b71084305d8b136bb317,openstack/rpm-packaging,master,I8d3cb27484c1cd3e2651b71084305d8b136bb317,Update taskflow to 3.0.0,MERGED,2017-12-11 16:56:59.000000000,2017-12-13 16:48:54.000000000,2017-12-13 16:48:54.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 16:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ed97137f16f95ede8741dfaedcceb7f8b2ee8821', 'message': 'Update taskflow to 2.18.0\n\nChange-Id: I8d3cb27484c1cd3e2651b71084305d8b136bb317\n'}, {'number': 2, 'created': '2017-12-12 04:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f6cf904a8969d8286f8896a977654e127fc24938', 'message': 'Update taskflow to 3.0.0\n\nChange-Id: I8d3cb27484c1cd3e2651b71084305d8b136bb317\n'}, {'number': 3, 'created': '2017-12-12 15:08:28.000000000', 'files': ['openstack/taskflow/taskflow.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e40eaa30a710caa4ad172ea75cef407909f16c8c', 'message': 'Update taskflow to 3.0.0\n\nDepends-on: Id2e4b02a41bd6182b28c1eae5c85af27d04633f1\nChange-Id: I8d3cb27484c1cd3e2651b71084305d8b136bb317\n'}]",0,527164,e40eaa30a710caa4ad172ea75cef407909f16c8c,23,6,3,17130,,,0,"Update taskflow to 3.0.0

Depends-on: Id2e4b02a41bd6182b28c1eae5c85af27d04633f1
Change-Id: I8d3cb27484c1cd3e2651b71084305d8b136bb317
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/64/527164/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/taskflow/taskflow.spec.j2'],1,ed97137f16f95ede8741dfaedcceb7f8b2ee8821,update-taskflow,Version: 2.18.0,Version: 2.17.0,1,1
openstack%2Frpm-packaging~master~Icd3fe9e5172844cf50513901b1f4c6064c409269,openstack/rpm-packaging,master,Icd3fe9e5172844cf50513901b1f4c6064c409269,Update oslo.rootwrap to 5.12.1,MERGED,2017-12-11 16:51:56.000000000,2017-12-13 16:48:53.000000000,2017-12-13 16:48:53.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 16:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c1fcfaf2b208c33890731b26e241c5d68685b2b4', 'message': 'Update oslo.rootwrap to 5.12.1\n\nChange-Id: Icd3fe9e5172844cf50513901b1f4c6064c409269\n'}, {'number': 2, 'created': '2017-12-12 15:09:34.000000000', 'files': ['openstack/oslo.rootwrap/oslo.rootwrap.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/99132b27ce5131dd6e167f81e69e1d4a6fbc1448', 'message': 'Update oslo.rootwrap to 5.12.1\n\nDepends-on: I373c436ab78a1ea52a5dcac74165723714d2373a\nChange-Id: Icd3fe9e5172844cf50513901b1f4c6064c409269\n'}]",0,527160,99132b27ce5131dd6e167f81e69e1d4a6fbc1448,13,6,2,17130,,,0,"Update oslo.rootwrap to 5.12.1

Depends-on: I373c436ab78a1ea52a5dcac74165723714d2373a
Change-Id: Icd3fe9e5172844cf50513901b1f4c6064c409269
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/60/527160/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.rootwrap/oslo.rootwrap.spec.j2'],1,c1fcfaf2b208c33890731b26e241c5d68685b2b4,oslo-rootwrap,{% set upstream_version = upstream_version('5.12.1') %},{% set upstream_version = upstream_version('5.12.0') %},1,1
openstack%2Frpm-packaging~master~I8c873489510d4156e19413b474e3d874b5c8b481,openstack/rpm-packaging,master,I8c873489510d4156e19413b474e3d874b5c8b481,Update python-neutronclient to 6.6.0,MERGED,2017-12-10 13:50:08.000000000,2017-12-13 16:48:18.000000000,2017-12-13 16:48:18.000000000,"[{'_account_id': 7102}, {'_account_id': 7613}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-10 13:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6efd1fd809b77009826c6da655db95b159dd6a3e', 'message': 'Update python-neutronclient to 6.6.0\n\nDepends-on: I0c309bf71b9664cd6595299231bed353b95ec117\nChange-Id: I8c873489510d4156e19413b474e3d874b5c8b481\n'}, {'number': 2, 'created': '2017-12-12 10:12:10.000000000', 'files': ['openstack/python-neutronclient/python-neutronclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d536cd52d03df8bb9ae61b96b57722b1b8e4d1cc', 'message': 'Update python-neutronclient to 6.6.0\n\nDepends-on: I0c309bf71b9664cd6595299231bed353b95ec117\nChange-Id: I8c873489510d4156e19413b474e3d874b5c8b481\n'}]",0,526923,d536cd52d03df8bb9ae61b96b57722b1b8e4d1cc,21,6,2,17130,,,0,"Update python-neutronclient to 6.6.0

Depends-on: I0c309bf71b9664cd6595299231bed353b95ec117
Change-Id: I8c873489510d4156e19413b474e3d874b5c8b481
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/23/526923/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-neutronclient/python-neutronclient.spec.j2'],1,6efd1fd809b77009826c6da655db95b159dd6a3e,python-neutronclient,Version: 6.6.0,Version: 6.5.0,1,1
openstack%2Fopenstack-ansible~master~Id95ad2f01b52222a07cb0775026d941ab86cd9ab,openstack/openstack-ansible,master,Id95ad2f01b52222a07cb0775026d941ab86cd9ab,Remove symlinked git cache functionality,MERGED,2017-11-21 07:58:12.000000000,2017-12-13 16:46:28.000000000,2017-12-13 16:46:28.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-11-21 07:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a09f8335c358679e39c17ef1af62de3980496ef6', 'message': 'Remove sylinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available,\nbut the cache will be synchronised into the container\ninstead of using bind mounts and symlinks.\n\nThis cuts down the complexity of the implementation.\n\nChange-Id: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}, {'number': 2, 'created': '2017-12-12 12:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cce9356148ea627e1e5737d57a8f05c8517ba744', 'message': 'Remove sylinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available\nfor deployers to use if they want to, but the cache will\nbe synchronised into the container instead of using bind\nmounts and symlinks which was the ionly method intended\nfor production use anyway.\n\nThis cuts down the complexity of the implementation.\n\nChange-Id: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}, {'number': 3, 'created': '2017-12-12 12:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b2322f0c2029e5925750cb7b066f68334ee82059', 'message': 'Remove sylinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available\nfor deployers to use if they want to, but the cache will\nbe synchronised into the container instead of using bind\nmounts and symlinks which was the ionly method intended\nfor production use anyway.\n\nThis cuts down the complexity of the implementation.\n\nNeeded-By: I397c67a4b0166ad9f42a186f5c7137571772693a\nChange-Id: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}, {'number': 4, 'created': '2017-12-12 12:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cb9b45f5d318726707fa9a18e39b0975d3b1cd15', 'message': 'Remove sylinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available\nfor deployers to use if they want to, but the cache will\nbe synchronised into the container instead of using bind\nmounts and symlinks which was the ionly method intended\nfor production use anyway.\n\nThis cuts down the complexity of the implementation.\n\nCo-Authored-By: Jean-Philippe Evrard <jean-philippe@evrard.me>\nNeeded-By: I397c67a4b0166ad9f42a186f5c7137571772693a\nChange-Id: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}, {'number': 5, 'created': '2017-12-12 16:12:27.000000000', 'files': ['playbooks/repo-build.yml', 'tests/roles/bootstrap-host/tasks/prepare_aio_config.yml', 'tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2', 'playbooks/repo-server.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3e0ef28675dca085d1ad1ba3303ad04acd30960d', 'message': 'Remove symlinked git cache functionality\n\nPrior to zuul v3 there was a cache of all git repositories\non the host, and this functionality used a bind-mount and\nsymlinks to pull the cache into the repo server as a way\nto cut time taken and reduce errors due to git cloning.\n\nThe cache is no longer there, so the functionality which\nimplements the symlink and bind-mount is being removed.\n\nThe ability to make use of a git cache is still available\nfor deployers to use if they want to, but the cache will\nbe synchronised into the container instead of using bind\nmounts and symlinks which was the ionly method intended\nfor production use anyway.\n\nThis cuts down the complexity of the implementation.\n\nCo-Authored-By: Jean-Philippe Evrard <jean-philippe@evrard.me>\nNeeded-By: I397c67a4b0166ad9f42a186f5c7137571772693a\nChange-Id: Id95ad2f01b52222a07cb0775026d941ab86cd9ab\n'}]",1,521749,3e0ef28675dca085d1ad1ba3303ad04acd30960d,24,8,5,6816,,,0,"Remove symlinked git cache functionality

Prior to zuul v3 there was a cache of all git repositories
on the host, and this functionality used a bind-mount and
symlinks to pull the cache into the repo server as a way
to cut time taken and reduce errors due to git cloning.

The cache is no longer there, so the functionality which
implements the symlink and bind-mount is being removed.

The ability to make use of a git cache is still available
for deployers to use if they want to, but the cache will
be synchronised into the container instead of using bind
mounts and symlinks which was the ionly method intended
for production use anyway.

This cuts down the complexity of the implementation.

Co-Authored-By: Jean-Philippe Evrard <jean-philippe@evrard.me>
Needed-By: I397c67a4b0166ad9f42a186f5c7137571772693a
Change-Id: Id95ad2f01b52222a07cb0775026d941ab86cd9ab
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/49/521749/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/repo-build.yml', 'playbooks/repo-server.yml']",2,a09f8335c358679e39c17ef1af62de3980496ef6,git-cache,," static: no when: repo_build_git_cache is not defined or not _local_git_cache.stat.exists - include: common-tasks/os-lxc-container-setup.yml static: no vars: list_of_bind_mounts: - mount_path: ""/openstack/{{ inventory_hostname }}"" bind_dir_path: ""/var/www"" - mount_path: ""{{ repo_build_git_cache }}"" bind_dir_path: ""{{ repo_build_git_cache }}"" when: - repo_build_git_cache is defined - _local_git_cache.stat.exists",0,59
openstack%2Fpymod2pkg~master~I2ead57cc2da8118c03e93f89d983a3a12d8b10c3,openstack/pymod2pkg,master,I2ead57cc2da8118c03e93f89d983a3a12d8b10c3,Add freezer for SUSE and RDO,MERGED,2017-12-13 15:46:33.000000000,2017-12-13 16:46:05.000000000,2017-12-13 16:46:05.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 13404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 15:46:33.000000000', 'files': ['pymod2pkg/__init__.py'], 'web_link': 'https://opendev.org/openstack/pymod2pkg/commit/7347926f43de1695c1fa11b60f068c11a8c9bf55', 'message': 'Add freezer for SUSE and RDO\n\nChange-Id: I2ead57cc2da8118c03e93f89d983a3a12d8b10c3\n'}]",0,527721,7347926f43de1695c1fa11b60f068c11a8c9bf55,8,4,1,7102,,,0,"Add freezer for SUSE and RDO

Change-Id: I2ead57cc2da8118c03e93f89d983a3a12d8b10c3
",git fetch https://review.opendev.org/openstack/pymod2pkg refs/changes/21/527721/1 && git format-patch -1 --stdout FETCH_HEAD,['pymod2pkg/__init__.py'],1,7347926f43de1695c1fa11b60f068c11a8c9bf55,," 'designate', 'ec2-api', 'freezer', 'glance', 'heat', 'heat-templates', 'ironic', 'ironic-discoverd', 'ironic-inspector', 'ironic-python-agent', 'karbor', 'keystone', 'magnum', 'manila', 'masakari', 'masakari-monitors', 'mistral', 'monasca-agent', 'monasca-api', 'monasca-ceilometer', 'monasca-log-api', 'monasca-notification', 'monasca-persister', 'monasca-transform', 'murano', 'neutron', 'neutron-fwaas', 'neutron-lbaas', 'neutron-vpnaas', 'nova', 'octavia', 'rally', 'sahara', 'swift', 'Tempest', 'tripleo-common', 'trove', 'tuskar', 'vitrage', 'zaqar'], mods=['ceilometer', 'cinder', 'designate', 'freezer', 'glance',"," 'designate', 'ec2-api', 'glance', 'heat', 'heat-templates', 'ironic', 'ironic-discoverd', 'ironic-inspector', 'ironic-python-agent', 'karbor', 'keystone', 'magnum', 'manila', 'masakari', 'masakari-monitors', 'mistral', 'monasca-agent', 'monasca-api', 'monasca-ceilometer', 'monasca-log-api', 'monasca-notification', 'monasca-persister', 'monasca-transform', 'murano', 'neutron', 'neutron-fwaas', 'neutron-lbaas', 'neutron-vpnaas', 'nova', 'octavia', 'rally', 'sahara', 'swift', 'Tempest', 'tripleo-common', 'trove', 'tuskar', 'vitrage', 'zaqar'], mods=['ceilometer', 'cinder', 'designate', 'glance',",11,11
openstack%2Fmonasca-ceilometer~stable%2Focata~I24da3b0df73079e03ff3f8a210851394a31c9c25,openstack/monasca-ceilometer,stable/ocata,I24da3b0df73079e03ff3f8a210851394a31c9c25,Fix ceilosca.sh vagrant env setup,MERGED,2017-12-07 01:11:15.000000000,2017-12-13 16:45:24.000000000,2017-12-13 16:45:24.000000000,"[{'_account_id': 7052}, {'_account_id': 10311}, {'_account_id': 11580}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 01:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/922abfbc45fb5486380d5d2fb677129e4eed6c6f', 'message': 'Fix ceilosca.sh vagrant env setup\n\nmonasca-ceilometer repo now gets\ncopied into the vagrant VM, and\nlocal.conf gets updated with\nlocation and branch information,\nso that any change can be\ntested.\n\nAlso made following two changes:\n\n1.)\nFix auth_url property being set in the\nservice_credentials section.\n\n2.)\nCreate pipeline yaml with meters which\nmatch monasca_definitions yaml.\n\nChange-Id: I24da3b0df73079e03ff3f8a210851394a31c9c25\n'}, {'number': 2, 'created': '2017-12-08 23:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/4b3f027eb925f5662d88b757e87efaa68996b4fe', 'message': 'Fix ceilosca.sh vagrant env setup\n\nmonasca-ceilometer repo now gets\ncopied into the vagrant VM, and\nlocal.conf gets updated with\nlocation and branch information,\nso that any change can be\ntested.\n\nAlso made following two changes:\n\n1.)\nFix auth_url property being set in the\nservice_credentials section.\n\n2.)\nCreate pipeline yaml with meters which\nmatch monasca_definitions yaml.\n\nChange-Id: I24da3b0df73079e03ff3f8a210851394a31c9c25\n'}, {'number': 3, 'created': '2017-12-12 00:16:05.000000000', 'files': ['etc/ceilometer/ceilosca_pipeline.yaml', 'devstack/Vagrantfile', 'devstack/plugin.sh', 'devstack/ceilosca.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/2a11d2b5e2ecd01ddd739e4f7ea54becdc929df6', 'message': 'Fix ceilosca.sh vagrant env setup\n\nmonasca-ceilometer repo now gets\ncopied into the vagrant VM, and\nlocal.conf gets updated with\nlocation and branch information,\nso that any change can be\ntested.\n\nAlso made following two changes:\n\n1.)\nFix auth_url property being set in the\nservice_credentials section.\n\n2.)\nCreate pipeline yaml with meters which\nmatch monasca_definitions yaml.\n\nChange-Id: I24da3b0df73079e03ff3f8a210851394a31c9c25\n'}]",0,526245,2a11d2b5e2ecd01ddd739e4f7ea54becdc929df6,13,4,3,10311,,,0,"Fix ceilosca.sh vagrant env setup

monasca-ceilometer repo now gets
copied into the vagrant VM, and
local.conf gets updated with
location and branch information,
so that any change can be
tested.

Also made following two changes:

1.)
Fix auth_url property being set in the
service_credentials section.

2.)
Create pipeline yaml with meters which
match monasca_definitions yaml.

Change-Id: I24da3b0df73079e03ff3f8a210851394a31c9c25
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/45/526245/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ceilometer/ceilosca_pipeline.yaml', 'devstack/Vagrantfile', 'devstack/plugin.sh', 'devstack/ceilosca.sh', 'devstack/settings']",5,922abfbc45fb5486380d5d2fb677129e4eed6c6f,catch-up-to-newton,CEILOSCA_CONF_FILES='ceilosca_pipeline.yaml:pipeline.yaml monasca_field_definitions.yaml',CEILOSCA_CONF_FILES='monasca_pipeline.yaml:pipeline.yaml monasca_field_definitions.yaml',68,4
openstack%2Fdragonflow~master~I1993f50e1dc69ed6d8a250f953deab7bc7d46bea,openstack/dragonflow,master,I1993f50e1dc69ed6d8a250f953deab7bc7d46bea,Increase the maximum allowed time for list-ports,MERGED,2017-12-11 10:25:44.000000000,2017-12-13 16:40:33.000000000,2017-12-13 16:40:33.000000000,"[{'_account_id': 17880}, {'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 23235}, {'_account_id': 23766}, {'_account_id': 26131}]","[{'number': 1, 'created': '2017-12-11 10:25:44.000000000', 'files': ['rally-jobs/dragonflow.yaml'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0667728d51682f381315d5d1d8928657c12db6e4', 'message': 'Increase the maximum allowed time for list-ports\n\nThe rally job fails as the list-ports takes too long in the\nNeutronNetworks.create_and_list_ports test.\nThis is because we create 100 ports per network, while neutron create\n50 ports per network, while we have the same maximum time (15 seconds).\nAs we create double the ports neutron create, we should also set the\nmaximum allowed time to double the time.\n\nChange-Id: I1993f50e1dc69ed6d8a250f953deab7bc7d46bea\n'}]",0,527053,0667728d51682f381315d5d1d8928657c12db6e4,26,6,1,17880,,,0,"Increase the maximum allowed time for list-ports

The rally job fails as the list-ports takes too long in the
NeutronNetworks.create_and_list_ports test.
This is because we create 100 ports per network, while neutron create
50 ports per network, while we have the same maximum time (15 seconds).
As we create double the ports neutron create, we should also set the
maximum allowed time to double the time.

Change-Id: I1993f50e1dc69ed6d8a250f953deab7bc7d46bea
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/53/527053/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-jobs/dragonflow.yaml'],1,0667728d51682f381315d5d1d8928657c12db6e4,fix_rally_gate, neutron.list_ports: 30 # reduce as perf is fixed, neutron.list_ports: 15 # reduce as perf is fixed,1,1
openstack%2Fdragonflow~master~I2638d252abc19b1489d9886bde5edfaee85007e0,openstack/dragonflow,master,I2638d252abc19b1489d9886bde5edfaee85007e0,Temporarily remove failing test from fullstack,MERGED,2017-12-13 07:46:06.000000000,2017-12-13 16:40:32.000000000,2017-12-13 16:40:32.000000000,"[{'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 23235}]","[{'number': 1, 'created': '2017-12-13 07:46:06.000000000', 'files': ['dragonflow/tests/fullstack/test_apps.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6a06bbe1f6d6914118bcba5b048dc0b5f889dda9', 'message': 'Temporarily remove failing test from fullstack\n\nThe test_reconnect_of_controller test fails consistently and fails all\nthe gate jobs for dragonflow-dsvm-fullstack-etcd-zmq.\nTemporarily remove it until we investigate and find solution.\n\nChange-Id: I2638d252abc19b1489d9886bde5edfaee85007e0\nPartial-Bug: #1737889\n'}]",0,527619,6a06bbe1f6d6914118bcba5b048dc0b5f889dda9,7,3,1,17880,,,0,"Temporarily remove failing test from fullstack

The test_reconnect_of_controller test fails consistently and fails all
the gate jobs for dragonflow-dsvm-fullstack-etcd-zmq.
Temporarily remove it until we investigate and find solution.

Change-Id: I2638d252abc19b1489d9886bde5edfaee85007e0
Partial-Bug: #1737889
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/19/527619/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/tests/fullstack/test_apps.py'],1,6a06bbe1f6d6914118bcba5b048dc0b5f889dda9,bug/1737889," @testtools.skip(""bug/1737889"")",,1,0
openstack%2Fneutron-fwaas-dashboard~master~I7d4ebaf1a493e8d4452c64c820a24e84b532005f,openstack/neutron-fwaas-dashboard,master,I7d4ebaf1a493e8d4452c64c820a24e84b532005f,Imported Translations from Zanata,MERGED,2017-12-12 06:16:28.000000000,2017-12-13 16:28:10.000000000,2017-12-13 16:28:10.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 06:16:28.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas-dashboard/commit/79434afbf5847dde3c69eb8bd2df6c3763bb0dce', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I7d4ebaf1a493e8d4452c64c820a24e84b532005f\n'}]",0,527311,79434afbf5847dde3c69eb8bd2df6c3763bb0dce,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I7d4ebaf1a493e8d4452c64c820a24e84b532005f
",git fetch https://review.opendev.org/openstack/neutron-fwaas-dashboard refs/changes/11/527311/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,79434afbf5847dde3c69eb8bd2df6c3763bb0dce,zanata/translations,"""Project-Id-Version: Neutron FWaaS Dashboard Release Notes\n""""POT-Creation-Date: 2017-11-27 22:17+0000\n""""PO-Revision-Date: 2017-12-12 02:33+0000\n""msgid ""1.1.0"" msgstr ""1.1.0"" msgid """" ""A panel for FWaaS v2 is newly added. There is no specific installation "" ""process. After installing the new release of neutron-fwaas-dashboard, if "" ""FWaaS v2 API is available on your neutron deployment, the panel for FWaaS v2 "" ""will be displayed."" msgstr """" ""A panel for FWaaS v2 is newly added. There is no specific installation "" ""process. After installing the new release of neutron-fwaas-dashboard, if "" ""FWaaS v2 API is available on your Neutron deployment, the panel for FWaaS v2 "" ""will be displayed."" ","""Project-Id-Version: Neutron FWaaS Dashboard Release Notes 1.0.1\n""""POT-Creation-Date: 2017-10-04 13:59+0000\n""""PO-Revision-Date: 2017-10-04 11:50+0000\n""",17,3
openstack%2Fopenstack-ansible~master~Iea5f639dd7c8348167d0a7f8079de19ad5dcf8a8,openstack/openstack-ansible,master,Iea5f639dd7c8348167d0a7f8079de19ad5dcf8a8,Fix release-yaml-file-prep.py to include ansible-hardening,MERGED,2017-09-12 17:24:19.000000000,2017-12-13 16:25:06.000000000,2017-12-13 16:21:51.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-09-12 17:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d49778ae8b9a890bac97b988b2104b9f5f846116', 'message': ""Fix release-yaml-file-prep.py to include ansible-hardening\n\nSince openstack-ansible-security renamed to ansible-hardening we haven't\nbeen releasing/tagging ansible-hardening.\n\nThis patch changes the regex to include ansible-hardening so we will\nrelease and tag ansible-hardening as we were before.\n\nChange-Id: Iea5f639dd7c8348167d0a7f8079de19ad5dcf8a8\n""}, {'number': 2, 'created': '2017-09-12 21:49:42.000000000', 'files': ['scripts/release-yaml-file-prep.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/be2c81b47a0f80c223ba05d2946156158c1ddfb2', 'message': ""Fix release-yaml-file-prep.py to include ansible-hardening\n\nSince openstack-ansible-security renamed to ansible-hardening we haven't\nbeen releasing/tagging ansible-hardening.\n\nThis patch changes the regex to include ansible-hardening so we will\nrelease and tag ansible-hardening as we were before.\n\nChange-Id: Iea5f639dd7c8348167d0a7f8079de19ad5dcf8a8\n""}]",0,503083,be2c81b47a0f80c223ba05d2946156158c1ddfb2,71,7,2,2799,,,0,"Fix release-yaml-file-prep.py to include ansible-hardening

Since openstack-ansible-security renamed to ansible-hardening we haven't
been releasing/tagging ansible-hardening.

This patch changes the regex to include ansible-hardening so we will
release and tag ansible-hardening as we were before.

Change-Id: Iea5f639dd7c8348167d0a7f8079de19ad5dcf8a8
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/83/503083/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/release-yaml-file-prep.py'],1,d49778ae8b9a890bac97b988b2104b9f5f846116,, regex = re.compile('^.*openstack/(ansible-hardening|openstack-ansible.*)$'), regex = re.compile('^.*openstack/openstack-ansible.*$'),1,1
openstack%2Fproject-config~master~I4ef44e64a03cc3089e02343de506e0a6fd85a55c,openstack/project-config,master,I4ef44e64a03cc3089e02343de506e0a6fd85a55c,base/multinode rename #2: Rename project-config jobs,MERGED,2017-12-07 22:46:32.000000000,2017-12-13 16:25:04.000000000,2017-12-13 16:25:03.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 22:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7952dcbff3d8cadc6076f0fcb1cbe2253879e199', 'message': ""base/multinode rename #2: Rename project-config jobs\n\nWe want to rename the base and multinode integration jobs in order\nto make sure they are not mistaken by users trying to test their\nprojects. These jobs are not meant to be used outside of integration\ntesting the playbooks and roles found in project-config, zuul-jobs and\nopenstack-zuul-jobs.\n\nThis is part one of three in renaming the base and multinode\nintegration jobs. We need to:\n1) Add new jobs in openstack-zuul-jobs\n2) Make project-config use the new job names  <-- We're here\n3) Remove old jobs\n\nDepends-On: I150a0a6dacc7b8862a40f1382ea730957dea0faf\nChange-Id: I4ef44e64a03cc3089e02343de506e0a6fd85a55c\n""}, {'number': 2, 'created': '2017-12-07 23:06:12.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/516b1bb1f61b1c91fae545862061b7a80f3ddbb9', 'message': ""base/multinode rename #2: Rename project-config jobs\n\nWe want to rename the base and multinode integration jobs in order\nto make sure they are not mistaken by users trying to test their\nprojects. These jobs are not meant to be used outside of integration\ntesting the playbooks and roles found in project-config, zuul-jobs and\nopenstack-zuul-jobs.\n\nThis is part two of three in renaming the base and multinode\nintegration jobs. We need to:\n1) Add new jobs in openstack-zuul-jobs\n2) Make project-config use the new job names  <-- We're here\n3) Remove old jobs\n\nDepends-On: I150a0a6dacc7b8862a40f1382ea730957dea0faf\nChange-Id: I4ef44e64a03cc3089e02343de506e0a6fd85a55c\n""}]",0,526534,516b1bb1f61b1c91fae545862061b7a80f3ddbb9,12,4,2,9061,,,0,"base/multinode rename #2: Rename project-config jobs

We want to rename the base and multinode integration jobs in order
to make sure they are not mistaken by users trying to test their
projects. These jobs are not meant to be used outside of integration
testing the playbooks and roles found in project-config, zuul-jobs and
openstack-zuul-jobs.

This is part two of three in renaming the base and multinode
integration jobs. We need to:
1) Add new jobs in openstack-zuul-jobs
2) Make project-config use the new job names  <-- We're here
3) Remove old jobs

Depends-On: I150a0a6dacc7b8862a40f1382ea730957dea0faf
Change-Id: I4ef44e64a03cc3089e02343de506e0a6fd85a55c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/34/526534/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,7952dcbff3d8cadc6076f0fcb1cbe2253879e199,base-rename, - openstack-infra-base-integration-centos-7 - openstack-infra-base-integration-debian-jessie - openstack-infra-base-integration-fedora-26 - openstack-infra-base-integration-ubuntu-trusty - openstack-infra-base-integration-ubuntu-xenial - openstack-infra-base-integration-opensuse423 - openstack-infra-multinode-integration-centos-7 - openstack-infra-multinode-integration-debian-jessie - openstack-infra-multinode-integration-fedora-26 - openstack-infra-multinode-integration-ubuntu-trusty - openstack-infra-multinode-integration-ubuntu-xenial - openstack-infra-multinode-integration-opensuse423 - openstack-infra-base-integration-centos-7 - openstack-infra-base-integration-debian-jessie - openstack-infra-base-integration-fedora-26 - openstack-infra-base-integration-ubuntu-trusty - openstack-infra-base-integration-ubuntu-xenial - openstack-infra-base-integration-opensuse423 - openstack-infra-multinode-integration-centos-7 - openstack-infra-multinode-integration-debian-jessie - openstack-infra-multinode-integration-fedora-26 - openstack-infra-multinode-integration-ubuntu-trusty - openstack-infra-multinode-integration-ubuntu-xenial - openstack-infra-multinode-integration-opensuse423, - base-integration-centos-7 - base-integration-debian-jessie - base-integration-fedora-26 - base-integration-ubuntu-trusty - base-integration-ubuntu-xenial - base-integration-opensuse423 - multinode-integration-centos-7 - multinode-integration-debian-jessie - multinode-integration-fedora-26 - multinode-integration-ubuntu-trusty - multinode-integration-ubuntu-xenial - multinode-integration-opensuse423 - base-integration-centos-7 - base-integration-debian-jessie - base-integration-fedora-26 - base-integration-ubuntu-trusty - base-integration-ubuntu-xenial - base-integration-opensuse423 - multinode-integration-centos-7 - multinode-integration-debian-jessie - multinode-integration-fedora-26 - multinode-integration-ubuntu-trusty - multinode-integration-ubuntu-xenial - multinode-integration-opensuse423,24,24
openstack%2Fopenstack-ansible-tests~stable%2Fpike~If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899,openstack/openstack-ansible-tests,stable/pike,If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899,Allow additional parameters for ansible-lint,MERGED,2017-12-13 09:31:24.000000000,2017-12-13 16:24:47.000000000,2017-12-13 16:24:47.000000000,"[{'_account_id': 538}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-13 09:31:24.000000000', 'files': ['test-ansible-lint.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/1b8116b86c7b1fb0c77db32d75e9066f978ea133', 'message': 'Allow additional parameters for ansible-lint\n\nIn order to facilitate providing additional parameters\nto ansible-lint for any tests, we add an additional\nenvironment variable for it.\n\nWe also add the printing out of any extra parameters\ngiven to the lint test to ease troubleshooting.\n\nRelated-Bug: #1737310\nChange-Id: If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899\n(cherry picked from commit fa828752c51911646664216f1726959a022e0721)\n'}]",0,527645,1b8116b86c7b1fb0c77db32d75e9066f978ea133,7,3,1,6816,,,0,"Allow additional parameters for ansible-lint

In order to facilitate providing additional parameters
to ansible-lint for any tests, we add an additional
environment variable for it.

We also add the printing out of any extra parameters
given to the lint test to ease troubleshooting.

Related-Bug: #1737310
Change-Id: If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899
(cherry picked from commit fa828752c51911646664216f1726959a022e0721)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/45/527645/1 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-lint.sh'],1,1b8116b86c7b1fb0c77db32d75e9066f978ea133,bug/1737310-stable/pike,"export ANSIBLE_LINT_PARAMS=${ANSIBLE_LINT_PARAMS:-} echo ""TEST_PLAYBOOK: ${TEST_PLAYBOOK}"" echo ""ANSIBLE_LINT_PARAMS: ${ANSIBLE_LINT_PARAMS}""ansible-lint ${ANSIBLE_LINT_PARAMS} -R -r ${COMMON_TESTS_PATH}/ansible-lint/ ${TEST_PLAYBOOK}",ansible-lint -R -r ${COMMON_TESTS_PATH}/ansible-lint/ ${TEST_PLAYBOOK},5,1
openstack%2Fopenstack-ansible-os_neutron~master~I4e4110683182310ca662de49ca4437ca56f9ca4c,openstack/openstack-ansible-os_neutron,master,I4e4110683182310ca662de49ca4437ca56f9ca4c,Fix tempest tests,MERGED,2017-12-13 13:17:02.000000000,2017-12-13 16:22:52.000000000,2017-12-13 16:22:52.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-13 13:17:02.000000000', 'files': ['tests/test-calico-functional.yml', 'tests/os_neutron-overrides.yml', 'tests/test-dragonflow-functional.yml', 'tests/neutron-overrides-ovs.yml', 'tests/neutron-overrides-opendaylight.yml', 'tests/neutron-overrides-ovs-nsh.yml', 'tests/neutron-overrides-dragonflow.yml', 'tests/test.yml', 'tests/neutron-overrides-calico.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/3db2ebb1b6d0065cf00c0e9d539ca086d367541b', 'message': 'Fix tempest tests\n\nThe neutron plugins are now in a new repository, and therefore\nthe path to the whitelist has changed.\n\nOn top of that, the ""when:"" condition on the include playbook\nnaturally didn\'t trigger. There is no when on play(book)s!\nDue to the fact this was ignored, we were running the tempest role\ntwice for a while. It didn\'t break, because the facts were properly\ngathered, but it was suboptimal. If facts failed to gather, the\nos_tempest role that gets included in the dragonflow play would fail,\nand that would break the functional test (not only the dragonflow test).\n\nThe ""when:"" condition on plays should be removed with ansible 2.4 coming\nsoon anyway.\n\nChange-Id: I4e4110683182310ca662de49ca4437ca56f9ca4c\n'}]",2,527686,3db2ebb1b6d0065cf00c0e9d539ca086d367541b,11,6,1,17068,,,0,"Fix tempest tests

The neutron plugins are now in a new repository, and therefore
the path to the whitelist has changed.

On top of that, the ""when:"" condition on the include playbook
naturally didn't trigger. There is no when on play(book)s!
Due to the fact this was ignored, we were running the tempest role
twice for a while. It didn't break, because the facts were properly
gathered, but it was suboptimal. If facts failed to gather, the
os_tempest role that gets included in the dragonflow play would fail,
and that would break the functional test (not only the dragonflow test).

The ""when:"" condition on plays should be removed with ansible 2.4 coming
soon anyway.

Change-Id: I4e4110683182310ca662de49ca4437ca56f9ca4c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/86/527686/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test-calico-functional.yml', 'tests/os_neutron-overrides.yml', 'tests/test-dragonflow-functional.yml', 'tests/neutron-overrides-ovs.yml', 'tests/neutron-overrides-opendaylight.yml', 'tests/neutron-overrides-ovs-nsh.yml', 'tests/neutron-overrides-dragonflow.yml', 'tests/test.yml', 'tests/neutron-overrides-calico.yml']",9,3db2ebb1b6d0065cf00c0e9d539ca086d367541b,fix_tempest," - name: neutron-plugins repo: https://git.openstack.org/openstack/neutron-tempest-plugin branch: master - ""neutron_tempest_plugin.api.test_networks*""", - neutron.tests.tempest.api.test_networks*,36,12
openstack%2Fnetworking-l2gw-tempest-plugin~master~If61a5ce158f3ca68a825b02d1101e75d20d21a49,openstack/networking-l2gw-tempest-plugin,master,If61a5ce158f3ca68a825b02d1101e75d20d21a49,Fixing tempest plugin after code sync,MERGED,2017-12-12 17:06:37.000000000,2017-12-13 16:21:55.000000000,2017-12-13 16:21:55.000000000,"[{'_account_id': 1653}, {'_account_id': 9656}, {'_account_id': 10459}, {'_account_id': 21626}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 17:06:37.000000000', 'files': ['networking_l2gw_tempest_plugin/plugin.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-l2gw-tempest-plugin/commit/ccc6be910436822642e4fa1f50f4347094b9eabe', 'message': 'Fixing tempest plugin after code sync\n\n  Tempest plugin code was moved to main directory.\n  This patch updates the entrypoints.\n\nChange-Id: If61a5ce158f3ca68a825b02d1101e75d20d21a49\nSigned-off-by: Ricardo Noriega <rnoriega@redhat.com>\n'}]",0,527464,ccc6be910436822642e4fa1f50f4347094b9eabe,9,5,1,21626,,,0,"Fixing tempest plugin after code sync

  Tempest plugin code was moved to main directory.
  This patch updates the entrypoints.

Change-Id: If61a5ce158f3ca68a825b02d1101e75d20d21a49
Signed-off-by: Ricardo Noriega <rnoriega@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-l2gw-tempest-plugin refs/changes/64/527464/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_l2gw_tempest_plugin/plugin.py', 'setup.cfg']",2,ccc6be910436822642e4fa1f50f4347094b9eabe,fix_plugin, networking_l2gw_tempest_plugin = networking_l2gw_tempest_plugin.plugin:NeutronL2gwTempestPlugin, networking_l2gw_tempest_plugin = networking_l2gw_tempest_plugin.tests.tempest.plugin:NeutronL2gwTempestPlugin,2,2
openstack%2Fopenstack-ansible~master~Ia1c0a7374d8027d0f0772f393b462ee807ea2090,openstack/openstack-ansible,master,Ia1c0a7374d8027d0f0772f393b462ee807ea2090,Update test tooling for manual testing,MERGED,2017-12-11 15:47:43.000000000,2017-12-13 16:21:43.000000000,2017-12-13 16:21:43.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-11 15:47:43.000000000', 'files': ['run_tests.sh', 'bindep.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/503ba6a9705d9050010529fac0e1611c0c2d8631', 'message': 'Update test tooling for manual testing\n\nIn https://review.openstack.org/520065 the lint tests\nwere updated to make use of the tests repo for all\nlinting. This works nicely within OpenStack-CI, but\nfails when trying to do it by hand due to missing\npackages on the hosts. It also requires the tester to\ninstall some things beforehand.\n\nTo align this repo with the way the role tests run,\nwe implement the same mechanism as used in the roles\nto prep the host using the run_tests.sh script and the\nappropriate bindep entries.\n\nChange-Id: Ia1c0a7374d8027d0f0772f393b462ee807ea2090\n'}]",0,527137,503ba6a9705d9050010529fac0e1611c0c2d8631,10,6,1,6816,,,0,"Update test tooling for manual testing

In https://review.openstack.org/520065 the lint tests
were updated to make use of the tests repo for all
linting. This works nicely within OpenStack-CI, but
fails when trying to do it by hand due to missing
packages on the hosts. It also requires the tester to
install some things beforehand.

To align this repo with the way the role tests run,
we implement the same mechanism as used in the roles
to prep the host using the run_tests.sh script and the
appropriate bindep entries.

Change-Id: Ia1c0a7374d8027d0f0772f393b462ee807ea2090
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/37/527137/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'bindep.txt']",2,503ba6a9705d9050010529fac0e1611c0c2d8631,allow-tests-by-hand,# - https://docs.openstack.org/infra/bindep/ # - https://git.openstack.org/cgit/openstack-infra/bindep# The gcc compiler gcc # Base requirements for Ubuntu git-core [platform:dpkg]python2.7 [platform:dpkg] python-apt [platform:dpkg] python-dev [platform:dpkg] python3 [platform:dpkg] python3-apt [platform:dpkg] python3-dev [platform:dpkg] # Base requirements for RPM distros gcc-c++ [platform:rpm] git [platform:rpm]python-devel [platform:rpm] python2-dnf [platform:fedora] # For SELinux libselinux-python [platform:redhat] libsemanage-python [platform:redhat] # Required for compressing collected log files in CI gzip,# - http://docs.openstack.org/infra/bindep/ # - https://git.openstack.org/openstack-infra/bindep# Required for compressing collected log files in CI gzip # Requirements for Paramiko 2.0 # For selinux libselinux-python [platform:rpm],83,7
openstack%2Fmistral~master~Ife653558bfcda794e7f37086832f70b0ad7c28a4,openstack/mistral,master,Ife653558bfcda794e7f37086832f70b0ad7c28a4,Pass the new ActionContext to mistral-lib,MERGED,2017-09-21 13:54:48.000000000,2017-12-13 16:21:42.000000000,2017-12-13 16:21:42.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9408}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 19206}, {'_account_id': 21970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-21 13:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4ac9d203f98c562e66374b7603d8c1b662dd77e3', 'message': '[WIP] Pass the new ActionContext to mistral-lib\n\nI think this is going in the correct direction - but I need to figure\nout how to get the values for the ExecutionContext.\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 2, 'created': '2017-09-21 14:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1a83affe7f4d8787e32c6a5c192b4e7cb44d77f0', 'message': '[WIP] Pass the new ActionContext to mistral-lib\n\nI think this is going in the correct direction - but I need to figure\nout how to get the values for the ExecutionContext.\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 3, 'created': '2017-09-22 07:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1a8ec06caf53e8db3aefa2cef89a23ae195b0040', 'message': '[WIP] Pass the new ActionContext to mistral-lib\n\nI think this is going in the correct direction - but I need to figure\nout how to get the values for the ExecutionContext.\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 4, 'created': '2017-10-09 09:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4ef229d8dd367bcfe56d028af8541f7610c8d0c4', 'message': '[WIP] Pass the new ActionContext to mistral-lib\n\nI think this is going in the correct direction - but I need to figure\nout how to get the values for the ExecutionContext.\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 5, 'created': '2017-10-11 10:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fe825dd9f4431d4ddc6e9d34e986da3f4d63cb13', 'message': '[WIP] Pass the new ActionContext to mistral-lib\n\nI think this is going in the correct direction - but I need to figure\nout how to get the values for the ExecutionContext.\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 6, 'created': '2017-10-11 12:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/852b9e8ad8c2cffb500cc3b1296408b4fac73ae6', 'message': '[WIP] Pass the new ActionContext to mistral-lib\n\nI think this is going in the correct direction - but I need to figure\nout how to get the values for the ExecutionContext.\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 7, 'created': '2017-10-17 16:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d454f4553f8fa6c86fd8bca738e4250281bc318f', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 8, 'created': '2017-10-18 15:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3e718b7c53a76e45036d0b0b83cfeac9950809d7', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 9, 'created': '2017-10-24 14:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ccb5f6575adc0e35adcc6ca3ad9b5f9c418d0101', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 10, 'created': '2017-10-27 11:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/80b8ff98a4c7be859f611b1f40024412d6f79d0f', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: Ib879ba58d4b9a04d4f5ea668ae94d79a82758919\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 11, 'created': '2017-10-30 09:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/18dea64087c9d5fa3a60b181114c937d4c013d87', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I5ea09c3c79df5a43b06194a48f7425a15a1b23cf\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 12, 'created': '2017-11-03 08:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c25e191de81fa29cb7b987e4c6ff2de237c38de9', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I5ea09c3c79df5a43b06194a48f7425a15a1b23cf\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 13, 'created': '2017-11-06 10:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8dcb41c8741d3b2c33fa729739954db5001c41fc', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I5ea09c3c79df5a43b06194a48f7425a15a1b23cf\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 14, 'created': '2017-11-08 18:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f69460671fb393e47da3da875ab23ea080e023b0', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I5ea09c3c79df5a43b06194a48f7425a15a1b23cf\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 15, 'created': '2017-11-09 09:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/44506eb7917e60e950e993331433cafb0893d3ec', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 16, 'created': '2017-11-16 08:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e4ef81ab24e88e458f3b6d4df7ca84883fef40bb', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 17, 'created': '2017-11-20 09:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ecd6000b8994ec3bae603cced14073b502e871bc', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 18, 'created': '2017-11-27 11:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6e0f090958518a3d47e1bf2a424aaec523cd5e3e', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 19, 'created': '2017-11-29 11:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9ee261a793cf78b22cfb83305cdf02ed65d187ce', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 20, 'created': '2017-12-04 15:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/783662d8d154d0bc233d84424a8657889f4170b6', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 21, 'created': '2017-12-05 10:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d64dfe889188f3e74f1696786493cd50901773c0', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 22, 'created': '2017-12-05 14:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9c1ef06472a7d12eeca5b8180c984465b75e6703', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 23, 'created': '2017-12-07 15:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a1ddb535b5aae2ed15ce4c4e3d00db2ccaa1e72b', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}, {'number': 24, 'created': '2017-12-11 22:43:03.000000000', 'files': ['mistral/executors/base.py', 'mistral/engine/action_queue.py', 'mistral/context.py', 'mistral/tests/unit/engine/test_environment.py', 'mistral/engine/actions.py', 'mistral/executors/default_executor.py', 'mistral/executors/executor_server.py', 'mistral/rpc/clients.py', 'mistral/tests/unit/engine/test_safe_rerun.py', 'mistral/engine/default_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/dd4a4bd440ba3fc14f0da782b99d64e7b338a1e7', 'message': 'Pass the new ActionContext to mistral-lib\n\nPartial-Bug: #1718353\nDepends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b\nChange-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4\n'}]",15,506185,dd4a4bd440ba3fc14f0da782b99d64e7b338a1e7,73,11,24,9712,,,0,"Pass the new ActionContext to mistral-lib

Partial-Bug: #1718353
Depends-On: I6057d0ce3fe4ae23468be8fb06cb85dc5f467f6b
Change-Id: Ife653558bfcda794e7f37086832f70b0ad7c28a4
",git fetch https://review.opendev.org/openstack/mistral refs/changes/85/506185/10 && git format-patch -1 --stdout FETCH_HEAD,['mistral/executors/default_executor.py'],1,4ac9d203f98c562e66374b7603d8c1b662dd77e3,bug/1718353,"from mistral_lib import context as lib_context # that it expects to be passed the context. if isinstance(action, mistral_lib.Action): context = context.ctx() security_ctx = lib_ctx.SecurityContext( auth_uri=context.auth_uri, auth_cacert=context.auth_cacert, insecure=context.insecure, service_catalog=context.service_catalog, region_name=context.region_name, is_trust_scoped=context.is_trust_scoped, redelivered=context.redelivered, expires_at=context.expires_at, trust_id=context.trust_id, is_target=context.is_target) execution_ctx = lib_ctx.ExecutionContext() action_ctx = lib_ctx.ActionContext(security_ctx, execution_ctx) result = action.run(action_ctx)"," # that it expects to be passed the context. We should deprecate # the builtin action class in Mistral. if isinstance(action, mistral_lib.Action): result = action.run(context.ctx())",16,3
openstack%2Ftripleo-quickstart-extras~master~I8d9d395f98221b10847ae16ca300fbb5e8a2896d,openstack/tripleo-quickstart-extras,master,I8d9d395f98221b10847ae16ca300fbb5e8a2896d,Enable mistral on the undercloud by default,MERGED,2017-12-11 15:30:53.000000000,2017-12-13 16:10:30.000000000,2017-12-13 16:10:30.000000000,"[{'_account_id': 8175}, {'_account_id': 10969}, {'_account_id': 13039}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 15:30:53.000000000', 'files': ['roles/undercloud-deploy/README.md', 'roles/undercloud-deploy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d69e0ea30d7835a3037ad04cc38da3a9482f7060', 'message': 'Enable mistral on the undercloud by default\n\nA prior patch merged that caused a regression in newton..\n\nhttps://github.com/openstack/tripleo-quickstart-extras/commit/5c966baa20f7b700fead51a9186b4314754228fa\n\nThis commit moves the default for undercloud_enable_mistral to true\n\nChange-Id: I8d9d395f98221b10847ae16ca300fbb5e8a2896d\nCloses-Bug: #1737502\n'}]",0,527132,d69e0ea30d7835a3037ad04cc38da3a9482f7060,25,8,1,21686,,,0,"Enable mistral on the undercloud by default

A prior patch merged that caused a regression in newton..

https://github.com/openstack/tripleo-quickstart-extras/commit/5c966baa20f7b700fead51a9186b4314754228fa

This commit moves the default for undercloud_enable_mistral to true

Change-Id: I8d9d395f98221b10847ae16ca300fbb5e8a2896d
Closes-Bug: #1737502
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/32/527132/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/undercloud-deploy/README.md', 'roles/undercloud-deploy/defaults/main.yml']",2,d69e0ea30d7835a3037ad04cc38da3a9482f7060,bug/1737502,undercloud_enable_mistral: true,undercloud_enable_mistral: false,2,2
openstack%2Fopenstack-zuul-jobs~master~I150a0a6dacc7b8862a40f1382ea730957dea0faf,openstack/openstack-zuul-jobs,master,I150a0a6dacc7b8862a40f1382ea730957dea0faf,base/multinode rename #1: Add renamed jobs,MERGED,2017-12-07 22:41:56.000000000,2017-12-13 16:10:18.000000000,2017-12-13 16:10:18.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 22:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/2b107eae8bf2347b859b684591a04b51bf91c4f1', 'message': ""base/multinode rename #1: Add renamed jobs\n\nWe want to rename the base and multinode integration jobs in order\nto make sure they are not mistaken by users trying to test their\nprojects. These jobs are not meant to be used outside of integration\ntesting the playbooks and roles found in project-config, zuul-jobs and\nopenstack-zuul-jobs.\n\nThis is part one of three in renaming the base and multinode\nintegration jobs. We need to:\n1) Add new jobs in openstack-zuul-jobs        <-- We're here\n2) Make project-config use the new job names\n3) Remove old jobs\n\nChange-Id: I150a0a6dacc7b8862a40f1382ea730957dea0faf\n""}, {'number': 2, 'created': '2017-12-07 22:54:20.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/9e70662242d9fbe4a8b369fc7b2a8311b226448a', 'message': ""base/multinode rename #1: Add renamed jobs\n\nWe want to rename the base and multinode integration jobs in order\nto make sure they are not mistaken by users trying to test their\nprojects. These jobs are not meant to be used outside of integration\ntesting the playbooks and roles found in project-config, zuul-jobs and\nopenstack-zuul-jobs.\n\nThis is part one of three in renaming the base and multinode\nintegration jobs. We need to:\n1) Add new jobs in openstack-zuul-jobs        <-- We're here\n2) Make project-config use the new job names\n3) Remove old jobs\n\nChange-Id: I150a0a6dacc7b8862a40f1382ea730957dea0faf\n""}]",0,526532,9e70662242d9fbe4a8b369fc7b2a8311b226448a,10,3,2,9061,,,0,"base/multinode rename #1: Add renamed jobs

We want to rename the base and multinode integration jobs in order
to make sure they are not mistaken by users trying to test their
projects. These jobs are not meant to be used outside of integration
testing the playbooks and roles found in project-config, zuul-jobs and
openstack-zuul-jobs.

This is part one of three in renaming the base and multinode
integration jobs. We need to:
1) Add new jobs in openstack-zuul-jobs        <-- We're here
2) Make project-config use the new job names
3) Remove old jobs

Change-Id: I150a0a6dacc7b8862a40f1382ea730957dea0faf
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/32/526532/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,2b107eae8bf2347b859b684591a04b51bf91c4f1,base-rename," name: openstack-infra-base-integration description: | Runs roles that are included by default in the 'base' job in order to prevent regressions. This job should not be used outside the context of testing roles and playbooks found in project-config, zuul-jobs and openstack-zuul-jobs. parent: base-minimal required-projects: - openstack-infra/project-config roles: - zuul: openstack-infra/zuul-jobs run: tests/base.yaml files: - ^roles/configure-mirror/.* - ^roles/configure-unbound/.* - ^roles/emit-job-header/.* - ^roles/fetch-zuul-cloner/.* - ^roles/mirror-info/.* - ^roles/set-zuul-log-path-fact/.* - ^roles/use-cached-repos/.* - ^tests/.* - job: name: openstack-infra-base-integration-centos-7 parent: openstack-infra-base-integration nodeset: centos-7 - job: name: openstack-infra-base-integration-debian-jessie parent: openstack-infra-base-integration nodeset: debian-jessie - job: name: openstack-infra-base-integration-fedora-26 parent: openstack-infra-base-integration nodeset: fedora-26 - job: name: openstack-infra-base-integration-opensuse423 parent: openstack-infra-base-integration nodeset: opensuse-423 - job: name: openstack-infra-base-integration-ubuntu-trusty parent: openstack-infra-base-integration nodeset: ubuntu-trusty - job: name: openstack-infra-base-integration-ubuntu-xenial parent: openstack-infra-base-integration nodeset: ubuntu-xenial - job: name: openstack-infra-multinode-integration description: | Runs roles that are included by default in the 'multinode' job in order to prevent regressions. This job should not be used outside the context of testing roles and playbooks found in project-config, zuul-jobs and openstack-zuul-jobs. parent: base-minimal vars: ara_generate_html: true required-projects: - openstack-infra/project-config roles: - zuul: openstack-infra/zuul-jobs run: tests/multinode.yaml files: - ^roles/configure-mirror/.* - ^roles/configure-unbound/.* - ^roles/emit-job-header/.* - ^roles/fetch-zuul-cloner/.* - ^roles/mirror-info/.* - ^roles/set-zuul-log-path-fact/.* - ^roles/use-cached-repos/.* - ^roles/multi-node-bridge/.* - ^roles/multi-node-firewall/.* - ^roles/multi-node-hosts-file/.* - ^roles/multi-node-known-hosts/.* - ^tests/.* - job: name: openstack-infra-multinode-integration-centos-7 parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: centos-7 - name: secondary label: centos-7 groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: openstack-infra-multinode-integration-debian-jessie parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: debian-jessie - name: secondary label: debian-jessie groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: openstack-infra-multinode-integration-fedora-26 parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: fedora-26 - name: secondary label: fedora-26 groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: openstack-infra-multinode-integration-opensuse423 parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: opensuse-423 - name: secondary label: opensuse-423 groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: openstack-infra-multinode-integration-ubuntu-trusty parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: ubuntu-trusty - name: secondary label: ubuntu-trusty groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job: name: openstack-infra-multinode-integration-ubuntu-xenial parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: ubuntu-xenial - name: secondary label: ubuntu-xenial groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job:",,184,0
openstack%2Fironic~master~I701899928f0f780939f17aabc59eb90593ba95f0,openstack/ironic,master,I701899928f0f780939f17aabc59eb90593ba95f0,"Auto-detect the defaults for [glance]swift_{account,temp_url_key,endpoint_url}",MERGED,2017-12-07 15:24:07.000000000,2017-12-13 16:09:25.000000000,2017-12-13 16:09:25.000000000,"[{'_account_id': 6637}, {'_account_id': 9542}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 15:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f7b0994b74e81bfb04ef2f195e23c1760dd5cf51', 'message': '[WIP] Auto-detect default for [glance]swift_account\n\nChange-Id: I701899928f0f780939f17aabc59eb90593ba95f0\n'}, {'number': 2, 'created': '2017-12-08 10:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c5e1a8792b43aee3b8fe77930f7e2d317fca3ea1', 'message': ""Auto-detect the default for [glance]swift_account\n\nIn many cases, including devstack and TripleO, the swift account to use\nis based on the project_id of the 'service' project, so it makes sense\nto use it as a default.\n\nChange-Id: I701899928f0f780939f17aabc59eb90593ba95f0\n""}, {'number': 3, 'created': '2017-12-08 11:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7e3cb0002382d4a8ee278fd9ac0b52fe78bd44cd', 'message': ""Auto-detect the defaults for [glance]swift_account and swift_temp_url_key\n\nIn many cases, including devstack and TripleO, the swift account to use\nis based on the project_id of the 'service' project, so it makes sense\nto use it as a default.\n\nSimilarly, the temporary URL key can be fetches from Swift, using HEAD\non the account used to access it.\n\nIn both cases it is assumed that the same project is used by Ironic\nand Glance to access Swift. Explicit values have to be provided\notherwise.\n\nChange-Id: I701899928f0f780939f17aabc59eb90593ba95f0\n""}, {'number': 4, 'created': '2017-12-08 16:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/37b719dd0f283cca58637c91eb77ea92c6742487', 'message': ""Auto-detect the defaults for [glance]swift_account and swift_temp_url_key\n\nIn many cases, including devstack and TripleO, the swift account to use\nis based on the project_id of the 'service' project, so it makes sense\nto use it as a default.\n\nSimilarly, the temporary URL key can be fetches from Swift, using HEAD\non the account used to access it.\n\nIn both cases it is assumed that the same project is used by Ironic\nand Glance to access Swift. Explicit values have to be provided\notherwise.\n\nChange-Id: I701899928f0f780939f17aabc59eb90593ba95f0\n""}, {'number': 5, 'created': '2017-12-12 10:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8a37135e2089f886d55cdbe16c80f0fb3b4aedfe', 'message': ""Auto-detect the defaults for [glance]swift_{account,temp_url_key,endpoint_url}\n\nIn many cases, including devstack and TripleO, the swift account to use\nis based on the project_id of the 'service' project, so it makes sense\nto use it as a default.\n\nSimilarly, the temporary URL key can be fetches from Swift, using HEAD\non the account used to access it.\n\nIn both cases it is assumed that the same project is used by Ironic\nand Glance to access Swift. Explicit values have to be provided\notherwise.\n\nFinally, the endpoint URL can be fetched from the service catalog. Care\nis taken to strip the /v1/AUTH_<tenant ID> suffix.\n\nCloses-Bug: #1737714\nChange-Id: I701899928f0f780939f17aabc59eb90593ba95f0\n""}, {'number': 6, 'created': '2017-12-12 10:48:27.000000000', 'files': ['devstack/lib/ironic', 'etc/ironic/ironic.conf.sample', 'ironic/common/swift.py', 'ironic/tests/unit/common/test_swift.py', 'doc/source/install/configure-glance-swift.rst', 'releasenotes/notes/default-swift_account-b008d08e85bdf154.yaml', 'ironic/common/glance_service/v2/image_service.py', 'ironic/tests/unit/common/test_glance_service.py', 'ironic/conf/glance.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/83dd6a1c0ea0b2ec8059b90a3f7af5f2d766fef2', 'message': ""Auto-detect the defaults for [glance]swift_{account,temp_url_key,endpoint_url}\n\nIn many cases, including devstack and TripleO, the swift account to use\nis based on the project_id of the 'service' project, so it makes sense\nto use it as a default.\n\nSimilarly, the temporary URL key can be fetches from Swift, using HEAD\non the account used to access it.\n\nIn both cases it is assumed that the same project is used by Ironic\nand Glance to access Swift. Explicit values have to be provided\notherwise.\n\nFinally, the endpoint URL can be fetched from the service catalog. Care\nis taken to strip the /v1/AUTH_<tenant ID> suffix.\n\nCloses-Bug: #1737714\nChange-Id: I701899928f0f780939f17aabc59eb90593ba95f0\n""}]",11,526429,83dd6a1c0ea0b2ec8059b90a3f7af5f2d766fef2,53,10,6,10239,,,0,"Auto-detect the defaults for [glance]swift_{account,temp_url_key,endpoint_url}

In many cases, including devstack and TripleO, the swift account to use
is based on the project_id of the 'service' project, so it makes sense
to use it as a default.

Similarly, the temporary URL key can be fetches from Swift, using HEAD
on the account used to access it.

In both cases it is assumed that the same project is used by Ironic
and Glance to access Swift. Explicit values have to be provided
otherwise.

Finally, the endpoint URL can be fetched from the service catalog. Care
is taken to strip the /v1/AUTH_<tenant ID> suffix.

Closes-Bug: #1737714
Change-Id: I701899928f0f780939f17aabc59eb90593ba95f0
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/526429/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/ironic', 'ironic/common/glance_service/v2/image_service.py']",2,f7b0994b74e81bfb04ef2f195e23c1760dd5cf51,bug/1737714,from ironic.common import swift account = CONF.glance.swift_account if not account: swift_session = swift._get_swift_session() auth_ref = swift_session.auth.get_auth_ref(swift_session) account = 'AUTH_%s' % auth_ref.project_id url_fragments['account'] = account," 'account': CONF.glance.swift_account, if (not CONF.glance.swift_account and CONF.deploy.object_store_endpoint_type == 'swift'): raise exc.MissingParameterValue(_( 'Swift temporary URLs require a Swift account string. ' 'You must provide ""swift_account"" as a config option.'))",8,9
openstack%2Fopenstack-zuul-jobs~master~I4ba3559fee979078c9748508c73bd4b900c3366a,openstack/openstack-zuul-jobs,master,I4ba3559fee979078c9748508c73bd4b900c3366a,puppet-unit-4.8: override ZUUL_BRANCH after puppet-ceph/jewel checkout,ABANDONED,2017-12-12 17:31:27.000000000,2017-12-13 16:06:36.000000000,,"[{'_account_id': 3153}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 17:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e51b25acf1c5e4a00e0c6e12a6d951a24ed07969', 'message': ""puppet-unit-4.8: override ZUUL_BRANCH after puppet-ceph/jewel checkout\n\nAfter zuul-cloning puppet-ceph / stable/jewel, we want to override\nZUUL_BRANCH to stable/pike, so all Puppet dependencies will be\ncheckouted from the right branch.\n\nIt also fix 174ecf50476d063566f43dddd77494406af920e0 where we overrided\ntoo early in the playbook, which led to checkouting stable/pike from\npuppet-ceph but it doesn't exist, so it falled back to master.\n\nChange-Id: I4ba3559fee979078c9748508c73bd4b900c3366a\n""}, {'number': 2, 'created': '2017-12-12 22:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/4fa2f9946cadd23adba2efb7b7c4442e0c6c76a3', 'message': ""puppet-unit-4.8: override ZUUL_BRANCH after puppet-ceph/jewel checkout\n\nAfter zuul-cloning puppet-ceph / stable/jewel, we want to override\nZUUL_BRANCH to stable/pike, so all Puppet dependencies will be\ncheckouted from the right branch.\n\nIt also fix 174ecf50476d063566f43dddd77494406af920e0 where we overrided\ntoo early in the playbook, which led to checkouting stable/pike from\npuppet-ceph but it doesn't exist, so it falled back to master.\n\nChange-Id: I4ba3559fee979078c9748508c73bd4b900c3366a\n""}, {'number': 3, 'created': '2017-12-13 02:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/19a6c5028e04561e804d6472668fae464823a2c8', 'message': ""puppet-unit-4.8: override ZUUL_BRANCH after puppet-ceph/jewel checkout\n\nAfter zuul-cloning puppet-ceph / stable/jewel, we want to override\nZUUL_BRANCH to stable/pike, so all Puppet dependencies will be\ncheckouted from the right branch.\n\nIt also fix 174ecf50476d063566f43dddd77494406af920e0 where we overrided\ntoo early in the playbook, which led to checkouting stable/pike from\npuppet-ceph but it doesn't exist, so it falled back to master.\n\nChange-Id: I4ba3559fee979078c9748508c73bd4b900c3366a\n""}, {'number': 4, 'created': '2017-12-13 02:30:31.000000000', 'files': ['playbooks/legacy/puppet-unit-4.8-centos-7/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e2aa3e529da2ec15af10dff1bdd9cc3462a20674', 'message': ""puppet-unit-4.8: override ZUUL_BRANCH after puppet-ceph/jewel checkout\n\nAfter zuul-cloning puppet-ceph / stable/jewel, we want to override\nZUUL_BRANCH to stable/pike, so all Puppet dependencies will be\ncheckouted from the right branch.\n\nIt also fix 174ecf50476d063566f43dddd77494406af920e0 where we overrided\ntoo early in the playbook, which led to checkouting stable/pike from\npuppet-ceph but it doesn't exist, so it falled back to master.\n\nChange-Id: I4ba3559fee979078c9748508c73bd4b900c3366a\n""}]",1,527474,e2aa3e529da2ec15af10dff1bdd9cc3462a20674,16,3,4,3153,,,0,"puppet-unit-4.8: override ZUUL_BRANCH after puppet-ceph/jewel checkout

After zuul-cloning puppet-ceph / stable/jewel, we want to override
ZUUL_BRANCH to stable/pike, so all Puppet dependencies will be
checkouted from the right branch.

It also fix 174ecf50476d063566f43dddd77494406af920e0 where we overrided
too early in the playbook, which led to checkouting stable/pike from
puppet-ceph but it doesn't exist, so it falled back to master.

Change-Id: I4ba3559fee979078c9748508c73bd4b900c3366a
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/74/527474/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/puppet-unit-4.8-centos-7/run.yaml'],1,e51b25acf1c5e4a00e0c6e12a6d951a24ed07969,fix-puppet-ceph-ci," # Workaround for puppet-ceph, where we need to checkout # dependencies from stable/pike when working on stable/jewel. # Ceph Jewel works with Newton and Pike. # Note: we override after cloning puppet-ceph, since puppet-ceph # needs to be checkouted on the real ZUUL_BRANCH. if [[ ""$ZUUL_BRANCH"" == ""stable/jewel"" ]]; then export ZUUL_BRANCH='stable/pike' fi"," ZUUL_BRANCH_REAL=${ZUUL_BRANCH:-master} # Workaround for puppet-ceph, where we need to checkout # puppet-openstack-integration from stable/pike when working on # stable/jewel. # Ceph Jewel works with Newton to Pike if [[ ""$ZUUL_BRANCH"" == ""stable/jewel"" ]]; then ZUUL_BRANCH_REAL='stable/pike' fi",8,8
openstack%2Fnova~master~Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5,openstack/nova,master,Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5,SchedulerReportClient._get_providers_in_tree,MERGED,2017-11-16 17:38:31.000000000,2017-12-13 16:04:15.000000000,2017-12-13 03:41:18.000000000,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25625}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-16 17:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b13f376aa468b8016f78c0d67058f84b77654e23', 'message': ""SchedulerReportClient._get_resource_provider_tree\n\nIntroducing SchedulerReportClient._get_resource_provider_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and returns None on any HTTP\nresponse other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 2, 'created': '2017-11-16 21:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ef5849e1b18dc8c71262cbb18d202d0d38cc5a5', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and returns None on any HTTP\nresponse other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 3, 'created': '2017-11-17 15:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e10e754ffd9ae6eb2827cbec3149b1a1357d6cb', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and returns None on any HTTP\nresponse other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 4, 'created': '2017-11-17 20:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a0f60c46ec548294292af0a63eec1ff43fbecc4', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and returns None on any HTTP\nresponse other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 5, 'created': '2017-11-28 20:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ceb1b69d6b8bef64dbb1b27444dfdfb844e89f5', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and returns None on any HTTP\nresponse other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 6, 'created': '2017-12-05 17:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cea0afb19502f0375f754d4b0b0aeed5e8bd0d00', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and returns None on any HTTP\nresponse other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 7, 'created': '2017-12-06 16:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa5248f8dc92b30148d71d6e6ead4b94d5ce92f1', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and raises an exception on any\nHTTP response other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 8, 'created': '2017-12-06 16:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16e4e2619f8308cabf940d5782f90063334dc708', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and raises an exception on any\nHTTP response other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}, {'number': 9, 'created': '2017-12-07 15:23:00.000000000', 'files': ['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/tests/functional/api/openstack/placement/test_report_client.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/108991c6b1e8521ad6b2501fe167848aa4fc3a0e', 'message': ""SchedulerReportClient._get_providers_in_tree\n\nIntroducing SchedulerReportClient._get_providers_in_tree, a private\nmethod to retrieve the list of resource providers associated with one\nprovider UUID.  Returns the empty list (not None) if there's no provider\nwith the specified UUID.  Logs an error and raises an exception on any\nHTTP response other than 200.\n\nChange-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5\nblueprint: nested-resource-providers\n""}]",17,520663,108991c6b1e8521ad6b2501fe167848aa4fc3a0e,116,21,9,14070,,,0,"SchedulerReportClient._get_providers_in_tree

Introducing SchedulerReportClient._get_providers_in_tree, a private
method to retrieve the list of resource providers associated with one
provider UUID.  Returns the empty list (not None) if there's no provider
with the specified UUID.  Logs an error and raises an exception on any
HTTP response other than 200.

Change-Id: Ifcaa1c9c0432af17ccc91a8bf0a85e37c9b00de5
blueprint: nested-resource-providers
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/520663/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/tests/functional/api/openstack/placement/test_report_client.py']",3,b13f376aa468b8016f78c0d67058f84b77654e23,bp/nested-resource-providers," rps = self.client._get_resource_provider_tree(self.compute_uuid) self.assertEqual([], rps) rps = self.client._get_resource_provider_tree(self.compute_uuid) self.assertEqual(1, len(rps))",,105,0
openstack%2Ftripleo-upgrade~master~Ie78c758c0548fbc3a15d4c41984ed5c04491833b,openstack/tripleo-upgrade,master,Ie78c758c0548fbc3a15d4c41984ed5c04491833b,Fix wrong indentation for create the custom upgrade init commands,ABANDONED,2017-12-12 15:47:53.000000000,2017-12-13 16:02:13.000000000,,"[{'_account_id': 8297}, {'_account_id': 16515}, {'_account_id': 18851}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 15:47:53.000000000', 'files': ['tasks/upgrade/create-upgrade-scripts.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/1fc859abd0c0b0a133a9937337ec64c4b1850d73', 'message': 'Fix wrong indentation for create the custom upgrade init commands\n\nChange-Id: Ie78c758c0548fbc3a15d4c41984ed5c04491833b\n'}]",0,527436,1fc859abd0c0b0a133a9937337ec64c4b1850d73,7,6,1,26343,,,0,"Fix wrong indentation for create the custom upgrade init commands

Change-Id: Ie78c758c0548fbc3a15d4c41984ed5c04491833b
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/36/527436/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/upgrade/create-upgrade-scripts.yaml'],1,1fc859abd0c0b0a133a9937337ec64c4b1850d73,merge_tripleo-upgrade,- name: create the custom upgrade init commands, - name: create the custom upgrade init commands,1,1
openstack%2Fironic~master~I400adba5d908b657751a83971811e8586f46c673,openstack/ironic,master,I400adba5d908b657751a83971811e8586f46c673,Receive and store agent version on heartbeat,MERGED,2016-09-02 11:53:25.000000000,2017-12-13 15:58:35.000000000,2017-12-13 15:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13689}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 20035}, {'_account_id': 20311}, {'_account_id': 22255}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2016-09-02 11:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cdc056306772e2650ac8eb30e845503c687d2f95', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 2, 'created': '2016-09-07 12:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e397121fa6dd08d51b98011b9a55ff7c93a97b42', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 3, 'created': '2016-09-07 13:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e6820c6dd7c34bff69aec6a21eecb34331461a7e', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 4, 'created': '2016-10-03 10:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8bad8fb064470c5d441a285b76c323e4f5d7cad7', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 5, 'created': '2017-06-12 17:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ef005f61a0003c3c8dec7bd918fa35e82a75f6e4', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 6, 'created': '2017-06-13 10:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/227055ec4cf76bcd99f3cf13b0267a7c5a178475', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 7, 'created': '2017-06-19 16:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9524e8c952e4f377e2c75ca0b54c7671503e8ae3', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 8, 'created': '2017-07-05 14:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b01ce3412e16fbfdd740f1624a5115615567ee63', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 9, 'created': '2017-07-13 14:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3094a5143771ff84bb6e390507e27311afc81481', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 10, 'created': '2017-07-24 16:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/24cce42dc406d557084dda6377754f0238c866ae', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 11, 'created': '2017-07-25 12:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/38b2954536e312cf5e4a7f78df85933add2f91a6', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 12, 'created': '2017-08-02 17:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fbed67f9ce4223e8979442958dc24faa870270a6', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 13, 'created': '2017-08-10 13:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9d7191686f4b33e875d8e3c9a455b0d29660606', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 14, 'created': '2017-11-28 14:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/512267b4462abc30db6882465335a2bd3f96e9b6', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 15, 'created': '2017-11-28 16:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0bf17824de6adbd43680cd4551a604acfaa2483', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 16, 'created': '2017-11-30 14:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ab60614f791b0e88dfd194ab3e0aa749bec20c44', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 17, 'created': '2017-12-01 14:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f88b3e3f6335a434d2f385219a874265320ed673', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 18, 'created': '2017-12-01 16:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5f1f83a982f0921ce87746938c5f6e2dc1297915', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 19, 'created': '2017-12-06 12:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8cffe4ccc72223d9e128024cb1d86c4e62b01879', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 20, 'created': '2017-12-07 12:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6d58896118281dfbcdaf3534f8348de5de4adf8e', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}, {'number': 21, 'created': '2017-12-11 16:26:04.000000000', 'files': ['api-ref/source/parameters.yaml', 'ironic/tests/unit/api/controllers/v1/test_ramdisk.py', 'ironic/tests/unit/conductor/test_rpcapi.py', 'ironic/drivers/base.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/api/controllers/v1/ramdisk.py', 'ironic/tests/unit/drivers/test_base.py', 'api-ref/source/baremetal-api-v1-misc.inc', 'doc/source/contributor/webapi-version-history.rst', 'ironic/conductor/rpcapi.py', 'ironic/tests/unit/drivers/modules/test_agent_base_vendor.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/agent_base_vendor.py', 'ironic/api/controllers/v1/versions.py', 'releasenotes/notes/heartbeat_agent_version-70f4e64b19b51d87.yaml', 'ironic/api/controllers/v1/utils.py', 'ironic/common/release_mappings.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b642f28be49f31693772231ee921ecfdbd7c80b9', 'message': 'Receive and store agent version on heartbeat\n\nThis patch enables receiving agent_version as part of heartbeat, and\nstores this information on driver_internal_info. This is so that Ironic\ncan dynamically adjust which features and parameters it uses based on\nwhich version of the agent is being used.\n\nChange-Id: I400adba5d908b657751a83971811e8586f46c673\nPartial-Bug: #1602265\n'}]",81,364861,b642f28be49f31693772231ee921ecfdbd7c80b9,195,21,21,6637,,,0,"Receive and store agent version on heartbeat

This patch enables receiving agent_version as part of heartbeat, and
stores this information on driver_internal_info. This is so that Ironic
can dynamically adjust which features and parameters it uses based on
which version of the agent is being used.

Change-Id: I400adba5d908b657751a83971811e8586f46c673
Partial-Bug: #1602265
",git fetch https://review.opendev.org/openstack/ironic refs/changes/61/364861/14 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/test_agent_base_vendor.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/agent_base_vendor.py', 'ironic/tests/unit/api/v1/test_ramdisk.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/api/controllers/v1/ramdisk.py', 'ironic/conductor/rpcapi.py']",7,cdc056306772e2650ac8eb30e845503c687d2f95,bug/1602265," def heartbeat(self, context, node_id, callback_url, topic=None, agent_version=None): callback_url=callback_url, agent_version=agent_version)"," def heartbeat(self, context, node_id, callback_url, topic=None): callback_url=callback_url)",59,14
openstack%2Fproject-config~master~Ib71241a862cf29f6e542dc1d4a2c5cd554d5d7d8,openstack/project-config,master,Ib71241a862cf29f6e542dc1d4a2c5cd554d5d7d8,Convert back to zuul.projects,MERGED,2017-12-01 04:01:06.000000000,2017-12-13 15:55:45.000000000,2017-12-13 15:55:44.000000000,"[{'_account_id': 1}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-01 04:01:06.000000000', 'files': ['roles/use-cached-repos/tasks/main.yaml', 'playbooks/release/pre.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4995f042eadef88a3bd852934ed085fcc222a1c9', 'message': 'Convert back to zuul.projects\n\nZuul has transitioned zuul.projects to a dict that mirrors\nzuul._projects.  Convert users back to zuul.projects so we can remove\nthe underscore version in zuul.\n\nChange-Id: Ib71241a862cf29f6e542dc1d4a2c5cd554d5d7d8\nDepends-On: I3c011f72933e98ccbf8badf0e9197c8659766c51\n'}]",0,524459,4995f042eadef88a3bd852934ed085fcc222a1c9,11,4,1,7118,,,0,"Convert back to zuul.projects

Zuul has transitioned zuul.projects to a dict that mirrors
zuul._projects.  Convert users back to zuul.projects so we can remove
the underscore version in zuul.

Change-Id: Ib71241a862cf29f6e542dc1d4a2c5cd554d5d7d8
Depends-On: I3c011f72933e98ccbf8badf0e9197c8659766c51
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/524459/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/use-cached-repos/tasks/main.yaml', 'playbooks/release/pre.yaml']",2,4995f042eadef88a3bd852934ed085fcc222a1c9,project-transition," with_items: ""{{ zuul.projects.values() | list }}"""," with_items: ""{{ zuul._projects.values() | list }}""",5,5
openstack%2Fproject-config~master~I062cd1d96d236c564b15ca96acb72e7f2e49f012,openstack/project-config,master,I062cd1d96d236c564b15ca96acb72e7f2e49f012,Grafana: reorder zuul graphs,MERGED,2017-12-13 15:23:58.000000000,2017-12-13 15:55:43.000000000,2017-12-13 15:55:43.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 15:23:58.000000000', 'files': ['grafana/zuul-status.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a32db95277f992b9f05eabf04dae16891a4b7738', 'message': 'Grafana: reorder zuul graphs\n\nDue to differing heights, the current layout wastes a lot of space\nat lower screen widths.  This rearranges the graphs so that the\ntaller ones are on the bottom and therefore tile better.\n\nChange-Id: I062cd1d96d236c564b15ca96acb72e7f2e49f012\n'}]",0,527714,a32db95277f992b9f05eabf04dae16891a4b7738,7,3,1,1,,,0,"Grafana: reorder zuul graphs

Due to differing heights, the current layout wastes a lot of space
at lower screen widths.  This rearranges the graphs so that the
taller ones are on the bottom and therefore tile better.

Change-Id: I062cd1d96d236c564b15ca96acb72e7f2e49f012
",git fetch https://review.opendev.org/openstack/project-config refs/changes/14/527714/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/zuul-status.yaml'],1,a32db95277f992b9f05eabf04dae16891a4b7738,," - title: Zuul Jobs Launched (per Hour) span: 4 targets: - target: alias(summarize(sumSeries(stats_counts.zuul.tenant.openstack.pipeline.*.all_jobs), '1h'), 'All Jobs') type: graph - title: Logstash Job Queue span: 4 targets: - target: alias(stats.gauges.logstash.geard.queue.running, 'Running') - target: alias(stats.gauges.logstash.geard.queue.waiting, 'Waiting') - target: alias(stats.gauges.logstash.geard.queue.total, 'Total Jobs') type: graph - title: Node Requests span: 4 targets: - target: alias(stats.gauges.zuul.nodepool.current_requests, 'Requests') type: graph - title: Zuul Job Queue span: 4 targets: - target: alias(stats.gauges.zuul.geard.queue.running, 'Running') - target: alias(stats.gauges.zuul.geard.queue.waiting, 'Waiting') - target: alias(stats.gauges.zuul.geard.queue.total, 'Total Jobs') type: graph - title: Gerrit Events (per Hour) span: 4 targets: - target: alias(summarize(stats_counts.zuul.event.gerrit.comment-added, '1h'), 'Comment added') - target: alias(summarize(stats_counts.zuul.event.gerrit.patchset-created, '1h'), 'Patchset created') - target: alias(summarize(stats_counts.zuul.event.gerrit.change-merged, '1h'), 'Change merged') type: graph"," - title: Node Requests span: 4 targets: - target: alias(stats.gauges.zuul.nodepool.current_requests, 'Requests') type: graph - title: Zuul Jobs Launched (per Hour) span: 4 targets: - target: alias(summarize(sumSeries(stats_counts.zuul.tenant.openstack.pipeline.*.all_jobs), '1h'), 'All Jobs') type: graph - title: Gerrit Events (per Hour) span: 4 targets: - target: alias(summarize(stats_counts.zuul.event.gerrit.comment-added, '1h'), 'Comment added') - target: alias(summarize(stats_counts.zuul.event.gerrit.patchset-created, '1h'), 'Patchset created') - target: alias(summarize(stats_counts.zuul.event.gerrit.change-merged, '1h'), 'Change merged') type: graph - title: Zuul Job Queue span: 4 targets: - target: alias(stats.gauges.zuul.geard.queue.running, 'Running') - target: alias(stats.gauges.zuul.geard.queue.waiting, 'Waiting') - target: alias(stats.gauges.zuul.geard.queue.total, 'Total Jobs') type: graph - title: Logstash Job Queue span: 4 targets: - target: alias(stats.gauges.logstash.geard.queue.running, 'Running') - target: alias(stats.gauges.logstash.geard.queue.waiting, 'Waiting') - target: alias(stats.gauges.logstash.geard.queue.total, 'Total Jobs') type: graph",31,31
openstack%2Fproject-config~master~Ic25911a077b23470569de9987214889727ef291c,openstack/project-config,master,Ic25911a077b23470569de9987214889727ef291c,puppet-ceph: keep minimum jobs in project-config,MERGED,2017-12-13 15:19:06.000000000,2017-12-13 15:55:41.000000000,2017-12-13 15:55:41.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 15:19:06.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c52aad0d445a1a768afff08707647dc4e8fce3af', 'message': 'puppet-ceph: keep minimum jobs in project-config\n\n- Keep the minimum jobs in project-config\n- The rest of jobs are defined in puppet-ceph / zuul.yaml\n\nThat allows us to easily specific the job definition fo reach branch of\npuppet-ceph, which is different from other modules.\n\nChange-Id: Ic25911a077b23470569de9987214889727ef291c\n'}]",0,527710,c52aad0d445a1a768afff08707647dc4e8fce3af,7,3,1,3153,,,0,"puppet-ceph: keep minimum jobs in project-config

- Keep the minimum jobs in project-config
- The rest of jobs are defined in puppet-ceph / zuul.yaml

That allows us to easily specific the job definition fo reach branch of
puppet-ceph, which is different from other modules.

Change-Id: Ic25911a077b23470569de9987214889727ef291c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/10/527710/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,c52aad0d445a1a768afff08707647dc4e8fce3af,puppet-ceph,, - puppet-openstack-check-jobs - puppet-module-unit-jobs - puppet-beaker-jobs - puppet-beaker-jobs-xenial - puppet-openstack-integration-jobs-scenario001 - puppet-openstack-integration-jobs-scenario004,0,6
openstack%2Fopenstack-zuul-jobs~master~I9eb17646bd949c3bd84fa61f92881e9fac015de5,openstack/openstack-zuul-jobs,master,I9eb17646bd949c3bd84fa61f92881e9fac015de5,Add system-config to rspec-infra jobs,MERGED,2017-12-13 04:47:52.000000000,2017-12-13 15:51:59.000000000,2017-12-13 15:51:59.000000000,"[{'_account_id': 1}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 04:47:52.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/3eb3a03448abd3def67d7f2a1112e6c0061b249d', 'message': 'Add system-config to rspec-infra jobs\n\nThe legacy-puppet-beaker-rspec-infra and\nlegacy-puppet-beaker-rspec-centos-7-infra jobs appear to be failing\ndue to a missing system-config repository\n\nChange-Id: I9eb17646bd949c3bd84fa61f92881e9fac015de5\n'}]",0,527572,3eb3a03448abd3def67d7f2a1112e6c0061b249d,9,4,1,7118,,,0,"Add system-config to rspec-infra jobs

The legacy-puppet-beaker-rspec-infra and
legacy-puppet-beaker-rspec-centos-7-infra jobs appear to be failing
due to a missing system-config repository

Change-Id: I9eb17646bd949c3bd84fa61f92881e9fac015de5
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/72/527572/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/zuul-legacy-jobs.yaml'],1,3eb3a03448abd3def67d7f2a1112e6c0061b249d,infra-xenial, - openstack-infra/system-config,,1,0
openstack%2Fkolla-ansible~master~I059f5167be170b617a440e2e06b421f9062843a6,openstack/kolla-ansible,master,I059f5167be170b617a440e2e06b421f9062843a6,add official default cpu allocation ratio.,MERGED,2017-10-31 08:29:43.000000000,2017-12-13 15:48:20.000000000,2017-12-13 15:48:20.000000000,"[{'_account_id': 167}, {'_account_id': 1390}, {'_account_id': 8157}, {'_account_id': 19316}, {'_account_id': 20663}, {'_account_id': 21797}, {'_account_id': 22056}, {'_account_id': 22348}, {'_account_id': 22582}, {'_account_id': 26001}, {'_account_id': 26553}, {'_account_id': 26576}]","[{'number': 1, 'created': '2017-10-31 08:29:43.000000000', 'files': ['doc/source/admin/advanced-configuration.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5b266b5d58d380fde087bcf1c11f510071716088', 'message': 'add official default cpu allocation ratio.\n\nEveryone know how to override default cpu allocation ratio via it.\n\nChange-Id: I059f5167be170b617a440e2e06b421f9062843a6\n'}]",3,516553,5b266b5d58d380fde087bcf1c11f510071716088,25,12,1,26576,,,0,"add official default cpu allocation ratio.

Everyone know how to override default cpu allocation ratio via it.

Change-Id: I059f5167be170b617a440e2e06b421f9062843a6
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/53/516553/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/advanced-configuration.rst'],1,5b266b5d58d380fde087bcf1c11f510071716088,add-offical-default-cpu,If the operator wants to configure compute node cpu and ram allocation ratio cpu_allocation_ratio = 16.0,If the operator wants to configure compute node ram allocation ratio,2,1
openstack%2Ftripleo-ci~master~I3ed261e3660426e62ed608bc1bc7923f3912a508,openstack/tripleo-ci,master,I3ed261e3660426e62ed608bc1bc7923f3912a508,Use playbook from tripleo-quickstart-extras for OVB,MERGED,2017-10-19 20:54:09.000000000,2017-12-13 15:47:30.000000000,2017-12-13 15:47:30.000000000,"[{'_account_id': 8367}, {'_account_id': 8652}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-10-19 20:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c9ff8a80ace96d72bb8f0dca1f83765ab0788cd8', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I70310bf09f181bacf0fc4956cb9be61e4cb4a976\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 2, 'created': '2017-10-20 12:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ae64aedf4bf0ba5e12d477c7b0fca152291de742', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: Ia7df40e8005d4b9261caf3d15d34ff895ef99013\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 3, 'created': '2017-10-20 15:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/42fef53c2cedf633b7088fe2ac8e27883531faf0', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I70310bf09f181bacf0fc4956cb9be61e4cb4a976\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 4, 'created': '2017-10-23 12:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f1ab1daee3955eac5bd727cf974e110faf386ba7', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I70310bf09f181bacf0fc4956cb9be61e4cb4a976\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 5, 'created': '2017-10-23 13:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9bb6272080c517ed9dc5a198f78f2f1f6ad1654b', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I70310bf09f181bacf0fc4956cb9be61e4cb4a976\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 6, 'created': '2017-10-23 16:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6968640e2733da787d55d46e0b2f0525634e56a2', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I70310bf09f181bacf0fc4956cb9be61e4cb4a976\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 7, 'created': '2017-10-24 10:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e29a6d34cd0f78ed69f59616ec99603b5285aa45', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I70310bf09f181bacf0fc4956cb9be61e4cb4a976\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 8, 'created': '2017-11-01 18:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9f805032430a8b716743b3543afb2c3f073c9fa4', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I5029753a665937ae7e0c596cf23944a573c8e22f\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 9, 'created': '2017-11-12 14:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/414530d9a5398b612effb05d2d358df378676102', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I5029753a665937ae7e0c596cf23944a573c8e22f\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 10, 'created': '2017-11-20 19:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ab5c62d82eee522bcd0c00022e134047f180a16b', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: I5029753a665937ae7e0c596cf23944a573c8e22f\nDepends-On: I347de079ada7c7b82f2f7affafa97f95c8029a3f\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 11, 'created': '2017-12-07 16:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b02959b94b54fe907e398c28b74e2877dfe54912', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: Ic2f1d2d50f8a5b0e19ca93e1b9631a94be91d3c5\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 12, 'created': '2017-12-07 20:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3ee283d79731f87838a8c2da9b1afe6d2ad81d32', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: Ic2f1d2d50f8a5b0e19ca93e1b9631a94be91d3c5\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 13, 'created': '2017-12-11 14:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f3ad7d0d1e901424f08dbf20ac02e39c6dc2ab7e', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: Ic2f1d2d50f8a5b0e19ca93e1b9631a94be91d3c5\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 14, 'created': '2017-12-11 15:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fc22385b7a0f1354bd25be6f5e022604be008267', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nDepends-On: Ic2f1d2d50f8a5b0e19ca93e1b9631a94be91d3c5\nDepends-On: I6cc171641c8390e458eb474be3479e732eb2c985\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}, {'number': 15, 'created': '2017-12-11 17:23:04.000000000', 'files': ['toci-quickstart/config/testenv/ovb.yml', 'toci_gate_test-oooq.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/473afcc755afb64e402708c833060fb65e7b4207', 'message': 'Use playbook from tripleo-quickstart-extras for OVB\n\nThis is the final step to cut over to the combined\nplaybook in tripleo-quickstart-extras, so that we can\nuse a common playbook whether there is a testenv broker\ninvolved or not.\n\nChange-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508\n'}]",1,513508,473afcc755afb64e402708c833060fb65e7b4207,134,9,15,12715,,,0,"Use playbook from tripleo-quickstart-extras for OVB

This is the final step to cut over to the combined
playbook in tripleo-quickstart-extras, so that we can
use a common playbook whether there is a testenv broker
involved or not.

Change-Id: I3ed261e3660426e62ed608bc1bc7923f3912a508
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/08/513508/1 && git format-patch -1 --stdout FETCH_HEAD,"['toci-quickstart/config/testenv/ovb.yml', 'toci_gate_test-oooq.sh']",2,c9ff8a80ace96d72bb8f0dca1f83765ab0788cd8,step-based-deploy," PLAYBOOK=""baremetal-full-deploy.yml"""," PLAYBOOK=""ovb.yml""",2,1
openstack%2Ftripleo-heat-templates~master~I7abdfdd55e38da80768c907863fa06429debf9cd,openstack/tripleo-heat-templates,master,I7abdfdd55e38da80768c907863fa06429debf9cd,Add missing keystone_domain_config,MERGED,2017-12-12 18:03:52.000000000,2017-12-13 15:47:29.000000000,2017-12-13 15:47:29.000000000,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 9914}, {'_account_id': 11589}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 18:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bb4081f45d24ce2a2047d5896b66fe31bd1d149b', 'message': 'Add missing keystone_docker_config\n\nWhen configuring the keystone LDAP integration we need to write out\ndomain configuration items using the keystone_docker_config provider.\nSince this tag was missed in the docker conversion, the configuration\nwas not actually available in the docker container.\n\nChange-Id: I7abdfdd55e38da80768c907863fa06429debf9cd\nCloses-Bug: #1737799\n'}, {'number': 2, 'created': '2017-12-12 18:06:58.000000000', 'files': ['docker/services/keystone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/40530c0e8c1bd28244db947309fe5b19010d3f4e', 'message': 'Add missing keystone_domain_config\n\nWhen configuring the keystone LDAP integration we need to write out\ndomain configuration items using the keystone_domain_config provider.\nSince this tag was missed in the docker conversion, the configuration\nwas not actually available in the docker container.\n\nChange-Id: I7abdfdd55e38da80768c907863fa06429debf9cd\nCloses-Bug: #1737799\n'}]",2,527485,40530c0e8c1bd28244db947309fe5b19010d3f4e,17,7,2,14985,,,0,"Add missing keystone_domain_config

When configuring the keystone LDAP integration we need to write out
domain configuration items using the keystone_domain_config provider.
Since this tag was missed in the docker conversion, the configuration
was not actually available in the docker container.

Change-Id: I7abdfdd55e38da80768c907863fa06429debf9cd
Closes-Bug: #1737799
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/527485/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/keystone.yaml'],1,bb4081f45d24ce2a2047d5896b66fe31bd1d149b,bug/1737799," puppet_tags: keystone_config,keystone_domain_config", puppet_tags: keystone_config,1,1
openstack%2Ftripleo-quickstart-extras~master~I08f259664c7810f3a1b1373285bfec1227144da9,openstack/tripleo-quickstart-extras,master,I08f259664c7810f3a1b1373285bfec1227144da9,Sudo fix overcloud-custom-tht-script.sh.j2,MERGED,2017-08-30 04:25:46.000000000,2017-12-13 15:47:28.000000000,2017-12-13 15:47:28.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}, {'_account_id': 26576}]","[{'number': 1, 'created': '2017-08-30 04:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/69a87c78c7ff61c04f1e8b03f8621a6fdf3cde4a', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 2, 'created': '2017-09-15 16:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f18e1c0a4aeabedcd12194d9f109eca50acc11ef', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 3, 'created': '2017-09-21 00:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2e6a8efe91766921a3cb56087dfea479edabf03f', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 4, 'created': '2017-09-21 22:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d75e6d70e39d0321b93aa365d52ade986cb1fcde', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 5, 'created': '2017-09-27 20:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/cd430f1e8a340aee90625a94d65f44571a3a910f', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 6, 'created': '2017-09-28 19:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9ed57de37c65b0b84959861212c1da6b08e9dad1', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 7, 'created': '2017-10-02 02:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/dad64db5b41d44a3b58da2a7a7df32c8868ba995', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 8, 'created': '2017-10-10 21:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1cbd0b17ad1701e28a6777205e378604504f4b26', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 9, 'created': '2017-10-26 20:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7c1bc77aa98c7a7c097ea1ba6920736cdffbf86f', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 10, 'created': '2017-11-15 23:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5c5fc2c072968b2285935ad8e40e901aff518a1f', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}, {'number': 11, 'created': '2017-12-10 20:01:27.000000000', 'files': ['roles/overcloud-prep-config/templates/overcloud-custom-tht-script.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/dc30a1e5a1fb27ed55dee7584dc9b01a1c6caddf', 'message': 'Sudo fix overcloud-custom-tht-script.sh.j2\n\nUsing overcloud-custom-tht-script.sh.j2 to use a git clone of tht\ncurrently fails because the user lacks permission to modify\n/usr/share.\n\nAlso, having the git clone directly into /usr/share is not very useful\nfor those using quickstart for tht development.\n\nThis change does a git clone of tht to the working directory and symlinks this\nto /usr/share/\n\nIt also makes $HOME readable so that mistral workflows have permission\nto read the local tripleo.\n\nChange-Id: I08f259664c7810f3a1b1373285bfec1227144da9\n'}]",18,499018,dc30a1e5a1fb27ed55dee7584dc9b01a1c6caddf,117,12,11,4571,,,0,"Sudo fix overcloud-custom-tht-script.sh.j2

Using overcloud-custom-tht-script.sh.j2 to use a git clone of tht
currently fails because the user lacks permission to modify
/usr/share.

Also, having the git clone directly into /usr/share is not very useful
for those using quickstart for tht development.

This change does a git clone of tht to the working directory and symlinks this
to /usr/share/

It also makes $HOME readable so that mistral workflows have permission
to read the local tripleo.

Change-Id: I08f259664c7810f3a1b1373285bfec1227144da9
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/18/499018/11 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-prep-config/templates/overcloud-custom-tht-script.sh.j2'],1,69a87c78c7ff61c04f1e8b03f8621a6fdf3cde4a,custom-tht,sudo rm -rf {{ overcloud_templates_path }} --single-branch{% endif %} {{ overcloud_templates_repo }} {{ working_dir }}/tripleo-heat-templates sudo ln -s {{ working_dir }}/tripleo-heat-templates {{ overcloud_templates_path }}pushd {{ working_dir }}/tripleo-heat-templates,rm -rf {{ overcloud_templates_path }} --single-branch{% endif %} {{ overcloud_templates_repo }} {{ overcloud_templates_path }}pushd {{overcloud_templates_path}},4,3
openstack%2Fopenstack-ansible-galera_server~stable%2Fnewton~Ie1b3b9724dd33de1d90634166e585ecceb1f4c96,openstack/openstack-ansible-galera_server,stable/newton,Ie1b3b9724dd33de1d90634166e585ecceb1f4c96,Implement a proper WSREP check for galera,MERGED,2017-12-13 12:48:01.000000000,2017-12-13 15:39:51.000000000,2017-12-13 15:39:50.000000000,"[{'_account_id': 538}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-13 12:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/47533f84262e54fc35b22df72f52c5f9a6d919fe', 'message': ""Implement a proper WSREP check for galera\n\nThe galera cluster rely on WSREP for cluster consistency. While the\ndefault MySQL monitor will allow us to know when the database node is\nminimally functional it does not provide the ability to query the node\nstate allowing loadbalancers, operators, and deployers to know a node\nis healthy prior to being allowed to accept connections. This change\nimplements the checkcluster script as provided by the fine folks at\nPercona. The implementation of this check follows the guild-lines noted\nhere [0]. With this in-place, we'll be able to convert our haproxy check\nfor the galera cluster nodes to use an HTTP check on port 9200 instead\nof the default MySQL login which will provide for a more robust and\nfault tolerant cluster.\n\n[0] https://www.percona.com/doc/percona-xtradb-cluster/LATEST/howtos/virt_sandbox.html\n\nCombined backport of:\n- https://review.openstack.org/520665\n- https://review.openstack.org/523850\n\nConflicts:\n>------handlers/main.yml\n>------tasks/galera_post_install.yml\n>------tests/test-galera-server-functional.yml\n>------vars/suse-42.yml\n\nCloses-Bug: #1665667\nChange-Id: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit ed739a5243b59596455b3488471c8cd81c15acf5)\n""}, {'number': 2, 'created': '2017-12-13 13:16:05.000000000', 'files': ['vars/redhat-7.yml', 'templates/clustercheck.j2', 'tasks/galera_post_install.yml', 'vars/ubuntu-14.04.yml', 'handlers/main.yml', 'releasenotes/notes/clustecheck-9311d05fb32f13b3.yaml', 'vars/ubuntu-16.04.yml', 'templates/mysqlchk.j2', 'defaults/main.yml', 'releasenotes/notes/new_healthcheck-9e559565745defd0.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/f46436b376d1f21cd541c62dd010a6cc5ff5c8bf', 'message': ""Implement a proper WSREP check for galera\n\nThe galera cluster rely on WSREP for cluster consistency. While the\ndefault MySQL monitor will allow us to know when the database node is\nminimally functional it does not provide the ability to query the node\nstate allowing loadbalancers, operators, and deployers to know a node\nis healthy prior to being allowed to accept connections. This change\nimplements the checkcluster script as provided by the fine folks at\nPercona. The implementation of this check follows the guild-lines noted\nhere [0]. With this in-place, we'll be able to convert our haproxy check\nfor the galera cluster nodes to use an HTTP check on port 9200 instead\nof the default MySQL login which will provide for a more robust and\nfault tolerant cluster.\n\n[0] https://www.percona.com/doc/percona-xtradb-cluster/LATEST/howtos/virt_sandbox.html\n\nCombined backport of:\n- https://review.openstack.org/520665\n- https://review.openstack.org/523850\n\nConflicts:\n>------handlers/main.yml\n>------tasks/galera_post_install.yml\n>------tests/test-galera-server-functional.yml\n>------vars/suse-42.yml\n\nCloses-Bug: #1665667\nChange-Id: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit ed739a5243b59596455b3488471c8cd81c15acf5)\n""}]",0,527684,f46436b376d1f21cd541c62dd010a6cc5ff5c8bf,9,3,2,6816,,,0,"Implement a proper WSREP check for galera

The galera cluster rely on WSREP for cluster consistency. While the
default MySQL monitor will allow us to know when the database node is
minimally functional it does not provide the ability to query the node
state allowing loadbalancers, operators, and deployers to know a node
is healthy prior to being allowed to accept connections. This change
implements the checkcluster script as provided by the fine folks at
Percona. The implementation of this check follows the guild-lines noted
here [0]. With this in-place, we'll be able to convert our haproxy check
for the galera cluster nodes to use an HTTP check on port 9200 instead
of the default MySQL login which will provide for a more robust and
fault tolerant cluster.

[0] https://www.percona.com/doc/percona-xtradb-cluster/LATEST/howtos/virt_sandbox.html

Combined backport of:
- https://review.openstack.org/520665
- https://review.openstack.org/523850

Conflicts:
>------handlers/main.yml
>------tasks/galera_post_install.yml
>------tests/test-galera-server-functional.yml
>------vars/suse-42.yml

Closes-Bug: #1665667
Change-Id: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit ed739a5243b59596455b3488471c8cd81c15acf5)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/84/527684/2 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'templates/clustercheck.j2', 'tasks/galera_post_install.yml', 'handlers/main.yml', 'releasenotes/notes/clustecheck-9311d05fb32f13b3.yaml', 'vars/ubuntu-16.04.yml', 'templates/mysqlchk.j2', 'defaults/main.yml', 'releasenotes/notes/new_healthcheck-9e559565745defd0.yaml']",9,47533f84262e54fc35b22df72f52c5f9a6d919fe,bug/1665667,"--- features: - | Galera healthcheck has been improved, and relies on an xinetd service. By default, the service is unaccessible (filtered with the no_access directive). You can override the directive by setting any xinetd valid value to ``galera_monitoring_allowed_source``. ",,191,0
openstack%2Fproject-config~master~Ief06ef2fde45851df0c9cea4764dfe38c1777e46,openstack/project-config,master,Ief06ef2fde45851df0c9cea4764dfe38c1777e46,ansible-role-rhsm: run openstack-tox-linters,MERGED,2017-12-13 05:10:08.000000000,2017-12-13 15:33:52.000000000,2017-12-13 15:33:52.000000000,"[{'_account_id': 3153}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 05:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a71151225f370c575931e3b0235369d4552d2885', 'message': 'ansible-role-rhsm: run openstack-tox-linters\n\nLike other Ansible modules in TripleO, run openstack-tox-linters\nwhich runs all the tests we need.\n\nChange-Id: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\n'}, {'number': 2, 'created': '2017-12-13 13:04:09.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9ff0f6fdfeeb6d00234670375fac438b6685ecb8', 'message': 'ansible-role-rhsm: run openstack-tox-linters\n\nLike other Ansible modules in TripleO, run openstack-tox-linters\nwhich runs all the tests we need.\n\nChange-Id: Ief06ef2fde45851df0c9cea4764dfe38c1777e46\n'}]",2,527575,9ff0f6fdfeeb6d00234670375fac438b6685ecb8,11,4,2,3153,,,0,"ansible-role-rhsm: run openstack-tox-linters

Like other Ansible modules in TripleO, run openstack-tox-linters
which runs all the tests we need.

Change-Id: Ief06ef2fde45851df0c9cea4764dfe38c1777e46
",git fetch https://review.opendev.org/openstack/project-config refs/changes/75/527575/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,a71151225f370c575931e3b0235369d4552d2885,import/ansible-role-rhsm, - check-requirements - release-notes-jobs - publish-to-pypi check: jobs: - openstack-tox-linters gate: jobs: - openstack-tox-linters, - ansible-lint-jobs,9,1
openstack%2Fnova~master~I6be3b236d8eadcde5714c08069708dff303dfd4d,openstack/nova,master,I6be3b236d8eadcde5714c08069708dff303dfd4d,Stabilize test_live_migration_abort func test,MERGED,2017-12-12 15:51:01.000000000,2017-12-13 15:32:35.000000000,2017-12-13 15:32:34.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-12-12 15:51:01.000000000', 'files': ['nova/tests/functional/notification_sample_tests/notification_sample_base.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/937db90146f04783183644bfeff78b1f6bf854b8', 'message': 'Stabilize test_live_migration_abort func test\n\nThe test_live_migration_abort test step in the\ntest_live_migration_actions notification sample test was unstable.\nThe test starts a live migration and then deletes the migration object\nvia the REST API to abort it. The test randomly failed to find the\nmigration object on the REST API. Based on the comparision of the logs\nof the successful and unsuccesful runs it was visible that in the\nunsuccesful case the test gave up to wait for the migration object too\nearly. In a succesful run it took 1.5 seconds after the the migration\nAPI call to have the migration object appear on the API while in an\nunsuccessful case the test gave up after 1 second.\n\nThis early give up was cause by the fact that the loop trying to\nget a migration does not applied any delay between such trials and\ntherefore the 20 attempts run out quickly.\n\nThis patch introduces a short sleep between trials to stabilize the\ntest.\n\nChange-Id: I6be3b236d8eadcde5714c08069708dff303dfd4d\nCloses-Bug: #1736976\n'}]",0,527440,937db90146f04783183644bfeff78b1f6bf854b8,16,7,1,9708,,,0,"Stabilize test_live_migration_abort func test

The test_live_migration_abort test step in the
test_live_migration_actions notification sample test was unstable.
The test starts a live migration and then deletes the migration object
via the REST API to abort it. The test randomly failed to find the
migration object on the REST API. Based on the comparision of the logs
of the successful and unsuccesful runs it was visible that in the
unsuccesful case the test gave up to wait for the migration object too
early. In a succesful run it took 1.5 seconds after the the migration
API call to have the migration object appear on the API while in an
unsuccessful case the test gave up after 1 second.

This early give up was cause by the fact that the loop trying to
get a migration does not applied any delay between such trials and
therefore the 20 attempts run out quickly.

This patch introduces a short sleep between trials to stabilize the
test.

Change-Id: I6be3b236d8eadcde5714c08069708dff303dfd4d
Closes-Bug: #1736976
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/527440/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/notification_sample_tests/notification_sample_base.py'],1,937db90146f04783183644bfeff78b1f6bf854b8,bug/1736976,import time time.sleep(0.5),,2,0
openstack%2Frpm-packaging~master~I3dd112b75ea3492e1a336b6206eb69f62bb4c1ff,openstack/rpm-packaging,master,I3dd112b75ea3492e1a336b6206eb69f62bb4c1ff,Update keystonemiddleware to 4.19.0,MERGED,2017-12-08 01:16:59.000000000,2017-12-13 15:30:39.000000000,2017-12-13 15:30:39.000000000,"[{'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-08 01:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/65896eefe5b471b7fef218001e975024e85c768f', 'message': 'Update keystonemiddleware to 4.19.0\n\nChange-Id: I3dd112b75ea3492e1a336b6206eb69f62bb4c1ff\nDeends-on: Icfa02672582af4f8e538a0f546e52d7e03c7d8d9\n'}, {'number': 2, 'created': '2017-12-13 13:29:22.000000000', 'files': ['openstack/keystonemiddleware/keystonemiddleware.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/70dfdd9d04756162c85557406f7c62ee131bda46', 'message': 'Update keystonemiddleware to 4.19.0\n\nChange-Id: I3dd112b75ea3492e1a336b6206eb69f62bb4c1ff\nDeends-on: Icfa02672582af4f8e538a0f546e52d7e03c7d8d9\n'}]",0,526562,70dfdd9d04756162c85557406f7c62ee131bda46,18,6,2,17130,,,0,"Update keystonemiddleware to 4.19.0

Change-Id: I3dd112b75ea3492e1a336b6206eb69f62bb4c1ff
Deends-on: Icfa02672582af4f8e538a0f546e52d7e03c7d8d9
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/62/526562/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/keystonemiddleware/keystonemiddleware.spec.j2'],1,65896eefe5b471b7fef218001e975024e85c768f,update-keystonemiddleware,Version: 4.19.0,Version: 4.18.0,1,1
openstack%2Fheat~master~I981c5a6476b40bf9f7fcd35ae0c638e77912f060,openstack/heat,master,I981c5a6476b40bf9f7fcd35ae0c638e77912f060,Remove setting of version/release from releasenotes,MERGED,2017-12-13 11:31:58.000000000,2017-12-13 15:28:31.000000000,2017-12-13 15:28:31.000000000,"[{'_account_id': 7385}, {'_account_id': 8833}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 11:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb0e71e85ccad774eae5fb5ddf6ca3f0bf858cb1', 'message': ""Ignore version in releasenote doc\n\nIt's not necessary to assign version and release for releasenote\ndoc. Also `build-openstack-releasenotes` job break when we try\nto import from heat.\nThis patch propose to use default empty string for `version` and\n`release` in `releasenotes/source/conf.py`.\nCloses-Bug: #1737955\n\nChange-Id: I981c5a6476b40bf9f7fcd35ae0c638e77912f060\n""}, {'number': 2, 'created': '2017-12-13 11:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5c10ad62d11c13986e124349145b7e8fa0279c5f', 'message': ""Ignore version and release in releasenote conf\n\nIt's not necessary to assign version and release for releasenote\ndoc. Also `build-openstack-releasenotes` job break when we try\nto import from heat.\nThis patch propose to use default empty string for `version` and\n`release` in `releasenotes/source/conf.py`.\nCloses-Bug: #1737955\n\nChange-Id: I981c5a6476b40bf9f7fcd35ae0c638e77912f060\n""}, {'number': 3, 'created': '2017-12-13 11:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/52583c8a891cd9540019645d60fc368cd0e33061', 'message': ""Remove setting of version/release from releasenotes\nRelease notes are version independent, so remove version/release\nvalues. We've found that projects now require the service package\nto be installed in order to build release notes, and this is entirely\ndue to the current convention of pulling in the version information.\n\nRelease notes should not need installation in order to build, so this\nunnecessary version setting needs to be removed.\n\nThis is needed for new release notes publishing, see\nI56909152975f731a9d2c21b2825b972195e48ee8 and the discussion starting\nat\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-November/124480.html\n.\nCloses-Bug: #1737955\n\nChange-Id: I981c5a6476b40bf9f7fcd35ae0c638e77912f060\n""}, {'number': 4, 'created': '2017-12-13 15:01:27.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b53f8e472d613bb14b785d55df5ebe7f28aa81b2', 'message': ""Remove setting of version/release from releasenotes\n\nRelease notes are version independent, so remove version/release\nvalues. We've found that projects now require the service package\nto be installed in order to build release notes, and this is entirely\ndue to the current convention of pulling in the version information.\n\nRelease notes should not need installation in order to build, so this\nunnecessary version setting needs to be removed.\n\nThis is needed for new release notes publishing, see\nI56909152975f731a9d2c21b2825b972195e48ee8 and the discussion starting\nat\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-November/124480.html\n.\nCloses-Bug: #1737955\n\nChange-Id: I981c5a6476b40bf9f7fcd35ae0c638e77912f060\n""}]",1,527672,b53f8e472d613bb14b785d55df5ebe7f28aa81b2,13,3,4,12404,,,0,"Remove setting of version/release from releasenotes

Release notes are version independent, so remove version/release
values. We've found that projects now require the service package
to be installed in order to build release notes, and this is entirely
due to the current convention of pulling in the version information.

Release notes should not need installation in order to build, so this
unnecessary version setting needs to be removed.

This is needed for new release notes publishing, see
I56909152975f731a9d2c21b2825b972195e48ee8 and the discussion starting
at
http://lists.openstack.org/pipermail/openstack-dev/2017-November/124480.html
.
Closes-Bug: #1737955

Change-Id: I981c5a6476b40bf9f7fcd35ae0c638e77912f060
",git fetch https://review.opendev.org/openstack/heat refs/changes/72/527672/3 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,cb0e71e85ccad774eae5fb5ddf6ca3f0bf858cb1,bug/1737955,release = ''version = '',# The short X.Y version. from heat.version import version_info as heat_versionrelease = heat_version.version_string_with_vcs()version = heat_version.canonical_version_string(),2,4
openstack%2Fpython-glanceclient~master~Ie99f79b61e5f8d469695fa19ad99d919fa23ae8e,openstack/python-glanceclient,master,Ie99f79b61e5f8d469695fa19ad99d919fa23ae8e,Add domain info to functional test clients,MERGED,2017-12-11 16:59:00.000000000,2017-12-13 15:26:49.000000000,2017-12-13 15:26:49.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 16:59:00.000000000', 'files': ['glanceclient/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/79d00516556b062fd68342bf7bc86cd5d810c2e3', 'message': 'Add domain info to functional test clients\n\nKeystone wants domain info, so pass it on.\n\nChange-Id: Ie99f79b61e5f8d469695fa19ad99d919fa23ae8e\nCloses-bug: #1737583\n'}]",0,527165,79d00516556b062fd68342bf7bc86cd5d810c2e3,13,4,1,5314,,,0,"Add domain info to functional test clients

Keystone wants domain info, so pass it on.

Change-Id: Ie99f79b61e5f8d469695fa19ad99d919fa23ae8e
Closes-bug: #1737583
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/65/527165/1 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/tests/functional/base.py'],1,79d00516556b062fd68342bf7bc86cd5d810c2e3,bug/1737583," user_domain_id=self.creds['user_domain_id'], project_domain_id=self.creds['project_domain_id'], project_name=self.creds[""project_name""], user_domain_id=self.creds[""user_domain_id""], project_domain_id=self.creds[""project_domain_id""])"," project_name=self.creds[""project_name""])",5,1
openstack%2Fmistral~master~Ib3f9c96fb8065c5aba31b5b6f11fa2110f70aa87,openstack/mistral,master,Ib3f9c96fb8065c5aba31b5b6f11fa2110f70aa87,Clear error info,MERGED,2017-12-08 16:03:36.000000000,2017-12-13 15:03:47.000000000,2017-12-13 15:03:47.000000000,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 22348}, {'_account_id': 23211}, {'_account_id': 23271}]","[{'number': 1, 'created': '2017-12-08 16:03:36.000000000', 'files': ['mistral/services/scheduler.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/d5d6d1f65f7f952e403c78085ed7e6239136d54d', 'message': 'Clear error info\n\nFor some reason, the exception info was not cleared after the\nexcept block. This caused subsequent log messages to include\nthe previous error message even if the error has already been\nresolved.\n\nChange-Id: Ib3f9c96fb8065c5aba31b5b6f11fa2110f70aa87\n'}]",1,526720,d5d6d1f65f7f952e403c78085ed7e6239136d54d,11,5,1,21970,,,0,"Clear error info

For some reason, the exception info was not cleared after the
except block. This caused subsequent log messages to include
the previous error message even if the error has already been
resolved.

Change-Id: Ib3f9c96fb8065c5aba31b5b6f11fa2110f70aa87
",git fetch https://review.opendev.org/openstack/mistral refs/changes/20/526720/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/services/scheduler.py'],1,d5d6d1f65f7f952e403c78085ed7e6239136d54d,clear-error,import sys # For some mysterious reason (probably eventlet related) # the exception is not cleared from the context automatically. # This results in subsequent log.warning calls to show invalid # info. sys.exc_clear() ,,7,0
openstack%2Fkolla~master~I8774a45bb1cfcdf5c3b675e235fb074af4a9646c,openstack/kolla,master,I8774a45bb1cfcdf5c3b675e235fb074af4a9646c,ironic-conductor: update driver dependencies for Queens,MERGED,2017-12-08 16:59:09.000000000,2017-12-13 15:01:47.000000000,2017-12-13 15:01:47.000000000,"[{'_account_id': 10239}, {'_account_id': 13039}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 27371}]","[{'number': 1, 'created': '2017-12-08 16:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b74eaf8fd8525faa88bae1372f498692113c2e8c', 'message': 'ironic-conductor: update list of drivers\n\n* Added python-sushy for CentOS/RHEL for the redfish driver\n* Added ansible and systemd-python for ansible driver\n* Added python-scciclient as it was packaged for CentOS/RHEL\n* Removed seamicroclient, pyghmi and pyremotevbox as these\n  drivers were removed\n* Removed wsman as no drivers use it any more\n\nChange-Id: I8774a45bb1cfcdf5c3b675e235fb074af4a9646c\n'}, {'number': 2, 'created': '2017-12-08 17:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/67a3dd8d6a14b9ed20e130d675001aa050f688aa', 'message': 'ironic-conductor: update driver dependencies for Queens\n\n* Added python-sushy for CentOS/RHEL for the redfish driver\n* Added ansible and systemd-python for ansible driver\n* Added python-scciclient as it was packaged for CentOS/RHEL\n* Removed seamicroclient, pyghmi and pyremotevbox as these\n  drivers were removed\n* Removed wsman as no drivers use it any more\n\nChange-Id: I8774a45bb1cfcdf5c3b675e235fb074af4a9646c\n'}, {'number': 3, 'created': '2017-12-12 07:26:14.000000000', 'files': ['docker/ironic/ironic-conductor/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/450f41aaa304035ed826422eab3144c4677a0ac9', 'message': 'ironic-conductor: update driver dependencies for Queens\n\n* Added python-sushy for CentOS/RHEL for the redfish driver\n  (introduced in the Pike release).\n* Added ansible and systemd-python for ansible driver\n  (introduced in the Queens cycle).\n* Added python-scciclient as it was packaged for CentOS/RHEL.\n* Removed seamicroclient, pyghmi and pyremotevbox as the\n  corresponding drivers were removed.\n* Removed wsman as no drivers use it any more: the AMT driver\n  was removed, the iDrac driver switched to python-dracclient.\n\nMost of removals happened as part of the Ocata driver cleanup:\nhttps://docs.openstack.org/releasenotes/ironic/ocata.html#id9\n\nChange-Id: I8774a45bb1cfcdf5c3b675e235fb074af4a9646c\n'}]",0,526734,450f41aaa304035ed826422eab3144c4677a0ac9,19,6,3,10239,,,0,"ironic-conductor: update driver dependencies for Queens

* Added python-sushy for CentOS/RHEL for the redfish driver
  (introduced in the Pike release).
* Added ansible and systemd-python for ansible driver
  (introduced in the Queens cycle).
* Added python-scciclient as it was packaged for CentOS/RHEL.
* Removed seamicroclient, pyghmi and pyremotevbox as the
  corresponding drivers were removed.
* Removed wsman as no drivers use it any more: the AMT driver
  was removed, the iDrac driver switched to python-dracclient.

Most of removals happened as part of the Ocata driver cleanup:
https://docs.openstack.org/releasenotes/ironic/ocata.html#id9

Change-Id: I8774a45bb1cfcdf5c3b675e235fb074af4a9646c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/34/526734/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/ironic/ironic-conductor/Dockerfile.j2'],1,b74eaf8fd8525faa88bae1372f498692113c2e8c,ironic-driver," # TODO(Jeffrey4l): no python-oneviewclient 'ansible', 'python-scciclient', 'python-sushy', 'systemd-python', # ImcSdk package, python-sushy 'ansible', 'python-systemd',"," # TODO(Jeffrey4l): no python-scciclient, python-oneviewclient, # python-seamicroclient, pyremotevbox package 'openwsman-python', 'python-pyghmi', # pyremotevbox, ImcSdk package 'python-openwsman', 'python-pyghmi', 'python-seamicroclient',",8,8
openstack%2Ftripleo-heat-templates~master~I106156851d9d64237df1138fe1ee40fa4dca4e3e,openstack/tripleo-heat-templates,master,I106156851d9d64237df1138fe1ee40fa4dca4e3e,Add support for containerized OVN Metadata Agent,ABANDONED,2017-12-04 11:47:36.000000000,2017-12-13 15:01:46.000000000,,"[{'_account_id': 3}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 10237}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-12-04 11:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/528f0c363b78e84fe1c97af6d2365aaaba679bad', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 2, 'created': '2017-12-04 13:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ffd0e6e7b08e6ef31cb45c3e6cc65b4239320c82', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 3, 'created': '2017-12-04 16:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aa2afcaaa28748dc57def01348f696f92131d15f', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 4, 'created': '2017-12-05 10:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b8e8e6ec19ed573f83bfb2b63da1b38f74da8e32', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 5, 'created': '2017-12-07 11:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8d74b113a32bebf11ad0a8c51d327dc44ff014e5', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 6, 'created': '2017-12-07 17:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/38e731f425773cf421444d7b34cf1bdbde00c611', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 7, 'created': '2017-12-07 17:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6bca0f568fbefab168404b92af9fe5c8cae25fe4', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 8, 'created': '2017-12-11 10:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8bd7081a1eaef84f452d35bd926f2eb882611e18', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 9, 'created': '2017-12-12 10:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1676b427184d5605d6576ea3a4a706ac98c1bf62', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 10, 'created': '2017-12-12 14:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b0f8d3096b0aa545e25dc3f65378bb02f4811449', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 11, 'created': '2017-12-12 17:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5de708c579d4b84ed6cc51424224bd52518c13d9', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 12, 'created': '2017-12-12 21:29:20.000000000', 'files': ['docker/services/ovn-metadata.yaml', 'environments/services-docker/neutron-ovn.yaml', 'environments/services-docker/neutron-ovn-ha.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8b635eca5b64c5bf6d625efb25734f84b3ce5d1', 'message': 'Add support for containerized OVN Metadata Agent\n\nThis patch adds the docker service file for the metadata agent\nin networking-ovn setups.\n\nDepends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9\nChange-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}]",3,525164,c8b635eca5b64c5bf6d625efb25734f84b3ce5d1,46,8,12,23804,,,0,"Add support for containerized OVN Metadata Agent

This patch adds the docker service file for the metadata agent
in networking-ovn setups.

Depends-On: I678652294cb8f964c34b742a0bc0ea360d736fb9
Change-Id: I106156851d9d64237df1138fe1ee40fa4dca4e3e
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/525164/10 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ovn-metadata.yaml'],1,528f0c363b78e84fe1c97af6d2365aaaba679bad,ovn-metadata-agent,"heat_template_version: queens description: > OpenStack containerized OVN Metadata agent parameters: DockerOVNMetadataImage: description: image type: string DockerNeutronConfigImage: description: The container image to use for the neutron config_volume type: string ServiceData: default: {} description: Dictionary packing service data type: json ServiceNetMap: default: {} description: Mapping of service_name -> network name. Typically set via parameter_defaults in the resource registry. This mapping overrides those in ServiceNetMapDefaults. type: json DefaultPasswords: default: {} type: json EndpointMap: default: {} description: Mapping of service endpoint -> protocol. Typically set via parameter_defaults in the resource registry. type: json RoleName: default: '' description: Role name on which the service is applied type: string RoleParameters: default: {} description: Parameters specific to the role type: json resources: ContainersCommon: type: ./containers-common.yaml OVNMetadataBase: type: ../../puppet/services/ovn-metadata.yaml properties: EndpointMap: {get_param: EndpointMap} ServiceData: {get_param: ServiceData} ServiceNetMap: {get_param: ServiceNetMap} DefaultPasswords: {get_param: DefaultPasswords} RoleName: {get_param: RoleName} RoleParameters: {get_param: RoleParameters} NeutronLogging: type: OS::TripleO::Services::Logging::NeutronCommon outputs: role_data: description: Role data for OVNMetadata agent value: service_name: {get_attr: [OVNMetadataBase, role_data, service_name]} config_settings: map_merge: - get_attr: [OVNMetadataBase, role_data, config_settings] - get_attr: [NeutronLogging, config_settings] logging_source: {get_attr: [OVNMetadataBase, role_data, logging_source]} logging_groups: {get_attr: [OVNMetadataBase, role_data, logging_groups]} puppet_config: puppet_tags: neutron_config,ovn_metadata_agent_config config_volume: neutron step_config: get_attr: [OVNMetadataBase, role_data, step_config] config_image: {get_param: DockerNeutronConfigImage} kolla_config: /var/lib/kolla/config_files/ovn_metadata_agent.json: command: /usr/bin/networking-ovn-metadata-agent --config-file /etc/neutron/plugins/networking-ovn/networking-ovn-metadata-agent.ini --config-dir /etc/neutron/conf.d/networking-ovn-metadata-agent config_files: - source: ""/var/lib/kolla/config_files/src/*"" dest: ""/"" merge: true preserve_properties: true permissions: - path: /var/log/neutron owner: neutron:neutron recurse: true - path: /var/lib/neutron owner: neutron:neutron recurse: true docker_config: step_4: ovn_metadata_agent: image: {get_param: DockerOVNMetadataImage} net: host pid: host privileged: true restart: always healthcheck: test: /openstack/healthcheck volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - {get_attr: [NeutronLogging, volumes]} - - /var/lib/kolla/config_files/ovn_metadata_agent.json:/var/lib/kolla/config_files/config.json:ro - /var/lib/config-data/puppet-generated/neutron/:/var/lib/kolla/config_files/src:ro - /lib/modules:/lib/modules:ro - /run:/run - /var/lib/neutron:/var/lib/neutron environment: - KOLLA_CONFIG_STRATEGY=COPY_ALWAYS host_prep_tasks: list_concat: - {get_attr: [NeutronLogging, host_prep_tasks]} - - name: create /var/lib/neutron file: path: /var/lib/neutron state: directory upgrade_tasks: - name: Check if ovn_metadata_agent is deployed command: systemctl is-enabled --quiet networking-ovn-metadata-agent tags: common ignore_errors: True register: networking_ovn_metadata_agent_enabled - name: ""PreUpgrade step0,validation: Check service networking-ovn-metadata-agent is running"" command: systemctl is-active --quiet networking-ovn-metadata-agent when: networking_ovn_metadata_agent_enabled.rc == 0 tags: step0,validation - name: Stop and disable networking_ovn_metadata service tags: step2 when: networking_ovn_metadata_agent_enabled.rc == 0 service: name=networking-ovn-metadata-agent state=stopped enabled=no ",,132,0
openstack%2Ftripleo-heat-templates~master~I005001483c0a17d1aebd2b5bb61f60bc75abddb5,openstack/tripleo-heat-templates,master,I005001483c0a17d1aebd2b5bb61f60bc75abddb5,Add OVN metadata agent service to scenario007 job,ABANDONED,2017-11-24 13:10:13.000000000,2017-12-13 15:01:46.000000000,,"[{'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-24 13:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/077b320867b297e48c756ae97354d3894caf6dc0', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}, {'number': 2, 'created': '2017-11-24 13:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06b3e9bd7ab8846abd1262cd37302f15c5d80249', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}, {'number': 3, 'created': '2017-12-04 16:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0aebaae8e98785b88e81efe7c3097aff8fd5492', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}, {'number': 4, 'created': '2017-12-04 18:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d5a15668675df16a3d193ddc0b67ce1c2426256b', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}, {'number': 5, 'created': '2017-12-11 12:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5190c8c8e77cccaa67b80ec173d43b7ba77a8bb9', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}, {'number': 6, 'created': '2017-12-12 21:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d2f8f90ce9fddb589a56e046903c43192f2c012c', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nDepends-On: Idc2bb4e31a64502ac6fcdac771d823509dc328e7\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}, {'number': 7, 'created': '2017-12-12 21:33:21.000000000', 'files': ['ci/environments/scenario007-multinode-containers.yaml', 'puppet/services/ovn-controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a49a8e9f3f0136cc26c28f83519a9d5bc45a9e25', 'message': ""Add OVN metadata agent service to scenario007 job\n\nThis patch adds the networking-ovn-metadata-agent service to the\nscenario007 job so that we don't have to use config drive anymore.\n\nChange-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5\n""}]",0,522813,a49a8e9f3f0136cc26c28f83519a9d5bc45a9e25,22,4,7,23804,,,0,"Add OVN metadata agent service to scenario007 job

This patch adds the networking-ovn-metadata-agent service to the
scenario007 job so that we don't have to use config drive anymore.

Change-Id: I005001483c0a17d1aebd2b5bb61f60bc75abddb5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/13/522813/2 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario007-multinode.yaml'],1,077b320867b297e48c756ae97354d3894caf6dc0,ovn-metadata-agent, OS::TripleO::Services::OVNMetadataAgent: ../../puppet/services/ovn-metadata.yaml - OS::TripleO::Services::OVNMetadataAgent,,2,0
openstack%2Ftempest~master~I64cbcfd229925101b8302151e65dc40ac3d6413f,openstack/tempest,master,I64cbcfd229925101b8302151e65dc40ac3d6413f,Handle deprecated compute os-floating-ips API,ABANDONED,2017-06-07 14:50:46.000000000,2017-12-13 14:54:05.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-06-07 14:50:46.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/api/compute/servers/test_server_rescue.py', 'tempest/api/compute/floating_ips/test_list_floating_ips.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e87927bc980645bcad7a5989af7403c896e8148', 'message': 'Handle deprecated compute os-floating-ips API\n\nThe os-floating-ips and os-floating-ip-pools compute APIs\nwere deprecated in the 2.36 microversion.\n\nThis change caps the FloatingIPDetailsTestJSON tests at 2.35.\n\nIt also changes a compute rescue API test which is using floating IPs\nto get them from Neutron if Neutron is available, otherwise use\nthe compute API.\n\nThis is part of a larger, long-running slow phase out of nova-network\nfrom OpenStack.\n\nChange-Id: I64cbcfd229925101b8302151e65dc40ac3d6413f\n'}]",2,471808,4e87927bc980645bcad7a5989af7403c896e8148,7,3,1,6873,,,0,"Handle deprecated compute os-floating-ips API

The os-floating-ips and os-floating-ip-pools compute APIs
were deprecated in the 2.36 microversion.

This change caps the FloatingIPDetailsTestJSON tests at 2.35.

It also changes a compute rescue API test which is using floating IPs
to get them from Neutron if Neutron is available, otherwise use
the compute API.

This is part of a larger, long-running slow phase out of nova-network
from OpenStack.

Change-Id: I64cbcfd229925101b8302151e65dc40ac3d6413f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/08/471808/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/api/compute/servers/test_server_rescue.py', 'tempest/api/compute/floating_ips/test_list_floating_ips.py']",3,4e87927bc980645bcad7a5989af7403c896e8148,create_validation_resources-neutron, # The os-floating-ips and os-floating-ip-pools APIs were deprecated in 2.36 max_microversion = '2.35',,24,6
openstack%2Ftripleo-heat-templates~master~Id7fed3746733c0ea0804532beda627c69e4ce078,openstack/tripleo-heat-templates,master,Id7fed3746733c0ea0804532beda627c69e4ce078,Add upgrade task to run gnocchi upgrade,MERGED,2017-11-20 18:11:15.000000000,2017-12-13 14:53:39.000000000,2017-11-21 21:16:28.000000000,"[{'_account_id': 6924}, {'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-20 18:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2e9fcdb9d67445e5122026566414aa27f3fc99c6', 'message': 'Add upgrade task to run gnocchi upgrade\n\nChange-Id: Id7fed3746733c0ea0804532beda627c69e4ce078\n'}, {'number': 2, 'created': '2017-11-20 20:16:11.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/60925faefc58d76adf3914f96c636ca2a5b8c783', 'message': 'Add upgrade task to run gnocchi upgrade\n\nCloses-bug: #1724328\n\nChange-Id: Id7fed3746733c0ea0804532beda627c69e4ce078\n'}]",2,521621,60925faefc58d76adf3914f96c636ca2a5b8c783,19,6,2,6924,,,0,"Add upgrade task to run gnocchi upgrade

Closes-bug: #1724328

Change-Id: Id7fed3746733c0ea0804532beda627c69e4ce078
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/521621/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-api.yaml'],1,2e9fcdb9d67445e5122026566414aa27f3fc99c6,bug/1724328, - name: get bootstrap nodeid tags: common command: hiera bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact tags: common set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Setup gnocchi db udring upgrade tags: step5 command: gnocchi-upgrade when: is_bootstrap_node,,11,0
openstack%2Ftripleo-heat-templates~stable%2Fpike~Id7fed3746733c0ea0804532beda627c69e4ce078,openstack/tripleo-heat-templates,stable/pike,Id7fed3746733c0ea0804532beda627c69e4ce078,Add upgrade task to run gnocchi upgrade,MERGED,2017-11-21 15:20:15.000000000,2017-12-13 14:50:49.000000000,2017-11-22 10:22:29.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-11-21 15:20:15.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aab7bdd6fbab0158cf2b57a63b4422cd3156beed', 'message': 'Add upgrade task to run gnocchi upgrade\n\nCloses-bug: #1724328\n\nChange-Id: Id7fed3746733c0ea0804532beda627c69e4ce078\n(cherry picked from commit 60925faefc58d76adf3914f96c636ca2a5b8c783)\n'}]",0,521890,aab7bdd6fbab0158cf2b57a63b4422cd3156beed,15,4,1,6924,,,0,"Add upgrade task to run gnocchi upgrade

Closes-bug: #1724328

Change-Id: Id7fed3746733c0ea0804532beda627c69e4ce078
(cherry picked from commit 60925faefc58d76adf3914f96c636ca2a5b8c783)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/521890/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-api.yaml'],1,aab7bdd6fbab0158cf2b57a63b4422cd3156beed,bug/1724328, - name: get bootstrap nodeid tags: common command: hiera bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact tags: common set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Setup gnocchi db during upgrade tags: step5 command: gnocchi-upgrade when: is_bootstrap_node,,11,0
openstack%2Ftripleo-heat-templates~stable%2Focata~Id7fed3746733c0ea0804532beda627c69e4ce078,openstack/tripleo-heat-templates,stable/ocata,Id7fed3746733c0ea0804532beda627c69e4ce078,Add upgrade task to run gnocchi upgrade,MERGED,2017-11-21 15:14:31.000000000,2017-12-13 14:50:19.000000000,2017-11-22 07:15:55.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-21 15:14:31.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/771189e91d50fd28d2be44d9b003ff061482b90d', 'message': 'Add upgrade task to run gnocchi upgrade\n\nCloses-bug: #1724328\n\nChange-Id: Id7fed3746733c0ea0804532beda627c69e4ce078\n(cherry picked from commit 60925faefc58d76adf3914f96c636ca2a5b8c783)\n'}]",0,521886,771189e91d50fd28d2be44d9b003ff061482b90d,9,4,1,6924,,,0,"Add upgrade task to run gnocchi upgrade

Closes-bug: #1724328

Change-Id: Id7fed3746733c0ea0804532beda627c69e4ce078
(cherry picked from commit 60925faefc58d76adf3914f96c636ca2a5b8c783)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/521886/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-api.yaml'],1,771189e91d50fd28d2be44d9b003ff061482b90d,bug/1724328, - name: get bootstrap nodeid tags: common command: hiera bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact tags: common set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Setup gnocchi db during upgrade tags: step5 command: gnocchi-upgrade when: is_bootstrap_node,,11,0
openstack%2Fopenstack-ansible~master~I3037249ff847cc805ac83f71e7df5943efe7eb25,openstack/openstack-ansible,master,I3037249ff847cc805ac83f71e7df5943efe7eb25,Fix automatic log copying in Zuul runs,MERGED,2017-10-30 20:49:46.000000000,2017-12-13 14:47:26.000000000,2017-12-13 14:47:26.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24441}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-10-30 20:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/649cbe6d3fac7518a4048dd69ab673ed7f9cae67', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 2, 'created': '2017-11-06 15:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/865cf43fe214091bb50e2692d18950380ffdd6d8', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 3, 'created': '2017-11-06 17:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2ed2904dcdc0c74f456134810431c81b668ff2c8', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 4, 'created': '2017-11-07 03:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f2fa552f17ad090e2746c6550b6f40436a87fc35', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 5, 'created': '2017-11-09 19:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/089a99b1ddcb7e1afa286803dc83cb21567f7ea5', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 6, 'created': '2017-11-09 21:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9cababb6c9ec72460f0e7773dcecee09400df1a4', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 7, 'created': '2017-11-10 01:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cd4a3fd87455dcedd65474c0462bb9eb321ef5c7', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 8, 'created': '2017-11-11 00:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3d0010bf78ce8832860c3055038b8f8ce03740c8', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 9, 'created': '2017-11-14 18:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/99b24babe0571463a19957963bbe73a06c6c55a7', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 10, 'created': '2017-11-21 19:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ed8a557915263610b3feca0799fa2c1383175b76', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 11, 'created': '2017-11-22 17:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/00f884070aa64a5f027c64fe16fb646550ab293e', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 12, 'created': '2017-12-12 13:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b69c56abc83f990533b9e433429e6feb61f1e3ed', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}, {'number': 13, 'created': '2017-12-13 09:05:26.000000000', 'files': ['scripts/gate-check-commit.sh', 'scripts/test-log-collect.sh', 'scripts/scripts-library.sh', 'zuul.d/jobs.yaml', 'zuul.d/playbooks/post.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3850e3d1a1b606c3794ef372951b0a768eae3082', 'message': 'Fix automatic log copying in Zuul runs\n\nKey off an environment variable, ""ZUUL_PROJECT"", instead of the\nexistence of /etc/nodepool, when determining whether to do a log\ncopy into the workspace at the end of the job.\n\nChange-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25\n'}]",3,516448,3850e3d1a1b606c3794ef372951b0a768eae3082,90,9,13,17799,,,0,"Fix automatic log copying in Zuul runs

Key off an environment variable, ""ZUUL_PROJECT"", instead of the
existence of /etc/nodepool, when determining whether to do a log
copy into the workspace at the end of the job.

Change-Id: I3037249ff847cc805ac83f71e7df5943efe7eb25
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/48/516448/10 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,649cbe6d3fac7518a4048dd69ab673ed7f9cae67,ci-logs-fix,"if [[ -n ""$ZUUL_PROJECT"" ]]; then","if [[ -d ""/etc/nodepool"" ]]; then",1,1
openstack%2Fpuppet-ceph~master~Ie5a9504b9b1e21cd088e9ffde751f54268655ad1,openstack/puppet-ceph,master,Ie5a9504b9b1e21cd088e9ffde751f54268655ad1,WIP - as discussed with EmilienM,ABANDONED,2017-12-13 14:42:16.000000000,2017-12-13 14:46:47.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-13 14:42:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/da30b8a038d401541981508dfbc89f6889017eed', 'message': 'WIP - as discussed with EmilienM\n\nChange-Id: Ie5a9504b9b1e21cd088e9ffde751f54268655ad1\n'}]",0,527700,da30b8a038d401541981508dfbc89f6889017eed,3,1,1,6547,,,0,"WIP - as discussed with EmilienM

Change-Id: Ie5a9504b9b1e21cd088e9ffde751f54268655ad1
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/00/527700/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,da30b8a038d401541981508dfbc89f6889017eed,fix-jewel-ci, check: jobs: my-test - job: name: my-test parent: legacy-puppet-unit-4.8-centos-7 description: | Just a proof of concept to see whether we can check out the proper branches. branches: stable/jewel required-projects: - openstack/puppet-openstack-integration: - override-checkout: stable/pike,,15,0
openstack%2Fnova~master~I044014861a6d7ad3f81c94b44fff6b30dbd6d589,openstack/nova,master,I044014861a6d7ad3f81c94b44fff6b30dbd6d589,placement: add ProviderTree.is_inventory_empty,ABANDONED,2017-07-06 10:20:28.000000000,2017-12-13 14:44:19.000000000,,"[{'_account_id': 3}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-07-06 10:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab6fe729272b5c852086acbc6dd41e0964f76261', 'message': 'placement: add ProviderTree.is_inventory_empty\n\nStandardize how we check for resource provider ""emptiness"".\n\nChange-Id: I044014861a6d7ad3f81c94b44fff6b30dbd6d589\nblueprint: nested-resource-providers\n'}, {'number': 2, 'created': '2017-09-22 14:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25220d2eecf3e09fe400caea312ab8b6f127d855', 'message': 'placement: add ProviderTree.is_inventory_empty\n\nStandardize how we check for resource provider ""emptiness"".\n\nChange-Id: I044014861a6d7ad3f81c94b44fff6b30dbd6d589\nblueprint: nested-resource-providers\n'}, {'number': 3, 'created': '2017-10-09 14:48:44.000000000', 'files': ['nova/scheduler/client/report.py', 'nova/compute/provider_tree.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/40808eb182452a5a78a7ae75e5fe83069347a4a9', 'message': 'placement: add ProviderTree.is_inventory_empty\n\nStandardize how we check for resource provider ""emptiness"".\n\nChange-Id: I044014861a6d7ad3f81c94b44fff6b30dbd6d589\nblueprint: nested-resource-providers\n'}]",0,480957,40808eb182452a5a78a7ae75e5fe83069347a4a9,34,17,3,15334,,,0,"placement: add ProviderTree.is_inventory_empty

Standardize how we check for resource provider ""emptiness"".

Change-Id: I044014861a6d7ad3f81c94b44fff6b30dbd6d589
blueprint: nested-resource-providers
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/480957/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/client/report.py', 'nova/compute/provider_tree.py']",2,ab6fe729272b5c852086acbc6dd41e0964f76261,bp/nested-resource-providers," def is_inventory_empty(self, name_or_uuid): """"""Returns True if the provider with the supplied name or UUID is empty. :param name_or_uuid: Either name or UUID of the resource provider to query inventory for. """""" # if ""unchanged"", the resource provider inventory is empty return not self.has_inventory_changed(name_or_uuid, {}) ",,11,1
openstack%2Fpuppet-ceph~master~Icfcabebed531c10229c9fa0f32e4135259feea41,openstack/puppet-ceph,master,Icfcabebed531c10229c9fa0f32e4135259feea41,Set file ACLs for Ceph keyrings,ABANDONED,2017-10-02 23:25:28.000000000,2017-12-13 14:43:29.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 19564}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-02 23:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/a163f164aa80f3268f2e47502819f9f521fede4e', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 2, 'created': '2017-10-04 17:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/bf4a2471396e63adf476ba77d99bbc411e8e6b8b', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 3, 'created': '2017-10-06 12:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/dde66ee6aca2e85c8954a019c946cf0a7a1194da', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 4, 'created': '2017-10-06 18:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/7d0cf0805ad0a82267c608d7f4612ddaadb0ccb5', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 5, 'created': '2017-10-09 11:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/d33bb0f5cca506005edcd3676e71ff91d4a8be8e', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 6, 'created': '2017-10-09 13:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/03263f2081b801cde0424c9aaa07e95604676a52', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 7, 'created': '2017-10-09 16:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/a05c803f7aa8eb5d2f08a9d24b17c607aeb46e01', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 8, 'created': '2017-10-12 13:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/3fb2449c8929dcfcff4495d5c9e5cbee4795d900', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 9, 'created': '2017-10-17 12:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/7b8d09d004e5d4da3bdb5139de06233989815f3a', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 10, 'created': '2017-10-17 18:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/6dde4c19343e532f899affbcd53f1c7821606892', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 11, 'created': '2017-10-17 23:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/8f371ae1052d09c67fbb3fb0c9f69b7f49c93eda', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 12, 'created': '2017-10-19 11:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/9d370166d3dc3257de5d76438e0bbbd0c284be67', 'message': 'WIP: Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 13, 'created': '2017-10-20 05:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/79bba411a3c6a6fb4c035ddfde5b26de7439eec8', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 14, 'created': '2017-10-20 14:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/0fa1502a46da5308dfedbe47372fd8a30499d07d', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 15, 'created': '2017-10-23 11:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/dfd45b87dc0b7552a57d85c68d24b64f1b4be9e6', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 16, 'created': '2017-10-23 14:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/55dbcf7df42d2a535e79390a1a5593164b67243f', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 17, 'created': '2017-10-23 19:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/18e83049bd5447cea39fa52cdf0f16d1638f2414', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 18, 'created': '2017-10-24 13:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/e8db4d620131e5a5253e2cbb5516c7dd84a501db', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 19, 'created': '2017-10-24 14:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/efd27e1a533871d91b96f594ccaef9cf5f614c8f', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 20, 'created': '2017-10-30 20:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/034e52b8df8633182c9f8333f2b7bde603d2e022', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 21, 'created': '2017-10-30 23:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/7d776332ed488a1580a37a629de7f16b836f1204', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 22, 'created': '2017-10-31 19:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/3d60d28e69a84ef11bedffe9a3a4d24d6bb5a8ae', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}, {'number': 23, 'created': '2017-11-01 02:29:46.000000000', 'files': ['manifests/params.pp', 'spec/defines/ceph_key_spec.rb', 'releasenotes/notes/add-acl-to-ceph-key-ca2f58c4eb191ded.yaml', 'manifests/key.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/0d191f4e3c85497fb0546bc9c5fefb22e8a09d3e', 'message': 'Set file ACLs for Ceph keyrings\n\nGiven a POSIX ACL list, enable puppet-ceph to set the provided\nCeph keyrings to the ACLs in the list.\n\nAuthor:    Keith Schincke <kschinck@redhat.com>\nCo-Author:    John Fulton <fulton@redhat.com>\nChange-Id: Icfcabebed531c10229c9fa0f32e4135259feea41\nCloses-Bug: #1720787\n'}]",12,509021,0d191f4e3c85497fb0546bc9c5fefb22e8a09d3e,64,7,23,18002,,,0,"Set file ACLs for Ceph keyrings

Given a POSIX ACL list, enable puppet-ceph to set the provided
Ceph keyrings to the ACLs in the list.

Author:    Keith Schincke <kschinck@redhat.com>
Co-Author:    John Fulton <fulton@redhat.com>
Change-Id: Icfcabebed531c10229c9fa0f32e4135259feea41
Closes-Bug: #1720787
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/21/509021/12 && git format-patch -1 --stdout FETCH_HEAD,['manifests/key.pp'],1,a163f164aa80f3268f2e47502819f9f521fede4e,bug/1720787,"# [*acls*] list of POSIX file ACLs # Optional. Only taken into account if 'acls' is not undef. # An array of strings in the same format as is used for setfacl. # Default to undef. # $acls = undef, # WIP: would require https://github.com/dobbymoodge/puppet-acl if defined($acls) { acl { $keyring_path: ensure => set, permission => $acls, provider => posixacl, recursive => false, } }",,15,0
openstack%2Fkeystone~master~I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566,openstack/keystone,master,I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566,Implement global scoping of tokens,ABANDONED,2017-08-28 19:29:31.000000000,2017-12-13 14:42:37.000000000,,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 10608}]","[{'number': 1, 'created': '2017-08-28 19:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0c8a7eda4fc69a107d23a9a8ccc2efc1dc100376', 'message': 'Allow global scoping of tokens\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 2, 'created': '2017-08-28 20:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ec2a284ba8284cb6a9b281d179ae2a302509f276', 'message': 'Allow global scoping of tokens\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 3, 'created': '2017-08-28 20:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/73c90f8fd0a1dfae93e81f2beca958e0acdb1bbb', 'message': 'Allow global scoping of tokens\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 4, 'created': '2017-08-28 21:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/15a94e46ad60f9b038bbcbbceb144623967bc093', 'message': 'Allow global scoping of tokens\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 5, 'created': '2017-08-28 21:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9c2ae20dc63971958095f728aa51f75e49db3b5c', 'message': 'Allow global scoping of tokens\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 6, 'created': '2017-08-28 22:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6899144b1fb158701f062363ea2ef3030feb48e3', 'message': 'Allow global scoping of tokens\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 7, 'created': '2017-08-29 14:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/76ef403cbeb517f2a9b09aba98ac0a3535b42c7a', 'message': 'Implement global scoping of tokens\n\nAllow the ability to get tokens scoped to global context.\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 8, 'created': '2017-08-29 15:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fd34834e5fc50e59897bc1322c1337d8da3e4bbd', 'message': 'Implement global scoping of tokens\n\nAllow the ability to get tokens scoped to global context.\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 9, 'created': '2017-08-29 15:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/57097c4b32a563bc52f991803cf8bb6dc03457ed', 'message': 'Implement global scoping of tokens\n\nAllow the ability to get tokens scoped to global context.\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 10, 'created': '2017-08-29 17:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5221f82eef8c34294689c803683d1f61fac78a7d', 'message': 'Implement global scoping of tokens\n\nAllow the ability to get tokens scoped to global context.\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}, {'number': 11, 'created': '2017-09-01 16:24:42.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/token/provider.py', 'keystone/token/controllers.py', 'keystone/token/providers/common.py', 'keystone/tests/unit/test_v3.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/assignment/core.py', 'keystone/auth/core.py', 'keystone/tests/common/auth.py', 'keystone/middleware/auth.py', 'keystone/auth/schema.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4a9307405ddbe01d524cd874b65a68d334e18b4f', 'message': 'Implement global scoping of tokens\n\nAllow the ability to get tokens scoped to global context.\n\nbp global-roles\n\nChange-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566\n'}]",3,498577,4a9307405ddbe01d524cd874b65a68d334e18b4f,23,4,11,5046,,,0,"Implement global scoping of tokens

Allow the ability to get tokens scoped to global context.

bp global-roles

Change-Id: I4238f20aa8b01d3f18b00a5ed8fae27dc1e92566
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/498577/11 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/controllers.py', 'keystone/token/controllers.py', 'keystone/token/provider.py', 'keystone/token/providers/common.py', 'keystone/tests/unit/test_v3.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/assignment/core.py', 'keystone/token/providers/fernet/token_formatters.py', 'keystone/token/providers/fernet/core.py', 'keystone/auth/core.py']",10,0c8a7eda4fc69a107d23a9a8ccc2efc1dc100376,bp/global-roles," self._scope_data = (None, None, None, None, None) # self._scope_data is # (domain_id, project_id, trust_ref, unscoped, global) # project scope: (None, project_id, None, None, None) # domain scope: (domain_id, None, None, None, None) # trust scope: (None, None, trust_ref, None, None) # unscoped: (None, None, None, 'unscoped', None) # global: (None, None, None, None, 'global') 'global' in self.auth['scope'], if 'global' in self.auth['scope']: self._scope_data = (None, None, None, None, 'global') if 'unscoped' in self.auth['scope']: self._scope_data = (None, None, None, 'unscoped', None) self._scope_data = (None, project_ref['id'], None, None, None) self._scope_data = (domain_ref['id'], None, None, None, None) self._scope_data = ( None, project_ref['id'], trust_ref, None, None ) else: self._scope_data = (None, None, trust_ref, None, None) unscoped=None, global_token=None): self._scope_data = ( domain_id, project_id, trust, unscoped, global_token )"," self._scope_data = (None, None, None, None) # self._scope_data is (domain_id, project_id, trust_ref, unscoped) # project scope: (None, project_id, None, None) # domain scope: (domain_id, None, None, None) # trust scope: (None, None, trust_ref, None) # unscoped: (None, None, None, 'unscoped') if 'unscoped' in self.auth['scope']: self._scope_data = (None, None, None, 'unscoped') self._scope_data = (None, project_ref['id'], None, None) self._scope_data = (domain_ref['id'], None, None, None) self._scope_data = (None, project_ref['id'], trust_ref, None) else: self._scope_data = (None, None, trust_ref, None) unscoped=None): self._scope_data = (domain_id, project_id, trust, unscoped)",463,111
openstack%2Fopenstack-ansible-os_glance~master~I716c9fe35391629532e67e212d45ea27a5422d1b,openstack/openstack-ansible-os_glance,master,I716c9fe35391629532e67e212d45ea27a5422d1b,Update glance NFS for systemd,MERGED,2017-12-10 17:11:32.000000000,2017-12-13 14:34:58.000000000,2017-12-13 14:34:58.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-10 17:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/1ffc1a3c3afd766900d2546552b9e829f1d2aa05', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-12-10 17:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/f27bbb4dccd13188f419278e39c52b142332c6d5', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2017-12-10 23:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/90135fe53044e045696e2c8059e52eea734b3b27', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - A test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2017-12-10 23:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/ee81862dbbb2066cf376dbba38c65e678329a162', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - A test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2017-12-11 00:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/b5c838137fff8ebcd5abecee2f7f7761c3c17aa3', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - To ensure out NFS backend solution works with the installation of\n   glance a test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2017-12-11 03:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/0117a32bdacb06a397fa34f7da06b82920b4cb81', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - To ensure out NFS backend solution works with the installation of\n   glance a test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2017-12-11 03:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/ae3de0f3ae61a788c8ff3c651656c39083754175', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - To ensure out NFS backend solution works with the installation of\n   glance a test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2017-12-11 23:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/775ebc846085baca2d264adb3a31296542e545ea', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - To ensure out NFS backend solution works with the installation of\n   glance a test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2017-12-12 03:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/4e2a6740e6c4417f966d53009a76aad478a5816b', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - To ensure out NFS backend solution works with the installation of\n   glance a test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2017-12-12 23:50:05.000000000', 'files': ['tasks/glance_post_install.yml', 'tests/overrides-nfs.yml', 'tests/test-create-nfs-dev.yml', 'tests/host_vars/localhost.yml', 'handlers/main.yml', 'tests/test.yml', 'defaults/main.yml', 'tasks/glance_pre_install.yml', 'releasenotes/notes/systemd-nfs-setup-5c35c23eda4443be.yaml', 'tests/group_vars/all_containers.yml', 'zuul.d/project.yaml', 'templates/glance-systemd-mount.j2', 'tox.ini', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/477d44cab947a1d5db68bfaa240eb753ad9fabf0', 'message': 'Update glance NFS for systemd\n\nSystemd has the ability to manage mounts and ensure functionality\n/ resource management. Using a systemd mount has the benifit of not\nrequiring writes to the legacy fstab file which can impact OS\nfunctionality especially when deploying on baremetal. This change\nmoves the glance NFS mount to a systemd unit file allowing systemd\nto manage it independently with no potentially breaking impact to\nthe underlying operating system.\n\nChanges:\n - This PR corrects a long standing issue when using Glance+NFS where\n   initial deployment would work but if the playbooks were run again\n   it would fail due to the glance images location being an NFS mount\n   point with a potentially different UID/GID. To correct this we stat\n   the directory and if it does NOT exist it is created.\n - Following the nova pattern options have been provided to set the UID\n   and GID of the glance user.\n - To ensure out NFS backend solution works with the installation of\n   glance a test has been added to deploy glance using an NFS backend.\n - An upgrade task has been added to this commit to clean up legacy\n   mounts, This task should be removed in R.\n\nChange-Id: I716c9fe35391629532e67e212d45ea27a5422d1b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",7,526930,477d44cab947a1d5db68bfaa240eb753ad9fabf0,36,5,10,7353,,,0,"Update glance NFS for systemd

Systemd has the ability to manage mounts and ensure functionality
/ resource management. Using a systemd mount has the benifit of not
requiring writes to the legacy fstab file which can impact OS
functionality especially when deploying on baremetal. This change
moves the glance NFS mount to a systemd unit file allowing systemd
to manage it independently with no potentially breaking impact to
the underlying operating system.

Changes:
 - This PR corrects a long standing issue when using Glance+NFS where
   initial deployment would work but if the playbooks were run again
   it would fail due to the glance images location being an NFS mount
   point with a potentially different UID/GID. To correct this we stat
   the directory and if it does NOT exist it is created.
 - Following the nova pattern options have been provided to set the UID
   and GID of the glance user.
 - To ensure out NFS backend solution works with the installation of
   glance a test has been added to deploy glance using an NFS backend.
 - An upgrade task has been added to this commit to clean up legacy
   mounts, This task should be removed in R.

Change-Id: I716c9fe35391629532e67e212d45ea27a5422d1b
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/30/526930/7 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/glance_post_install.yml', 'handlers/main.yml', 'templates/glance-systemd-mount.j2', 'defaults/main.yml']",4,1ffc1a3c3afd766900d2546552b9e829f1d2aa05,systemd-nfs-mount,"# config_overrides: ""{}"" ## Override dictionary for unit file",,38,6
openstack%2Fpython-watcherclient~master~I830abe0a3cd67484e165a0a42d5a57b75ed4dac6,openstack/python-watcherclient,master,I830abe0a3cd67484e165a0a42d5a57b75ed4dac6,Fix unnecessary retries during conflict,MERGED,2017-10-20 02:27:16.000000000,2017-12-13 14:24:13.000000000,2017-12-13 14:24:13.000000000,"[{'_account_id': 12394}, {'_account_id': 13111}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 22775}, {'_account_id': 24872}]","[{'number': 1, 'created': '2017-10-20 02:27:16.000000000', 'files': ['watcherclient/common/httpclient.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/5378102cd61fcafa6f052e231cd3ece3624fb363', 'message': 'Fix unnecessary retries during conflict\n\nThis patch removes retries from python-watcherclient in case\nwatcher-api responded with conflict case.\n\nChange-Id: I830abe0a3cd67484e165a0a42d5a57b75ed4dac6\nCloses-Bug: #1725088\n'}]",0,513584,5378102cd61fcafa6f052e231cd3ece3624fb363,8,8,1,19457,,,0,"Fix unnecessary retries during conflict

This patch removes retries from python-watcherclient in case
watcher-api responded with conflict case.

Change-Id: I830abe0a3cd67484e165a0a42d5a57b75ed4dac6
Closes-Bug: #1725088
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/84/513584/1 && git format-patch -1 --stdout FETCH_HEAD,['watcherclient/common/httpclient.py'],1,5378102cd61fcafa6f052e231cd3ece3624fb363,bug/1725088,"_RETRY_EXCEPTIONS = (exceptions.ServiceUnavailable,","_RETRY_EXCEPTIONS = (exceptions.Conflict, exceptions.ServiceUnavailable,",1,2
openstack%2Fopenstack-ansible-plugins~master~If91214dd2d2a36da82e5433a3a4a36c3946cbf4e,openstack/openstack-ansible-plugins,master,If91214dd2d2a36da82e5433a3a4a36c3946cbf4e,Remove the vars plugin as it's no longer used,MERGED,2017-12-12 14:36:18.000000000,2017-12-13 14:13:10.000000000,2017-12-13 14:13:10.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/e33eb357c73fcc5ba045e3ae1857ace43a984d22', 'message': ""Remove the vars plugin as it's no longer used\n\nThis plugin is no longer used and conflicts with Ansible 2.4. Master\nhas recently moved to Ansible 2.4 and placed all of the group_vars back\ninto the inventory path. Being that the plugin is no longer required\nand results in a runtime warning[0] it's being removed.\n\n[0] - http://paste.openstack.org/show/628674/\n\nChange-Id: If91214dd2d2a36da82e5433a3a4a36c3946cbf4e\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 2, 'created': '2017-12-13 04:09:51.000000000', 'files': ['releasenotes/notes/removed-vars-plugin-0f9fb96e8b2c430d.yaml', 'vars_plugins/override_folder.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/c665f9f2a2dea2ac532402d41b68b6132fd774bc', 'message': ""Remove the vars plugin as it's no longer used\n\nThis plugin is no longer used and conflicts with Ansible 2.4. Master\nhas recently moved to Ansible 2.4 and placed all of the group_vars back\ninto the inventory path. Being that the plugin is no longer required\nand results in a runtime warning[0] it's being removed.\n\n[0] - http://paste.openstack.org/show/628674/\n\nChange-Id: If91214dd2d2a36da82e5433a3a4a36c3946cbf4e\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,527415,c665f9f2a2dea2ac532402d41b68b6132fd774bc,12,6,2,7353,,,0,"Remove the vars plugin as it's no longer used

This plugin is no longer used and conflicts with Ansible 2.4. Master
has recently moved to Ansible 2.4 and placed all of the group_vars back
into the inventory path. Being that the plugin is no longer required
and results in a runtime warning[0] it's being removed.

[0] - http://paste.openstack.org/show/628674/

Change-Id: If91214dd2d2a36da82e5433a3a4a36c3946cbf4e
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/15/527415/2 && git format-patch -1 --stdout FETCH_HEAD,['vars_plugins/override_folder.py'],1,e33eb357c73fcc5ba045e3ae1857ace43a984d22,,,"# (c) 2017, Jean-Philippe Evrard <jean-philippe.evrard@rackspace.co.uk> # # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from __future__ import (absolute_import, division, print_function) __metaclass__ = type import os try: from __main__ import display except ImportError: from ansible.utils.display import Display display = Display() from ansible.parsing.dataloader import DataLoader from ansible.utils.vars import merge_hash from ansible import __version__ as ansible_version from distutils.version import LooseVersion def vars_files_loading(folder, name, matched=False): """""" Load files recursively and sort them """""" files = [] try: candidates = [os.path.join(folder, f) for f in os.listdir(folder)] except OSError: return files for f in candidates: if (os.path.basename(f) in [name, name + "".yml"", name + "".yaml""] or matched): if os.path.isfile(f): files.append(f) elif os.path.isdir(f): files.extend(vars_files_loading(f, name, matched=True)) return sorted(files) if LooseVersion(ansible_version) < LooseVersion('2.4.0'): class VarsModule(object): """""" Loads variables for groups and/or hosts """""" def __init__(self, inventory): """""" constructor """""" self.inventory = inventory self.inventory_basedir = inventory.basedir() self.grp_vars_string = os.environ.get( 'GROUP_VARS_PATH', '/etc/openstack_deploy/group_vars') self.grp_vars_folders = self.grp_vars_string.split("":"") self.host_vars_string = os.environ.get( 'HOST_VARS_PATH', '/etc/openstack_deploy/host_vars') self.host_vars_folders = self.host_vars_string.split("":"") def run(self, host, vault_password=None): """""" This function is only used for backwards compatibility with ansible1. We don't need to handle this case. """""" return {} def get_host_vars(self, host, vault_password=None): """""" Get host specific variables. """""" resulting_host_vars = {} var_files = [] for host_var_folder in self.host_vars_folders: var_files.extend(vars_files_loading(host_var_folder, host.name)) _dataloader = DataLoader() _dataloader.set_vault_password(vault_password) for filename in var_files: display.vvvvv( ""Hostname {}: Loading var file {}"".format(host.name, filename)) data = _dataloader.load_from_file(filename) if data is not None: resulting_host_vars = merge_hash(resulting_host_vars, data) return resulting_host_vars def get_group_vars(self, group, vault_password=None): """""" Get group specific variables. """""" resulting_group_vars = {} var_files = [] for grp_var_folder in self.grp_vars_folders: var_files.extend(vars_files_loading(grp_var_folder, group.name)) _dataloader = DataLoader() _dataloader.set_vault_password(vault_password) for filename in var_files: display.vvvvv( ""Group {}: Loading var file {}"".format(group.name, filename)) data = _dataloader.load_from_file(filename) if data is not None: resulting_group_vars = merge_hash(resulting_group_vars, data) return resulting_group_vars ",0,111
openstack%2Fpuppet-octavia~master~I712db2e7310ba32cb68a7266c6b563ab3f4ab8cf,openstack/puppet-octavia,master,I712db2e7310ba32cb68a7266c6b563ab3f4ab8cf,Add auth_type parameter to service_auth section,MERGED,2017-12-12 15:51:37.000000000,2017-12-13 14:12:02.000000000,2017-12-13 14:12:02.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 25899}]","[{'number': 1, 'created': '2017-12-12 15:51:37.000000000', 'files': ['spec/classes/octavia_service_auth_spec.rb', 'manifests/service_auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/8cb1a195e452be579818f747b5838eefcc67f599', 'message': 'Add auth_type parameter to service_auth section\n\nAdd parameter to allow setting auth_type.\n\nChange-Id: I712db2e7310ba32cb68a7266c6b563ab3f4ab8cf\n'}]",0,527441,8cb1a195e452be579818f747b5838eefcc67f599,9,4,1,6681,,,0,"Add auth_type parameter to service_auth section

Add parameter to allow setting auth_type.

Change-Id: I712db2e7310ba32cb68a7266c6b563ab3f4ab8cf
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/41/527441/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/octavia_service_auth_spec.rb', 'manifests/service_auth.pp']",2,8cb1a195e452be579818f747b5838eefcc67f599,,"# [*auth_type*] # (optional) keystone authentication type # Defaults to $::os_service_default # $auth_type = $::os_service_default, 'service_auth/auth_type' : value => $auth_type;",,10,1
openstack%2Fnetworking-bagpipe~master~I1579cbfdacb964e1248ce26c64f7efba9aabe7e7,openstack/networking-bagpipe,master,I1579cbfdacb964e1248ce26c64f7efba9aabe7e7,Add _port_data to agent extensions unit tests base class,MERGED,2017-12-12 15:28:43.000000000,2017-12-13 14:03:02.000000000,2017-12-13 14:03:02.000000000,"[{'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 15:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/ed9fe12f2680bcbca057dde4885e46e10943d059', 'message': 'Add _port_data to agent extensions unit tests base class\n\nThis method will be usefull for the unit tests\nof all services (l2, bgpvpn, sfc).\n\nChange-Id: I1579cbfdacb964e1248ce26c64f7efba9aabe7e7\n'}, {'number': 2, 'created': '2017-12-13 11:02:29.000000000', 'files': ['networking_bagpipe/tests/unit/agent/base.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/dc9830614d331f65b7d8270fd1d1b2051b91d9eb', 'message': 'Add _port_data to agent extensions unit tests base class\n\nThis method will be usefull for the unit tests\nof all services (l2, bgpvpn, sfc).\n\nChange-Id: I1579cbfdacb964e1248ce26c64f7efba9aabe7e7\n'}]",0,527427,dc9830614d331f65b7d8270fd1d1b2051b91d9eb,8,2,2,12021,,,0,"Add _port_data to agent extensions unit tests base class

This method will be usefull for the unit tests
of all services (l2, bgpvpn, sfc).

Change-Id: I1579cbfdacb964e1248ce26c64f7efba9aabe7e7
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/27/527427/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bagpipe/tests/unit/agent/base.py'],1,ed9fe12f2680bcbca057dde4885e46e10943d059,bp/bagpipe-bgpvpn-ovo," def _port_data(self, port, delete=False): data = { 'port_id': port['id'] } if not delete: data.update({ 'port_id': port['id'], 'network_id': port_2_net[port['id']]['id'], 'segmentation_id': TEST_VNI, 'network_type': 'vxlan', 'device_owner': 'compute:None', 'mac_address': port['mac_address'], 'fixed_ips': [ { 'ip_address': port['ip_address'], } ] }) return data ",,20,0
openstack%2Fkolla-ansible~master~Icd8cb0dd27a58ac9f10f4228d883934d0fab9bbb,openstack/kolla-ansible,master,Icd8cb0dd27a58ac9f10f4228d883934d0fab9bbb,[DNM]Test jobs.roles,ABANDONED,2017-12-12 05:19:42.000000000,2017-12-13 13:53:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2017-12-12 05:19:42.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d5b4dbdf780059772bcaaef0719e8dae106bcf15', 'message': '[DNM]Test jobs.roles\n\nChange-Id: Icd8cb0dd27a58ac9f10f4228d883934d0fab9bbb\n'}]",0,527304,d5b4dbdf780059772bcaaef0719e8dae106bcf15,3,1,1,7488,,,0,"[DNM]Test jobs.roles

Change-Id: Icd8cb0dd27a58ac9f10f4228d883934d0fab9bbb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/04/527304/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d5b4dbdf780059772bcaaef0719e8dae106bcf15,, roles: - zuul: openstack/kolla, - kolla-ansible-ubuntu-source - kolla-ansible-oraclelinux-source,2,2
openstack%2Fblazar~master~I1fb02c403c6e588e49fa455969895731b88e5dd7,openstack/blazar,master,I1fb02c403c6e588e49fa455969895731b88e5dd7,Enable uWSGI deployment of the blazar-api service,MERGED,2017-11-20 06:00:02.000000000,2017-12-13 13:50:55.000000000,2017-12-13 13:50:55.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 19853}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-11-20 06:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/f17eb4fc59fe07b951dca6feeda693d5c82ce87d', 'message': 'Enable uwsgi deplyment of blazar-api service\n\nThis patch adds wsgi entry point to setup.cfg and enables\nusers to deploy blazar-api service as an uwsgi service.\n\nPatially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7\n'}, {'number': 2, 'created': '2017-11-20 06:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/d5909c503c3c64d078c67b346ea45af601c118d3', 'message': 'Enable uwsgi deplyment of blazar-api service\n\nThis patch adds wsgi entry point to setup.cfg and enables\nusers to deploy blazar-api service as an uwsgi service.\n\nPatially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7\n'}, {'number': 3, 'created': '2017-12-04 07:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/8fda30aad7a0d140277197f0fcb979a7db20dfeb', 'message': 'Enable uwsgi deplyment of blazar-api service\n\nThis patch adds wsgi entry point to setup.cfg and enables\nusers to deploy blazar-api service as an uwsgi service.\n\nIf operators want to deploy blazar-api under their own\nservers that support wsgi application, they can get wsgi\napp by calling blazar.api.wsgi_app.init_app().\n\nIf you need more details about wsgi itself, please see the\nfollowing link.\n\nhttps://www.python.org/dev/peps/pep-3333/\n\nPatially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7\n'}, {'number': 4, 'created': '2017-12-05 10:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/88607fb41172cd74361181cc84f3857ec2bbc1a8', 'message': 'Enable uwsgi deployment of blazar-api service\n\nThis patch adds a wsgi entry point to setup.cfg and enables users to\ndeploy the blazar-api service as a uwsgi service.\n\nIf operators want to deploy blazar-api under their own servers that\nsupport wsgi applications, they can get the wsgi app by calling\nblazar.api.wsgi_app.init_app().\n\nIf you need more details about wsgi itself, please see the following\nlink: https://www.python.org/dev/peps/pep-3333/\n\nPatially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7\n'}, {'number': 5, 'created': '2017-12-13 12:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/5550e86c6f7f02d76d33543af60dde2b41b17959', 'message': 'Enable uWSGI deployment of the blazar-api service\n\nThis patch adds a WSGI entry point to setup.cfg and enables users to\ndeploy the blazar-api service as a uWSGI service.\n\nIf operators want to deploy blazar-api under their own servers that\nsupport WSGI applications, they can get the WSGI app by calling\nblazar.api.wsgi_app.init_app().\n\nIf you need more details about WSGI itself, please see the following\nlink: https://www.python.org/dev/peps/pep-3333/\n\nPatially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7\n'}, {'number': 6, 'created': '2017-12-13 12:30:17.000000000', 'files': ['blazar/cmd/api.py', 'blazar/opts.py', 'blazar/config.py', 'blazar/api/wsgi_app.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/blazar/commit/06424f8e074879a997931cdb8c15206039704882', 'message': 'Enable uWSGI deployment of the blazar-api service\n\nThis patch adds a WSGI entry point to setup.cfg and enables users to\ndeploy the blazar-api service as a uWSGI service.\n\nIf operators want to deploy blazar-api under their own servers that\nsupport WSGI applications, they can get the WSGI app by calling\nblazar.api.wsgi_app.init_app().\n\nIf you need more details about WSGI itself, please see the following\nlink: https://www.python.org/dev/peps/pep-3333/\n\nPatially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7\n'}]",5,521423,06424f8e074879a997931cdb8c15206039704882,24,5,6,8878,,,0,"Enable uWSGI deployment of the blazar-api service

This patch adds a WSGI entry point to setup.cfg and enables users to
deploy the blazar-api service as a uWSGI service.

If operators want to deploy blazar-api under their own servers that
support WSGI applications, they can get the WSGI app by calling
blazar.api.wsgi_app.init_app().

If you need more details about WSGI itself, please see the following
link: https://www.python.org/dev/peps/pep-3333/

Patially Implements: blueprint deploy-api-in-wsgi
Change-Id: I1fb02c403c6e588e49fa455969895731b88e5dd7
",git fetch https://review.opendev.org/openstack/blazar refs/changes/23/521423/6 && git format-patch -1 --stdout FETCH_HEAD,"['blazar/common/wsgi_app.py', 'blazar/cmd/api.py', 'blazar/config.py', 'setup.cfg']",4,f17eb4fc59fe07b951dca6feeda693d5c82ce87d,goal-deploy-api-in-wsgi,wsgi_scripts = blazar-api-wsgi = blazar.common.wsgi_app:init_app ,,62,9
openstack%2Fwatcher-dashboard~master~I863d45805b3d7df4c4a40019ecfbbb9abb2c8ced,openstack/watcher-dashboard,master,I863d45805b3d7df4c4a40019ecfbbb9abb2c8ced,Cleanup test-requirements,MERGED,2017-12-11 13:13:53.000000000,2017-12-13 13:50:27.000000000,2017-12-13 13:50:27.000000000,"[{'_account_id': 19055}, {'_account_id': 21692}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 13:13:53.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/watcher-dashboard/commit/c9803bec292738d64d524b66da771056144d9af5', 'message': 'Cleanup test-requirements\n\npython-subunit is not used directly anywhere\nand it is dependency of both testrepository\nand os-testr\n(probably was used by some tox wrapper script before)\n\nChange-Id: I863d45805b3d7df4c4a40019ecfbbb9abb2c8ced\n'}]",0,527084,c9803bec292738d64d524b66da771056144d9af5,7,3,1,17130,,,0,"Cleanup test-requirements

python-subunit is not used directly anywhere
and it is dependency of both testrepository
and os-testr
(probably was used by some tox wrapper script before)

Change-Id: I863d45805b3d7df4c4a40019ecfbbb9abb2c8ced
",git fetch https://review.opendev.org/openstack/watcher-dashboard refs/changes/84/527084/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c9803bec292738d64d524b66da771056144d9af5,update-requirement,,testrepository>=0.0.18 # Apache-2.0/BSD,0,1
openstack%2Fvitrage~master~I4b2d12d9be01fa8243ceab9b6457eb4e2e99331e,openstack/vitrage,master,I4b2d12d9be01fa8243ceab9b6457eb4e2e99331e,fix unit test unstable database creation,ABANDONED,2017-12-13 08:44:38.000000000,2017-12-13 13:47:36.000000000,,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 08:44:38.000000000', 'files': ['vitrage/tests/test_configuration.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a0af732189c1d6087c53d4c4002dd54659a6f45e', 'message': 'fix unit test unstable database creation\n\nChange-Id: I4b2d12d9be01fa8243ceab9b6457eb4e2e99331e\n'}]",0,527632,a0af732189c1d6087c53d4c4002dd54659a6f45e,8,4,1,19184,,,0,"fix unit test unstable database creation

Change-Id: I4b2d12d9be01fa8243ceab9b6457eb4e2e99331e
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/32/527632/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/tests/test_configuration.py'],1,a0af732189c1d6087c53d4c4002dd54659a6f45e,fix_unitest_unstable_database," db_name = ""sqlite:///test_%s.db"" % cls.__name__ conf.set_override('connection', db_name, group='database') models.Base.metadata.drop_all(engine)"," conf.set_override('connection', 'sqlite:///:test.db:', group='database')",3,2
openstack%2Fironic~master~I79a694a436a7b2ab8b780600bbf2ca44a8ef049f,openstack/ironic,master,I79a694a436a7b2ab8b780600bbf2ca44a8ef049f,[DO NOT MERGE] Testing gate fix,ABANDONED,2017-12-11 12:29:00.000000000,2017-12-13 13:41:54.000000000,,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 12:29:00.000000000', 'files': ['ironic/version.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e2efd155c044398dc8a801ef672fba2415c3ca40', 'message': '[DO NOT MERGE] Testing gate fix\n\nChange-Id: I79a694a436a7b2ab8b780600bbf2ca44a8ef049f\nDepends-On: I4253cffca3dbf558c875eed7e77711a31e9e3406\n'}]",0,527075,e2efd155c044398dc8a801ef672fba2415c3ca40,17,7,1,10239,,,0,"[DO NOT MERGE] Testing gate fix

Change-Id: I79a694a436a7b2ab8b780600bbf2ca44a8ef049f
Depends-On: I4253cffca3dbf558c875eed7e77711a31e9e3406
",git fetch https://review.opendev.org/openstack/ironic refs/changes/75/527075/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/version.py'],1,e2efd155c044398dc8a801ef672fba2415c3ca40,test,,,1,0
openstack%2Fnova~master~I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e,openstack/nova,master,I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e,[placement] Add cache headers to placement api requests,MERGED,2017-11-20 19:16:34.000000000,2017-12-13 13:37:14.000000000,2017-12-13 05:30:32.000000000,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-20 19:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a07702276b43c0ec0dbc64189e70680873b621b', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.12 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.12, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 2, 'created': '2017-11-21 09:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8be50b80c8172b0aa220834867cf60d5402f1325', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.12 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.12, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 3, 'created': '2017-11-28 13:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d71bdbd6bf8e196e92a9181cb2ffc440331df1f9', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.13 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.13, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 4, 'created': '2017-11-29 16:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0833443b33837a7b4a6873803a5702bd0b932596', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.14 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.14, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 5, 'created': '2017-11-30 10:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2898db76e856595d22962a5f148bfe8fb05969e1', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.14 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.14, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 6, 'created': '2017-12-04 11:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a5ef4c4ca971b4501332a7a82b4b344709c2d1d', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.14 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.14, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 7, 'created': '2017-12-06 15:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7602ce95323cafdf1aa1db19238e9f7f4965b07', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.14 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.14, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 8, 'created': '2017-12-07 19:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/44d629c708efb84b94be8dc3f749d1aa0482cefd', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.14 which adds the headers to GET\nrequests and any PUT or POST requests that include response bodies.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. This is assisted\n  by a new util method: pick_last_modfied.\n* For PUT and POST with bodies use the current time\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, the current time is used.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.14, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 9, 'created': '2017-12-11 19:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18f478523a52de920972b6de2ec3852fd0cc22d5', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.15 which adds the headers to GET\nrequests and some PUT or POST requests.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. In most loops,\n  we only do that if we have a high enough microversion such that the\n  information will be used. This is not done when listing inventories\n  because the expectation is that no single resource provider will\n  ever have a huge number of inventory records.\n* Both of the prior steps are assisted by a new util method:\n  pick_last_modfied.\n\nWhere a time cannot be determined the current time is used.\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, such as usages and aggregate associtions the current time\nis used.\n\nThe handler for PUT /traits is modified a bit more extensively than some\nof the others: This is because the method can either create or validate\nthe existence of the trait. In the case where the trait already exists,\nwe need to get it from the DB to get its created_at time. We only do\nthis if the microversion is high enough (at least 1.15) to warrant\nneeding the info.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.15, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}, {'number': 10, 'created': '2017-12-12 15:53:51.000000000', 'files': ['nova/tests/functional/api/openstack/placement/gabbits/usage.yaml', 'nova/api/openstack/placement/handlers/inventory.py', 'releasenotes/notes/placement-last-modified-cf43aece4c54fc97.yaml', 'nova/api/openstack/placement/handlers/resource_class.py', 'nova/tests/functional/api/openstack/placement/gabbits/resource-provider.yaml', 'nova/api/openstack/placement/handlers/root.py', 'nova/api/openstack/placement/handlers/allocation.py', 'nova/tests/functional/api/openstack/placement/gabbits/with-allocations.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocations.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/traits.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/basic-http.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/inventory.yaml', 'nova/tests/unit/api/openstack/placement/test_handler.py', 'nova/api/openstack/placement/util.py', 'nova/tests/functional/api/openstack/placement/gabbits/aggregate.yaml', 'nova/tests/unit/api/openstack/placement/test_util.py', 'nova/api/openstack/placement/handlers/trait.py', 'nova/tests/functional/api/openstack/placement/gabbits/microversion.yaml', 'nova/api/openstack/placement/microversion.py', 'nova/api/openstack/placement/rest_api_version_history.rst', 'nova/api/openstack/placement/handlers/aggregate.py', 'nova/api/openstack/placement/handlers/allocation_candidate.py', 'nova/api/openstack/placement/handlers/usage.py', 'nova/api/openstack/placement/handlers/resource_provider.py', 'nova/tests/functional/api/openstack/placement/gabbits/resource-classes-last-modified.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/83030804cc7556d50023c2968c51d2a6173063a0', 'message': '[placement] Add cache headers to placement api requests\n\nIn relevant requests to the placement API add last-modified\nand cache-control headers.\n\nAccording the HTTP 1.1 RFC headers last-modified headers SHOULD always\nbe sent and should have a tie to the real last modified time. If we do\nsend them, we need Cache-Control headers to prevent inadvertent caching\nof resources.\n\nThis change adds a microversion 1.15 which adds the headers to GET\nrequests and some PUT or POST requests.\n\nDespite what it says \'no-cache\' means ""check to see if the version you\nhave is still valid as far as the server is concerned"". Since our server\ndoesn\'t currently validate conditional requests and will always return an\nentity, it ends up meaning ""don\'t cache"" (which is what we want).\n\nThe main steps in the patch are:\n\n* To both the get single entity and get collection handlers add\n  response.cache_control = \'no-cache\'\n* For single entity add response.last_modified = obj.updated_at or\n  obj.created_at\n* For collections, discover the max modified time when traversing the\n  list of objects to create the serialized JSON output. In most of\n  those loops an optimization is done where we only check for\n  last-modified information if we have a high enough microversion such\n  that the information will be used. This is not done when listing\n  inventories because the expectation is that no single resource\n  provider will ever have a huge number of inventory records.\n* Both of the prior steps are assisted by a new util method:\n  pick_last_modfied.\n\nWhere a time cannot be determined the current time is used.\n\nIn typical placement framework fashion this has been done in a very\nexplicit way, as it makes what the handler is doing very visible, even\nthough it results in a bit of boilerplate.\n\nFor those requests that are created from multiple objects or by doing\ncalculations, such as usages and aggregate associations, the current time\nis used.\n\nThe handler for PUT /traits is modified a bit more extensively than some\nof the others: This is because the method can either create or validate\nthe existence of the trait. In the case where the trait already exists,\nwe need to get it from the DB to get its created_at time. We only do\nthis if the microversion is high enough (at least 1.15) to warrant\nneeding the info.\n\nBecause these changes add new headers (even though they don\'t do\nanything) a new microversion, 1.15, is added.\n\nPartial-Bug: #1632852\nPartially-Implements: bp placement-cache-headers\n\nChange-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e\n'}]",56,521640,83030804cc7556d50023c2968c51d2a6173063a0,167,17,10,11564,,,0,"[placement] Add cache headers to placement api requests

In relevant requests to the placement API add last-modified
and cache-control headers.

According the HTTP 1.1 RFC headers last-modified headers SHOULD always
be sent and should have a tie to the real last modified time. If we do
send them, we need Cache-Control headers to prevent inadvertent caching
of resources.

This change adds a microversion 1.15 which adds the headers to GET
requests and some PUT or POST requests.

Despite what it says 'no-cache' means ""check to see if the version you
have is still valid as far as the server is concerned"". Since our server
doesn't currently validate conditional requests and will always return an
entity, it ends up meaning ""don't cache"" (which is what we want).

The main steps in the patch are:

* To both the get single entity and get collection handlers add
  response.cache_control = 'no-cache'
* For single entity add response.last_modified = obj.updated_at or
  obj.created_at
* For collections, discover the max modified time when traversing the
  list of objects to create the serialized JSON output. In most of
  those loops an optimization is done where we only check for
  last-modified information if we have a high enough microversion such
  that the information will be used. This is not done when listing
  inventories because the expectation is that no single resource
  provider will ever have a huge number of inventory records.
* Both of the prior steps are assisted by a new util method:
  pick_last_modfied.

Where a time cannot be determined the current time is used.

In typical placement framework fashion this has been done in a very
explicit way, as it makes what the handler is doing very visible, even
though it results in a bit of boilerplate.

For those requests that are created from multiple objects or by doing
calculations, such as usages and aggregate associations, the current time
is used.

The handler for PUT /traits is modified a bit more extensively than some
of the others: This is because the method can either create or validate
the existence of the trait. In the case where the trait already exists,
we need to get it from the DB to get its created_at time. We only do
this if the microversion is high enough (at least 1.15) to warrant
needing the info.

Because these changes add new headers (even though they don't do
anything) a new microversion, 1.15, is added.

Partial-Bug: #1632852
Partially-Implements: bp placement-cache-headers

Change-Id: I727d4c77aaa31f0ef31c8af22c2d46cad8ab8b8e
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/521640/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api/openstack/placement/gabbits/usage.yaml', 'nova/api/openstack/placement/handlers/inventory.py', 'releasenotes/notes/placement-last-modified-cf43aece4c54fc97.yaml', 'nova/api/openstack/placement/handlers/resource_class.py', 'nova/tests/functional/api/openstack/placement/gabbits/resource-provider.yaml', 'nova/api/openstack/placement/handlers/root.py', 'nova/api/openstack/placement/handlers/allocation.py', 'nova/tests/functional/api/openstack/placement/gabbits/with-allocations.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocations.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/traits.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/basic-http.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/inventory.yaml', 'nova/api/openstack/placement/util.py', 'nova/tests/functional/api/openstack/placement/gabbits/aggregate.yaml', 'nova/tests/unit/api/openstack/placement/test_util.py', 'nova/api/openstack/placement/handlers/trait.py', 'nova/tests/functional/api/openstack/placement/gabbits/microversion.yaml', 'nova/api/openstack/placement/microversion.py', 'nova/api/openstack/placement/rest_api_version_history.rst', 'nova/api/openstack/placement/handlers/aggregate.py', 'nova/api/openstack/placement/handlers/allocation_candidate.py', 'nova/api/openstack/placement/handlers/usage.py', 'nova/api/openstack/placement/handlers/resource_provider.py', 'nova/tests/functional/api/openstack/placement/gabbits/resource-classes-last-modified.yaml']",25,3a07702276b43c0ec0dbc64189e70680873b621b,bug/1632852,"# Confirm the behavior and presence of last-modified headers for resource # classes across multiple microversions. # # We have the following routes, with associated microversion, and bodies. # # '/resource_classes': { # 'GET': resource_class.list_resource_classes, # v1.2, body # 'POST': resource_class.create_resource_class # v1.2, no body # }, # '/resource_classes/{name}': { # 'GET': resource_class.get_resource_class, # v1.2, body # 'PUT': resource_class.update_resource_class, # v1.2, body, but time's arrow # v1.7, no body # 'DELETE': resource_class.delete_resource_class, # v1.2, no body # }, # # This means that in 1.12 we only expect last-modified headers for # the two GET requests, for the other requests we should confirm it # is not there. fixtures: - APIFixture defaults: request_headers: x-auth-token: admin accept: application/json content-type: application/json openstack-api-version: placement 1.12 tests: - name: get resource classes desc: last modified is now with standards only GET: /resource_classes response_headers: cache-control: no-cache # Does last-modified look like a legit timestamp? last-modified: /^\w+, \d+ \w+ \d{4} [\d:]+ GMT$/ - name: create a custom class PUT: /resource_classes/CUSTOM_MOO_MACHINE status: 201 response_forbidden_headers: - last-modified - cache-control - name: get custom class GET: $LAST_URL response_headers: cache-control: no-cache # Does last-modified look like a legit timestamp? last-modified: /^\w+, \d+ \w+ \d{4} [\d:]+ GMT$/ - name: get standard class GET: /resource_classes/VCPU response_headers: cache-control: no-cache # Does last-modified look like a legit timestamp? last-modified: /^\w+, \d+ \w+ \d{4} [\d:]+ GMT$/ - name: post a resource class POST: /resource_classes data: name: CUSTOM_ALPHA status: 201 response_forbidden_headers: - last-modified - cache-control - name: get resource classes including custom desc: last modified will still be now with customs because of standards GET: /resource_classes response_headers: cache-control: no-cache # Does last-modified look like a legit timestamp? last-modified: /^\w+, \d+ \w+ \d{4} [\d:]+ GMT$/ - name: put a resource class 1.6 microversion PUT: /resource_classes/CUSTOM_MOO_MACHINE request_headers: openstack-api-version: placement 1.6 data: name: CUSTOM_BETA status: 200 response_forbidden_headers: - last-modified - cache-control - name: get resource classes old microversion GET: /resource_classes request_headers: openstack-api-version: placement 1.11 response_forbidden_headers: - last-modified - cache-control - name: get standard class old microversion GET: /resource_classes/VCPU request_headers: openstack-api-version: placement 1.11 response_forbidden_headers: - last-modified - cache-control - name: get custom class old microversion GET: $LAST_URL request_headers: openstack-api-version: placement 1.11 response_forbidden_headers: - last-modified - cache-control ",,703,50
openstack%2Fvitrage~master~Ie00fab852c613065ad425e4a444338bb2a1006c0,openstack/vitrage,master,Ie00fab852c613065ad425e4a444338bb2a1006c0,Add database configuration to unit tests,MERGED,2017-12-11 09:22:36.000000000,2017-12-13 13:35:45.000000000,2017-12-11 16:17:14.000000000,"[{'_account_id': 19194}, {'_account_id': 22348}, {'_account_id': 26091}, {'_account_id': 26339}]","[{'number': 1, 'created': '2017-12-11 09:22:36.000000000', 'files': ['vitrage/tests/unit/evaluator/test_scenario_repository.py', 'vitrage/tests/functional/entity_graph/consistency/test_consistency.py', 'vitrage/tests/functional/evaluator/test_scenario_evaluator.py', 'vitrage/tests/test_configuration.py', 'vitrage/tests/functional/evaluator/test_action_executor.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/b166be36d54a70ddee2c59fcb8ab411d8cea41db', 'message': 'Add database configuration to unit tests\n\nChange-Id: Ie00fab852c613065ad425e4a444338bb2a1006c0\n'}]",0,527025,b166be36d54a70ddee2c59fcb8ab411d8cea41db,9,4,1,26095,,,0,"Add database configuration to unit tests

Change-Id: Ie00fab852c613065ad425e4a444338bb2a1006c0
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/25/527025/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/tests/unit/evaluator/test_scenario_repository.py', 'vitrage/tests/functional/entity_graph/consistency/test_consistency.py', 'vitrage/tests/functional/evaluator/test_scenario_evaluator.py', 'vitrage/tests/test_configuration.py', 'vitrage/tests/functional/evaluator/test_action_executor.py']",5,b166be36d54a70ddee2c59fcb8ab411d8cea41db,,"from vitrage.tests.test_configuration import TestConfiguration class TestActionExecutor(TestFunctionalBase, TestConfiguration): cls.add_db(cls.conf)","from oslo_db.options import database_optsfrom vitrage import storage from vitrage.storage.sqlalchemy import models class TestActionExecutor(TestFunctionalBase): cls.conf.register_opts(database_opts, group='database') cls.conf.set_override('connection', 'sqlite:///:memory:', group='database') cls._db = storage.get_connection_from_config(cls.conf) engine = cls._db._engine_facade.get_engine() models.Base.metadata.create_all(engine)",57,35
openstack%2Fwatcher~master~If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9,openstack/watcher,master,If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9,Add and identify excluded instances in compute CDM,MERGED,2017-09-15 02:06:46.000000000,2017-12-13 13:34:33.000000000,2017-12-13 13:34:32.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 13111}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 22775}, {'_account_id': 24501}, {'_account_id': 24872}]","[{'number': 1, 'created': '2017-09-15 02:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/58e1d96e78ec3c6547e2c1983c020de379372a8a', 'message': 'Add and identify excluded instances in compute CDM\n\nChange-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9\nImplements:blueprint compute-cdm-include-all-instances\n'}, {'number': 2, 'created': '2017-09-15 03:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/97e8fe26c5d53a56776a41ff4ddbdefc2de2330c', 'message': 'Add and identify excluded instances in compute CDM\n\nChange-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9\nImplements:blueprint compute-cdm-include-all-instances\n'}, {'number': 3, 'created': '2017-11-09 03:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/56ead771c0e3e38266b2fa5187cb65f982406729', 'message': 'Add and identify excluded instances in compute CDM\n\nChange-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9\nImplements:blueprint compute-cdm-include-all-instances\n'}, {'number': 4, 'created': '2017-11-09 03:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/ce177f9ab07fd625f49697f3ad286bacebbfee12', 'message': 'Add and identify excluded instances in compute CDM\n\nChange-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9\nImplements:blueprint compute-cdm-include-all-instances\n'}, {'number': 5, 'created': '2017-11-09 06:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/897fb9e1963b7394f20ea77df67a7963c3018328', 'message': 'Add and identify excluded instances in compute CDM\n\nChange-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9\nImplements:blueprint compute-cdm-include-all-instances\n'}, {'number': 6, 'created': '2017-12-06 12:41:33.000000000', 'files': ['watcher/tests/decision_engine/scope/test_compute.py', 'watcher/decision_engine/scope/compute.py', 'watcher/decision_engine/model/element/instance.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/d91f0bff22155bcd39cab6f3cf75a9bb39e7b409', 'message': 'Add and identify excluded instances in compute CDM\n\nChange-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9\nImplements:blueprint compute-cdm-include-all-instances\n'}]",0,504303,d91f0bff22155bcd39cab6f3cf75a9bb39e7b409,20,11,6,24501,,,0,"Add and identify excluded instances in compute CDM

Change-Id: If03893c5e9b6a37e1126ad91e4f3bfafe0f101d9
Implements:blueprint compute-cdm-include-all-instances
",git fetch https://review.opendev.org/openstack/watcher refs/changes/03/504303/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/scope/default.py', 'watcher/decision_engine/model/element/instance.py', 'watcher/tests/decision_engine/scope/test_default.py']",3,58e1d96e78ec3c6547e2c1983c020de379372a8a,bp/compute-cdm-include-all-instances," def test_update_exclude_instances_in_model(self): osc=mock.Mock()).update_exclude_instance_in_model( ('INSTANCE_1', 'Node_0'), ('INSTANCE_2', 'Node_1'), self.assertEqual(False, model.get_instance_by_uuid('INSTANCE_0').exclude) self.assertEqual(True, model.get_instance_by_uuid('INSTANCE_1').exclude)", def test_remove_instances_from_model(self): osc=mock.Mock()).remove_instances_from_model(,23,8
openstack%2Fglance~master~I4d97f74ed37b7b0e9a613ecfe33c4b26216ca768,openstack/glance,master,I4d97f74ed37b7b0e9a613ecfe33c4b26216ca768,Add fixture to only emit DeprecationWarning once,MERGED,2017-11-27 18:30:49.000000000,2017-12-13 13:20:43.000000000,2017-12-13 13:20:42.000000000,"[{'_account_id': 5202}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 14676}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-27 18:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/198618cde0b327fa53f9ccbb86c87e22b8f26f0d', 'message': 'Add fixture to only emit DeprecationWarning once\n\nWe have a ton of DeprecationWarning messages in our unit test runs.\nMost of these are out of our control from third party libs. This\nadds a WarningsFixture to limit warning output to once per test\nrun. In local py35 unit testing, this went from 14549 warnings to\n8913.\n\nBased on work previously done in Nova and Cinder.\n\nChange-Id: I4d97f74ed37b7b0e9a613ecfe33c4b26216ca768\n'}, {'number': 2, 'created': '2017-11-28 00:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/da0f875669685e7890da77063d58f7cd2cb11ba0', 'message': 'Add fixture to only emit DeprecationWarning once\n\nWe have a ton of DeprecationWarning messages in our unit test runs.\nMost of these are out of our control from third party libs. This\nadds a WarningsFixture to limit warning output to once per test\nrun. In local py35 unit testing, this went from 14549 warnings to\n8913.\n\nBased on work previously done in Nova and Cinder.\n\nChange-Id: I4d97f74ed37b7b0e9a613ecfe33c4b26216ca768\n'}, {'number': 3, 'created': '2017-12-12 15:49:07.000000000', 'files': ['glance/tests/unit/fixtures.py', 'glance/tests/unit/test_image_cache.py', 'glance/tests/unit/test_glance_replicator.py', 'glance/tests/unit/test_manage.py', 'glance/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/96334ad9517a6fa4cf675b34ebf5772824856872', 'message': ""Add fixture to only emit DeprecationWarning once\n\nWe have a ton of DeprecationWarning messages in our unit test runs.\nMost of these are out of our control from third party libs. This\nadds a WarningsFixture to limit warning output to once per test\nrun. In local py35 unit testing, this went from 14549 warnings to\n8913.\n\nAlso including ignorning a policy 'is_admin' deprecation warning\nthat was added before a clear plan or replacement had been put\nin place. Other projects have added this rather than fixing it\nat the source since it is currently being reworked.\n\nBased on work previously done in Nova and Cinder.\n\nChange-Id: I4d97f74ed37b7b0e9a613ecfe33c4b26216ca768\n""}]",2,523185,96334ad9517a6fa4cf675b34ebf5772824856872,22,6,3,11904,,,0,"Add fixture to only emit DeprecationWarning once

We have a ton of DeprecationWarning messages in our unit test runs.
Most of these are out of our control from third party libs. This
adds a WarningsFixture to limit warning output to once per test
run. In local py35 unit testing, this went from 14549 warnings to
8913.

Also including ignorning a policy 'is_admin' deprecation warning
that was added before a clear plan or replacement had been put
in place. Other projects have added this rather than fixing it
at the source since it is currently being reworked.

Based on work previously done in Nova and Cinder.

Change-Id: I4d97f74ed37b7b0e9a613ecfe33c4b26216ca768
",git fetch https://review.opendev.org/openstack/glance refs/changes/85/523185/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/fixtures.py', 'glance/tests/utils.py']",2,198618cde0b327fa53f9ccbb86c87e22b8f26f0d,depr_log_once,from glance.tests.unit import fixtures as glance_fixtures # Limit the amount of DeprecationWarning messages in the unit test logs self.useFixture(glance_fixtures.WarningsFixture()) ,,42,0
openstack%2Fmonasca-api~stable%2Focata~I47e0a9d1718bd5268610b2183397dec22911947a,openstack/monasca-api,stable/ocata,I47e0a9d1718bd5268610b2183397dec22911947a,Download Kafka from Apache Archives,MERGED,2017-12-05 09:57:14.000000000,2017-12-13 13:19:36.000000000,2017-12-13 13:19:36.000000000,"[{'_account_id': 14273}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26733}]","[{'number': 1, 'created': '2017-12-05 09:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/7e5670d5f82996bf33b135aa2fb13d76678c5a56', 'message': 'Download Kafka from Apache Archives\n\nApache Kafka 0.9.0.1 is not available on mirrors any more.\n\nChange-Id: I47e0a9d1718bd5268610b2183397dec22911947a\n(cherry picked from commit I47e0a9d1718bd5268610b2183397dec22911947a)\n'}, {'number': 2, 'created': '2017-12-11 14:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/96a9c0d2f4ffc8f00d3d0689124df285062c2396', 'message': 'Download Kafka from Apache Archives\n\nApache Kafka 0.9.0.1 is not available on mirrors any more.\n\nDepends-On: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f\nChange-Id: I47e0a9d1718bd5268610b2183397dec22911947a\n(cherry picked from commit I47e0a9d1718bd5268610b2183397dec22911947a)\n'}, {'number': 3, 'created': '2017-12-13 08:46:48.000000000', 'files': ['devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/7b43b26652d799cdfb443626b20d9bcd20ea7217', 'message': 'Download Kafka from Apache Archives\n\nApache Kafka 0.9.0.1 is not available on mirrors any more.\n\nDepends-On: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f\nChange-Id: I47e0a9d1718bd5268610b2183397dec22911947a\n(cherry picked from commit I47e0a9d1718bd5268610b2183397dec22911947a)\n'}]",0,525517,7b43b26652d799cdfb443626b20d9bcd20ea7217,12,4,3,16222,,,0,"Download Kafka from Apache Archives

Apache Kafka 0.9.0.1 is not available on mirrors any more.

Depends-On: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f
Change-Id: I47e0a9d1718bd5268610b2183397dec22911947a
(cherry picked from commit I47e0a9d1718bd5268610b2183397dec22911947a)
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/17/525517/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'devstack/settings']",2,7e5670d5f82996bf33b135aa2fb13d76678c5a56,zuul3,"# Apache Kafka 0.9.0.1 is only available in Apache Archives APACHE_ARCHIVES=${APACHE_ARCHIVES:-""https://archive.apache.org/dist/""} ",,4,1
openstack%2Frally~master~I55a42535bd7fad2be5b0b73f0a9c14b18fa29e67,openstack/rally,master,I55a42535bd7fad2be5b0b73f0a9c14b18fa29e67,Matching the tenant_id when removing default security_group,MERGED,2017-12-11 16:07:24.000000000,2017-12-13 13:19:28.000000000,2017-12-13 13:19:28.000000000,"[{'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 22348}, {'_account_id': 26025}]","[{'number': 1, 'created': '2017-12-11 16:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c794b8eac4823f46cab72a2c4b6b740637f39315', 'message': 'Matching the tenant_id when removing default security_group\n\n1. when creating admin user, it will return all default security-groups and\nthe new created security-group will not be deleted.\n\nChange-Id: I55a42535bd7fad2be5b0b73f0a9c14b18fa29e67\n'}, {'number': 2, 'created': '2017-12-13 07:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1bf180deeffe03efc996149a21eee38226fadae7', 'message': 'Matching the tenant_id when removing default security_group\n\n1. When the ""admin"" role is assigned to users created by users@openstack,\n   Neutron returns security groups for all tenants. Also, other roles can\n   lead to the same behavior.\n   To cleanup the proper default security groups, we need\n   to apply the filtering by tenant explicitly\n\nChange-Id: I55a42535bd7fad2be5b0b73f0a9c14b18fa29e67\n'}, {'number': 3, 'created': '2017-12-13 07:40:06.000000000', 'files': ['rally/plugins/openstack/context/keystone/users.py', 'tests/unit/plugins/openstack/context/keystone/test_users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/c8b3eba15954a8f5bfc0ea6ec4ed38c598b18ecd', 'message': 'Matching the tenant_id when removing default security_group\n\n1. When the ""admin"" role is assigned to users created by users@openstack,\n   Neutron returns security groups for all tenants. Also, other roles can\n   lead to the same behavior.\n   To cleanup the proper default security groups, we need\n   to apply the filtering by tenant explicitly\n\nChange-Id: I55a42535bd7fad2be5b0b73f0a9c14b18fa29e67\n'}]",3,527143,c8b3eba15954a8f5bfc0ea6ec4ed38c598b18ecd,17,4,3,26025,,,0,"Matching the tenant_id when removing default security_group

1. When the ""admin"" role is assigned to users created by users@openstack,
   Neutron returns security groups for all tenants. Also, other roles can
   lead to the same behavior.
   To cleanup the proper default security groups, we need
   to apply the filtering by tenant explicitly

Change-Id: I55a42535bd7fad2be5b0b73f0a9c14b18fa29e67
",git fetch https://review.opendev.org/openstack/rally refs/changes/43/527143/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/context/keystone/users.py', 'tests/unit/plugins/openstack/context/keystone/test_users.py']",2,c794b8eac4823f46cab72a2c4b6b740637f39315,develop," ""security_groups"": [{""id"": ""id-1"", ""name"": ""default"", ""tenant_id"": ""t1""}, [mock.call(""id-1"")],"," ""security_groups"": [{""id"": ""id-1"", ""name"": ""default""}, [mock.call(""id-1""), mock.call(""id-3"")],",5,4
openstack%2Fansible-role-k8s-glance~master~I74cd634955e38fb7af775b5d0d5605876c78586f,openstack/ansible-role-k8s-glance,master,I74cd634955e38fb7af775b5d0d5605876c78586f,Pass domain to user creation,MERGED,2017-12-11 10:59:40.000000000,2017-12-13 13:17:36.000000000,2017-12-13 13:17:36.000000000,"[{'_account_id': 6159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 10:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-glance/commit/bd34d6758f73796dd411b5183fd110730c0a4a39', 'message': 'Pass domain to user creation\n\nChange-Id: I74cd634955e38fb7af775b5d0d5605876c78586f\n'}, {'number': 2, 'created': '2017-12-11 11:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-glance/commit/ba4d21c92eef13f96e0e469b898dfebffddd3d2a', 'message': 'Pass domain to user creation\n\nDepends-On: Iae0e3a68b9bfc8abe6702521979500d03d5368f5\nChange-Id: I74cd634955e38fb7af775b5d0d5605876c78586f\n'}, {'number': 3, 'created': '2017-12-13 12:56:16.000000000', 'files': ['tasks/keystone.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-glance/commit/f25cb1bd32a5280d1978909e6249a7b2990ad1ff', 'message': 'Pass domain to user creation\n\nChange-Id: I74cd634955e38fb7af775b5d0d5605876c78586f\n'}]",0,527058,f25cb1bd32a5280d1978909e6249a7b2990ad1ff,15,2,3,6159,,,0,"Pass domain to user creation

Change-Id: I74cd634955e38fb7af775b5d0d5605876c78586f
",git fetch https://review.opendev.org/openstack/ansible-role-k8s-glance refs/changes/58/527058/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/keystone.yml'],1,bd34d6758f73796dd411b5183fd110730c0a4a39,, service_region: '{{glance_config.keystone_region}}' service_domain: '{{glance_config.keystone_default_domain}}', service_region: 'RegionOne',2,1
openstack%2Fkolla~master~I62fbcf9e4ee5c3170c96576698f4ae8b66db1b74,openstack/kolla,master,I62fbcf9e4ee5c3170c96576698f4ae8b66db1b74,"Revert ""nova-libvirt: fix kvm permission issue""",MERGED,2017-12-06 06:35:29.000000000,2017-12-13 13:10:55.000000000,2017-12-13 13:10:54.000000000,"[{'_account_id': 7488}, {'_account_id': 22076}, {'_account_id': 22348}, {'_account_id': 22997}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-12-06 06:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fbe76be66888e6477df6e0c7a0298068caf8676f', 'message': 'Revert ""nova-libvirt: fix kvm permission issue""\n\nThis is not needed. If we make sure qemu use nova user.\nBecause nova user in group qemu.\n\nSee comment #7 of bug #1715356:\nThe root cause for this issue is that qemu not run with nova user on\ndebian.\nIf we set qemu running with nova user with this patch:\nhttps://review.openstack.org/#/c/525891/\nThen we need to revert commit f1b98a4925826333cf22dafe15ef755066c51d48.\n\nThis reverts commit f1b98a4925826333cf22dafe15ef755066c51d48.\nCloses-bug: #1715356\n\nChange-Id: I62fbcf9e4ee5c3170c96576698f4ae8b66db1b74\n'}, {'number': 2, 'created': '2017-12-11 09:44:03.000000000', 'files': ['docker/nova/nova-libvirt/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/14cda91c4ef7020ac43f430869798387de15dae4', 'message': 'Revert ""nova-libvirt: fix kvm permission issue""\n\nThis is not needed. If we make sure qemu use nova user.\nBecause nova user in group qemu.\n\nSee comment #7 of bug #1715356:\nThe root cause for this issue is that qemu not run with nova user on\ndebian.\nIf we set qemu running with nova user with this patch:\nhttps://review.openstack.org/#/c/525891/\nThen we need to revert commit f1b98a4925826333cf22dafe15ef755066c51d48.\n\nThis reverts commit f1b98a4925826333cf22dafe15ef755066c51d48.\nCloses-bug: #1715356\nDepends-on: I36720af0c7d3dd7c69d2404843f54c0991aea1bb\n\nChange-Id: I62fbcf9e4ee5c3170c96576698f4ae8b66db1b74\n'}]",2,525900,14cda91c4ef7020ac43f430869798387de15dae4,14,5,2,22997,,,0,"Revert ""nova-libvirt: fix kvm permission issue""

This is not needed. If we make sure qemu use nova user.
Because nova user in group qemu.

See comment #7 of bug #1715356:
The root cause for this issue is that qemu not run with nova user on
debian.
If we set qemu running with nova user with this patch:
https://review.openstack.org/#/c/525891/
Then we need to revert commit f1b98a4925826333cf22dafe15ef755066c51d48.

This reverts commit f1b98a4925826333cf22dafe15ef755066c51d48.
Closes-bug: #1715356
Depends-on: I36720af0c7d3dd7c69d2404843f54c0991aea1bb

Change-Id: I62fbcf9e4ee5c3170c96576698f4ae8b66db1b74
",git fetch https://review.opendev.org/openstack/kolla refs/changes/00/525900/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova/nova-libvirt/extend_start.sh'],1,fbe76be66888e6477df6e0c7a0298068caf8676f,bug/1715356, chmod 660 /dev/kvm chown root:qemu /dev/kvm," if [[ ""${KOLLA_BASE_DISTRO}"" =~ debian|ubuntu ]]; then chmod 660 /dev/kvm if [[ ""$(uname -m)"" == ""aarch64"" ]]; then chown root:kvm /dev/kvm else chown root:qemu /dev/kvm fi else chmod 666 /dev/kvm chown root:kvm /dev/kvm fi",2,11
openstack%2Fsahara-dashboard~master~Ica5f0afacb693de4eed7552d728c5b1e06a32643,openstack/sahara-dashboard,master,Ica5f0afacb693de4eed7552d728c5b1e06a32643,Imported Translations from Zanata,MERGED,2017-12-13 06:25:46.000000000,2017-12-13 13:06:35.000000000,2017-12-13 13:06:35.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 06:25:46.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/89a75e09467bd5484f92b63ae20cd966c524a836', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ica5f0afacb693de4eed7552d728c5b1e06a32643\n'}]",0,527594,89a75e09467bd5484f92b63ae20cd966c524a836,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ica5f0afacb693de4eed7552d728c5b1e06a32643
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/94/527594/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,89a75e09467bd5484f92b63ae20cd966c524a836,zanata/translations,"""POT-Creation-Date: 2017-12-11 20:26+0000\n""""PO-Revision-Date: 2017-12-12 02:29+0000\n""msgid ""8.0.0.0b2"" msgstr ""8.0.0.0b2""","""POT-Creation-Date: 2017-12-08 19:03+0000\n""""PO-Revision-Date: 2017-12-08 11:41+0000\n""msgid ""8.0.0.0b1-24"" msgstr ""8.0.0.0b1-24""",4,4
openstack%2Fmonasca-api~stable%2Focata~I30f2edc4d34d0fad63f961f99dcecaf5c767f57f,openstack/monasca-api,stable/ocata,I30f2edc4d34d0fad63f961f99dcecaf5c767f57f,Make legacy gates working,MERGED,2017-12-05 10:37:23.000000000,2017-12-13 13:04:52.000000000,2017-12-13 13:04:52.000000000,"[{'_account_id': 10311}, {'_account_id': 14517}, {'_account_id': 16168}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 26733}]","[{'number': 1, 'created': '2017-12-05 10:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/09a9dcdfd3c916b88e15e6e92116ad9245c4f4cd', 'message': 'Make legacy gates working\n\n- make pep8 working by removing ChangeLog that is not generated\n- make maven working by removing condidation for user\n- make legacy dsvm working by using $USER intstead of hardcoded jenkins\n\nChange-Id: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f\n(cherry picked from commit dae93af09d7f6eb06b1222fa57c5491445c0ed41)\n'}, {'number': 2, 'created': '2017-12-06 09:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/1e97bd4370dde810d6a174117991e21651e235a9', 'message': 'Make legacy gates working\n\n- make pep8 working by removing ChangeLog that is not generated\n- make maven working by removing condidation for user\n- make legacy dsvm working by using $USER intstead of hardcoded jenkins\n\nChange-Id: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f\nDepends-On: I862d90aec2a94c6939ccc6823a854b68981b8adb\n(cherry picked from commit dae93af09d7f6eb06b1222fa57c5491445c0ed41)\n'}, {'number': 3, 'created': '2017-12-07 09:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/83bdf22386d7fd61b4b3bc4f556a71894279512e', 'message': 'Make legacy gates working\n\n- make pep8 working by removing ChangeLog that is not generated\n- make maven working by removing condidation for user\n- make legacy dsvm working by using $USER instead of hardcoded jenkins\n\nChange-Id: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f\nDepends-On: I862d90aec2a94c6939ccc6823a854b68981b8adb\n(cherry picked from commit dae93af09d7f6eb06b1222fa57c5491445c0ed41)\n'}, {'number': 4, 'created': '2017-12-07 17:43:56.000000000', 'files': ['common/build_common.sh', 'devstack/post_test_hook.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/dc0e4665556631cac37ae8723abb00f2d0e1083a', 'message': 'Make legacy gates working\n\n- make maven working by removing condidation for user\n- make legacy dsvm working by using $USER instead of hardcoded jenkins\n\nChange-Id: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f\nDepends-On: I862d90aec2a94c6939ccc6823a854b68981b8adb\n(cherry picked from commit dae93af09d7f6eb06b1222fa57c5491445c0ed41)\n'}]",1,525522,dc0e4665556631cac37ae8723abb00f2d0e1083a,23,7,4,16222,,,0,"Make legacy gates working

- make maven working by removing condidation for user
- make legacy dsvm working by using $USER instead of hardcoded jenkins

Change-Id: I30f2edc4d34d0fad63f961f99dcecaf5c767f57f
Depends-On: I862d90aec2a94c6939ccc6823a854b68981b8adb
(cherry picked from commit dae93af09d7f6eb06b1222fa57c5491445c0ed41)
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/22/525522/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/index.rst', 'common/build_common.sh', 'devstack/post_test_hook.sh', 'tox.ini']",4,09a9dcdfd3c916b88e15e6e92116ad9245c4f4cd,zuul3,import_exceptions = six.moves,,35,10
openstack%2Fmonasca-api~stable%2Fpike~I263b1a92a9ec7b5e38d9c1dc8b02e214102a92c2,openstack/monasca-api,stable/pike,I263b1a92a9ec7b5e38d9c1dc8b02e214102a92c2,Migrate to Zuul v3,MERGED,2017-12-04 15:02:48.000000000,2017-12-13 13:04:51.000000000,2017-12-13 13:04:51.000000000,"[{'_account_id': 6547}, {'_account_id': 16222}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-12-04 15:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/0cb7950614a6282bd77cfe4862933dfdecb9e0c6', 'message': 'Migrate to Zuul v3\n\nStory: 2001238\nTask: 5764\nTask: 5765\n\nChange-Id: I263b1a92a9ec7b5e38d9c1dc8b02e214102a92c2\nNeeded-By: I7bc913d0e5cd9e8a06a63cc3d11740056c7036d7\n(cherry picked from commit cdc3acb279b818857cc7abb12bfc5b08b2ff5338)\n'}, {'number': 2, 'created': '2017-12-04 15:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e39cf5c492d32ac8765bccc401db7bd54ba7df6b', 'message': 'Migrate to Zuul v3\n\nStory: 2001238\nTask: 5764\nTask: 5765\n\n(cherry picked from commit cdc3acb279b818857cc7abb12bfc5b08b2ff5338)\n\nZuul: add file extension to playbook path\n\nZuul now supports including the file extension on the playbook path\nand omitting the extension is now deprecrated.  Update references\nto include the extension.\n\n(cherry picked from commit a80537774facf90079091ebd5527038ac7341d45)\n\nChange-Id: I263b1a92a9ec7b5e38d9c1dc8b02e214102a92c2\n'}, {'number': 3, 'created': '2017-12-11 16:06:49.000000000', 'files': ['monasca_tempest_tests/contrib/post_test_hook.sh', '.zuul.yaml', 'devstack/post_test_hook.sh', 'playbooks/legacy/monasca-tempest-base/post.yaml', 'playbooks/legacy/monasca-tempest-base/run.yaml', 'monasca_tempest_tests/contrib/gate_hook.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/1e053b538907b280547a6648f2ac963339e5fde8', 'message': 'Migrate to Zuul v3\n\nStory: 2001238\nTask: 5764\nTask: 5765\n\n(cherry picked from commit cdc3acb279b818857cc7abb12bfc5b08b2ff5338)\n\nZuul: add file extension to playbook path\n\nZuul now supports including the file extension on the playbook path\nand omitting the extension is now deprecrated.  Update references\nto include the extension.\n\n(cherry picked from commit a80537774facf90079091ebd5527038ac7341d45)\n\nChange-Id: I263b1a92a9ec7b5e38d9c1dc8b02e214102a92c2\n'}]",2,525230,1e053b538907b280547a6648f2ac963339e5fde8,21,5,3,16222,,,0,"Migrate to Zuul v3

Story: 2001238
Task: 5764
Task: 5765

(cherry picked from commit cdc3acb279b818857cc7abb12bfc5b08b2ff5338)

Zuul: add file extension to playbook path

Zuul now supports including the file extension on the playbook path
and omitting the extension is now deprecrated.  Update references
to include the extension.

(cherry picked from commit a80537774facf90079091ebd5527038ac7341d45)

Change-Id: I263b1a92a9ec7b5e38d9c1dc8b02e214102a92c2
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/30/525230/3 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_tempest_tests/contrib/post_test_hook.sh', '.zuul.yaml', 'devstack/post_test_hook.sh', 'playbooks/legacy/monasca-tempest-base/post.yaml', 'playbooks/legacy/monasca-tempest-base/run.yaml', 'monasca_tempest_tests/contrib/gate_hook.sh', 'tox.ini']",7,0cb7950614a6282bd77cfe4862933dfdecb9e0c6,zuulv3-stable/pike,,skip_install = True usedevelop = False,264,2
openstack%2Ftripleo-quickstart-extras~master~I0da6116799cfbd64c7b1c1dc957f12df27c75387,openstack/tripleo-quickstart-extras,master,I0da6116799cfbd64c7b1c1dc957f12df27c75387,Updated tempest_version to 17.1.0 for Pike and 16.1.0 for ocata,MERGED,2017-11-13 10:32:04.000000000,2017-12-13 13:01:17.000000000,2017-12-13 13:01:17.000000000,"[{'_account_id': 3153}, {'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-11-13 10:32:04.000000000', 'files': ['roles/validate-tempest/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4b05e5e7b3bbdb2315158f49bc40e855917971cd', 'message': 'Updated tempest_version to 17.1.0 for Pike and 16.1.0 for ocata\n\n* https://review.rdoproject.org/r/10476 - tempest-16.1.0 for Ocata\n* https://review.rdoproject.org/r/10265 - tempest-17.1.0 for Pike\n\nChange-Id: I0da6116799cfbd64c7b1c1dc957f12df27c75387\n'}]",0,519305,4b05e5e7b3bbdb2315158f49bc40e855917971cd,24,8,1,12393,,,0,"Updated tempest_version to 17.1.0 for Pike and 16.1.0 for ocata

* https://review.rdoproject.org/r/10476 - tempest-16.1.0 for Ocata
* https://review.rdoproject.org/r/10265 - tempest-17.1.0 for Pike

Change-Id: I0da6116799cfbd64c7b1c1dc957f12df27c75387
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/05/519305/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/defaults/main.yml'],1,4b05e5e7b3bbdb2315158f49bc40e855917971cd,tempest_1610_ocata,"tempest_version_dict: { 'newton': 'newton', 'ocata': '16.1.0', 'pike': '17.1.0', 'master': 'master'}","tempest_version_dict: { 'newton': 'newton', 'ocata': '16.0.0', 'pike': '16.1.0', 'master': 'master'}",1,1
openstack%2Fpuppet-tripleo~master~I0c1bc3d2362c6500b1a515d99f641f8c1468754a,openstack/puppet-tripleo,master,I0c1bc3d2362c6500b1a515d99f641f8c1468754a,Update cephx keys with ACLs for openstack services.,MERGED,2017-11-14 04:18:38.000000000,2017-12-13 13:01:16.000000000,2017-12-13 13:01:16.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 19564}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-14 04:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/09cf2b46cfdbb8d1b922594838fa156324451158', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 2, 'created': '2017-11-14 16:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2da03fb2b0b8244cd1931827bbb0b8191b1a7032', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 3, 'created': '2017-11-15 02:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/bca5cf4c69dedf2a234725919f3267b96e295860', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 4, 'created': '2017-11-15 19:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/3d6eac0164fa06971648997c92e678c6c690637a', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 5, 'created': '2017-11-16 03:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b4250382cc146103bfc697d8cdecc747e28eadff', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 6, 'created': '2017-11-16 16:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d68703f5dd400fa73ab46e3acfe336ea821405c7', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 7, 'created': '2017-11-21 18:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/40bf28447af0d9fbca175e8eb4db3efe5751f1df', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 8, 'created': '2017-11-22 21:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0ea3053d6af021b41072e612193e739de8f7e037', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}, {'number': 9, 'created': '2017-12-05 20:45:52.000000000', 'files': ['manifests/profile/base/manila/share.pp', 'metadata.json', 'manifests/profile/base/cinder/volume.pp', 'spec/classes/tripleo_profile_base_gnocchi_api_spec.rb', 'manifests/profile/base/gnocchi/api.pp', 'manifests/profile/base/nova/compute_libvirt_shared.pp', 'spec/classes/tripleo_profile_base_cinder_volume_spec.rb', 'manifests/profile/base/glance/api.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/48c417519f88472d035c3ad6a92edcc2e6039d9b', 'message': 'Update cephx keys with ACLs for openstack services.\n\nThis patch will set file system ACLs on the ceph client keyring.\nThis will help resolve (1) for OSP Ocata and before\n\nChange-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a\nPartial-Bug: #1720787\n1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657\n'}]",10,519531,48c417519f88472d035c3ad6a92edcc2e6039d9b,96,8,9,19564,,,0,"Update cephx keys with ACLs for openstack services.

This patch will set file system ACLs on the ceph client keyring.
This will help resolve (1) for OSP Ocata and before

Change-Id: I0c1bc3d2362c6500b1a515d99f641f8c1468754a
Partial-Bug: #1720787
1: https://bugzilla.redhat.com/show_bug.cgi?id=1462657
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/31/519531/8 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/manila/share.pp', 'manifests/profile/base/cinder/volume.pp', 'manifests/profile/base/gnocchi/api.pp', 'manifests/profile/base/nova/compute_libvirt_shared.pp', 'manifests/profile/base/glance/api.pp']",5,09cf2b46cfdbb8d1b922594838fa156324451158,bug/1720787," 'rbd': { $backend_store = 'rbd' $glance_rbd_client_name = hiera('glance::backend::rbd::rbd_store_user') exec{ ""exec-setfacl-${glance_rbd_client_name}-glance"": path => ['/bin', '/usr/bin'], command => ""setfacl -m u:glance:r-- /etc/ceph/ceph.client.${glance_rbd_client_name}.keyring"", unless => ""getfacl /etc/ceph/ceph.client.${glance_rbd_client_name}.keyring | grep -q user:glance:r--"", } Ceph::Key[""client.${glance_rbd_client_name}""] -> Exec[""exec-setfacl-${glance_rbd_client_name}-glance""] }", 'rbd': { $backend_store = 'rbd' },42,3
openstack%2Fmanila~master~I12c41a46140b04f26565d8934e0326480477c612,openstack/manila,master,I12c41a46140b04f26565d8934e0326480477c612,Add count info in /shares and /shares/detail response,MERGED,2017-11-02 08:35:52.000000000,2017-12-13 13:00:29.000000000,2017-12-13 13:00:29.000000000,"[{'_account_id': 6491}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 13984}, {'_account_id': 14384}, {'_account_id': 15100}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 18529}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-11-02 08:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e0b2722aa2a4554d1cd208f7800de36ebb5fc21c', 'message': 'Add count info in /shares and /shares/detail response\n\nAdded support for display count info\nin share list&detail APIs:\n\n1. /v3/{project_id}/shares?with_count=True\n2. /v3/{project_id}/shares/detail?with_count=True\n\nPartially-Implements bp add-amount-info-in-list-api\nChange-Id: I12c41a46140b04f26565d8934e0326480477c612\n'}, {'number': 2, 'created': '2017-11-23 03:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e58ba57ebecf08b80bb79be70eb3dd54b5b3ad49', 'message': 'Add count info in /shares and /shares/detail response\n\nAdded support for display count info\nin share list&detail APIs:\n\n1. /v3/{project_id}/shares?with_count=True\n2. /v3/{project_id}/shares/detail?with_count=True\n\nPartially-Implements bp add-amount-info-in-list-api\nChange-Id: I12c41a46140b04f26565d8934e0326480477c612\n'}, {'number': 3, 'created': '2017-12-11 01:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/623c60f6f409f5099614b4c98ecc1da5735934e0', 'message': 'Add count info in /shares and /shares/detail response\n\nAdded support for display count info\nin share list&detail APIs:\n\n1. /v2/{project_id}/shares?with_count=True\n2. /v2/{project_id}/shares/detail?with_count=True\n\nPartially-Implements bp add-amount-info-in-list-api\nChange-Id: I12c41a46140b04f26565d8934e0326480477c612\n'}, {'number': 4, 'created': '2017-12-13 01:46:24.000000000', 'files': ['manila_tempest_tests/tests/api/test_shares_actions.py', 'manila_tempest_tests/config.py', 'manila/tests/api/v2/test_shares.py', 'manila/api/v1/shares.py', 'releasenotes/notes/add-count-info-in-share-21a6b36c0f4c87b9.yaml', 'manila/api/openstack/api_version_request.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/api/views/shares.py', 'manila/api/v2/shares.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/6dac83660dd650ad650739d7c141d5d6a9d84101', 'message': 'Add count info in /shares and /shares/detail response\n\nAdded support for display count info\nin share list&detail APIs:\n\n1. /v2/{project_id}/shares?with_count=True\n2. /v2/{project_id}/shares/detail?with_count=True\n\nPartially-Implements bp add-amount-info-in-list-api\nChange-Id: I12c41a46140b04f26565d8934e0326480477c612\n'}]",5,517208,6dac83660dd650ad650739d7c141d5d6a9d84101,57,19,4,15100,,,0,"Add count info in /shares and /shares/detail response

Added support for display count info
in share list&detail APIs:

1. /v2/{project_id}/shares?with_count=True
2. /v2/{project_id}/shares/detail?with_count=True

Partially-Implements bp add-amount-info-in-list-api
Change-Id: I12c41a46140b04f26565d8934e0326480477c612
",git fetch https://review.opendev.org/openstack/manila refs/changes/08/517208/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila_tempest_tests/tests/api/test_shares_actions.py', 'manila_tempest_tests/config.py', 'manila/tests/api/v2/test_shares.py', 'manila/api/v1/shares.py', 'releasenotes/notes/add-count-info-in-share-21a6b36c0f4c87b9.yaml', 'manila/api/openstack/api_version_request.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/api/views/shares.py', 'manila/api/v2/shares.py']",9,e0b2722aa2a4554d1cd208f7800de36ebb5fc21c,bp/add-amount-info-in-list-api," if req.api_version_request < api_version.APIVersionRequest(""2.41""): req.GET.pop('with_count', None) ",,62,11
openstack%2Fnova-specs~master~Ib0415add7cc92e94303f6494f1f0287848f27c98,openstack/nova-specs,master,Ib0415add7cc92e94303f6494f1f0287848f27c98,Add multiattach support to Nova,MERGED,2017-08-31 20:12:12.000000000,2017-12-13 12:59:08.000000000,2017-10-19 21:10:04.000000000,"[{'_account_id': 3}, {'_account_id': 136}, {'_account_id': 782}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 6873}, {'_account_id': 9562}, {'_account_id': 10135}, {'_account_id': 11564}, {'_account_id': 11604}, {'_account_id': 17386}, {'_account_id': 19930}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-08-31 20:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b71ebd3aaa350d785b3d4966e5dd26556b477f69', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 2, 'created': '2017-09-14 16:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/53c885bdae39e10a2b29fc10bd95ecfef4440087', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 3, 'created': '2017-09-21 18:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/82aae4c2bb44554ae83c71f9124e3a661d4d2d6c', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 4, 'created': '2017-09-25 20:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2394dd7ee7ad01943cd065ac721befec06b6cf68', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 5, 'created': '2017-10-17 13:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cb8cce4a69fbb79f78b75409f3fffe31ec6744b3', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 6, 'created': '2017-10-19 15:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a9a1641c37b0a4ddd95f512a63dc1c8d9faf2162', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 7, 'created': '2017-10-19 17:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d287d4504bad22a8fa1f8a29b81a86376bfebde6', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}, {'number': 8, 'created': '2017-10-19 20:14:20.000000000', 'files': ['specs/queens/approved/cinder-volume-multi-attach.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7b6f5329eceabcdfa640b572c1f9a4bfc44ec001', 'message': ""Add multiattach support to Nova\n\nThe spec is describing the Nova side of the 'multiattach' feature.\nThe functionality targets to add support for attaching a Cinder\nvolume to multiple VM instances.\n\nChange-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98\nPreviously-approved: newton\nImplements: blueprint multi-attach-volume\n""}]",133,499777,7b6f5329eceabcdfa640b572c1f9a4bfc44ec001,61,13,8,9562,,,0,"Add multiattach support to Nova

The spec is describing the Nova side of the 'multiattach' feature.
The functionality targets to add support for attaching a Cinder
volume to multiple VM instances.

Change-Id: Ib0415add7cc92e94303f6494f1f0287848f27c98
Previously-approved: newton
Implements: blueprint multi-attach-volume
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/77/499777/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/approved/cinder-volume-multi-attach.rst'],1,b71ebd3aaa350d785b3d4966e5dd26556b477f69,bp/volume-multi-attach,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================== Support Cinder Volume Multi-attach ================================== https://blueprints.launchpad.net/nova/+spec/multi-attach-volume Currently, Nova only allows a volume to be attached to a single instance. There are times when a user may want to be able to attach the same volume to multiple instances. Problem description =================== Currently Nova is not prepared to attach a single Cinder volume to multiple VM instances even if the volume itself allows that operation. This document describes the required changes in Nova to introduce this new functionality and also lists the limitations it has. Use Cases --------- Allow users to share volumes between multiple guests using either read-write or read-only attachments. Clustered applications with two nodes where one is active and one is passive. Both require access to the same volume although only one accesses actively. When the active one goes down, the passive one can take over quickly and has access to the data. Proposed change =============== The new 'multi-attach' functionality will be enabled by using the new Cinder attach/detach API which is available from the API microversion 3.44. Cinder will only allow a volume to be attached more than once if its 'multiattach' flag is set on the volume at create time. Nova is expected to rely on Cinder to do the check on the volume state when it's reserving the volume on the API level by calling attachment_create. In addition there are cases where we will not enable 'multi-attach', it is Nova's responsibility to disable the functionality and send a proper API response to the caller. Details are explained below. Nova also needs to know when it can safely disconnect the volume. Cinder is planned to provide the information to Nova, the change will be added under new API microversion(s). Nova will not support multi-attach, when Cinder does not have the minimum required microversion. By default libvirt assumes all disks are exclusively used by a single guest. If you want to share disks between instances, you need to tell libvirt when configuring the guest XML for that disk via setting the 'shareable' flag for the disk. This means that the hypervisor will not try to take an exclusive lock on the disk, that all I/O caching is disabled, and any SELinux labeling allows use by all domains. Nova needs to set this 'shareable' flag for the multi-attach disks of the instances. Only the libvirt driver is modified to support multi-attach, for all other virt drivers this capability is disabled, the information is stored among the virt driver capabilities dict in the base ComputeDriver. Nova should reject the attach request in case the hypervisor does not support it, but with the current API it is not possible. This could probably be solved with policies later on but as a first we will leave it for the computes to fail in case of not running libvirt. Due to the need to add the 'shareable' flag to the guest xml and further possible changes in the computes for detach we need to check whether the min version is high enough to enable multi-attach. Alternatives ------------ For the use case described above the failover scenario can be handled by attaching the volume to the passive/standby instance. This means that the standby instance is not a hot standby anymore as the volume attachment requires time, which means that the new primary instance is without volume for the time of re-attaching, which can vary in the sense of marking the volume free after the failure of the primary instance. Another alternative is to clone a volume and attach the clone to the second instance. The downside to this is any changes to the original volume don't show up in the mounted clone so this is only a viable alternative if the volume is read-only. Data model impact ----------------- None REST API impact --------------- There are features of the Nova API that has to be handled by care or disabled completely for now for volumes that support multi-attach. The create call in the 'os-assisted-volume-snapshot' API calls the 'volume_snapshot_create' where we don't have the instance_uuid to retrieve the right BDM, therefore we need to disable this call for multi-attach. The API format for this request is not changed, it is only a protection until the required API changes to support this request with multi-attach. Another feature that needs limitations is the 'boot from volume' (BFV). In case of this feature two aspects need further investigation. The first is the 'delete_on_termination' flag, which if set to True is intended to remove the volume that is attached to the instance when it is deleted. This option does not cause problem as Cinder takes care of not deleting a volume if it still has active attachments. Nova will receive an error from Cinder that the volume deletion failed, which will then be logged [#]_, but will not affect the instance termination process. According to this this flag will be allowed to use along with multi-attach, no changes are necessary when the volume provided has multiattach=True and the delete_on_termination=True flag is passed in for BFV. The second aspect of BFV is the boot process. In this case the only issue comes with the bootable volumes, which are specified in the boot request as boot device. For this the 'block_device_mapping' list has to be checked to filter out the cases when we have a multiattachable volume specified as boot device. It can be done by checking the 'source_type' and 'destination_type' of a BDM and also search for 'boot_index': 0 item in the BDM dict. Based on the volume_id stored within the BDM information the volume can be retrieved from Cinder to check whether the 'multiattach' flag is set to True in which case the request will return an error that this operation is not supported for multi-attach volumes. For cases, where Nova creates the volume itself, i.e. source_type is blank/image/snapshot, it should not enable multi-attach for the volume for now. When we attach a volume at boot time (BFV with source=volume,dest=volume) scheduling will retry in case of selecting computes that do not support multi-attach. To make it more efficient, later on we can add a new scheduler filter to avoid the overhead of repeating the scheduling until a valid host is found. The filter would check the compute capabilities. This step is considered to be a future improvement. Security impact --------------- In the libvirt driver, the disk is given a shared SELinux label, and so that disk has no longer strong sVirt SELinux isolation. The OpenStack volume encryption capability is supposed to work out of the box with this use case also, it should not break how the encryptor works below the clustered file system, by using the same key for all connections. The attachment of an encrypted volume to multiple instances should be tested in Tempest to see if there is any unexpected issue with it. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Based on the work from Walter Boring and Charlie Zhou. Agreed with Walter to start the work again. Assignee(s) ----------- Primary assignee: ildiko-vancsa Work Items ---------- 1. Update libvirt driver to generate proper domain XML for instances with multi-attach volumes 2. Provide the necessary checks in the Nova API to block the operation in the above listed cases 3. Add Tempest test cases and documentation Dependencies ============ * This requires the version 3.2.0 or above of the python-cinderclient. Corresponding blueprint: https://blueprints.launchpad.net/python-cinderclient/+spec/multi-attach-volume * Corresponding, implemented spec in Cinder: https://blueprints.launchpad.net/cinder/+spec/multi-attach-volume * Link needed to Cinder spec to address detach issues currently captured here: https://etherpad.openstack.org/p/cinder-nova-api-changes Testing ======= We'll have to add new Tempest tests to support the new Cinder volume multiattach flag. The new cinder multiattach flag is what allows a volume to be attached more than once. For instance the following scenarios will need to be tested: * Attach the same volume to two instances. * Boot from volume with multiattach * Encrypted volume with multiattach * Negative testing: * Boot from multi-attachable volume with boot_index=0 * Tying to attach a non-multiattach volume to multiple instances Additionally to the above, Cinder migrate needs to be tested on the gate, as it triggres swap_volume in Nova that is not tested today at all. Documentation Impact ==================== We will have to update the documentations to discuss the new ability to attach a volume to multiple instances if the cinder multiattach flag is set on a volume. It is also need to be added to the documentation that the volume creation for these types of volumes will not be supported by the API due to the deprecation of the volume creation Nova API. If a volume needs to allow multiple volume attachments it has to be created on the Cinder side with the needed properties specified. It also needs to be outlined in the documentation that attaching a volume multiple times in read-write mode can cause data corruption, if not handled correctly. It is the users' responsibility to add some type of exclusion (at the file system or network file system layer) to prevent multiple writers from corrupting the data. Examples should be provided if available to guide users on how to do this. References ========== * This is the cinder wiki page that discusses the approach to multi-attach https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume .. [#] http://lists.openstack.org/pipermail/openstack-dev/2016-May/094089.html .. [#] https://github.com/openstack/nova/blob/295224c41e7da07c5ddbdafc72ac5abf2d708c69/nova/compute/manager.py#L2369 History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Kilo - Introduced * - Liberty - Re-approved * - Mitaka-1 - Re-approved * - Mitaka-2 - Updated with API limitations and testing scenarios * - Newton - Re-approved ",,281,0
openstack%2Fansible-role-k8s-tripleo~master~Iae0e3a68b9bfc8abe6702521979500d03d5368f5,openstack/ansible-role-k8s-tripleo,master,Iae0e3a68b9bfc8abe6702521979500d03d5368f5,Domain required to create user,MERGED,2017-12-11 10:59:42.000000000,2017-12-13 12:55:14.000000000,2017-12-13 12:55:14.000000000,"[{'_account_id': 6159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 10:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-tripleo/commit/5f70deed8230b41586aeb926c1961090ae26f770', 'message': 'Domain required to create user\n\nChange-Id: Iae0e3a68b9bfc8abe6702521979500d03d5368f5\n'}, {'number': 2, 'created': '2017-12-12 12:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-tripleo/commit/77b0f1ec1ccc0879adfed81866b97cba01906ed5', 'message': 'Domain required to create user\n\nDepends-On: I0c2720e9be8e601388825307c81f396fc6c6f509\nChange-Id: Iae0e3a68b9bfc8abe6702521979500d03d5368f5\n'}, {'number': 3, 'created': '2017-12-13 09:09:31.000000000', 'files': ['tasks/bootstrap-service-endpoints.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-tripleo/commit/f9e74eee66e7698c904a95e3d3bfd24e7db6e09c', 'message': 'Domain required to create user\n\nChange-Id: Iae0e3a68b9bfc8abe6702521979500d03d5368f5\n'}]",0,527059,f9e74eee66e7698c904a95e3d3bfd24e7db6e09c,15,2,3,6159,,,0,"Domain required to create user

Change-Id: Iae0e3a68b9bfc8abe6702521979500d03d5368f5
",git fetch https://review.opendev.org/openstack/ansible-role-k8s-tripleo refs/changes/59/527059/3 && git format-patch -1 --stdout FETCH_HEAD,['tasks/bootstrap-service-endpoints.yml'],1,5f70deed8230b41586aeb926c1961090ae26f770,," domain: ""{{service_domain}}""",,1,0
openstack%2Fneutron-tempest-plugin~master~I8c85088251ffb0411589bf5bd30cbaf97fe45c53,openstack/neutron-tempest-plugin,master,I8c85088251ffb0411589bf5bd30cbaf97fe45c53,Add tests for external network,MERGED,2017-11-16 01:32:11.000000000,2017-12-13 12:46:38.000000000,2017-12-13 12:46:38.000000000,"[{'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-16 01:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/182312e15d8773fce4deb9c2ebb3f828f4113f0b', 'message': 'Add tests for external network\n\nAdd two tests for external network while deleting RBAC policy.\n\nDepends-on: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nChange-Id: I8c85088251ffb0411589bf5bd30cbaf97fe45c53\nRelated-bug: #1692472\n'}, {'number': 2, 'created': '2017-11-18 03:48:12.000000000', 'files': ['neutron_tempest_plugin/api/admin/test_external_network_extension.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/32330e2c4ec4b79e396c22e01ecd437da5c040b9', 'message': 'Add tests for external network\n\nAdd three tests for external network while deleting RBAC policy.\n\nDepends-on: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nChange-Id: I8c85088251ffb0411589bf5bd30cbaf97fe45c53\nRelated-bug: #1692472\n'}]",0,520255,32330e2c4ec4b79e396c22e01ecd437da5c040b9,22,5,2,12860,,,0,"Add tests for external network

Add three tests for external network while deleting RBAC policy.

Depends-on: Ibdbe8a88581e54250259825bbf1c77485fd09f89
Change-Id: I8c85088251ffb0411589bf5bd30cbaf97fe45c53
Related-bug: #1692472
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/55/520255/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/api/admin/test_external_network_extension.py'],1,182312e15d8773fce4deb9c2ebb3f828f4113f0b,bug/1692472," @decorators.idempotent_id('beddbe9d-304c-4577-8bbe-9b61d0a449b4') def test_external_conversion_on_policy_delete(self): net_id = self._create_network(external=False)['id'] policy = self.admin_client.create_rbac_policy( object_type='network', object_id=net_id, action='access_as_external', target_tenant='*') body = self.admin_client.show_network(net_id)['network'] self.assertTrue(body['router:external']) self.admin_client.delete_rbac_policy(policy['rbac_policy']['id']) body = self.admin_client.show_network(net_id)['network'] self.assertFalse(body['router:external']) @decorators.idempotent_id('046aff1a-3962-4e2b-9a3b-93a24f255fd0') def test_external_network_on_shared_policy_delete(self): net_id = self._create_network(external=True)['id'] policy = self.admin_client.create_rbac_policy( object_type='network', object_id=net_id, action='access_as_shared', target_tenant='*') self.admin_client.delete_rbac_policy(policy['rbac_policy']['id']) body = self.admin_client.show_network(net_id)['network'] self.assertTrue(body['router:external']) ",,24,0
openstack%2Fpanko~master~I63e5927c625d0a080bd6a9ea77ff939253039d5e,openstack/panko,master,I63e5927c625d0a080bd6a9ea77ff939253039d5e,Remove jsonutils usage,MERGED,2017-11-22 10:12:54.000000000,2017-12-13 12:41:37.000000000,2017-12-13 12:41:37.000000000,"[{'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22348}, {'_account_id': 22752}, {'_account_id': 25254}]","[{'number': 1, 'created': '2017-11-22 10:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/panko/commit/0f005dafb0fce993048a5b4c676a464da6dcb6fa', 'message': ""Replace jsonutils by json\n\nPanko does not depends on oslo.serialization while it is using it. However,\nsince it does not really need it, let's use the regular json module.\n\nChange-Id: I63e5927c625d0a080bd6a9ea77ff939253039d5e\n""}, {'number': 2, 'created': '2017-11-22 22:40:50.000000000', 'files': ['panko/tests/functional/api/v2/test_event_scenarios.py'], 'web_link': 'https://opendev.org/openstack/panko/commit/70219e318871357da53129f41f1ef3685e656fca', 'message': ""Remove jsonutils usage\n\nPanko does not depends on oslo.serialization while it is using it. However,\nsince it does not really need it, let's use the regular json attribute anyway.\n\nChange-Id: I63e5927c625d0a080bd6a9ea77ff939253039d5e\n""}]",1,522201,70219e318871357da53129f41f1ef3685e656fca,23,5,2,1669,,,0,"Remove jsonutils usage

Panko does not depends on oslo.serialization while it is using it. However,
since it does not really need it, let's use the regular json attribute anyway.

Change-Id: I63e5927c625d0a080bd6a9ea77ff939253039d5e
",git fetch https://review.opendev.org/openstack/panko refs/changes/01/522201/1 && git format-patch -1 --stdout FETCH_HEAD,['panko/tests/functional/api/v2/test_event_scenarios.py'],1,0f005dafb0fce993048a5b4c676a464da6dcb6fa,fix-oslo-serialization,import json json.loads(resp.body)['error_message'] json.loads(resp.body)['error_message'], from oslo_serialization import jsonutils jsonutils.loads(resp.body)['error_message'] jsonutils.loads(resp.body)['error_message'],3,3
openstack%2Ftripleo-puppet-elements~master~Id92e056ae4ebb07e38976968b5734a8f3f5fbc0f,openstack/tripleo-puppet-elements,master,Id92e056ae4ebb07e38976968b5734a8f3f5fbc0f,Update test-requirements to work with reno,MERGED,2017-12-12 21:07:59.000000000,2017-12-13 12:30:57.000000000,2017-12-13 12:30:57.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 21:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/c60463f44a24eae9f430fd55616ac582aaf6bf09', 'message': 'Update test-requirements to work with reno\n\nChange-Id: Id92e056ae4ebb07e38976968b5734a8f3f5fbc0f\n'}, {'number': 2, 'created': '2017-12-13 01:42:10.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/6a9d83d8cdff93a4a02badbb8738d545967152a9', 'message': 'Update test-requirements to work with reno\n\nChange-Id: Id92e056ae4ebb07e38976968b5734a8f3f5fbc0f\n'}]",0,527518,6a9d83d8cdff93a4a02badbb8738d545967152a9,8,2,2,3153,,,0,"Update test-requirements to work with reno

Change-Id: Id92e056ae4ebb07e38976968b5734a8f3f5fbc0f
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/18/527518/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c60463f44a24eae9f430fd55616ac582aaf6bf09,reno/fix,# This is required for the docs build jobsopenstackdocstheme>=1.17.0 # Apache-2.0 # This is required for the releasenotes build jobs reno>=2.5.0 # Apache-2.0,"openstackdocstheme>=1.11.0 # Apache-2.0 hacking>=0.8.0,<0.9 oslotesttestrepository>=0.0.18 reno>=1.8.0 # Apache-2.0",5,6
openstack%2Finstack-undercloud~stable%2Fpike~Iffe0f3d7b85586534d558bc552ac21998391efac,openstack/instack-undercloud,stable/pike,Iffe0f3d7b85586534d558bc552ac21998391efac,Set nova dhcp_domain to empty string,MERGED,2017-12-07 09:26:12.000000000,2017-12-13 12:30:56.000000000,2017-12-13 12:30:55.000000000,"[{'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2017-12-07 09:26:12.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/5f3c268f59ad7cd46c968933cdea55cba2c76db1', 'message': 'Set nova dhcp_domain to empty string\n\nWith change I4db66155b2c4ba8e0639ec00f938a8bc2ac85762 we removed this\nsetting entirely but in such a scenario nova is appending .novalocal\nand not leaving it empty.\n\nThis change explicitly sets it value to empty string, as we do already\nfor the overcloud [1].\n\n1. https://github.com/openstack/tripleo-heat-templates/blob/stable/pike/puppet/services/nova-base.yaml#L221\n\nChange-Id: Iffe0f3d7b85586534d558bc552ac21998391efac\nRelated-Bug: #1733874\n(cherry picked from commit 53e125199e44ed9f2d6dc7a8b982b72e38b9e57b)\n'}]",1,526323,5f3c268f59ad7cd46c968933cdea55cba2c76db1,16,5,1,6796,,,0,"Set nova dhcp_domain to empty string

With change I4db66155b2c4ba8e0639ec00f938a8bc2ac85762 we removed this
setting entirely but in such a scenario nova is appending .novalocal
and not leaving it empty.

This change explicitly sets it value to empty string, as we do already
for the overcloud [1].

1. https://github.com/openstack/tripleo-heat-templates/blob/stable/pike/puppet/services/nova-base.yaml#L221

Change-Id: Iffe0f3d7b85586534d558bc552ac21998391efac
Related-Bug: #1733874
(cherry picked from commit 53e125199e44ed9f2d6dc7a8b982b72e38b9e57b)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/23/526323/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,5f3c268f59ad7cd46c968933cdea55cba2c76db1,bug/1733874,nova::network::neutron::dhcp_domain: '',,1,0
openstack%2Finstack-undercloud~master~Iee8604a6a942c12e6fa6b9cb8ea88a2cee1ead8f,openstack/instack-undercloud,master,Iee8604a6a942c12e6fa6b9cb8ea88a2cee1ead8f,Set default_resource_class to baremetal,MERGED,2017-12-06 13:57:33.000000000,2017-12-13 12:30:56.000000000,2017-12-13 12:30:56.000000000,"[{'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2017-12-06 13:57:33.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/f5f37c9534d375c17e995c9487ba2a627514fd7f', 'message': ""Set default_resource_class to baremetal\n\nWe already default to this value when enrolling nodes with our workflows, and when\nupgrading an undercloud to Pike. This change ensures that nodes enrolled outside\nof our workflows also default to 'baremetal'.\n\nChange-Id: Iee8604a6a942c12e6fa6b9cb8ea88a2cee1ead8f\nPartial-Bug: #1732190\n""}]",0,526072,f5f37c9534d375c17e995c9487ba2a627514fd7f,22,7,1,10239,,,0,"Set default_resource_class to baremetal

We already default to this value when enrolling nodes with our workflows, and when
upgrading an undercloud to Pike. This change ensures that nodes enrolled outside
of our workflows also default to 'baremetal'.

Change-Id: Iee8604a6a942c12e6fa6b9cb8ea88a2cee1ead8f
Partial-Bug: #1732190
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/72/526072/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,f5f37c9534d375c17e995c9487ba2a627514fd7f,bug/1732190, # Make sure new nodes default to 'baremetal' resource class ironic::default_resource_class: 'baremetal' ,,4,0
openstack%2Fproject-config~master~I1508933ef77669754adf8032fc3d835960f78cb7,openstack/project-config,master,I1508933ef77669754adf8032fc3d835960f78cb7,Remove legacy novaclient jobs,MERGED,2017-11-22 03:33:51.000000000,2017-12-13 12:21:50.000000000,2017-12-13 12:21:50.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 9061}, {'_account_id': 11278}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 03:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a9fe23dad5c43a406eda2cc78f2c08c778207875', 'message': 'Remove legacy novaclient jobs\n\nDepends-On: I43a8435485751748ca6228f67d401945cb32652e\nChange-Id: I1508933ef77669754adf8032fc3d835960f78cb7\n'}, {'number': 2, 'created': '2017-11-22 03:41:23.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/85fd2f81236df7fd65509be3ef0cb96b467fbc4b', 'message': 'Remove legacy novaclient jobs\n\nDepends-On: I43a8435485751748ca6228f67d401945cb32652e\nNeeded-By: I37b02be0aeffc3a0f0516616b5294444012b8dea\nChange-Id: I1508933ef77669754adf8032fc3d835960f78cb7\n'}]",0,522101,85fd2f81236df7fd65509be3ef0cb96b467fbc4b,17,7,2,8556,,,0,"Remove legacy novaclient jobs

Depends-On: I43a8435485751748ca6228f67d401945cb32652e
Needed-By: I37b02be0aeffc3a0f0516616b5294444012b8dea
Change-Id: I1508933ef77669754adf8032fc3d835960f78cb7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/522101/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,a9fe23dad5c43a406eda2cc78f2c08c778207875,zuulv3-novaclient,, check: jobs: - legacy-novaclient-dsvm-functional-identity-v3-only: voting: false - legacy-novaclient-dsvm-functional-neutron gate: jobs: - legacy-novaclient-dsvm-functional-neutron,0,8
openstack%2Fopenstack-ansible-os_nova~master~Ie840b3e06a8c6be6a0afcac48fb831ff437af9b2,openstack/openstack-ansible-os_nova,master,Ie840b3e06a8c6be6a0afcac48fb831ff437af9b2,Update static files,MERGED,2017-12-07 08:12:19.000000000,2017-12-13 12:16:35.000000000,2017-12-13 12:16:35.000000000,"[{'_account_id': 538}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-07 08:12:19.000000000', 'files': ['files/rootwrap.d/compute.filters'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/36c4f11710da549fdbce89f314ea99c355e33e0d', 'message': 'Update static files\n\nThis patch updates the role static files in tree\n\nChange-Id: Ie840b3e06a8c6be6a0afcac48fb831ff437af9b2\n'}]",0,526308,36c4f11710da549fdbce89f314ea99c355e33e0d,13,4,1,17068,,,0,"Update static files

This patch updates the role static files in tree

Change-Id: Ie840b3e06a8c6be6a0afcac48fb831ff437af9b2
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/08/526308/1 && git format-patch -1 --stdout FETCH_HEAD,['files/rootwrap.d/compute.filters'],1,36c4f11710da549fdbce89f314ea99c355e33e0d,osa_release,,"# nova/virt/disk/mount/api.py: 'kpartx', '-a', device # nova/virt/disk/mount/api.py: 'kpartx', '-d', device kpartx: CommandFilter, kpartx, root # nova/virt/disk/mount/api.py: 'mount', mapped_device # nova/virt/disk/api.py: 'mount', '-o', 'bind', src, target # nova/virt/xenapi/vm_utils.py: 'mount', '-t', 'ext2,ext3,ext4,reiserfs'.. # nova/virt/configdrive.py: 'mount', device, mountdir mount: CommandFilter, mount, root # nova/virt/disk/mount/api.py: 'umount', mapped_device # nova/virt/disk/api.py: 'umount' target # nova/virt/xenapi/vm_utils.py: 'umount', dev_path # nova/virt/configdrive.py: 'umount', mountdir umount: CommandFilter, umount, root # nova/virt/disk/mount/nbd.py: 'qemu-nbd', '-c', device, image # nova/virt/disk/mount/nbd.py: 'qemu-nbd', '-d', device qemu-nbd: CommandFilter, qemu-nbd, root # nova/virt/disk/mount/loop.py: 'losetup', '--find', '--show', image # nova/virt/disk/mount/loop.py: 'losetup', '--detach', device losetup: CommandFilter, losetup, root # nova/virt/disk/vfs/localfs.py: 'blkid', '-o', 'value', '-s', 'TYPE', device blkid: CommandFilter, blkid, root # nova/virt/libvirt/vif.py: 'vrouter-port-control', ... vrouter-port-control: CommandFilter, vrouter-port-control, root # nova/virt/libvirt/vif.py: 'ebrctl', ... ebrctl: CommandFilter, ebrctl, root # nova/virt/libvirt/vif.py: 'mm-ctl', ... mm-ctl: CommandFilter, mm-ctl, root # nova/virt/libvirt/utils.py: 'nova-idmapshift' nova-idmapshift: CommandFilter, nova-idmapshift, root # nova/virt/libvirt/driver.py: lvremove: CommandFilter, lvremove, root # nova/virt/libvirt/utils.py: lvcreate: CommandFilter, lvcreate, root # nova/virt/libvirt/utils.py: lvs: CommandFilter, lvs, root # nova/virt/libvirt/utils.py: vgs: CommandFilter, vgs, root # nova/virt/libvirt/utils.py: 'shred', '-n3', '-s%d' % volume_size, path shred: CommandFilter, shred, root # nova/virt/libvirt/utils.py: 'xend', 'status' xend: CommandFilter, xend, root ",0,57
openstack%2Fnetworking-midonet~master~I073c06b3a83347b18f8359a36d43ee5538dc9f19,openstack/networking-midonet,master,I073c06b3a83347b18f8359a36d43ee5538dc9f19,test_router_interface_fip: Check revision numbers correctly,ABANDONED,2017-12-13 06:15:38.000000000,2017-12-13 12:10:55.000000000,,"[{'_account_id': 6854}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 06:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/23795128583221f9d55955c94deba0532cafb1fa', 'message': 'test_router_interface_fip: Check revision numbers\n\nChange-Id: I073c06b3a83347b18f8359a36d43ee5538dc9f19\n'}, {'number': 2, 'created': '2017-12-13 09:18:15.000000000', 'files': ['midonet/neutron/tests/tempest/tests/api/test_router_interface_fip.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/24e716da93c5882724556efbe99bbd57ffedc4b7', 'message': 'test_router_interface_fip: Check revision numbers correctly\n\nThe problem was exposed by the recent Neutron OVO change. [1]\nAfter the change, update_floatingip_status bumps the revision number\ncorrectly.\n\n[1] I543669ed3bd59a1f7d5b999e3113bcea7b3c52a8\n\nCloses-Bug: #1737503\nChange-Id: I073c06b3a83347b18f8359a36d43ee5538dc9f19\n'}]",0,527588,24e716da93c5882724556efbe99bbd57ffedc4b7,6,2,2,6854,,,0,"test_router_interface_fip: Check revision numbers correctly

The problem was exposed by the recent Neutron OVO change. [1]
After the change, update_floatingip_status bumps the revision number
correctly.

[1] I543669ed3bd59a1f7d5b999e3113bcea7b3c52a8

Closes-Bug: #1737503
Change-Id: I073c06b3a83347b18f8359a36d43ee5538dc9f19
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/88/527588/2 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/tests/tempest/tests/api/test_router_interface_fip.py'],1,23795128583221f9d55955c94deba0532cafb1fa,bug/1737467," if 'revision_number' in fip2: self.assertGreater(fip2_updated['revision_number'], fip2['revision_number']) if 'revision_number' in fip2: self.assertGreater(fip2_shown['revision_number'], fip2_updated['revision_number'])",,6,0
openstack%2Fcongress~master~I7619f744dd4ac705bd25dfe1bf31d1d0c1575372,openstack/congress,master,I7619f744dd4ac705bd25dfe1bf31d1d0c1575372,Updated from global requirements,MERGED,2017-12-07 13:19:51.000000000,2017-12-13 12:07:19.000000000,2017-12-13 12:07:18.000000000,"[{'_account_id': 11278}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 13:19:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/4e1eca8a096059405695de9879c2c69b379a2c80', 'message': 'Updated from global requirements\n\nChange-Id: I7619f744dd4ac705bd25dfe1bf31d1d0c1575372\n'}]",0,526368,4e1eca8a096059405695de9879c2c69b379a2c80,8,2,1,11131,,,0,"Updated from global requirements

Change-Id: I7619f744dd4ac705bd25dfe1bf31d1d0c1575372
",git fetch https://review.opendev.org/openstack/congress refs/changes/68/526368/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4e1eca8a096059405695de9879c2c69b379a2c80,openstack/requirements,oslo.policy>=1.30.0 # Apache-2.0,oslo.policy>=1.23.0 # Apache-2.0,1,1
openstack%2Fosprofiler~master~I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44,openstack/osprofiler,master,I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44,Add Zuul job for functional testing,MERGED,2017-10-25 15:31:05.000000000,2017-12-13 12:04:37.000000000,2017-12-13 12:04:37.000000000,"[{'_account_id': 3012}, {'_account_id': 5950}, {'_account_id': 6547}, {'_account_id': 17645}, {'_account_id': 22348}, {'_account_id': 23630}]","[{'number': 1, 'created': '2017-10-25 15:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/f8a95397262630b44a43020a936af11cb35d2087', 'message': 'Add Zuul job for functional testing\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 2, 'created': '2017-10-25 16:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/6bbf5c08a0692fefc8fbf2297b588c66587beef7', 'message': 'Add Zuul job for functional testing\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 3, 'created': '2017-10-26 07:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/4b1bd579e274525218f4b2e4613b37170832f420', 'message': '[WIP] Add Zuul job for functional testing\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 4, 'created': '2017-10-26 07:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/f2f3dc67a1302cd448deade00a67ea69727aec5e', 'message': '[WIP] Add Zuul job for functional testing\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 5, 'created': '2017-10-26 10:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/225458f5c62148d60978f3ed4b2448037a677ec3', 'message': '[WIP] Add Zuul job for functional testing\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 6, 'created': '2017-10-26 15:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/b5fbb55b283c6a9b05f7b636b968ea5587c5aec7', 'message': 'Add Zuul job for functional testing\n\nThe job prepares VM with RabbitMQ installed, then it executes tests\nlocated under osprofiler/tests/functional.\n\nTo run the job manually use `tox -e functional-py27` or\n`tox -e functional-py35`.\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 7, 'created': '2017-10-27 11:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/ded27e0dc2aa02c9bfe74e57f63cac51bde46557', 'message': 'Add Zuul job for functional testing\n\nThe job prepares VM with RabbitMQ installed, then it executes tests\nlocated under osprofiler/tests/functional.\n\nTo run the job manually use `tox -e functional-py27` or\n`tox -e functional-py35`.\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}, {'number': 8, 'created': '2017-11-08 08:06:06.000000000', 'files': ['bindep.txt', 'osprofiler/tests/test.py', '.zuul.yaml', 'osprofiler/tests/functional/config.cfg', 'osprofiler/tests/functional/test_driver.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/71589dd64f4391afba0bfe28c2263dfd43a6950e', 'message': 'Add Zuul job for functional testing\n\nThe job prepares VM with RabbitMQ installed, then it executes tests\nlocated under osprofiler/tests/functional.\n\nTo run the job manually use `tox -e functional` or\n`tox -e functional-py35`.\n\nChange-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44\n'}]",3,515108,71589dd64f4391afba0bfe28c2263dfd43a6950e,36,6,8,5950,,,0,"Add Zuul job for functional testing

The job prepares VM with RabbitMQ installed, then it executes tests
located under osprofiler/tests/functional.

To run the job manually use `tox -e functional` or
`tox -e functional-py35`.

Change-Id: I1f2b99737d1f17bb09662dc24c4858a1a7a1ad44
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/08/515108/7 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f8a95397262630b44a43020a936af11cb35d2087,add-functional-job,- project: name: openstack/osprofiler check: jobs: - osprofiler-functional-py27 gate: jobs: - osprofiler-functional-py27 - job: name: osprofiler-functional-py27 parent: tox description: | Run functional tests under Python 2.7 Uses tox with the ``functional`` environment. vars: tox_envlist: functional ,,18,0
openstack%2Fhorizon~master~Id641bde457e8723ace0bc1e49aab2c46b2227485,openstack/horizon,master,Id641bde457e8723ace0bc1e49aab2c46b2227485,Prevent non-admin users from detaching interfaces,MERGED,2017-12-12 14:26:51.000000000,2017-12-13 12:03:30.000000000,2017-12-13 12:03:30.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a873fa5a7c0635a2dccc8b6fab5ae3e4f481115c', 'message': 'Prevent non-admin users from detaching interfaces\n\nRemove the option to detach_interface from running instances for\nnon-admin users.\n\nChange-Id: Id641bde457e8723ace0bc1e49aab2c46b2227485\nCloses-bug: #1690790\n'}, {'number': 2, 'created': '2017-12-13 07:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e4d0d5cace882d058443263bd99553279d93d852', 'message': 'Prevent non-admin users from detaching interfaces\n\nRemove the option to detach_interface from running instances for\nnon-admin users.\n\nChange-Id: Id641bde457e8723ace0bc1e49aab2c46b2227485\nCloses-bug: #1690790\n'}, {'number': 3, 'created': '2017-12-13 08:03:32.000000000', 'files': ['openstack_dashboard/conf/nova_policy.json', 'openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c999239fed8d2213a8913d1cc8fb294f7086b594', 'message': 'Prevent non-admin users from detaching interfaces\n\nRemove the option to detach_interface from running instances for\nnon-admin users.\n\nChange-Id: Id641bde457e8723ace0bc1e49aab2c46b2227485\nCloses-bug: #1690790\n'}]",2,527414,c999239fed8d2213a8913d1cc8fb294f7086b594,11,2,3,27275,,,0,"Prevent non-admin users from detaching interfaces

Remove the option to detach_interface from running instances for
non-admin users.

Change-Id: Id641bde457e8723ace0bc1e49aab2c46b2227485
Closes-bug: #1690790
",git fetch https://review.opendev.org/openstack/horizon refs/changes/14/527414/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/conf/nova_policy.json', 'openstack_dashboard/dashboards/project/instances/tables.py']",2,a873fa5a7c0635a2dccc8b6fab5ae3e4f481115c,bug/1690790," policy_rules = ((""compute"", ""os_compute_api:os-detach-interfaces""),)","# TODO(lyj): the policy for detach interface not exists in nova.json, # once it's added, it should be added here.",2,2
openstack%2Fkolla-ansible~master~I9418bf40a4bc3dcfc07c8b2eae17cb5779f5b444,openstack/kolla-ansible,master,I9418bf40a4bc3dcfc07c8b2eae17cb5779f5b444,Implement ceph-mgr service,MERGED,2017-12-05 08:17:04.000000000,2017-12-13 11:58:17.000000000,2017-12-13 11:58:17.000000000,"[{'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 20663}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 08:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/138ea817a342738536f04d846421c779ccd610fb', 'message': 'Implement ceph-mgr service\n\nceph-mgr service is mandatory in ceph luminous\n\nDepends-On: I875f84012a92d4f8b9dcb212d917cf61167270b8\nChange-Id: I9418bf40a4bc3dcfc07c8b2eae17cb5779f5b444\nImplements: blueprint ceph-luminous\n'}, {'number': 2, 'created': '2017-12-08 04:46:52.000000000', 'files': ['ansible/inventory/multinode', 'ansible/roles/ceph/tasks/start_mgrs.yml', 'ansible/roles/ceph/defaults/main.yml', 'ansible/roles/ceph/tasks/pull.yml', 'ansible/roles/ceph/templates/ceph-mgr.json.j2', 'ansible/roles/ceph/tasks/deploy.yml', 'ansible/roles/ceph/tasks/config.yml', 'ansible/inventory/all-in-one', 'releasenotes/notes/implement-ceph-mgr-d631d12ee30df5c8.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8acb77554888ec0ddbe289f9b2f3aa221e891067', 'message': 'Implement ceph-mgr service\n\nceph-mgr service is mandatory in ceph luminous\n\nDepends-On: I875f84012a92d4f8b9dcb212d917cf61167270b8\nChange-Id: I9418bf40a4bc3dcfc07c8b2eae17cb5779f5b444\nImplements: blueprint ceph-luminous\n'}]",0,525495,8acb77554888ec0ddbe289f9b2f3aa221e891067,21,5,2,7488,,,0,"Implement ceph-mgr service

ceph-mgr service is mandatory in ceph luminous

Depends-On: I875f84012a92d4f8b9dcb212d917cf61167270b8
Change-Id: I9418bf40a4bc3dcfc07c8b2eae17cb5779f5b444
Implements: blueprint ceph-luminous
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/95/525495/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/inventory/multinode', 'ansible/roles/ceph/tasks/start_mgrs.yml', 'ansible/roles/ceph/defaults/main.yml', 'ansible/roles/ceph/tasks/pull.yml', 'ansible/roles/ceph/templates/ceph-mgr.json.j2', 'ansible/roles/ceph/tasks/deploy.yml', 'ansible/roles/ceph/tasks/config.yml', 'ansible/inventory/all-in-one']",8,138ea817a342738536f04d846421c779ccd610fb,bp/ceph-luminous,[ceph-mgr:children] ceph ,,69,0
openstack%2Fnetworking-ovn~master~Ibbf5376d2e57a10d478b456b6828e01d7d480595,openstack/networking-ovn,master,Ibbf5376d2e57a10d478b456b6828e01d7d480595,get rid of update_port in OVNMechanismDriver,MERGED,2017-12-08 10:05:56.000000000,2017-12-13 11:55:53.000000000,2017-12-13 11:55:53.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23458}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-12-08 10:05:56.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/ml2/qos_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/unit/ml2/test_qos_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8194851ab905382d8d76ed10d108208c455cf8ec', 'message': 'get rid of update_port in OVNMechanismDriver\n\nRemove OVNMechanismDriver.update_port and use invoking\nOVNClient.update_port instead.\n\nChange-Id: Ibbf5376d2e57a10d478b456b6828e01d7d480595\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",0,526639,8194851ab905382d8d76ed10d108208c455cf8ec,21,4,1,23458,,,0,"get rid of update_port in OVNMechanismDriver

Remove OVNMechanismDriver.update_port and use invoking
OVNClient.update_port instead.

Change-Id: Ibbf5376d2e57a10d478b456b6828e01d7d480595
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/39/526639/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/ml2/qos_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/unit/ml2/test_qos_driver.py']",4,8194851ab905382d8d76ed10d108208c455cf8ec,qos," self.mech_driver._ovn_client = mock.Mock() self.mech_driver._ovn_client._qos_driver = mock.Mock() self.driver = qos_driver.OVNQosNotificationDriver.create( self.mech_driver) self.driver._driver._ovn_client._qos_driver.create_policy.\ assert_not_called() self.driver._driver._ovn_client._qos_driver.update_policy.\ assert_called_once_with(context, self.policy) self.driver._driver._ovn_client._qos_driver.delete_policy.\ assert_not_called() self.ovn_client = mock.Mock() self.driver = qos_driver.OVNQosDriver(self.ovn_client) with mock.patch.object(self.ovn_client, mock.patch.object(self.ovn_client, 'update_port', update_port.assert_called_once_with(self.port, self.port, qos_options={})"," self.driver = qos_driver.OVNQosNotificationDriver() self.qos_driver = mock.Mock() self.driver._driver_property = self.mech_driver self.mech_driver.qos_driver = self.qos_driver self.qos_driver.create_policy.assert_not_called() self.qos_driver.update_policy.assert_called_once_with(context, self.policy) self.qos_driver.delete_policy.assert_not_called() self.mech_driver = mock.Mock() self.driver = qos_driver.OVNQosDriver(self.mech_driver) with mock.patch.object(self.mech_driver, mock.patch.object(self.mech_driver, 'update_port', update_port.assert_called_once_with(self.port, self.port, {})",26,42
openstack%2Frpm-packaging~master~I2055607eb784cbf68a486e9243fac76869f45aaf,openstack/rpm-packaging,master,I2055607eb784cbf68a486e9243fac76869f45aaf,Prepare to update lastest taskflow to 3.0.0,ABANDONED,2017-12-12 03:22:45.000000000,2017-12-13 11:48:09.000000000,,"[{'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26584}]","[{'number': 1, 'created': '2017-12-12 03:22:45.000000000', 'files': ['openstack/taskflow/taskflow.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c5ae5d07bb01fb4b182ed8b85c8f937d5e3e4864', 'message': 'Prepare to update lastest taskflow to 3.0.0\n\nChange-Id: I2055607eb784cbf68a486e9243fac76869f45aaf\n'}]",0,527295,c5ae5d07bb01fb4b182ed8b85c8f937d5e3e4864,12,6,1,26584,,,0,"Prepare to update lastest taskflow to 3.0.0

Change-Id: I2055607eb784cbf68a486e9243fac76869f45aaf
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/95/527295/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/taskflow/taskflow.spec.j2'],1,c5ae5d07bb01fb4b182ed8b85c8f937d5e3e4864,taskflow,Version: 3.0.0,Version: 2.17.0,1,1
openstack%2Frpm-packaging~master~Ia5e42a3f86844203b0ac7b3789f918c5a633e1bc,openstack/rpm-packaging,master,Ia5e42a3f86844203b0ac7b3789f918c5a633e1bc,Prepare to update lastest oslo.utils 3.33.0,ABANDONED,2017-12-12 03:19:29.000000000,2017-12-13 11:47:45.000000000,,"[{'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26584}]","[{'number': 1, 'created': '2017-12-12 03:19:29.000000000', 'files': ['openstack/oslo.utils/oslo.utils.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/94b5179d29996125efc836e5d1bc7ead86fbe92c', 'message': 'Prepare to update lastest oslo.utils 3.33.0\n\nChange-Id: Ia5e42a3f86844203b0ac7b3789f918c5a633e1bc\n'}]",0,527294,94b5179d29996125efc836e5d1bc7ead86fbe92c,12,6,1,26584,,,0,"Prepare to update lastest oslo.utils 3.33.0

Change-Id: Ia5e42a3f86844203b0ac7b3789f918c5a633e1bc
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/94/527294/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.utils/oslo.utils.spec.j2'],1,94b5179d29996125efc836e5d1bc7ead86fbe92c,q-oslo-utils,{% set upstream_version = upstream_version('3.33.0') %},{% set upstream_version = upstream_version('3.32.0') %},1,1
openstack%2Frpm-packaging~master~Ie1b8ed5e2d1c61741805c4846cc39cac11bc7917,openstack/rpm-packaging,master,Ie1b8ed5e2d1c61741805c4846cc39cac11bc7917,Prepare to update lastest oslo.concurrency 3.24.0,ABANDONED,2017-12-12 03:14:44.000000000,2017-12-13 11:47:37.000000000,,"[{'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26584}]","[{'number': 1, 'created': '2017-12-12 03:14:44.000000000', 'files': ['openstack/oslo.concurrency/oslo.concurrency.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/86e65c29634b8190442978065ef9a32ede9b60a9', 'message': 'Prepare to update lastest oslo.concurrency 3.24.0\n\nChange-Id: Ie1b8ed5e2d1c61741805c4846cc39cac11bc7917\n'}]",0,527292,86e65c29634b8190442978065ef9a32ede9b60a9,17,6,1,26584,,,0,"Prepare to update lastest oslo.concurrency 3.24.0

Change-Id: Ie1b8ed5e2d1c61741805c4846cc39cac11bc7917
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/92/527292/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.concurrency/oslo.concurrency.spec.j2'],1,86e65c29634b8190442978065ef9a32ede9b60a9,oslo-concuurency,{% set upstream_version = upstream_version('3.24.0') %},{% set upstream_version = upstream_version('3.23.0') %},1,1
openstack%2Fopenstack-ansible~stable%2Fpike~I49e371a2743618a0b5544a23e892aa28bb8567eb,openstack/openstack-ansible,stable/pike,I49e371a2743618a0b5544a23e892aa28bb8567eb,Change the galera health check for better cluster health,MERGED,2017-12-11 14:13:02.000000000,2017-12-13 11:47:27.000000000,2017-12-13 11:47:27.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-11 14:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/92c22c8251de5f08821c5da233624079fd43110b', 'message': ""Change the galera health check for better cluster health\n\nThe current galera cluster health check simply logs into a cluster node\nbut does not check if the node is sync'd. This can lead to an issue\nwhere a node is placed back into the pool before it is ready. If this\nhappens it can lead to a broken OpenStack environment until the wsrep\nreceived queue is processed which is especially true if the node out of\nsync happens to be the primary.\n\nCombined backport of:\n- https://review.openstack.org/520673\n- https://review.openstack.org/523854\n- https://review.openstack.org/524107\n\nCloses-Bug: #1665667\nChange-Id: I49e371a2743618a0b5544a23e892aa28bb8567eb\nDepends-On: I81c924464aa4b19c2a62f37b5bf26c3c0453786a\nDepends-On: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 2, 'created': '2017-12-11 18:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d588ce482e3e3ffe99703c7a1efe56c2c8987188', 'message': ""Change the galera health check for better cluster health\n\nThe current galera cluster health check simply logs into a cluster node\nbut does not check if the node is sync'd. This can lead to an issue\nwhere a node is placed back into the pool before it is ready. If this\nhappens it can lead to a broken OpenStack environment until the wsrep\nreceived queue is processed which is especially true if the node out of\nsync happens to be the primary.\n\nCombined backport of:\n- https://review.openstack.org/520673\n- https://review.openstack.org/523854\n- https://review.openstack.org/524107\n\nCloses-Bug: #1665667\nChange-Id: I49e371a2743618a0b5544a23e892aa28bb8567eb\nDepends-On: I81c924464aa4b19c2a62f37b5bf26c3c0453786a\nDepends-On: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 3, 'created': '2017-12-12 23:55:35.000000000', 'files': ['group_vars/all/haproxy.yml', 'ansible-role-requirements.yml', 'group_vars/galera_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8c0ce1c62f73f880ed255b20ea932852288d23e9', 'message': ""Change the galera health check for better cluster health\n\nThe current galera cluster health check simply logs into a cluster node\nbut does not check if the node is sync'd. This can lead to an issue\nwhere a node is placed back into the pool before it is ready. If this\nhappens it can lead to a broken OpenStack environment until the wsrep\nreceived queue is processed which is especially true if the node out of\nsync happens to be the primary.\n\nCombined backport of:\n- https://review.openstack.org/520673\n- https://review.openstack.org/523854\n- https://review.openstack.org/524107\n\nCloses-Bug: #1665667\nChange-Id: I49e371a2743618a0b5544a23e892aa28bb8567eb\nDepends-On: I81c924464aa4b19c2a62f37b5bf26c3c0453786a\nDepends-On: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,527099,8c0ce1c62f73f880ed255b20ea932852288d23e9,24,5,3,6816,,,0,"Change the galera health check for better cluster health

The current galera cluster health check simply logs into a cluster node
but does not check if the node is sync'd. This can lead to an issue
where a node is placed back into the pool before it is ready. If this
happens it can lead to a broken OpenStack environment until the wsrep
received queue is processed which is especially true if the node out of
sync happens to be the primary.

Combined backport of:
- https://review.openstack.org/520673
- https://review.openstack.org/523854
- https://review.openstack.org/524107

Closes-Bug: #1665667
Change-Id: I49e371a2743618a0b5544a23e892aa28bb8567eb
Depends-On: I81c924464aa4b19c2a62f37b5bf26c3c0453786a
Depends-On: Ie1b3b9724dd33de1d90634166e585ecceb1f4c96
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/99/527099/1 && git format-patch -1 --stdout FETCH_HEAD,"['group_vars/all/haproxy.yml', 'group_vars/galera_all.yml']",2,92c22c8251de5f08821c5da233624079fd43110b,bug/1665667," # By default galera_monitoring xinetd app is open to 0.0.0.0/0 # This makes sure the monitoring is only restricted to the necessary nodes: # the load balancers, and the galera nodes. galera_monitoring_allowed_source: ""{% for node in groups['galera_all'] + groups['haproxy_all'] %}{{ hostvars[node]['ansible_host'] }} {% endfor %} 127.0.0.1""",,7,1
openstack%2Frpm-packaging~master~Ieef83d195ab1cbab683846bfaf8539cce6a22ca9,openstack/rpm-packaging,master,Ieef83d195ab1cbab683846bfaf8539cce6a22ca9,Update keystonemiddleware to 4.19.0,ABANDONED,2017-12-12 01:52:18.000000000,2017-12-13 11:47:24.000000000,,"[{'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-12 01:52:18.000000000', 'files': ['openstack/keystonemiddleware/keystonemiddleware.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d0bdc4c6dbf534e516a82d5f51d8268ba67c0db1', 'message': 'Update keystonemiddleware to 4.19.0\n\nChange-Id: Ieef83d195ab1cbab683846bfaf8539cce6a22ca9\n'}]",0,527283,d0bdc4c6dbf534e516a82d5f51d8268ba67c0db1,7,5,1,26584,,,0,"Update keystonemiddleware to 4.19.0

Change-Id: Ieef83d195ab1cbab683846bfaf8539cce6a22ca9
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/83/527283/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/keystonemiddleware/keystonemiddleware.spec.j2'],1,d0bdc4c6dbf534e516a82d5f51d8268ba67c0db1,keystonemiddleware,Version: 4.19.0,Version: 4.18.0,1,1
openstack%2Fpython-watcherclient~master~I72078850152e0ccf2abc0d35b06a5142df35c312,openstack/python-watcherclient,master,I72078850152e0ccf2abc0d35b06a5142df35c312,marker when retrive audit,MERGED,2017-11-03 07:55:09.000000000,2017-12-13 11:43:17.000000000,2017-12-13 11:43:16.000000000,"[{'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-03 07:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/b9494c95a67e7dd525ab632a34d1e1c3252099bc', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}, {'number': 2, 'created': '2017-11-03 08:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/eed364b18830831251ac09894b0fd9a6dbcc1246', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}, {'number': 3, 'created': '2017-11-20 09:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/98b0ee9310c691e3012bd12ccc17fe9f9d7ad8d8', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}, {'number': 4, 'created': '2017-11-20 09:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/a4e71bdf54b0f43403186a79c11009c50289282b', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}, {'number': 5, 'created': '2017-11-20 09:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/abe9f93f1a0cd8581bbbc64ff88aa4504b195235', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}, {'number': 6, 'created': '2017-11-21 14:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/be1cc83ad37103c461c3422ce2db2caade2e8987', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}, {'number': 7, 'created': '2017-11-27 06:56:01.000000000', 'files': ['watcherclient/tests/unit/v1/test_audit.py', 'watcherclient/v1/audit_shell.py', 'watcherclient/v1/audit.py', 'watcherclient/tests/unit/v1/test_audit_shell.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/fada471714cca0c2370ef9de3cd15928aa386535', 'message': 'marker when retrive audit\n\nChange-Id: I72078850152e0ccf2abc0d35b06a5142df35c312\n'}]",0,517566,fada471714cca0c2370ef9de3cd15928aa386535,23,3,7,24501,,,0,"marker when retrive audit

Change-Id: I72078850152e0ccf2abc0d35b06a5142df35c312
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/66/517566/4 && git format-patch -1 --stdout FETCH_HEAD,"['watcherclient/v1/audit_shell.py', 'watcherclient/v1/audit.py']",2,b9494c95a67e7dd525ab632a34d1e1c3252099bc,add-marker," sort_dir=None, detail=False, goal=None, strategy=None, marker=None): if marker is not None: filters.append('marker=%s' % marker)"," sort_dir=None, detail=False, goal=None, strategy=None):",14,1
openstack%2Fnova~master~I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6,openstack/nova,master,I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6,Fix backwards compatibility for InstanceNUMACell,ABANDONED,2016-11-10 13:04:56.000000000,2017-12-13 11:38:26.000000000,,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 11351}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 18337}, {'_account_id': 20040}, {'_account_id': 21511}, {'_account_id': 21784}, {'_account_id': 21813}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25625}, {'_account_id': 26490}, {'_account_id': 26515}]","[{'number': 1, 'created': '2016-11-10 13:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81f779b19662096389c107283a9b39accada6185', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_pinning' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}, {'number': 2, 'created': '2016-11-15 16:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f037f9867bb9b7450036368a03e368d00f1892fc', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_pinning' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}, {'number': 3, 'created': '2016-11-16 10:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bca9e5144b23b59618c0ffc1be489c50b52a23e0', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_pinning' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}, {'number': 4, 'created': '2016-11-16 13:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7c0fd76897ba4aec4c1e6fd31dd4d080132e9be', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_pinning' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}, {'number': 5, 'created': '2016-11-21 15:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b0cc1bbf3184552e7fda8707f0341044c6f3869', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_pinning' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}, {'number': 6, 'created': '2016-12-01 11:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93fa7fb5aa251374622d63f927794e697fa6fef3', 'message': 'Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn\'t have a \'cpu_policy\' field.\nHowever, after this, the \'cpu_pinning_requested\' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\nThis check can be removed when such objects are no longer found\n""on-the-wire"".\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n'}, {'number': 7, 'created': '2016-12-02 13:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f03bcd66fea7a7085eb388bfd1e3f503ac65634b', 'message': 'Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn\'t have a \'cpu_policy\' field.\nHowever, after this, the \'cpu_pinning_requested\' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\nThis check can be removed when such objects are no longer found\n""on-the-wire"".\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n'}, {'number': 8, 'created': '2017-01-05 16:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9f66bcd826708212163782627089926211ee56f', 'message': 'Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn\'t have a \'cpu_policy\' field.\nHowever, after this, the \'cpu_pinning_requested\' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\nThis check can be removed when such objects are no longer found\n""on-the-wire"".\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n'}, {'number': 9, 'created': '2017-01-05 16:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ac5514688618398c158935b55fd756b5c9045c3', 'message': 'Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn\'t have a \'cpu_policy\' field.\nHowever, after this, the \'cpu_pinning_requested\' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\nThis check can be removed when such objects are no longer found\n""on-the-wire"".\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n'}, {'number': 10, 'created': '2017-01-27 15:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48b0069243b3a7c9acb5a1720290ba0665070f32', 'message': 'Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn\'t have a \'cpu_policy\' field.\nHowever, after this, the \'cpu_pinning_requested\' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\nThis check can be removed when such objects are no longer found\n""on-the-wire"".\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n'}, {'number': 11, 'created': '2017-02-02 11:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/154482a6544456ce56a1e85a7c1d3dcc69b38cd2', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_policy' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}, {'number': 12, 'created': '2017-03-14 11:35:06.000000000', 'files': ['nova/tests/unit/objects/test_instance_numa_topology.py', 'nova/objects/instance_numa_topology.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aedd039a5509fde7f03688b790399e3544841e90', 'message': ""Fix backwards compatibility for InstanceNUMACell\n\nPre-1.3 versions of InstanceNUMACell didn't have a 'cpu_policy' field.\nHowever, after this, the 'cpu_pinning_requested' function was changed\nto rely on this variable. This was not backwards compatible. Resolve\nthis by reinstating the pre-1.3 check for pre-1.3 objects versions.\n\nChange-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6\nResolves-bug: #1636338\n""}]",22,396184,aedd039a5509fde7f03688b790399e3544841e90,198,37,12,15334,,,0,"Fix backwards compatibility for InstanceNUMACell

Pre-1.3 versions of InstanceNUMACell didn't have a 'cpu_policy' field.
However, after this, the 'cpu_pinning_requested' function was changed
to rely on this variable. This was not backwards compatible. Resolve
this by reinstating the pre-1.3 check for pre-1.3 objects versions.

Change-Id: I6512310ae87b85eb1d029142b6f5aaa6f91bb2a6
Resolves-bug: #1636338
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/396184/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_instance_numa_topology.py', 'nova/objects/instance_numa_topology.py']",2,81f779b19662096389c107283a9b39accada6185,bug/1636338," # NOTE(sfinucan): Handle pre-1.3 versions of the object, where the # cpu_policy field did not exist and therefore was not set. See # #1636338 if self.cpu_pinning and not self.cpu_policy: self.cpu_policy = obj_fields.CPUAllocationPolicy.DEDICATED ",,14,0
openstack%2Fnova~master~Idb006049b2741abdd4348090a3e118b729d71e7d,openstack/nova,master,Idb006049b2741abdd4348090a3e118b729d71e7d,Combine obj_make_compatible tests,ABANDONED,2017-01-27 15:09:58.000000000,2017-12-13 11:30:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 8556}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}, {'_account_id': 21813}, {'_account_id': 23630}, {'_account_id': 25625}, {'_account_id': 26490}]","[{'number': 1, 'created': '2017-01-27 15:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/645f767d4a380e30e737d08927f111d18d268b77', 'message': ""Combine obj_make_compatible tests\n\nThis fixes a bug with one test: we should check 'nova_object.data',\nnot the primitive itself.\n\nChange-Id: Idb006049b2741abdd4348090a3e118b729d71e7d\nTrivialFix\n""}, {'number': 2, 'created': '2017-03-14 11:35:06.000000000', 'files': ['nova/tests/unit/objects/test_instance_numa_topology.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c9e5f28291fdc105ac9bba660d403520f549a812', 'message': ""Combine obj_make_compatible tests\n\nThis fixes a bug with one test: we should check 'nova_object.data',\nnot the primitive itself.\n\nChange-Id: Idb006049b2741abdd4348090a3e118b729d71e7d\nTrivialFix\n""}]",1,426261,c9e5f28291fdc105ac9bba660d403520f549a812,22,14,2,15334,,,0,"Combine obj_make_compatible tests

This fixes a bug with one test: we should check 'nova_object.data',
not the primitive itself.

Change-Id: Idb006049b2741abdd4348090a3e118b729d71e7d
TrivialFix
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/426261/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_instance_numa_topology.py'],1,645f767d4a380e30e737d08927f111d18d268b77,bug/1636338," def test_obj_make_compatible(self): cpuset_reserved=set([1, 2]), # version 1.4 primitive = inst_cell.obj_to_primitive(target_version='1.4', version_manifest=versions) self.assertIn('cpuset_reserved', primitive['nova_object.data']) self.assertNotIn('cpuset_reserved', primitive['nova_object.data'])"," def test_obj_make_compatible_numa_cell_pre_1_4(self): topo_obj = objects.InstanceNUMACell( cpuset_reserved=set([1, 2])) versions = ovo_base.obj_tree_get_versions('InstanceNUMACell') primitive = topo_obj.obj_to_primitive(target_version='1.3', version_manifest=versions) self.assertNotIn('cpuset_reserved', primitive) def test_obj_make_compatible_cell(self):",8,9
openstack%2Fdragonflow~master~I3e7a557a642d8150f48f971e33e6bcc966e76030,openstack/dragonflow,master,I3e7a557a642d8150f48f971e33e6bcc966e76030,Add support for MACVLAN/IPVLAN,MERGED,2017-12-06 13:06:49.000000000,2017-12-13 11:28:21.000000000,2017-12-13 11:28:21.000000000,"[{'_account_id': 6598}, {'_account_id': 17880}, {'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 23235}, {'_account_id': 23766}, {'_account_id': 26131}]","[{'number': 1, 'created': '2017-12-06 13:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9289989fb26e7eae71c28956d9a152fba25bcb0d', 'message': 'Add support for MACVLAN/IPVLAN\n\nAdds support for MACVLAN and IPVLAN in Dragonflow db model and\nDragonflow controller trunk application.\n\nThis adds support for e.g., MACVLAN containers, and amphora VMs.\n\nChange-Id: I3e7a557a642d8150f48f971e33e6bcc966e76030\nPartial-Bug: #1720734\n'}, {'number': 2, 'created': '2017-12-07 07:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b64ed19ac16b9e2331caca57e7e88d383593cf01', 'message': 'Add support for MACVLAN/IPVLAN\n\nAdds support for MACVLAN and IPVLAN in Dragonflow db model and\nDragonflow controller trunk application.\n\nThis adds support for e.g., MACVLAN containers, and amphora VMs.\n\nChange-Id: I3e7a557a642d8150f48f971e33e6bcc966e76030\nPartial-Bug: #1720734\n'}, {'number': 3, 'created': '2017-12-11 07:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d7b492f882e2273ce7f6e4571b66ebb3502a9119', 'message': 'Add support for MACVLAN/IPVLAN\n\nAdds support for MACVLAN and IPVLAN in Dragonflow db model and\nDragonflow controller trunk application.\n\nThis adds support for e.g., MACVLAN containers, and amphora VMs.\n\nChange-Id: I3e7a557a642d8150f48f971e33e6bcc966e76030\nPartial-Bug: #1720734\n'}, {'number': 4, 'created': '2017-12-12 08:07:36.000000000', 'files': ['dragonflow/common/exceptions.py', 'dragonflow/db/models/trunk.py', 'dragonflow/controller/apps/trunk.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8fe3e29cb31c9d0ff83447473abb8bd2ef8588e2', 'message': 'Add support for MACVLAN/IPVLAN\n\nAdds support for MACVLAN and IPVLAN in Dragonflow db model and\nDragonflow controller trunk application.\n\nThis adds support for e.g., MACVLAN containers, and amphora VMs.\n\nChange-Id: I3e7a557a642d8150f48f971e33e6bcc966e76030\nPartial-Bug: #1720734\n'}]",2,526058,8fe3e29cb31c9d0ff83447473abb8bd2ef8588e2,30,7,4,20229,,,0,"Add support for MACVLAN/IPVLAN

Adds support for MACVLAN and IPVLAN in Dragonflow db model and
Dragonflow controller trunk application.

This adds support for e.g., MACVLAN containers, and amphora VMs.

Change-Id: I3e7a557a642d8150f48f971e33e6bcc966e76030
Partial-Bug: #1720734
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/58/526058/4 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/common/exceptions.py', 'dragonflow/db/models/trunk.py', 'dragonflow/controller/apps/trunk.py']",3,9289989fb26e7eae71c28956d9a152fba25bcb0d,bug/1720734,"from ryu.ofproto import ether def _get_classification_params_ip(self, child_port_segmentation): child = child_port_segmentation.port child_ip = child.ip child_ip_version = child_ip.version if child_ip_version == n_const.IP_VERSION_4: ip_field = 'ipv4_src' eth_type = ether.ETH_TYPE_IP elif child_ip_version == n_const.IP_VERSION_6: ip_field = 'ipv6_src' eth_type = ether.ETH_TYPE_IPV6 else: LOG.warning('Unkown version %s for IP %r', child_ip, child_ip_version) raise exceptions.InvalidIPAddressException(key=child_ip) return ip_field, eth_type, child_ip def _get_classification_params_ipvlan(self, child_port_segmentation): ip_field, eth_type, child_ip = self._get_classification_params_ip( child_port_segmentation) return {'eth_src': child_port_segmentation.parent.mac, 'eth_type': eth_type, ip_field: child_ip} def _get_classification_params_macvlan(self, child_port_segmentation): ip_field, eth_type, child_ip = self._get_classification_params_ip( child_port_segmentation) return {'eth_src': child_port_segmentation.port.mac, 'eth_type': eth_type, ip_field: child_ip} elif trunk.TYPE_MACVLAN == segmentation_type: params.update( self._get_classification_params_macvlan( child_port_segmentation), ) elif trunk.TYPE_IPVLAN == segmentation_type: params.update( self._get_classification_params_ipvlan( child_port_segmentation), ) else: raise exceptions.UnsupportedSegmentationTypeException( def _add_classification_actions_vlan(self, actions, child_port_segmentation): def _add_classification_actions_ipvlan(self, actions, child_port_segmentation): """""" Replace packet MAC from parent to child (Parent doesn't know child MAC) """""" actions.append(self.parser.OFPActionSetField( eth_src=child_port_segmentation.port.mac)) elif trunk.TYPE_MACVLAN == segmentation_type: pass # No action needed elif trunk.TYPE_IPVLAN == segmentation_type: self._add_classification_actions_ipvlan(actions, child_port_segmentation) else: raise exceptions.UnsupportedSegmentationTypeException( def _add_dispatch_actions_ipvlan(self, actions, child_port_segmentation): """""" Replace packet MAC from child to parent (Parent doesn't know child MAC) """""" # TODO(oanson) Maybe add MAC to child_port_segmentation model # so we won't have to guess which MAC? actions.append(self.parser.OFPActionSetField( eth_dst=child_port_segmentation.parent.mac)) elif trunk.TYPE_MACVLAN == segmentation_type: pass # No action needed elif trunk.TYPE_IPVLAN == segmentation_type: self._add_dispatch_actions_ipvlan(actions, child_port_segmentation) else: raise exceptions.UnsupportedSegmentationTypeException("," else: raise exceptions.UnsupportedSegmentationType( def _add_classification_actions_vlan(self, actions, child_port_segmentation): else: raise exceptions.UnsupportedSegmentationType( else: raise exceptions.UnsupportedSegmentationType(",95,7
openstack%2Ftacker~master~I919ba223c3687d553e937512fa649b8eb99c276e,openstack/tacker,master,I919ba223c3687d553e937512fa649b8eb99c276e,"Fix the deprecated usage of ""get_transport""",MERGED,2017-12-05 13:45:21.000000000,2017-12-13 11:27:01.000000000,2017-12-13 11:27:01.000000000,"[{'_account_id': 2874}, {'_account_id': 11278}, {'_account_id': 18955}, {'_account_id': 19316}, {'_account_id': 19644}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 13:45:21.000000000', 'files': ['tacker/common/rpc.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/19c8f749155e8cc8339795bf71fb6e0a58bcb565', 'message': 'Fix the deprecated usage of ""get_transport""\n\nAs log says, \'oslo_messaging.transport.get_transport()\' is deprecated.\nThe reference link of oslo_messaging is at [1].\n\n[1] https://review.openstack.org/#/c/454194/\n\nChange-Id: I919ba223c3687d553e937512fa649b8eb99c276e\n'}]",0,525609,19c8f749155e8cc8339795bf71fb6e0a58bcb565,12,6,1,24209,,,0,"Fix the deprecated usage of ""get_transport""

As log says, 'oslo_messaging.transport.get_transport()' is deprecated.
The reference link of oslo_messaging is at [1].

[1] https://review.openstack.org/#/c/454194/

Change-Id: I919ba223c3687d553e937512fa649b8eb99c276e
",git fetch https://review.opendev.org/openstack/tacker refs/changes/09/525609/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/common/rpc.py'],1,19c8f749155e8cc8339795bf71fb6e0a58bcb565,oslo-debt," TRANSPORT = oslo_messaging.get_rpc_transport(conf) TRANSPORT = oslo_messaging.get_rpc_transport(conf, allowed_remote_exmods=exmods)"," TRANSPORT = oslo_messaging.get_transport(conf) TRANSPORT = oslo_messaging.get_transport(conf, allowed_remote_exmods=exmods)",3,3
openstack%2Fmistral~master~Ib40a327d299292ba3a417f3f0384f466fcefaa80,openstack/mistral,master,Ib40a327d299292ba3a417f3f0384f466fcefaa80,Modify log infomation to achieve the same format,MERGED,2017-11-15 09:16:04.000000000,2017-12-13 11:24:58.000000000,2017-12-13 11:24:57.000000000,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 21118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-15 09:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7d2b8925c25720db5120409b40e13a7142dca147', 'message': 'Modify log infomation to achieve the same format\n\nSome log information starts with capital letter\nSome log information starts with lowercase letter\nChange them to starting with capital letter\n\nCloses-Bug:#1732375\n\nChange-Id: Ib40a327d299292ba3a417f3f0384f466fcefaa80\n'}, {'number': 2, 'created': '2017-11-20 09:04:54.000000000', 'files': ['mistral/db/sqlalchemy/migration/cli.py', 'mistral/services/expiration_policy.py', 'mistral/services/workflows.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/068aa5362372fd8a7533e29bbb4c9af91ecacb41', 'message': 'Modify log infomation to achieve the same format\n\nSome log information starts with capital letter\nSome log information starts with lowercase letter\nChange them to starting with capital letter\n\nCloses-Bug:#1732375\n\nChange-Id: Ib40a327d299292ba3a417f3f0384f466fcefaa80\n'}]",0,520016,068aa5362372fd8a7533e29bbb4c9af91ecacb41,12,5,2,21118,,,0,"Modify log infomation to achieve the same format

Some log information starts with capital letter
Some log information starts with lowercase letter
Change them to starting with capital letter

Closes-Bug:#1732375

Change-Id: Ib40a327d299292ba3a417f3f0384f466fcefaa80
",git fetch https://review.opendev.org/openstack/mistral refs/changes/16/520016/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/db/sqlalchemy/migration/cli.py', 'mistral/services/expiration_policy.py', 'mistral/services/workflows.py']",3,7d2b8925c25720db5120409b40e13a7142dca147,bug/1732375," LOG.debug(""Registering standard workflows"") LOG.debug(""Creating workflows"") LOG.debug(""Updating workflows"")"," LOG.debug(""registering standard workflows"") LOG.debug(""creating workflows"") LOG.debug(""updating workflows"")",5,5
openstack%2Fmistral~master~Ia44256b1f1d46b14ac6cb93004ba9bd506a56cf8,openstack/mistral,master,Ia44256b1f1d46b14ac6cb93004ba9bd506a56cf8,Log a warning log message if the task isn't found,MERGED,2017-12-07 12:47:06.000000000,2017-12-13 11:08:33.000000000,2017-12-13 11:08:33.000000000,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 27346}]","[{'number': 1, 'created': '2017-12-07 12:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/0c43f716e065f20aa7d4a4c5f612ce6e08953976', 'message': ""Add a warning log message if the task isn't found\n\nIf you make a typo in the workflow task name it can be quite hard to\nspot the issue. Adding a warning to the Mistral logs will give us\nanother clue to look for.\n\nChange-Id: Ia44256b1f1d46b14ac6cb93004ba9bd506a56cf8\n""}, {'number': 2, 'created': '2017-12-07 12:50:17.000000000', 'files': ['mistral/utils/expression_utils.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/07fcb70ea0189817fc439e0a40103fa2c171b006', 'message': ""Log a warning log message if the task isn't found\n\nIf you make a typo in the workflow task name it can be quite hard to\nspot the issue. Adding a warning to the Mistral logs will give us\nanother clue to look for.\n\nChange-Id: Ia44256b1f1d46b14ac6cb93004ba9bd506a56cf8\n""}]",0,526359,07fcb70ea0189817fc439e0a40103fa2c171b006,9,5,2,9712,,,0,"Log a warning log message if the task isn't found

If you make a typo in the workflow task name it can be quite hard to
spot the issue. Adding a warning to the Mistral logs will give us
another clue to look for.

Change-Id: Ia44256b1f1d46b14ac6cb93004ba9bd506a56cf8
",git fetch https://review.opendev.org/openstack/mistral refs/changes/59/526359/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/utils/expression_utils.py'],1,0c43f716e065f20aa7d4a4c5f612ce6e08953976,,"from oslo_log import log as loggingLOG = logging.getLogger(__name__) LOG.warning( ""Task '%s' not found by the task() expression function"", task_name )",,6,0
openstack%2Fironic~master~I4dc5373eee022648893c94b6e64a9c72ca40726d,openstack/ironic,master,I4dc5373eee022648893c94b6e64a9c72ca40726d,Add 'nova hypervisor-list' in example set of commands to compare the resources in Compute service and Bare Metal service.,MERGED,2017-12-12 02:59:51.000000000,2017-12-13 11:04:26.000000000,2017-12-13 11:04:26.000000000,"[{'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 02:59:51.000000000', 'files': ['doc/source/install/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c70b7dd057734b574032488715622788e0d19bcb', 'message': ""Add 'nova hypervisor-list' in example set of commands to compare the resources in Compute service and Bare Metal service.\n\nChange-Id: I4dc5373eee022648893c94b6e64a9c72ca40726d\nCloses-Bug: #1737521\n""}]",0,527288,c70b7dd057734b574032488715622788e0d19bcb,9,4,1,27371,,,0,"Add 'nova hypervisor-list' in example set of commands to compare the resources in Compute service and Bare Metal service.

Change-Id: I4dc5373eee022648893c94b6e64a9c72ca40726d
Closes-Bug: #1737521
",git fetch https://review.opendev.org/openstack/ironic refs/changes/88/527288/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/troubleshooting.rst'],1,c70b7dd057734b574032488715622788e0d19bcb,bug/1737521, $ nova hypervisor-list +--------------------------------------+--------------------------------------+-------+---------+ | ID | Hypervisor hostname | State | Status | +--------------------------------------+--------------------------------------+-------+---------+ | 584cfdc8-9afd-4fbb-82ef-9ff25e1ad3f3 | 86a2b1bb-8b29-4964-a817-f90031debddb | up | enabled | +--------------------------------------+--------------------------------------+-------+---------+ $ nova hypervisor-show 584cfdc8-9afd-4fbb-82ef-9ff25e1ad3f3, $ nova hypervisor-show 1,8,1
openstack%2Fproject-config~master~I0c3d0d38a722890cc4047cc6d2900c8fb8e43258,openstack/project-config,master,I0c3d0d38a722890cc4047cc6d2900c8fb8e43258,Use templates instead of (pre-)release jobs for Blazar repos,MERGED,2017-12-04 20:41:19.000000000,2017-12-13 11:01:23.000000000,2017-12-13 11:01:23.000000000,"[{'_account_id': 6547}, {'_account_id': 8878}, {'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-12-04 20:41:19.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/57474b23334260acad0b066816ace056b117066f', 'message': 'Use templates instead of (pre-)release jobs for Blazar repos\n\nChange-Id: I0c3d0d38a722890cc4047cc6d2900c8fb8e43258\n'}]",0,525305,57474b23334260acad0b066816ace056b117066f,11,6,1,15197,,,0,"Use templates instead of (pre-)release jobs for Blazar repos

Change-Id: I0c3d0d38a722890cc4047cc6d2900c8fb8e43258
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/525305/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,57474b23334260acad0b066816ace056b117066f,blazar, - release-openstack-server - release-openstack-server - release-openstack-server - publish-to-pypi, pre-release: jobs: - release-openstack-python-without-pypi release: jobs: - release-openstack-python-without-pypi pre-release: jobs: - release-openstack-python-without-pypi: required-projects: - openstack/horizon release: jobs: - release-openstack-python-without-pypi: required-projects: - openstack/horizon pre-release: jobs: - release-openstack-python-without-pypi release: jobs: - release-openstack-python-without-pypi pre-release: jobs: - release-openstack-python-without-pypi release: jobs: - release-openstack-python-without-pypi,4,28
openstack%2Freleases~master~I721ef34aeafde3a547bd573c21359bbc7a753bca,openstack/releases,master,I721ef34aeafde3a547bd573c21359bbc7a753bca,Release Murano-dashboard 5.0.0.0b2,MERGED,2017-12-13 05:10:22.000000000,2017-12-13 10:49:42.000000000,2017-12-13 10:49:42.000000000,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 05:10:22.000000000', 'files': ['deliverables/queens/murano-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e5318e390a0387a30dc0e7cc129b1a1fe4efb33f', 'message': 'Release Murano-dashboard 5.0.0.0b2\n\nChange-Id: I721ef34aeafde3a547bd573c21359bbc7a753bca\n'}]",0,527576,e5318e390a0387a30dc0e7cc129b1a1fe4efb33f,6,2,1,14107,,,0,"Release Murano-dashboard 5.0.0.0b2

Change-Id: I721ef34aeafde3a547bd573c21359bbc7a753bca
",git fetch https://review.opendev.org/openstack/releases refs/changes/76/527576/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/murano-dashboard.yaml'],1,e5318e390a0387a30dc0e7cc129b1a1fe4efb33f,, - version: 5.0.0.0b2 projects: - repo: openstack/murano-dashboard hash: c0b5c009e7180880316dd148c5fe14a2a8da5b73,,4,0
openstack%2Ftripleo-quickstart~master~If1fb7d94cd28364c23efae4bb716e64ac6db93f4,openstack/tripleo-quickstart,master,If1fb7d94cd28364c23efae4bb716e64ac6db93f4,add basic/simple tests for the tripleo-ui,MERGED,2017-10-24 19:01:02.000000000,2017-12-13 10:47:14.000000000,2017-11-22 21:49:47.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 10112}, {'_account_id': 12715}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-10-24 19:01:02.000000000', 'files': ['config/environments/default_libvirt.yml', 'quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/627b955b82243e631fddda988d0a7068f77f457e', 'message': 'add basic/simple tests for the tripleo-ui\n\nStarting simple with just a curl test.\nWe need to ensure the tripleo-ui is always\nworking after a deployment.\n\nRelated-Bug: #1722674\nDepends-On: Ie320cf86a6d6d2bc810221e18f4be5e029c26df2\nChange-Id: If1fb7d94cd28364c23efae4bb716e64ac6db93f4\n'}]",1,514795,627b955b82243e631fddda988d0a7068f77f457e,24,9,1,9592,,,0,"add basic/simple tests for the tripleo-ui

Starting simple with just a curl test.
We need to ensure the tripleo-ui is always
working after a deployment.

Related-Bug: #1722674
Depends-On: Ie320cf86a6d6d2bc810221e18f4be5e029c26df2
Change-Id: If1fb7d94cd28364c23efae4bb716e64ac6db93f4
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/95/514795/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/environments/default_libvirt.yml', 'quickstart.sh']",2,627b955b82243e631fddda988d0a7068f77f457e,bug/1722674,"DEFAULT_OPT_TAGS=""untagged,provision,environment,undercloud-scripts,overcloud-scripts,undercloud-install,undercloud-post-install,tripleoui-validate""","DEFAULT_OPT_TAGS=""untagged,provision,environment,undercloud-scripts,overcloud-scripts,undercloud-install,undercloud-post-install""",2,1
openstack%2Fcinder~master~If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb,openstack/cinder,master,If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb,"Convert filter_properties to OVO (create, retype)",ABANDONED,2015-12-14 12:14:41.000000000,2017-12-13 10:46:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16308}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17275}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18883}, {'_account_id': 19146}, {'_account_id': 19191}, {'_account_id': 19852}, {'_account_id': 19917}, {'_account_id': 19933}, {'_account_id': 20105}, {'_account_id': 20490}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22510}, {'_account_id': 22804}]","[{'number': 1, 'created': '2015-12-14 12:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3855180d05b9ab531b456261f7937a155d203bc7', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 2, 'created': '2015-12-14 12:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2ce775c8c7787e0680417c9399907d56999e1b3a', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 3, 'created': '2015-12-18 14:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21faafc6a45ea5916d700c6e38584e8340554fc1', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 4, 'created': '2015-12-22 13:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/36e96578f6e2395e6d1c0272e255e03e66fba003', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 5, 'created': '2015-12-22 16:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e28a292e558845fa03c8485e37845daa85cfeb7', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 6, 'created': '2015-12-28 10:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/50d01c06e329159aaab621638c36580119467b34', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 7, 'created': '2015-12-28 14:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ef1807916aed6b44f01ab8aac8ab506dee83699c', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 8, 'created': '2016-01-05 10:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e4663d1f24ffdca3be9fa7241293cf513d4313fb', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 9, 'created': '2016-01-11 20:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dd4be7b841f2974f5dd0212dd43cd8e1f953273c', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 10, 'created': '2016-01-12 10:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f4ecf9efcdafa60bf251115424513c941bf67965', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 11, 'created': '2016-01-12 10:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fdaf11b5da5f616943575aa64b9ba74a5f33e3c7', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 12, 'created': '2016-01-15 19:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2bbc26de0713f26f5c77750f1e369e88781154cd', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 13, 'created': '2016-01-15 19:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf386f45168349cbb1d90e08f0216424d1c9a132', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 14, 'created': '2016-01-21 09:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7607816c7dcb5aed3fc2fa0a7fa2463476476ff', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 15, 'created': '2016-01-29 14:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/af377037207e3f2b92f867e0e08bf7c91fc38bac', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 16, 'created': '2016-02-09 10:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22b0fe898e228f5a7af8ebf07824472dc2dc55a3', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 17, 'created': '2016-02-11 22:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/050da61af312696b5170a64e72c6c724d5834a70', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 18, 'created': '2016-02-16 13:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c45174f3b1cbef86d25db11652868a8ae45488ab', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 19, 'created': '2016-02-17 15:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7316eb1a67393071a746d82c3cf68b257009a841', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 20, 'created': '2016-04-19 14:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/08c563b94cc74a863847d2e177b09497ab8cdb2f', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 21, 'created': '2016-04-20 08:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1396c562a2e7ae941904b2300f1b71f63e7c037e', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 22, 'created': '2016-05-19 08:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0003fa29269b4206202d6fada59b76dece7ddef7', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 23, 'created': '2016-05-25 09:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/084874051623132b75578e7870796e73908417ba', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 24, 'created': '2016-05-25 11:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a57accfc7574f288bec78950243898d230d7eafc', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 25, 'created': '2016-06-01 14:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/af7f4dba0b4314400fd947299485c25b14afbb54', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 26, 'created': '2016-06-10 08:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/012d4c96b18a1f707170debb74aa256aa1a6d1df', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 27, 'created': '2016-06-10 10:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bc03634772c3732d47e99d43212d5c7b2f1e7031', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 28, 'created': '2016-06-13 14:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b93d19dc875b3464100b522c43c44f88d23025c2', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 29, 'created': '2016-06-15 08:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f85e217c397ee57bb82de6abfb7e48caa9d7b6b', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 30, 'created': '2016-06-17 13:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ee657464eb1a89b7a6091b55ed161bb262ed2c52', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 31, 'created': '2016-06-20 14:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/513463af92d514a0d013e15f4e4c40c259a3cdac', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 32, 'created': '2016-06-28 15:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c19b2a75977fe1ef804de97d3c4081c427d2dee7', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 33, 'created': '2016-07-04 17:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a0ca6708e534090680e2f7e970dd888048227c91', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 34, 'created': '2016-07-04 19:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9897e037ac5ba335b5913b36c5de4ca719cc47e2', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 35, 'created': '2016-07-07 10:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aa6d8e4982fa2ddbffc91de846359ae6dda00d71', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 36, 'created': '2016-07-08 09:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5a32b24b73c100ad510a28e2b33b55c74e3b654a', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 37, 'created': '2016-07-14 16:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/561f23964c36474d0bde3db6acb3b695292c9b39', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 38, 'created': '2016-07-15 08:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4108f495116580230eeb987a868a0fb647427385', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 39, 'created': '2016-07-15 15:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03414bcf528708119e88867793580f3085b5b2e6', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 40, 'created': '2016-07-18 12:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0fee1256e67f7cd4a3d2a1d078f38fb9956c9795', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 41, 'created': '2016-07-21 15:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/421eae328efd370a08e52a9198af14d9474bbaf2', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 42, 'created': '2016-07-28 11:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4594ea462583116979da3e418e5efdee0edbd103', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 43, 'created': '2016-08-01 19:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/37951cc5c8aa1827eae1e6b5a3f52dca45b3cdc5', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 44, 'created': '2016-08-01 23:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a10ffab566cff0d67f6b049305cc873aab861a8a', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 45, 'created': '2016-08-23 14:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/18a92a380e610e6805afb3134915f1505fb06d32', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 46, 'created': '2016-08-24 10:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce3172214aa55728b706b40acd5fdcf7e7ab0148', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 47, 'created': '2016-08-25 08:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fee12dc03f434dd96a2be3f1b5bb5a2938adf926', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}, {'number': 48, 'created': '2016-08-29 11:55:07.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/scheduler/rpcapi.py', 'cinder/volume/manager.py', 'cinder/tests/unit/objects/test_filter_properties.py', 'cinder/objects/base.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/objects/__init__.py', 'cinder/scheduler/manager.py', 'cinder/objects/fields.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/scheduler/test_filter_scheduler.py', 'cinder/objects/filter_properties.py', 'cinder/tests/unit/test_volume_rpcapi.py', 'tools/lintstack.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/scheduler/test_rpcapi.py', 'cinder/volume/rpcapi.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b6032d3a8391d32b112a18427e8d7c690ccf009', 'message': 'Convert filter_properties to OVO (create, retype)\n\nThis commit introduces FilterProperties object to formalize data\nearlier sent over RPC as undefined dict blob. This is required to be\nable to make non-backward compatible changes to data sent as this\nparameter while maintaining compatibility with previous release - so to\nsupport rolling upgrades.\n\nAs for now create and retype calls are converted. filter_properties\nparameter is used also in manage_existing, create_consistencygroup and\nmigrate_volume_to_host. These parameters are however currently unused,\nso we can convert them in a later time.\n\nPartial-Implements: blueprint cinder-objects\nChange-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb\n'}]",19,257305,1b6032d3a8391d32b112a18427e8d7c690ccf009,1185,73,48,11600,,,0,"Convert filter_properties to OVO (create, retype)

This commit introduces FilterProperties object to formalize data
earlier sent over RPC as undefined dict blob. This is required to be
able to make non-backward compatible changes to data sent as this
parameter while maintaining compatibility with previous release - so to
support rolling upgrades.

As for now create and retype calls are converted. filter_properties
parameter is used also in manage_existing, create_consistencygroup and
migrate_volume_to_host. These parameters are however currently unused,
so we can convert them in a later time.

Partial-Implements: blueprint cinder-objects
Change-Id: If04256ebadca9f2bf3b44698faf6ee1ba48d1bbb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/257305/21 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/scheduler/rpcapi.py', 'cinder/volume/manager.py', 'cinder/objects/base.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/objects/__init__.py', 'cinder/scheduler/manager.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/test_volume.py', 'cinder/tests/unit/scheduler/test_filter_scheduler.py', 'cinder/objects/filter_properties.py', 'cinder/tests/unit/test_volume_rpcapi.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/scheduler/test_rpcapi.py', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/volume/rpcapi.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/volume/api.py']",18,3855180d05b9ab531b456261f7937a155d203bc7,bp/cinder-objects," self.scheduler_rpcapi.retype( context, CONF.volume_topic, volume.id, request_spec=request_spec, filter_properties=objects.FilterProperties(), volume=volume)"," self.scheduler_rpcapi.retype(context, CONF.volume_topic, volume.id, request_spec=request_spec, filter_properties={}, volume=volume)",267,77
openstack%2Fcinder~master~I878ee0af19f07a36e201189133cb35876427bb2e,openstack/cinder,master,I878ee0af19f07a36e201189133cb35876427bb2e,Switch request_spec_list in create CG to OVO,ABANDONED,2015-12-03 15:52:46.000000000,2017-12-13 10:46:29.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 8871}, {'_account_id': 8912}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11803}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 12825}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14732}, {'_account_id': 14797}, {'_account_id': 14865}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16308}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17130}, {'_account_id': 17275}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18883}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19191}, {'_account_id': 19852}, {'_account_id': 19904}, {'_account_id': 19917}, {'_account_id': 19933}, {'_account_id': 20490}, {'_account_id': 20629}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22510}, {'_account_id': 22804}, {'_account_id': 22880}]","[{'number': 1, 'created': '2015-12-03 15:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e09c681bf57cf51a0e15ff059d666cd5d5b927ec', 'message': 'Switch request_spec_list in create CG to ovo\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 2, 'created': '2015-12-10 12:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2020a0823d1c469d2be42866964c43bb718c3f27', 'message': 'Switch request_spec_list in create CG to ovo\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 3, 'created': '2015-12-14 12:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/da0665a235f37cc7963002565418d556a448a35f', 'message': 'Switch request_spec_list in create CG to ovo\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 4, 'created': '2015-12-18 14:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/baee10552079ec968b863f49289e93691c91b27b', 'message': 'Switch request_spec_list in create CG to ovo\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 5, 'created': '2015-12-22 13:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c3d269be96d4153cadf5486d653793a0912d1e0f', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 6, 'created': '2015-12-22 16:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/45d4cf36984bae97e0a5f8e3b7ac3c11fdf1c1f5', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 7, 'created': '2015-12-28 14:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0446f502de603d1fcefb4f7c5164775c7f5c827', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 8, 'created': '2016-01-05 10:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bc8934f5c1ab15fa42925b01abe841f51b4a34ba', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 9, 'created': '2016-01-11 20:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/359a1b07268da6b2e13072488feecc1ddffaa5c9', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 10, 'created': '2016-01-12 10:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4602859368faf7b11dfacefb4821ee79a5292df4', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nImplements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 11, 'created': '2016-01-12 10:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71ef4950ace92552bc99af84d2538c4088cc5237', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 12, 'created': '2016-01-15 19:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/29fba95d18d3cb361a47b18fab487ef9d88ab0c7', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 13, 'created': '2016-01-21 09:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0a4ab4a1cceb503b4aed89ef8bc9cfbebb917d49', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 14, 'created': '2016-01-29 14:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c65e1cc573922bd11fa09ad4cee0f500bb7a84fb', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 15, 'created': '2016-02-09 10:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a880871ff844960343d5d4ed8c6a217d2c2975d7', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 16, 'created': '2016-02-11 22:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a6970a333f922ad4b46ef62799751bfc201977d4', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 17, 'created': '2016-02-16 13:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f4f4bb427d60246a3a2e387768e1cb89603aa04', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 18, 'created': '2016-02-17 15:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f72987778696deb1e42b728fe1b8232c86388486', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 19, 'created': '2016-04-19 14:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2abb7aaf0fcffc3deff76a483404ceadcce3b707', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 20, 'created': '2016-04-20 08:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3c8cf348a0b58b71027179c37f6476f775c79766', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 21, 'created': '2016-05-19 08:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f480356e58425f77fb37e20d8138ecce657036c2', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 22, 'created': '2016-05-25 09:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/514205d0fbe0f6b07d7df6eed9f6d68be2aa5c7f', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 23, 'created': '2016-05-25 11:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/57ccb2739a4f99913c8dcc8b69c52f80a6b79ea7', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 24, 'created': '2016-06-01 14:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b49e26911edac322ca64360426263a4e0a2e7aaf', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 25, 'created': '2016-06-10 08:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22534e7ee684c50628aec0c8404661aba73bde47', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 26, 'created': '2016-06-10 10:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e9d134c4b2e1339a0b2b35944e03d82e55d5ab9f', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 27, 'created': '2016-06-10 10:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a6f5f8c358ef5f1713a2ae82b47f74cd6489b692', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 28, 'created': '2016-06-13 14:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d54faed8182a1b28418c5f6b9f4b558d44276a1c', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 29, 'created': '2016-06-15 08:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b3b9e50aa3d4d653281fda6d6cd9ee70d1504575', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 30, 'created': '2016-06-17 13:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1eeed8cab35d025d8278b3c73cf34babcedaeabe', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 31, 'created': '2016-06-20 14:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2566938ae1753f4ac40dccf3aaf1bf3bcc1b1a2c', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 32, 'created': '2016-06-28 15:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4842b86f18bfb1896644457b2726d86bdace3fa3', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 33, 'created': '2016-07-04 17:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2addbc151c3a4ee55f1996b719cab9f77cd13fdd', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 34, 'created': '2016-07-04 19:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ad96cf509a72169a900ca39f1a61027611901ae8', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 35, 'created': '2016-07-07 10:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9685d749f01013bacbda94da33f57d57147ea400', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 36, 'created': '2016-07-08 09:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/85eaa947a4585f3718f9b64e641e2e912a31ffe4', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 37, 'created': '2016-07-14 16:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f0e2514224c31cc04de4381e3e5e80992cd9c0f', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 38, 'created': '2016-07-15 08:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/708bf921a80767ed4775532e3d4973f622730d3f', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 39, 'created': '2016-07-15 15:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3b4872d20d2fc703c4c766372f9a1af9720274d1', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 40, 'created': '2016-07-18 12:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e89de62e28103d029ccdbaf0372bef777c536c94', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 41, 'created': '2016-07-21 15:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ea9756d5fc2a9388fb019893cb25395d7277d2e', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 42, 'created': '2016-07-28 11:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8eac0cb7934f7646a6bee46495e2d1c078af690', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 43, 'created': '2016-08-01 19:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/95718c5a896710cba69de3be840db8a4ecd3d91e', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 44, 'created': '2016-08-01 23:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4d09f0b9f553a9f4dd5fb90493e71166d01d8af5', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 45, 'created': '2016-08-23 14:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b94aa693307a458b755dfb3da19f745d8d3f012c', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 46, 'created': '2016-08-24 10:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2cb39a8e6fc93af290ccdd5ab6d10f3294c62b2', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 47, 'created': '2016-08-25 08:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f51ea9fbf8842e7d50e3f5e290146aab2516e5f7', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}, {'number': 48, 'created': '2016-08-29 11:55:07.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/scheduler/rpcapi.py', 'cinder/objects/volume_type.py', 'cinder/scheduler/manager.py', 'cinder/consistencygroup/api.py', 'cinder/tests/unit/objects/test_volume_type.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bf58a92db9b8198ca5bc97f13764d10a7a67df12', 'message': 'Switch request_spec_list in create CG to OVO\n\nThis commit updates create_consistencygroup RPC call to use RequestSpec\nobject instead of passing list of undefined dict blobs. This is required\nto be able to do changes in request_spec structure while maintaining\nbackward compatibilty (and rolling upgrades).\n\nPartial-Implements: blueprint cinder-objects\n\nChange-Id: I878ee0af19f07a36e201189133cb35876427bb2e\n'}]",14,253033,bf58a92db9b8198ca5bc97f13764d10a7a67df12,1227,81,48,11600,,,0,"Switch request_spec_list in create CG to OVO

This commit updates create_consistencygroup RPC call to use RequestSpec
object instead of passing list of undefined dict blobs. This is required
to be able to do changes in request_spec structure while maintaining
backward compatibilty (and rolling upgrades).

Partial-Implements: blueprint cinder-objects

Change-Id: I878ee0af19f07a36e201189133cb35876427bb2e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/33/253033/7 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/scheduler/rpcapi.py', 'cinder/objects/volume_type.py', 'cinder/consistencygroup/api.py', 'cinder/scheduler/manager.py', 'cinder/tests/unit/objects/test_objects.py']",6,e09c681bf57cf51a0e15ff059d666cd5d5b927ec,bp/cinder-objects," 'VolumeTypeList': '1.0-d60f6ba0d142e86e3b880148228397ec',"," 'VolumeTypeList': '1.0-09b01f4526266c1a58cb206ba509d6d2',",65,60
openstack%2Freleases~master~I115e1adf78897b03bd35bd328ef469d4c9785c31,openstack/releases,master,I115e1adf78897b03bd35bd328ef469d4c9785c31,Release Murano 5.0.0.0b2,MERGED,2017-12-13 05:07:47.000000000,2017-12-13 10:41:09.000000000,2017-12-13 10:41:09.000000000,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 05:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/9a9e429613b9db8f6260340148ffe9e207c5dc0c', 'message': 'Release Murano 6.0.0.0b2\n\nChange-Id: I115e1adf78897b03bd35bd328ef469d4c9785c31\n'}, {'number': 2, 'created': '2017-12-13 05:10:06.000000000', 'files': ['deliverables/queens/murano.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/11b0b37bd1a0c86a9e6872286f4ebf59addd024a', 'message': 'Release Murano 5.0.0.0b2\n\nChange-Id: I115e1adf78897b03bd35bd328ef469d4c9785c31\n'}]",0,527574,11b0b37bd1a0c86a9e6872286f4ebf59addd024a,7,2,2,14107,,,0,"Release Murano 5.0.0.0b2

Change-Id: I115e1adf78897b03bd35bd328ef469d4c9785c31
",git fetch https://review.opendev.org/openstack/releases refs/changes/74/527574/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/murano.yaml'],1,9a9e429613b9db8f6260340148ffe9e207c5dc0c,, - version: 5.0.0.0b2 projects: - repo: openstack/murano hash: ac67e669a9010eff05e54b6a83e19e0431709a8a,,4,0
openstack%2Frequirements~master~Id77bcbbcf5d6bd4b7b47847fac4645d0d9133e4d,openstack/requirements,master,Id77bcbbcf5d6bd4b7b47847fac4645d0d9133e4d,Bump pifpaf version in u-c to 1.11.2,MERGED,2017-12-07 14:53:41.000000000,2017-12-13 10:41:08.000000000,2017-12-13 10:41:08.000000000,"[{'_account_id': 11105}, {'_account_id': 14288}, {'_account_id': 20523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 14:53:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e14dcbdd60249ea2ab546f2fff8816ce80fc2c93', 'message': 'Bump pifpaf version in u-c to 1.11.2\n\nChange-Id: Id77bcbbcf5d6bd4b7b47847fac4645d0d9133e4d\n'}]",0,526424,e14dcbdd60249ea2ab546f2fff8816ce80fc2c93,22,4,1,20523,,,0,"Bump pifpaf version in u-c to 1.11.2

Change-Id: Id77bcbbcf5d6bd4b7b47847fac4645d0d9133e4d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/24/526424/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e14dcbdd60249ea2ab546f2fff8816ce80fc2c93,bump_pifpaf,pifpaf===1.11.2,pifpaf===1.11.1,1,1
openstack%2Freleases~master~I8f869739356b9b5010dbc9457d36524877244f6c,openstack/releases,master,I8f869739356b9b5010dbc9457d36524877244f6c,Release Zaqar-UI Queens-2,MERGED,2017-12-12 03:08:19.000000000,2017-12-13 10:40:04.000000000,2017-12-13 10:40:04.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 03:08:19.000000000', 'files': ['deliverables/queens/zaqar-ui.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1f40405692fa555a138f9b9ed6ed65465d79954d', 'message': 'Release Zaqar-UI Queens-2\n\nChange-Id: I8f869739356b9b5010dbc9457d36524877244f6c\n'}]",0,527291,1f40405692fa555a138f9b9ed6ed65465d79954d,7,3,1,6484,,,0,"Release Zaqar-UI Queens-2

Change-Id: I8f869739356b9b5010dbc9457d36524877244f6c
",git fetch https://review.opendev.org/openstack/releases refs/changes/91/527291/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/zaqar-ui.yaml'],1,1f40405692fa555a138f9b9ed6ed65465d79954d,zaqar-ui-queens-2, - version: 4.0.0.0b2 projects: - repo: openstack/zaqar-ui hash: 2406e9e7e80bc2654767751c75155178c8269f74,,4,0
openstack%2Freleases~master~I5f842ddb32881ce15ea018186195f1856b3ffb52,openstack/releases,master,I5f842ddb32881ce15ea018186195f1856b3ffb52,Release Zaqar Queens-2,MERGED,2017-12-12 03:05:13.000000000,2017-12-13 10:40:01.000000000,2017-12-13 10:40:01.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 03:05:13.000000000', 'files': ['deliverables/queens/zaqar.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/9b65dbd12b82f4e249c586c9e2a2801df2dd1279', 'message': 'Release Zaqar Queens-2\n\nChange-Id: I5f842ddb32881ce15ea018186195f1856b3ffb52\n'}]",0,527290,9b65dbd12b82f4e249c586c9e2a2801df2dd1279,7,3,1,6484,,,0,"Release Zaqar Queens-2

Change-Id: I5f842ddb32881ce15ea018186195f1856b3ffb52
",git fetch https://review.opendev.org/openstack/releases refs/changes/90/527290/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/zaqar.yaml'],1,9b65dbd12b82f4e249c586c9e2a2801df2dd1279,zaqar-queens-2, - version: 6.0.0.0b2 projects: - repo: openstack/zaqar hash: 07a2a5b28811d3eb3e8649b9140d422053ddea2f,,4,0
openstack%2Frequirements~master~I349e53273a7f259443b7bacc6d83af796caafa8e,openstack/requirements,master,I349e53273a7f259443b7bacc6d83af796caafa8e,update constraint for oslo.service to new release 1.28.1,MERGED,2017-12-12 16:19:37.000000000,2017-12-13 10:36:35.000000000,2017-12-13 10:36:35.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 17130}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 16:19:37.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/01d356d868a8b95688cea83b0cd361dbc1a4bc22', 'message': 'update constraint for oslo.service to new release 1.28.1\n\nChange-Id: I349e53273a7f259443b7bacc6d83af796caafa8e\nmeta:version: 1.28.1\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,527451,01d356d868a8b95688cea83b0cd361dbc1a4bc22,9,4,1,11131,,,0,"update constraint for oslo.service to new release 1.28.1

Change-Id: I349e53273a7f259443b7bacc6d83af796caafa8e
meta:version: 1.28.1
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/51/527451/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,01d356d868a8b95688cea83b0cd361dbc1a4bc22,new-release,oslo.service===1.28.1,oslo.service===1.28.0,1,1
openstack%2Fopenstack-ansible-os_tempest~stable%2Fnewton~I44acb420155d3bc09b271a4b2fa92b488aae4c89,openstack/openstack-ansible-os_tempest,stable/newton,I44acb420155d3bc09b271a4b2fa92b488aae4c89,Fix tempest plugins installation,MERGED,2017-12-11 12:05:18.000000000,2017-12-13 10:18:12.000000000,2017-12-13 10:18:12.000000000,"[{'_account_id': 538}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-11 12:05:18.000000000', 'files': ['tasks/tempest_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/b116bebb91f95ed04f43b7f8eea4d07d6fa52149', 'message': 'Fix tempest plugins installation\n\nThe conditional was wrong, and therefore always skipped.\nWhen you have registered the output of with items, you get the\nwhole list in _registered_var.results.\n\nEach item is the result itself, and for convenience, ansible\nthrows in the original item under the dict ""item"".\n\nSo here original item\'s repo in the results should be in\n_registered_var.results[0].item.repo while the stat of the folder\nshould be in _registered_var.results[0].stat.<whatever>.\n\nReplace _registered_var.results[::] with item and you get your\nconditional. Magic!\n\nChange-Id: I44acb420155d3bc09b271a4b2fa92b488aae4c89\n(cherry picked from commit 9de4f4a9ba541fbe788cc00b315d44803231a626)\n'}]",0,527070,b116bebb91f95ed04f43b7f8eea4d07d6fa52149,8,4,1,6816,,,0,"Fix tempest plugins installation

The conditional was wrong, and therefore always skipped.
When you have registered the output of with items, you get the
whole list in _registered_var.results.

Each item is the result itself, and for convenience, ansible
throws in the original item under the dict ""item"".

So here original item's repo in the results should be in
_registered_var.results[0].item.repo while the stat of the folder
should be in _registered_var.results[0].stat.<whatever>.

Replace _registered_var.results[::] with item and you get your
conditional. Magic!

Change-Id: I44acb420155d3bc09b271a4b2fa92b488aae4c89
(cherry picked from commit 9de4f4a9ba541fbe788cc00b315d44803231a626)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/70/527070/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/tempest_install.yml'],1,b116bebb91f95ed04f43b7f8eea4d07d6fa52149,fix_tempest_plugins_instalation-stable/newton," - ""item.item.repo is defined""", - item.repo is defined,1,1
openstack%2Fnetworking-odl~master~I1a55014f0c3e94723c1e82a26007637dd76efe6c,openstack/networking-odl,master,I1a55014f0c3e94723c1e82a26007637dd76efe6c,Add a NOOP function.,MERGED,2017-12-07 19:05:53.000000000,2017-12-13 10:13:13.000000000,2017-12-13 10:13:13.000000000,"[{'_account_id': 333}, {'_account_id': 7921}, {'_account_id': 17120}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 19:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/33576c7b754bee7da1fd7e34d75194869ddcc479', 'message': 'Add a NOOP function.\n\ndevstack/lib/neutron has call to neutron_plugin_create_nova_conf,\nwhich in case of single node setup works fine, but in case of multinode\nwhere only compute node is set, stack.sh ends up in error.\n\n[log].\nhttp://logs.openstack.org/59/519759/3/check/networking-odl-tempest-nitrogen-multinode/b69474e/logs/subnode-2/devstacklog.txt.gz#_2017-12-04_18_08_17_040\n\nChange-Id: I1a55014f0c3e94723c1e82a26007637dd76efe6c\n'}, {'number': 2, 'created': '2017-12-07 22:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/40c4d8e9361e5a002341821860e02f80aa10a080', 'message': 'Add a NOOP function.\n\ndevstack/lib/neutron has call to neutron_plugin_create_nova_conf,\nwhich in case of single node setup works fine, but in case of multinode\nwhere only compute node is set, stack.sh ends up in error.\n\n[log].\nhttp://logs.openstack.org/59/519759/3/check/networking-odl-tempest-nitrogen-multinode/b69474e/logs/subnode-2/devstacklog.txt.gz#_2017-12-04_18_08_17_040\n\nChange-Id: I1a55014f0c3e94723c1e82a26007637dd76efe6c\n'}, {'number': 3, 'created': '2017-12-07 22:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/35847b748a31c20cb447b6c701978e126c90aa1b', 'message': 'Add a NOOP function.\n\ndevstack/lib/neutron has call to neutron_plugin_create_nova_conf,\nwhich in case of single node setup works fine, but in case of multinode\nwhere only compute node is set, stack.sh ends up in error.\n\n[log].\nhttp://logs.openstack.org/59/519759/3/check/networking-odl-tempest-nitrogen-multinode/b69474e/logs/subnode-2/devstacklog.txt.gz#_2017-12-04_18_08_17_040\n\nChange-Id: I1a55014f0c3e94723c1e82a26007637dd76efe6c\n'}, {'number': 4, 'created': '2017-12-08 00:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/452a8f6737ddb4fb98b3e51cfe45c6f6064febe0', 'message': 'Add a NOOP function.\n\ndevstack/lib/neutron has call to neutron_plugin_create_nova_conf,\nwhich in case of single node setup works fine, but in case of multinode\nwhere only compute node is set, stack.sh ends up in error.\n\n[log].\nhttp://logs.openstack.org/59/519759/3/check/networking-odl-tempest-nitrogen-multinode/b69474e/logs/subnode-2/devstacklog.txt.gz#_2017-12-04_18_08_17_040\n\nChange-Id: I1a55014f0c3e94723c1e82a26007637dd76efe6c\n'}, {'number': 5, 'created': '2017-12-12 16:06:38.000000000', 'files': ['devstack/functions'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/09bb871ed680deb1d6c90f64ffc640e08e51a622', 'message': 'Add a NOOP function.\n\ndevstack/lib/neutron has call to neutron_plugin_create_nova_conf,\nwhich in case of single node setup works fine, but in case of multinode\nwhere only compute node is set, stack.sh ends up in error.\n\n[log excerpt].\n/opt/stack/new/devstack/lib/neutron: line 314: neutron_plugin_create_nova_conf: command not found\n\nChange-Id: I1a55014f0c3e94723c1e82a26007637dd76efe6c\n'}]",4,526482,09bb871ed680deb1d6c90f64ffc640e08e51a622,23,4,5,17120,,,0,"Add a NOOP function.

devstack/lib/neutron has call to neutron_plugin_create_nova_conf,
which in case of single node setup works fine, but in case of multinode
where only compute node is set, stack.sh ends up in error.

[log excerpt].
/opt/stack/new/devstack/lib/neutron: line 314: neutron_plugin_create_nova_conf: command not found

Change-Id: I1a55014f0c3e94723c1e82a26007637dd76efe6c
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/82/526482/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack/functions'],1,33576c7b754bee7da1fd7e34d75194869ddcc479,, function neutron_plugin_create_nova_conf { : },,5,0
openstack%2Fnova~master~I7a0b59e2cb399d09b3c69038dce966ec47df6569,openstack/nova,master,I7a0b59e2cb399d09b3c69038dce966ec47df6569,Remove the unused request_id filter from api-paste.ini,MERGED,2017-12-06 09:17:52.000000000,2017-12-13 10:12:50.000000000,2017-12-13 06:17:55.000000000,"[{'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14107}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25747}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-12-06 09:17:52.000000000', 'files': ['etc/nova/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/45e5ac828372195929b25761681be8140fa906f7', 'message': 'Remove the unused request_id filter from api-paste.ini\n\nChange-Id: I7a0b59e2cb399d09b3c69038dce966ec47df6569\n'}]",1,526001,45e5ac828372195929b25761681be8140fa906f7,34,18,1,14107,,,0,"Remove the unused request_id filter from api-paste.ini

Change-Id: I7a0b59e2cb399d09b3c69038dce966ec47df6569
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/526001/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/api-paste.ini'],1,45e5ac828372195929b25761681be8140fa906f7,,,[filter:request_id] paste.filter_factory = oslo_middleware:RequestId.factory ,0,3
openstack%2Fcharm-glance~master~Id6198d534af95013af47c0c1292ac65c79470af4,openstack/charm-glance,master,Id6198d534af95013af47c0c1292ac65c79470af4,Restrict get_image_location policy to role:admin,MERGED,2017-06-22 16:58:04.000000000,2017-12-13 10:11:28.000000000,2017-12-13 10:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 2276}, {'_account_id': 2424}, {'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-06-22 16:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/25a88c1c42ba6dff2c66e522a5e666198b0f0194', 'message': 'Set ""get_image_location"" policy to role:admin when object-store is\nrelated.\n\nIf expose-image-locations is set to True and swift is related,\nwe update the glance policy ""get_image_location"" for hidding to direct_url\nfield which includes the swift user credentials for non-admin users.\n(LP: #1699565).\n\nCloses-Bug: #1699565\n\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\nSigned-off-by: Jorge Niedbalski <jorge.niedbalski@canonical.com>\n'}, {'number': 2, 'created': '2017-06-22 17:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/4683b5f4b7d73c10011e3a024b20bd08d4fe5256', 'message': 'Set ""get_image_location"" policy to role:admin when object-store is\nrelated.\n\nIf expose-image-locations is set to True and swift is related,\nwe update the glance policy ""get_image_location"" for hidding to direct_url\nfield which includes the swift user credentials for non-admin users.\n(LP: #1699565).\n\nCloses-Bug: #1699565\n\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\nSigned-off-by: Jorge Niedbalski <jorge.niedbalski@canonical.com>\n'}, {'number': 3, 'created': '2017-07-31 19:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/5eedc4f7203b26c69080f1755b4ac993c7105047', 'message': 'Set ""get_image_location"" policy to role:admin when object-store is\nrelated.\n\nIf expose-image-locations is set to True and swift is related,\nwe update the glance policy ""get_image_location"" for hidding to direct_url\nfield which includes the swift user credentials for non-admin users.\n(LP: #1699565).\n\nCloses-Bug: #1699565\n\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\nSigned-off-by: Jorge Niedbalski <jorge.niedbalski@canonical.com>\n'}, {'number': 4, 'created': '2017-12-08 12:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/5c30405df6136bc80f3f05b4d7f1e9fe74a44251', 'message': 'Restrict get_image_location policy to role:admin\n\nIf expose-image-locations is set to True and swift is related,\nwe update the glance policy ""get_image_location"" for hidding\nto direct_url field which includes the swift user credentials\nfor non-admin users.\n\nCloses-Bug: #1699565\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\n'}, {'number': 5, 'created': '2017-12-08 16:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/6b754eff7ed316f259693a636a0198dde12b25a9', 'message': 'Restrict get_image_location policy to role:admin\n\nThis patch will cause /etc/glance/policy.json to\nbe updated so that *_image_location rules are\nset to role:admin so that only admins can see\nthat info. On first update the original values are\nstored on the local kvstore in case they need to\nbe retrieved for later restoring or comparison.\n\nCloses-Bug: #1699565\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\n'}, {'number': 6, 'created': '2017-12-11 12:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/f323d4cc80244456c721c85a06e7f2fd3fcb582b', 'message': 'Restrict get_image_location policy to role:admin\n\nThis patch will cause /etc/glance/policy.json to\nbe updated so that *_image_location rules are\nset to role:admin so that only admins can see\nthat info. On first update the original values are\nstored on the local kvstore in case they need to\nbe retrieved for later restoring or comparison.\n\nCloses-Bug: #1699565\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\n'}, {'number': 7, 'created': '2017-12-11 16:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/d267076d9548d69f90d4d2dd90ca6448fdcdd615', 'message': 'Restrict get_image_location policy to role:admin\n\nThis patch will cause /etc/glance/policy.json to\nbe updated so that *_image_location rules are\nset to role:admin so that only admins can see\nthat info. On first update the original values are\nstored on the local kvstore in case they need to\nbe retrieved for later restoring or comparison.\n\nCloses-Bug: #1699565\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\n'}, {'number': 8, 'created': '2017-12-12 19:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/ff8383f82c63474fa836072b9b018572226660e8', 'message': 'Restrict get_image_location policy to role:admin\n\nThis patch will cause /etc/glance/policy.json to\nbe updated so that *_image_location rules are\nset to role:admin so that only admins can see\nthat info. On first update the original values are\nstored on the local kvstore in case they need to\nbe retrieved for later restoring or comparison.\n\nCloses-Bug: #1699565\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\n'}, {'number': 9, 'created': '2017-12-12 22:05:35.000000000', 'files': ['hooks/glance_utils.py', 'charmhelpers/contrib/openstack/utils.py', 'unit_tests/test_glance_relations.py', 'unit_tests/test_glance_utils.py', 'hooks/glance_relations.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/b95ad9c0230ca58281449465ce783374b84e2095', 'message': 'Restrict get_image_location policy to role:admin\n\nThis patch will cause /etc/glance/policy.json to\nbe updated so that *_image_location rules are\nset to role:admin so that only admins can see\nthat info. On first update the original values are\nstored on the local kvstore in case they need to\nbe retrieved for later restoring or comparison.\n\nCloses-Bug: #1699565\nChange-Id: Id6198d534af95013af47c0c1292ac65c79470af4\n'}]",8,476627,b95ad9c0230ca58281449465ce783374b84e2095,47,7,9,2276,,,0,"Restrict get_image_location policy to role:admin

This patch will cause /etc/glance/policy.json to
be updated so that *_image_location rules are
set to role:admin so that only admins can see
that info. On first update the original values are
stored on the local kvstore in case they need to
be retrieved for later restoring or comparison.

Closes-Bug: #1699565
Change-Id: Id6198d534af95013af47c0c1292ac65c79470af4
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/27/476627/9 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/glance_utils.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/fetch/__init__.py', 'tests/charmhelpers/__init__.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'tests/charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'unit_tests/test_glance_relations.py', 'charmhelpers/contrib/openstack/keystone.py', 'hooks/glance_relations.py', 'charmhelpers/core/host.py', 'unit_tests/test_utils.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/fetch/centos.py', 'charmhelpers/__init__.py']",19,25a88c1c42ba6dff2c66e522a5e666198b0f0194,bug/1699565,"from __future__ import print_function from __future__ import absolute_import import functools import inspect # Holds a list of mapping of mangled function names that have been deprecated # using the @deprecate decorator below. This is so that the warning is only # printed once for each usage of the function. __deprecated_functions = {} def deprecate(warning, date=None, log=None): """"""Add a deprecation warning the first time the function is used. The date, which is a string in semi-ISO8660 format indicate the year-month that the function is officially going to be removed. usage: @deprecate('use core/fetch/add_source() instead', '2017-04') def contributed_add_source_thing(...): ... And it then prints to the log ONCE that the function is deprecated. The reason for passing the logging function (log) is so that hookenv.log can be used for a charm if needed. :param warning: String to indicat where it has moved ot. :param date: optional sting, in YYYY-MM format to indicate when the function will definitely (probably) be removed. :param log: The log function to call to log. If not, logs to stdout """""" def wrap(f): @functools.wraps(f) def wrapped_f(*args, **kwargs): try: module = inspect.getmodule(f) file = inspect.getsourcefile(f) lines = inspect.getsourcelines(f) f_name = ""{}-{}-{}..{}-{}"".format( module.__name__, file, lines[0], lines[-1], f.__name__) except (IOError, TypeError): # assume it was local, so just use the name of the function f_name = f.__name__ if f_name not in __deprecated_functions: __deprecated_functions[f_name] = True s = ""DEPRECATION WARNING: Function {} is being removed"".format( f.__name__) if date: s = ""{} on/around {}"".format(s, date) if warning: s = ""{} : {}"".format(s, warning) if log: log(s) else: print(s) return f(*args, **kwargs) return wrapped_f return wrap",,730,277
openstack%2Fkolla~master~Iad404c2c888d2b3b8aed6497224e59f5049ba427,openstack/kolla,master,Iad404c2c888d2b3b8aed6497224e59f5049ba427,Add collectd-gnocchi plugin,MERGED,2017-12-11 10:08:39.000000000,2017-12-13 10:11:05.000000000,2017-12-13 10:11:05.000000000,"[{'_account_id': 1390}, {'_account_id': 4264}, {'_account_id': 5241}, {'_account_id': 11105}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-12-11 10:08:39.000000000', 'files': ['docker/collectd/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/14e774b84f52985df13337353d1b8841ff373dbc', 'message': 'Add collectd-gnocchi plugin\n\nin order to be able to use gnocchi as data store for collectd metrics.\n\nChange-Id: Iad404c2c888d2b3b8aed6497224e59f5049ba427\n'}]",0,527043,14e774b84f52985df13337353d1b8841ff373dbc,10,6,1,4264,,,0,"Add collectd-gnocchi plugin

in order to be able to use gnocchi as data store for collectd metrics.

Change-Id: Iad404c2c888d2b3b8aed6497224e59f5049ba427
",git fetch https://review.opendev.org/openstack/kolla refs/changes/43/527043/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/collectd/Dockerfile.j2'],1,14e774b84f52985df13337353d1b8841ff373dbc,collectd_gnocchi," 'collectd-virt', 'python-collectd-gnocchi'", 'collectd-virt',2,1
openstack%2Fopenstack-ansible-os_neutron~master~Iee55b6718d226a9095e5f4512e34159f68b18ddd,openstack/openstack-ansible-os_neutron,master,Iee55b6718d226a9095e5f4512e34159f68b18ddd,Include neutron plugins for neutron testing,ABANDONED,2017-12-11 15:27:46.000000000,2017-12-13 10:10:26.000000000,,"[{'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 15:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/81435fc553a52f88c7bdcad2f3e12989c15dbc5e', 'message': ""Include neutron plugins for neutron testing\n\nThis includes the neutron plugins for tempest, as these aren't\ndefined in the default tests repository (and they shouldn't,\nbecause then it would mean we may need to care of the override\norder, if any).\n\nChange-Id: Iee55b6718d226a9095e5f4512e34159f68b18ddd\n""}, {'number': 2, 'created': '2017-12-11 15:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/e4328dd038fc771dc63d4d2cdc24909f9f086a5d', 'message': ""Include neutron plugins for neutron testing\n\nThis includes the neutron plugins for tempest, as these aren't\ndefined in the default tests repository (and they shouldn't,\nbecause then it would mean we may need to care of the override\norder, if any).\n\nDepends-On: Ic15b9902e3b0b51040f3f32938b30a060c592e97\nChange-Id: Iee55b6718d226a9095e5f4512e34159f68b18ddd\n""}, {'number': 3, 'created': '2017-12-13 10:04:07.000000000', 'files': ['tests/neutron-overrides.yml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/9decb35621a6c535f986e1de2a97205883e266c1', 'message': ""Include neutron plugins for neutron testing\n\nThis includes the neutron plugins for tempest, as these aren't\ndefined in the default tests repository (and they shouldn't,\nbecause then it would mean we may need to care of the override\norder, if any).\n\nDepends-On: Ic15b9902e3b0b51040f3f32938b30a060c592e97\nChange-Id: Iee55b6718d226a9095e5f4512e34159f68b18ddd\n""}]",8,527127,9decb35621a6c535f986e1de2a97205883e266c1,11,3,3,17068,,,0,"Include neutron plugins for neutron testing

This includes the neutron plugins for tempest, as these aren't
defined in the default tests repository (and they shouldn't,
because then it would mean we may need to care of the override
order, if any).

Depends-On: Ic15b9902e3b0b51040f3f32938b30a060c592e97
Change-Id: Iee55b6718d226a9095e5f4512e34159f68b18ddd
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/27/527127/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/neutron-overrides.yml', 'tox.ini']",2,81435fc553a52f88c7bdcad2f3e12989c15dbc5e,fix_tempest, ANSIBLE_OVERRIDES={toxinidir}/tests/neutron-overrides.yml,,6,0
openstack%2Fovsdbapp~master~I8bed0513e71ee9af3a9b0ad07fd8a812169fd160,openstack/ovsdbapp,master,I8bed0513e71ee9af3a9b0ad07fd8a812169fd160,Display attempt number during transaction commit,MERGED,2017-12-07 22:57:27.000000000,2017-12-13 10:10:10.000000000,2017-12-13 10:10:10.000000000,"[{'_account_id': 8655}, {'_account_id': 20229}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 22:57:27.000000000', 'files': ['ovsdbapp/backend/ovs_idl/transaction.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/36a13474f6f734bc72a79ebcdde2d472c2c80234', 'message': 'Display attempt number during transaction commit\n\nChange-Id: I8bed0513e71ee9af3a9b0ad07fd8a812169fd160\n'}]",0,526537,36a13474f6f734bc72a79ebcdde2d472c2c80234,13,3,1,5756,,,0,"Display attempt number during transaction commit

Change-Id: I8bed0513e71ee9af3a9b0ad07fd8a812169fd160
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/37/526537/1 && git format-patch -1 --stdout FETCH_HEAD,['ovsdbapp/backend/ovs_idl/transaction.py'],1,36a13474f6f734bc72a79ebcdde2d472c2c80234,," LOG.debug(""Running txn n=%(n)d command(idx=%(idx)s): %(cmd)s"", {'idx': i, 'cmd': command, 'n': attempts})"," LOG.debug(""Running txn command(idx=%(idx)s): %(cmd)s"", {'idx': i, 'cmd': command})",2,2
openstack%2Fpython-watcherclient~master~I4275127e7f76ba6ad05f478278204c3de535cf5c,openstack/python-watcherclient,master,I4275127e7f76ba6ad05f478278204c3de535cf5c,Update audit_template create help message,MERGED,2017-11-24 03:20:55.000000000,2017-12-13 10:06:17.000000000,2017-12-13 10:06:17.000000000,"[{'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-24 03:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/1782e6fc4778d233f754ddae22fbdeb5b610e18f', 'message': 'bug fix:host-aggregate id error in watcher audittemplate create\nCloses-Bug: #1734056\n\nChange-Id: I4275127e7f76ba6ad05f478278204c3de535cf5c\n'}, {'number': 2, 'created': '2017-11-24 03:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/bed80ded0993b22c5871f22072b9257de5e93bc1', 'message': 'bug fix:host-aggregate id error in watcher audittemplate create\n\nCloses-Bug: #1734056\n\nChange-Id: I4275127e7f76ba6ad05f478278204c3de535cf5c\n'}, {'number': 3, 'created': '2017-11-28 02:07:11.000000000', 'files': ['watcherclient/v1/audit_template_shell.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/1a6703266fe8e1b4ea969b783f23a323c20547ec', 'message': ""Update audit_template create help message\n\n'id' should be an integer, not string.\nCloses-Bug: #1734056\nChange-Id: I4275127e7f76ba6ad05f478278204c3de535cf5c\n""}]",0,522694,1a6703266fe8e1b4ea969b783f23a323c20547ec,14,3,3,24872,,,0,"Update audit_template create help message

'id' should be an integer, not string.
Closes-Bug: #1734056
Change-Id: I4275127e7f76ba6ad05f478278204c3de535cf5c
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/94/522694/3 && git format-patch -1 --stdout FETCH_HEAD,['watcherclient/v1/audit_template_shell.py'],1,1782e6fc4778d233f754ddae22fbdeb5b610e18f,bug/1734056," "" {\""id\"": 1},\n"" "" {\""id\"": 2},\n"" "" {\""id\"": 3}]},\n"""," "" {\""id\"": \""1\""},\n"" "" {\""id\"": \""2\""},\n"" "" {\""id\"": \""3\""}]},\n""",3,3
openstack%2Fopenstack-ansible-os_glance~stable%2Fpike~I14f3162a4666d770beec9746469021466fa4d449,openstack/openstack-ansible-os_glance,stable/pike,I14f3162a4666d770beec9746469021466fa4d449,Fix systemd init template for program override,MERGED,2017-12-11 12:54:54.000000000,2017-12-13 10:01:40.000000000,2017-12-13 10:01:40.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 14805}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-11 12:54:54.000000000', 'files': ['templates/glance-systemd-init.j2', 'templates/glance-uwsgi.ini.j2', 'vars/redhat-7.yml', 'vars/suse-42.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/2caced40fb8de110590b46b27858f37255cb7f09', 'message': ""Fix systemd init template for program override\n\nThe systemd-init template was not looking at the program_override\nvariable within each service's dictionary.\n\nThis also fixes glance-api so that it's running under uWSGI when the v1\nAPI is disabled. Creating images from a remote URL is exclusive to the\nv1 API and does not work when glance-api is run under uWSGI.\n\nThe libxml2-dev package is required by uWSGI and has been added to the\ndistro package list.\n\nAdditional options have been added to the uWSGI configuration to better\nsupport requests containing chunked data (image uploads).\n\nChange-Id: I14f3162a4666d770beec9746469021466fa4d449\n(cherry picked from commit 43aa00424f233a6125f7a9216cec42da1d8ca4c5)\n""}]",0,527080,2caced40fb8de110590b46b27858f37255cb7f09,9,5,1,6816,,,0,"Fix systemd init template for program override

The systemd-init template was not looking at the program_override
variable within each service's dictionary.

This also fixes glance-api so that it's running under uWSGI when the v1
API is disabled. Creating images from a remote URL is exclusive to the
v1 API and does not work when glance-api is run under uWSGI.

The libxml2-dev package is required by uWSGI and has been added to the
distro package list.

Additional options have been added to the uWSGI configuration to better
support requests containing chunked data (image uploads).

Change-Id: I14f3162a4666d770beec9746469021466fa4d449
(cherry picked from commit 43aa00424f233a6125f7a9216cec42da1d8ca4c5)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/80/527080/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/glance-systemd-init.j2', 'templates/glance-uwsgi.ini.j2', 'vars/redhat-7.yml', 'vars/suse-42.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml']",6,2caced40fb8de110590b46b27858f37255cb7f09,fix-systemd-template-stable/pike," wsgi_app: ""{{ not glance_enable_v1_api }}"" log_string: ""{{ glance_enable_v1_api | ternary('--log-file=', '--logto ') }}"" program_override: >- {{ glance_enable_v1_api | ternary( glance_bin ~ '/glance-api', glance_bin ~ '/uwsgi --ini /etc/uwsgi/glance-api.ini') }}"," wsgi_app: True log_string: ""--logto "" program_override: ""{{ glance_bin }}/uwsgi --ini /etc/uwsgi/glance-api.ini""",20,10
openstack%2Fswift~master~I2f2fb519250172763abdc4b7ee5381e2f9dc084f,openstack/swift,master,I2f2fb519250172763abdc4b7ee5381e2f9dc084f,Symlink support in container-sync,ABANDONED,2017-01-18 05:08:30.000000000,2017-12-13 09:58:54.000000000,,"[{'_account_id': 3}, {'_account_id': 9625}, {'_account_id': 13052}, {'_account_id': 14766}]","[{'number': 1, 'created': '2017-01-18 05:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/57bb2eb87ba29d50259639aa420965e6a6165443', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 2, 'created': '2017-01-18 05:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2a19da33c05eb66db023252179c399a30b11b651', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 3, 'created': '2017-01-27 16:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7e3598b2fcf97b73a1802bf3ffa6e6265ed27c84', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nAlso may want to change how skiptest is determined for probetests.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 4, 'created': '2017-06-20 04:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d55858bb6596208fd5b87475d794897ff6d2e033', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nAlso may want to change how skiptest is determined for probetests.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 5, 'created': '2017-06-20 07:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/de3c5b26cc42fb72d8030f16f3a44e9dd3181332', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nAlso may want to change how skiptest is determined for probetests.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 6, 'created': '2017-06-20 08:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3e908794806645f438c1cf98059fa8e405caa2bf', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nAlso may want to change how skiptest is determined for probetests.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 7, 'created': '2017-06-20 08:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e6efc2e7afc128194f41d725ab46fbcf39e8e517', 'message': 'WIP: Symlink support in container-sync\n\nStill needs a test for cross-account symlinks and maybe some failure\ncases.\nAlso may want to change how skiptest is determined for probetests.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 8, 'created': '2017-06-20 10:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7398209cc01d1d7ca75076af8668a6d6f7e2cea3', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 9, 'created': '2017-06-21 07:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a554f5f00895867a9c6c0524e67cd1285bfe4f67', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 10, 'created': '2017-06-21 08:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/700cdc9bb55798b2ab967aebde456cc7cba64aeb', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 11, 'created': '2017-06-21 09:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e5ced74f67a2e67b5a397e613770584374d3db6e', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 12, 'created': '2017-06-22 11:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/802f6983f83f52ac0e756c95fb1c4019352b3ea7', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 13, 'created': '2017-06-23 01:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2b6695e2f06f6b14eef370a5fbfb5b421049af26', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}, {'number': 14, 'created': '2017-09-11 16:59:56.000000000', 'files': ['test/functional/test_symlink.py', 'swift/common/middleware/symlink.py', 'swift/container/sync.py', 'test/unit/common/test_internal_client.py', 'etc/internal-client.conf-sample', 'test/unit/container/test_sync.py', 'test/probe/test_container_sync.py', 'swift/common/internal_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3e42340cbd34b0092cb725dd90a04cd9e4171a48', 'message': 'Symlink support in container-sync\n\nThis patch fix container-sync behavior to sync symlinks itself,\nnot target objects.\n\nThis may be squashed into the symlink implementation patch at\nhttps://review.openstack.org/232162/ upon which this patch depends.\n\nChange-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f\n'}]",0,421669,3e42340cbd34b0092cb725dd90a04cd9e4171a48,47,4,14,12279,,,0,"Symlink support in container-sync

This patch fix container-sync behavior to sync symlinks itself,
not target objects.

This may be squashed into the symlink implementation patch at
https://review.openstack.org/232162/ upon which this patch depends.

Change-Id: I2f2fb519250172763abdc4b7ee5381e2f9dc084f
",git fetch https://review.opendev.org/openstack/swift refs/changes/69/421669/14 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/sync.py', 'swift/common/internal_client.py', 'test/probe/test_container_sync.py']",3,57bb2eb87ba29d50259639aa420965e6a6165443,symlink_cont_sync,"import time def test_sync_symlink(self): # Verify that symlinks are sync'd as symlinks. dest_account = self.account_2 source_container, dest_container = self._setup_synced_containers( dest_overrides=dest_account ) # Create source and dest containers for target objects in separate # accounts. # These containers must have same name for the destination symlink # to use the same target object. Initially the destination has no sync # key so target will not sync. tgt_container = 'targets-%s' % uuid.uuid4() dest_tgt_info = dict(dest_account) dest_tgt_info.update({'name': tgt_container, 'sync_key': None}) self._setup_synced_containers( source_overrides={'name': tgt_container, 'sync_key': 'tgt_key'}, dest_overrides=dest_tgt_info) # upload a target to source target_name = 'target-%s' % uuid.uuid4() target_body = 'target body' client.put_object( self.url, self.token, tgt_container, target_name, target_body) # Note that this tests when the target object is in the same account target_path = '/%s/%s' % (tgt_container, target_name) symlink_name = 'symlink-%s' % uuid.uuid4() put_headers = {'X-Symlink-Target': target_path} # upload the symlink client.put_object( self.url, self.token, source_container, symlink_name, '', headers=put_headers) # verify object is a symlink resp_headers, symlink_body = client.get_object( self.url, self.token, source_container, symlink_name, query_string='symlink=true') self.assertEqual('', symlink_body) self.assertIn('x-symlink-target', resp_headers) # verify symlink behavior resp_headers, actual_target_body = client.get_object( self.url, self.token, source_container, symlink_name) self.assertEqual(target_body, actual_target_body) # cycle container-sync Manager(['container-sync']).once() # verify symlink was sync'd resp_headers, dest_listing = client.get_container( dest_account['url'], dest_account['token'], dest_container) self.assertFalse(dest_listing[1:]) self.assertEqual(symlink_name, dest_listing[0]['name']) # verify symlink remained only a symlink resp_headers, body = client.get_object( dest_account['url'], dest_account['token'], dest_container, symlink_name, query_string='symlink=true') self.assertEqual('', symlink_body) self.assertIn('x-symlink-target', resp_headers) # attempt to GET the target object via symlink will fail because # the target wasn't sync'd with self.assertRaises(ClientException) as cm: client.get_object(dest_account['url'], dest_account['token'], dest_container, symlink_name) self.assertEqual(404, cm.exception.http_status) # now set sync key on destination target container client.put_container( dest_account['url'], dest_account['token'], tgt_container, headers={'X-Container-Sync-Key': 'tgt_key'}) # cycle container-sync Manager(['container-sync']).once() # sanity check - verify symlink remained only a symlink resp_headers, body = client.get_object( dest_account['url'], dest_account['token'], dest_container, symlink_name, query_string='symlink=true') self.assertEqual('', symlink_body) self.assertIn('x-symlink-target', resp_headers) # verify GET of target object via symlink now succeeds resp_headers, body = client.get_object( dest_account['url'], dest_account['token'], dest_container, symlink_name) self.assertEqual(target_body, body) ",,98,2
openstack%2Fqinling~master~Ie2f7572b61b0a88a488f8dcceea35e8d7c689abe,openstack/qinling,master,Ie2f7572b61b0a88a488f8dcceea35e8d7c689abe,Execution operations by admin user,MERGED,2017-12-13 09:04:52.000000000,2017-12-13 09:52:38.000000000,2017-12-13 09:52:38.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 09:04:52.000000000', 'files': ['qinling/api/controllers/v1/function.py', 'qinling_tempest_plugin/tests/api/test_executions.py', 'qinling/api/controllers/v1/execution.py', 'etc/policy.json.sample'], 'web_link': 'https://opendev.org/openstack/qinling/commit/e120058fbe150c523ecab31301f927195b8b172a', 'message': 'Execution operations by admin user\n\nPartially implements: blueprint qinling-admin-operations\nChange-Id: Ie2f7572b61b0a88a488f8dcceea35e8d7c689abe\n'}]",0,527636,e120058fbe150c523ecab31301f927195b8b172a,6,2,1,6732,,,0,"Execution operations by admin user

Partially implements: blueprint qinling-admin-operations
Change-Id: Ie2f7572b61b0a88a488f8dcceea35e8d7c689abe
",git fetch https://review.opendev.org/openstack/qinling refs/changes/36/527636/1 && git format-patch -1 --stdout FETCH_HEAD,"['qinling/api/controllers/v1/function.py', 'qinling_tempest_plugin/tests/api/test_executions.py', 'qinling/api/controllers/v1/execution.py', 'etc/policy.json.sample']",4,e120058fbe150c523ecab31301f927195b8b172a,bp/qinling-admin-operations," ""execution:get_all:all_projects"": ""rule:context_is_admin"",",,68,8
openstack%2Fmistral-tempest-plugin~master~I2ea70b228f3240ed89c3a3d4bd991459a6736f8c,openstack/mistral-tempest-plugin,master,I2ea70b228f3240ed89c3a3d4bd991459a6736f8c,Re-work the direct action call tempest test,MERGED,2017-12-13 09:26:42.000000000,2017-12-13 09:51:42.000000000,2017-12-13 09:51:42.000000000,"[{'_account_id': 9712}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 09:26:42.000000000', 'files': ['mistral_tempest_tests/tests/api/v2/test_action_executions.py'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/2b4471bf84eb858ab90569c60de3c2ebe3f56cc5', 'message': 'Re-work the direct action call tempest test\n\nThe current version calls the Mistral API, this seems to be unstable.\nUsing another std action is enough to validate that this works\ncorrectly.\n\nRelated-Bug: #1736685\nChange-Id: I2ea70b228f3240ed89c3a3d4bd991459a6736f8c\n(cherry picked from commit b291e502b27eaa5ffb4d5d971fe0f6aac8f3b866)\n'}]",0,527643,2b4471bf84eb858ab90569c60de3c2ebe3f56cc5,6,2,1,9712,,,0,"Re-work the direct action call tempest test

The current version calls the Mistral API, this seems to be unstable.
Using another std action is enough to validate that this works
correctly.

Related-Bug: #1736685
Change-Id: I2ea70b228f3240ed89c3a3d4bd991459a6736f8c
(cherry picked from commit b291e502b27eaa5ffb4d5d971fe0f6aac8f3b866)
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/43/527643/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral_tempest_tests/tests/api/v2/test_action_executions.py'],1,2b4471bf84eb858ab90569c60de3c2ebe3f56cc5,bug/1736685," def test_create_action_execution_sync(self): 'name': 'std.echo', 'input': '{""output"": ""Hello Tempest""}' self.assertEqual(""Hello Tempest"", output['result'])"," @decorators.skip_because(bug=""1736685"") def test_create_action_execution_sync(self): token = self.client.auth_provider.get_token() 'name': 'std.http', 'input': ('{{""url"": ""http://localhost:8989/v2/workflows"",' '""headers"": {{""X-Auth-Token"": ""{}""}}}}' ).format(token) self.assertEqual(200, output['result']['status'])",3,7
openstack%2Fkuryr-kubernetes~master~I735b08c481d9b7675fdd849de3d8d9c111bcad82,openstack/kuryr-kubernetes,master,I735b08c481d9b7675fdd849de3d8d9c111bcad82,Make some Tempest gates voting,MERGED,2017-12-12 10:13:36.000000000,2017-12-13 09:45:37.000000000,2017-12-13 09:45:37.000000000,"[{'_account_id': 6598}, {'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 21041}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 10:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9663628fd272925c31bbcaa931ec3ac649692e56', 'message': 'Make some Tempest gates voting\n\nThis commit makes following gates voting:\n* tempest-kuryr-kubernetes-lbaasv2\n* tempest-kuryr-kubernetes-lbaasv2-daemon\n* tempest-kuryr-kubernetes-octavia\n\nI was supposed to provide stability graphs from graphite.openstack.org,\nbut it looks like data from Zuul v3 is not put in there.\n\nChange-Id: I735b08c481d9b7675fdd849de3d8d9c111bcad82\nPartial-Implements: blueprint enhance-upstream-gates\n'}, {'number': 2, 'created': '2017-12-12 13:54:46.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/653ee56b3e7e954095df52bf0a81e9066c9c711f', 'message': 'Make some Tempest gates voting\n\nThis commit makes following gates voting:\n* tempest-kuryr-kubernetes-lbaasv2\n* tempest-kuryr-kubernetes-lbaasv2-daemon\n* tempest-kuryr-kubernetes-octavia\n\nI was supposed to provide stability graphs from graphite.openstack.org,\nbut it looks like data from Zuul v3 is not put in there.\n\nChange-Id: I735b08c481d9b7675fdd849de3d8d9c111bcad82\nPartial-Implements: blueprint enhance-upstream-gates\n'}]",3,527360,653ee56b3e7e954095df52bf0a81e9066c9c711f,16,5,2,11600,,,0,"Make some Tempest gates voting

This commit makes following gates voting:
* tempest-kuryr-kubernetes-lbaasv2
* tempest-kuryr-kubernetes-lbaasv2-daemon
* tempest-kuryr-kubernetes-octavia

I was supposed to provide stability graphs from graphite.openstack.org,
but it looks like data from Zuul v3 is not put in there.

Change-Id: I735b08c481d9b7675fdd849de3d8d9c111bcad82
Partial-Implements: blueprint enhance-upstream-gates
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/60/527360/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,9663628fd272925c31bbcaa931ec3ac649692e56,bp/enhance-upstream-gates, voting: true voting: true voting: true,,3,0
openstack%2Fkuryr-kubernetes~master~I0598109152cf353b0a23a225bb8f290da0069d96,openstack/kuryr-kubernetes,master,I0598109152cf353b0a23a225bb8f290da0069d96,Use K8s 1.8 with Hyperkube,MERGED,2017-12-05 08:51:23.000000000,2017-12-13 09:45:37.000000000,2017-12-13 09:45:37.000000000,"[{'_account_id': 6598}, {'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 26131}]","[{'number': 1, 'created': '2017-12-05 08:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/87479155ab68513104f2221eda569821794b812e', 'message': 'WiP: K8s 1.8 with hyperkube\n\nThis commit does necessary changes to allow using K8s 1.8 in our\nDevStack plugin. In particular:\n\n* Contents of setup-files.sh are copied into the DevStack plugin\n  directly.\n* Deprecated and removed --api-servers option of kubelet is replaced by\n  --kubeconfig=<path> --require-kubeconfig\n\nChange-Id: I0598109152cf353b0a23a225bb8f290da0069d96\n'}, {'number': 2, 'created': '2017-12-05 09:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2261acf69ac6af297a2e90731ed0363fab3dfcd4', 'message': 'WiP: K8s 1.8 with hyperkube\n\nThis commit does necessary changes to allow using K8s 1.8 in our\nDevStack plugin. In particular:\n\n* Contents of setup-files.sh are copied into the DevStack plugin\n  directly.\n* Deprecated and removed --api-servers option of kubelet is replaced by\n  --kubeconfig=<path> --require-kubeconfig\n\nChange-Id: I0598109152cf353b0a23a225bb8f290da0069d96\n'}, {'number': 3, 'created': '2017-12-11 21:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/4c8b3c973a9383048c12171ccc9d56b07569acbd', 'message': 'Use K8s 1.8 with Hyperkube\n\nThis commit does necessary changes to allow using K8s 1.8 in our\nDevStack plugin. In particular:\n\n* Contents of missing setup-files.sh are introduced into the DevStack\n  plugin directly.\n* Deprecated and removed `--api-servers` option of kubelet is\n  replaced by `--kubeconfig=<path> --require-kubeconfig`\n* Switches default value of KURYR_HYPERKUBE_VERSION to point to latest\n  1.8.\n\nIn long term we should probably move to kubeadm along with splitting the\nK8s DevStack plugin out of Kuryr repo. This is short term solution to\nusing ancient kubernetes version in upstream testing.\n\nCloses-Bug: 1734834\nChange-Id: I0598109152cf353b0a23a225bb8f290da0069d96\n'}, {'number': 4, 'created': '2017-12-11 21:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2273c810a1675930939fbaa275f65ce811243267', 'message': 'Use K8s 1.8 with Hyperkube\n\nThis commit does necessary changes to allow using K8s 1.8 in our\nDevStack plugin. In particular:\n\n* Contents of missing setup-files.sh are introduced into the DevStack\n  plugin directly.\n* Deprecated and removed `--api-servers` option of kubelet is\n  replaced by `--kubeconfig=<path> --require-kubeconfig`\n* Switches default value of KURYR_HYPERKUBE_VERSION to point to latest\n  1.8.\n\nIn long term we should probably move to kubeadm along with splitting the\nK8s DevStack plugin out of Kuryr repo. This is short term solution to\nusing ancient kubernetes version in upstream testing.\n\nCloses-Bug: 1734834\nChange-Id: I0598109152cf353b0a23a225bb8f290da0069d96\n'}, {'number': 5, 'created': '2017-12-12 09:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f052b812baa5efe2cbf653517847056a93a2a1e7', 'message': 'Use K8s 1.8 with Hyperkube\n\nThis commit does necessary changes to allow using K8s 1.8 in our\nDevStack plugin. In particular:\n\n* Contents of missing setup-files.sh are introduced into the DevStack\n  plugin directly.\n* Deprecated and removed `--api-servers` option of kubelet is\n  replaced by `--kubeconfig=<path> --require-kubeconfig`\n* Switches default value of KURYR_HYPERKUBE_VERSION to point to latest\n  1.8.\n\nIn long term we should probably move to kubeadm along with splitting the\nK8s DevStack plugin out of Kuryr repo. This is short term solution to\nusing ancient kubernetes version in upstream testing.\n\nCloses-Bug: 1734834\nChange-Id: I0598109152cf353b0a23a225bb8f290da0069d96\n'}, {'number': 6, 'created': '2017-12-12 09:35:48.000000000', 'files': ['devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/a93415b7bf66c9a1feabbf43443c072071c7a07a', 'message': 'Use K8s 1.8 with Hyperkube\n\nThis commit does necessary changes to allow using K8s 1.8 in our\nDevStack plugin. In particular:\n\n* Contents of missing setup-files.sh are introduced into the DevStack\n  plugin directly.\n* Deprecated and removed `--api-servers` option of kubelet is\n  replaced by `--kubeconfig=<path> --require-kubeconfig`\n* Switches default value of KURYR_HYPERKUBE_VERSION to point to latest\n  1.8.\n\nIn long term we should probably move to kubeadm along with splitting the\nK8s DevStack plugin out of Kuryr repo. This is short term solution to\nusing ancient kubernetes version in upstream testing.\n\nCloses-Bug: 1734834\nChange-Id: I0598109152cf353b0a23a225bb8f290da0069d96\n'}]",0,525502,a93415b7bf66c9a1feabbf43443c072071c7a07a,24,5,6,11600,,,0,"Use K8s 1.8 with Hyperkube

This commit does necessary changes to allow using K8s 1.8 in our
DevStack plugin. In particular:

* Contents of missing setup-files.sh are introduced into the DevStack
  plugin directly.
* Deprecated and removed `--api-servers` option of kubelet is
  replaced by `--kubeconfig=<path> --require-kubeconfig`
* Switches default value of KURYR_HYPERKUBE_VERSION to point to latest
  1.8.

In long term we should probably move to kubeadm along with splitting the
K8s DevStack plugin out of Kuryr repo. This is short term solution to
using ancient kubernetes version in upstream testing.

Closes-Bug: 1734834
Change-Id: I0598109152cf353b0a23a225bb8f290da0069d96
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/02/525502/6 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,87479155ab68513104f2221eda569821794b812e,bp/daemon-pool-port-choice,"function create_token() { echo $(cat /dev/urandom | base64 | tr -d ""=+/"" | dd bs=32 count=1 2> /dev/null) } # TODO(dulek): That's a hacky way of getting the script. curl -o /tmp/make-ca-cert.sh https://raw.githubusercontent.com/kubernetes/kubernetes/release-1.8/cluster/saltbase/salt/generate-cert/make-ca-cert.sh chmod +x /tmp/make-ca-cert.sh # Create HTTPS certificates sudo groupadd -f -r kube-cert # hostname -I gets the ip of the node sudo CERT_DIR=${KURYR_HYPERKUBE_DATA_DIR} /tmp/make-ca-cert.sh $(hostname -I | awk '{print $1}') ""IP:${HOST_IP},IP:${k8s_api_clusterip},DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc,DNS:kubernetes.default.svc.cluster.local"" # Create basic token authorization echo ""admin,admin,admin"" > ${KURYR_HYPERKUBE_DATA_DIR}/basic_auth.csv # Create known tokens for service accounts echo ""$(create_token),admin,admin"" >> ${KURYR_HYPERKUBE_DATA_DIR}/known_tokens.csv echo ""$(create_token),kubelet,kubelet"" >> ${KURYR_HYPERKUBE_DATA_DIR}/known_tokens.csv echo ""$(create_token),kube_proxy,kube_proxy"" >> ${KURYR_HYPERKUBE_DATA_DIR}/known_tokens.csv # TODO(dulek): /opt/stack/.kube/config should be taken from an env var. --kubeconfig=/opt/stack/.kube/config --require-kubeconfig"," local mountpoint mountpoint=$(get_hyperkube_container_cacert_setup_dir ""$KURYR_HYPERKUBE_VERSION"") docker run \ --name devstack-k8s-setup-files \ --detach \ --volume ""${KURYR_HYPERKUBE_DATA_DIR}:${mountpoint}:rw"" \ ""${KURYR_HYPERKUBE_IMAGE}:${KURYR_HYPERKUBE_VERSION}"" \ /setup-files.sh \ ""IP:${HOST_IP},IP:${k8s_api_clusterip},DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc,DNS:kubernetes.default.svc.cluster.local"" --api-servers=$KURYR_K8S_API_URL \ docker kill devstack-k8s-setup-files docker rm devstack-k8s-setup-files",23,12
openstack%2Fmistral-tempest-plugin~master~Icfa134d391476cad6ef925c84e93754d8a625ef2,openstack/mistral-tempest-plugin,master,Icfa134d391476cad6ef925c84e93754d8a625ef2,Disable unstable tempest test_create_action_execution_sync test,MERGED,2017-12-13 09:26:42.000000000,2017-12-13 09:45:34.000000000,2017-12-13 09:45:34.000000000,"[{'_account_id': 9712}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 09:26:42.000000000', 'files': ['mistral_tempest_tests/tests/api/v2/test_action_executions.py'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/0dc7e574b32d8898cd3196484dd0035100b4bc77', 'message': 'Disable unstable tempest test_create_action_execution_sync test\n\nThis disables test_create_action_execution_sync.\nDoing so allows us to mvoe towards a voting tempest job. We need to come\nback and fix or replace this test later.\n\nRelated-Bug: #1736685\nChange-Id: Icfa134d391476cad6ef925c84e93754d8a625ef2\n(cherry picked from commit d53c1a983454777f8bee16806a1331bb0bd5c1cb)\n'}]",0,527642,0dc7e574b32d8898cd3196484dd0035100b4bc77,6,2,1,9712,,,0,"Disable unstable tempest test_create_action_execution_sync test

This disables test_create_action_execution_sync.
Doing so allows us to mvoe towards a voting tempest job. We need to come
back and fix or replace this test later.

Related-Bug: #1736685
Change-Id: Icfa134d391476cad6ef925c84e93754d8a625ef2
(cherry picked from commit d53c1a983454777f8bee16806a1331bb0bd5c1cb)
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/42/527642/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral_tempest_tests/tests/api/v2/test_action_executions.py'],1,0dc7e574b32d8898cd3196484dd0035100b4bc77,bug/1736685," @decorators.skip_because(bug=""1736685"")",,1,0
openstack%2Fmistral-tempest-plugin~master~Ie6a9e67837fb8c6386f915209ecf11974ab052c6,openstack/mistral-tempest-plugin,master,Ie6a9e67837fb8c6386f915209ecf11974ab052c6,Disable unstable tempest multi_vim_authentication test,MERGED,2017-12-13 09:26:42.000000000,2017-12-13 09:45:34.000000000,2017-12-13 09:45:34.000000000,"[{'_account_id': 9712}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 09:26:42.000000000', 'files': ['mistral_tempest_tests/tests/scenario/engine/actions/v2/test_multi_vim_authentication.py'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/955327c231ba9e837b10abb3fae5b991e66cda2d', 'message': 'Disable unstable tempest multi_vim_authentication test\n\nThis disables test_multi_vim_support_target_headers_and_service_catalog.\nDoing so allows us to mvoe towards a voting tempest job. We need to come\nback and fix or replace this test later.\n\nRelated-Bug: #1736685\nChange-Id: Ie6a9e67837fb8c6386f915209ecf11974ab052c6\n(cherry picked from commit cd37173c8c1134155e9218b67e4a68c56e79d77c)\n'}]",0,527641,955327c231ba9e837b10abb3fae5b991e66cda2d,6,2,1,9712,,,0,"Disable unstable tempest multi_vim_authentication test

This disables test_multi_vim_support_target_headers_and_service_catalog.
Doing so allows us to mvoe towards a voting tempest job. We need to come
back and fix or replace this test later.

Related-Bug: #1736685
Change-Id: Ie6a9e67837fb8c6386f915209ecf11974ab052c6
(cherry picked from commit cd37173c8c1134155e9218b67e4a68c56e79d77c)
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/41/527641/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral_tempest_tests/tests/scenario/engine/actions/v2/test_multi_vim_authentication.py'],1,955327c231ba9e837b10abb3fae5b991e66cda2d,bug/1736685," @decorators.skip_because(bug=""1736685"")",,1,0
openstack%2Fmistral-tempest-plugin~master~Ie18493c8f59f5d77107f0adf5db491b0db05cee2,openstack/mistral-tempest-plugin,master,Ie18493c8f59f5d77107f0adf5db491b0db05cee2,Allow filtering executions by their root_execution_id,MERGED,2017-12-13 09:25:24.000000000,2017-12-13 09:45:33.000000000,2017-12-13 09:45:33.000000000,"[{'_account_id': 9712}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 09:25:24.000000000', 'files': ['mistral_tempest_tests/tests/api/v2/test_executions.py', 'mistral_tempest_tests/tests/resources/wf_v2.yaml', 'mistral_tempest_tests/tests/api/v2/test_action_executions.py'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/7963809930538c5a4c68a78f6772ab1c28853833', 'message': 'Allow filtering executions by their root_execution_id\n\nWith this filter, it will be possible to find all the workflow\nexecutions started by a root execution.\n\nImplements: blueprint mistral-root-execution-id\nChange-Id: Ie18493c8f59f5d77107f0adf5db491b0db05cee2\n(cherry picked from commit 28130bb862b33c57f5513fbe139eee3e4444fdac)\n'}]",0,527640,7963809930538c5a4c68a78f6772ab1c28853833,6,2,1,9712,,,0,"Allow filtering executions by their root_execution_id

With this filter, it will be possible to find all the workflow
executions started by a root execution.

Implements: blueprint mistral-root-execution-id
Change-Id: Ie18493c8f59f5d77107f0adf5db491b0db05cee2
(cherry picked from commit 28130bb862b33c57f5513fbe139eee3e4444fdac)
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/40/527640/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral_tempest_tests/tests/api/v2/test_executions.py', 'mistral_tempest_tests/tests/resources/wf_v2.yaml', 'mistral_tempest_tests/tests/api/v2/test_action_executions.py']",3,7963809930538c5a4c68a78f6772ab1c28853833,bp/mistral-root-execution-id," wf_name = ""wf"" resp, execution = self.client.create_execution( self.client.wait_execution_success(execution)"," wf_name = body['workflows'][0]['name'] resp, body = self.client.create_execution(",46,2
openstack%2Fmonasca-api~stable%2Fpike~Ib093ed2c72b430d5f09511c4515d0d9dc2a63c5b,openstack/monasca-api,stable/pike,Ib093ed2c72b430d5f09511c4515d0d9dc2a63c5b,Use stable/pike branch in devstack,MERGED,2017-12-11 16:04:21.000000000,2017-12-13 09:42:54.000000000,2017-12-13 09:42:54.000000000,"[{'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-12-11 16:04:21.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/ae241dcd42b9fa8473736d5ffa06e31af8e4ce19', 'message': 'Use stable/pike branch in devstack\n\nChange-Id: Ib093ed2c72b430d5f09511c4515d0d9dc2a63c5b\n'}]",0,527141,ae241dcd42b9fa8473736d5ffa06e31af8e4ce19,7,3,1,16222,,,0,"Use stable/pike branch in devstack

Change-Id: Ib093ed2c72b430d5f09511c4515d0d9dc2a63c5b
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/41/527141/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,ae241dcd42b9fa8473736d5ffa06e31af8e4ce19,,MONASCA_API_BRANCH=${MONASCA_API_BRANCH:-stable/pike}MONASCA_PERSISTER_BRANCH=${MONASCA_PERSISTER_BRANCH:-stable/pike}MONASCA_NOTIFICATION_BRANCH=${MONASCA_NOTIFICATION_BRANCH:-stable/pike}MONASCA_THRESH_BRANCH=${MONASCA_THRESH_BRANCH:-stable/pike}MONASCA_CLIENT_BRANCH=${MONASCA_CLIENT_BRANCH:-stable/pike}MONASCA_AGENT_BRANCH=${MONASCA_AGENT_BRANCH:-stable/pike}MONASCA_UI_BRANCH=${MONASCA_UI_BRANCH:-stable/pike}MONASCA_COMMON_BRANCH=${MONASCA_COMMON_BRANCH:-stable/pike}MONASCA_STATSD_BRANCH=${MONASCA_STATSD_BRANCH:-stable/pike},MONASCA_API_BRANCH=${MONASCA_API_BRANCH:-master}MONASCA_PERSISTER_BRANCH=${MONASCA_PERSISTER_BRANCH:-master}MONASCA_NOTIFICATION_BRANCH=${MONASCA_NOTIFICATION_BRANCH:-master}MONASCA_THRESH_BRANCH=${MONASCA_THRESH_BRANCH:-master}MONASCA_CLIENT_BRANCH=${MONASCA_CLIENT_BRANCH:-master}MONASCA_AGENT_BRANCH=${MONASCA_AGENT_BRANCH:-master}MONASCA_UI_BRANCH=${MONASCA_UI_BRANCH:-master}MONASCA_COMMON_BRANCH=${MONASCA_COMMON_BRANCH:-master}MONASCA_STATSD_BRANCH=${MONASCA_STATSD_BRANCH:-master},9,9
openstack%2Fcharms.ceph~master~Ib7f9f59d157edbd223e848e7e2fde2e27556f079,openstack/charms.ceph,master,Ib7f9f59d157edbd223e848e7e2fde2e27556f079,Add unit tests to cover permissions requests,MERGED,2017-12-12 15:53:30.000000000,2017-12-13 09:42:11.000000000,2017-12-13 09:42:10.000000000,"[{'_account_id': 20634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 15:53:30.000000000', 'files': ['ceph/broker.py', 'unit_tests/test_broker.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/6ea5e98786cf144d2bb92c0edebcfa10bb938e6a', 'message': 'Add unit tests to cover permissions requests\n\nAdd unit tests to increase coverage of permissions requests from\nbroker. This is a prerequisite for work to add object prefix\npermissions.\n\nSort permissions list to ensure permissions string does keep changing\nwhen running under py3.\n\nChange-Id: Ib7f9f59d157edbd223e848e7e2fde2e27556f079\n'}]",0,527442,6ea5e98786cf144d2bb92c0edebcfa10bb938e6a,6,2,1,12549,,,0,"Add unit tests to cover permissions requests

Add unit tests to increase coverage of permissions requests from
broker. This is a prerequisite for work to add object prefix
permissions.

Sort permissions list to ensure permissions string does keep changing
when running under py3.

Change-Id: Ib7f9f59d157edbd223e848e7e2fde2e27556f079
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/42/527442/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph/broker.py', 'unit_tests/test_broker.py']",2,6ea5e98786cf144d2bb92c0edebcfa10bb938e6a,ceph-unit-tests," def test_pool_permission_list_for_service_multi(self): service = { 'group_names': {'rwx': ['images', 'group1'], 'r': ['group2']}, 'groups': { 'images': { 'pools': ['glance'], 'services': ['nova']}, 'group1': { 'pools': ['p1'], 'services': ['svc1']}, 'group2': { 'pools': ['p2'], 'services': ['svc2']}} } result = ceph.broker.pool_permission_list_for_service(service) self.assertEqual( result, [ 'mon', 'allow r', 'osd', 'allow r pool=p2, allow rwx pool=glance, allow rwx pool=p1']) @patch.object(ceph.broker, 'handle_add_permissions_to_key') @patch.object(ceph.broker, 'log') def test_process_requests_add_perms(self, mock_log, mock_handle_add_permissions_to_key): request = { ""api-version"": 1, ""request-id"": ""0155c14b"", ""ops"": [ { ""namespace"": None, ""group-permission"": ""rwx"", ""group"": ""images"", ""name"": ""glance"", ""op"": ""add-permissions-to-key"" } ] } reqs = json.dumps(request) rc = ceph.broker.process_requests(reqs) mock_handle_add_permissions_to_key.assert_called_once_with( request={ u'namespace': None, u'group-permission': u'rwx', u'group': u'images', u'name': u'glance', u'op': u'add-permissions-to-key'}, service='admin') self.assertEqual( json.loads(rc), {'exit-code': 0, u'request-id': u'0155c14b'}) @patch.object(ceph.broker, 'handle_add_permissions_to_key') @patch.object(ceph.broker, 'log') def test_process_requests_add_multi_perms(self, mock_log, mock_handle_add_perms_to_key): request = { ""api-version"": 1, ""request-id"": ""0155c14b"", ""ops"": [ { ""namespace"": None, ""group-permission"": ""rwx"", ""group"": ""images"", ""name"": ""glance"", ""op"": ""add-permissions-to-key"" }, { ""namespace"": None, ""group-permission"": ""r"", ""group"": ""volumes"", ""name"": ""cinder"", ""op"": ""add-permissions-to-key"" } ] } reqs = json.dumps(request) rc = ceph.broker.process_requests(reqs) call1 = call( request={ u'namespace': None, u'group-permission': u'rwx', u'group': u'images', u'name': u'glance', u'op': u'add-permissions-to-key'}, service='admin') call2 = call( request={ u'namespace': None, u'group-permission': u'r', u'group': u'volumes', u'name': u'cinder', u'op': u'add-permissions-to-key'}, service='admin') mock_handle_add_perms_to_key.assert_has_calls([call1, call2]) self.assertEqual( json.loads(rc), {'exit-code': 0, u'request-id': u'0155c14b'}) @patch.object(ceph.broker, 'save_service') @patch.object(ceph.broker, 'save_group') @patch.object(ceph.broker, 'monitor_key_get') @patch.object(ceph.broker, 'update_service_permissions') def test_handle_add_permissions_to_key(self, mock_update_service_permissions, mock_monitor_key_get, mock_save_group, mock_save_service): mkey = { 'cephx.services.glance': ('{""groups"": {}, ' '""group_names"": {""rwx"": [""images""]}}'), 'cephx.groups.images': ('{""services"": [""glance"", ""cinder-ceph"", ' '""nova-compute""], ""pools"": [""glance""]}')} mock_monitor_key_get.side_effect = lambda service, key: mkey[key] expect_service_name = u'glance' expected_group = { u'services': [ u'glance', u'cinder-ceph', u'nova-compute'], u'pools': [u'glance']} expect_service_obj = { u'groups': { u'images': expected_group}, u'group_names': { u'rwx': [u'images']}} expect_group_namespace = None ceph.broker.handle_add_permissions_to_key( request={ u'namespace': None, u'group-permission': u'rwx', u'group': u'images', u'name': u'glance', u'op': u'add-permissions-to-key'}, service='admin') mock_save_group.assert_called_once_with( group=expected_group, group_name='images') mock_save_service.assert_called_once_with( service=expect_service_obj, service_name=expect_service_name) mock_update_service_permissions.assert_called_once_with( expect_service_name, expect_service_obj, expect_group_namespace)",,149,1
openstack%2Fmurano-tempest-plugin~master~I506516c7f127a21d0445d6ac09b4b504d9d19cf6,openstack/murano-tempest-plugin,master,I506516c7f127a21d0445d6ac09b4b504d9d19cf6,Add requests to requirements,MERGED,2017-12-11 10:25:17.000000000,2017-12-13 09:39:09.000000000,2017-12-13 09:39:09.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 10:25:17.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano-tempest-plugin/commit/57c9512a5ce90fa8b2663fe9c89924e3809dc15d', 'message': 'Add requests to requirements\n\nChange-Id: I506516c7f127a21d0445d6ac09b4b504d9d19cf6\n'}]",0,527052,57c9512a5ce90fa8b2663fe9c89924e3809dc15d,6,2,1,14107,,,0,"Add requests to requirements

Change-Id: I506516c7f127a21d0445d6ac09b4b504d9d19cf6
",git fetch https://review.opendev.org/openstack/murano-tempest-plugin refs/changes/52/527052/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,57c9512a5ce90fa8b2663fe9c89924e3809dc15d,,requests>=2.14.2 # Apache-2.0,,1,0
openstack%2Fneutron-tempest-plugin~master~I9c2eadf1dc86cb60190fb22393a02ffa02770620,openstack/neutron-tempest-plugin,master,I9c2eadf1dc86cb60190fb22393a02ffa02770620,Tests for DNS integration,ABANDONED,2017-11-15 22:54:26.000000000,2017-12-13 09:36:06.000000000,,"[{'_account_id': 4694}, {'_account_id': 8655}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-15 22:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/c460af2a44e4063231f6842f5c70a891f28ea9fd', 'message': 'Tests for DNS integration\n\nAdd test coverage for the integration with designate, confirming that\nthe correct DNS records are generated for\n\n- floating IP created with dns_(domain|name) attributes\n- instances that have a floating IP assigned\n\nDepends-On: Ib380d8a98e991a475b20140f5c37e3747aa5fc0c\nChange-Id: I9c2eadf1dc86cb60190fb22393a02ffa02770620\n'}, {'number': 2, 'created': '2017-11-21 10:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/c516793c7d5e8fbc88a5bfa54fbd5e52ecfe03f3', 'message': 'Tests for DNS integration\n\nAdd test coverage for the integration with designate, confirming that\nthe correct DNS records are generated for\n\n- floating IP created with dns_(domain|name) attributes\n- instances that have a floating IP assigned\n\nDepends-On: Ib380d8a98e991a475b20140f5c37e3747aa5fc0c\nChange-Id: I9c2eadf1dc86cb60190fb22393a02ffa02770620\n'}, {'number': 3, 'created': '2017-11-22 07:52:45.000000000', 'files': ['neutron_tempest_plugin/api/base.py', 'neutron_tempest_plugin/scenario/test_dns_integration.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/8f88d358292ac2c0dd59e435954e92cdcf0556c4', 'message': 'Tests for DNS integration\n\nAdd test coverage for the integration with designate, confirming that\nthe correct DNS records are generated for\n\n- floating IP created with dns_(domain|name) attributes\n- instances that have a floating IP assigned\n\nDepends-On: Ib380d8a98e991a475b20140f5c37e3747aa5fc0c\nChange-Id: I9c2eadf1dc86cb60190fb22393a02ffa02770620\n'}]",0,520237,8f88d358292ac2c0dd59e435954e92cdcf0556c4,10,4,3,13252,,,0,"Tests for DNS integration

Add test coverage for the integration with designate, confirming that
the correct DNS records are generated for

- floating IP created with dns_(domain|name) attributes
- instances that have a floating IP assigned

Depends-On: Ib380d8a98e991a475b20140f5c37e3747aa5fc0c
Change-Id: I9c2eadf1dc86cb60190fb22393a02ffa02770620
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/37/520237/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_tempest_plugin/api/base.py', 'neutron_tempest_plugin/scenario/test_dns_integration.py']",2,c460af2a44e4063231f6842f5c70a891f28ea9fd,dns-int,"# Copyright (c) 2017 x-ion GmbH # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import ipaddress import testtools from tempest.common import utils from tempest.common import waiters from tempest.lib.common.utils import data_utils from tempest.lib import decorators from tempest.lib import exceptions as lib_exc from neutron_tempest_plugin import config from neutron_tempest_plugin.scenario import base from neutron_tempest_plugin.scenario import constants CONF = config.CONF # Note(jh): Need to do a bit of juggling here in order to avoid failures # when designate_tempest_plugin is not available dns_base = testtools.try_import('designate_tempest_plugin.tests.base') dns_waiters = testtools.try_import('designate_tempest_plugin.common.waiters') if dns_base: DNSMixin = dns_base.BaseDnsV2Test else: DNSMixin = object class DNSIntegrationTests(base.BaseTempestTestCase, DNSMixin): credentials = ['primary'] @classmethod def setup_clients(cls): super(DNSIntegrationTests, cls).setup_clients() cls.dns_client = cls.os_tempest.zones_client cls.query_client = cls.os_tempest.query_client cls.query_client.build_timeout = 30 @classmethod def skip_checks(cls): super(DNSIntegrationTests, cls).skip_checks() if not ('designate' in CONF.service_available and CONF.service_available.designate): raise cls.skipException(""Designate support is required"") if not (dns_base and dns_waiters): raise cls.skipException(""Designate tempest plugin is missing"") @classmethod @utils.requires_ext(extension=""dns-integration"", service=""network"") def resource_setup(cls): super(DNSIntegrationTests, cls).resource_setup() _, cls.zone = cls.dns_client.create_zone() cls.addClassResourceCleanup(cls.dns_client.delete_zone, cls.zone['id'], ignore_errors=lib_exc.NotFound) dns_waiters.wait_for_zone_status( cls.dns_client, cls.zone['id'], 'ACTIVE') cls.network = cls.create_network(dns_domain=cls.zone['name']) cls.subnet = cls.create_subnet(cls.network) cls.router = cls.create_router_by_client() cls.create_router_interface(cls.router['id'], cls.subnet['id']) cls.keypair = cls.create_keypair() def _create_floatingip_with_dns(self, dns_name): fip = self.os_primary.network_client.create_floatingip( CONF.network.public_network_id, dns_name=dns_name, dns_domain=self.zone['name'])['floatingip'] self.floating_ips.append(fip) return fip def _create_server(self, name=None): port = self.create_port(self.network) server = self.create_server( flavor_ref=CONF.compute.flavor_ref, image_ref=CONF.compute.image_ref, key_name=self.keypair['name'], name=name, networks=[{'port': port['id']}])['server'] waiters.wait_for_server_status(self.os_primary.servers_client, server['id'], constants.SERVER_STATUS_ACTIVE) fip = self.create_and_associate_floatingip(port['id']) return {'port': port, 'fip': fip, 'server': server} def _verify_dns_records(self, address, name): forward = name + '.' + self.zone['name'] reverse = ipaddress.ip_address(address).reverse_pointer dns_waiters.wait_for_query(self.query_client, forward, 'A') dns_waiters.wait_for_query(self.query_client, reverse, 'PTR') fwd_response = self.query_client.query(forward, 'A') rev_response = self.query_client.query(reverse, 'PTR') for r in fwd_response: for rr in r.answer: self.assertIn(address, rr.to_text()) for r in rev_response: for rr in r.answer: self.assertIn(forward, rr.to_text()) @decorators.idempotent_id('850ee378-4b5a-4f71-960e-0e7b12e03a34') def test_server_with_fip(self): name = data_utils.rand_name('server-test') server = self._create_server(name=name) server_ip = server['fip']['floating_ip_address'] self._verify_dns_records(server_ip, name) @decorators.idempotent_id('a8f2fade-8d5c-40f9-80f0-3de4b8d91985') def test_fip(self): name = data_utils.rand_name('fip-test') fip = self._create_floatingip_with_dns(name) self._verify_dns_records(fip['floating_ip_address'], name) ",,126,0
openstack%2Fopenstack-ansible~master~I74ef40ce36256dacbd373fd22372f48b6bf276b4,openstack/openstack-ansible,master,I74ef40ce36256dacbd373fd22372f48b6bf276b4,Reduce console output in gate jobs,MERGED,2017-12-01 20:34:46.000000000,2017-12-13 09:32:09.000000000,2017-12-12 22:16:01.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-01 20:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dd92d33f9b34c3a12473912b5e4dc03ff1f4c4ba', 'message': 'Reduce console output in gate jobs\n\nThis patch brings over the rsync command from the\nopenstack-ansible-tests repository and reduces the\nconsole log output.\n\nChange-Id: I74ef40ce36256dacbd373fd22372f48b6bf276b4\n'}, {'number': 2, 'created': '2017-12-04 14:49:12.000000000', 'files': ['scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e795415993fd0959ccfc7c4cd150899990c38bef', 'message': 'Reduce console output in gate jobs\n\nThis patch brings over the rsync command from the\nopenstack-ansible-tests repository and reduces the\nconsole log output.\n\nChange-Id: I74ef40ce36256dacbd373fd22372f48b6bf276b4\n'}]",1,524721,e795415993fd0959ccfc7c4cd150899990c38bef,16,6,2,538,,,0,"Reduce console output in gate jobs

This patch brings over the rsync command from the
openstack-ansible-tests repository and reduces the
console log output.

Change-Id: I74ef40ce36256dacbd373fd22372f48b6bf276b4
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/21/524721/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,dd92d33f9b34c3a12473912b5e4dc03ff1f4c4ba,reduce-console-output," RSYNC_CMD=""rsync --archive --safe-links --ignore-errors --quiet --no-perms --no-owner --no-group"" ${RSYNC_CMD} /var/log/ ""${GATE_LOG_DIR}/host"" || true ${RSYNC_CMD} /openstack/log/ ""${GATE_LOG_DIR}/openstack"" || true"," rsync --archive --verbose --safe-links --ignore-errors /var/log/ ""${GATE_LOG_DIR}/host"" || true rsync --archive --verbose --safe-links --ignore-errors /openstack/log/ ""${GATE_LOG_DIR}/openstack"" || true",3,2
openstack%2Fopenstack-ansible~master~Icaa997a37d9e31c70e952a80a3f75050965d7ef5,openstack/openstack-ansible,master,Icaa997a37d9e31c70e952a80a3f75050965d7ef5,Skip ansible-lint test against roles,MERGED,2017-12-11 17:57:41.000000000,2017-12-13 09:31:33.000000000,2017-12-12 22:16:04.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-11 17:57:41.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d98afec530ed8cd2ecf6431dadddcaa818ce494c', 'message': 'Skip ansible-lint test against roles\n\nIn order to decouple changes in this repo from changes\nneeded in other repositories due to the ansible-lint\ntest, this repo will skip all roles when executing the\nlint test. The roles can be updated in time as patches\nare submitted to those repositories.\n\nCloses-Bug: #1737310\nDepends-On: If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899\nChange-Id: Icaa997a37d9e31c70e952a80a3f75050965d7ef5\n'}]",0,527198,d98afec530ed8cd2ecf6431dadddcaa818ce494c,11,5,1,6816,,,0,"Skip ansible-lint test against roles

In order to decouple changes in this repo from changes
needed in other repositories due to the ansible-lint
test, this repo will skip all roles when executing the
lint test. The roles can be updated in time as patches
are submitted to those repositories.

Closes-Bug: #1737310
Depends-On: If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899
Change-Id: Icaa997a37d9e31c70e952a80a3f75050965d7ef5
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/98/527198/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d98afec530ed8cd2ecf6431dadddcaa818ce494c,bug/1737310, ANSIBLE_LINT_PARAMS=--exclude={homedir}/.ansible/roles,,1,0
openstack%2Fopenstack-ansible-tests~master~If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899,openstack/openstack-ansible-tests,master,If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899,Allow additional parameters for ansible-lint,MERGED,2017-12-11 17:41:17.000000000,2017-12-13 09:31:24.000000000,2017-12-12 20:53:25.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 17:41:17.000000000', 'files': ['test-ansible-lint.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/fa828752c51911646664216f1726959a022e0721', 'message': 'Allow additional parameters for ansible-lint\n\nIn order to facilitate providing additional parameters\nto ansible-lint for any tests, we add an additional\nenvironment variable for it.\n\nWe also add the printing out of any extra parameters\ngiven to the lint test to ease troubleshooting.\n\nRelated-Bug: #1737310\nChange-Id: If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899\n'}]",0,527195,fa828752c51911646664216f1726959a022e0721,11,4,1,6816,,,0,"Allow additional parameters for ansible-lint

In order to facilitate providing additional parameters
to ansible-lint for any tests, we add an additional
environment variable for it.

We also add the printing out of any extra parameters
given to the lint test to ease troubleshooting.

Related-Bug: #1737310
Change-Id: If5746d35ee1b8ce5d6fd1a14a2abca16e29cb899
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/95/527195/1 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-lint.sh'],1,fa828752c51911646664216f1726959a022e0721,bug/1737310,"export ANSIBLE_LINT_PARAMS=${ANSIBLE_LINT_PARAMS:-} echo ""TEST_PLAYBOOK: ${TEST_PLAYBOOK}"" echo ""ANSIBLE_LINT_PARAMS: ${ANSIBLE_LINT_PARAMS}""ansible-lint ${ANSIBLE_LINT_PARAMS} -R -r ${COMMON_TESTS_PATH}/ansible-lint/ ${TEST_PLAYBOOK}",ansible-lint -R -r ${COMMON_TESTS_PATH}/ansible-lint/ ${TEST_PLAYBOOK},5,1
openstack%2Fpanko~master~I6f426b544575cfdd93e0b4b67ae7132c7a23534e,openstack/panko,master,I6f426b544575cfdd93e0b4b67ae7132c7a23534e,[Fix gate] import python-memcached to fix issue,ABANDONED,2017-12-13 02:43:47.000000000,2017-12-13 09:31:01.000000000,,"[{'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22348}, {'_account_id': 22752}, {'_account_id': 25254}]","[{'number': 1, 'created': '2017-12-13 02:43:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/panko/commit/cff4b5a0f25b37ec3659644fc55b3e4af28c52b1', 'message': '[Fix gate] import python-memcached to fix issue\n\nGate raised the following issue:\n\n    ""ImportError: No module named memcache""\n\nWe need to setup this package along with tox check.\n\nChange-Id: I6f426b544575cfdd93e0b4b67ae7132c7a23534e\n'}]",0,527565,cff4b5a0f25b37ec3659644fc55b3e4af28c52b1,7,5,1,25254,,,0,"[Fix gate] import python-memcached to fix issue

Gate raised the following issue:

    ""ImportError: No module named memcache""

We need to setup this package along with tox check.

Change-Id: I6f426b544575cfdd93e0b4b67ae7132c7a23534e
",git fetch https://review.opendev.org/openstack/panko refs/changes/65/527565/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cff4b5a0f25b37ec3659644fc55b3e4af28c52b1,fix-gate,python-memcached>=1.56 # PSF,,1,0
openstack%2Fpython-qinlingclient~master~I0d6ff1e3c10943fed174e1751d66d05264350657,openstack/python-qinlingclient,master,I0d6ff1e3c10943fed174e1751d66d05264350657,Get executions by admin user,MERGED,2017-12-13 08:56:02.000000000,2017-12-13 09:19:43.000000000,2017-12-13 09:19:43.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 08:56:02.000000000', 'files': ['qinlingclient/v1/function_execution.py'], 'web_link': 'https://opendev.org/openstack/python-qinlingclient/commit/0ff6d6eaee8cad16a737abe0ca884da0e95c219f', 'message': 'Get executions by admin user\n\nChange-Id: I0d6ff1e3c10943fed174e1751d66d05264350657\n'}]",0,527634,0ff6d6eaee8cad16a737abe0ca884da0e95c219f,6,2,1,6732,,,0,"Get executions by admin user

Change-Id: I0d6ff1e3c10943fed174e1751d66d05264350657
",git fetch https://review.opendev.org/openstack/python-qinlingclient refs/changes/34/527634/1 && git format-patch -1 --stdout FETCH_HEAD,['qinlingclient/v1/function_execution.py'],1,0ff6d6eaee8cad16a737abe0ca884da0e95c219f,admin-executions," def list(self, **kwargs): q_list = [] for key, value in kwargs.items(): q_list.append('%s=%s' % (key, value)) q_params = '&'.join(q_list) url = '/v1/executions'"," def list(self, function_id=None, **kwargs): q_params = '' if function_id: q_params += 'function_id=%s' % function_id url = ""/v1/executions""",6,6
openstack%2Fnova~master~Ie7200dbfb863d27115e12347e0e8b4ad444489e1,openstack/nova,master,Ie7200dbfb863d27115e12347e0e8b4ad444489e1,Refactor placement version check,MERGED,2017-10-17 06:40:18.000000000,2017-12-13 09:19:25.000000000,2017-12-13 07:11:23.000000000,"[{'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-17 06:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/824d2604e04c84aaa3352be279ef76e90134b7a4', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 2, 'created': '2017-10-18 02:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75290ac4b2ad44f7fc835f5444c6373355080780', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 3, 'created': '2017-10-18 06:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd57fa00f6a4cefe70f504252ca9768ad41cdb2e', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 4, 'created': '2017-10-18 08:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63a70581dbd47fb73d844ae9a705ca1bdf1b1058', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 5, 'created': '2017-10-18 11:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97b2f7e8bbb1a9c51cf7fe6229f457b9422e0361', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 6, 'created': '2017-10-19 02:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/066b373c456878b9c5b8395ba792f317efffe6e0', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 7, 'created': '2017-10-20 08:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd07a67f2995b819f6632e6815789f0444891b45', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 8, 'created': '2017-10-23 01:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89905f381a172790f7bb047d7e6f3cee155af668', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nAlso, fixed a typo in comment as well.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 9, 'created': '2017-10-23 01:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e640e16225dd3061fe2d7c3b112ae3eae09fe55', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nAlso, fixed a typo in comment as well.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 10, 'created': '2017-11-12 07:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52a2497c15f3e177944cd65939eefc7ff4c88e3a', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nAlso, fixed a typo in comment as well.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 11, 'created': '2017-12-01 04:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/581717e444ec0c70a41974101b53d1bcda7b56d2', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nAlso, fixed a typo in comment as well.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}, {'number': 12, 'created': '2017-12-06 06:55:38.000000000', 'files': ['nova/api/openstack/placement/handlers/aggregate.py', 'nova/api/openstack/placement/handlers/inventory.py', 'nova/api/openstack/placement/microversion.py', 'nova/tests/unit/api/openstack/placement/test_microversion.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ae2e2c0686fefd1894425c11c8b11fd5da21c76', 'message': ""Refactor placement version check\n\nraise_http_status_code_if_not_version are duplicate\nwe don't need keep this function, instead, use\nthe decorater to check version.\n\nAlso, fixed a typo in comment as well.\n\nChange-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1\n""}]",13,512497,6ae2e2c0686fefd1894425c11c8b11fd5da21c76,151,21,12,6062,,,0,"Refactor placement version check

raise_http_status_code_if_not_version are duplicate
we don't need keep this function, instead, use
the decorater to check version.

Also, fixed a typo in comment as well.

Change-Id: Ie7200dbfb863d27115e12347e0e8b4ad444489e1
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/512497/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/placement/handlers/aggregate.py', 'nova/api/openstack/placement/handlers/inventory.py', 'nova/api/openstack/placement/microversion.py', 'nova/tests/unit/api/openstack/placement/test_microversion.py']",4,824d2604e04c84aaa3352be279ef76e90134b7a4,refactory_placement_api_version,,"class TestMicroversionUtility(test.NoDBTestCase): req = webob.Request.blank('/', method=""GET"") req.accept = 'application/json' def test_raise_405_out_of_date_version(self): version_obj = microversion.parse_version_string('1.4') self.req.environ['placement.microversion'] = version_obj self.assertRaises(webob.exc.HTTPMethodNotAllowed, microversion.raise_http_status_code_if_not_version, self.req, 405, (1, 5)) def test_raise_405_out_of_date_version_max(self): version_obj = microversion.parse_version_string('1.4') self.req.environ['placement.microversion'] = version_obj self.assertRaises(webob.exc.HTTPMethodNotAllowed, microversion.raise_http_status_code_if_not_version, self.req, 405, (1, 2), '1.3') def test_raise_keyerror_out_of_date_version_tuple(self): version_obj = microversion.parse_version_string('1.4') self.req.environ['placement.microversion'] = version_obj self.assertRaises(KeyError, microversion.raise_http_status_code_if_not_version, self.req, 999, (1, 5)) def test_raise_keyerror_out_of_date_version_string(self): version_obj = microversion.parse_version_string('1.4') self.req.environ['placement.microversion'] = version_obj self.assertRaises(KeyError, microversion.raise_http_status_code_if_not_version, self.req, 999, '1.5') ",9,64
openstack%2Fpython-mistralclient~master~I70ca546c939afdae2cc5df6ad3e155bb44310a4b,openstack/python-mistralclient,master,I70ca546c939afdae2cc5df6ad3e155bb44310a4b,Fix limit handling to not send value of -1,MERGED,2017-11-20 16:18:15.000000000,2017-12-13 09:07:10.000000000,2017-12-13 09:07:10.000000000,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 16511}, {'_account_id': 21970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-20 16:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/cbc261c072f7d523149e01b17fd033239c88fe0c', 'message': 'Fix limit handling to not send value of -1\n\nUpdated all list commands that use limit to not send a value of -1.\nAdded tests for all of these cases.\n\nChange-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b\nCloses-Bug: 1730755\n'}, {'number': 2, 'created': '2017-11-20 17:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/06c7d291230ff6e37baa1d4d2ffbdadb7e0b8eb6', 'message': 'Fix limit handling to not send value of -1\n\nUpdated all list commands that use limit to not send a value of -1.\nAdded tests for all of these cases.\n\nChange-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b\nCloses-Bug: 1730755\n'}, {'number': 3, 'created': '2017-11-20 17:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/28a63b8587139df8689905afd98c2a26c0ddffad', 'message': 'Fix limit handling to not send value of -1\n\nUpdated all list commands that use limit to not send a value of -1.\nAdded tests for all of these cases.\n\nChange-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b\nCloses-Bug: 1730755\n'}, {'number': 4, 'created': '2017-11-20 23:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/c5dceb9f2b1fd2331d915e93e21e518828ba26c9', 'message': 'Fix limit handling to not send value of -1\n\nUpdated all list commands that use limit to not send a value of -1.\nAdded tests for all of these cases.\n\nChange-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b\nCloses-Bug: 1730755\n'}, {'number': 5, 'created': '2017-11-20 23:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/455292f216b3a5aa577d6b7a4826ceff739163f5', 'message': 'Fix limit handling to not send value of -1\n\nUpdated all list commands that use limit to not send a value of -1.\nAdded tests for all of these cases.\n\nChange-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b\nCloses-Bug: 1730755\n'}, {'number': 6, 'created': '2017-11-25 19:21:09.000000000', 'files': ['mistralclient/api/v2/actions.py', 'mistralclient/tests/unit/v2/test_action_executions.py', 'mistralclient/tests/unit/v2/test_actions.py', 'mistralclient/tests/unit/v2/test_tasks.py', 'mistralclient/api/v2/tasks.py', 'mistralclient/tests/unit/v2/test_executions.py', 'mistralclient/api/v2/executions.py', 'mistralclient/api/v2/workflows.py', 'mistralclient/api/v2/action_executions.py', 'mistralclient/tests/unit/v2/test_workflows.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/77afe252fe3407dcaffaa998c69b39c70b18bef7', 'message': 'Fix limit handling to not send value of -1\n\nUpdated all list commands that use limit to not send a value of -1.\nAdded tests for all of these cases.\n\nChange-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b\nCloses-Bug: 1730755\n'}]",0,521572,77afe252fe3407dcaffaa998c69b39c70b18bef7,18,5,6,16511,,,0,"Fix limit handling to not send value of -1

Updated all list commands that use limit to not send a value of -1.
Added tests for all of these cases.

Change-Id: I70ca546c939afdae2cc5df6ad3e155bb44310a4b
Closes-Bug: 1730755
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/72/521572/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/api/v2/actions.py', 'mistralclient/tests/unit/v2/test_action_executions.py', 'mistralclient/tests/unit/v2/test_actions.py', 'mistralclient/tests/unit/v2/test_tasks.py', 'mistralclient/api/v2/tasks.py', 'mistralclient/tests/unit/v2/test_executions.py', 'mistralclient/api/v2/action_executions.py', 'mistralclient/api/v2/executions.py', 'mistralclient/api/v2/workflows.py', 'mistralclient/tests/functional/cli/v2/cli_tests_v2.py', 'mistralclient/tests/unit/v2/test_workflows.py']",11,cbc261c072f7d523149e01b17fd033239c88fe0c,bug/1730755," def test_list_with_no_limit(self): self.requests_mock.get(self.TEST_URL + URL_TEMPLATE, json={'workflows': [WORKFLOW]}) workflows_list = self.workflows.list(limit=-1) self.assertEqual(1, len(workflows_list)) last_request = self.requests_mock.last_request self.assertNotIn('limit', last_request.qs) ",,118,5
openstack%2Fneutron~master~Ibdbe8a88581e54250259825bbf1c77485fd09f89,openstack/neutron,master,Ibdbe8a88581e54250259825bbf1c77485fd09f89,Update network external attribute for RBAC change,MERGED,2017-10-17 05:19:29.000000000,2017-12-13 08:55:05.000000000,2017-12-13 08:55:05.000000000,"[{'_account_id': 841}, {'_account_id': 4694}, {'_account_id': 7249}, {'_account_id': 7715}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 15309}, {'_account_id': 15471}, {'_account_id': 15752}, {'_account_id': 17491}, {'_account_id': 17776}, {'_account_id': 22348}, {'_account_id': 25564}, {'_account_id': 25618}, {'_account_id': 26072}]","[{'number': 1, 'created': '2017-10-17 05:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a5d82424cf6e62b9a18fbf69fa07a5f1cc2dfb4', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 2, 'created': '2017-10-18 07:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f16630b6657a8bb6e15f79e0f4e89ee1e96ec9e8', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 3, 'created': '2017-10-18 08:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9a61052bec6f3a5333731af64a2d60474c12168', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 4, 'created': '2017-10-18 08:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e2a9baf3ce2cc2f32596a4938a6d79d4be760fb', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 5, 'created': '2017-10-20 06:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/82f40e24dcde30bf052bdd8bbda9aacc042fd98a', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 6, 'created': '2017-10-21 00:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/72ad87d6998857b2641053e422f594dbde6e9166', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 7, 'created': '2017-10-23 03:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c6268568c27097431b50cdd787c803d986cefcd', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 8, 'created': '2017-10-23 09:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b59533beeb3ce3d50012c2f53936d66162d64ce1', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 9, 'created': '2017-10-25 11:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d52b8f028b3b24a248dcaed8a6a81ebf866c0c7b', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 10, 'created': '2017-10-26 06:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41529eeb84dadb64b7e350ec4854b4af8acac0a7', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 11, 'created': '2017-10-26 08:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38bc1a44665d30cc0c9c5bc5a7dc5c6842146ebe', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 12, 'created': '2017-11-16 02:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b2548897bb7a0ac7d4049628c0ef4747c0c2909', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 13, 'created': '2017-11-16 02:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e111b43eee192bde21bd93ae6a056a7e5916541', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 14, 'created': '2017-11-16 05:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dfda14d7d293694100b86a1aae504127e49aace8', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 15, 'created': '2017-11-16 10:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5516d54eec55597bc30c2a7cb38445d9b06acfd9', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 16, 'created': '2017-11-18 03:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42630b7b7caad918b8bbafc12d2ce95e242ba383', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 17, 'created': '2017-11-18 03:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52ce0547bf5d62bd6fbac8c5448708100d153538', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nTempest API test patch: https://review.openstack.org/#/c/520255/\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 18, 'created': '2017-11-18 07:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65a9bb3ce680da1bb49f8372c02c8b7c391a8ff6', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nTempest API test patch: https://review.openstack.org/#/c/520255/\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 19, 'created': '2017-11-30 04:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/59fb27c4dcd6a2049af7449b93ee0a76e395e926', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nTempest API test patch: https://review.openstack.org/#/c/520255/\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 20, 'created': '2017-12-10 09:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f704a0fceeb20929a68a9a9dfe6318ec0150cea9', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nTempest API test patch: https://review.openstack.org/#/c/520255/\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 21, 'created': '2017-12-11 07:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8212228bd2e1c573ff7b7b155a125dc1146420de', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute delete, we\nshould updates the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nTempest API test patch: https://review.openstack.org/#/c/520255/\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}, {'number': 22, 'created': '2017-12-12 01:24:52.000000000', 'files': ['neutron/tests/unit/db/test_rbac_db_mixin.py', 'neutron/db/rbac_db_mixin.py', 'neutron/db/external_net_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3ca20fb57c30e218a23dc6ea7098cb2234d2981', 'message': ""Update network external attribute for RBAC change\n\nIf a network's RBAC external attribute is deleted, we\nshould update the router:external attribute to False\nif there is no other access_as_external rbac policy on the network.\n\nTempest API test patch: https://review.openstack.org/#/c/520255/\n\nChange-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89\nCloses-Bug: #1692472\n""}]",55,512484,e3ca20fb57c30e218a23dc6ea7098cb2234d2981,165,19,22,12860,,,0,"Update network external attribute for RBAC change

If a network's RBAC external attribute is deleted, we
should update the router:external attribute to False
if there is no other access_as_external rbac policy on the network.

Tempest API test patch: https://review.openstack.org/#/c/520255/

Change-Id: Ibdbe8a88581e54250259825bbf1c77485fd09f89
Closes-Bug: #1692472
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/512484/8 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/rbac_db_mixin.py', 'neutron/db/external_net_db.py']",2,6a5d82424cf6e62b9a18fbf69fa07a5f1cc2dfb4,bug/1692472," @registry.receives('rbac-policy', [events.AFTER_DELETE]) def _process_ext_policy_delete(self, resource, event, trigger, context, object_type, policy, **kwargs): if object_type != 'network': return net = self.get_network(context, policy['object_id']) if not context.is_admin and net['tenant_id'] != context.tenant_id: msg = _(""Only admins can manipulate policies on networks they "" ""do not own"") raise n_exc.InvalidInput(error_message=msg) if self._network_is_external(context, policy['object_id']): self._process_l3_update(context, net, {external_net.EXTERNAL: False}, allow_all=False) ",,18,0
openstack%2Frequirements~stable%2Fpike~I9f5b68e1a6f15957382deb29bc6e6bb462b86b34,openstack/requirements,stable/pike,I9f5b68e1a6f15957382deb29bc6e6bb462b86b34,switch to zuul.projects from zuul._projects,MERGED,2017-12-11 16:52:57.000000000,2017-12-13 08:46:29.000000000,2017-12-13 08:46:28.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 16:52:57.000000000', 'files': ['playbooks/requirements-check.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/64f4853668d97e610230e33b5562c5fb7317651d', 'message': 'switch to zuul.projects from zuul._projects\n\nChange-Id: I9f5b68e1a6f15957382deb29bc6e6bb462b86b34\n'}]",0,527161,64f4853668d97e610230e33b5562c5fb7317651d,15,3,1,14288,,,0,"switch to zuul.projects from zuul._projects

Change-Id: I9f5b68e1a6f15957382deb29bc6e6bb462b86b34
",git fetch https://review.opendev.org/openstack/requirements refs/changes/61/527161/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/requirements-check.yaml'],1,64f4853668d97e610230e33b5562c5fb7317651d,pike/remove-_projects," command: ""{{ zuul.projects['git.openstack.org/openstack/requirements'].src_dir }}/playbooks/files/project-requirements-change.py {{ zuul.project.src_dir }} {{ zuul.branch }}"""," command: ""{{ zuul._projects['git.openstack.org/openstack/requirements'].src_dir }}/playbooks/files/project-requirements-change.py {{ zuul.project.src_dir }} {{ zuul.branch }}""",1,1
openstack%2Fmagnum~master~I8254a52b9902efba885172a83e487286b6e3011d,openstack/magnum,master,I8254a52b9902efba885172a83e487286b6e3011d,Updated from global requirements,MERGED,2017-11-29 09:00:05.000000000,2017-12-13 08:42:05.000000000,2017-12-13 08:42:05.000000000,"[{'_account_id': 13861}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-29 09:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d3139fffd69b21f8db16c28b0c2027e3f01349b3', 'message': 'Updated from global requirements\n\nChange-Id: I8254a52b9902efba885172a83e487286b6e3011d\n'}, {'number': 2, 'created': '2017-12-05 03:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8cfb8419c619556fa20b9956bdf137cd6cb2c9e0', 'message': 'Updated from global requirements\n\nChange-Id: I8254a52b9902efba885172a83e487286b6e3011d\n'}, {'number': 3, 'created': '2017-12-05 16:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/99c0e75af97e27f3c3648a13ebe1de6beac0ccf8', 'message': 'Updated from global requirements\n\nChange-Id: I8254a52b9902efba885172a83e487286b6e3011d\n'}, {'number': 4, 'created': '2017-12-07 13:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cfae27e5b498683db10467bb42587a01aee6f777', 'message': 'Updated from global requirements\n\nChange-Id: I8254a52b9902efba885172a83e487286b6e3011d\n'}, {'number': 5, 'created': '2017-12-07 13:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/eb35e7391691ed3537bba02cf9c3555794f64a9f', 'message': 'Updated from global requirements\n\nChange-Id: I8254a52b9902efba885172a83e487286b6e3011d\n'}, {'number': 6, 'created': '2017-12-10 07:11:34.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/73b725003e1e05703a84f5a07e5cc8a3ae01cbe9', 'message': 'Updated from global requirements\n\nChange-Id: I8254a52b9902efba885172a83e487286b6e3011d\n'}]",0,523741,73b725003e1e05703a84f5a07e5cc8a3ae01cbe9,22,3,6,11131,,,0,"Updated from global requirements

Change-Id: I8254a52b9902efba885172a83e487286b6e3011d
",git fetch https://review.opendev.org/openstack/magnum refs/changes/41/523741/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d3139fffd69b21f8db16c28b0c2027e3f01349b3,openstack/requirements,oslo.config>=5.1.0 # Apache-2.0,oslo.config>=4.6.0 # Apache-2.0,1,1
openstack%2Fvitrage-dashboard~master~Ia8694fe79a4830e7dc1f8d80d48b94c2159fca47,openstack/vitrage-dashboard,master,Ia8694fe79a4830e7dc1f8d80d48b94c2159fca47,Drop django_openstack_auth from requirements.txt,MERGED,2017-11-24 02:46:32.000000000,2017-12-13 08:39:59.000000000,2017-12-13 08:39:58.000000000,"[{'_account_id': 841}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22348}, {'_account_id': 24441}]","[{'number': 1, 'created': '2017-11-24 02:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/2162db276d320a4afaa5330aee5cd94332439439', 'message': 'Drop django_openstack_auth from requirements.txt\n\ndjango_openstack_auth has been merged into horizon tree\nas an effort of blueprint merge-openstack-auth.\nThere is no need to depend on django_openstack_auth any more.\n\nChange-Id: Ia8694fe79a4830e7dc1f8d80d48b94c2159fca47\n'}, {'number': 2, 'created': '2017-12-11 02:10:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/6aba020012913c5c65b93bb4d93f54393e7b04f3', 'message': 'Drop django_openstack_auth from requirements.txt\n\ndjango_openstack_auth has been merged into horizon tree\nas an effort of blueprint merge-openstack-auth.\nThere is no need to depend on django_openstack_auth any more.\n\nChange-Id: Ia8694fe79a4830e7dc1f8d80d48b94c2159fca47\n'}]",0,522688,6aba020012913c5c65b93bb4d93f54393e7b04f3,11,5,2,25254,,,0,"Drop django_openstack_auth from requirements.txt

django_openstack_auth has been merged into horizon tree
as an effort of blueprint merge-openstack-auth.
There is no need to depend on django_openstack_auth any more.

Change-Id: Ia8694fe79a4830e7dc1f8d80d48b94c2159fca47
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/88/522688/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2162db276d320a4afaa5330aee5cd94332439439,bp/merge-openstack-auth,,django-openstack-auth>=3.1.0 # Apache-2.0,0,1
openstack%2Fvitrage-dashboard~master~I2cd41bb244b4767de6fcb9c4c2925c4eb2ddbdaa,openstack/vitrage-dashboard,master,I2cd41bb244b4767de6fcb9c4c2925c4eb2ddbdaa,Added release notes for the alarm-header blueprint,MERGED,2017-11-28 15:50:27.000000000,2017-12-13 08:37:20.000000000,2017-12-13 08:37:20.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-28 15:50:27.000000000', 'files': ['releasenotes/notes/alarm-banner-7aa616e3f8e69171.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/5cb19cbb79c1b9db7bf36fc172bf16b7b0413986', 'message': 'Added release notes for the alarm-header blueprint\n\nChange-Id: I2cd41bb244b4767de6fcb9c4c2925c4eb2ddbdaa\n'}]",0,523448,5cb19cbb79c1b9db7bf36fc172bf16b7b0413986,7,3,1,26438,,,0,"Added release notes for the alarm-header blueprint

Change-Id: I2cd41bb244b4767de6fcb9c4c2925c4eb2ddbdaa
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/48/523448/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/alarm-banner-7aa616e3f8e69171.yaml'],1,5cb19cbb79c1b9db7bf36fc172bf16b7b0413986,,--- features: - Added an extensible header section to the top bar to display the current count of alarms present in the system. ,,4,0
openstack%2Fpython-watcherclient~master~Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902,openstack/python-watcherclient,master,Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902,marker when retrive action,MERGED,2017-11-03 07:40:44.000000000,2017-12-13 08:36:22.000000000,2017-12-13 08:36:22.000000000,"[{'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-03 07:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/8aeb24eceba3c46045149835131d38ef6fa16b77', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}, {'number': 2, 'created': '2017-11-03 08:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/e6146abe4e00bd4ba66235d98f3ea726a4175bb2', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}, {'number': 3, 'created': '2017-11-20 09:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/e2435863d2125fc60c0f8357740095e8657881ee', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}, {'number': 4, 'created': '2017-11-20 11:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/97c17435f0eb050b86f7bab95aa0304a35267e61', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}, {'number': 5, 'created': '2017-11-21 13:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/423faece802c0da46f0540d67b9bece0445e4e74', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}, {'number': 6, 'created': '2017-11-22 13:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/f2d839e4c7117739edfee999c1b98f36a2119315', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}, {'number': 7, 'created': '2017-11-27 06:54:42.000000000', 'files': ['watcherclient/tests/unit/v1/test_action.py', 'watcherclient/v1/action.py', 'watcherclient/tests/unit/v1/test_action_shell.py', 'watcherclient/v1/action_shell.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/1cd8c38d95981ec73b9bd5a0ee6bf66c859b9d3f', 'message': 'marker when retrive action\n\nChange-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902\n'}]",0,517563,1cd8c38d95981ec73b9bd5a0ee6bf66c859b9d3f,26,3,7,24501,,,0,"marker when retrive action

Change-Id: Ic733c3e79a31c7cd99226e6e49dfbbc8c3b58902
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/63/517563/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcherclient/v1/action.py', 'watcherclient/v1/action_shell.py']",2,8aeb24eceba3c46045149835131d38ef6fa16b77,add-marker," parser.add_argument( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last action UUID of the previous page; ' 'displays list of actions after ""marker"".')) if parsed_args.marker is not None: params['marker'] = parsed_args.marker",,12,1
openstack%2Fglance~master~I11474cd404b360a8fb2eebc2452348d923a83a2e,openstack/glance,master,I11474cd404b360a8fb2eebc2452348d923a83a2e,[import-tests] Enhance image import tests,MERGED,2017-11-27 18:09:31.000000000,2017-12-13 08:32:39.000000000,2017-12-13 04:31:14.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 14676}, {'_account_id': 15062}, {'_account_id': 22348}, {'_account_id': 27190}]","[{'number': 1, 'created': '2017-11-27 18:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1b1eeb0dee5b675aa5f0bf605fa31eb1e9dca44a', 'message': '[import-tests] Enhance image import tests\n\nThis commit adds more tests. This connects to the blueprint:\nhttps://blueprints.launchpad.net/glance/+spec/image-import-refactor\n\netherpad (discussion):\n https://etherpad.openstack.org/p/glance-image-import-tests\n\nChange-Id: I11474cd404b360a8fb2eebc2452348d923a83a2e\nCo-Authored-By: Abhishek Kekane <akekane@redhat.com>\n'}, {'number': 2, 'created': '2017-12-13 00:33:12.000000000', 'files': ['glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/830526c3ed9e49e558ac3ca17579923cc89a8abd', 'message': '[import-tests] Enhance image import tests\n\nThis commit adds more tests. This connects to the blueprint:\nhttps://blueprints.launchpad.net/glance/+spec/image-import-refactor\n\netherpad (discussion):\n https://etherpad.openstack.org/p/glance-image-import-tests\n\nChange-Id: I11474cd404b360a8fb2eebc2452348d923a83a2e\nCo-Authored-By: Abhishek Kekane <akekane@redhat.com>\n'}]",0,523179,830526c3ed9e49e558ac3ca17579923cc89a8abd,32,8,2,15062,,,0,"[import-tests] Enhance image import tests

This commit adds more tests. This connects to the blueprint:
https://blueprints.launchpad.net/glance/+spec/image-import-refactor

etherpad (discussion):
 https://etherpad.openstack.org/p/glance-image-import-tests

Change-Id: I11474cd404b360a8fb2eebc2452348d923a83a2e
Co-Authored-By: Abhishek Kekane <akekane@redhat.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/79/523179/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/v2/test_images_resource.py'],1,1b1eeb0dee5b675aa5f0bf605fa31eb1e9dca44a,import-tests," def test_image_import(self): request = unit_test_utils.get_fake_request() output = self.controller.import_image(request, UUID4, {}) self.assertEqual(UUID4, output) def test_image_import_not_allowed(self): request = unit_test_utils.get_fake_request() # NOTE(abhishekk): For coverage purpose setting tenant to # None. It is not expected to do in normal scenarios. request.context.tenant = None self.assertRaises(webob.exc.HTTPForbidden, self.controller.import_image, request, UUID4, {}) def test_image_import(self): self.config(enable_image_import=True) request = unit_test_utils.get_fake_request() import_body = { ""method"": { ""name"": ""glance-direct"" } } request.body = jsonutils.dump_as_bytes(import_body) output = self.deserializer.import_image(request) expected = {""body"": import_body} self.assertEqual(expected, output) def test_import_image_disabled(self): self.config(enable_image_import=False) request = unit_test_utils.get_fake_request() self.assertRaises(webob.exc.HTTPNotFound, self.deserializer.import_image, request) def test_import_image_invalid_body(self): self.config(enable_image_import=True) request = unit_test_utils.get_fake_request() import_body = { ""method1"": { ""name"": ""glance-direct"" } } request.body = jsonutils.dump_as_bytes(import_body) self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.import_image, request) def test_import_image_invalid_input(self): self.config(enable_image_import=True) request = unit_test_utils.get_fake_request() import_body = { ""method"": { ""abcd"": ""glance-direct"" } } request.body = jsonutils.dump_as_bytes(import_body) self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.import_image, request) def test_import_image_invalid_import_method(self): self.config(enable_image_import=True) request = unit_test_utils.get_fake_request() import_body = { ""method"": { ""name"": ""abcd"" } } request.body = jsonutils.dump_as_bytes(import_body) self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.import_image, request) def test_import_image(self): response = webob.Response() self.serializer.import_image(response, {}) self.assertEqual(http.ACCEPTED, response.status_int) self.assertEqual('0', response.headers['Content-Length']) ",,80,0
openstack%2Fopenstack-ansible~stable%2Fpike~Ib9b9daf816b0f62522997d2b0e66b6a5acd9a645,openstack/openstack-ansible,stable/pike,Ib9b9daf816b0f62522997d2b0e66b6a5acd9a645,Allow disabling container restarts,MERGED,2017-12-11 22:33:15.000000000,2017-12-13 08:32:39.000000000,2017-12-13 01:22:44.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 11290}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-11 22:33:15.000000000', 'files': ['playbooks/common-tasks/os-lxc-container-setup.yml', 'releasenotes/notes/add-lxc-container-restart-option-acf4cd9a20ef61e4.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/19107d077c87316dbfa4885f9b827c1073331a93', 'message': 'Allow disabling container restarts\n\nAllow a deployer to disable container restarts by setting\n``lxc_container_allow_restarts`` to ``false``.\n\nThe tasks in common-tasks/os-lxc-container-setup.yml change some\ncontainer options that require a restart to be effective. If these\nchange during an upgrade this can cause uncoordinated LXC container\nrestarts of galera or rabbitmq containers.\n\nThis is a complement to the same option already present in the\nlxc_container_create role.\n\nChange-Id: Ib9b9daf816b0f62522997d2b0e66b6a5acd9a645\n(cherry picked from commit 35d1415a22364ece46514b883370d6b750829630)\n'}]",0,527256,19107d077c87316dbfa4885f9b827c1073331a93,21,7,1,7353,,,0,"Allow disabling container restarts

Allow a deployer to disable container restarts by setting
``lxc_container_allow_restarts`` to ``false``.

The tasks in common-tasks/os-lxc-container-setup.yml change some
container options that require a restart to be effective. If these
change during an upgrade this can cause uncoordinated LXC container
restarts of galera or rabbitmq containers.

This is a complement to the same option already present in the
lxc_container_create role.

Change-Id: Ib9b9daf816b0f62522997d2b0e66b6a5acd9a645
(cherry picked from commit 35d1415a22364ece46514b883370d6b750829630)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/56/527256/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/common-tasks/os-lxc-container-setup.yml', 'releasenotes/notes/add-lxc-container-restart-option-acf4cd9a20ef61e4.yaml']",2,19107d077c87316dbfa4885f9b827c1073331a93,lxc_container_allow_restarts-stable/pike,--- features: - A new variable has been added to allow a deployer to control the restart of containers from common-tasks/os-lxc-container-setup.yml. This new option is ``lxc_container_allow_restarts`` and has a default of ``true``. If a deployer wishes to disable the auto-restart functionality they can set this value to ``false`` and automatic container restarts will be disabled. This is a complement to the same option already present in the lxc_container_create role. This option is useful to avoid uncoordinated restarts of galera or rabbitmq containers if the LXC container configuration changes in a way that requires a restart. ,,16,0
openstack%2Fnova~master~I366058a31c88aac0ea0a37b4e20485d247c22947,openstack/nova,master,I366058a31c88aac0ea0a37b4e20485d247c22947,[DNM] test,ABANDONED,2017-12-11 10:10:10.000000000,2017-12-13 08:32:03.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}]","[{'number': 1, 'created': '2017-12-11 10:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f9a268dcc1ec1440e480c28cb5d5aecd0f4b70e', 'message': '[DNM] test\n\ntest\n\nChange-Id: I366058a31c88aac0ea0a37b4e20485d247c22947\n'}, {'number': 2, 'created': '2017-12-11 11:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c1d6d029608a7f7877d61ecf3538c1c35c4937c', 'message': '[DNM] test\n\ntest\n\nChange-Id: I366058a31c88aac0ea0a37b4e20485d247c22947\n'}, {'number': 3, 'created': '2017-12-11 13:47:41.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8c4e7d0a310dd7940f5be5c4fa6a24fd360d3feb', 'message': '[DNM] test\n\ntest\n\nChange-Id: I366058a31c88aac0ea0a37b4e20485d247c22947\n'}]",0,527045,8c4e7d0a310dd7940f5be5c4fa6a24fd360d3feb,29,9,3,20722,,,0,"[DNM] test

test

Change-Id: I366058a31c88aac0ea0a37b4e20485d247c22947
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/527045/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,9f9a268dcc1ec1440e480c28cb5d5aecd0f4b70e,bug/1719561,, action.save(context.session) action.save(context.session),0,2
openstack%2Frequirements~master~I373c436ab78a1ea52a5dcac74165723714d2373a,openstack/requirements,master,I373c436ab78a1ea52a5dcac74165723714d2373a,update constraint for oslo.rootwrap to new release 5.12.1,MERGED,2017-12-12 14:20:12.000000000,2017-12-13 08:25:48.000000000,2017-12-13 08:25:48.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:20:12.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/45dae123e64d3f5f1811fe459adc6434e0f0798b', 'message': 'update constraint for oslo.rootwrap to new release 5.12.1\n\nChange-Id: I373c436ab78a1ea52a5dcac74165723714d2373a\nmeta:version: 5.12.1\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,527412,45dae123e64d3f5f1811fe459adc6434e0f0798b,11,3,1,11131,,,0,"update constraint for oslo.rootwrap to new release 5.12.1

Change-Id: I373c436ab78a1ea52a5dcac74165723714d2373a
meta:version: 5.12.1
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/12/527412/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,45dae123e64d3f5f1811fe459adc6434e0f0798b,new-release,oslo.rootwrap===5.12.1,oslo.rootwrap===5.12.0,1,1
openstack%2Frequirements~master~Id2e4b02a41bd6182b28c1eae5c85af27d04633f1,openstack/requirements,master,Id2e4b02a41bd6182b28c1eae5c85af27d04633f1,update constraint for taskflow to new release 3.0.0,MERGED,2017-12-12 14:20:01.000000000,2017-12-13 08:25:47.000000000,2017-12-13 08:25:47.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:20:01.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/db7626d23ed3dd29df9385893afd6fa1c5e53df7', 'message': 'update constraint for taskflow to new release 3.0.0\n\nChange-Id: Id2e4b02a41bd6182b28c1eae5c85af27d04633f1\nmeta:version: 3.0.0\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,527409,db7626d23ed3dd29df9385893afd6fa1c5e53df7,11,3,1,11131,,,0,"update constraint for taskflow to new release 3.0.0

Change-Id: Id2e4b02a41bd6182b28c1eae5c85af27d04633f1
meta:version: 3.0.0
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/09/527409/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,db7626d23ed3dd29df9385893afd6fa1c5e53df7,new-release,taskflow===3.0.0,taskflow===2.17.0,1,1
openstack%2Frequirements~master~Iedf927cae5c51a5c21893cd64718df0f6011701d,openstack/requirements,master,Iedf927cae5c51a5c21893cd64718df0f6011701d,update constraint for oslo.policy to new release 1.32.1,MERGED,2017-12-12 14:20:01.000000000,2017-12-13 08:23:05.000000000,2017-12-13 08:23:05.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:20:01.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6365c96daf7aa7362f3dd974effa48cf86e32069', 'message': 'update constraint for oslo.policy to new release 1.32.1\n\nChange-Id: Iedf927cae5c51a5c21893cd64718df0f6011701d\nmeta:version: 1.32.1\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,527410,6365c96daf7aa7362f3dd974effa48cf86e32069,11,3,1,11131,,,0,"update constraint for oslo.policy to new release 1.32.1

Change-Id: Iedf927cae5c51a5c21893cd64718df0f6011701d
meta:version: 1.32.1
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/10/527410/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,6365c96daf7aa7362f3dd974effa48cf86e32069,new-release,oslo.policy===1.32.1,oslo.policy===1.32.0,1,1
openstack%2Frequirements~master~Ib06d8605bc3a6523a83705e0e36b5a699900da74,openstack/requirements,master,Ib06d8605bc3a6523a83705e0e36b5a699900da74,update constraint for oslo.utils to new release 3.33.0,MERGED,2017-12-12 14:22:48.000000000,2017-12-13 08:17:40.000000000,2017-12-13 08:17:40.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 14:22:48.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5376697f1b8e99d441e7fbd3ff254365f7570181', 'message': 'update constraint for oslo.utils to new release 3.33.0\n\nChange-Id: Ib06d8605bc3a6523a83705e0e36b5a699900da74\nmeta:version: 3.33.0\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,527413,5376697f1b8e99d441e7fbd3ff254365f7570181,11,3,1,11131,,,0,"update constraint for oslo.utils to new release 3.33.0

Change-Id: Ib06d8605bc3a6523a83705e0e36b5a699900da74
meta:version: 3.33.0
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/527413/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5376697f1b8e99d441e7fbd3ff254365f7570181,new-release,oslo.utils===3.33.0,oslo.utils===3.32.0,1,1
openstack%2Fmistral-dashboard~master~I702d2b196f87e46bc39da00cad509d2f08f5d24c,openstack/mistral-dashboard,master,I702d2b196f87e46bc39da00cad509d2f08f5d24c,Expand parameter list for workflow execution,MERGED,2017-08-22 12:28:17.000000000,2017-12-13 08:12:52.000000000,2017-12-13 08:12:52.000000000,"[{'_account_id': 3}, {'_account_id': 5575}, {'_account_id': 8731}, {'_account_id': 22348}, {'_account_id': 27346}]","[{'number': 1, 'created': '2017-08-22 12:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/74c7875cf3c4d8a02587219915fbfe494855ebb1', 'message': 'Expand parameter list for workflow execution\n\nCurrently one generic field ""Input"" is shown when executing a workflow.\nThis patch checks list of parameters for a workflow and generates\na Django form according to the results, also prefilling any default\nvalue.\n\nIn case default value for a parameter is none, field is not marked\nas required.\n\nCloses-bug: #1712322\nChange-Id: I702d2b196f87e46bc39da00cad509d2f08f5d24c\n'}, {'number': 2, 'created': '2017-08-22 12:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/68fbf6b06392a21d56fa00750686514c7c2bb414', 'message': 'Expand parameter list for workflow execution\n\nCurrently one generic field ""Input"" is shown when executing a workflow.\nThis patch checks list of parameters for a workflow and generates\na Django form according to the results, also prefilling any default\nvalue.\n\nIn case default value for a parameter is none, field is not marked\nas required.\n\nCloses-bug: #1712322\nChange-Id: I702d2b196f87e46bc39da00cad509d2f08f5d24c\n'}, {'number': 3, 'created': '2017-08-22 12:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/bc2980d36101f0b80d194eba4301bcaa71f93ef7', 'message': 'Expand parameter list for workflow execution\n\nCurrently one generic field ""Input"" is shown when executing a workflow.\nThis patch checks list of parameters for a workflow and generates\na Django form according to the results, also prefilling any default\nvalue.\n\nIn case default value for a parameter is none, field is not marked\nas required.\n\nCloses-bug: #1712322\nChange-Id: I702d2b196f87e46bc39da00cad509d2f08f5d24c\n'}, {'number': 4, 'created': '2017-08-22 12:30:38.000000000', 'files': ['mistraldashboard/workflows/forms.py', 'mistraldashboard/workflows/views.py'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/b42b2c4f25b5e7d95d514323608b481d8c05e232', 'message': 'Expand parameter list for workflow execution\n\nCurrently one generic field ""Input"" is shown when executing a workflow.\nThis patch checks list of parameters for a workflow and generates\na Django form according to the results, also prefilling any default\nvalue.\n\nIn case default value for a parameter is none, field is not marked\nas required.\n\nCloses-bug: #1712322\nChange-Id: I702d2b196f87e46bc39da00cad509d2f08f5d24c\n'}]",0,496220,b42b2c4f25b5e7d95d514323608b481d8c05e232,13,5,4,23757,,,0,"Expand parameter list for workflow execution

Currently one generic field ""Input"" is shown when executing a workflow.
This patch checks list of parameters for a workflow and generates
a Django form according to the results, also prefilling any default
value.

In case default value for a parameter is none, field is not marked
as required.

Closes-bug: #1712322
Change-Id: I702d2b196f87e46bc39da00cad509d2f08f5d24c
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/20/496220/4 && git format-patch -1 --stdout FETCH_HEAD,"['mistraldashboard/workflows/forms.py', 'mistraldashboard/workflows/views.py']",2,74c7875cf3c4d8a02587219915fbfe494855ebb1,bug/1712322,"import yaml workflow = get_single_data(self.request, self.kwargs['workflow_name']) return {'workflow_name': self.kwargs['workflow_name'], 'parameter_list': workflow.input}", return {'workflow_name': self.kwargs['workflow_name']},31,7
openstack%2Fkolla-ansible~master~I36720af0c7d3dd7c69d2404843f54c0991aea1bb,openstack/kolla-ansible,master,I36720af0c7d3dd7c69d2404843f54c0991aea1bb,Make qemu use nova user on all distros,MERGED,2017-12-06 06:14:57.000000000,2017-12-13 08:10:15.000000000,2017-12-13 08:10:14.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 19316}, {'_account_id': 22076}, {'_account_id': 22348}, {'_account_id': 22997}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-12-06 06:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/43d876be8b4272a6845cd7562e8e63beed507567', 'message': 'Make qemu use nova user on debian\n\nThis fix libvirtError Unable to open logfile issue.\nRelated-Bug: #1668654\nChange-Id: I36720af0c7d3dd7c69d2404843f54c0991aea1bb\n'}, {'number': 2, 'created': '2017-12-07 08:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/81c1975850a34543a00cc9f0e63a80827f971628', 'message': 'Make qemu use nova user on all distros\n\nThis fix libvirtError Unable to open logfile issue.\nRelated-Bug: #1668654\nChange-Id: I36720af0c7d3dd7c69d2404843f54c0991aea1bb\n'}, {'number': 3, 'created': '2017-12-13 02:19:02.000000000', 'files': ['ansible/roles/nova/templates/qemu.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a102cd8efdd76cc9af70827391d6d29445bdd7bd', 'message': 'Make qemu use nova user on all distros\n\nThis fix libvirtError Unable to open logfile issue.\nRelated-Bug: #1668654\nChange-Id: I36720af0c7d3dd7c69d2404843f54c0991aea1bb\n'}]",5,525891,a102cd8efdd76cc9af70827391d6d29445bdd7bd,18,8,3,22997,,,0,"Make qemu use nova user on all distros

This fix libvirtError Unable to open logfile issue.
Related-Bug: #1668654
Change-Id: I36720af0c7d3dd7c69d2404843f54c0991aea1bb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/91/525891/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/templates/qemu.conf.j2'],1,43d876be8b4272a6845cd7562e8e63beed507567,logfile-open-fix,"{% if kolla_base_distro in ['ubuntu', 'centos', 'oraclelinux', 'debian']%}","{% if kolla_base_distro in ['ubuntu', 'centos', 'oraclelinux']%}",1,1
openstack%2Fcharm-designate~master~I14236fb745bffc46129e0cebbd2f527ab318b6c8,openstack/charm-designate,master,I14236fb745bffc46129e0cebbd2f527ab318b6c8,Update HAProxy default timeout values,MERGED,2017-12-11 21:00:23.000000000,2017-12-13 08:08:18.000000000,2017-12-13 07:39:08.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 21:00:23.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/04735bccb8ad85ebe14b3edeb253aec2b9751e51', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis source charm rebuild pulls in the changes to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I14236fb745bffc46129e0cebbd2f527ab318b6c8\n'}]",0,527239,04735bccb8ad85ebe14b3edeb253aec2b9751e51,10,4,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This source charm rebuild pulls in the changes to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I14236fb745bffc46129e0cebbd2f527ab318b6c8
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/39/527239/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,04735bccb8ad85ebe14b3edeb253aec2b9751e51,bug/1736171,4a1812b2-deb6-11e7-8cb5-cb62334859bb,a311cc4d-67db-4c90-953a-71af604b8b48,1,1
openstack%2Fcharm-aodh~master~Ifd52da3b5ad89a068885da2004484c55c334a46f,openstack/charm-aodh,master,Ifd52da3b5ad89a068885da2004484c55c334a46f,Update HAProxy default timeout values,MERGED,2017-12-11 21:00:07.000000000,2017-12-13 07:58:34.000000000,2017-12-13 07:40:06.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 21:00:07.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-aodh/commit/72a9dcfae00a1fee6fc2b0422ea0b403d2ef2b5c', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis source charm rebuild pulls in the changes to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: Ifd52da3b5ad89a068885da2004484c55c334a46f\n'}]",0,527237,72a9dcfae00a1fee6fc2b0422ea0b403d2ef2b5c,10,4,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This source charm rebuild pulls in the changes to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: Ifd52da3b5ad89a068885da2004484c55c334a46f
",git fetch https://review.opendev.org/openstack/charm-aodh refs/changes/37/527237/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,72a9dcfae00a1fee6fc2b0422ea0b403d2ef2b5c,bug/1736171,402cf70e-deb6-11e7-9bf3-7b2869346e5d,e347d310-a3c3-11e7-8d95-fa163e8aa73b,1,1
openstack%2Fcharm-manila~master~I2a3a4b1624174e9efa7b9aebc29ff88af00a19d3,openstack/charm-manila,master,I2a3a4b1624174e9efa7b9aebc29ff88af00a19d3,Update HAProxy default timeout values,MERGED,2017-12-11 21:00:30.000000000,2017-12-13 07:57:04.000000000,2017-12-13 07:38:22.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 21:00:30.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/10e3532842652e545cf590fc7ddfcd28737acc41', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis source charm rebuild pulls in the changes to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I2a3a4b1624174e9efa7b9aebc29ff88af00a19d3\n'}]",0,527240,10e3532842652e545cf590fc7ddfcd28737acc41,10,4,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This source charm rebuild pulls in the changes to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I2a3a4b1624174e9efa7b9aebc29ff88af00a19d3
",git fetch https://review.opendev.org/openstack/charm-manila refs/changes/40/527240/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,10e3532842652e545cf590fc7ddfcd28737acc41,bug/1736171,"# This file is used to trigger rebuilds # when dependencies of the charm change, # but nothing in the charm needs to. # simply change the uuid to something new 4e82502e-deb6-11e7-bc33-b3c5ad77ebf8",8e836620-d058-11e7-a783-bfccc1ddeb2b,5,1
openstack%2Fneutron~master~If49aaa48a5e95ccd0a236db984d3984a6e44c87c,openstack/neutron,master,If49aaa48a5e95ccd0a236db984d3984a6e44c87c,Prevent LBaaS VRRP ports from populating DVR router ARP table,MERGED,2017-11-30 01:58:12.000000000,2017-12-13 07:56:20.000000000,2017-12-13 07:56:20.000000000,"[{'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12860}, {'_account_id': 19554}, {'_account_id': 21891}, {'_account_id': 22348}, {'_account_id': 27374}]","[{'number': 1, 'created': '2017-11-30 01:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee1120795342479263370c8c85c961c855fb7d7b', 'message': 'Prevent LBaaS VRRP ports from populating DVR in ARP\n\nPrevents the MAC addresses for VRRP ports in LBaaS\nand LBaaSv2 instances from populating in the\nDVR router arp table.\n\nChange-Id: If49aaa48a5e95ccd0a236db984d3984a6e44c87c\nCloses-Bug: 1733852\n'}, {'number': 2, 'created': '2017-12-07 21:32:35.000000000', 'files': ['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/af73882a9db994b06d8df18d4d5abc05c7aecd32', 'message': 'Prevent LBaaS VRRP ports from populating DVR router ARP table\n\nPrevents the MAC address of the VIP address of an LBaaS or\nLBaaSv2 instance from populating in the DVR router ARP table\n\nChange-Id: If49aaa48a5e95ccd0a236db984d3984a6e44c87c\nCloses-Bug: 1733852\n'}]",4,524037,af73882a9db994b06d8df18d4d5abc05c7aecd32,47,10,2,21891,,,0,"Prevent LBaaS VRRP ports from populating DVR router ARP table

Prevents the MAC address of the VIP address of an LBaaS or
LBaaSv2 instance from populating in the DVR router ARP table

Change-Id: If49aaa48a5e95ccd0a236db984d3984a6e44c87c
Closes-Bug: 1733852
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/524037/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py']",2,ee1120795342479263370c8c85c961c855fb7d7b,bug/1733852," 'subnet_id': subnet_id}]}, {'mac_address': '11:22:33:44:55:66', 'device_owner': lib_constants.DEVICE_OWNER_LOADBALANCER, 'fixed_ips': [{'ip_address': '1.2.3.5', 'prefixlen': 24, 'subnet_id': subnet_id}]}, {'mac_address': '22:33:44:55:66:77', 'device_owner': lib_constants.DEVICE_OWNER_LOADBALANCERV2, 'fixed_ips': [{'ip_address': '1.2.3.6', 'prefixlen': 24,",,15,1
openstack%2Foslo.context~master~Ie418ecadcff9351a776ff790492c73225efddb6f,openstack/oslo.context,master,Ie418ecadcff9351a776ff790492c73225efddb6f,add bandit to pep8 job,MERGED,2017-11-30 03:13:02.000000000,2017-12-13 07:55:23.000000000,2017-12-13 07:55:23.000000000,"[{'_account_id': 2472}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 03:13:02.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/c7a2b56c4f7d135f51f73afeb5e981c04bd753d5', 'message': 'add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: Ie418ecadcff9351a776ff790492c73225efddb6f\n'}]",0,524051,c7a2b56c4f7d135f51f73afeb5e981c04bd753d5,12,3,1,9796,,,0,"add bandit to pep8 job

Add the bandit security scanner to the pep8 job.

Change-Id: Ie418ecadcff9351a776ff790492c73225efddb6f
",git fetch https://review.opendev.org/openstack/oslo.context refs/changes/51/524051/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,c7a2b56c4f7d135f51f73afeb5e981c04bd753d5,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_context -x tests -n5,commands = flake8,9,1
openstack%2Fi18n~master~I973e58d44151c05394b02e3eee78a4e48f8a06b9,openstack/i18n,master,I973e58d44151c05394b02e3eee78a4e48f8a06b9,Imported Translations from Zanata,MERGED,2017-12-13 07:02:32.000000000,2017-12-13 07:45:39.000000000,2017-12-13 07:45:39.000000000,"[{'_account_id': 14482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 07:02:32.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc.po', 'doc/source/locale/id/LC_MESSAGES/doc.po', 'doc/source/locale/ja/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc.po', 'doc/source/locale/tr_TR/LC_MESSAGES/doc.po'], 'web_link': 'https://opendev.org/openstack/i18n/commit/dcc52d48b0de504a4a8ef02f96692138a626d2a3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I973e58d44151c05394b02e3eee78a4e48f8a06b9\n'}]",0,527606,dcc52d48b0de504a4a8ef02f96692138a626d2a3,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I973e58d44151c05394b02e3eee78a4e48f8a06b9
",git fetch https://review.opendev.org/openstack/i18n refs/changes/06/527606/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc.po', 'doc/source/locale/id/LC_MESSAGES/doc.po', 'doc/source/locale/ja/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc.po', 'doc/source/locale/tr_TR/LC_MESSAGES/doc.po']",6,dcc52d48b0de504a4a8ef02f96692138a626d2a3,zanata/translations,"""POT-Creation-Date: 2017-12-08 19:33+0000\n""","""POT-Creation-Date: 2017-11-04 05:13+0000\n""""`include/build-releasenotes.sh <http://git.openstack.org/cgit/openstack-"" ""infra/project-config/tree/jenkins/jobs/include/build-releasenotes.sh>`__"" msgstr """" ""`include/build-releasenotes.sh <http://git.openstack.org/cgit/openstack-"" ""infra/project-config/tree/jenkins/jobs/include/build-releasenotes.sh>`__"" msgid """"",21,49
openstack%2Ftraining-guides~master~I614fab2e6a89e5d4f0b554cef9ec0c0bc9d6b848,openstack/training-guides,master,I614fab2e6a89e5d4f0b554cef9ec0c0bc9d6b848,Imported Translations from Zanata,MERGED,2017-12-13 07:16:20.000000000,2017-12-13 07:44:56.000000000,2017-12-13 07:44:56.000000000,"[{'_account_id': 14482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 07:16:20.000000000', 'files': ['doc/upstream-training/source/locale/ko_KR/LC_MESSAGES/upstream-training.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4ceeb406c1a29206c50fd378c23e70e2d483bb02', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I614fab2e6a89e5d4f0b554cef9ec0c0bc9d6b848\n'}]",0,527609,4ceeb406c1a29206c50fd378c23e70e2d483bb02,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I614fab2e6a89e5d4f0b554cef9ec0c0bc9d6b848
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/09/527609/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/locale/ko_KR/LC_MESSAGES/upstream-training.po'],1,4ceeb406c1a29206c50fd378c23e70e2d483bb02,zanata/translations,"""PO-Revision-Date: 2017-12-12 02:23+0000\n""msgid ""'Gates' code entering the stable or master branches"" msgstr ""안정이나 마스터 브랜치에 들어가는 'Gate' 코드"" msgid ""Analysing Zuul Failures"" msgstr ""Zull 실패 분석"" msgid ""Can use the patch number to track status in Zuul status page."" msgstr ""Zull 상태 페이지에서 상태를 추적하기 위해 패치 번호를 사용할 수 있음."" msgid ""Discuss your findings with your group"" msgstr ""발견한 것에 대해 당신의 그룹과 논의하세요"" msgid ""Documentation build/publishing, tarball generation, image build"" msgstr ""문서 빌드/출판, tarball 생성, 이미지 빌드"" msgid ""Filtering on Patch Number in Zuul"" msgstr ""Zull에서 패치 번호를 필터링"" msgid ""Find the information that can be retrieved for each patch in a pipeline"" msgstr ""파이프라인의 각 패치를 가져올 수 있는 정보를 찾으세요."" msgid ""How many gate and check jobs are running"" msgstr ""얼마나 많은 관문과 검사 작업이 실행되고 있는지"" msgid ""Jobs run against a patch after it merges"" msgstr ""병합 후 패치에 대한 작업 실행"" msgid ""Logs may be accessed by clicking on the test's name"" msgstr ""테스트 이름을 클릭하여 로그에 접속할 수 있음"" msgid ""Look at the `Zuul <http://status.openstack.org/zuul>`_ status page"" msgstr ""`Zuul <http://status.openstack.org/zuul>`_ 상태 페이지를 살펴보세요"" msgid ""More extensive testing than check pipeline"" msgstr ""검사 파이프라인보다 더 광범위한 테스트"" msgid ""Only run after a patch is approved by a core reviewer"" msgstr ""코드 검토자에 의해 패치가 승인된 후에만 실행하세요"" msgid ""Patch Number"" msgstr ""패치 번호"" msgid """" ""Pick your favorite project and report how many jobs it has running in IRC"" msgstr """" ""선호하는 프로젝트를 선택하고 IRC에서 얼마나 많은 작업이 실행되고 있는지 보고"" ""하세요."" msgid ""Runs another unit test run along with additional tempest testing"" msgstr ""추가적인 템페스트 테스트와 함께 다른 단위 테스트를 실행하세요"" msgid """" ""Runs unit testing, Pep8, docs/releasenote build and functional tempest "" ""testing"" msgstr ""실행 단위 테스트, Pep8, 문서/릴리즈노트 빌드와 기능 템페스트 테스트"" msgid ""Shows the Zuul status page filtered down to just the patch of interest."" msgstr ""관심 있는 패치로 필터되어 Zull 상태 페이지가 보여짐"" msgid """" ""The above jobs are examples of what is run in each pipeline. What is "" ""actually run varies based upon the project being tested."" msgstr """" ""위의 작업들은 각 파이프라인에서 무엇이 실행하는지에대한 예제입니다. 실제로 실"" ""행되는 것은 테스트되고 있는 프로젝트에 따라 다릅니다."" msgid ""The number next to 'Change' is the patch number."" msgstr ""'Change' 다음의 번호가 패치 번호입니다."" msgid ""What happens if you click on a patch under test"" msgstr ""테스트 중인 패치를 클릭하면 어떤 일이 일어나는지"" msgid ""What is the significance of the dots, lines and colors"" msgstr ""점, 선, 색깔의 의미는 무엇인지"" msgid ""Zuul Failures"" msgstr ""Zull 실패"" msgid ""Zuul Pipelines - cont."" msgstr ""Zull 파이프라인 - 계속."" msgid ""Zuul votes +1/-1 depending on test results"" msgstr ""테스트 결과에 따라 Zull은 +1/-1을 부여합니다."" ","""PO-Revision-Date: 2017-12-08 03:06+0000\n""",85,1
openstack%2Fopenstack-ansible~master~Id16b1bcd67bf075a8677206a205ece010e7b014c,openstack/openstack-ansible,master,Id16b1bcd67bf075a8677206a205ece010e7b014c,Converge neutron agents onto Baremetal,MERGED,2017-04-07 05:02:03.000000000,2017-12-13 07:42:18.000000000,2017-12-13 07:42:18.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 15993}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-04-07 05:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b82f356b436b71eb5e2a492709b1f93a348e376a', 'message': '[WIP] Converge neutron agents onto Baremetal\n\nIf no neutron-network_hosts are defined neutron agents like the l3 agent\netc will be deployed onto baremetal along side compute.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-04-07 16:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6b32adadfa30476d9f2b2e2521092e9a074b6e50', 'message': '[WIP] Converge neutron agents onto Baremetal\n\nIf no neutron-network_hosts are defined neutron agents like the l3 agent\netc will be deployed onto baremetal along side compute.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2017-04-07 19:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/431a3e07e73b1cb50bfaf5639dfca3ede731263f', 'message': '[WIP] Converge neutron agents onto Baremetal\n\nIf no neutron-network_hosts are defined neutron agents like the l3 agent\netc will be deployed onto baremetal along side compute.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2017-04-08 00:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/70c6b282221d2a10a4544aecd26087355ebf300e', 'message': 'Converge neutron agents onto Baremetal\n\nIf no ""network-connectivity_hosts"" are defined, the neutron connectivity agents\nwill be deployed onto baremetal along side the last three nova compute\nhosts. This gives deployers the ability to simplify deployments, keep a\nstandard topology, and scale to meet the demands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2017-04-08 04:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3e2440090af7741ed59aed7a416bab6a9600ad7b', 'message': 'Converge neutron agents onto Baremetal\n\nIf no ""network-connectivity_hosts"" are defined, the neutron connectivity agents\nwill be deployed onto baremetal along side the last three nova compute\nhosts. This gives deployers the ability to simplify deployments, keep a\nstandard topology, and scale to meet the demands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2017-04-10 02:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bf094431d580ee97b705644f48135e2b88dfd00a', 'message': 'Converge neutron agents onto Baremetal\n\nIf no ""network-connectivity_hosts"" are defined, the neutron connectivity agents\nwill be deployed onto baremetal along side the last three nova compute\nhosts. This gives deployers the ability to simplify deployments, keep a\nstandard topology, and scale to meet the demands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2017-04-25 23:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9bf3a5b00d2752c45b30c0b5c4a819a847db6aea', 'message': 'Converge neutron agents onto Baremetal\n\nIf no ""network-connectivity_hosts"" are defined, the neutron connectivity agents\nwill be deployed onto baremetal along side the last three nova compute\nhosts. This gives deployers the ability to simplify deployments, keep a\nstandard topology, and scale to meet the demands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2017-09-25 21:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ba0a69a45b60df8df95addaec8b37d665a35bffd', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2017-10-05 13:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a24aff1a239b0dca318683c96cc7c3fb6d717f14', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2017-10-05 13:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e41cd4f723042b678aba2177c187fa2a58fdaa4e', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 11, 'created': '2017-10-27 00:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9dde058ad320f2d2020c12e30c06c0b0ba4e5370', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 12, 'created': '2017-10-28 23:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a29a4af9715664e21a4ec54bf23c138d4e39f2d4', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 13, 'created': '2017-11-01 05:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2dcbcf17de0b2c8e7dc3f78207eff3ea8b57c62f', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 14, 'created': '2017-11-22 07:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/82f312652105b02909eb6974cbb6c347423797e3', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 15, 'created': '2017-11-24 06:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e4a92e6cb39c874c77f784b20dadd6f393f2b5d2', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 16, 'created': '2017-11-25 06:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6b3457e07bc6ae30658d49f839b6e8d7da7579f4', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 17, 'created': '2017-11-27 03:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a4ffa1f02ea802189fe160c3ed3c715e2b803a95', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 18, 'created': '2017-11-27 15:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0ba17128ea895bd854d8bd1ceb388c2db4f79d79', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 19, 'created': '2017-11-27 15:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/478f48f3581d64036735724cc1278efba575544d', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 20, 'created': '2017-11-28 08:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/12b847df4ef6d0c2e681082dc04f228763297b41', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 21, 'created': '2017-12-10 17:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e927d4230a61902b82e79b3e9d6bcb90ccd14ed4', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 22, 'created': '2017-12-11 15:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c276d150fe6dd01f8de7663990fa349d072ea585', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 23, 'created': '2017-12-11 23:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/28d215793bb8ec5aed73eec4052379548b309ff6', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 24, 'created': '2017-12-12 03:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e7d10046d6eb72db7a432a9f0a3a00f4ec684e78', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 25, 'created': '2017-12-12 03:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f480055d6c891b034893bd147ccf6eb35bc807ba', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 26, 'created': '2017-12-12 03:55:15.000000000', 'files': ['playbooks/inventory/env.d/neutron.yml', 'releasenotes/notes/neutron-agent-baremetal-c229e65c77e615fa.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/330dcd376c2709d268501a9783365ada04023292', 'message': 'Converge neutron agents onto Baremetal\n\nThe neutron connectivity agents will be deployed onto baremetal along\nside the defined ""network_hosts"". This gives deployers the ability to\nsimplify deployments, keep a standard topology, and scale to meet the\ndemands of the environment.\n\nThis addresses several long standing operational issues where the\nneutron_agent container would be restarted, due to config changes,\nupgrades, etc. This can cause a prolonged network outages when L3\ntenant networks are in service. Moving these services to baremetal\nresolves the issue permanently by ensuring consistent hardware\nconfigurations, mac addresses, and simplifying the network transport\nas no vethpairs or macvlans are in service.\n\nChange-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",21,454450,330dcd376c2709d268501a9783365ada04023292,106,9,26,7353,,,0,"Converge neutron agents onto Baremetal

The neutron connectivity agents will be deployed onto baremetal along
side the defined ""network_hosts"". This gives deployers the ability to
simplify deployments, keep a standard topology, and scale to meet the
demands of the environment.

This addresses several long standing operational issues where the
neutron_agent container would be restarted, due to config changes,
upgrades, etc. This can cause a prolonged network outages when L3
tenant networks are in service. Moving these services to baremetal
resolves the issue permanently by ensuring consistent hardware
configurations, mac addresses, and simplifying the network transport
as no vethpairs or macvlans are in service.

Change-Id: Id16b1bcd67bf075a8677206a205ece010e7b014c
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/50/454450/26 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/inventory/env.d/nova.yml', 'playbooks/os-neutron-install.yml', 'etc/openstack_deploy/openstack_user_config.yml.prod.example', 'playbooks/inventory/env.d/neutron.yml', 'etc/openstack_deploy/openstack_user_config.yml.example']",5,b82f356b436b71eb5e2a492709b1f93a348e376a,nspawn-driver,"# -------- # # Level: neutron-network_hosts (optional) # List of target hosts on which to deploy neutron agent services. Recommend three # minimum target hosts for this service. Typically contains specialized hosts used for # consolidating L3 network traffic. These services will be deployed on baremetal # (without containers). # # Level: <value> (required, string) # Hostname of a target host. # # Option: ip (required, string) # IP address of this target host, typically the IP address assigned to # the management bridge. # # Example: # # Define three OpenStack neutron network hosts: # # neutron-network_hosts: # network1: # ip: 172.29.236.201 # network2: # ip: 172.29.236.202 # network3: # ip: 172.29.236.203 # # -------- #",,63,12
openstack%2Fproject-config~master~I2405394d27cf4163f4f75136a08806100685f691,openstack/project-config,master,I2405394d27cf4163f4f75136a08806100685f691,networking-midonet: Remove some of legacy jobs on master,ABANDONED,2017-12-12 03:18:33.000000000,2017-12-13 07:36:29.000000000,,"[{'_account_id': 1131}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 03:18:33.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a0ad178794ec0cd79c6e416ec56b64eb9b4914b7', 'message': 'networking-midonet: Remove some of legacy jobs on master\n\nRemove jobs which now have in-repo counterpart.\nIn-repo jobs for stable branches are still under review. [1]\n\n[1] I778ddb080cf1bdfffef52003632614dd43ae01ab\n\nRelated-Bug: #1728766\nChange-Id: I2405394d27cf4163f4f75136a08806100685f691\n'}]",1,527293,a0ad178794ec0cd79c6e416ec56b64eb9b4914b7,10,5,1,6854,,,0,"networking-midonet: Remove some of legacy jobs on master

Remove jobs which now have in-repo counterpart.
In-repo jobs for stable branches are still under review. [1]

[1] I778ddb080cf1bdfffef52003632614dd43ae01ab

Related-Bug: #1728766
Change-Id: I2405394d27cf4163f4f75136a08806100685f691
",git fetch https://review.opendev.org/openstack/project-config refs/changes/93/527293/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,a0ad178794ec0cd79c6e416ec56b64eb9b4914b7,bug/1728766, branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$ branches: ^(stable/(ocata|pike)).*$, irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^midonet/neutron/tests/unit/.*$ - ^setup.cfg$ - ^specs/.*$ - legacy-tempest-dsvm-networking-midonet-aio-ml2-full-legacy: voting: false branches: ^(?!stable/(ocata|pike)).*$,10,10
openstack%2Fheat-dashboard~master~I111078dc52f290c28742a2289aed191ead815896,openstack/heat-dashboard,master,I111078dc52f290c28742a2289aed191ead815896,Imported Translations from Zanata,MERGED,2017-12-11 06:44:52.000000000,2017-12-13 07:34:43.000000000,2017-12-13 07:34:43.000000000,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 06:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/d3bd2ce204b8a0be5c28cc2c8521095913078499', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I111078dc52f290c28742a2289aed191ead815896\n'}, {'number': 2, 'created': '2017-12-13 07:04:24.000000000', 'files': ['heat_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'heat_dashboard/locale/de/LC_MESSAGES/django.po', 'heat_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'heat_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'heat_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'heat_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'heat_dashboard/locale/cs/LC_MESSAGES/django.po', 'heat_dashboard/locale/it/LC_MESSAGES/django.po', 'heat_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'heat_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'heat_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'heat_dashboard/locale/es/LC_MESSAGES/django.po', 'heat_dashboard/locale/ja/LC_MESSAGES/django.po', 'heat_dashboard/locale/ru/LC_MESSAGES/django.po', 'heat_dashboard/locale/fr/LC_MESSAGES/django.po', 'heat_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'heat_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'heat_dashboard/locale/id/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/4783ec21799eb5ca15dd0ad6f06e4fb7e70063b9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I111078dc52f290c28742a2289aed191ead815896\n'}]",0,526996,4783ec21799eb5ca15dd0ad6f06e4fb7e70063b9,8,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I111078dc52f290c28742a2289aed191ead815896
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/96/526996/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'heat_dashboard/locale/de/LC_MESSAGES/django.po', 'heat_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'heat_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'heat_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'heat_dashboard/locale/cs/LC_MESSAGES/django.po', 'heat_dashboard/locale/it/LC_MESSAGES/django.po', 'heat_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'heat_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'heat_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'heat_dashboard/locale/es/LC_MESSAGES/django.po', 'heat_dashboard/locale/ja/LC_MESSAGES/django.po', 'heat_dashboard/locale/ru/LC_MESSAGES/django.po', 'heat_dashboard/locale/fr/LC_MESSAGES/django.po', 'heat_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'heat_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'heat_dashboard/locale/id/LC_MESSAGES/django.po']",17,d3bd2ce204b8a0be5c28cc2c8521095913078499,zanata/translations,"# OpenStack Infra <zanata@openstack.org>, 2015. #zanata # suhartono <cloudsuhartono@gmail.com>, 2016. #zanata # suhartono <cloudsuhartono@gmail.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: heat-dashboard 0.0.1.dev938\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2017-12-07 18:26+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-12-03 04:07+0000\n"" ""Last-Translator: suhartono <cloudsuhartono@gmail.com>\n"" ""Language-Team: Indonesian\n"" ""Language: id\n"" ""X-Generator: Zanata 3.9.6\n"" ""Plural-Forms: nplurals=1; plural=0\n"" msgid ""A local environment to upload."" msgstr ""Sebuah lingkungan lokal untuk meng-upload."" msgid ""A local template to upload."" msgstr ""Sebuah template lokal untuk meng-upload."" msgctxt ""current status of stack"" msgid ""Adopt Complete"" msgstr ""Adopt Complete"" msgctxt ""current status of stack"" msgid ""Adopt Failed"" msgstr ""Adopt Failed"" msgctxt ""current status of stack"" msgid ""Adopt In Progress"" msgstr ""Adopt In Progress"" msgid ""An external (HTTP) URL to load the template from."" msgstr ""URL (HTTP) Eksternal untuk memuat template"" msgid ""Case sensitive"" msgstr ""Case sensitive (case sensitive)"" msgid ""Case-sensitive"" msgstr ""Case-sensitive (case sensitive)"" msgid ""Change Stack Template"" msgstr ""Change Stack Template"" msgid ""Change Template"" msgstr ""Merubah template"" msgctxt ""current status of stack"" msgid ""Check Complete"" msgstr ""Check Complete"" msgctxt ""current status of stack"" msgid ""Check Failed"" msgstr ""Check Failed"" msgctxt ""current status of stack"" msgid ""Check In Progress"" msgstr ""Check In Progress"" msgid ""Check Stack"" msgid_plural ""Check Stacks"" msgstr[0] ""Check Stack"" msgid ""Checked Stack"" msgid_plural ""Checked Stacks"" msgstr[0] ""Checked Stack"" msgctxt ""current status of stack"" msgid ""Create Complete"" msgstr ""Create Complete"" msgctxt ""current status of stack"" msgid ""Create Failed"" msgstr ""Create Failed"" msgctxt ""current status of stack"" msgid ""Create In Progress"" msgstr ""Create In Progress"" msgid ""Create Stack"" msgstr ""Buat stack "" msgid ""Created"" msgstr ""Created"" msgid ""Creation Timeout (minutes)"" msgstr ""Creation Timeout (minutes)"" msgid ""Date Updated"" msgstr ""Date Updated"" msgctxt ""current status of stack"" msgid ""Delete Complete"" msgstr ""Delete Complete"" msgctxt ""current status of stack"" msgid ""Delete Failed"" msgstr ""Delete Failed"" msgctxt ""current status of stack"" msgid ""Delete In Progress"" msgstr ""Delete In Progress"" msgid ""Delete Stack"" msgid_plural ""Delete Stacks"" msgstr[0] ""Delete Stack"" msgid ""Deleted Stack"" msgid_plural ""Deleted Stacks"" msgstr[0] ""Deleted Stack"" msgid ""Description"" msgstr ""Deskripsi"" msgid ""Direct Input"" msgstr ""Direct Input (masukan langsung)"" msgid ""Edit Template"" msgstr ""Edit Template (edit template)"" msgid ""Enable rollback on create/update failure."" msgstr ""Aktifkan rollback pada kegagalan create/update."" msgid ""Environment Data"" msgstr ""Environment Data"" msgid ""Environment File"" msgstr ""Environment File"" msgid ""Environment Source"" msgstr ""Environment Source"" msgid ""Events"" msgstr ""Acara"" msgid ""File"" msgstr ""File"" msgid ""Function"" msgstr ""Function"" msgctxt ""current status of stack"" msgid ""Init Complete"" msgstr ""Init Complete"" msgctxt ""current status of stack"" msgid ""Init Failed"" msgstr ""Init Failed"" msgctxt ""current status of stack"" msgid ""Init In Progress"" msgstr ""Init In Progress"" msgid ""Launch"" msgstr ""Launch (luncurkan)"" msgid ""Launch Stack"" msgstr ""Launch Stack"" msgid """" ""Name must start with a letter and may only contain letters, numbers, "" ""underscores, periods and hyphens."" msgstr """" ""Nama harus dimulai dengan huruf dan hanya dapat berisi huruf, angka, garis "" ""bawah, periode dan tanda hubung."" msgid ""Name of the stack to create."" msgstr ""Nama dari tumpukan untuk membuat."" msgid ""Next"" msgstr ""Next (berikutnya)"" msgid ""Orchestration"" msgstr ""Orchestration"" msgid ""Overview"" msgstr ""Ikhtisar"" #, python-format msgid ""Password for user \""%s\"""" msgstr ""Password untuk pengguna \""%s\"""" #, python-format msgid ""Please specify a %s using only one source method."" msgstr ""Silakan tentukan %s hanya menggunakan satu metode sumber."" msgid ""Preview"" msgstr ""Preview"" msgid ""Preview Stack"" msgstr ""Preview Stack"" msgid ""Preview Stack Details"" msgstr ""Preview Stack Details"" msgid ""Preview Stack Parameters"" msgstr ""Preview Stack Parameters"" msgid ""Preview Template"" msgstr ""Preview Template (lihat template)"" msgid ""Resource"" msgstr ""Resource"" msgid ""Resource Types"" msgstr ""Resource Types (tipe sumber daya)"" msgid ""Resources"" msgstr ""Sumber daya"" msgctxt ""current status of stack"" msgid ""Resume Complete"" msgstr ""Resume Complete"" msgctxt ""current status of stack"" msgid ""Resume Failed"" msgstr ""Resume Failed"" msgctxt ""current status of stack"" msgid ""Resume In Progress"" msgstr ""Resume In Progress"" msgid ""Resume Stack"" msgid_plural ""Resume Stacks"" msgstr[0] ""Resume Stack"" msgid ""Resumed Stack"" msgid_plural ""Resumed Stacks"" msgstr[0] ""Resumed Stack"" msgctxt ""current status of stack"" msgid ""Rollback Complete"" msgstr ""Rollback Complete"" msgctxt ""current status of stack"" msgid ""Rollback Failed"" msgstr ""Rollback Failed"" msgctxt ""current status of stack"" msgid ""Rollback In Progress"" msgstr ""Rollback In Progress"" msgid ""Rollback On Failure"" msgstr ""Rollback On Failure"" msgid ""Select Template"" msgstr ""Pilih template"" msgid ""Select a new template to preview a stack."" msgstr ""Pilih template baru untuk melihat setumpuk (stack)."" msgid ""Select a new template to re-launch a stack."" msgstr ""Pilih template baru untuk meluncurkan kembali tumpukan (stack)."" msgid ""Select a template to launch a stack."" msgstr ""Pilih template untuk meluncurkan stack."" msgctxt ""current status of stack"" msgid ""Snapshot Complete"" msgstr ""Snapshot Complete"" msgctxt ""current status of stack"" msgid ""Snapshot Failed"" msgstr ""Snapshot Failed"" msgctxt ""current status of stack"" msgid ""Snapshot In Progress"" msgstr ""Snapshot In Progress"" msgid ""Stack Events"" msgstr ""Stack Events"" msgid ""Stack ID"" msgstr ""Stack ID (ID stack)"" msgid ""Stack ID ="" msgstr ""Stack ID = (stack ID=)"" msgid ""Stack Name"" msgstr ""Stack Name (nama stack)"" msgid ""Stack Name ="" msgstr ""Stack Name ="" msgid ""Stack Resource"" msgstr ""Stack Resource"" msgid ""Stack Resource Type"" msgstr ""Stack Resource Type"" msgid ""Stack Resources"" msgstr ""Stack Resources"" msgid ""Stack creation started."" msgstr ""Pembuatan Stack mulai."" msgid ""Stack creation timeout in minutes."" msgstr ""Batas waktu pembuatan stack dalam hitungan menit."" msgid ""Stack update started."" msgstr ""Stack pembaruan mulai."" msgid ""Stacks"" msgstr ""Stacks"" msgid ""Status"" msgstr ""Status"" msgid ""Status ="" msgstr ""Status = "" msgid ""Status Reason"" msgstr ""Status Reason"" msgctxt ""current status of stack"" msgid ""Suspend Complete"" msgstr ""Suspend Complete"" msgctxt ""current status of stack"" msgid ""Suspend Failed"" msgstr ""Suspend Failed"" msgctxt ""current status of stack"" msgid ""Suspend In Progress"" msgstr ""Suspend In Progress"" msgid ""Suspend Stack"" msgid_plural ""Suspend Stacks"" msgstr[0] ""Suspend Stack"" msgid ""Suspended Stack"" msgid_plural ""Suspended Stacks"" msgstr[0] ""Suspended Stack"" msgid ""Template"" msgstr ""Template"" msgid ""Template Data"" msgstr ""Template Data"" msgid ""Template File"" msgstr ""Template File"" msgid ""Template Functions"" msgstr ""Template Functions"" msgid ""Template Source"" msgstr ""Template Source"" msgid ""Template URL"" msgstr ""URL template"" msgid ""Template Versions"" msgstr ""Template Versions"" msgid ""The raw contents of the environment file."" msgstr ""Isi baku file lingkungan."" msgid ""The raw contents of the template."" msgstr ""Isi baku template."" #, python-format msgid ""There was a problem parsing the %(prefix)s: %(error)s"" msgstr ""Ada masalah parsing (analisa) %(prefix)s: %(error)s"" msgid """" ""This is required for operations to be performed throughout the lifecycle of "" ""the stack"" msgstr """" ""Hal ini diperlukan untuk operasi yang akan dilakukan di seluruh siklus hidup "" ""stack"" msgid ""Time Since Event"" msgstr ""Time Since Event"" msgid ""Topology"" msgstr ""Topology (topologi)"" msgid ""Type"" msgstr ""Type"" msgid ""Type ="" msgstr ""Type = (tipe=)"" msgid ""URL"" msgstr ""URL"" #, python-format msgid ""Unable to get events for stack \""%s\""."" msgstr ""Tidak dapat mendapatkan events untuk stack \""%s\""."" #, python-format msgid ""Unable to get functions for template version \""%s\""."" msgstr ""Tidak dapat mendapatkan fungsi untuk versi template \""%s\""."" #, python-format msgid ""Unable to get resources for stack \""%s\""."" msgstr ""Tidak dapat mendapatkan sumber daya untuk stack \""%s\""."" msgid ""Unable to retrieve metadata."" msgstr ""Tidak dapat mengambil metadata."" msgid ""Unable to retrieve resource type details."" msgstr ""Tidak dapat mengambil rincian jenis sumber daya."" msgid ""Unable to retrieve resource."" msgstr ""Tidak dapat mengambil sumber daya."" msgid ""Unable to retrieve stack list."" msgstr ""Tidak dapat mengambil daftar stack."" msgid ""Unable to retrieve stack resource types."" msgstr ""Tidak dapat mengambil jenis sumber daya stack."" msgid ""Unable to retrieve stack template."" msgstr ""Tidak dapat mengambil template stack."" msgid ""Unable to retrieve stack."" msgstr ""Tidak dapat mengambil tumpukan (stack)."" msgid ""Unable to retrieve template functions."" msgstr ""Tidak dapat mengambil fungsi template."" msgid ""Unable to retrieve template versions."" msgstr ""Tidak dapat mengambil versi Template."" msgid ""Update"" msgstr ""Update"" msgctxt ""current status of stack"" msgid ""Update Complete"" msgstr ""Update Complete"" msgctxt ""current status of stack"" msgid ""Update Failed"" msgstr ""Update Failed"" msgctxt ""current status of stack"" msgid ""Update In Progress"" msgstr ""Update In Progress"" msgid ""Update Stack"" msgstr ""Update Stack"" msgid ""Update Stack Parameters"" msgstr ""Update Stack Parameters"" msgid ""Updated"" msgstr ""Updated"" msgid ""Version"" msgstr ""Version"" msgid ""You must specify a template via one of the available sources."" msgstr """" ""Anda harus menentukan template melalui salah satu sumber yang tersedia."" msgid ""environment"" msgstr ""environment"" msgid ""template"" msgstr ""template"" ",,7548,0
openstack%2Fqinling~master~Ia17e52ad1f7541e63b9e815b47751ad94d33e743,openstack/qinling,master,Ia17e52ad1f7541e63b9e815b47751ad94d33e743,Support to get workers by admin user,MERGED,2017-12-08 00:52:42.000000000,2017-12-13 07:29:44.000000000,2017-12-13 07:29:44.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 00:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/656dce88ff9f6dd4fcb3a4355df9fdc8319dd965', 'message': 'Support to get workers by admin user\n\nAdmin user can get current workers related to a function.\n\nChange-Id: Ia17e52ad1f7541e63b9e815b47751ad94d33e743\n'}, {'number': 2, 'created': '2017-12-09 06:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/125762c3021038ff429689fc92de3a212b00d549', 'message': 'Support to get workers by admin user\n\nAdmin user can get current workers related to a function.\n\nChange-Id: Ia17e52ad1f7541e63b9e815b47751ad94d33e743\n'}, {'number': 3, 'created': '2017-12-13 02:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/f86b6121a0595cf965614c454ba2aad6af7ef306', 'message': 'Support to get workers by admin user\n\nAdmin user can get current workers related to a function.\n\nChange-Id: Ia17e52ad1f7541e63b9e815b47751ad94d33e743\n'}, {'number': 4, 'created': '2017-12-13 06:45:39.000000000', 'files': ['qinling_tempest_plugin/functions/test_python_sleep.py', 'qinling/api/controllers/v1/function.py', 'qinling/orchestrator/kubernetes/manager.py', 'qinling_tempest_plugin/services/qinling_client.py', 'test-requirements.txt', 'qinling_tempest_plugin/tests/api/test_executions.py', 'etc/policy.json.sample', 'qinling/api/controllers/v1/resources.py', 'qinling/db/sqlalchemy/api.py', 'qinling/tests/unit/api/controllers/v1/test_function_worker.py'], 'web_link': 'https://opendev.org/openstack/qinling/commit/939ba95cc490096af620e1b7abd2f829dae021aa', 'message': 'Support to get workers by admin user\n\nAdmin user can get current workers related to a function.\n\nChange-Id: Ia17e52ad1f7541e63b9e815b47751ad94d33e743\n'}]",0,526560,939ba95cc490096af620e1b7abd2f829dae021aa,14,2,4,6732,,,0,"Support to get workers by admin user

Admin user can get current workers related to a function.

Change-Id: Ia17e52ad1f7541e63b9e815b47751ad94d33e743
",git fetch https://review.opendev.org/openstack/qinling refs/changes/60/526560/4 && git format-patch -1 --stdout FETCH_HEAD,"['qinling_tempest_plugin/functions/test_python_sleep.py', 'qinling/api/controllers/v1/function.py', 'qinling_tempest_plugin/services/qinling_client.py', 'test-requirements.txt', 'qinling_tempest_plugin/tests/api/test_executions.py', 'etc/policy.json.sample', 'qinling/api/controllers/v1/resources.py', 'qinling/tests/unit/api/controllers/v1/test_function_worker.py']",8,656dce88ff9f6dd4fcb3a4355df9fdc8319dd965,get_workers,"# Copyright 2017 Catalyst IT Limited # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from qinling.db import api as db_api from qinling.tests.unit.api import base TEST_CASE_NAME = 'TestFunctionWorkerController' class TestFunctionWorkerController(base.APITest): def setUp(self): super(TestFunctionWorkerController, self).setUp() db_func = self.create_function(prefix=TEST_CASE_NAME) self.function_id = db_func.id def test_get_all_workers(self): db_worker = db_api.create_function_worker( { 'function_id': self.function_id, 'worker_name': 'worker_1', } ) expected = { ""id"": db_worker.id, ""function_id"": self.function_id, ""worker_name"": ""worker_1"", } resp = self.app.get('/v1/functions/%s/workers' % self.function_id) self.assertEqual(200, resp.status_int) actual = self._assert_single_item( resp.json['workers'], id=db_worker.id ) self._assertDictContainsSubset(actual, expected) ",,143,4
openstack%2Fheat~master~I81e3a62c890f0ad043dd604443f56766ba6c11b4,openstack/heat,master,I81e3a62c890f0ad043dd604443f56766ba6c11b4,Remove unused variable,MERGED,2017-03-01 10:46:27.000000000,2017-12-13 07:28:43.000000000,2017-12-13 07:28:43.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7385}, {'_account_id': 12404}, {'_account_id': 18603}, {'_account_id': 19930}, {'_account_id': 22348}, {'_account_id': 26242}]","[{'number': 1, 'created': '2017-03-01 10:46:27.000000000', 'files': ['heat/objects/raw_template.py', 'heat/engine/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3aee78d863155ddab39dc18f066fc5d7e14866de', 'message': 'Remove unused variable\n\nTrivialFix\n\nChange-Id: I81e3a62c890f0ad043dd604443f56766ba6c11b4\n'}]",0,439531,3aee78d863155ddab39dc18f066fc5d7e14866de,22,8,1,18603,,,0,"Remove unused variable

TrivialFix

Change-Id: I81e3a62c890f0ad043dd604443f56766ba6c11b4
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/439531/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/objects/raw_template.py', 'heat/engine/stack.py']",2,3aee78d863155ddab39dc18f066fc5d7e14866de,, for ext_rsrc in self.ext_rsrcs_db.values():," for id, ext_rsrc in self.ext_rsrcs_db.items():",2,2
openstack%2Ftripleo-upgrade~master~I0bc03873b749dc9c15b13cacbfff78cead4360d8,openstack/tripleo-upgrade,master,I0bc03873b749dc9c15b13cacbfff78cead4360d8,Merge tripleo-upgrade repo from redhat-openstack namespace,MERGED,2017-11-30 11:16:45.000000000,2017-12-13 07:25:31.000000000,2017-12-13 07:25:31.000000000,"[{'_account_id': 3153}, {'_account_id': 8297}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-11-30 11:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/e02f4175b554c15101f64f17449b71f4bb5e1536', 'message': 'Merge tripleo-upgrade repo from redhat-openstack namespace\n\nMake sure scripts are created with the executable bit set.\n\nChange-Id: I731902411e987b4ea7c2aa84fef869fe5e1c25ae\n\nAdd a oooq comptatibility layer, documentation and example.\n\nChange-Id: I30fe6359f1c0098ff9bcdd5939724491d94ef199\n\nAdd support for applying w/a before and after upgrade\n\nThis change adds the ability to apply workarounds before and after\nthe overcloud upgrade process has finished. This allows the user\nto workaround particular issues that show up after the upgrade\nprocess has finished.\n\nChange-Id: I21a7e885bcc466af6bf80410ba2cc8d03865cb33\n\nFix missing quotes\n\nThis changes adds missing quotes to the node_upgrade_script.yml\ntemplates. Currently the task is failing because of the missing quotes.\n\nChange-Id: Ied9217df374d09bf90e6878a7c79e22042f44d99\n\nAdd support for applying workarounds post undercloud upgrade\n\nThis change adds support for applying workarounds after the undercloud\nupgrade process has finished as part of the undercloud upgrade.\n\nChange-Id: If85900969c0d591cf6024408d958a82fa8c8a534\n\nAdjust overcloud_converge_upgrade_script script\n\nThis change adjusts the overcloud_converge_upgrade_script to allow\nrunning the upgrade converge stage. In addition it adjust the ssh\nconfig file to skip host key check so the non-controller script does\nnot get stuck waiting for user input.\n\nChange-Id: Ic38f325c61e90165a5322ef754f7e5514ed8e687\n\nAppend working_dir to logs generated\n\nChange-Id: I6bc9f0c58ad8684ed03dee042e9cfb2bdc6835f6\n\nInstall ceph-ansible during undercloud upgrade\n\nceph-ansible is required to be installed manually for deployments\nwith ceph nodes. This change installs the ceph-ansible package\nbefore the undercloud upgrade.\n\nChange-Id: If8918a38250a10681d965d0715ebc17078166336\n\nUse openstack overcloud container image prepare command\n\nThis change adds the use of openstack overcloud container image prepare\ncommand for generating the environment file containing the container\nimage names and local registry address.\n\nChange-Id: I174f7e3aae415d51224cf73da83a859e90eed095\n\nDo not rely on ansible inventory for upgrading non controller nodes\n\nCurrently we are relying on the ansible inventory to provide groups\ncontaining compute nodes and their facts when creating the upgrade\nscripts. In order to remove this requirement and provide easier\nintegration this change discovers the compute and swift storage nodes\nfrom the undercloud. In addition it adds a wait loop for instance live\nmigration to complete before and after upgrading compute nodes and adds\nsupport for swift storage nodes upgrade.\n\nChange-Id: Ia4b2e81845c3fec9036c4695f0dd1746d4c5c6b8\n\nAdd silent and nobuffer options to curl command\n\nChange-Id: I0f4bd71b67d4827717d9f7d3fc075fc396eb6363\n\nAdjust tht environment files and custom roles data during upgrade\n\nThis change switches the environment files used in the overcloud deploy\ncommand to their variants used for deploying containers. In addition, if\nusing a custom roles data file for composable roles deployments, this\nchange adjusts the local roles data copy with the changes introduced in\nPike.\n\nChange-Id: Icd3c3b67342c0bd10fc3d28ed89a94fc9f714db4\n\nFix overcloud_deploy_script var location in oooq_test playbook\n\nChange-Id: I01f18a5413ff223cbca900521037e739ebc43d5d\n\nDisconnect ssh session before uploading images to local registry\n\nThis change disconnects the running ssh session in order to allow\nthe stack user to connect to the docker daemon. This acts as a\nworkaround for https://bugs.launchpad.net/tripleo/+bug/1699477\n\nChange-Id: Ia06fe8581ba17525cbcb2d955d7947b7c546811d\n\nAdd undercloud_reboot var and reboot only on ovs or kernel updates\n\nThis change adds the undercloud_reboot var to manipulate if undercloud\nreboots should be made or not and does the reboot only when kernel or\novs updates occur.\n\nChange-Id: Ic89291c5791bbd098204b2c85793335e0faa8d94\n\nAdd InfraRed docs\n\nThis change adds the steps required to run the tripleo-upgrade role\nas an InfraRed plugin.\n\nChange-Id: I08fde6c8954ec4eeedc47971607bec592fc801a1\n\nAdd docs for running the role manually from the undercloud\n\nChange-Id: I6d5bb6479b6e1fb45e34aa776d3c315cfae98ae4\n\nDo not stop services before undercloud upgrade\n\nAccording to the docs stopping services should be done by the undercloud\nupgrade process so we do not need to manually do it.\n\nChange-Id: I7f14257b4e90d3a0610c0f90e856096643325861\n\nSpecifically become_user: root when running ovs command\n\nCurrently become_user is set to the undercloud user, usually\nstack, when invoking the undercloud_validate_upgrade.yaml playbook.\nThis change overrides become_user and sets it to root when running\novs-vsctl command as it requires privilege escalation.\n\nChange-Id: Ia93245f4a2d09d73849c03401d38ffb25e7be802\n\nUse ip address instead of name when rebooting\n\nOOOQ doesn\'t set a name for the undercloud in hosts so in case the\nreboot is triggered the virthost cannot reach the undercloud. This\nchange switches the wait condition and calls the ip address instead\nof the name.\n\nChange-Id: I2121e2dabe9794d31fe70bbfa0ff8e53da6b3b1b\n\nAdd reload ssh tag to the Kill SSH task\n\nAdd a tag to the Kill SSH task so it can be avoided when\nrunning the role manually from the undercloud.\n\nChange-Id: Iec088cc174d7e8270fbea0698ee76227b45842f7\n\nAdd option to create script with --setup-heat-output option\n\nAccording to BZ#1477962 in order to be able to run non controller\nupgrade scripts after major upgrade composable steps we need to run\nthe deploy command with the --setup-heat-outputs option.\n\nChange-Id: I8137ff18047a130c5ea8dca2ce11378eabc30329\n\nAdd deprecated params to custom roles data file\n\nIn Pike there were additional flags assigned to the default roles\ndata file. This change adds these flags during the upgrade process\nto the roles defined in the custom roles data file.\n\nChange-Id: I58c2f30ff74d2302027d7488dc03c5146c371649\n\nUse a default value for the HOME env var\n\nChange-Id: I40e2f46f1311dc4b797977c8136ec4037505ef05\n\nUpdate python-openstackclient before undercloud upgrade\n\nUpdating python-openstackclient before undercloud upgrade is a\nrequirement to get undercloud upgrade passing.\n\nChange-Id: I4ab67f9af68036a29e11bb2457d70535bd94b7b0\n\nCreate environment file for injecting undercloud certificate\n\nWhen undercloud is SSL enabled the overcloud nodes need to be aware\nof the undercloud CA cert. This change creates this file during upgrade\nand adds it to the overcloud deploy commands when the overcloud nodes\nare not able to reach the undercloud ssl enabled public endpoints.\n\nChange-Id: I79a03299bc28d0ca2dbd83c28087a4c56f6b2271\n\nConvert puppet ceph parameters to ceph ansible during upgrade\n\nThis is a workaround for BZ#1488855.\n\nChange-Id: I58ac44b2166abddf56a327a4ee09457139c831da\n\nRemove setup heat outputs workaround\n\nhttps://review.openstack.org/#/c/502470/ allows us to obtain the\nRoleConfig output so there\'s no need to run the setup heat outputs\nstep anylonger. This change remove this step.\n\nChange-Id: I7235b8625eea4f77a055d0ab1862d0318f3a776f\n\nEcho bug number in workarounds script\n\nThis change replaces the bug number comments with an echo statement.\nThis provides easier way to debug what workarounds failed to apply\nwhen the workarounds script is run.\n\nChange-Id: I02c5534427ee5cf7b7af618f36577c1008d50992\n\nFix uc_keystone_conn condition\n\nThis change adds an addition condition to inject the undercloud\ncertificate in the CAMap only when  undercloud ssl is enabled.\n\nChange-Id: Iae023922bf1ed0bb22e86710b122c65a8f1568a3\n\nGather facts only from undercloud node\n\nFacts are only required for the undercloud node. This change adjusts\nthe existing playbooks to gather facts only from undercloud node in\norder to save some time and not rely on nodes which are not required\nto be reachable.\n\nChange-Id: Idceec3d10d84ef112da558109d9904a1d8c6ed93\n\nDo not include docker.yaml and docker-ha.yaml environments\n\nAs described in BZ#1466744 the docker.yaml and docker-ha.yaml\nenvironments are currently included by default so we do not need\nto specifically include them.\n\nChange-Id: I44a72ddd65cf816003ceca21ef33470a3ab125a7\n\nReboot compute nodes post upgrade\n\nAs a post upgrade requirement we need to reboot the nodes in case\nof an OVS upgrade. This change runs a post upgrade check for non\ncontroller nodes and reboots the nodes if an ovs upgrade has been\ndetected. It also adds additional validation for compute nodes to\nmake sure that the nova-compute service is enabled after reboot.\n\nChange-Id: I583e589118aabae84f8e1dc9ec2c4b43ca17a250\n\nAdd L3 agent connectivity check during upgrade\n\nThis change adds a check which validates that ICMP\nconnectivity with a floating IP is not interrupted\nduring the major upgrade composable step.\n\nChange-Id: Iee55af85b9a2c3ece86731e043130d191ff6a821\n\nRun pre docker composable upgrade workarounds at correct position\n\nThis change moves the pre docker composable upgrade workarounds to\nbe run right before the docker composable upgrade step.\n\nChange-Id: I604ea2eb6202d48b0f771ea80e5e731df687600e\n\nUse bool with ansible booleans\n\nuse bool filter when using ansible booleans.\n\nChange-Id: Ibeb59772e935cc28a661ccddcaa4773388ce296d\n\nAdd option for creating workloads before upgrade\n\nThis change adds the option to launch an instance before\nstarting upgrade. This operation is useful when doing\ntests such as instance live migration during upgrade or\nfloating ip connectivity testing during upgrade. The\nscript requires a network defined in the external_network_name\nvar which provides external connectivity to exist beforehand.\n\nChange-Id: Ib39e41b36fac7794ea515c8a9d56141866dcfeed\n\nFix pre compute upgrade check\n\nThis change adds the MIGRATING state to be checked before the\ncompute nodes upgrade.\n\nChange-Id: I0073a7e69a71a044882d4760dbb49cd4f455dd89\n\nFix workload_launch position\n\nChange-Id: I6193ac6a60165bb20ece6277067c05696ed6d3b1\n\nRun non controller node pre upgrade script\n\nThis change runs the non controller node pre upgrade script.\nIn addition it exposes the option to run instances migration\nbetween compute nodes during upgrade.\n\nChange-Id: Ief55eecdc85bb620f637c4ed4d9b5bc3243b37d1\n\nUpdate roles_data adjustments to latest changes\n\nThis change updates the roles_data file adjustments to the latest\nchanges.\n\nChange-Id: Ic787b135cdf96b33829e05140e069b398df7196f\n\nUse docker and docker-ha environment files for upstream deployments\n\nChange-Id: I70bb9767e97f616729adff983fff065858a6dcdc\n\nConvert services environments to services-docker only for upstream\n\nPer BZ#116463 in downstream the environments used for extra service\nenablement now point to docker resources.\n\nChange-Id: I379622ec2749ac8b485aec79a7500308ef74214e\n\nEcho debug message to differentiate live migration from block\n\nChange-Id: I69e7f381543d84fcd308acbd3a90f5d0ac23ae1b\n\nAccept <= 5% ICMP packet loss during upgrade connectivity check\n\nChange-Id: I34d1de225c0e391035e22e18f63356e04afbbfd5\n\nReorganize playbooks to separate upgrade/update\n\nThis change adds separate directories for upgrade/update which\nprovides a better separation between updates and upgrades.\n\nChange-Id: Icf1a09514fb0e6236535ae32265bbd3805918478\n\nRun block migrate multiple times\n\nBlock migrate doesn\'t work seem to work if triggered once but it\ndoes if the command is run for a second time. This change runs the\nblock migrate command multiple times to make sure that the instance\ngets migrated.\n\nChange-Id: I8b9a9ecae21f7ce49a03945afec66b9e671622b7\n\nEnsure files/ are part of the setup.cfg files to copy\n\nWhen installing tripleo-upgrade into a .quickstart\nenvironment, the files/ folder wasn\'t getting copied, which is necessary\nat least for ""adjust ssh config to skip host key check"" in\ncreate-upgrade-scripts.yaml.\n\nChange-Id: I7d862ec5c13ba719923c90cc40790b842b582999\n\nAdd tasks for undercloud minor update\n\nStart adding the minor undercloud update tasks\n\nChange-Id: I33705b270e2d5e6a28f1cad8179e1f4b3e4ea975\n\nRemove timeouts from upgrade scripts\n\nDepending on the number of deployed nodes upgrade could take longer\nand we want to rely on the heat stack timeout. This change clears\nany manual timeouts set in the upgrade scripts.\n\nChange-Id: I5d141e2cc13621d3be5fb0c27b0ac3c3fc30d424\n\nMinor updates of RHOS 12.\n\nManage minor update workflow from within tripleo-upgrade repo.\n\nChange-Id: I8c6771af4825ce166e8470413ca4687be0a58cb9\n\nReboot controller nodes post upgrade\n\nThis change adds the option to reboot controller nodes post upgrade\nand performs basic verifications that the clustered services are\nreported as up.\n\nChange-Id: I370d421e5968ae50bd1ff140cdfcf98a4db03a5f\n\nDon\'t force ssh_config on everybody.\n\nThis add an option to be able to not overwrite the ssh_config file.\nAs a side note the ssh_config is missing from the repo, so by default\nthis task is broken.\n\nChange-Id: Idfb78e2b7226a7e6295acd3f250bbfb48d0a103d\n\nFix filter used in the node upgrade scripts\n\nThis change is fixes the current filter used for node upgrade\nscripts so that deployment with $domain.tld format are supported.\n\nChange-Id: I18f43c440bb93e0fcefb664c7d716ff9368673a4\n\nRun live migration multiple times\n\nChange-Id: I7c028defd3cb9080efa7bdbe9daa6ed201df8640\n\nManually inject undercloud SSL cert to overcloud nodes\n\nPer BZ#1501779 the compute nodes do not get their trusted store\nupdated when using a CAMap and upgrade fails. This change updates\nthe overcloud nodes trusted store manually so the overcloud nodes\nare prepared for update. This should translate in a documentation\nstep that before upgrade starts the user needs to make  sure the\novercloud nodes are able to reach the undercloud SSL public\nendpoint.\n\nChange-Id: Ib95a29c608803504a866ae71cbc0082faf3c194f\n\nReplace puppet external ceph environment with ceph-ansible one\n\nThis change replaces during the upgrade the external ceph puppet\nenvironment file with its ceph-ansible equivalent.\n\nChange-Id: I9020e8f7c43f91259b551caa2e20f03be1424106\n\nAppend deprecated params only to predefined roles\n\nWe should append the deprecated params only to predefined roles\nin order to avoid failures such as reported in BZ#1501237.\n\nChange-Id: I3a7c332b35da9639fb6f8e5b38234dc0c55d8499\n\nSplit the post controller scripts into per services scripts\n\nThis change splits the post upgrade controller scripts into\nper service checks and adds them to a common directory so\nthey can be shared between update and upgrade.\n\nChange-Id: I8f2fb6162a5acb8a92057400a7b04e6e2388abaa\n\nAdd the ability to specify a remote docker registry\n\nThis change adds the ability to specify a remote docker registry\nto be used for downloading the Docker images on the undercloud or\nbe used directly by the overcloud nodes during upgrade.\n\nChange-Id: I132a8b94f9a101d1c9c624d202bb01527dc2b844\n\nFix BZ#1499677 workaround condition\n\nIn addition to empty gvwstate.dat file there might be situations\nwhere the gvwstate.dat file is missing after reboot. This patch\naddresses this condition for BZ#1499677 workaround.\n\nChange-Id: I295b133248f48ab41b1748225cbe9359662b280d\n\nCleanup galera resource instead of rebooting node for BZ#1499677\n\nInstead of rebooting the node while implementing the workaround for\nBZ#1499677 we should simply cleanup the Galera resource. This way\nwe can save some time and potential issues caused by an additional\nreboot.\n\nChange-Id: I391daeae41321baec1cbd8c458132a3161cd96d5\n\n[UPDATES] Introduce option for minor updates workarounds.\n\nTo speed up testing of minor updates it might be required\n to apply some patches before they are landed.\nHence we need a flag to differentiate if workarounds are required\n or not\n\nChange-Id: I642e4ade204f5fd30ec9433f1d90a2d539287c5e\n\nDo not pipe curl output in container images environment script\n\nCurl can sometimes exit with exit code 23 when its output is piped\ninto another command. To avoid this errors we save the curl output\nto a file.\n\nChange-Id: I4123b6c66ae2873c11631f229cb8e3eec5a5a66b\n\nUse service environment files when generating the images environment\n\nIn the last build openstack overcloud container image prepare only\ngenerates the parameters for the services included by default. In\norder to make it work when extra non-default services are enabled\nwe need to pass the environment files to the prepare command. This\nchange addresses this issue.\n\nChange-Id: I86ab6faaffcd4c7cc1a07e9a6ed1e890cb5cf980\n\nPlace the oooq deploy command into overcloud_deploy_script var\n\nThis change places the openstack overcloud deploy command with its\narguments in the location defined by the overcloud_deploy_script\nvar. This way we don\'t require oooq users to specifically set the\novercloud_deploy_script to a hardcoded location and make it less\nconfusing.\n\nChange-Id: Id2b14fcffbd169c342df4b5b9105dff81e18e3a0\n\nReplace ceph radosgw environment during upgrade\n\nChange-Id: I489211f39941bba5b1ca2ddf1b635c3bdb0151fe\n\nAvoid losing undercloud connection in TripleO CI.\n\nWhen running the role in the TripleO upstream CI\nthe connectivity to the undercloud gets lost when\nrebooting the undercloud after upgrade or killing\nthe ssh service, this makes the playbook fail.\n\nAs a solution, a flag tripleo_ci has been added.\nThis flag will default to false, and when set to\ntrue no undercloud reboot, nor ssh killing will\nbe executed.\n\nChange-Id: If4a303fff49bbe55cdfb7142d8dd69264ab47ab4\n\nAlign deployment-files option with IR.\n\ndeployment-files option is not a list of choices in IR,\nadjust it accordingly.\n\nChange-Id: I6889e9b75f842cc466278fed5dbf85a80cb58ee0\n\nAppend docker-ha only when needed.\n\nBefore appending the docker-ha.yaml env\nfile, we need to check if the overcloud\nwas deployed with pacemaker. If so, then\nwe\'ll add the env file to the upgrade\nscript.\n\nChange-Id: I9867d86b6d23385c576d2f8c5a25ab3333f7113d\n\nSpecify tht directory used in upgrade script.\n\nWhen deploying with oooq, the generated script\novercloud-deploy.sh is reused in order to append\nthe cooresponding env files for the upgrade.\n\nHowever, if the location of the tripleo-heat-templates\ndirectory is different from the used when deploying\nthen the upgrade does not succeed.\n\nThis change modifies the tripleo-heat-templates\nlocation used to upgrade when the directory found\nin overcloud-deploy.sh is different. If it is the\nsame no change is done.\n\nChange-Id: I55ada3e75b7463b1c14c8734410d2591cf162e67\n\nDon\'t append DockerInsecureRegistryAddress\n\nThis is no longer required as the prepare command detects whether the\nregistry is secure and DockerInsecureRegistryAddress as necessary.\n\nDepends on upstream https://review.openstack.org/#/c/514473/\nRelated-Bug: #1722632\n\nChange-Id: Ia9d91f6280600c59d0079c5d1f26a00f04040426\n\nFix the controller regex during roles_data conversion\n\nThe Ocata roles_data controller role might include a comment for\nthe controller role name. This change adjusts the regexp used during\nthe roles data conversion to take into consideration that comment.\n\nChange-Id: I7b43b1fcb9e477de8e1265ef6aa6ba5149e82d47\n\nUse prepare --set for ceph image parameter\n\nThis is more maintainable, and consistent with other uses of prepare.\n\nChange-Id: Ieec88e271973a248192c2b247cd2c5e0cccbfb7c\n\nAdd storage environment files to be used for containers prepare\n\nThis change adds the storage environments files to be matched when\ncreating the environment file containing the Docker images names\nwhich gets created via container image prepare.\n\nChange-Id: I34c3cdaab1b63ce3f43d748372d35143bc12b8b4\n\nAdd environment file containing required DPDK changes during upgrade\n\nChange-Id: Iabaf16e18ee7546bd6275f8f84226892423a6c95\n\nCreate failed_upgrade log files.\n\nMost of the stack failures in the TripleO\nCI are registered inside two log files\nfailed_upgrade_list.log and failed_upgrade.log.\n\nThis patch adds the option of inject the\nstack failures list command into these two\nlog files, as well as priting out the detailed\nstack failure list (--long).\n\nChange-Id: I4fad989818f67ad0a73e45b47f835750f18c3bb6\n\nReplace storage-environemnt.yaml for upstream only\n\nPer BZ#1502862 the Ceph environment files switch during upgrade is\nonly needed for upstream deployments. This change does the changes\nto accommodate this.\n\nChange-Id: Ia3adb120c9b524c66d069593b0779b3399295fd4\n\nDo not update python-openstackclient before upgrade\n\nBZ#1488471 was fixed so there\'s no need to update the python-\nopenstackclient package before upgrade.\n\nChange-Id: I2aba7515ec43926ec4f8de5c701467dea31dba1b\n\nBe more aggressive on accepted packet loss during upgrade\n\nTests have shown that the packet loss shouldn\'t eceed 1% during\nthe upgrade steps. This change adjusts the accepted level to this.\n\nChange-Id: I9e47ea56a78e4e9eab40fca609cbedaecfcf1e14\n\nAdd more tags for the upgrade process.\n\nThis enable one to either do only a small part of the whole process.\nThis can be useful for debugging or development.\n\nChange-Id: Ic6cc9a1e6aa2793fde65636d2ad92bc174173252\n\nUse new method of discovering tag and adjust local registry upload\n\nThis change uses the new mechanism of retrieving the tag from the\nlatest image provided in the registry.\n\nChange-Id: I7e063f13c7d4812e9986452774881235b620bd0e\n\nSwap baremetal environment file for containerized.\n\nIn oooq, when upgrading from baremetal\nto containerized overcloud two different\nenvironment files are used. These env\nfiles are located in [0].\n\nWhen upgrading using tripleo-upgrade, we\nneed to convert that environment file name\nto its corresponding containers version.\n\n[0] https://github.com/openstack/tripleo-heat-templates/tree/master/ci/environments\n\nChange-Id: I6c9fad2f402a162cf663c5089e79c2e10f3d0928\n\nAdd condition to create local docker registry.\n\nThe only way to not execute the docker\nregistry environment file creation task\nis via tags, which is not easy to handle\nin TripleO CI.\n\nAs tripleo-quickstart already prepares\nthe local docker registry file, there\nis no need to execute it. So a new\nparameter \'create_docker_registry\' is\nbeen added.\n\nAlso, the \'force\' option is being added\nto avoid overwritting a provided script\nwith the role template.\n\nChange-Id: I800d6696b8dbb83f05f3d9381c6e5689558f4b77\n\nPrepare workloads before update/upgrade.\n\nPrepare scripts for managing workload on oc before running\n update/upgrade operation.\n\nAllow to run ping test during minor update.\n\nChange-Id: I1d5754f36f53588c97c646aa4e1380e9ca5938bc\n\nRemove tag parsing from the image prepare command\n\nParsing the tag is not needed anymore and the one returned by the\ncontainer image prepare command can be used.\n\nChange-Id: If782fc655da7b22e4d4a803509e9cc8c49774368\n\n[UPDATES] Run minor update per role.\n\nWith recent changes it\'s advised to perform minor update in batches:\nrole-by-role.\nThis change limits the scope of update with \'--nodes <Role>\' option.\n\nChange-Id: I0bc03873b749dc9c15b13cacbfff78cead4360d8\n'}, {'number': 2, 'created': '2017-12-08 19:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/02cd18aab4106d16135be08f3624a73b5f68c648', 'message': 'Merge tripleo-upgrade repo from redhat-openstack namespace\n\nMake sure scripts are created with the executable bit set.\n\nChange-Id: I731902411e987b4ea7c2aa84fef869fe5e1c25ae\n\nAdd a oooq comptatibility layer, documentation and example.\n\nChange-Id: I30fe6359f1c0098ff9bcdd5939724491d94ef199\n\nAdd support for applying w/a before and after upgrade\n\nThis change adds the ability to apply workarounds before and after\nthe overcloud upgrade process has finished. This allows the user\nto workaround particular issues that show up after the upgrade\nprocess has finished.\n\nChange-Id: I21a7e885bcc466af6bf80410ba2cc8d03865cb33\n\nFix missing quotes\n\nThis changes adds missing quotes to the node_upgrade_script.yml\ntemplates. Currently the task is failing because of the missing quotes.\n\nChange-Id: Ied9217df374d09bf90e6878a7c79e22042f44d99\n\nAdd support for applying workarounds post undercloud upgrade\n\nThis change adds support for applying workarounds after the undercloud\nupgrade process has finished as part of the undercloud upgrade.\n\nChange-Id: If85900969c0d591cf6024408d958a82fa8c8a534\n\nAdjust overcloud_converge_upgrade_script script\n\nThis change adjusts the overcloud_converge_upgrade_script to allow\nrunning the upgrade converge stage. In addition it adjust the ssh\nconfig file to skip host key check so the non-controller script does\nnot get stuck waiting for user input.\n\nChange-Id: Ic38f325c61e90165a5322ef754f7e5514ed8e687\n\nAppend working_dir to logs generated\n\nChange-Id: I6bc9f0c58ad8684ed03dee042e9cfb2bdc6835f6\n\nInstall ceph-ansible during undercloud upgrade\n\nceph-ansible is required to be installed manually for deployments\nwith ceph nodes. This change installs the ceph-ansible package\nbefore the undercloud upgrade.\n\nChange-Id: If8918a38250a10681d965d0715ebc17078166336\n\nUse openstack overcloud container image prepare command\n\nThis change adds the use of openstack overcloud container image prepare\ncommand for generating the environment file containing the container\nimage names and local registry address.\n\nChange-Id: I174f7e3aae415d51224cf73da83a859e90eed095\n\nDo not rely on ansible inventory for upgrading non controller nodes\n\nCurrently we are relying on the ansible inventory to provide groups\ncontaining compute nodes and their facts when creating the upgrade\nscripts. In order to remove this requirement and provide easier\nintegration this change discovers the compute and swift storage nodes\nfrom the undercloud. In addition it adds a wait loop for instance live\nmigration to complete before and after upgrading compute nodes and adds\nsupport for swift storage nodes upgrade.\n\nChange-Id: Ia4b2e81845c3fec9036c4695f0dd1746d4c5c6b8\n\nAdd silent and nobuffer options to curl command\n\nChange-Id: I0f4bd71b67d4827717d9f7d3fc075fc396eb6363\n\nAdjust tht environment files and custom roles data during upgrade\n\nThis change switches the environment files used in the overcloud deploy\ncommand to their variants used for deploying containers. In addition, if\nusing a custom roles data file for composable roles deployments, this\nchange adjusts the local roles data copy with the changes introduced in\nPike.\n\nChange-Id: Icd3c3b67342c0bd10fc3d28ed89a94fc9f714db4\n\nFix overcloud_deploy_script var location in oooq_test playbook\n\nChange-Id: I01f18a5413ff223cbca900521037e739ebc43d5d\n\nDisconnect ssh session before uploading images to local registry\n\nThis change disconnects the running ssh session in order to allow\nthe stack user to connect to the docker daemon. This acts as a\nworkaround for https://bugs.launchpad.net/tripleo/+bug/1699477\n\nChange-Id: Ia06fe8581ba17525cbcb2d955d7947b7c546811d\n\nAdd undercloud_reboot var and reboot only on ovs or kernel updates\n\nThis change adds the undercloud_reboot var to manipulate if undercloud\nreboots should be made or not and does the reboot only when kernel or\novs updates occur.\n\nChange-Id: Ic89291c5791bbd098204b2c85793335e0faa8d94\n\nAdd InfraRed docs\n\nThis change adds the steps required to run the tripleo-upgrade role\nas an InfraRed plugin.\n\nChange-Id: I08fde6c8954ec4eeedc47971607bec592fc801a1\n\nAdd docs for running the role manually from the undercloud\n\nChange-Id: I6d5bb6479b6e1fb45e34aa776d3c315cfae98ae4\n\nDo not stop services before undercloud upgrade\n\nAccording to the docs stopping services should be done by the undercloud\nupgrade process so we do not need to manually do it.\n\nChange-Id: I7f14257b4e90d3a0610c0f90e856096643325861\n\nSpecifically become_user: root when running ovs command\n\nCurrently become_user is set to the undercloud user, usually\nstack, when invoking the undercloud_validate_upgrade.yaml playbook.\nThis change overrides become_user and sets it to root when running\novs-vsctl command as it requires privilege escalation.\n\nChange-Id: Ia93245f4a2d09d73849c03401d38ffb25e7be802\n\nUse ip address instead of name when rebooting\n\nOOOQ doesn\'t set a name for the undercloud in hosts so in case the\nreboot is triggered the virthost cannot reach the undercloud. This\nchange switches the wait condition and calls the ip address instead\nof the name.\n\nChange-Id: I2121e2dabe9794d31fe70bbfa0ff8e53da6b3b1b\n\nAdd reload ssh tag to the Kill SSH task\n\nAdd a tag to the Kill SSH task so it can be avoided when\nrunning the role manually from the undercloud.\n\nChange-Id: Iec088cc174d7e8270fbea0698ee76227b45842f7\n\nAdd option to create script with --setup-heat-output option\n\nAccording to BZ#1477962 in order to be able to run non controller\nupgrade scripts after major upgrade composable steps we need to run\nthe deploy command with the --setup-heat-outputs option.\n\nChange-Id: I8137ff18047a130c5ea8dca2ce11378eabc30329\n\nAdd deprecated params to custom roles data file\n\nIn Pike there were additional flags assigned to the default roles\ndata file. This change adds these flags during the upgrade process\nto the roles defined in the custom roles data file.\n\nChange-Id: I58c2f30ff74d2302027d7488dc03c5146c371649\n\nUse a default value for the HOME env var\n\nChange-Id: I40e2f46f1311dc4b797977c8136ec4037505ef05\n\nUpdate python-openstackclient before undercloud upgrade\n\nUpdating python-openstackclient before undercloud upgrade is a\nrequirement to get undercloud upgrade passing.\n\nChange-Id: I4ab67f9af68036a29e11bb2457d70535bd94b7b0\n\nCreate environment file for injecting undercloud certificate\n\nWhen undercloud is SSL enabled the overcloud nodes need to be aware\nof the undercloud CA cert. This change creates this file during upgrade\nand adds it to the overcloud deploy commands when the overcloud nodes\nare not able to reach the undercloud ssl enabled public endpoints.\n\nChange-Id: I79a03299bc28d0ca2dbd83c28087a4c56f6b2271\n\nConvert puppet ceph parameters to ceph ansible during upgrade\n\nThis is a workaround for BZ#1488855.\n\nChange-Id: I58ac44b2166abddf56a327a4ee09457139c831da\n\nRemove setup heat outputs workaround\n\nhttps://review.openstack.org/#/c/502470/ allows us to obtain the\nRoleConfig output so there\'s no need to run the setup heat outputs\nstep anylonger. This change remove this step.\n\nChange-Id: I7235b8625eea4f77a055d0ab1862d0318f3a776f\n\nEcho bug number in workarounds script\n\nThis change replaces the bug number comments with an echo statement.\nThis provides easier way to debug what workarounds failed to apply\nwhen the workarounds script is run.\n\nChange-Id: I02c5534427ee5cf7b7af618f36577c1008d50992\n\nFix uc_keystone_conn condition\n\nThis change adds an addition condition to inject the undercloud\ncertificate in the CAMap only when  undercloud ssl is enabled.\n\nChange-Id: Iae023922bf1ed0bb22e86710b122c65a8f1568a3\n\nGather facts only from undercloud node\n\nFacts are only required for the undercloud node. This change adjusts\nthe existing playbooks to gather facts only from undercloud node in\norder to save some time and not rely on nodes which are not required\nto be reachable.\n\nChange-Id: Idceec3d10d84ef112da558109d9904a1d8c6ed93\n\nDo not include docker.yaml and docker-ha.yaml environments\n\nAs described in BZ#1466744 the docker.yaml and docker-ha.yaml\nenvironments are currently included by default so we do not need\nto specifically include them.\n\nChange-Id: I44a72ddd65cf816003ceca21ef33470a3ab125a7\n\nReboot compute nodes post upgrade\n\nAs a post upgrade requirement we need to reboot the nodes in case\nof an OVS upgrade. This change runs a post upgrade check for non\ncontroller nodes and reboots the nodes if an ovs upgrade has been\ndetected. It also adds additional validation for compute nodes to\nmake sure that the nova-compute service is enabled after reboot.\n\nChange-Id: I583e589118aabae84f8e1dc9ec2c4b43ca17a250\n\nAdd L3 agent connectivity check during upgrade\n\nThis change adds a check which validates that ICMP\nconnectivity with a floating IP is not interrupted\nduring the major upgrade composable step.\n\nChange-Id: Iee55af85b9a2c3ece86731e043130d191ff6a821\n\nRun pre docker composable upgrade workarounds at correct position\n\nThis change moves the pre docker composable upgrade workarounds to\nbe run right before the docker composable upgrade step.\n\nChange-Id: I604ea2eb6202d48b0f771ea80e5e731df687600e\n\nUse bool with ansible booleans\n\nuse bool filter when using ansible booleans.\n\nChange-Id: Ibeb59772e935cc28a661ccddcaa4773388ce296d\n\nAdd option for creating workloads before upgrade\n\nThis change adds the option to launch an instance before\nstarting upgrade. This operation is useful when doing\ntests such as instance live migration during upgrade or\nfloating ip connectivity testing during upgrade. The\nscript requires a network defined in the external_network_name\nvar which provides external connectivity to exist beforehand.\n\nChange-Id: Ib39e41b36fac7794ea515c8a9d56141866dcfeed\n\nFix pre compute upgrade check\n\nThis change adds the MIGRATING state to be checked before the\ncompute nodes upgrade.\n\nChange-Id: I0073a7e69a71a044882d4760dbb49cd4f455dd89\n\nFix workload_launch position\n\nChange-Id: I6193ac6a60165bb20ece6277067c05696ed6d3b1\n\nRun non controller node pre upgrade script\n\nThis change runs the non controller node pre upgrade script.\nIn addition it exposes the option to run instances migration\nbetween compute nodes during upgrade.\n\nChange-Id: Ief55eecdc85bb620f637c4ed4d9b5bc3243b37d1\n\nUpdate roles_data adjustments to latest changes\n\nThis change updates the roles_data file adjustments to the latest\nchanges.\n\nChange-Id: Ic787b135cdf96b33829e05140e069b398df7196f\n\nUse docker and docker-ha environment files for upstream deployments\n\nChange-Id: I70bb9767e97f616729adff983fff065858a6dcdc\n\nConvert services environments to services-docker only for upstream\n\nPer BZ#116463 in downstream the environments used for extra service\nenablement now point to docker resources.\n\nChange-Id: I379622ec2749ac8b485aec79a7500308ef74214e\n\nEcho debug message to differentiate live migration from block\n\nChange-Id: I69e7f381543d84fcd308acbd3a90f5d0ac23ae1b\n\nAccept <= 5% ICMP packet loss during upgrade connectivity check\n\nChange-Id: I34d1de225c0e391035e22e18f63356e04afbbfd5\n\nReorganize playbooks to separate upgrade/update\n\nThis change adds separate directories for upgrade/update which\nprovides a better separation between updates and upgrades.\n\nChange-Id: Icf1a09514fb0e6236535ae32265bbd3805918478\n\nRun block migrate multiple times\n\nBlock migrate doesn\'t work seem to work if triggered once but it\ndoes if the command is run for a second time. This change runs the\nblock migrate command multiple times to make sure that the instance\ngets migrated.\n\nChange-Id: I8b9a9ecae21f7ce49a03945afec66b9e671622b7\n\nEnsure files/ are part of the setup.cfg files to copy\n\nWhen installing tripleo-upgrade into a .quickstart\nenvironment, the files/ folder wasn\'t getting copied, which is necessary\nat least for ""adjust ssh config to skip host key check"" in\ncreate-upgrade-scripts.yaml.\n\nChange-Id: I7d862ec5c13ba719923c90cc40790b842b582999\n\nAdd tasks for undercloud minor update\n\nStart adding the minor undercloud update tasks\n\nChange-Id: I33705b270e2d5e6a28f1cad8179e1f4b3e4ea975\n\nRemove timeouts from upgrade scripts\n\nDepending on the number of deployed nodes upgrade could take longer\nand we want to rely on the heat stack timeout. This change clears\nany manual timeouts set in the upgrade scripts.\n\nChange-Id: I5d141e2cc13621d3be5fb0c27b0ac3c3fc30d424\n\nMinor updates of RHOS 12.\n\nManage minor update workflow from within tripleo-upgrade repo.\n\nChange-Id: I8c6771af4825ce166e8470413ca4687be0a58cb9\n\nReboot controller nodes post upgrade\n\nThis change adds the option to reboot controller nodes post upgrade\nand performs basic verifications that the clustered services are\nreported as up.\n\nChange-Id: I370d421e5968ae50bd1ff140cdfcf98a4db03a5f\n\nDon\'t force ssh_config on everybody.\n\nThis add an option to be able to not overwrite the ssh_config file.\nAs a side note the ssh_config is missing from the repo, so by default\nthis task is broken.\n\nChange-Id: Idfb78e2b7226a7e6295acd3f250bbfb48d0a103d\n\nFix filter used in the node upgrade scripts\n\nThis change is fixes the current filter used for node upgrade\nscripts so that deployment with $domain.tld format are supported.\n\nChange-Id: I18f43c440bb93e0fcefb664c7d716ff9368673a4\n\nRun live migration multiple times\n\nChange-Id: I7c028defd3cb9080efa7bdbe9daa6ed201df8640\n\nManually inject undercloud SSL cert to overcloud nodes\n\nPer BZ#1501779 the compute nodes do not get their trusted store\nupdated when using a CAMap and upgrade fails. This change updates\nthe overcloud nodes trusted store manually so the overcloud nodes\nare prepared for update. This should translate in a documentation\nstep that before upgrade starts the user needs to make  sure the\novercloud nodes are able to reach the undercloud SSL public\nendpoint.\n\nChange-Id: Ib95a29c608803504a866ae71cbc0082faf3c194f\n\nReplace puppet external ceph environment with ceph-ansible one\n\nThis change replaces during the upgrade the external ceph puppet\nenvironment file with its ceph-ansible equivalent.\n\nChange-Id: I9020e8f7c43f91259b551caa2e20f03be1424106\n\nAppend deprecated params only to predefined roles\n\nWe should append the deprecated params only to predefined roles\nin order to avoid failures such as reported in BZ#1501237.\n\nChange-Id: I3a7c332b35da9639fb6f8e5b38234dc0c55d8499\n\nSplit the post controller scripts into per services scripts\n\nThis change splits the post upgrade controller scripts into\nper service checks and adds them to a common directory so\nthey can be shared between update and upgrade.\n\nChange-Id: I8f2fb6162a5acb8a92057400a7b04e6e2388abaa\n\nAdd the ability to specify a remote docker registry\n\nThis change adds the ability to specify a remote docker registry\nto be used for downloading the Docker images on the undercloud or\nbe used directly by the overcloud nodes during upgrade.\n\nChange-Id: I132a8b94f9a101d1c9c624d202bb01527dc2b844\n\nFix BZ#1499677 workaround condition\n\nIn addition to empty gvwstate.dat file there might be situations\nwhere the gvwstate.dat file is missing after reboot. This patch\naddresses this condition for BZ#1499677 workaround.\n\nChange-Id: I295b133248f48ab41b1748225cbe9359662b280d\n\nCleanup galera resource instead of rebooting node for BZ#1499677\n\nInstead of rebooting the node while implementing the workaround for\nBZ#1499677 we should simply cleanup the Galera resource. This way\nwe can save some time and potential issues caused by an additional\nreboot.\n\nChange-Id: I391daeae41321baec1cbd8c458132a3161cd96d5\n\n[UPDATES] Introduce option for minor updates workarounds.\n\nTo speed up testing of minor updates it might be required\n to apply some patches before they are landed.\nHence we need a flag to differentiate if workarounds are required\n or not\n\nChange-Id: I642e4ade204f5fd30ec9433f1d90a2d539287c5e\n\nDo not pipe curl output in container images environment script\n\nCurl can sometimes exit with exit code 23 when its output is piped\ninto another command. To avoid this errors we save the curl output\nto a file.\n\nChange-Id: I4123b6c66ae2873c11631f229cb8e3eec5a5a66b\n\nUse service environment files when generating the images environment\n\nIn the last build openstack overcloud container image prepare only\ngenerates the parameters for the services included by default. In\norder to make it work when extra non-default services are enabled\nwe need to pass the environment files to the prepare command. This\nchange addresses this issue.\n\nChange-Id: I86ab6faaffcd4c7cc1a07e9a6ed1e890cb5cf980\n\nPlace the oooq deploy command into overcloud_deploy_script var\n\nThis change places the openstack overcloud deploy command with its\narguments in the location defined by the overcloud_deploy_script\nvar. This way we don\'t require oooq users to specifically set the\novercloud_deploy_script to a hardcoded location and make it less\nconfusing.\n\nChange-Id: Id2b14fcffbd169c342df4b5b9105dff81e18e3a0\n\nReplace ceph radosgw environment during upgrade\n\nChange-Id: I489211f39941bba5b1ca2ddf1b635c3bdb0151fe\n\nAvoid losing undercloud connection in TripleO CI.\n\nWhen running the role in the TripleO upstream CI\nthe connectivity to the undercloud gets lost when\nrebooting the undercloud after upgrade or killing\nthe ssh service, this makes the playbook fail.\n\nAs a solution, a flag tripleo_ci has been added.\nThis flag will default to false, and when set to\ntrue no undercloud reboot, nor ssh killing will\nbe executed.\n\nChange-Id: If4a303fff49bbe55cdfb7142d8dd69264ab47ab4\n\nAlign deployment-files option with IR.\n\ndeployment-files option is not a list of choices in IR,\nadjust it accordingly.\n\nChange-Id: I6889e9b75f842cc466278fed5dbf85a80cb58ee0\n\nAppend docker-ha only when needed.\n\nBefore appending the docker-ha.yaml env\nfile, we need to check if the overcloud\nwas deployed with pacemaker. If so, then\nwe\'ll add the env file to the upgrade\nscript.\n\nChange-Id: I9867d86b6d23385c576d2f8c5a25ab3333f7113d\n\nSpecify tht directory used in upgrade script.\n\nWhen deploying with oooq, the generated script\novercloud-deploy.sh is reused in order to append\nthe cooresponding env files for the upgrade.\n\nHowever, if the location of the tripleo-heat-templates\ndirectory is different from the used when deploying\nthen the upgrade does not succeed.\n\nThis change modifies the tripleo-heat-templates\nlocation used to upgrade when the directory found\nin overcloud-deploy.sh is different. If it is the\nsame no change is done.\n\nChange-Id: I55ada3e75b7463b1c14c8734410d2591cf162e67\n\nDon\'t append DockerInsecureRegistryAddress\n\nThis is no longer required as the prepare command detects whether the\nregistry is secure and DockerInsecureRegistryAddress as necessary.\n\nDepends on upstream https://review.openstack.org/#/c/514473/\nRelated-Bug: #1722632\n\nChange-Id: Ia9d91f6280600c59d0079c5d1f26a00f04040426\n\nFix the controller regex during roles_data conversion\n\nThe Ocata roles_data controller role might include a comment for\nthe controller role name. This change adjusts the regexp used during\nthe roles data conversion to take into consideration that comment.\n\nChange-Id: I7b43b1fcb9e477de8e1265ef6aa6ba5149e82d47\n\nUse prepare --set for ceph image parameter\n\nThis is more maintainable, and consistent with other uses of prepare.\n\nChange-Id: Ieec88e271973a248192c2b247cd2c5e0cccbfb7c\n\nAdd storage environment files to be used for containers prepare\n\nThis change adds the storage environments files to be matched when\ncreating the environment file containing the Docker images names\nwhich gets created via container image prepare.\n\nChange-Id: I34c3cdaab1b63ce3f43d748372d35143bc12b8b4\n\nAdd environment file containing required DPDK changes during upgrade\n\nChange-Id: Iabaf16e18ee7546bd6275f8f84226892423a6c95\n\nCreate failed_upgrade log files.\n\nMost of the stack failures in the TripleO\nCI are registered inside two log files\nfailed_upgrade_list.log and failed_upgrade.log.\n\nThis patch adds the option of inject the\nstack failures list command into these two\nlog files, as well as priting out the detailed\nstack failure list (--long).\n\nChange-Id: I4fad989818f67ad0a73e45b47f835750f18c3bb6\n\nReplace storage-environemnt.yaml for upstream only\n\nPer BZ#1502862 the Ceph environment files switch during upgrade is\nonly needed for upstream deployments. This change does the changes\nto accommodate this.\n\nChange-Id: Ia3adb120c9b524c66d069593b0779b3399295fd4\n\nDo not update python-openstackclient before upgrade\n\nBZ#1488471 was fixed so there\'s no need to update the python-\nopenstackclient package before upgrade.\n\nChange-Id: I2aba7515ec43926ec4f8de5c701467dea31dba1b\n\nBe more aggressive on accepted packet loss during upgrade\n\nTests have shown that the packet loss shouldn\'t eceed 1% during\nthe upgrade steps. This change adjusts the accepted level to this.\n\nChange-Id: I9e47ea56a78e4e9eab40fca609cbedaecfcf1e14\n\nAdd more tags for the upgrade process.\n\nThis enable one to either do only a small part of the whole process.\nThis can be useful for debugging or development.\n\nChange-Id: Ic6cc9a1e6aa2793fde65636d2ad92bc174173252\n\nUse new method of discovering tag and adjust local registry upload\n\nThis change uses the new mechanism of retrieving the tag from the\nlatest image provided in the registry.\n\nChange-Id: I7e063f13c7d4812e9986452774881235b620bd0e\n\nSwap baremetal environment file for containerized.\n\nIn oooq, when upgrading from baremetal\nto containerized overcloud two different\nenvironment files are used. These env\nfiles are located in [0].\n\nWhen upgrading using tripleo-upgrade, we\nneed to convert that environment file name\nto its corresponding containers version.\n\n[0] https://github.com/openstack/tripleo-heat-templates/tree/master/ci/environments\n\nChange-Id: I6c9fad2f402a162cf663c5089e79c2e10f3d0928\n\nAdd condition to create local docker registry.\n\nThe only way to not execute the docker\nregistry environment file creation task\nis via tags, which is not easy to handle\nin TripleO CI.\n\nAs tripleo-quickstart already prepares\nthe local docker registry file, there\nis no need to execute it. So a new\nparameter \'create_docker_registry\' is\nbeen added.\n\nAlso, the \'force\' option is being added\nto avoid overwritting a provided script\nwith the role template.\n\nChange-Id: I800d6696b8dbb83f05f3d9381c6e5689558f4b77\n\nPrepare workloads before update/upgrade.\n\nPrepare scripts for managing workload on oc before running\n update/upgrade operation.\n\nAllow to run ping test during minor update.\n\nChange-Id: I1d5754f36f53588c97c646aa4e1380e9ca5938bc\n\nRemove tag parsing from the image prepare command\n\nParsing the tag is not needed anymore and the one returned by the\ncontainer image prepare command can be used.\n\nChange-Id: If782fc655da7b22e4d4a803509e9cc8c49774368\n\n[UPDATES] Run minor update per role.\n\nWith recent changes it\'s advised to perform minor update in batches:\nrole-by-role.\nThis change limits the scope of update with \'--nodes <Role>\' option.\n\nChange-Id: I0bc03873b749dc9c15b13cacbfff78cead4360d8\n'}, {'number': 3, 'created': '2017-12-08 19:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/72bb2f32610d798ea6f49e81d6fa6738b9671b3e', 'message': 'Merge tripleo-upgrade repo from redhat-openstack namespace\n\nMake sure scripts are created with the executable bit set.\n\nChange-Id: I731902411e987b4ea7c2aa84fef869fe5e1c25ae\n\nAdd a oooq comptatibility layer, documentation and example.\n\nChange-Id: I30fe6359f1c0098ff9bcdd5939724491d94ef199\n\nAdd support for applying w/a before and after upgrade\n\nThis change adds the ability to apply workarounds before and after\nthe overcloud upgrade process has finished. This allows the user\nto workaround particular issues that show up after the upgrade\nprocess has finished.\n\nChange-Id: I21a7e885bcc466af6bf80410ba2cc8d03865cb33\n\nFix missing quotes\n\nThis changes adds missing quotes to the node_upgrade_script.yml\ntemplates. Currently the task is failing because of the missing quotes.\n\nChange-Id: Ied9217df374d09bf90e6878a7c79e22042f44d99\n\nAdd support for applying workarounds post undercloud upgrade\n\nThis change adds support for applying workarounds after the undercloud\nupgrade process has finished as part of the undercloud upgrade.\n\nChange-Id: If85900969c0d591cf6024408d958a82fa8c8a534\n\nAdjust overcloud_converge_upgrade_script script\n\nThis change adjusts the overcloud_converge_upgrade_script to allow\nrunning the upgrade converge stage. In addition it adjust the ssh\nconfig file to skip host key check so the non-controller script does\nnot get stuck waiting for user input.\n\nChange-Id: Ic38f325c61e90165a5322ef754f7e5514ed8e687\n\nAppend working_dir to logs generated\n\nChange-Id: I6bc9f0c58ad8684ed03dee042e9cfb2bdc6835f6\n\nInstall ceph-ansible during undercloud upgrade\n\nceph-ansible is required to be installed manually for deployments\nwith ceph nodes. This change installs the ceph-ansible package\nbefore the undercloud upgrade.\n\nChange-Id: If8918a38250a10681d965d0715ebc17078166336\n\nUse openstack overcloud container image prepare command\n\nThis change adds the use of openstack overcloud container image prepare\ncommand for generating the environment file containing the container\nimage names and local registry address.\n\nChange-Id: I174f7e3aae415d51224cf73da83a859e90eed095\n\nDo not rely on ansible inventory for upgrading non controller nodes\n\nCurrently we are relying on the ansible inventory to provide groups\ncontaining compute nodes and their facts when creating the upgrade\nscripts. In order to remove this requirement and provide easier\nintegration this change discovers the compute and swift storage nodes\nfrom the undercloud. In addition it adds a wait loop for instance live\nmigration to complete before and after upgrading compute nodes and adds\nsupport for swift storage nodes upgrade.\n\nChange-Id: Ia4b2e81845c3fec9036c4695f0dd1746d4c5c6b8\n\nAdd silent and nobuffer options to curl command\n\nChange-Id: I0f4bd71b67d4827717d9f7d3fc075fc396eb6363\n\nAdjust tht environment files and custom roles data during upgrade\n\nThis change switches the environment files used in the overcloud deploy\ncommand to their variants used for deploying containers. In addition, if\nusing a custom roles data file for composable roles deployments, this\nchange adjusts the local roles data copy with the changes introduced in\nPike.\n\nChange-Id: Icd3c3b67342c0bd10fc3d28ed89a94fc9f714db4\n\nFix overcloud_deploy_script var location in oooq_test playbook\n\nChange-Id: I01f18a5413ff223cbca900521037e739ebc43d5d\n\nDisconnect ssh session before uploading images to local registry\n\nThis change disconnects the running ssh session in order to allow\nthe stack user to connect to the docker daemon. This acts as a\nworkaround for https://bugs.launchpad.net/tripleo/+bug/1699477\n\nChange-Id: Ia06fe8581ba17525cbcb2d955d7947b7c546811d\n\nAdd undercloud_reboot var and reboot only on ovs or kernel updates\n\nThis change adds the undercloud_reboot var to manipulate if undercloud\nreboots should be made or not and does the reboot only when kernel or\novs updates occur.\n\nChange-Id: Ic89291c5791bbd098204b2c85793335e0faa8d94\n\nAdd InfraRed docs\n\nThis change adds the steps required to run the tripleo-upgrade role\nas an InfraRed plugin.\n\nChange-Id: I08fde6c8954ec4eeedc47971607bec592fc801a1\n\nAdd docs for running the role manually from the undercloud\n\nChange-Id: I6d5bb6479b6e1fb45e34aa776d3c315cfae98ae4\n\nDo not stop services before undercloud upgrade\n\nAccording to the docs stopping services should be done by the undercloud\nupgrade process so we do not need to manually do it.\n\nChange-Id: I7f14257b4e90d3a0610c0f90e856096643325861\n\nSpecifically become_user: root when running ovs command\n\nCurrently become_user is set to the undercloud user, usually\nstack, when invoking the undercloud_validate_upgrade.yaml playbook.\nThis change overrides become_user and sets it to root when running\novs-vsctl command as it requires privilege escalation.\n\nChange-Id: Ia93245f4a2d09d73849c03401d38ffb25e7be802\n\nUse ip address instead of name when rebooting\n\nOOOQ doesn\'t set a name for the undercloud in hosts so in case the\nreboot is triggered the virthost cannot reach the undercloud. This\nchange switches the wait condition and calls the ip address instead\nof the name.\n\nChange-Id: I2121e2dabe9794d31fe70bbfa0ff8e53da6b3b1b\n\nAdd reload ssh tag to the Kill SSH task\n\nAdd a tag to the Kill SSH task so it can be avoided when\nrunning the role manually from the undercloud.\n\nChange-Id: Iec088cc174d7e8270fbea0698ee76227b45842f7\n\nAdd option to create script with --setup-heat-output option\n\nAccording to BZ#1477962 in order to be able to run non controller\nupgrade scripts after major upgrade composable steps we need to run\nthe deploy command with the --setup-heat-outputs option.\n\nChange-Id: I8137ff18047a130c5ea8dca2ce11378eabc30329\n\nAdd deprecated params to custom roles data file\n\nIn Pike there were additional flags assigned to the default roles\ndata file. This change adds these flags during the upgrade process\nto the roles defined in the custom roles data file.\n\nChange-Id: I58c2f30ff74d2302027d7488dc03c5146c371649\n\nUse a default value for the HOME env var\n\nChange-Id: I40e2f46f1311dc4b797977c8136ec4037505ef05\n\nUpdate python-openstackclient before undercloud upgrade\n\nUpdating python-openstackclient before undercloud upgrade is a\nrequirement to get undercloud upgrade passing.\n\nChange-Id: I4ab67f9af68036a29e11bb2457d70535bd94b7b0\n\nCreate environment file for injecting undercloud certificate\n\nWhen undercloud is SSL enabled the overcloud nodes need to be aware\nof the undercloud CA cert. This change creates this file during upgrade\nand adds it to the overcloud deploy commands when the overcloud nodes\nare not able to reach the undercloud ssl enabled public endpoints.\n\nChange-Id: I79a03299bc28d0ca2dbd83c28087a4c56f6b2271\n\nConvert puppet ceph parameters to ceph ansible during upgrade\n\nThis is a workaround for BZ#1488855.\n\nChange-Id: I58ac44b2166abddf56a327a4ee09457139c831da\n\nRemove setup heat outputs workaround\n\nhttps://review.openstack.org/#/c/502470/ allows us to obtain the\nRoleConfig output so there\'s no need to run the setup heat outputs\nstep anylonger. This change remove this step.\n\nChange-Id: I7235b8625eea4f77a055d0ab1862d0318f3a776f\n\nEcho bug number in workarounds script\n\nThis change replaces the bug number comments with an echo statement.\nThis provides easier way to debug what workarounds failed to apply\nwhen the workarounds script is run.\n\nChange-Id: I02c5534427ee5cf7b7af618f36577c1008d50992\n\nFix uc_keystone_conn condition\n\nThis change adds an addition condition to inject the undercloud\ncertificate in the CAMap only when  undercloud ssl is enabled.\n\nChange-Id: Iae023922bf1ed0bb22e86710b122c65a8f1568a3\n\nGather facts only from undercloud node\n\nFacts are only required for the undercloud node. This change adjusts\nthe existing playbooks to gather facts only from undercloud node in\norder to save some time and not rely on nodes which are not required\nto be reachable.\n\nChange-Id: Idceec3d10d84ef112da558109d9904a1d8c6ed93\n\nDo not include docker.yaml and docker-ha.yaml environments\n\nAs described in BZ#1466744 the docker.yaml and docker-ha.yaml\nenvironments are currently included by default so we do not need\nto specifically include them.\n\nChange-Id: I44a72ddd65cf816003ceca21ef33470a3ab125a7\n\nReboot compute nodes post upgrade\n\nAs a post upgrade requirement we need to reboot the nodes in case\nof an OVS upgrade. This change runs a post upgrade check for non\ncontroller nodes and reboots the nodes if an ovs upgrade has been\ndetected. It also adds additional validation for compute nodes to\nmake sure that the nova-compute service is enabled after reboot.\n\nChange-Id: I583e589118aabae84f8e1dc9ec2c4b43ca17a250\n\nAdd L3 agent connectivity check during upgrade\n\nThis change adds a check which validates that ICMP\nconnectivity with a floating IP is not interrupted\nduring the major upgrade composable step.\n\nChange-Id: Iee55af85b9a2c3ece86731e043130d191ff6a821\n\nRun pre docker composable upgrade workarounds at correct position\n\nThis change moves the pre docker composable upgrade workarounds to\nbe run right before the docker composable upgrade step.\n\nChange-Id: I604ea2eb6202d48b0f771ea80e5e731df687600e\n\nUse bool with ansible booleans\n\nuse bool filter when using ansible booleans.\n\nChange-Id: Ibeb59772e935cc28a661ccddcaa4773388ce296d\n\nAdd option for creating workloads before upgrade\n\nThis change adds the option to launch an instance before\nstarting upgrade. This operation is useful when doing\ntests such as instance live migration during upgrade or\nfloating ip connectivity testing during upgrade. The\nscript requires a network defined in the external_network_name\nvar which provides external connectivity to exist beforehand.\n\nChange-Id: Ib39e41b36fac7794ea515c8a9d56141866dcfeed\n\nFix pre compute upgrade check\n\nThis change adds the MIGRATING state to be checked before the\ncompute nodes upgrade.\n\nChange-Id: I0073a7e69a71a044882d4760dbb49cd4f455dd89\n\nFix workload_launch position\n\nChange-Id: I6193ac6a60165bb20ece6277067c05696ed6d3b1\n\nRun non controller node pre upgrade script\n\nThis change runs the non controller node pre upgrade script.\nIn addition it exposes the option to run instances migration\nbetween compute nodes during upgrade.\n\nChange-Id: Ief55eecdc85bb620f637c4ed4d9b5bc3243b37d1\n\nUpdate roles_data adjustments to latest changes\n\nThis change updates the roles_data file adjustments to the latest\nchanges.\n\nChange-Id: Ic787b135cdf96b33829e05140e069b398df7196f\n\nUse docker and docker-ha environment files for upstream deployments\n\nChange-Id: I70bb9767e97f616729adff983fff065858a6dcdc\n\nConvert services environments to services-docker only for upstream\n\nPer BZ#116463 in downstream the environments used for extra service\nenablement now point to docker resources.\n\nChange-Id: I379622ec2749ac8b485aec79a7500308ef74214e\n\nEcho debug message to differentiate live migration from block\n\nChange-Id: I69e7f381543d84fcd308acbd3a90f5d0ac23ae1b\n\nAccept <= 5% ICMP packet loss during upgrade connectivity check\n\nChange-Id: I34d1de225c0e391035e22e18f63356e04afbbfd5\n\nReorganize playbooks to separate upgrade/update\n\nThis change adds separate directories for upgrade/update which\nprovides a better separation between updates and upgrades.\n\nChange-Id: Icf1a09514fb0e6236535ae32265bbd3805918478\n\nRun block migrate multiple times\n\nBlock migrate doesn\'t work seem to work if triggered once but it\ndoes if the command is run for a second time. This change runs the\nblock migrate command multiple times to make sure that the instance\ngets migrated.\n\nChange-Id: I8b9a9ecae21f7ce49a03945afec66b9e671622b7\n\nEnsure files/ are part of the setup.cfg files to copy\n\nWhen installing tripleo-upgrade into a .quickstart\nenvironment, the files/ folder wasn\'t getting copied, which is necessary\nat least for ""adjust ssh config to skip host key check"" in\ncreate-upgrade-scripts.yaml.\n\nChange-Id: I7d862ec5c13ba719923c90cc40790b842b582999\n\nAdd tasks for undercloud minor update\n\nStart adding the minor undercloud update tasks\n\nChange-Id: I33705b270e2d5e6a28f1cad8179e1f4b3e4ea975\n\nRemove timeouts from upgrade scripts\n\nDepending on the number of deployed nodes upgrade could take longer\nand we want to rely on the heat stack timeout. This change clears\nany manual timeouts set in the upgrade scripts.\n\nChange-Id: I5d141e2cc13621d3be5fb0c27b0ac3c3fc30d424\n\nMinor updates of RHOS 12.\n\nManage minor update workflow from within tripleo-upgrade repo.\n\nChange-Id: I8c6771af4825ce166e8470413ca4687be0a58cb9\n\nReboot controller nodes post upgrade\n\nThis change adds the option to reboot controller nodes post upgrade\nand performs basic verifications that the clustered services are\nreported as up.\n\nChange-Id: I370d421e5968ae50bd1ff140cdfcf98a4db03a5f\n\nDon\'t force ssh_config on everybody.\n\nThis add an option to be able to not overwrite the ssh_config file.\nAs a side note the ssh_config is missing from the repo, so by default\nthis task is broken.\n\nChange-Id: Idfb78e2b7226a7e6295acd3f250bbfb48d0a103d\n\nFix filter used in the node upgrade scripts\n\nThis change is fixes the current filter used for node upgrade\nscripts so that deployment with $domain.tld format are supported.\n\nChange-Id: I18f43c440bb93e0fcefb664c7d716ff9368673a4\n\nRun live migration multiple times\n\nChange-Id: I7c028defd3cb9080efa7bdbe9daa6ed201df8640\n\nManually inject undercloud SSL cert to overcloud nodes\n\nPer BZ#1501779 the compute nodes do not get their trusted store\nupdated when using a CAMap and upgrade fails. This change updates\nthe overcloud nodes trusted store manually so the overcloud nodes\nare prepared for update. This should translate in a documentation\nstep that before upgrade starts the user needs to make  sure the\novercloud nodes are able to reach the undercloud SSL public\nendpoint.\n\nChange-Id: Ib95a29c608803504a866ae71cbc0082faf3c194f\n\nReplace puppet external ceph environment with ceph-ansible one\n\nThis change replaces during the upgrade the external ceph puppet\nenvironment file with its ceph-ansible equivalent.\n\nChange-Id: I9020e8f7c43f91259b551caa2e20f03be1424106\n\nAppend deprecated params only to predefined roles\n\nWe should append the deprecated params only to predefined roles\nin order to avoid failures such as reported in BZ#1501237.\n\nChange-Id: I3a7c332b35da9639fb6f8e5b38234dc0c55d8499\n\nSplit the post controller scripts into per services scripts\n\nThis change splits the post upgrade controller scripts into\nper service checks and adds them to a common directory so\nthey can be shared between update and upgrade.\n\nChange-Id: I8f2fb6162a5acb8a92057400a7b04e6e2388abaa\n\nAdd the ability to specify a remote docker registry\n\nThis change adds the ability to specify a remote docker registry\nto be used for downloading the Docker images on the undercloud or\nbe used directly by the overcloud nodes during upgrade.\n\nChange-Id: I132a8b94f9a101d1c9c624d202bb01527dc2b844\n\nFix BZ#1499677 workaround condition\n\nIn addition to empty gvwstate.dat file there might be situations\nwhere the gvwstate.dat file is missing after reboot. This patch\naddresses this condition for BZ#1499677 workaround.\n\nChange-Id: I295b133248f48ab41b1748225cbe9359662b280d\n\nCleanup galera resource instead of rebooting node for BZ#1499677\n\nInstead of rebooting the node while implementing the workaround for\nBZ#1499677 we should simply cleanup the Galera resource. This way\nwe can save some time and potential issues caused by an additional\nreboot.\n\nChange-Id: I391daeae41321baec1cbd8c458132a3161cd96d5\n\n[UPDATES] Introduce option for minor updates workarounds.\n\nTo speed up testing of minor updates it might be required\n to apply some patches before they are landed.\nHence we need a flag to differentiate if workarounds are required\n or not\n\nChange-Id: I642e4ade204f5fd30ec9433f1d90a2d539287c5e\n\nDo not pipe curl output in container images environment script\n\nCurl can sometimes exit with exit code 23 when its output is piped\ninto another command. To avoid this errors we save the curl output\nto a file.\n\nChange-Id: I4123b6c66ae2873c11631f229cb8e3eec5a5a66b\n\nUse service environment files when generating the images environment\n\nIn the last build openstack overcloud container image prepare only\ngenerates the parameters for the services included by default. In\norder to make it work when extra non-default services are enabled\nwe need to pass the environment files to the prepare command. This\nchange addresses this issue.\n\nChange-Id: I86ab6faaffcd4c7cc1a07e9a6ed1e890cb5cf980\n\nPlace the oooq deploy command into overcloud_deploy_script var\n\nThis change places the openstack overcloud deploy command with its\narguments in the location defined by the overcloud_deploy_script\nvar. This way we don\'t require oooq users to specifically set the\novercloud_deploy_script to a hardcoded location and make it less\nconfusing.\n\nChange-Id: Id2b14fcffbd169c342df4b5b9105dff81e18e3a0\n\nReplace ceph radosgw environment during upgrade\n\nChange-Id: I489211f39941bba5b1ca2ddf1b635c3bdb0151fe\n\nAvoid losing undercloud connection in TripleO CI.\n\nWhen running the role in the TripleO upstream CI\nthe connectivity to the undercloud gets lost when\nrebooting the undercloud after upgrade or killing\nthe ssh service, this makes the playbook fail.\n\nAs a solution, a flag tripleo_ci has been added.\nThis flag will default to false, and when set to\ntrue no undercloud reboot, nor ssh killing will\nbe executed.\n\nChange-Id: If4a303fff49bbe55cdfb7142d8dd69264ab47ab4\n\nAlign deployment-files option with IR.\n\ndeployment-files option is not a list of choices in IR,\nadjust it accordingly.\n\nChange-Id: I6889e9b75f842cc466278fed5dbf85a80cb58ee0\n\nAppend docker-ha only when needed.\n\nBefore appending the docker-ha.yaml env\nfile, we need to check if the overcloud\nwas deployed with pacemaker. If so, then\nwe\'ll add the env file to the upgrade\nscript.\n\nChange-Id: I9867d86b6d23385c576d2f8c5a25ab3333f7113d\n\nSpecify tht directory used in upgrade script.\n\nWhen deploying with oooq, the generated script\novercloud-deploy.sh is reused in order to append\nthe cooresponding env files for the upgrade.\n\nHowever, if the location of the tripleo-heat-templates\ndirectory is different from the used when deploying\nthen the upgrade does not succeed.\n\nThis change modifies the tripleo-heat-templates\nlocation used to upgrade when the directory found\nin overcloud-deploy.sh is different. If it is the\nsame no change is done.\n\nChange-Id: I55ada3e75b7463b1c14c8734410d2591cf162e67\n\nDon\'t append DockerInsecureRegistryAddress\n\nThis is no longer required as the prepare command detects whether the\nregistry is secure and DockerInsecureRegistryAddress as necessary.\n\nDepends on upstream https://review.openstack.org/#/c/514473/\nRelated-Bug: #1722632\n\nChange-Id: Ia9d91f6280600c59d0079c5d1f26a00f04040426\n\nFix the controller regex during roles_data conversion\n\nThe Ocata roles_data controller role might include a comment for\nthe controller role name. This change adjusts the regexp used during\nthe roles data conversion to take into consideration that comment.\n\nChange-Id: I7b43b1fcb9e477de8e1265ef6aa6ba5149e82d47\n\nUse prepare --set for ceph image parameter\n\nThis is more maintainable, and consistent with other uses of prepare.\n\nChange-Id: Ieec88e271973a248192c2b247cd2c5e0cccbfb7c\n\nAdd storage environment files to be used for containers prepare\n\nThis change adds the storage environments files to be matched when\ncreating the environment file containing the Docker images names\nwhich gets created via container image prepare.\n\nChange-Id: I34c3cdaab1b63ce3f43d748372d35143bc12b8b4\n\nAdd environment file containing required DPDK changes during upgrade\n\nChange-Id: Iabaf16e18ee7546bd6275f8f84226892423a6c95\n\nCreate failed_upgrade log files.\n\nMost of the stack failures in the TripleO\nCI are registered inside two log files\nfailed_upgrade_list.log and failed_upgrade.log.\n\nThis patch adds the option of inject the\nstack failures list command into these two\nlog files, as well as priting out the detailed\nstack failure list (--long).\n\nChange-Id: I4fad989818f67ad0a73e45b47f835750f18c3bb6\n\nReplace storage-environemnt.yaml for upstream only\n\nPer BZ#1502862 the Ceph environment files switch during upgrade is\nonly needed for upstream deployments. This change does the changes\nto accommodate this.\n\nChange-Id: Ia3adb120c9b524c66d069593b0779b3399295fd4\n\nDo not update python-openstackclient before upgrade\n\nBZ#1488471 was fixed so there\'s no need to update the python-\nopenstackclient package before upgrade.\n\nChange-Id: I2aba7515ec43926ec4f8de5c701467dea31dba1b\n\nBe more aggressive on accepted packet loss during upgrade\n\nTests have shown that the packet loss shouldn\'t eceed 1% during\nthe upgrade steps. This change adjusts the accepted level to this.\n\nChange-Id: I9e47ea56a78e4e9eab40fca609cbedaecfcf1e14\n\nAdd more tags for the upgrade process.\n\nThis enable one to either do only a small part of the whole process.\nThis can be useful for debugging or development.\n\nChange-Id: Ic6cc9a1e6aa2793fde65636d2ad92bc174173252\n\nUse new method of discovering tag and adjust local registry upload\n\nThis change uses the new mechanism of retrieving the tag from the\nlatest image provided in the registry.\n\nChange-Id: I7e063f13c7d4812e9986452774881235b620bd0e\n\nSwap baremetal environment file for containerized.\n\nIn oooq, when upgrading from baremetal\nto containerized overcloud two different\nenvironment files are used. These env\nfiles are located in [0].\n\nWhen upgrading using tripleo-upgrade, we\nneed to convert that environment file name\nto its corresponding containers version.\n\n[0] https://github.com/openstack/tripleo-heat-templates/tree/master/ci/environments\n\nChange-Id: I6c9fad2f402a162cf663c5089e79c2e10f3d0928\n\nAdd condition to create local docker registry.\n\nThe only way to not execute the docker\nregistry environment file creation task\nis via tags, which is not easy to handle\nin TripleO CI.\n\nAs tripleo-quickstart already prepares\nthe local docker registry file, there\nis no need to execute it. So a new\nparameter \'create_docker_registry\' is\nbeen added.\n\nAlso, the \'force\' option is being added\nto avoid overwritting a provided script\nwith the role template.\n\nChange-Id: I800d6696b8dbb83f05f3d9381c6e5689558f4b77\n\nPrepare workloads before update/upgrade.\n\nPrepare scripts for managing workload on oc before running\n update/upgrade operation.\n\nAllow to run ping test during minor update.\n\nChange-Id: I1d5754f36f53588c97c646aa4e1380e9ca5938bc\n\nRemove tag parsing from the image prepare command\n\nParsing the tag is not needed anymore and the one returned by the\ncontainer image prepare command can be used.\n\nChange-Id: If782fc655da7b22e4d4a803509e9cc8c49774368\n\n[UPDATES] Run minor update per role.\n\nWith recent changes it\'s advised to perform minor update in batches:\nrole-by-role.\nThis change limits the scope of update with \'--nodes <Role>\' option.\n\nChange-Id: I0bc03873b749dc9c15b13cacbfff78cead4360d8\nDepends-On: I2b8ba3d2785ade99943adfc2ed31155679321bb0\n'}, {'number': 4, 'created': '2017-12-09 02:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/21c5b5b9d5ba7ad188cd9a0d018aa739f4c915bd', 'message': 'Merge tripleo-upgrade repo from redhat-openstack namespace\n\nMake sure scripts are created with the executable bit set.\n\nChange-Id: I731902411e987b4ea7c2aa84fef869fe5e1c25ae\n\nAdd a oooq comptatibility layer, documentation and example.\n\nChange-Id: I30fe6359f1c0098ff9bcdd5939724491d94ef199\n\nAdd support for applying w/a before and after upgrade\n\nThis change adds the ability to apply workarounds before and after\nthe overcloud upgrade process has finished. This allows the user\nto workaround particular issues that show up after the upgrade\nprocess has finished.\n\nChange-Id: I21a7e885bcc466af6bf80410ba2cc8d03865cb33\n\nFix missing quotes\n\nThis changes adds missing quotes to the node_upgrade_script.yml\ntemplates. Currently the task is failing because of the missing quotes.\n\nChange-Id: Ied9217df374d09bf90e6878a7c79e22042f44d99\n\nAdd support for applying workarounds post undercloud upgrade\n\nThis change adds support for applying workarounds after the undercloud\nupgrade process has finished as part of the undercloud upgrade.\n\nChange-Id: If85900969c0d591cf6024408d958a82fa8c8a534\n\nAdjust overcloud_converge_upgrade_script script\n\nThis change adjusts the overcloud_converge_upgrade_script to allow\nrunning the upgrade converge stage. In addition it adjust the ssh\nconfig file to skip host key check so the non-controller script does\nnot get stuck waiting for user input.\n\nChange-Id: Ic38f325c61e90165a5322ef754f7e5514ed8e687\n\nAppend working_dir to logs generated\n\nChange-Id: I6bc9f0c58ad8684ed03dee042e9cfb2bdc6835f6\n\nInstall ceph-ansible during undercloud upgrade\n\nceph-ansible is required to be installed manually for deployments\nwith ceph nodes. This change installs the ceph-ansible package\nbefore the undercloud upgrade.\n\nChange-Id: If8918a38250a10681d965d0715ebc17078166336\n\nUse openstack overcloud container image prepare command\n\nThis change adds the use of openstack overcloud container image prepare\ncommand for generating the environment file containing the container\nimage names and local registry address.\n\nChange-Id: I174f7e3aae415d51224cf73da83a859e90eed095\n\nDo not rely on ansible inventory for upgrading non controller nodes\n\nCurrently we are relying on the ansible inventory to provide groups\ncontaining compute nodes and their facts when creating the upgrade\nscripts. In order to remove this requirement and provide easier\nintegration this change discovers the compute and swift storage nodes\nfrom the undercloud. In addition it adds a wait loop for instance live\nmigration to complete before and after upgrading compute nodes and adds\nsupport for swift storage nodes upgrade.\n\nChange-Id: Ia4b2e81845c3fec9036c4695f0dd1746d4c5c6b8\n\nAdd silent and nobuffer options to curl command\n\nChange-Id: I0f4bd71b67d4827717d9f7d3fc075fc396eb6363\n\nAdjust tht environment files and custom roles data during upgrade\n\nThis change switches the environment files used in the overcloud deploy\ncommand to their variants used for deploying containers. In addition, if\nusing a custom roles data file for composable roles deployments, this\nchange adjusts the local roles data copy with the changes introduced in\nPike.\n\nChange-Id: Icd3c3b67342c0bd10fc3d28ed89a94fc9f714db4\n\nFix overcloud_deploy_script var location in oooq_test playbook\n\nChange-Id: I01f18a5413ff223cbca900521037e739ebc43d5d\n\nDisconnect ssh session before uploading images to local registry\n\nThis change disconnects the running ssh session in order to allow\nthe stack user to connect to the docker daemon. This acts as a\nworkaround for https://bugs.launchpad.net/tripleo/+bug/1699477\n\nChange-Id: Ia06fe8581ba17525cbcb2d955d7947b7c546811d\n\nAdd undercloud_reboot var and reboot only on ovs or kernel updates\n\nThis change adds the undercloud_reboot var to manipulate if undercloud\nreboots should be made or not and does the reboot only when kernel or\novs updates occur.\n\nChange-Id: Ic89291c5791bbd098204b2c85793335e0faa8d94\n\nAdd InfraRed docs\n\nThis change adds the steps required to run the tripleo-upgrade role\nas an InfraRed plugin.\n\nChange-Id: I08fde6c8954ec4eeedc47971607bec592fc801a1\n\nAdd docs for running the role manually from the undercloud\n\nChange-Id: I6d5bb6479b6e1fb45e34aa776d3c315cfae98ae4\n\nDo not stop services before undercloud upgrade\n\nAccording to the docs stopping services should be done by the undercloud\nupgrade process so we do not need to manually do it.\n\nChange-Id: I7f14257b4e90d3a0610c0f90e856096643325861\n\nSpecifically become_user: root when running ovs command\n\nCurrently become_user is set to the undercloud user, usually\nstack, when invoking the undercloud_validate_upgrade.yaml playbook.\nThis change overrides become_user and sets it to root when running\novs-vsctl command as it requires privilege escalation.\n\nChange-Id: Ia93245f4a2d09d73849c03401d38ffb25e7be802\n\nUse ip address instead of name when rebooting\n\nOOOQ doesn\'t set a name for the undercloud in hosts so in case the\nreboot is triggered the virthost cannot reach the undercloud. This\nchange switches the wait condition and calls the ip address instead\nof the name.\n\nChange-Id: I2121e2dabe9794d31fe70bbfa0ff8e53da6b3b1b\n\nAdd reload ssh tag to the Kill SSH task\n\nAdd a tag to the Kill SSH task so it can be avoided when\nrunning the role manually from the undercloud.\n\nChange-Id: Iec088cc174d7e8270fbea0698ee76227b45842f7\n\nAdd option to create script with --setup-heat-output option\n\nAccording to BZ#1477962 in order to be able to run non controller\nupgrade scripts after major upgrade composable steps we need to run\nthe deploy command with the --setup-heat-outputs option.\n\nChange-Id: I8137ff18047a130c5ea8dca2ce11378eabc30329\n\nAdd deprecated params to custom roles data file\n\nIn Pike there were additional flags assigned to the default roles\ndata file. This change adds these flags during the upgrade process\nto the roles defined in the custom roles data file.\n\nChange-Id: I58c2f30ff74d2302027d7488dc03c5146c371649\n\nUse a default value for the HOME env var\n\nChange-Id: I40e2f46f1311dc4b797977c8136ec4037505ef05\n\nUpdate python-openstackclient before undercloud upgrade\n\nUpdating python-openstackclient before undercloud upgrade is a\nrequirement to get undercloud upgrade passing.\n\nChange-Id: I4ab67f9af68036a29e11bb2457d70535bd94b7b0\n\nCreate environment file for injecting undercloud certificate\n\nWhen undercloud is SSL enabled the overcloud nodes need to be aware\nof the undercloud CA cert. This change creates this file during upgrade\nand adds it to the overcloud deploy commands when the overcloud nodes\nare not able to reach the undercloud ssl enabled public endpoints.\n\nChange-Id: I79a03299bc28d0ca2dbd83c28087a4c56f6b2271\n\nConvert puppet ceph parameters to ceph ansible during upgrade\n\nThis is a workaround for BZ#1488855.\n\nChange-Id: I58ac44b2166abddf56a327a4ee09457139c831da\n\nRemove setup heat outputs workaround\n\nhttps://review.openstack.org/#/c/502470/ allows us to obtain the\nRoleConfig output so there\'s no need to run the setup heat outputs\nstep anylonger. This change remove this step.\n\nChange-Id: I7235b8625eea4f77a055d0ab1862d0318f3a776f\n\nEcho bug number in workarounds script\n\nThis change replaces the bug number comments with an echo statement.\nThis provides easier way to debug what workarounds failed to apply\nwhen the workarounds script is run.\n\nChange-Id: I02c5534427ee5cf7b7af618f36577c1008d50992\n\nFix uc_keystone_conn condition\n\nThis change adds an addition condition to inject the undercloud\ncertificate in the CAMap only when  undercloud ssl is enabled.\n\nChange-Id: Iae023922bf1ed0bb22e86710b122c65a8f1568a3\n\nGather facts only from undercloud node\n\nFacts are only required for the undercloud node. This change adjusts\nthe existing playbooks to gather facts only from undercloud node in\norder to save some time and not rely on nodes which are not required\nto be reachable.\n\nChange-Id: Idceec3d10d84ef112da558109d9904a1d8c6ed93\n\nDo not include docker.yaml and docker-ha.yaml environments\n\nAs described in BZ#1466744 the docker.yaml and docker-ha.yaml\nenvironments are currently included by default so we do not need\nto specifically include them.\n\nChange-Id: I44a72ddd65cf816003ceca21ef33470a3ab125a7\n\nReboot compute nodes post upgrade\n\nAs a post upgrade requirement we need to reboot the nodes in case\nof an OVS upgrade. This change runs a post upgrade check for non\ncontroller nodes and reboots the nodes if an ovs upgrade has been\ndetected. It also adds additional validation for compute nodes to\nmake sure that the nova-compute service is enabled after reboot.\n\nChange-Id: I583e589118aabae84f8e1dc9ec2c4b43ca17a250\n\nAdd L3 agent connectivity check during upgrade\n\nThis change adds a check which validates that ICMP\nconnectivity with a floating IP is not interrupted\nduring the major upgrade composable step.\n\nChange-Id: Iee55af85b9a2c3ece86731e043130d191ff6a821\n\nRun pre docker composable upgrade workarounds at correct position\n\nThis change moves the pre docker composable upgrade workarounds to\nbe run right before the docker composable upgrade step.\n\nChange-Id: I604ea2eb6202d48b0f771ea80e5e731df687600e\n\nUse bool with ansible booleans\n\nuse bool filter when using ansible booleans.\n\nChange-Id: Ibeb59772e935cc28a661ccddcaa4773388ce296d\n\nAdd option for creating workloads before upgrade\n\nThis change adds the option to launch an instance before\nstarting upgrade. This operation is useful when doing\ntests such as instance live migration during upgrade or\nfloating ip connectivity testing during upgrade. The\nscript requires a network defined in the external_network_name\nvar which provides external connectivity to exist beforehand.\n\nChange-Id: Ib39e41b36fac7794ea515c8a9d56141866dcfeed\n\nFix pre compute upgrade check\n\nThis change adds the MIGRATING state to be checked before the\ncompute nodes upgrade.\n\nChange-Id: I0073a7e69a71a044882d4760dbb49cd4f455dd89\n\nFix workload_launch position\n\nChange-Id: I6193ac6a60165bb20ece6277067c05696ed6d3b1\n\nRun non controller node pre upgrade script\n\nThis change runs the non controller node pre upgrade script.\nIn addition it exposes the option to run instances migration\nbetween compute nodes during upgrade.\n\nChange-Id: Ief55eecdc85bb620f637c4ed4d9b5bc3243b37d1\n\nUpdate roles_data adjustments to latest changes\n\nThis change updates the roles_data file adjustments to the latest\nchanges.\n\nChange-Id: Ic787b135cdf96b33829e05140e069b398df7196f\n\nUse docker and docker-ha environment files for upstream deployments\n\nChange-Id: I70bb9767e97f616729adff983fff065858a6dcdc\n\nConvert services environments to services-docker only for upstream\n\nPer BZ#116463 in downstream the environments used for extra service\nenablement now point to docker resources.\n\nChange-Id: I379622ec2749ac8b485aec79a7500308ef74214e\n\nEcho debug message to differentiate live migration from block\n\nChange-Id: I69e7f381543d84fcd308acbd3a90f5d0ac23ae1b\n\nAccept <= 5% ICMP packet loss during upgrade connectivity check\n\nChange-Id: I34d1de225c0e391035e22e18f63356e04afbbfd5\n\nReorganize playbooks to separate upgrade/update\n\nThis change adds separate directories for upgrade/update which\nprovides a better separation between updates and upgrades.\n\nChange-Id: Icf1a09514fb0e6236535ae32265bbd3805918478\n\nRun block migrate multiple times\n\nBlock migrate doesn\'t work seem to work if triggered once but it\ndoes if the command is run for a second time. This change runs the\nblock migrate command multiple times to make sure that the instance\ngets migrated.\n\nChange-Id: I8b9a9ecae21f7ce49a03945afec66b9e671622b7\n\nEnsure files/ are part of the setup.cfg files to copy\n\nWhen installing tripleo-upgrade into a .quickstart\nenvironment, the files/ folder wasn\'t getting copied, which is necessary\nat least for ""adjust ssh config to skip host key check"" in\ncreate-upgrade-scripts.yaml.\n\nChange-Id: I7d862ec5c13ba719923c90cc40790b842b582999\n\nAdd tasks for undercloud minor update\n\nStart adding the minor undercloud update tasks\n\nChange-Id: I33705b270e2d5e6a28f1cad8179e1f4b3e4ea975\n\nRemove timeouts from upgrade scripts\n\nDepending on the number of deployed nodes upgrade could take longer\nand we want to rely on the heat stack timeout. This change clears\nany manual timeouts set in the upgrade scripts.\n\nChange-Id: I5d141e2cc13621d3be5fb0c27b0ac3c3fc30d424\n\nMinor updates of RHOS 12.\n\nManage minor update workflow from within tripleo-upgrade repo.\n\nChange-Id: I8c6771af4825ce166e8470413ca4687be0a58cb9\n\nReboot controller nodes post upgrade\n\nThis change adds the option to reboot controller nodes post upgrade\nand performs basic verifications that the clustered services are\nreported as up.\n\nChange-Id: I370d421e5968ae50bd1ff140cdfcf98a4db03a5f\n\nDon\'t force ssh_config on everybody.\n\nThis add an option to be able to not overwrite the ssh_config file.\nAs a side note the ssh_config is missing from the repo, so by default\nthis task is broken.\n\nChange-Id: Idfb78e2b7226a7e6295acd3f250bbfb48d0a103d\n\nFix filter used in the node upgrade scripts\n\nThis change is fixes the current filter used for node upgrade\nscripts so that deployment with $domain.tld format are supported.\n\nChange-Id: I18f43c440bb93e0fcefb664c7d716ff9368673a4\n\nRun live migration multiple times\n\nChange-Id: I7c028defd3cb9080efa7bdbe9daa6ed201df8640\n\nManually inject undercloud SSL cert to overcloud nodes\n\nPer BZ#1501779 the compute nodes do not get their trusted store\nupdated when using a CAMap and upgrade fails. This change updates\nthe overcloud nodes trusted store manually so the overcloud nodes\nare prepared for update. This should translate in a documentation\nstep that before upgrade starts the user needs to make  sure the\novercloud nodes are able to reach the undercloud SSL public\nendpoint.\n\nChange-Id: Ib95a29c608803504a866ae71cbc0082faf3c194f\n\nReplace puppet external ceph environment with ceph-ansible one\n\nThis change replaces during the upgrade the external ceph puppet\nenvironment file with its ceph-ansible equivalent.\n\nChange-Id: I9020e8f7c43f91259b551caa2e20f03be1424106\n\nAppend deprecated params only to predefined roles\n\nWe should append the deprecated params only to predefined roles\nin order to avoid failures such as reported in BZ#1501237.\n\nChange-Id: I3a7c332b35da9639fb6f8e5b38234dc0c55d8499\n\nSplit the post controller scripts into per services scripts\n\nThis change splits the post upgrade controller scripts into\nper service checks and adds them to a common directory so\nthey can be shared between update and upgrade.\n\nChange-Id: I8f2fb6162a5acb8a92057400a7b04e6e2388abaa\n\nAdd the ability to specify a remote docker registry\n\nThis change adds the ability to specify a remote docker registry\nto be used for downloading the Docker images on the undercloud or\nbe used directly by the overcloud nodes during upgrade.\n\nChange-Id: I132a8b94f9a101d1c9c624d202bb01527dc2b844\n\nFix BZ#1499677 workaround condition\n\nIn addition to empty gvwstate.dat file there might be situations\nwhere the gvwstate.dat file is missing after reboot. This patch\naddresses this condition for BZ#1499677 workaround.\n\nChange-Id: I295b133248f48ab41b1748225cbe9359662b280d\n\nCleanup galera resource instead of rebooting node for BZ#1499677\n\nInstead of rebooting the node while implementing the workaround for\nBZ#1499677 we should simply cleanup the Galera resource. This way\nwe can save some time and potential issues caused by an additional\nreboot.\n\nChange-Id: I391daeae41321baec1cbd8c458132a3161cd96d5\n\n[UPDATES] Introduce option for minor updates workarounds.\n\nTo speed up testing of minor updates it might be required\n to apply some patches before they are landed.\nHence we need a flag to differentiate if workarounds are required\n or not\n\nChange-Id: I642e4ade204f5fd30ec9433f1d90a2d539287c5e\n\nDo not pipe curl output in container images environment script\n\nCurl can sometimes exit with exit code 23 when its output is piped\ninto another command. To avoid this errors we save the curl output\nto a file.\n\nChange-Id: I4123b6c66ae2873c11631f229cb8e3eec5a5a66b\n\nUse service environment files when generating the images environment\n\nIn the last build openstack overcloud container image prepare only\ngenerates the parameters for the services included by default. In\norder to make it work when extra non-default services are enabled\nwe need to pass the environment files to the prepare command. This\nchange addresses this issue.\n\nChange-Id: I86ab6faaffcd4c7cc1a07e9a6ed1e890cb5cf980\n\nPlace the oooq deploy command into overcloud_deploy_script var\n\nThis change places the openstack overcloud deploy command with its\narguments in the location defined by the overcloud_deploy_script\nvar. This way we don\'t require oooq users to specifically set the\novercloud_deploy_script to a hardcoded location and make it less\nconfusing.\n\nChange-Id: Id2b14fcffbd169c342df4b5b9105dff81e18e3a0\n\nReplace ceph radosgw environment during upgrade\n\nChange-Id: I489211f39941bba5b1ca2ddf1b635c3bdb0151fe\n\nAvoid losing undercloud connection in TripleO CI.\n\nWhen running the role in the TripleO upstream CI\nthe connectivity to the undercloud gets lost when\nrebooting the undercloud after upgrade or killing\nthe ssh service, this makes the playbook fail.\n\nAs a solution, a flag tripleo_ci has been added.\nThis flag will default to false, and when set to\ntrue no undercloud reboot, nor ssh killing will\nbe executed.\n\nChange-Id: If4a303fff49bbe55cdfb7142d8dd69264ab47ab4\n\nAlign deployment-files option with IR.\n\ndeployment-files option is not a list of choices in IR,\nadjust it accordingly.\n\nChange-Id: I6889e9b75f842cc466278fed5dbf85a80cb58ee0\n\nAppend docker-ha only when needed.\n\nBefore appending the docker-ha.yaml env\nfile, we need to check if the overcloud\nwas deployed with pacemaker. If so, then\nwe\'ll add the env file to the upgrade\nscript.\n\nChange-Id: I9867d86b6d23385c576d2f8c5a25ab3333f7113d\n\nSpecify tht directory used in upgrade script.\n\nWhen deploying with oooq, the generated script\novercloud-deploy.sh is reused in order to append\nthe cooresponding env files for the upgrade.\n\nHowever, if the location of the tripleo-heat-templates\ndirectory is different from the used when deploying\nthen the upgrade does not succeed.\n\nThis change modifies the tripleo-heat-templates\nlocation used to upgrade when the directory found\nin overcloud-deploy.sh is different. If it is the\nsame no change is done.\n\nChange-Id: I55ada3e75b7463b1c14c8734410d2591cf162e67\n\nDon\'t append DockerInsecureRegistryAddress\n\nThis is no longer required as the prepare command detects whether the\nregistry is secure and DockerInsecureRegistryAddress as necessary.\n\nDepends on upstream https://review.openstack.org/#/c/514473/\nRelated-Bug: #1722632\n\nChange-Id: Ia9d91f6280600c59d0079c5d1f26a00f04040426\n\nFix the controller regex during roles_data conversion\n\nThe Ocata roles_data controller role might include a comment for\nthe controller role name. This change adjusts the regexp used during\nthe roles data conversion to take into consideration that comment.\n\nChange-Id: I7b43b1fcb9e477de8e1265ef6aa6ba5149e82d47\n\nUse prepare --set for ceph image parameter\n\nThis is more maintainable, and consistent with other uses of prepare.\n\nChange-Id: Ieec88e271973a248192c2b247cd2c5e0cccbfb7c\n\nAdd storage environment files to be used for containers prepare\n\nThis change adds the storage environments files to be matched when\ncreating the environment file containing the Docker images names\nwhich gets created via container image prepare.\n\nChange-Id: I34c3cdaab1b63ce3f43d748372d35143bc12b8b4\n\nAdd environment file containing required DPDK changes during upgrade\n\nChange-Id: Iabaf16e18ee7546bd6275f8f84226892423a6c95\n\nCreate failed_upgrade log files.\n\nMost of the stack failures in the TripleO\nCI are registered inside two log files\nfailed_upgrade_list.log and failed_upgrade.log.\n\nThis patch adds the option of inject the\nstack failures list command into these two\nlog files, as well as priting out the detailed\nstack failure list (--long).\n\nChange-Id: I4fad989818f67ad0a73e45b47f835750f18c3bb6\n\nReplace storage-environemnt.yaml for upstream only\n\nPer BZ#1502862 the Ceph environment files switch during upgrade is\nonly needed for upstream deployments. This change does the changes\nto accommodate this.\n\nChange-Id: Ia3adb120c9b524c66d069593b0779b3399295fd4\n\nDo not update python-openstackclient before upgrade\n\nBZ#1488471 was fixed so there\'s no need to update the python-\nopenstackclient package before upgrade.\n\nChange-Id: I2aba7515ec43926ec4f8de5c701467dea31dba1b\n\nBe more aggressive on accepted packet loss during upgrade\n\nTests have shown that the packet loss shouldn\'t eceed 1% during\nthe upgrade steps. This change adjusts the accepted level to this.\n\nChange-Id: I9e47ea56a78e4e9eab40fca609cbedaecfcf1e14\n\nAdd more tags for the upgrade process.\n\nThis enable one to either do only a small part of the whole process.\nThis can be useful for debugging or development.\n\nChange-Id: Ic6cc9a1e6aa2793fde65636d2ad92bc174173252\n\nUse new method of discovering tag and adjust local registry upload\n\nThis change uses the new mechanism of retrieving the tag from the\nlatest image provided in the registry.\n\nChange-Id: I7e063f13c7d4812e9986452774881235b620bd0e\n\nSwap baremetal environment file for containerized.\n\nIn oooq, when upgrading from baremetal\nto containerized overcloud two different\nenvironment files are used. These env\nfiles are located in [0].\n\nWhen upgrading using tripleo-upgrade, we\nneed to convert that environment file name\nto its corresponding containers version.\n\n[0] https://github.com/openstack/tripleo-heat-templates/tree/master/ci/environments\n\nChange-Id: I6c9fad2f402a162cf663c5089e79c2e10f3d0928\n\nAdd condition to create local docker registry.\n\nThe only way to not execute the docker\nregistry environment file creation task\nis via tags, which is not easy to handle\nin TripleO CI.\n\nAs tripleo-quickstart already prepares\nthe local docker registry file, there\nis no need to execute it. So a new\nparameter \'create_docker_registry\' is\nbeen added.\n\nAlso, the \'force\' option is being added\nto avoid overwritting a provided script\nwith the role template.\n\nChange-Id: I800d6696b8dbb83f05f3d9381c6e5689558f4b77\n\nPrepare workloads before update/upgrade.\n\nPrepare scripts for managing workload on oc before running\n update/upgrade operation.\n\nAllow to run ping test during minor update.\n\nChange-Id: I1d5754f36f53588c97c646aa4e1380e9ca5938bc\n\nRemove tag parsing from the image prepare command\n\nParsing the tag is not needed anymore and the one returned by the\ncontainer image prepare command can be used.\n\nChange-Id: If782fc655da7b22e4d4a803509e9cc8c49774368\n\n[UPDATES] Run minor update per role.\n\nWith recent changes it\'s advised to perform minor update in batches:\nrole-by-role.\nThis change limits the scope of update with \'--nodes <Role>\' option.\n\nChange-Id: I0bc03873b749dc9c15b13cacbfff78cead4360d8\n'}, {'number': 5, 'created': '2017-12-09 03:01:09.000000000', 'files': ['tasks/main.yml', 'templates/l3_agent_stop_ping.sh.j2', 'tasks/upgrade/compute_upgrade.yml', 'tasks/node_upgrade_script.yml', 'tasks/update/main.yml', 'defaults/main.yml', 'tasks/upgrade/docker_registry_images_env.yaml', 'tasks/update/create-update-scripts.yaml', 'tasks/node_upgrade.yml', 'tasks/common/controller_post_scripts.yml', 'templates/undercloud_upgrade.sh.j2', 'templates/oooq_deploy_transformation.sh.j2', 'tasks/upgrade/controller_post_upgrade.yml', 'tasks/upgrade/main.yml', 'templates/create_registry_env.sh.j2', 'tasks/upgrade/local_docker_registry_env.yaml', 'templates/download_images.sh.j2', 'templates/check_service_galera.sh.j2', 'infrared_plugin/plugin.spec', 'templates/workload_launch.sh.j2', 'templates/check_service_haproxy.sh.j2', 'templates/overcloud_update.sh.j2', 'templates/undercloud_update.sh.j2', 'tasks/upgrade/swiftstorage_upgrade.yml', 'templates/update_workarounds.sh.j2', 'README.md', 'templates/check_service_reboot.sh.j2', 'templates/upgrade_undercloud_workarounds.sh.j2', 'templates/node_upgrade_pre.sh.j2', 'tasks/upgrade/convert_ceph_params.yaml', 'tasks/upgrade/undercloud_ssl_camap.yaml', 'templates/node_upgrade_post.sh.j2', 'setup.cfg', 'tasks/common/controller_post_script.yml', 'tasks/upgrade/non_controller_upgrade_scripts.yml', 'tasks/upgrade/docker_converge_upgrade.yml', 'tasks/upgrade/convert_roles_data.yaml', 'tasks/upgrade/controller_node_upgrade.yml', 'tasks/upgrade/docker_composable_upgrade.yml', 'tasks/undercloud_validate_upgrade.yaml', 'tasks/container_images.yaml', 'templates/check_service_rabbitmq.sh.j2', 'tasks/upgrade/undercloud_validate_upgrade.yaml', 'tests/oooq-test.yaml', 'tasks/docker_composable_upgrade.yml', 'tasks/upgrade/node_upgrade_script.yml', 'tasks/upgrade/use_oooq.yaml', 'infrared_plugin/main.yml', 'tasks/upgrade/create-upgrade-scripts.yaml', 'templates/cephosd.yaml.j2', 'tasks/upgrade/container_images.yaml', 'templates/overcloud_update_setup.sh.j2', 'templates/workarounds.sh.j2', 'templates/upgrade_overcloud_workarounds.sh.j2', 'tasks/upgrade/step_upgrade.yml', 'templates/check_service_redis.sh.j2', 'tests/test.yml', 'tasks/common/create_workload.yml', 'templates/node_upgrade.sh.j2', 'tasks/upgrade/node_upgrade.yml', 'tasks/create-scripts.yaml', 'templates/check_service_haproxy_backend.sh.j2', 'templates/dpdk-upgrade-env.yaml.j2', 'templates/l3_agent_start_ping.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/4572055ffb52b9fe6ff3567afe709a0a68cf1d6b', 'message': 'Merge tripleo-upgrade repo from redhat-openstack namespace\n\nMake sure scripts are created with the executable bit set.\n\nChange-Id: I731902411e987b4ea7c2aa84fef869fe5e1c25ae\n\nAdd a oooq comptatibility layer, documentation and example.\n\nChange-Id: I30fe6359f1c0098ff9bcdd5939724491d94ef199\n\nAdd support for applying w/a before and after upgrade\n\nThis change adds the ability to apply workarounds before and after\nthe overcloud upgrade process has finished. This allows the user\nto workaround particular issues that show up after the upgrade\nprocess has finished.\n\nChange-Id: I21a7e885bcc466af6bf80410ba2cc8d03865cb33\n\nFix missing quotes\n\nThis changes adds missing quotes to the node_upgrade_script.yml\ntemplates. Currently the task is failing because of the missing quotes.\n\nChange-Id: Ied9217df374d09bf90e6878a7c79e22042f44d99\n\nAdd support for applying workarounds post undercloud upgrade\n\nThis change adds support for applying workarounds after the undercloud\nupgrade process has finished as part of the undercloud upgrade.\n\nChange-Id: If85900969c0d591cf6024408d958a82fa8c8a534\n\nAdjust overcloud_converge_upgrade_script script\n\nThis change adjusts the overcloud_converge_upgrade_script to allow\nrunning the upgrade converge stage. In addition it adjust the ssh\nconfig file to skip host key check so the non-controller script does\nnot get stuck waiting for user input.\n\nChange-Id: Ic38f325c61e90165a5322ef754f7e5514ed8e687\n\nAppend working_dir to logs generated\n\nChange-Id: I6bc9f0c58ad8684ed03dee042e9cfb2bdc6835f6\n\nInstall ceph-ansible during undercloud upgrade\n\nceph-ansible is required to be installed manually for deployments\nwith ceph nodes. This change installs the ceph-ansible package\nbefore the undercloud upgrade.\n\nChange-Id: If8918a38250a10681d965d0715ebc17078166336\n\nUse openstack overcloud container image prepare command\n\nThis change adds the use of openstack overcloud container image prepare\ncommand for generating the environment file containing the container\nimage names and local registry address.\n\nChange-Id: I174f7e3aae415d51224cf73da83a859e90eed095\n\nDo not rely on ansible inventory for upgrading non controller nodes\n\nCurrently we are relying on the ansible inventory to provide groups\ncontaining compute nodes and their facts when creating the upgrade\nscripts. In order to remove this requirement and provide easier\nintegration this change discovers the compute and swift storage nodes\nfrom the undercloud. In addition it adds a wait loop for instance live\nmigration to complete before and after upgrading compute nodes and adds\nsupport for swift storage nodes upgrade.\n\nChange-Id: Ia4b2e81845c3fec9036c4695f0dd1746d4c5c6b8\n\nAdd silent and nobuffer options to curl command\n\nChange-Id: I0f4bd71b67d4827717d9f7d3fc075fc396eb6363\n\nAdjust tht environment files and custom roles data during upgrade\n\nThis change switches the environment files used in the overcloud deploy\ncommand to their variants used for deploying containers. In addition, if\nusing a custom roles data file for composable roles deployments, this\nchange adjusts the local roles data copy with the changes introduced in\nPike.\n\nChange-Id: Icd3c3b67342c0bd10fc3d28ed89a94fc9f714db4\n\nFix overcloud_deploy_script var location in oooq_test playbook\n\nChange-Id: I01f18a5413ff223cbca900521037e739ebc43d5d\n\nDisconnect ssh session before uploading images to local registry\n\nThis change disconnects the running ssh session in order to allow\nthe stack user to connect to the docker daemon. This acts as a\nworkaround for https://bugs.launchpad.net/tripleo/+bug/1699477\n\nChange-Id: Ia06fe8581ba17525cbcb2d955d7947b7c546811d\n\nAdd undercloud_reboot var and reboot only on ovs or kernel updates\n\nThis change adds the undercloud_reboot var to manipulate if undercloud\nreboots should be made or not and does the reboot only when kernel or\novs updates occur.\n\nChange-Id: Ic89291c5791bbd098204b2c85793335e0faa8d94\n\nAdd InfraRed docs\n\nThis change adds the steps required to run the tripleo-upgrade role\nas an InfraRed plugin.\n\nChange-Id: I08fde6c8954ec4eeedc47971607bec592fc801a1\n\nAdd docs for running the role manually from the undercloud\n\nChange-Id: I6d5bb6479b6e1fb45e34aa776d3c315cfae98ae4\n\nDo not stop services before undercloud upgrade\n\nAccording to the docs stopping services should be done by the undercloud\nupgrade process so we do not need to manually do it.\n\nChange-Id: I7f14257b4e90d3a0610c0f90e856096643325861\n\nSpecifically become_user: root when running ovs command\n\nCurrently become_user is set to the undercloud user, usually\nstack, when invoking the undercloud_validate_upgrade.yaml playbook.\nThis change overrides become_user and sets it to root when running\novs-vsctl command as it requires privilege escalation.\n\nChange-Id: Ia93245f4a2d09d73849c03401d38ffb25e7be802\n\nUse ip address instead of name when rebooting\n\nOOOQ doesn\'t set a name for the undercloud in hosts so in case the\nreboot is triggered the virthost cannot reach the undercloud. This\nchange switches the wait condition and calls the ip address instead\nof the name.\n\nChange-Id: I2121e2dabe9794d31fe70bbfa0ff8e53da6b3b1b\n\nAdd reload ssh tag to the Kill SSH task\n\nAdd a tag to the Kill SSH task so it can be avoided when\nrunning the role manually from the undercloud.\n\nChange-Id: Iec088cc174d7e8270fbea0698ee76227b45842f7\n\nAdd option to create script with --setup-heat-output option\n\nAccording to BZ#1477962 in order to be able to run non controller\nupgrade scripts after major upgrade composable steps we need to run\nthe deploy command with the --setup-heat-outputs option.\n\nChange-Id: I8137ff18047a130c5ea8dca2ce11378eabc30329\n\nAdd deprecated params to custom roles data file\n\nIn Pike there were additional flags assigned to the default roles\ndata file. This change adds these flags during the upgrade process\nto the roles defined in the custom roles data file.\n\nChange-Id: I58c2f30ff74d2302027d7488dc03c5146c371649\n\nUse a default value for the HOME env var\n\nChange-Id: I40e2f46f1311dc4b797977c8136ec4037505ef05\n\nUpdate python-openstackclient before undercloud upgrade\n\nUpdating python-openstackclient before undercloud upgrade is a\nrequirement to get undercloud upgrade passing.\n\nChange-Id: I4ab67f9af68036a29e11bb2457d70535bd94b7b0\n\nCreate environment file for injecting undercloud certificate\n\nWhen undercloud is SSL enabled the overcloud nodes need to be aware\nof the undercloud CA cert. This change creates this file during upgrade\nand adds it to the overcloud deploy commands when the overcloud nodes\nare not able to reach the undercloud ssl enabled public endpoints.\n\nChange-Id: I79a03299bc28d0ca2dbd83c28087a4c56f6b2271\n\nConvert puppet ceph parameters to ceph ansible during upgrade\n\nThis is a workaround for BZ#1488855.\n\nChange-Id: I58ac44b2166abddf56a327a4ee09457139c831da\n\nRemove setup heat outputs workaround\n\nhttps://review.openstack.org/#/c/502470/ allows us to obtain the\nRoleConfig output so there\'s no need to run the setup heat outputs\nstep anylonger. This change remove this step.\n\nChange-Id: I7235b8625eea4f77a055d0ab1862d0318f3a776f\n\nEcho bug number in workarounds script\n\nThis change replaces the bug number comments with an echo statement.\nThis provides easier way to debug what workarounds failed to apply\nwhen the workarounds script is run.\n\nChange-Id: I02c5534427ee5cf7b7af618f36577c1008d50992\n\nFix uc_keystone_conn condition\n\nThis change adds an addition condition to inject the undercloud\ncertificate in the CAMap only when  undercloud ssl is enabled.\n\nChange-Id: Iae023922bf1ed0bb22e86710b122c65a8f1568a3\n\nGather facts only from undercloud node\n\nFacts are only required for the undercloud node. This change adjusts\nthe existing playbooks to gather facts only from undercloud node in\norder to save some time and not rely on nodes which are not required\nto be reachable.\n\nChange-Id: Idceec3d10d84ef112da558109d9904a1d8c6ed93\n\nDo not include docker.yaml and docker-ha.yaml environments\n\nAs described in BZ#1466744 the docker.yaml and docker-ha.yaml\nenvironments are currently included by default so we do not need\nto specifically include them.\n\nChange-Id: I44a72ddd65cf816003ceca21ef33470a3ab125a7\n\nReboot compute nodes post upgrade\n\nAs a post upgrade requirement we need to reboot the nodes in case\nof an OVS upgrade. This change runs a post upgrade check for non\ncontroller nodes and reboots the nodes if an ovs upgrade has been\ndetected. It also adds additional validation for compute nodes to\nmake sure that the nova-compute service is enabled after reboot.\n\nChange-Id: I583e589118aabae84f8e1dc9ec2c4b43ca17a250\n\nAdd L3 agent connectivity check during upgrade\n\nThis change adds a check which validates that ICMP\nconnectivity with a floating IP is not interrupted\nduring the major upgrade composable step.\n\nChange-Id: Iee55af85b9a2c3ece86731e043130d191ff6a821\n\nRun pre docker composable upgrade workarounds at correct position\n\nThis change moves the pre docker composable upgrade workarounds to\nbe run right before the docker composable upgrade step.\n\nChange-Id: I604ea2eb6202d48b0f771ea80e5e731df687600e\n\nUse bool with ansible booleans\n\nuse bool filter when using ansible booleans.\n\nChange-Id: Ibeb59772e935cc28a661ccddcaa4773388ce296d\n\nAdd option for creating workloads before upgrade\n\nThis change adds the option to launch an instance before\nstarting upgrade. This operation is useful when doing\ntests such as instance live migration during upgrade or\nfloating ip connectivity testing during upgrade. The\nscript requires a network defined in the external_network_name\nvar which provides external connectivity to exist beforehand.\n\nChange-Id: Ib39e41b36fac7794ea515c8a9d56141866dcfeed\n\nFix pre compute upgrade check\n\nThis change adds the MIGRATING state to be checked before the\ncompute nodes upgrade.\n\nChange-Id: I0073a7e69a71a044882d4760dbb49cd4f455dd89\n\nFix workload_launch position\n\nChange-Id: I6193ac6a60165bb20ece6277067c05696ed6d3b1\n\nRun non controller node pre upgrade script\n\nThis change runs the non controller node pre upgrade script.\nIn addition it exposes the option to run instances migration\nbetween compute nodes during upgrade.\n\nChange-Id: Ief55eecdc85bb620f637c4ed4d9b5bc3243b37d1\n\nUpdate roles_data adjustments to latest changes\n\nThis change updates the roles_data file adjustments to the latest\nchanges.\n\nChange-Id: Ic787b135cdf96b33829e05140e069b398df7196f\n\nUse docker and docker-ha environment files for upstream deployments\n\nChange-Id: I70bb9767e97f616729adff983fff065858a6dcdc\n\nConvert services environments to services-docker only for upstream\n\nPer BZ#116463 in downstream the environments used for extra service\nenablement now point to docker resources.\n\nChange-Id: I379622ec2749ac8b485aec79a7500308ef74214e\n\nEcho debug message to differentiate live migration from block\n\nChange-Id: I69e7f381543d84fcd308acbd3a90f5d0ac23ae1b\n\nAccept <= 5% ICMP packet loss during upgrade connectivity check\n\nChange-Id: I34d1de225c0e391035e22e18f63356e04afbbfd5\n\nReorganize playbooks to separate upgrade/update\n\nThis change adds separate directories for upgrade/update which\nprovides a better separation between updates and upgrades.\n\nChange-Id: Icf1a09514fb0e6236535ae32265bbd3805918478\n\nRun block migrate multiple times\n\nBlock migrate doesn\'t work seem to work if triggered once but it\ndoes if the command is run for a second time. This change runs the\nblock migrate command multiple times to make sure that the instance\ngets migrated.\n\nChange-Id: I8b9a9ecae21f7ce49a03945afec66b9e671622b7\n\nEnsure files/ are part of the setup.cfg files to copy\n\nWhen installing tripleo-upgrade into a .quickstart\nenvironment, the files/ folder wasn\'t getting copied, which is necessary\nat least for ""adjust ssh config to skip host key check"" in\ncreate-upgrade-scripts.yaml.\n\nChange-Id: I7d862ec5c13ba719923c90cc40790b842b582999\n\nAdd tasks for undercloud minor update\n\nStart adding the minor undercloud update tasks\n\nChange-Id: I33705b270e2d5e6a28f1cad8179e1f4b3e4ea975\n\nRemove timeouts from upgrade scripts\n\nDepending on the number of deployed nodes upgrade could take longer\nand we want to rely on the heat stack timeout. This change clears\nany manual timeouts set in the upgrade scripts.\n\nChange-Id: I5d141e2cc13621d3be5fb0c27b0ac3c3fc30d424\n\nMinor updates of RHOS 12.\n\nManage minor update workflow from within tripleo-upgrade repo.\n\nChange-Id: I8c6771af4825ce166e8470413ca4687be0a58cb9\n\nReboot controller nodes post upgrade\n\nThis change adds the option to reboot controller nodes post upgrade\nand performs basic verifications that the clustered services are\nreported as up.\n\nChange-Id: I370d421e5968ae50bd1ff140cdfcf98a4db03a5f\n\nDon\'t force ssh_config on everybody.\n\nThis add an option to be able to not overwrite the ssh_config file.\nAs a side note the ssh_config is missing from the repo, so by default\nthis task is broken.\n\nChange-Id: Idfb78e2b7226a7e6295acd3f250bbfb48d0a103d\n\nFix filter used in the node upgrade scripts\n\nThis change is fixes the current filter used for node upgrade\nscripts so that deployment with $domain.tld format are supported.\n\nChange-Id: I18f43c440bb93e0fcefb664c7d716ff9368673a4\n\nRun live migration multiple times\n\nChange-Id: I7c028defd3cb9080efa7bdbe9daa6ed201df8640\n\nManually inject undercloud SSL cert to overcloud nodes\n\nPer BZ#1501779 the compute nodes do not get their trusted store\nupdated when using a CAMap and upgrade fails. This change updates\nthe overcloud nodes trusted store manually so the overcloud nodes\nare prepared for update. This should translate in a documentation\nstep that before upgrade starts the user needs to make  sure the\novercloud nodes are able to reach the undercloud SSL public\nendpoint.\n\nChange-Id: Ib95a29c608803504a866ae71cbc0082faf3c194f\n\nReplace puppet external ceph environment with ceph-ansible one\n\nThis change replaces during the upgrade the external ceph puppet\nenvironment file with its ceph-ansible equivalent.\n\nChange-Id: I9020e8f7c43f91259b551caa2e20f03be1424106\n\nAppend deprecated params only to predefined roles\n\nWe should append the deprecated params only to predefined roles\nin order to avoid failures such as reported in BZ#1501237.\n\nChange-Id: I3a7c332b35da9639fb6f8e5b38234dc0c55d8499\n\nSplit the post controller scripts into per services scripts\n\nThis change splits the post upgrade controller scripts into\nper service checks and adds them to a common directory so\nthey can be shared between update and upgrade.\n\nChange-Id: I8f2fb6162a5acb8a92057400a7b04e6e2388abaa\n\nAdd the ability to specify a remote docker registry\n\nThis change adds the ability to specify a remote docker registry\nto be used for downloading the Docker images on the undercloud or\nbe used directly by the overcloud nodes during upgrade.\n\nChange-Id: I132a8b94f9a101d1c9c624d202bb01527dc2b844\n\nFix BZ#1499677 workaround condition\n\nIn addition to empty gvwstate.dat file there might be situations\nwhere the gvwstate.dat file is missing after reboot. This patch\naddresses this condition for BZ#1499677 workaround.\n\nChange-Id: I295b133248f48ab41b1748225cbe9359662b280d\n\nCleanup galera resource instead of rebooting node for BZ#1499677\n\nInstead of rebooting the node while implementing the workaround for\nBZ#1499677 we should simply cleanup the Galera resource. This way\nwe can save some time and potential issues caused by an additional\nreboot.\n\nChange-Id: I391daeae41321baec1cbd8c458132a3161cd96d5\n\n[UPDATES] Introduce option for minor updates workarounds.\n\nTo speed up testing of minor updates it might be required\n to apply some patches before they are landed.\nHence we need a flag to differentiate if workarounds are required\n or not\n\nChange-Id: I642e4ade204f5fd30ec9433f1d90a2d539287c5e\n\nDo not pipe curl output in container images environment script\n\nCurl can sometimes exit with exit code 23 when its output is piped\ninto another command. To avoid this errors we save the curl output\nto a file.\n\nChange-Id: I4123b6c66ae2873c11631f229cb8e3eec5a5a66b\n\nUse service environment files when generating the images environment\n\nIn the last build openstack overcloud container image prepare only\ngenerates the parameters for the services included by default. In\norder to make it work when extra non-default services are enabled\nwe need to pass the environment files to the prepare command. This\nchange addresses this issue.\n\nChange-Id: I86ab6faaffcd4c7cc1a07e9a6ed1e890cb5cf980\n\nPlace the oooq deploy command into overcloud_deploy_script var\n\nThis change places the openstack overcloud deploy command with its\narguments in the location defined by the overcloud_deploy_script\nvar. This way we don\'t require oooq users to specifically set the\novercloud_deploy_script to a hardcoded location and make it less\nconfusing.\n\nChange-Id: Id2b14fcffbd169c342df4b5b9105dff81e18e3a0\n\nReplace ceph radosgw environment during upgrade\n\nChange-Id: I489211f39941bba5b1ca2ddf1b635c3bdb0151fe\n\nAvoid losing undercloud connection in TripleO CI.\n\nWhen running the role in the TripleO upstream CI\nthe connectivity to the undercloud gets lost when\nrebooting the undercloud after upgrade or killing\nthe ssh service, this makes the playbook fail.\n\nAs a solution, a flag tripleo_ci has been added.\nThis flag will default to false, and when set to\ntrue no undercloud reboot, nor ssh killing will\nbe executed.\n\nChange-Id: If4a303fff49bbe55cdfb7142d8dd69264ab47ab4\n\nAlign deployment-files option with IR.\n\ndeployment-files option is not a list of choices in IR,\nadjust it accordingly.\n\nChange-Id: I6889e9b75f842cc466278fed5dbf85a80cb58ee0\n\nAppend docker-ha only when needed.\n\nBefore appending the docker-ha.yaml env\nfile, we need to check if the overcloud\nwas deployed with pacemaker. If so, then\nwe\'ll add the env file to the upgrade\nscript.\n\nChange-Id: I9867d86b6d23385c576d2f8c5a25ab3333f7113d\n\nSpecify tht directory used in upgrade script.\n\nWhen deploying with oooq, the generated script\novercloud-deploy.sh is reused in order to append\nthe cooresponding env files for the upgrade.\n\nHowever, if the location of the tripleo-heat-templates\ndirectory is different from the used when deploying\nthen the upgrade does not succeed.\n\nThis change modifies the tripleo-heat-templates\nlocation used to upgrade when the directory found\nin overcloud-deploy.sh is different. If it is the\nsame no change is done.\n\nChange-Id: I55ada3e75b7463b1c14c8734410d2591cf162e67\n\nDon\'t append DockerInsecureRegistryAddress\n\nThis is no longer required as the prepare command detects whether the\nregistry is secure and DockerInsecureRegistryAddress as necessary.\n\nDepends on upstream https://review.openstack.org/#/c/514473/\nRelated-Bug: #1722632\n\nChange-Id: Ia9d91f6280600c59d0079c5d1f26a00f04040426\n\nFix the controller regex during roles_data conversion\n\nThe Ocata roles_data controller role might include a comment for\nthe controller role name. This change adjusts the regexp used during\nthe roles data conversion to take into consideration that comment.\n\nChange-Id: I7b43b1fcb9e477de8e1265ef6aa6ba5149e82d47\n\nUse prepare --set for ceph image parameter\n\nThis is more maintainable, and consistent with other uses of prepare.\n\nChange-Id: Ieec88e271973a248192c2b247cd2c5e0cccbfb7c\n\nAdd storage environment files to be used for containers prepare\n\nThis change adds the storage environments files to be matched when\ncreating the environment file containing the Docker images names\nwhich gets created via container image prepare.\n\nChange-Id: I34c3cdaab1b63ce3f43d748372d35143bc12b8b4\n\nAdd environment file containing required DPDK changes during upgrade\n\nChange-Id: Iabaf16e18ee7546bd6275f8f84226892423a6c95\n\nCreate failed_upgrade log files.\n\nMost of the stack failures in the TripleO\nCI are registered inside two log files\nfailed_upgrade_list.log and failed_upgrade.log.\n\nThis patch adds the option of inject the\nstack failures list command into these two\nlog files, as well as priting out the detailed\nstack failure list (--long).\n\nChange-Id: I4fad989818f67ad0a73e45b47f835750f18c3bb6\n\nReplace storage-environemnt.yaml for upstream only\n\nPer BZ#1502862 the Ceph environment files switch during upgrade is\nonly needed for upstream deployments. This change does the changes\nto accommodate this.\n\nChange-Id: Ia3adb120c9b524c66d069593b0779b3399295fd4\n\nDo not update python-openstackclient before upgrade\n\nBZ#1488471 was fixed so there\'s no need to update the python-\nopenstackclient package before upgrade.\n\nChange-Id: I2aba7515ec43926ec4f8de5c701467dea31dba1b\n\nBe more aggressive on accepted packet loss during upgrade\n\nTests have shown that the packet loss shouldn\'t eceed 1% during\nthe upgrade steps. This change adjusts the accepted level to this.\n\nChange-Id: I9e47ea56a78e4e9eab40fca609cbedaecfcf1e14\n\nAdd more tags for the upgrade process.\n\nThis enable one to either do only a small part of the whole process.\nThis can be useful for debugging or development.\n\nChange-Id: Ic6cc9a1e6aa2793fde65636d2ad92bc174173252\n\nUse new method of discovering tag and adjust local registry upload\n\nThis change uses the new mechanism of retrieving the tag from the\nlatest image provided in the registry.\n\nChange-Id: I7e063f13c7d4812e9986452774881235b620bd0e\n\nSwap baremetal environment file for containerized.\n\nIn oooq, when upgrading from baremetal\nto containerized overcloud two different\nenvironment files are used. These env\nfiles are located in [0].\n\nWhen upgrading using tripleo-upgrade, we\nneed to convert that environment file name\nto its corresponding containers version.\n\n[0] https://github.com/openstack/tripleo-heat-templates/tree/master/ci/environments\n\nChange-Id: I6c9fad2f402a162cf663c5089e79c2e10f3d0928\n\nAdd condition to create local docker registry.\n\nThe only way to not execute the docker\nregistry environment file creation task\nis via tags, which is not easy to handle\nin TripleO CI.\n\nAs tripleo-quickstart already prepares\nthe local docker registry file, there\nis no need to execute it. So a new\nparameter \'create_docker_registry\' is\nbeen added.\n\nAlso, the \'force\' option is being added\nto avoid overwritting a provided script\nwith the role template.\n\nChange-Id: I800d6696b8dbb83f05f3d9381c6e5689558f4b77\n\nPrepare workloads before update/upgrade.\n\nPrepare scripts for managing workload on oc before running\n update/upgrade operation.\n\nAllow to run ping test during minor update.\n\nChange-Id: I1d5754f36f53588c97c646aa4e1380e9ca5938bc\n\nRemove tag parsing from the image prepare command\n\nParsing the tag is not needed anymore and the one returned by the\ncontainer image prepare command can be used.\n\nChange-Id: If782fc655da7b22e4d4a803509e9cc8c49774368\n\n[UPDATES] Run minor update per role.\n\nWith recent changes it\'s advised to perform minor update in batches:\nrole-by-role.\nThis change limits the scope of update with \'--nodes <Role>\' option.\n\nChange-Id: I0bc03873b749dc9c15b13cacbfff78cead4360d8\n'}]",0,524141,4572055ffb52b9fe6ff3567afe709a0a68cf1d6b,27,13,5,26343,,,0,"Merge tripleo-upgrade repo from redhat-openstack namespace

Make sure scripts are created with the executable bit set.

Change-Id: I731902411e987b4ea7c2aa84fef869fe5e1c25ae

Add a oooq comptatibility layer, documentation and example.

Change-Id: I30fe6359f1c0098ff9bcdd5939724491d94ef199

Add support for applying w/a before and after upgrade

This change adds the ability to apply workarounds before and after
the overcloud upgrade process has finished. This allows the user
to workaround particular issues that show up after the upgrade
process has finished.

Change-Id: I21a7e885bcc466af6bf80410ba2cc8d03865cb33

Fix missing quotes

This changes adds missing quotes to the node_upgrade_script.yml
templates. Currently the task is failing because of the missing quotes.

Change-Id: Ied9217df374d09bf90e6878a7c79e22042f44d99

Add support for applying workarounds post undercloud upgrade

This change adds support for applying workarounds after the undercloud
upgrade process has finished as part of the undercloud upgrade.

Change-Id: If85900969c0d591cf6024408d958a82fa8c8a534

Adjust overcloud_converge_upgrade_script script

This change adjusts the overcloud_converge_upgrade_script to allow
running the upgrade converge stage. In addition it adjust the ssh
config file to skip host key check so the non-controller script does
not get stuck waiting for user input.

Change-Id: Ic38f325c61e90165a5322ef754f7e5514ed8e687

Append working_dir to logs generated

Change-Id: I6bc9f0c58ad8684ed03dee042e9cfb2bdc6835f6

Install ceph-ansible during undercloud upgrade

ceph-ansible is required to be installed manually for deployments
with ceph nodes. This change installs the ceph-ansible package
before the undercloud upgrade.

Change-Id: If8918a38250a10681d965d0715ebc17078166336

Use openstack overcloud container image prepare command

This change adds the use of openstack overcloud container image prepare
command for generating the environment file containing the container
image names and local registry address.

Change-Id: I174f7e3aae415d51224cf73da83a859e90eed095

Do not rely on ansible inventory for upgrading non controller nodes

Currently we are relying on the ansible inventory to provide groups
containing compute nodes and their facts when creating the upgrade
scripts. In order to remove this requirement and provide easier
integration this change discovers the compute and swift storage nodes
from the undercloud. In addition it adds a wait loop for instance live
migration to complete before and after upgrading compute nodes and adds
support for swift storage nodes upgrade.

Change-Id: Ia4b2e81845c3fec9036c4695f0dd1746d4c5c6b8

Add silent and nobuffer options to curl command

Change-Id: I0f4bd71b67d4827717d9f7d3fc075fc396eb6363

Adjust tht environment files and custom roles data during upgrade

This change switches the environment files used in the overcloud deploy
command to their variants used for deploying containers. In addition, if
using a custom roles data file for composable roles deployments, this
change adjusts the local roles data copy with the changes introduced in
Pike.

Change-Id: Icd3c3b67342c0bd10fc3d28ed89a94fc9f714db4

Fix overcloud_deploy_script var location in oooq_test playbook

Change-Id: I01f18a5413ff223cbca900521037e739ebc43d5d

Disconnect ssh session before uploading images to local registry

This change disconnects the running ssh session in order to allow
the stack user to connect to the docker daemon. This acts as a
workaround for https://bugs.launchpad.net/tripleo/+bug/1699477

Change-Id: Ia06fe8581ba17525cbcb2d955d7947b7c546811d

Add undercloud_reboot var and reboot only on ovs or kernel updates

This change adds the undercloud_reboot var to manipulate if undercloud
reboots should be made or not and does the reboot only when kernel or
ovs updates occur.

Change-Id: Ic89291c5791bbd098204b2c85793335e0faa8d94

Add InfraRed docs

This change adds the steps required to run the tripleo-upgrade role
as an InfraRed plugin.

Change-Id: I08fde6c8954ec4eeedc47971607bec592fc801a1

Add docs for running the role manually from the undercloud

Change-Id: I6d5bb6479b6e1fb45e34aa776d3c315cfae98ae4

Do not stop services before undercloud upgrade

According to the docs stopping services should be done by the undercloud
upgrade process so we do not need to manually do it.

Change-Id: I7f14257b4e90d3a0610c0f90e856096643325861

Specifically become_user: root when running ovs command

Currently become_user is set to the undercloud user, usually
stack, when invoking the undercloud_validate_upgrade.yaml playbook.
This change overrides become_user and sets it to root when running
ovs-vsctl command as it requires privilege escalation.

Change-Id: Ia93245f4a2d09d73849c03401d38ffb25e7be802

Use ip address instead of name when rebooting

OOOQ doesn't set a name for the undercloud in hosts so in case the
reboot is triggered the virthost cannot reach the undercloud. This
change switches the wait condition and calls the ip address instead
of the name.

Change-Id: I2121e2dabe9794d31fe70bbfa0ff8e53da6b3b1b

Add reload ssh tag to the Kill SSH task

Add a tag to the Kill SSH task so it can be avoided when
running the role manually from the undercloud.

Change-Id: Iec088cc174d7e8270fbea0698ee76227b45842f7

Add option to create script with --setup-heat-output option

According to BZ#1477962 in order to be able to run non controller
upgrade scripts after major upgrade composable steps we need to run
the deploy command with the --setup-heat-outputs option.

Change-Id: I8137ff18047a130c5ea8dca2ce11378eabc30329

Add deprecated params to custom roles data file

In Pike there were additional flags assigned to the default roles
data file. This change adds these flags during the upgrade process
to the roles defined in the custom roles data file.

Change-Id: I58c2f30ff74d2302027d7488dc03c5146c371649

Use a default value for the HOME env var

Change-Id: I40e2f46f1311dc4b797977c8136ec4037505ef05

Update python-openstackclient before undercloud upgrade

Updating python-openstackclient before undercloud upgrade is a
requirement to get undercloud upgrade passing.

Change-Id: I4ab67f9af68036a29e11bb2457d70535bd94b7b0

Create environment file for injecting undercloud certificate

When undercloud is SSL enabled the overcloud nodes need to be aware
of the undercloud CA cert. This change creates this file during upgrade
and adds it to the overcloud deploy commands when the overcloud nodes
are not able to reach the undercloud ssl enabled public endpoints.

Change-Id: I79a03299bc28d0ca2dbd83c28087a4c56f6b2271

Convert puppet ceph parameters to ceph ansible during upgrade

This is a workaround for BZ#1488855.

Change-Id: I58ac44b2166abddf56a327a4ee09457139c831da

Remove setup heat outputs workaround

https://review.openstack.org/#/c/502470/ allows us to obtain the
RoleConfig output so there's no need to run the setup heat outputs
step anylonger. This change remove this step.

Change-Id: I7235b8625eea4f77a055d0ab1862d0318f3a776f

Echo bug number in workarounds script

This change replaces the bug number comments with an echo statement.
This provides easier way to debug what workarounds failed to apply
when the workarounds script is run.

Change-Id: I02c5534427ee5cf7b7af618f36577c1008d50992

Fix uc_keystone_conn condition

This change adds an addition condition to inject the undercloud
certificate in the CAMap only when  undercloud ssl is enabled.

Change-Id: Iae023922bf1ed0bb22e86710b122c65a8f1568a3

Gather facts only from undercloud node

Facts are only required for the undercloud node. This change adjusts
the existing playbooks to gather facts only from undercloud node in
order to save some time and not rely on nodes which are not required
to be reachable.

Change-Id: Idceec3d10d84ef112da558109d9904a1d8c6ed93

Do not include docker.yaml and docker-ha.yaml environments

As described in BZ#1466744 the docker.yaml and docker-ha.yaml
environments are currently included by default so we do not need
to specifically include them.

Change-Id: I44a72ddd65cf816003ceca21ef33470a3ab125a7

Reboot compute nodes post upgrade

As a post upgrade requirement we need to reboot the nodes in case
of an OVS upgrade. This change runs a post upgrade check for non
controller nodes and reboots the nodes if an ovs upgrade has been
detected. It also adds additional validation for compute nodes to
make sure that the nova-compute service is enabled after reboot.

Change-Id: I583e589118aabae84f8e1dc9ec2c4b43ca17a250

Add L3 agent connectivity check during upgrade

This change adds a check which validates that ICMP
connectivity with a floating IP is not interrupted
during the major upgrade composable step.

Change-Id: Iee55af85b9a2c3ece86731e043130d191ff6a821

Run pre docker composable upgrade workarounds at correct position

This change moves the pre docker composable upgrade workarounds to
be run right before the docker composable upgrade step.

Change-Id: I604ea2eb6202d48b0f771ea80e5e731df687600e

Use bool with ansible booleans

use bool filter when using ansible booleans.

Change-Id: Ibeb59772e935cc28a661ccddcaa4773388ce296d

Add option for creating workloads before upgrade

This change adds the option to launch an instance before
starting upgrade. This operation is useful when doing
tests such as instance live migration during upgrade or
floating ip connectivity testing during upgrade. The
script requires a network defined in the external_network_name
var which provides external connectivity to exist beforehand.

Change-Id: Ib39e41b36fac7794ea515c8a9d56141866dcfeed

Fix pre compute upgrade check

This change adds the MIGRATING state to be checked before the
compute nodes upgrade.

Change-Id: I0073a7e69a71a044882d4760dbb49cd4f455dd89

Fix workload_launch position

Change-Id: I6193ac6a60165bb20ece6277067c05696ed6d3b1

Run non controller node pre upgrade script

This change runs the non controller node pre upgrade script.
In addition it exposes the option to run instances migration
between compute nodes during upgrade.

Change-Id: Ief55eecdc85bb620f637c4ed4d9b5bc3243b37d1

Update roles_data adjustments to latest changes

This change updates the roles_data file adjustments to the latest
changes.

Change-Id: Ic787b135cdf96b33829e05140e069b398df7196f

Use docker and docker-ha environment files for upstream deployments

Change-Id: I70bb9767e97f616729adff983fff065858a6dcdc

Convert services environments to services-docker only for upstream

Per BZ#116463 in downstream the environments used for extra service
enablement now point to docker resources.

Change-Id: I379622ec2749ac8b485aec79a7500308ef74214e

Echo debug message to differentiate live migration from block

Change-Id: I69e7f381543d84fcd308acbd3a90f5d0ac23ae1b

Accept <= 5% ICMP packet loss during upgrade connectivity check

Change-Id: I34d1de225c0e391035e22e18f63356e04afbbfd5

Reorganize playbooks to separate upgrade/update

This change adds separate directories for upgrade/update which
provides a better separation between updates and upgrades.

Change-Id: Icf1a09514fb0e6236535ae32265bbd3805918478

Run block migrate multiple times

Block migrate doesn't work seem to work if triggered once but it
does if the command is run for a second time. This change runs the
block migrate command multiple times to make sure that the instance
gets migrated.

Change-Id: I8b9a9ecae21f7ce49a03945afec66b9e671622b7

Ensure files/ are part of the setup.cfg files to copy

When installing tripleo-upgrade into a .quickstart
environment, the files/ folder wasn't getting copied, which is necessary
at least for ""adjust ssh config to skip host key check"" in
create-upgrade-scripts.yaml.

Change-Id: I7d862ec5c13ba719923c90cc40790b842b582999

Add tasks for undercloud minor update

Start adding the minor undercloud update tasks

Change-Id: I33705b270e2d5e6a28f1cad8179e1f4b3e4ea975

Remove timeouts from upgrade scripts

Depending on the number of deployed nodes upgrade could take longer
and we want to rely on the heat stack timeout. This change clears
any manual timeouts set in the upgrade scripts.

Change-Id: I5d141e2cc13621d3be5fb0c27b0ac3c3fc30d424

Minor updates of RHOS 12.

Manage minor update workflow from within tripleo-upgrade repo.

Change-Id: I8c6771af4825ce166e8470413ca4687be0a58cb9

Reboot controller nodes post upgrade

This change adds the option to reboot controller nodes post upgrade
and performs basic verifications that the clustered services are
reported as up.

Change-Id: I370d421e5968ae50bd1ff140cdfcf98a4db03a5f

Don't force ssh_config on everybody.

This add an option to be able to not overwrite the ssh_config file.
As a side note the ssh_config is missing from the repo, so by default
this task is broken.

Change-Id: Idfb78e2b7226a7e6295acd3f250bbfb48d0a103d

Fix filter used in the node upgrade scripts

This change is fixes the current filter used for node upgrade
scripts so that deployment with $domain.tld format are supported.

Change-Id: I18f43c440bb93e0fcefb664c7d716ff9368673a4

Run live migration multiple times

Change-Id: I7c028defd3cb9080efa7bdbe9daa6ed201df8640

Manually inject undercloud SSL cert to overcloud nodes

Per BZ#1501779 the compute nodes do not get their trusted store
updated when using a CAMap and upgrade fails. This change updates
the overcloud nodes trusted store manually so the overcloud nodes
are prepared for update. This should translate in a documentation
step that before upgrade starts the user needs to make  sure the
overcloud nodes are able to reach the undercloud SSL public
endpoint.

Change-Id: Ib95a29c608803504a866ae71cbc0082faf3c194f

Replace puppet external ceph environment with ceph-ansible one

This change replaces during the upgrade the external ceph puppet
environment file with its ceph-ansible equivalent.

Change-Id: I9020e8f7c43f91259b551caa2e20f03be1424106

Append deprecated params only to predefined roles

We should append the deprecated params only to predefined roles
in order to avoid failures such as reported in BZ#1501237.

Change-Id: I3a7c332b35da9639fb6f8e5b38234dc0c55d8499

Split the post controller scripts into per services scripts

This change splits the post upgrade controller scripts into
per service checks and adds them to a common directory so
they can be shared between update and upgrade.

Change-Id: I8f2fb6162a5acb8a92057400a7b04e6e2388abaa

Add the ability to specify a remote docker registry

This change adds the ability to specify a remote docker registry
to be used for downloading the Docker images on the undercloud or
be used directly by the overcloud nodes during upgrade.

Change-Id: I132a8b94f9a101d1c9c624d202bb01527dc2b844

Fix BZ#1499677 workaround condition

In addition to empty gvwstate.dat file there might be situations
where the gvwstate.dat file is missing after reboot. This patch
addresses this condition for BZ#1499677 workaround.

Change-Id: I295b133248f48ab41b1748225cbe9359662b280d

Cleanup galera resource instead of rebooting node for BZ#1499677

Instead of rebooting the node while implementing the workaround for
BZ#1499677 we should simply cleanup the Galera resource. This way
we can save some time and potential issues caused by an additional
reboot.

Change-Id: I391daeae41321baec1cbd8c458132a3161cd96d5

[UPDATES] Introduce option for minor updates workarounds.

To speed up testing of minor updates it might be required
 to apply some patches before they are landed.
Hence we need a flag to differentiate if workarounds are required
 or not

Change-Id: I642e4ade204f5fd30ec9433f1d90a2d539287c5e

Do not pipe curl output in container images environment script

Curl can sometimes exit with exit code 23 when its output is piped
into another command. To avoid this errors we save the curl output
to a file.

Change-Id: I4123b6c66ae2873c11631f229cb8e3eec5a5a66b

Use service environment files when generating the images environment

In the last build openstack overcloud container image prepare only
generates the parameters for the services included by default. In
order to make it work when extra non-default services are enabled
we need to pass the environment files to the prepare command. This
change addresses this issue.

Change-Id: I86ab6faaffcd4c7cc1a07e9a6ed1e890cb5cf980

Place the oooq deploy command into overcloud_deploy_script var

This change places the openstack overcloud deploy command with its
arguments in the location defined by the overcloud_deploy_script
var. This way we don't require oooq users to specifically set the
overcloud_deploy_script to a hardcoded location and make it less
confusing.

Change-Id: Id2b14fcffbd169c342df4b5b9105dff81e18e3a0

Replace ceph radosgw environment during upgrade

Change-Id: I489211f39941bba5b1ca2ddf1b635c3bdb0151fe

Avoid losing undercloud connection in TripleO CI.

When running the role in the TripleO upstream CI
the connectivity to the undercloud gets lost when
rebooting the undercloud after upgrade or killing
the ssh service, this makes the playbook fail.

As a solution, a flag tripleo_ci has been added.
This flag will default to false, and when set to
true no undercloud reboot, nor ssh killing will
be executed.

Change-Id: If4a303fff49bbe55cdfb7142d8dd69264ab47ab4

Align deployment-files option with IR.

deployment-files option is not a list of choices in IR,
adjust it accordingly.

Change-Id: I6889e9b75f842cc466278fed5dbf85a80cb58ee0

Append docker-ha only when needed.

Before appending the docker-ha.yaml env
file, we need to check if the overcloud
was deployed with pacemaker. If so, then
we'll add the env file to the upgrade
script.

Change-Id: I9867d86b6d23385c576d2f8c5a25ab3333f7113d

Specify tht directory used in upgrade script.

When deploying with oooq, the generated script
overcloud-deploy.sh is reused in order to append
the cooresponding env files for the upgrade.

However, if the location of the tripleo-heat-templates
directory is different from the used when deploying
then the upgrade does not succeed.

This change modifies the tripleo-heat-templates
location used to upgrade when the directory found
in overcloud-deploy.sh is different. If it is the
same no change is done.

Change-Id: I55ada3e75b7463b1c14c8734410d2591cf162e67

Don't append DockerInsecureRegistryAddress

This is no longer required as the prepare command detects whether the
registry is secure and DockerInsecureRegistryAddress as necessary.

Depends on upstream https://review.openstack.org/#/c/514473/
Related-Bug: #1722632

Change-Id: Ia9d91f6280600c59d0079c5d1f26a00f04040426

Fix the controller regex during roles_data conversion

The Ocata roles_data controller role might include a comment for
the controller role name. This change adjusts the regexp used during
the roles data conversion to take into consideration that comment.

Change-Id: I7b43b1fcb9e477de8e1265ef6aa6ba5149e82d47

Use prepare --set for ceph image parameter

This is more maintainable, and consistent with other uses of prepare.

Change-Id: Ieec88e271973a248192c2b247cd2c5e0cccbfb7c

Add storage environment files to be used for containers prepare

This change adds the storage environments files to be matched when
creating the environment file containing the Docker images names
which gets created via container image prepare.

Change-Id: I34c3cdaab1b63ce3f43d748372d35143bc12b8b4

Add environment file containing required DPDK changes during upgrade

Change-Id: Iabaf16e18ee7546bd6275f8f84226892423a6c95

Create failed_upgrade log files.

Most of the stack failures in the TripleO
CI are registered inside two log files
failed_upgrade_list.log and failed_upgrade.log.

This patch adds the option of inject the
stack failures list command into these two
log files, as well as priting out the detailed
stack failure list (--long).

Change-Id: I4fad989818f67ad0a73e45b47f835750f18c3bb6

Replace storage-environemnt.yaml for upstream only

Per BZ#1502862 the Ceph environment files switch during upgrade is
only needed for upstream deployments. This change does the changes
to accommodate this.

Change-Id: Ia3adb120c9b524c66d069593b0779b3399295fd4

Do not update python-openstackclient before upgrade

BZ#1488471 was fixed so there's no need to update the python-
openstackclient package before upgrade.

Change-Id: I2aba7515ec43926ec4f8de5c701467dea31dba1b

Be more aggressive on accepted packet loss during upgrade

Tests have shown that the packet loss shouldn't eceed 1% during
the upgrade steps. This change adjusts the accepted level to this.

Change-Id: I9e47ea56a78e4e9eab40fca609cbedaecfcf1e14

Add more tags for the upgrade process.

This enable one to either do only a small part of the whole process.
This can be useful for debugging or development.

Change-Id: Ic6cc9a1e6aa2793fde65636d2ad92bc174173252

Use new method of discovering tag and adjust local registry upload

This change uses the new mechanism of retrieving the tag from the
latest image provided in the registry.

Change-Id: I7e063f13c7d4812e9986452774881235b620bd0e

Swap baremetal environment file for containerized.

In oooq, when upgrading from baremetal
to containerized overcloud two different
environment files are used. These env
files are located in [0].

When upgrading using tripleo-upgrade, we
need to convert that environment file name
to its corresponding containers version.

[0] https://github.com/openstack/tripleo-heat-templates/tree/master/ci/environments

Change-Id: I6c9fad2f402a162cf663c5089e79c2e10f3d0928

Add condition to create local docker registry.

The only way to not execute the docker
registry environment file creation task
is via tags, which is not easy to handle
in TripleO CI.

As tripleo-quickstart already prepares
the local docker registry file, there
is no need to execute it. So a new
parameter 'create_docker_registry' is
been added.

Also, the 'force' option is being added
to avoid overwritting a provided script
with the role template.

Change-Id: I800d6696b8dbb83f05f3d9381c6e5689558f4b77

Prepare workloads before update/upgrade.

Prepare scripts for managing workload on oc before running
 update/upgrade operation.

Allow to run ping test during minor update.

Change-Id: I1d5754f36f53588c97c646aa4e1380e9ca5938bc

Remove tag parsing from the image prepare command

Parsing the tag is not needed anymore and the one returned by the
container image prepare command can be used.

Change-Id: If782fc655da7b22e4d4a803509e9cc8c49774368

[UPDATES] Run minor update per role.

With recent changes it's advised to perform minor update in batches:
role-by-role.
This change limits the scope of update with '--nodes <Role>' option.

Change-Id: I0bc03873b749dc9c15b13cacbfff78cead4360d8
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/41/524141/3 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'templates/l3_agent_stop_ping.sh.j2', 'tasks/upgrade/compute_upgrade.yml', 'tasks/node_upgrade_script.yml', 'tasks/update/main.yml', 'defaults/main.yml', 'tasks/upgrade/docker_registry_images_env.yaml', 'tasks/update/create-update-scripts.yaml', 'tasks/node_upgrade.yml', 'tasks/common/controller_post_scripts.yml', 'templates/undercloud_upgrade.sh.j2', 'templates/oooq_deploy_transformation.sh.j2', 'tasks/upgrade/controller_post_upgrade.yml', 'tasks/upgrade/main.yml', 'templates/create_registry_env.sh.j2', 'tasks/upgrade/local_docker_registry_env.yaml', 'templates/download_images.sh.j2', 'templates/check_service_galera.sh.j2', 'infrared_plugin/plugin.spec', 'templates/workload_launch.sh.j2', 'templates/check_service_haproxy.sh.j2', 'templates/overcloud_update.sh.j2', 'templates/undercloud_update.sh.j2', 'tasks/upgrade/swiftstorage_upgrade.yml', 'templates/update_workarounds.sh.j2', 'README.md', 'templates/check_service_reboot.sh.j2', 'templates/upgrade_undercloud_workarounds.sh.j2', 'templates/node_upgrade_pre.sh.j2', 'tasks/upgrade/convert_ceph_params.yaml', 'tasks/upgrade/undercloud_ssl_camap.yaml', 'templates/node_upgrade_post.sh.j2', 'setup.cfg', 'tasks/common/controller_post_script.yml', 'tasks/upgrade/non_controller_upgrade_scripts.yml', 'tasks/upgrade/docker_converge_upgrade.yml', 'tasks/upgrade/convert_roles_data.yaml', 'tasks/upgrade/controller_node_upgrade.yml', 'tasks/upgrade/docker_composable_upgrade.yml', 'tasks/undercloud_validate_upgrade.yaml', 'tasks/container_images.yaml', 'templates/check_service_rabbitmq.sh.j2', 'tasks/upgrade/undercloud_validate_upgrade.yaml', 'tests/oooq-test.yaml', 'tasks/docker_composable_upgrade.yml', 'tasks/upgrade/node_upgrade_script.yml', 'tasks/upgrade/use_oooq.yaml', 'infrared_plugin/main.yml', 'tasks/upgrade/create-upgrade-scripts.yaml', 'templates/cephosd.yaml.j2', 'tasks/upgrade/container_images.yaml', 'templates/overcloud_update_setup.sh.j2', 'templates/workarounds.sh.j2', 'templates/upgrade_overcloud_workarounds.sh.j2', 'tasks/upgrade/step_upgrade.yml', 'templates/check_service_redis.sh.j2', 'tests/test.yml', 'tasks/common/create_workload.yml', 'templates/node_upgrade.sh.j2', 'tasks/upgrade/node_upgrade.yml', 'tasks/create-scripts.yaml', 'templates/check_service_haproxy_backend.sh.j2', 'templates/dpdk-upgrade-env.yaml.j2', 'templates/l3_agent_start_ping.sh.j2']",64,e02f4175b554c15101f64f17449b71f4bb5e1536,merge_tripleo-upgrade,"#!/bin/bash # # Script which start an ICMP connectivity check on the first in use # floating IP during upgrade FIP=$(openstack floating ip list -f json | jq -r -c '.[] | select(.Port) | .[""Floating IP Address""]' | head -1) ping -D ${FIP} >> ~/ping_results_$(date +%Y%m%d%H%M) & ",,2094,233
openstack%2Fnetworking-midonet~stable%2Focata~I778ddb080cf1bdfffef52003632614dd43ae01ab,openstack/networking-midonet,stable/ocata,I778ddb080cf1bdfffef52003632614dd43ae01ab,Add in-repo jobs,MERGED,2017-11-23 00:57:10.000000000,2017-12-13 07:18:34.000000000,2017-12-13 07:18:34.000000000,"[{'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 00:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/1523fbbd0a014bf841780c6aecdfae17d0a995a9', 'message': 'Add in-repo jobs\n\nBased on the following versions:\n\n    project-config 3782b998e4514c510ebd3bf5956c853fed8eec9e\n    openstack-zuul-jobs be8c79d8b8af3f4f8304d9eca8291692bc9a7a6e\n\nCloses-Bug: #1728766\nChange-Id: I778ddb080cf1bdfffef52003632614dd43ae01ab\n(cherry picked from commit 062d0cf0dddf459231a31134589d426ce6f6d367)\n'}, {'number': 2, 'created': '2017-12-11 13:01:13.000000000', 'files': ['playbooks/tempest-multinode-ml2/post.yaml', 'playbooks/grenade-v2/post.yaml', 'playbooks/rally-v2/post.yaml', 'playbooks/rally-v2/run.yaml', 'playbooks/tempest-aio-v2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/run.yaml', 'playbooks/tempest-aio-v2-full/run.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/post.yaml', 'playbooks/rally-ml2/run.yaml', 'playbooks/tempest-aio-ml2-centos-7/post.yaml', 'playbooks/tempest-aio-ml2/post.yaml', 'playbooks/tempest-aio-v2-full/post.yaml', 'playbooks/grenade-ml2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/post.yaml', 'playbooks/tempest-aio-ml2/run.yaml', '.zuul.yaml', 'playbooks/rally-ml2/post.yaml', 'playbooks/tempest-multinode-ml2/run.yaml', 'playbooks/grenade-ml2/post.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/post.yaml', 'playbooks/grenade-v2/run.yaml', 'playbooks/tempest-aio-v2/post.yaml', 'playbooks/tempest-aio-ml2-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/run.yaml'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/ec038266c83abe4832420a988ef046d6940990a6', 'message': 'Add in-repo jobs\n\nBased on the following versions:\n\n    project-config 3782b998e4514c510ebd3bf5956c853fed8eec9e\n    openstack-zuul-jobs be8c79d8b8af3f4f8304d9eca8291692bc9a7a6e\n\nCloses-Bug: #1728766\nChange-Id: I778ddb080cf1bdfffef52003632614dd43ae01ab\n(cherry picked from commit 062d0cf0dddf459231a31134589d426ce6f6d367)\n'}]",0,522415,ec038266c83abe4832420a988ef046d6940990a6,13,4,2,6854,,,0,"Add in-repo jobs

Based on the following versions:

    project-config 3782b998e4514c510ebd3bf5956c853fed8eec9e
    openstack-zuul-jobs be8c79d8b8af3f4f8304d9eca8291692bc9a7a6e

Closes-Bug: #1728766
Change-Id: I778ddb080cf1bdfffef52003632614dd43ae01ab
(cherry picked from commit 062d0cf0dddf459231a31134589d426ce6f6d367)
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/15/522415/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/tempest-multinode-ml2/post.yaml', 'playbooks/grenade-v2/post.yaml', 'playbooks/rally-v2/post.yaml', 'playbooks/rally-v2/run.yaml', 'playbooks/tempest-aio-v2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/run.yaml', 'playbooks/tempest-aio-v2-full/run.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/post.yaml', 'playbooks/rally-ml2/run.yaml', 'playbooks/tempest-aio-ml2-centos-7/post.yaml', 'playbooks/tempest-aio-ml2/post.yaml', 'playbooks/tempest-aio-v2-full/post.yaml', 'playbooks/grenade-ml2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/post.yaml', 'playbooks/tempest-aio-ml2/run.yaml', '.zuul.yaml', 'playbooks/rally-ml2/post.yaml', 'playbooks/tempest-multinode-ml2/run.yaml', 'playbooks/grenade-ml2/post.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/post.yaml', 'playbooks/grenade-v2/run.yaml', 'playbooks/tempest-aio-v2/post.yaml', 'playbooks/tempest-aio-ml2-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/run.yaml']",25,1523fbbd0a014bf841780c6aecdfae17d0a995a9,bug/1608980-stable/ocata,"- hosts: all name: Autoconverted job legacy-tempest-dsvm-networking-midonet-aio-ml2-full from old job gate-tempest-dsvm-networking-midonet-aio-ml2-full-ubuntu-xenial-nv tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST=1 export BRANCH_OVERRIDE=default if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_GATE_TOPOLOGY=aio # Because we are testing a non standard project, add # our project repository. This makes zuul do the right # reference magic for testing changes. export PROJECTS=""openstack/networking-midonet $PROJECTS"" export PROJECTS=""openstack/neutron-dynamic-routing $PROJECTS"" export PROJECTS=""openstack/networking-l2gw $PROJECTS"" export PROJECTS=""openstack/tap-as-a-service $PROJECTS"" function gate_hook { bash -xe $BASE/new/networking-midonet/devstack/ci/gate_hook.sh ml2-full } export -f gate_hook export DEVSTACK_GATE_SETTINGS=/opt/stack/new/networking-midonet/devstack/devstackgaterc cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",,1367,0
openstack%2Frequirements~stable%2Fnewton~I4164a9dee608a5de4382561419d0897df4b20ddc,openstack/requirements,stable/newton,I4164a9dee608a5de4382561419d0897df4b20ddc,update constraint for tripleo-common to new release 5.4.5,ABANDONED,2017-11-03 20:32:58.000000000,2017-12-13 07:18:22.000000000,,"[{'_account_id': 6593}, {'_account_id': 13404}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-03 20:32:58.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/01f7a72bf2b27ce783dd9631debce6c4085fa0c8', 'message': 'update constraint for tripleo-common to new release 5.4.5\n\nChange-Id: I4164a9dee608a5de4382561419d0897df4b20ddc\nmeta:version: 5.4.5\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Emilien Macchi <emilien@redhat.com>\nmeta:release:Commit: Emilien Macchi <emilien@redhat.com>\nmeta:release:Change-Id: Iac3adf8fa170fd1db41318517666f1eb952abc35\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Code-Review+1: yanpeifei <yanpeifei@gohighsec.com>\nmeta:release:Code-Review+1: melissaml <ma.lei@99cloud.net>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,517722,01f7a72bf2b27ce783dd9631debce6c4085fa0c8,15,4,1,11131,,,0,"update constraint for tripleo-common to new release 5.4.5

Change-Id: I4164a9dee608a5de4382561419d0897df4b20ddc
meta:version: 5.4.5
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Emilien Macchi <emilien@redhat.com>
meta:release:Commit: Emilien Macchi <emilien@redhat.com>
meta:release:Change-Id: Iac3adf8fa170fd1db41318517666f1eb952abc35
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Code-Review+1: yanpeifei <yanpeifei@gohighsec.com>
meta:release:Code-Review+1: melissaml <ma.lei@99cloud.net>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/22/517722/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,01f7a72bf2b27ce783dd9631debce6c4085fa0c8,new-release,tripleo-common===5.4.5,tripleo-common===5.4.4,1,1
openstack%2Frequirements~stable%2Fnewton~I6ad9d4a3d494203530a86f84483084061ce5eabe,openstack/requirements,stable/newton,I6ad9d4a3d494203530a86f84483084061ce5eabe,Use constraints for docs builds in stable/newton,ABANDONED,2017-11-23 17:14:27.000000000,2017-12-13 07:18:10.000000000,,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 17:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a832039c8f72a2c640023e9fd9b191209fc3b549', 'message': 'Use constraints for docs builds in stable/newton\n\nChange-Id: I6ad9d4a3d494203530a86f84483084061ce5eabe\n(cherry picked from commit e9889b07623c223bdc487a2f7eb8085553d5bec9)\n'}, {'number': 2, 'created': '2017-11-24 22:51:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7ca6cd60d4fd6d066fa3d101d6b2ac970a049abe', 'message': 'Use constraints for docs builds in stable/newton\n\nDepends-On: Id6bb6552b0b0e6f9c3584ac48e31505dda1ebc41\nChange-Id: I6ad9d4a3d494203530a86f84483084061ce5eabe\n(cherry picked from commit e9889b07623c223bdc487a2f7eb8085553d5bec9)\n'}]",0,522619,7ca6cd60d4fd6d066fa3d101d6b2ac970a049abe,13,3,2,6593,,,0,"Use constraints for docs builds in stable/newton

Depends-On: Id6bb6552b0b0e6f9c3584ac48e31505dda1ebc41
Change-Id: I6ad9d4a3d494203530a86f84483084061ce5eabe
(cherry picked from commit e9889b07623c223bdc487a2f7eb8085553d5bec9)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/19/522619/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a832039c8f72a2c640023e9fd9b191209fc3b549,fix-docs-ocata-stable/newton,install_command = pip install -U {opts} -c {toxinidir}/upper-constraints.txt {packages},,1,0
openstack%2Frequirements~stable%2Fnewton~I55bf5161d01bc542b1314a874978b6fb02b1c3bb,openstack/requirements,stable/newton,I55bf5161d01bc542b1314a874978b6fb02b1c3bb,update constraint for tripleo-common to new release 5.4.6,ABANDONED,2017-11-14 20:13:09.000000000,2017-12-13 07:17:59.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-14 20:13:09.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/97e404b868ec342ad80237de66c2ec4bee8daaa0', 'message': 'update constraint for tripleo-common to new release 5.4.6\n\nChange-Id: I55bf5161d01bc542b1314a874978b6fb02b1c3bb\nmeta:version: 5.4.6\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Emilien Macchi <emilien@redhat.com>\nmeta:release:Commit: Emilien Macchi <emilien@redhat.com>\nmeta:release:Change-Id: Iae7d6659387fa44e1c4743fa160bb7842bc1c818\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,519740,97e404b868ec342ad80237de66c2ec4bee8daaa0,11,2,1,11131,,,0,"update constraint for tripleo-common to new release 5.4.6

Change-Id: I55bf5161d01bc542b1314a874978b6fb02b1c3bb
meta:version: 5.4.6
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Emilien Macchi <emilien@redhat.com>
meta:release:Commit: Emilien Macchi <emilien@redhat.com>
meta:release:Change-Id: Iae7d6659387fa44e1c4743fa160bb7842bc1c818
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/40/519740/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,97e404b868ec342ad80237de66c2ec4bee8daaa0,new-release,tripleo-common===5.4.6,tripleo-common===5.4.4,1,1
openstack%2Frequirements~stable%2Fnewton~Ibd17adb9c4a56f6850c5a11f9ade390a06b294ef,openstack/requirements,stable/newton,Ibd17adb9c4a56f6850c5a11f9ade390a06b294ef,update constraint for os-apply-config to new release 5.1.1,ABANDONED,2017-11-22 02:40:10.000000000,2017-12-13 07:17:48.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 02:40:10.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/79e0a6d50d5dfc638fd1b8e89fd0628651b4a333', 'message': 'update constraint for os-apply-config to new release 5.1.1\n\nChange-Id: Ibd17adb9c4a56f6850c5a11f9ade390a06b294ef\nmeta:version: 5.1.1\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Emilien Macchi <emilien@redhat.com>\nmeta:release:Commit: Emilien Macchi <emilien@redhat.com>\nmeta:release:Change-Id: I3935869a4bf976c2558da80d433a361c2d4096a0\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>\n'}]",0,522075,79e0a6d50d5dfc638fd1b8e89fd0628651b4a333,7,2,1,11131,,,0,"update constraint for os-apply-config to new release 5.1.1

Change-Id: Ibd17adb9c4a56f6850c5a11f9ade390a06b294ef
meta:version: 5.1.1
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Emilien Macchi <emilien@redhat.com>
meta:release:Commit: Emilien Macchi <emilien@redhat.com>
meta:release:Change-Id: I3935869a4bf976c2558da80d433a361c2d4096a0
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/75/522075/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,79e0a6d50d5dfc638fd1b8e89fd0628651b4a333,new-release,os-apply-config===5.1.1,os-apply-config===5.1.0,1,1
openstack%2Frequirements~stable%2Fnewton~I141cae5f928da47d4b02587db338b1b7dad3661e,openstack/requirements,stable/newton,I141cae5f928da47d4b02587db338b1b7dad3661e,update constraint for os-collect-config to new release 5.2.1,ABANDONED,2017-11-22 02:36:27.000000000,2017-12-13 07:17:41.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 02:36:27.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/8593df60f949ca6e3663f6b1b53d8495fe7bfb32', 'message': 'update constraint for os-collect-config to new release 5.2.1\n\nChange-Id: I141cae5f928da47d4b02587db338b1b7dad3661e\nmeta:version: 5.2.1\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Emilien Macchi <emilien@redhat.com>\nmeta:release:Commit: Emilien Macchi <emilien@redhat.com>\nmeta:release:Change-Id: I3935869a4bf976c2558da80d433a361c2d4096a0\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>\n'}]",0,522072,8593df60f949ca6e3663f6b1b53d8495fe7bfb32,7,2,1,11131,,,0,"update constraint for os-collect-config to new release 5.2.1

Change-Id: I141cae5f928da47d4b02587db338b1b7dad3661e
meta:version: 5.2.1
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Emilien Macchi <emilien@redhat.com>
meta:release:Commit: Emilien Macchi <emilien@redhat.com>
meta:release:Change-Id: I3935869a4bf976c2558da80d433a361c2d4096a0
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/72/522072/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,8593df60f949ca6e3663f6b1b53d8495fe7bfb32,new-release,os-collect-config===5.2.1,os-collect-config===5.2.0,1,1
openstack%2Frequirements~stable%2Fnewton~Ibd64753c71d43ed3330edd596b19dc267da0d63d,openstack/requirements,stable/newton,Ibd64753c71d43ed3330edd596b19dc267da0d63d,update constraint for tripleo-common to new release 5.4.7,ABANDONED,2017-11-22 02:37:43.000000000,2017-12-13 07:17:34.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 02:37:43.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fe946a8a3805e5dd29122195cc35170503ee0428', 'message': 'update constraint for tripleo-common to new release 5.4.7\n\nChange-Id: Ibd64753c71d43ed3330edd596b19dc267da0d63d\nmeta:version: 5.4.7\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Emilien Macchi <emilien@redhat.com>\nmeta:release:Commit: Emilien Macchi <emilien@redhat.com>\nmeta:release:Change-Id: I3935869a4bf976c2558da80d433a361c2d4096a0\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>\n'}]",0,522074,fe946a8a3805e5dd29122195cc35170503ee0428,7,2,1,11131,,,0,"update constraint for tripleo-common to new release 5.4.7

Change-Id: Ibd64753c71d43ed3330edd596b19dc267da0d63d
meta:version: 5.4.7
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Emilien Macchi <emilien@redhat.com>
meta:release:Commit: Emilien Macchi <emilien@redhat.com>
meta:release:Change-Id: I3935869a4bf976c2558da80d433a361c2d4096a0
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/522074/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,fe946a8a3805e5dd29122195cc35170503ee0428,new-release,tripleo-common===5.4.7,tripleo-common===5.4.4,1,1
openstack%2Frequirements~stable%2Fnewton~I6018ec17cc435a54fa9aed83bf53a27967e78831,openstack/requirements,stable/newton,I6018ec17cc435a54fa9aed83bf53a27967e78831,Backport zuulv3 configuration to stable branches,ABANDONED,2017-11-22 11:55:27.000000000,2017-12-13 07:17:25.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 11:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/18c6c37aae5b5b528cbeac533c39ee6213905bdb', 'message': ""Backport zuulv3 configuration to stable branches\n\nThis change contains the following changes squashed:\n\nAdd copy project-config's legacy-requirements-cross-* jobs\n\nThese are going to be rewritten to native zuulv3 jobs\nin the next commit.\n\nNeeded-By: I3b0dbdcc02a0a8cff0c52701fadf7632648afb97\nChange-Id: I3b9a86528350242c4d785d0f49c318de6c29ec75\nCloses-Bug: #1730673\n\nAdd requirements-check job\n\nThis is a straight copy of the original gate-{name}-requirements job,\nexcept it copies the script over to the host rather than depending on a\nbaked-in copy of the script. Followups should rework it to stop using\nzuul-cloner.\n\n(jlk) updated to fix pep8 errors so that the patch can land.\n\nChange-Id: I734db3b3e4d445e15084d1ca6e60cf2fe392385d\n\nFix check-requirements\n\nFix check-requirements: The assumptions with remote branch are not valid\nanymore with Zuul v3, the change is on the proposed branch, check against\nHEAD^1 instead.\n\nUse the command module instead of script to get stdout in the\njob-output.txt.gz file. Zuul v3 currently will not record the output from script\nmodule in that file, only when command is used.\n\nNote that the script module copied the file to the remote system - the\nsystem where the tests are run - while command does not do this. But\nthe command is already on the remote system, use correct path for it.\n\nCo-Authored-By: James E. Blair <corvus@inaugust.com>\nChange-Id: Ib44332b4daf63b9d3fca6eadf0b4825614ca4aeb\n\nAdd a Zuul v3 native cross-check job\n\nConvert the existing legacy-cross-* jobs over to the\nnew cross-check-job.\n\nAdds a small bump to upper-constraints in order to test\nthe success of this review.\n\nCo-Authored-By: Dirk Mueller <dirk@dmllr.de>\nChange-Id: Iba6a025e3a10185ad1d8217244b967713cace3f6\n\nChange-Id: I6018ec17cc435a54fa9aed83bf53a27967e78831\n(cherry picked from commit 688cda42199a433d2a0ab358f105f6cbe1efc1ff)\n""}, {'number': 2, 'created': '2017-11-23 17:14:48.000000000', 'files': ['playbooks/requirements-check.yaml', '.zuul.d/project-template.yaml', '.zuul.d/project.yaml', 'playbooks/files/project-requirements-change.py', '.zuul.d/jobs.yaml', '.zuul.d/cross-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c4eb5203981285c41e75641cf8dcae9fbff3a684', 'message': ""Backport zuulv3 configuration to stable branches\n\nThis change contains the following changes squashed:\n\nAdd copy project-config's legacy-requirements-cross-* jobs\n\nThese are going to be rewritten to native zuulv3 jobs\nin the next commit.\n\nNeeded-By: I3b0dbdcc02a0a8cff0c52701fadf7632648afb97\nChange-Id: I3b9a86528350242c4d785d0f49c318de6c29ec75\nCloses-Bug: #1730673\n\nAdd requirements-check job\n\nThis is a straight copy of the original gate-{name}-requirements job,\nexcept it copies the script over to the host rather than depending on a\nbaked-in copy of the script. Followups should rework it to stop using\nzuul-cloner.\n\n(jlk) updated to fix pep8 errors so that the patch can land.\n\nChange-Id: I734db3b3e4d445e15084d1ca6e60cf2fe392385d\n\nFix check-requirements\n\nFix check-requirements: The assumptions with remote branch are not valid\nanymore with Zuul v3, the change is on the proposed branch, check against\nHEAD^1 instead.\n\nUse the command module instead of script to get stdout in the\njob-output.txt.gz file. Zuul v3 currently will not record the output from script\nmodule in that file, only when command is used.\n\nNote that the script module copied the file to the remote system - the\nsystem where the tests are run - while command does not do this. But\nthe command is already on the remote system, use correct path for it.\n\nCo-Authored-By: James E. Blair <corvus@inaugust.com>\nChange-Id: Ib44332b4daf63b9d3fca6eadf0b4825614ca4aeb\n\nAdd a Zuul v3 native cross-check job\n\nConvert the existing legacy-cross-* jobs over to the\nnew cross-check-job.\n\nAdds a small bump to upper-constraints in order to test\nthe success of this review.\n\nCo-Authored-By: Dirk Mueller <dirk@dmllr.de>\nChange-Id: Iba6a025e3a10185ad1d8217244b967713cace3f6\n\nChange-Id: I6018ec17cc435a54fa9aed83bf53a27967e78831\n(cherry picked from commit 688cda42199a433d2a0ab358f105f6cbe1efc1ff)\n""}]",0,522223,c4eb5203981285c41e75641cf8dcae9fbff3a684,7,2,2,6593,,,0,"Backport zuulv3 configuration to stable branches

This change contains the following changes squashed:

Add copy project-config's legacy-requirements-cross-* jobs

These are going to be rewritten to native zuulv3 jobs
in the next commit.

Needed-By: I3b0dbdcc02a0a8cff0c52701fadf7632648afb97
Change-Id: I3b9a86528350242c4d785d0f49c318de6c29ec75
Closes-Bug: #1730673

Add requirements-check job

This is a straight copy of the original gate-{name}-requirements job,
except it copies the script over to the host rather than depending on a
baked-in copy of the script. Followups should rework it to stop using
zuul-cloner.

(jlk) updated to fix pep8 errors so that the patch can land.

Change-Id: I734db3b3e4d445e15084d1ca6e60cf2fe392385d

Fix check-requirements

Fix check-requirements: The assumptions with remote branch are not valid
anymore with Zuul v3, the change is on the proposed branch, check against
HEAD^1 instead.

Use the command module instead of script to get stdout in the
job-output.txt.gz file. Zuul v3 currently will not record the output from script
module in that file, only when command is used.

Note that the script module copied the file to the remote system - the
system where the tests are run - while command does not do this. But
the command is already on the remote system, use correct path for it.

Co-Authored-By: James E. Blair <corvus@inaugust.com>
Change-Id: Ib44332b4daf63b9d3fca6eadf0b4825614ca4aeb

Add a Zuul v3 native cross-check job

Convert the existing legacy-cross-* jobs over to the
new cross-check-job.

Adds a small bump to upper-constraints in order to test
the success of this review.

Co-Authored-By: Dirk Mueller <dirk@dmllr.de>
Change-Id: Iba6a025e3a10185ad1d8217244b967713cace3f6

Change-Id: I6018ec17cc435a54fa9aed83bf53a27967e78831
(cherry picked from commit 688cda42199a433d2a0ab358f105f6cbe1efc1ff)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/23/522223/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.d/project-template.yaml', 'playbooks/requirements-check.yaml', '.zuul.d/project.yaml', 'playbooks/files/project-requirements-change.py', '.zuul.d/jobs.yaml', '.zuul.d/cross-jobs.yaml']",6,18c6c37aae5b5b528cbeac533c39ee6213905bdb,bug/1730673-stable/ocata-stable/newton,"- job: name: requirements-cross-test parent: openstack-tox description: | A parent job to perform cross-repository tests. Inherit from this job, and add the intended project to ``required-projects``. Also, set the following variable: .. zuul:jobvar:: tox_envlist Use the specified tox environments (``ALL`` selects all). vars: zuul_work_dir: ""{{ (zuul.projects | selectattr('required') | selectattr('name', 'match', '^(?!openstack/requirements)') | list)[0].src_dir }}"" # NOTE(jeblair): temporarily disabled tox_siblings until the fix # in https://review.openstack.org/514058 lands. tox_install_siblings: false files: - upper-constraints.txt - .zuul.d/cross-jobs.yaml - job: name: cross-cinder-py27 parent: requirements-cross-test description: Run cross-project tests on cinder with py27. required-projects: openstack/cinder vars: tox_envlist: py27 - job: name: cross-cinder-py35 parent: requirements-cross-test description: Run cross-project tests on cinder with py35. required-projects: openstack/cinder # cinder seems to have very nasty races in its unit tests voting: false vars: tox_envlist: py35 - job: name: cross-glance-py27 parent: requirements-cross-test description: Run cross-project tests on glance with py27. required-projects: openstack/glance vars: tox_envlist: py27 - job: name: cross-glance-py35 parent: requirements-cross-test description: Run cross-project tests on glance with py35. required-projects: openstack/glance vars: tox_envlist: py35 - job: name: cross-horizon-py27 parent: requirements-cross-test description: Run cross-project tests on horizon with py27. required-projects: openstack/horizon vars: tox_envlist: py27 - job: name: cross-horizon-py35 parent: requirements-cross-test description: Run cross-project tests on horizon with py35. required-projects: openstack/horizon vars: tox_envlist: py35 - job: name: cross-keystone-py27 parent: requirements-cross-test description: Run cross-project tests on keystone with py27. required-projects: openstack/keystone vars: tox_envlist: py27 - job: name: cross-keystone-py35 parent: requirements-cross-test description: Run cross-project tests on keystone with py35. required-projects: openstack/keystone vars: tox_envlist: py35 - job: name: cross-neutron-py27 parent: requirements-cross-test description: Run cross-project tests on neutron with py27. required-projects: openstack/neutron vars: tox_envlist: py27 - job: name: cross-neutron-py35 parent: requirements-cross-test description: Run cross-project tests on neutron with py35. required-projects: openstack/neutron vars: tox_envlist: py35 - job: name: cross-nova-functional parent: requirements-cross-test description: Run cross-project functional tests on nova. required-projects: openstack/nova vars: tox_envlist: functional - job: name: cross-nova-py27 parent: requirements-cross-test description: Run cross-project tests on nova with py27. required-projects: openstack/nova vars: tox_envlist: py27 - job: name: cross-nova-py35 parent: requirements-cross-test description: Run cross-project tests on nova with py35. required-projects: openstack/nova vars: tox_envlist: py35 - job: name: cross-swift-py27 parent: requirements-cross-test description: Run cross-project tests on swift with py27. required-projects: openstack/swift vars: tox_envlist: py27 - job: name: cross-swift-py35 parent: requirements-cross-test description: Run cross-project tests on swift with py35. required-projects: openstack/swift vars: tox_envlist: py35 ",,530,0
openstack%2Fkeystonemiddleware~master~I036edd94d3e6c67f47e95114a4856dfc3ebc1113,openstack/keystonemiddleware,master,I036edd94d3e6c67f47e95114a4856dfc3ebc1113,Add missing python-memcached requirements,ABANDONED,2017-12-08 08:34:54.000000000,2017-12-13 07:08:37.000000000,,"[{'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 2903}, {'_account_id': 7191}, {'_account_id': 22348}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-12-08 08:34:54.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/0c5070a035ca2eea200c5a7ab6b40375498463ac', 'message': 'Add missing python-memcached requirements\n\nNow, we depend on oslo.cache [1], and use the private/internal\nmemcache_pool code of the lib, making oslo.cache failing to import\ninstead of just log an error about missing requirement for selected\ndrivers at runtime.\n\nThis change adds the missing dependency since we import internal\nstuffs that require it.\n\n[1] 9d8e2836fe7fca186e0380d8a532540ff5cc5215\n\nChange-Id: I036edd94d3e6c67f47e95114a4856dfc3ebc1113\nCloses-bug: #1737115\n'}]",0,526624,0c5070a035ca2eea200c5a7ab6b40375498463ac,14,6,1,2813,,,0,"Add missing python-memcached requirements

Now, we depend on oslo.cache [1], and use the private/internal
memcache_pool code of the lib, making oslo.cache failing to import
instead of just log an error about missing requirement for selected
drivers at runtime.

This change adds the missing dependency since we import internal
stuffs that require it.

[1] 9d8e2836fe7fca186e0380d8a532540ff5cc5215

Change-Id: I036edd94d3e6c67f47e95114a4856dfc3ebc1113
Closes-bug: #1737115
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/24/526624/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0c5070a035ca2eea200c5a7ab6b40375498463ac,bug/1737115,python-memcached>=1.56 # PSF,,1,0
openstack%2Fnetworking-midonet~stable%2Focata~Ia9e3ec7dd4beeef80a2693b89d25cca9375de554,openstack/networking-midonet,stable/ocata,Ia9e3ec7dd4beeef80a2693b89d25cca9375de554,Drop MANIFEST.in pbr doesn't need it,MERGED,2017-11-23 09:23:38.000000000,2017-12-13 07:04:03.000000000,2017-12-13 07:04:03.000000000,"[{'_account_id': 156}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 09:23:38.000000000', 'files': ['tools/check_manifest.sh', 'tox.ini', 'MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/f2ec2ad58ce3bf1aa038c28baad46a3f1edc51ae', 'message': ""Drop MANIFEST.in pbr doesn't need it\n\nnetworking-midonet uses PBR.\nNow tools/check_manifest.sh doesn't make sense, remove it.\n\nChange-Id: Ia9e3ec7dd4beeef80a2693b89d25cca9375de554\nCloses-bug: #1608980\n(cherry picked from commit bb8291786dd5158a53ae77b8aa0137af4d619c20)\n""}]",0,522493,f2ec2ad58ce3bf1aa038c28baad46a3f1edc51ae,9,5,1,6854,,,0,"Drop MANIFEST.in pbr doesn't need it

networking-midonet uses PBR.
Now tools/check_manifest.sh doesn't make sense, remove it.

Change-Id: Ia9e3ec7dd4beeef80a2693b89d25cca9375de554
Closes-bug: #1608980
(cherry picked from commit bb8291786dd5158a53ae77b8aa0137af4d619c20)
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/93/522493/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/check_manifest.sh', 'tox.ini', 'MANIFEST.in']",3,f2ec2ad58ce3bf1aa038c28baad46a3f1edc51ae,bug/1608980-stable/ocata,,include README.rst include AUTHORS include CONTRIBUTING.rst include LICENSE include TESTING.rst include requirements.txt include test-requirements.txt include etc/policy.json include etc/midonet_rootwrap.filters include midonet/neutron/db/migration/alembic.ini include midonet/neutron/db/migration/alembic_migration/README include midonet/neutron/db/migration/alembic_migration/script.py.mako recursive-include midonet/neutron/db/migration/alembic_migration/versions * recursive-include doc/source * recursive-include api-ref/source * exclude .gitignore exclude .gitreview exclude .coveragerc exclude .pylintrc exclude .testr.conf exclude run_tests.sh exclude tox.ini exclude doc/source/specs exclude babel.cfg recursive-exclude specs * recursive-exclude tools * recursive-exclude devstack * recursive-exclude releasenotes * recursive-exclude midonet/neutron/tests * recursive-exclude rally-jobs * global-exclude *.pyc ,0,70
openstack%2Ftripleo-heat-templates~master~I2cad0b81eeab07785dfd4bb66e582d359504b0aa,openstack/tripleo-heat-templates,master,I2cad0b81eeab07785dfd4bb66e582d359504b0aa,Add glance config for barbican,MERGED,2017-11-30 04:38:16.000000000,2017-12-13 06:58:30.000000000,2017-12-13 06:58:30.000000000,"[{'_account_id': 3153}, {'_account_id': 8623}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-30 04:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/15a793ba1affd2329591da3a81d774ab6237e40c', 'message': 'Add glance config for barbican\n\nConfigure glance to use barbican as a key manager\nwhen barbican is enabled for image signing.\n\nChange-Id: I2cad0b81eeab07785dfd4bb66e582d359504b0aa\nDepends-On: I9e87e7b927fa595d05e1ac872fa1aa1cbe40e5eb\n'}, {'number': 2, 'created': '2017-12-08 00:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9981ae72544e3c060a067c5957c25541c9eb73d2', 'message': 'Add glance config for barbican\n\nConfigure glance to use barbican as a key manager\nwhen barbican is enabled for image signing.\n\nChange-Id: I2cad0b81eeab07785dfd4bb66e582d359504b0aa\nDepends-On: I9e87e7b927fa595d05e1ac872fa1aa1cbe40e5eb\nDepends-On: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\n'}, {'number': 3, 'created': '2017-12-08 22:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/264ff6ec7fc3a19679b7527ec7a512e245206697', 'message': 'Add glance config for barbican\n\nConfigure glance to use barbican as a key manager\nwhen barbican is enabled for image signing.\n\nChange-Id: I2cad0b81eeab07785dfd4bb66e582d359504b0aa\nDepends-On: I06e428e51bf157ea22b7f46b9c00cfdf7bea5a7d\nDepends-On: I159ca055db5e5279a70c43998f46773318406922\n'}, {'number': 4, 'created': '2017-12-11 15:20:05.000000000', 'files': ['puppet/services/barbican-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e3792470f272fa4e08cfe29b9eb8ab49b1d774d', 'message': 'Add glance config for barbican\n\nConfigure glance to use barbican as a key manager\nwhen barbican is enabled for image signing.\n\nChange-Id: I2cad0b81eeab07785dfd4bb66e582d359504b0aa\n'}]",0,524063,1e3792470f272fa4e08cfe29b9eb8ab49b1d774d,28,7,4,9914,,,0,"Add glance config for barbican

Configure glance to use barbican as a key manager
when barbican is enabled for image signing.

Change-Id: I2cad0b81eeab07785dfd4bb66e582d359504b0aa
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/524063/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/barbican-api.yaml'],1,15a793ba1affd2329591da3a81d774ab6237e40c,set_glance_barbican_config," glance_api: glance::api::keymgr_backend: > castellan.key_manager.barbican_key_manager.BarbicanKeyManager glance::api::keymgr_encryption_api_url: get_param: [EndpointMap, BarbicanInternal, uri] glance::api::keymgr_encryption_auth_url: get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]",,7,0
openstack%2Ftripleo-heat-templates~master~Idb1e776b6fa24d6be09b02300d4a57440bd9e05c,openstack/tripleo-heat-templates,master,Idb1e776b6fa24d6be09b02300d4a57440bd9e05c,Add parameters for Barbican worker image,MERGED,2017-12-05 20:06:03.000000000,2017-12-13 06:58:29.000000000,2017-12-13 06:58:29.000000000,"[{'_account_id': 3153}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-05 20:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2d635b0b58f06ebd5ff6ee926e7e004f7b8d3dcf', 'message': 'Add parameters for Barbican worker image\n\nChange-Id: Idb1e776b6fa24d6be09b02300d4a57440bd9e05c\n'}, {'number': 2, 'created': '2017-12-06 19:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a5dda896ab591feac0d0ae5a03750fa84f91a52b', 'message': 'Add parameters for Barbican worker image\n\nChange-Id: Idb1e776b6fa24d6be09b02300d4a57440bd9e05c\n'}, {'number': 3, 'created': '2017-12-08 22:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/248d2b5469dda0ee579ab7faceb70f56a5cdd4ae', 'message': 'Add parameters for Barbican worker image\n\nChange-Id: Idb1e776b6fa24d6be09b02300d4a57440bd9e05c\n'}, {'number': 4, 'created': '2017-12-11 20:38:21.000000000', 'files': ['docker/services/barbican-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f464e3d99f524ea74768d584858f00711bc6272b', 'message': 'Add parameters for Barbican worker image\n\nChange-Id: Idb1e776b6fa24d6be09b02300d4a57440bd9e05c\n'}]",1,525742,f464e3d99f524ea74768d584858f00711bc6272b,29,6,4,9914,,,0,"Add parameters for Barbican worker image

Change-Id: Idb1e776b6fa24d6be09b02300d4a57440bd9e05c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/525742/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/barbican-api.yaml'],1,2d635b0b58f06ebd5ff6ee926e7e004f7b8d3dcf,add_parameters_for_barbican_keystone_listener," DockerBarbicanWorkerImage: description: image type: string /var/lib/kolla/config_files/barbican_worker.json: command: /usr/bin/barbican-worker config_files: - source: ""/var/lib/kolla/config_files/src/*"" dest: ""/"" merge: true preserve_properties: true barbican_worker: image: {get_param: DockerBarbicanWorkerImage} net: host privileged: false restart: always user: root volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - {get_attr: [BarbicanApiLogging, volumes]} - - /var/lib/kolla/config_files/barbican_worker.json:/var/lib/kolla/config_files/config.json:ro - /var/lib/config-data/puppet-generated/barbican/:/var/lib/kolla/config_files/src:ro environment: *kolla_env",,24,0
openstack%2Fproject-config~master~I225d73a2f9321329b34a282e08aea6773622df5b,openstack/project-config,master,I225d73a2f9321329b34a282e08aea6773622df5b,releasenotes: Remove package install,MERGED,2017-12-09 14:33:22.000000000,2017-12-13 06:42:39.000000000,2017-12-13 06:42:39.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 24441}]","[{'number': 1, 'created': '2017-12-09 14:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5b1604417a300bb70f04f7fcc8f1c30af56891e0', 'message': 'releasenotes: Remove package install\n\nThe vast majority of changes to enable running releasenotes without\ninstallating of the package itself are merged. Remove the package\ninstall now.\n\nThe remaining few changes can merge at any time, projects had enough\ntime.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-November/124815.html\n\nChange-Id: I225d73a2f9321329b34a282e08aea6773622df5b\nDepends-On: I6d461a69537d3f7dd44e9b9877f652df656eedd8\n'}, {'number': 2, 'created': '2017-12-11 12:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/61b8da0926eb78bf81bb51f1ca4a34d04eda1754', 'message': 'releasenotes: Remove package install\n\nThe vast majority of changes to enable running releasenotes without\ninstallating of the package itself are merged. Remove the package\ninstall now. Note that install-if-python is the proper role for this,\nthe previous setting was a noop.\n\nThe remaining few changes can merge at any time, projects had enough\ntime.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-November/124815.html\n\nChange-Id: I225d73a2f9321329b34a282e08aea6773622df5b\nDepends-On: I6d461a69537d3f7dd44e9b9877f652df656eedd8\n'}, {'number': 3, 'created': '2017-12-11 13:18:12.000000000', 'files': ['playbooks/releasenotes/run.yaml', 'playbooks/releasenotes/pre.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/51cd3ef0ae422ba8e73b99f6a0f58b6d8ad8ff8f', 'message': 'releasenotes: Remove package install\n\nThe vast majority of changes to enable running releasenotes without\ninstallating of the package itself are merged. Remove the package\ninstall now. Note that install-if-python is the proper role for this,\nthe previous setting was a noop.\n\nThe remaining few changes can merge at any time, projects had enough\ntime.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-November/124815.html\n\nChange-Id: I225d73a2f9321329b34a282e08aea6773622df5b\nDepends-On: I6d461a69537d3f7dd44e9b9877f652df656eedd8\n'}]",0,526851,51cd3ef0ae422ba8e73b99f6a0f58b6d8ad8ff8f,13,5,3,6547,,,0,"releasenotes: Remove package install

The vast majority of changes to enable running releasenotes without
installating of the package itself are merged. Remove the package
install now. Note that install-if-python is the proper role for this,
the previous setting was a noop.

The remaining few changes can merge at any time, projects had enough
time.

See also
http://lists.openstack.org/pipermail/openstack-dev/2017-November/124815.html

Change-Id: I225d73a2f9321329b34a282e08aea6773622df5b
Depends-On: I6d461a69537d3f7dd44e9b9877f652df656eedd8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/526851/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/releasenotes/pre.yaml'],1,5b1604417a300bb70f04f7fcc8f1c30af56891e0,releasenotes-version, # Releasenotes do not need the package itself to be installed install_package: false, # TODO(jaegerandi): Remove once all repos are fixed. install_package: yes,2,2
openstack%2Fproject-config~master~I895e0678953c005a5c894d07a6833fc1b4d01d8f,openstack/project-config,master,I895e0678953c005a5c894d07a6833fc1b4d01d8f,Normalize projects.yaml,MERGED,2017-12-13 06:16:50.000000000,2017-12-13 06:39:28.000000000,2017-12-13 06:39:28.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 06:16:50.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/beb39845e3c4fae3340bc43e003a0500fe03f6f6', 'message': 'Normalize projects.yaml\n\nChange-Id: I895e0678953c005a5c894d07a6833fc1b4d01d8f\n'}]",0,527589,beb39845e3c4fae3340bc43e003a0500fe03f6f6,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I895e0678953c005a5c894d07a6833fc1b4d01d8f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/89/527589/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,beb39845e3c4fae3340bc43e003a0500fe03f6f6,project-yaml-normalization,, upstream: https://github.com/samdoran/ansible-role-redhat-subscription.git,0,1
openstack%2Fansible-role-k8s-mariadb~master~I0c2720e9be8e601388825307c81f396fc6c6f509,openstack/ansible-role-k8s-mariadb,master,I0c2720e9be8e601388825307c81f396fc6c6f509,zuul.projects is now a hash,MERGED,2017-12-12 07:13:50.000000000,2017-12-13 06:35:14.000000000,2017-12-13 06:35:14.000000000,"[{'_account_id': 6159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 07:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-mariadb/commit/fd95226af34ea4d37cd20f05f37e76cb234be0e7', 'message': 'test\n\nChange-Id: I0c2720e9be8e601388825307c81f396fc6c6f509\n'}, {'number': 2, 'created': '2017-12-12 07:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-mariadb/commit/424394aa0b251f564ee82bfb5ce3b0ca15821940', 'message': 'test\n\nChange-Id: I0c2720e9be8e601388825307c81f396fc6c6f509\n'}, {'number': 3, 'created': '2017-12-12 08:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-mariadb/commit/5c2639cddf50a3c2bcbb52797b5a90d61f38ade4', 'message': 'test\n\nChange-Id: I0c2720e9be8e601388825307c81f396fc6c6f509\n'}, {'number': 4, 'created': '2017-12-12 12:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-mariadb/commit/126d03238d3d567e2ebfa3af76dc4a0fa9d74340', 'message': 'zuul.projects is now a hash\n\nChange-Id: I0c2720e9be8e601388825307c81f396fc6c6f509\n'}, {'number': 5, 'created': '2017-12-12 15:59:36.000000000', 'files': ['tests/pre.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-k8s-mariadb/commit/d2ed23ef3caedb44a84c1c8029445bb7667fe267', 'message': 'zuul.projects is now a hash\n\nChange-Id: I0c2720e9be8e601388825307c81f396fc6c6f509\n'}]",0,527325,d2ed23ef3caedb44a84c1c8029445bb7667fe267,15,2,5,6159,,,0,"zuul.projects is now a hash

Change-Id: I0c2720e9be8e601388825307c81f396fc6c6f509
",git fetch https://review.opendev.org/openstack/ansible-role-k8s-mariadb refs/changes/25/527325/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/pre.yml'],1,fd95226af34ea4d37cd20f05f37e76cb234be0e7,," - debug: msg: ""{{zuul.projects}}"" ",,3,0
openstack%2Fsahara-image-elements~master~I3e8459edc6fa94675f5b8f4b8519f11f8f2e3436,openstack/sahara-image-elements,master,I3e8459edc6fa94675f5b8f4b8519f11f8f2e3436,Adding generation of Storm 1.1.1,MERGED,2017-12-07 12:48:48.000000000,2017-12-13 06:25:36.000000000,2017-12-13 06:25:36.000000000,"[{'_account_id': 7213}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 22689}, {'_account_id': 23078}]","[{'number': 1, 'created': '2017-12-07 12:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/ce07026e97b3c2f7633b0b5b69ce4396979ac6a4', 'message': 'Adding generation of Storm 1.1.1\n\nWe are adding the newest version of Storm to image generation\n\nChange-Id: I3e8459edc6fa94675f5b8f4b8519f11f8f2e3436\n'}, {'number': 2, 'created': '2017-12-08 13:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/feb241473330a632458f93bd6aea99b053303e77', 'message': 'Adding generation of Storm 1.1.1\n\nWe are adding the newest version of Storm to image generation\n\nChange-Id: I3e8459edc6fa94675f5b8f4b8519f11f8f2e3436\n'}, {'number': 3, 'created': '2017-12-11 13:32:05.000000000', 'files': ['diskimage-create/diskimage-create.sh'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/589abcce315a973a5526fc22d5386ee3bb808a6e', 'message': 'Adding generation of Storm 1.1.1\n\nWe are adding the newest version of Storm to image generation.\n\nChange-Id: I3e8459edc6fa94675f5b8f4b8519f11f8f2e3436\n'}]",1,526361,589abcce315a973a5526fc22d5386ee3bb808a6e,20,6,3,8932,,,0,"Adding generation of Storm 1.1.1

We are adding the newest version of Storm to image generation.

Change-Id: I3e8459edc6fa94675f5b8f4b8519f11f8f2e3436
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/61/526361/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,ce07026e97b3c2f7633b0b5b69ce4396979ac6a4,storm_v1.1.1," echo "" [-t 0.9.2|1.0.1|1.1.0|1.1.1]"" ""0.9.2"" | ""1.0.1"" | ""1.1.0"" | ""1.1.1"");;"," echo "" [-t 0.9.2|1.0.1|1.1.0]"" ""0.9.2"" | ""1.0.1"" | ""1.1.0"");;",2,2
openstack%2Ftripleo-validations~master~I9c76c3a90fed305b77b80ed39a7b2451f16de21c,openstack/tripleo-validations,master,I9c76c3a90fed305b77b80ed39a7b2451f16de21c,ctlplane-ip-range: Verify lower IP bound is smaller than upper,MERGED,2017-10-06 12:06:02.000000000,2017-12-13 06:20:09.000000000,2017-12-13 06:20:09.000000000,"[{'_account_id': 3}, {'_account_id': 9317}, {'_account_id': 10873}, {'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 18009}, {'_account_id': 20970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-06 12:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/d406e134805c4f6b9c95f5f5863c31884310275f', 'message': 'ctlplane-ip-range: Verify lower IP bound is smaller than upper\n\nChange-Id: I9c76c3a90fed305b77b80ed39a7b2451f16de21c\n'}, {'number': 2, 'created': '2017-10-19 14:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5fcf513083d02403e31612782e9a7c3830515950', 'message': 'ctlplane-ip-range: Verify lower IP bound is smaller than upper\n\nChange-Id: I9c76c3a90fed305b77b80ed39a7b2451f16de21c\n'}, {'number': 3, 'created': '2017-10-20 14:31:29.000000000', 'files': ['releasenotes/notes/ip-range-input-23493c5850ddbf49.yaml', 'validations/library/ip_range.py', 'tripleo_validations/tests/test_ip_range.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/f5ba8e6f2fd3a29c00a86ffd4f4bad07599c864b', 'message': 'ctlplane-ip-range: Verify lower IP bound is smaller than upper\n\nChange-Id: I9c76c3a90fed305b77b80ed39a7b2451f16de21c\n'}]",4,510082,f5ba8e6f2fd3a29c00a86ffd4f4bad07599c864b,21,8,3,9317,,,0,"ctlplane-ip-range: Verify lower IP bound is smaller than upper

Change-Id: I9c76c3a90fed305b77b80ed39a7b2451f16de21c
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/82/510082/2 && git format-patch -1 --stdout FETCH_HEAD,['validations/ctlplane-ip-range.yaml'],1,d406e134805c4f6b9c95f5f5863c31884310275f,ip_range," - name: Set lower and upper IP bounds set_fact: - name: Verify lower IP bound is smaller than upper fail: msg: ""Lower IP bound ({{start}}) must be smaller than upper bound ({{end}})"" when: '""start|ipaddr"" > ""end|ipaddr""' - name: Check the size of the DHCP range for overcloud nodes ip_range: start: ""{{ start }}"" end: ""{{ end }}""", - name: Check the size of the DHCP range for overcloud nodes ip_range:,10,2
openstack%2Ftripleo-validations~master~I63298a1bdd8ae793ec37070559537497e81b8ca4,openstack/tripleo-validations,master,I63298a1bdd8ae793ec37070559537497e81b8ca4,Warn if there are not enough node IPs in pools,MERGED,2017-10-11 17:18:06.000000000,2017-12-13 06:20:08.000000000,2017-12-13 06:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 9317}, {'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-11 17:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/68e2a1a05f600ca271bead3400bb6fa982f31015', 'message': 'Warn if there are not enough node IPs in pools\n\nEnhance the network-validation with an additional check which ensures\nsufficient number of IPs for assigned nodes. Static IP pools are\ndefined in the environments/ips-from-pool-all.yaml file in THT,\nand assigned nodes are saved in plan-environment.yaml. This change\nadds a check which compares the above values to ensure there are enough\nIPs allocated in each pool for every role.\n\nChange-Id: I63298a1bdd8ae793ec37070559537497e81b8ca4\n'}, {'number': 2, 'created': '2017-10-19 16:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/34408b6fe0c25a05b425e95ceb6ddadd10a06276', 'message': 'Warn if there are not enough node IPs in pools\n\nEnhance the network-validation with an additional check which ensures\nsufficient number of IPs for assigned nodes. Static IP pools are\ndefined in the environments/ips-from-pool-all.yaml file in THT,\nand assigned nodes are saved in plan-environment.yaml. This change\nadds a check which compares the above values to ensure there are enough\nIPs allocated in each pool for every role.\n\nChange-Id: I63298a1bdd8ae793ec37070559537497e81b8ca4\n'}, {'number': 3, 'created': '2017-10-20 14:28:18.000000000', 'files': ['releasenotes/notes/node-pool-size-0e109b2c41ad6680.yaml', 'validations/library/network_environment.py', 'tripleo_validations/tests/library/test_network_environment.py', 'validations/network-environment.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/b870fd52bc0f83018b77ff030ac6e6f5c207e8e9', 'message': 'Warn if there are not enough node IPs in pools\n\nEnhance the network-validation with an additional check which ensures\nsufficient number of IPs for assigned nodes. Static IP pools are\ndefined in the environments/ips-from-pool-all.yaml file in THT,\nand assigned nodes are saved in plan-environment.yaml. This change\nadds a check which compares the above values to ensure there are enough\nIPs allocated in each pool for every role.\n\nChange-Id: I63298a1bdd8ae793ec37070559537497e81b8ca4\n'}]",0,511304,b870fd52bc0f83018b77ff030ac6e6f5c207e8e9,19,5,3,9317,,,0,"Warn if there are not enough node IPs in pools

Enhance the network-validation with an additional check which ensures
sufficient number of IPs for assigned nodes. Static IP pools are
defined in the environments/ips-from-pool-all.yaml file in THT,
and assigned nodes are saved in plan-environment.yaml. This change
adds a check which compares the above values to ensure there are enough
IPs allocated in each pool for every role.

Change-Id: I63298a1bdd8ae793ec37070559537497e81b8ca4
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/04/511304/3 && git format-patch -1 --stdout FETCH_HEAD,"['validations/library/network_environment.py', 'validations/network-environment.yaml']",2,68e2a1a05f600ca271bead3400bb6fa982f31015,node_pool_size," plan_env_path: plan-environment.yaml ip_pools_path: environments/ips-from-pool-all.yaml netenv_path: ""{{ network_environment_path }}"" plan_env_path: ""{{ plan_env_path }}"" ip_pools_path: ""{{ ip_pools_path }}"""," path: ""{{ network_environment_path }}""",61,5
openstack%2Ftripleo-validations~master~I70d88ca3a640003f213ad9df4d730e151cd0b1ef,openstack/tripleo-validations,master,I70d88ca3a640003f213ad9df4d730e151cd0b1ef,Enhance repo validation to check for unwanted enabled repos,MERGED,2017-10-26 13:47:45.000000000,2017-12-13 06:20:07.000000000,2017-12-13 06:20:07.000000000,"[{'_account_id': 8449}, {'_account_id': 9317}, {'_account_id': 10112}, {'_account_id': 11491}, {'_account_id': 13039}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-26 13:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/cb3a03b1b464447a952b1fe8f18b3a684f9fa6d8', 'message': 'Enhance repo validation to check for unwanted enabled repos\n\nChange-Id: I70d88ca3a640003f213ad9df4d730e151cd0b1ef\n'}, {'number': 2, 'created': '2017-12-04 11:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/26e21de884fea708a3afbffbb8c2835f04efadf6', 'message': 'Enhance repo validation to check for unwanted enabled repos\n\nChange-Id: I70d88ca3a640003f213ad9df4d730e151cd0b1ef\n'}, {'number': 3, 'created': '2017-12-04 22:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/fa65fd9a24ee219bb6dfa689ed44175212af5523', 'message': 'Enhance repo validation to check for unwanted enabled repos\n\nChange-Id: I70d88ca3a640003f213ad9df4d730e151cd0b1ef\n'}, {'number': 4, 'created': '2017-12-07 14:21:03.000000000', 'files': ['validations/repos.yaml', 'validations/check-repo-availability.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/bf378665b3c6363386293ec5c17624390952ffac', 'message': 'Enhance repo validation to check for unwanted enabled repos\n\nChange-Id: I70d88ca3a640003f213ad9df4d730e151cd0b1ef\n'}]",4,515412,bf378665b3c6363386293ec5c17624390952ffac,24,7,4,9317,,,0,"Enhance repo validation to check for unwanted enabled repos

Change-Id: I70d88ca3a640003f213ad9df4d730e151cd0b1ef
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/12/515412/4 && git format-patch -1 --stdout FETCH_HEAD,"['validations/repos.yaml', 'validations/check-repo-availability.yaml']",2,cb3a03b1b464447a952b1fe8f18b3a684f9fa6d8,repos,,"--- - hosts: undercloud, overcloud vars: metadata: name: Check availability of current repositories description: > Detect whether the repositories listed in `yum repolist` can be connected to and that there is at least one repo configured. groups: - pre-upgrade tasks: - name: Find repository URLs shell: 'yum repolist -v | grep Repo-baseurl | sed ""s/Repo-baseurl.*\(http[^ ]*\).*/\1/g""' register: repository_urls - name: Check if there is at least one repository baseurl fail: msg: No repository found in yum repolist when: repository_urls.stdout_lines|length < 1 - name: Call repository URLs uri: url: ""{{ item }}"" with_items: ""{{ repository_urls.stdout_lines }}"" ",38,23
openstack%2Ftripleo-quickstart~master~I4169e4936e0db1e3965a395a4e947895983a4d28,openstack/tripleo-quickstart,master,I4169e4936e0db1e3965a395a4e947895983a4d28,Add ansible_facts_cache/ to .gitignore,MERGED,2017-12-07 19:56:38.000000000,2017-12-13 06:20:06.000000000,2017-12-13 06:20:06.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-12-07 19:56:38.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f43a76f027ef037a1ffa35475add458a1303e168', 'message': ""Add ansible_facts_cache/ to .gitignore\n\nansible_facts_cache/ is populated when running quickstart or devmode\nfrom the tripleo-quickstart repository directory.\n\nThese show up as unadded changes.  It's likely best to avoid them\nbeing accidentally added to version control.\n\nChange-Id: I4169e4936e0db1e3965a395a4e947895983a4d28\n""}]",0,526497,f43a76f027ef037a1ffa35475add458a1303e168,15,9,1,27427,,,0,"Add ansible_facts_cache/ to .gitignore

ansible_facts_cache/ is populated when running quickstart or devmode
from the tripleo-quickstart repository directory.

These show up as unadded changes.  It's likely best to avoid them
being accidentally added to version control.

Change-Id: I4169e4936e0db1e3965a395a4e947895983a4d28
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/97/526497/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,f43a76f027ef037a1ffa35475add458a1303e168,gitignore-facts-cache, # Ansible facts cache ansible_facts_cache/,,3,0
openstack%2Fceilometer~master~I3a96fdafbc966732096f4db03cd7f035d169a978,openstack/ceilometer,master,I3a96fdafbc966732096f4db03cd7f035d169a978,Move utils.dict_to_keyval to opendaylight,MERGED,2017-11-17 15:21:42.000000000,2017-12-13 06:10:19.000000000,2017-12-13 06:10:19.000000000,"[{'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 20223}, {'_account_id': 22348}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-11-17 15:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/eb4e8b5b0c830f7c6f837276e40ac17c6bf3ef14', 'message': ""Move utils.dict_to_keyval to opendaylight\n\nThis seems to be a data transformation specific to this driver, so let's move\nit there.\n\nChange-Id: I3a96fdafbc966732096f4db03cd7f035d169a978\n""}, {'number': 2, 'created': '2017-12-08 14:47:45.000000000', 'files': ['ceilometer/tests/unit/test_utils.py', 'ceilometer/tests/unit/network/statistics/opendaylight/test_driver.py', 'ceilometer/network/statistics/opendaylight/driver.py', 'ceilometer/utils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ac4fa144ad2b128fa1bfeb6e7e286976c7bb9d4c', 'message': ""Move utils.dict_to_keyval to opendaylight\n\nThis seems to be a data transformation specific to this driver, so let's move\nit there.\n\nChange-Id: I3a96fdafbc966732096f4db03cd7f035d169a978\n""}]",0,521108,ac4fa144ad2b128fa1bfeb6e7e286976c7bb9d4c,16,5,2,1669,,,0,"Move utils.dict_to_keyval to opendaylight

This seems to be a data transformation specific to this driver, so let's move
it there.

Change-Id: I3a96fdafbc966732096f4db03cd7f035d169a978
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/08/521108/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/unit/test_utils.py', 'ceilometer/tests/unit/network/statistics/opendaylight/test_driver.py', 'ceilometer/network/statistics/opendaylight/driver.py', 'ceilometer/utils.py']",4,eb4e8b5b0c830f7c6f837276e40ac17c6bf3ef14,dict-to-keyval,,"def dict_to_keyval(value, key_base=None): """"""Expand a given dict to its corresponding key-value pairs. Generated keys are fully qualified, delimited using dot notation. ie. key = 'key.child_key.grandchild_key[0]' """""" val_iter, key_func = None, None if isinstance(value, dict): val_iter = six.iteritems(value) key_func = lambda k: key_base + '.' + k if key_base else k elif isinstance(value, (tuple, list)): val_iter = enumerate(value) key_func = lambda k: key_base + '[%d]' % k if val_iter: for k, v in val_iter: key_gen = key_func(k) if isinstance(v, dict) or isinstance(v, (tuple, list)): for key_gen, v in dict_to_keyval(v, key_gen): yield key_gen, v else: yield key_gen, v ",43,46
openstack%2Fmagnum-ui~master~I3cf5f6b5063d989f81a0edcf816d919de905422b,openstack/magnum-ui,master,I3cf5f6b5063d989f81a0edcf816d919de905422b,Add '.idea' into .gitignore,MERGED,2017-12-13 05:27:07.000000000,2017-12-13 05:49:57.000000000,2017-12-13 05:49:57.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 05:27:07.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/ec1c6467f22ac8ce72e0739abcfd379f6a30eaef', 'message': ""Add '.idea' into .gitignore\n\nThis patch adds following directory for PyCharm.\n- '.idea'\n\nChange-Id: I3cf5f6b5063d989f81a0edcf816d919de905422b\n""}]",0,527580,ec1c6467f22ac8ce72e0739abcfd379f6a30eaef,6,2,1,16352,,,0,"Add '.idea' into .gitignore

This patch adds following directory for PyCharm.
- '.idea'

Change-Id: I3cf5f6b5063d989f81a0edcf816d919de905422b
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/80/527580/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,ec1c6467f22ac8ce72e0739abcfd379f6a30eaef,maintain-gitignore,.idea,,1,0
openstack%2Fneutron-tempest-plugin~master~I7282fa60db15427c73dfef84a40093904e083db2,openstack/neutron-tempest-plugin,master,I7282fa60db15427c73dfef84a40093904e083db2,Add devstack plugin to ease integration tests,MERGED,2017-12-06 12:05:59.000000000,2017-12-13 05:47:11.000000000,2017-12-13 05:47:11.000000000,"[{'_account_id': 841}, {'_account_id': 1921}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 12393}, {'_account_id': 13252}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 12:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/226aaec98c2c64a197efebf6abe69677705e82b6', 'message': 'DNM: Add devstack plugin to ease integration tests\n\nInstead of requiring users to install the plugin manually, add a\ndevstack plugin that can be enabled in order to perform the\ninstallation.\n\nChange-Id: I7282fa60db15427c73dfef84a40093904e083db2\nTODO: Add to other playbooks\n'}, {'number': 2, 'created': '2017-12-06 15:10:34.000000000', 'files': ['playbooks/neutron-tempest-plugin-scenario-linuxbridge/run.yaml', 'playbooks/neutron-tempest-plugin-dvr-multinode-scenario/run.yaml', 'devstack/plugin.sh', 'playbooks/neutron-tempest-plugin-api/run.yaml', 'devstack/README.rst', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/228d5b8fb960f492486e75c63645b76d809c6058', 'message': 'Add devstack plugin to ease integration tests\n\nInstead of requiring users to install the plugin manually, add a\ndevstack plugin that can be enabled in order to perform the\ninstallation.\n\nChange the integration tests to use the globally installed plugin\ninstead of using TEMPEST_PLUGINS.\n\nChange-Id: I7282fa60db15427c73dfef84a40093904e083db2\n'}]",3,526044,228d5b8fb960f492486e75c63645b76d809c6058,21,8,2,13252,,,0,"Add devstack plugin to ease integration tests

Instead of requiring users to install the plugin manually, add a
devstack plugin that can be enabled in order to perform the
installation.

Change the integration tests to use the globally installed plugin
instead of using TEMPEST_PLUGINS.

Change-Id: I7282fa60db15427c73dfef84a40093904e083db2
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/44/526044/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/neutron-tempest-plugin-scenario-linuxbridge/run.yaml', '.zuul.yaml', 'devstack/plugin.sh', 'devstack/README.rst', 'devstack/settings']",5,226aaec98c2c64a197efebf6abe69677705e82b6,add-devstack-plugin,"GITREPO[""neutron-tempest-plugin""]=${NEUTRON_TEMPEST_REPO:-${GIT_BASE}/openstack/neutron-tempest-plugin.git} GITDIR[""neutron-tempest-plugin""]=$DEST/neutron-tempest-plugin GITBRANCH[""neutron-tempest-plugin""]=master ",,43,2
openstack%2Fstorlets~master~I24e679c2b54d8dacc94e8d2d586e9d332bf341cf,openstack/storlets,master,I24e679c2b54d8dacc94e8d2d586e9d332bf341cf,Rework storlets functional from lagacy to zuul v3,MERGED,2017-12-11 07:07:42.000000000,2017-12-13 05:46:21.000000000,2017-12-13 05:46:21.000000000,"[{'_account_id': 4608}, {'_account_id': 11317}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 07:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/1776d9c2ffd33c79e3168b99abb41387fcb7a2c5', 'message': 'WIP: try out to rework storlets functional from lagacy to zuul v3\n\nChange-Id: I24e679c2b54d8dacc94e8d2d586e9d332bf341cf\n'}, {'number': 2, 'created': '2017-12-12 01:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/9f2d4413d132f632adc188c00863e3e7a6501ed2', 'message': 'WIP: try out to rework storlets functional from lagacy to zuul v3\n\nChange-Id: I24e679c2b54d8dacc94e8d2d586e9d332bf341cf\n'}, {'number': 3, 'created': '2017-12-12 02:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/84e5ff3e441ecafc6da341e88a87f516f7554e6a', 'message': 'WIP: try out to rework storlets functional from lagacy to zuul v3\n\nChange-Id: I24e679c2b54d8dacc94e8d2d586e9d332bf341cf\n'}, {'number': 4, 'created': '2017-12-12 04:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/1aa2642347ae34e4c9cec2e982d65b5b93d29696', 'message': 'Rework storlets functional from lagacy to zuul v3\n\nChange-Id: I24e679c2b54d8dacc94e8d2d586e9d332bf341cf\n'}, {'number': 5, 'created': '2017-12-12 05:15:35.000000000', 'files': ['playbooks/storlets-functional/pre.yaml', '.zuul.yaml', 'playbooks/legacy/storlets-functional/post.yaml', 'playbooks/legacy/storlets-functional/run.yaml', 'playbooks/storlets-functional/run.yaml'], 'web_link': 'https://opendev.org/openstack/storlets/commit/e750de85c1ef6fa8b592743dec5ce90aaf1ca914', 'message': 'Rework storlets functional from lagacy to zuul v3\n\nRelated-change: I4f58dc284b47e4892b812a3f3ff0b8427738131b\n\nChange-Id: I24e679c2b54d8dacc94e8d2d586e9d332bf341cf\n'}]",0,527000,e750de85c1ef6fa8b592743dec5ce90aaf1ca914,21,3,5,4608,,,0,"Rework storlets functional from lagacy to zuul v3

Related-change: I4f58dc284b47e4892b812a3f3ff0b8427738131b

Change-Id: I24e679c2b54d8dacc94e8d2d586e9d332bf341cf
",git fetch https://review.opendev.org/openstack/storlets refs/changes/00/527000/5 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'playbooks/legacy/storlets-functional/post.yaml', 'playbooks/legacy/storlets-functional/run.yaml']",3,1776d9c2ffd33c79e3168b99abb41387fcb7a2c5,zuul-v3,,"- hosts: all name: Autoconverted job legacy-storlets-functional from old job gate-storlets-functional-ubuntu-xenial tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ git://git.openstack.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x tests/setup_functional_test.sh tox -e func executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",3,131
openstack%2Fswift~master~Ie3fe915035b5d9d15f071b3e6d0e8b1b52ad7d8e,openstack/swift,master,Ie3fe915035b5d9d15f071b3e6d0e8b1b52ad7d8e,Do not leak symlinks to proxy & obj layer,ABANDONED,2017-12-08 01:31:22.000000000,2017-12-13 05:44:54.000000000,,"[{'_account_id': 1179}, {'_account_id': 4608}, {'_account_id': 13052}, {'_account_id': 14766}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 01:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1399ebf36bf62da9d135c9092297eea7ad770529', 'message': 'Do not leak symlinks to proxy & obj layer\n\nChange-Id: Ie3fe915035b5d9d15f071b3e6d0e8b1b52ad7d8e\n'}, {'number': 2, 'created': '2017-12-08 19:10:50.000000000', 'files': ['swift/obj/server.py', 'swift/common/middleware/symlink.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/411b3011e006e5c4d82cea25310a69419209145e', 'message': 'Do not leak symlinks to proxy & obj layer\n\nCo-Authored-By: Kota Tsuyuzaki <tsuyuzaki.kota@lab.ntt.co.jp>\n\nSquashed-Change-Id: I7057c28845862f504f3dace8b2dc97acc3ef0219\nRelated-Change-Id: I838ed71bacb3e33916db8dd42c7880d5bb9f8e18\nChange-Id: Ie3fe915035b5d9d15f071b3e6d0e8b1b52ad7d8e\n'}]",1,526564,411b3011e006e5c4d82cea25310a69419209145e,13,5,2,1179,,,0,"Do not leak symlinks to proxy & obj layer

Co-Authored-By: Kota Tsuyuzaki <tsuyuzaki.kota@lab.ntt.co.jp>

Squashed-Change-Id: I7057c28845862f504f3dace8b2dc97acc3ef0219
Related-Change-Id: I838ed71bacb3e33916db8dd42c7880d5bb9f8e18
Change-Id: Ie3fe915035b5d9d15f071b3e6d0e8b1b52ad7d8e
",git fetch https://review.opendev.org/openstack/swift refs/changes/64/526564/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/symlink.py', 'swift/obj/server.py', 'swift/proxy/controllers/obj.py']",3,1399ebf36bf62da9d135c9092297eea7ad770529,symlink_api-patch44," conditional_response=True,"," cr = req.params.get('symlink') == 'get' or \ 'X-Object-Sysmeta-Symlink-Target' not in resp_headers conditional_response=cr,",9,27
openstack%2Fpython-watcherclient~master~Ia2cd0598770359c2727ec569dd7f2531f7b5f40a,openstack/python-watcherclient,master,Ia2cd0598770359c2727ec569dd7f2531f7b5f40a,marker when retrive audit template,MERGED,2017-11-03 08:28:53.000000000,2017-12-13 05:39:09.000000000,2017-12-13 05:39:09.000000000,"[{'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-03 08:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/604d96e929cf8f1aad1b3ed57fd8377a4ba6675c', 'message': 'marker when retrive audit template\n\nChange-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a\n'}, {'number': 2, 'created': '2017-11-20 08:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/f3f0ecb8127b6e0c6a9b47190e90937092c7110c', 'message': 'marker when retrive audit template\n\nChange-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a\n'}, {'number': 3, 'created': '2017-11-20 09:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/1c6d063e2c170aa20e1f0fd0c4962312ef0d6fa1', 'message': 'marker when retrive audit template\n\nChange-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a\n'}, {'number': 4, 'created': '2017-11-20 09:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/f6229f07bdb65681db470448dba0a4a3dd106a5e', 'message': 'marker when retrive audit template\n\nChange-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a\n'}, {'number': 5, 'created': '2017-11-21 14:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/488fb3fa697ea688900b9a264d44ab7ad5a833ed', 'message': 'marker when retrive audit template\n\nChange-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a\n'}, {'number': 6, 'created': '2017-11-22 13:34:18.000000000', 'files': ['watcherclient/v1/audit_template.py', 'watcherclient/v1/audit_template_shell.py', 'watcherclient/tests/unit/v1/test_audit_template_shell.py', 'watcherclient/tests/unit/v1/test_audit_template.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/0257aa911630d6c7fc60eb2629571df173bb2b21', 'message': 'marker when retrive audit template\n\nChange-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a\n'}]",0,517573,0257aa911630d6c7fc60eb2629571df173bb2b21,25,3,6,24501,,,0,"marker when retrive audit template

Change-Id: Ia2cd0598770359c2727ec569dd7f2531f7b5f40a
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/73/517573/6 && git format-patch -1 --stdout FETCH_HEAD,"['watcherclient/v1/audit_template.py', 'watcherclient/v1/audit_template_shell.py']",2,604d96e929cf8f1aad1b3ed57fd8377a4ba6675c,add-marker," parser.add_argument( '--marker', dest='marker', metavar='<marker>', default=None, help=_('UUID of the last audit template of the previous page; ' 'displays list of audit templates after ""marker"".')) if parsed_args.marker is not None: params['marker'] = parsed_args.marker ",,16,1
openstack%2Fnova~master~I8f0c3006d1bb97d228f73256c58a79235cd12670,openstack/nova,master,I8f0c3006d1bb97d228f73256c58a79235cd12670,[placement] Add info about last-modified to contrib docs,MERGED,2017-12-06 14:45:59.000000000,2017-12-13 05:35:18.000000000,2017-12-13 05:35:18.000000000,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}]","[{'number': 1, 'created': '2017-12-06 14:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ed03a5c93d478b24c46588ac9ab8d7cb62d8878', 'message': '[placement] Add info about last-modified to contrib docs\n\nAdd some instructions on how and when to add last-modified headers\nwhen creating a new handler in the placement API.\n\nChange-Id: I8f0c3006d1bb97d228f73256c58a79235cd12670\n'}, {'number': 2, 'created': '2017-12-06 15:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/381624721858a951e9aff75f914641f06b3803b2', 'message': '[placement] Add info about last-modified to contrib docs\n\nAdd some instructions on how and when to add last-modified headers\nwhen creating a new handler in the placement API.\n\nChange-Id: I8f0c3006d1bb97d228f73256c58a79235cd12670\n'}, {'number': 3, 'created': '2017-12-07 19:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b73376feb6f68d449766a9a9ac0acda5453d18d', 'message': '[placement] Add info about last-modified to contrib docs\n\nAdd some instructions on how and when to add last-modified headers\nwhen creating a new handler in the placement API.\n\nChange-Id: I8f0c3006d1bb97d228f73256c58a79235cd12670\n'}, {'number': 4, 'created': '2017-12-11 19:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edf06047e7f92587d1189aac60d8896b35c20d45', 'message': '[placement] Add info about last-modified to contrib docs\n\nAdd some instructions on how and when to add last-modified headers\nwhen creating a new handler in the placement API.\n\nChange-Id: I8f0c3006d1bb97d228f73256c58a79235cd12670\n'}, {'number': 5, 'created': '2017-12-12 15:53:51.000000000', 'files': ['doc/source/contributor/placement.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/413d50e78eac2b7d23c2b2df1330e8f2aee3aa18', 'message': '[placement] Add info about last-modified to contrib docs\n\nAdd some instructions on how and when to add last-modified headers\nwhen creating a new handler in the placement API.\n\nChange-Id: I8f0c3006d1bb97d228f73256c58a79235cd12670\n'}]",1,526084,413d50e78eac2b7d23c2b2df1330e8f2aee3aa18,33,9,5,11564,,,0,"[placement] Add info about last-modified to contrib docs

Add some instructions on how and when to add last-modified headers
when creating a new handler in the placement API.

Change-Id: I8f0c3006d1bb97d228f73256c58a79235cd12670
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/526084/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/placement.rst'],1,8ed03a5c93d478b24c46588ac9ab8d7cb62d8878,bug/1632852,"If a hander returns a response body, a ``Last-Modified`` header should be included with the response. If the entity or entities in the response body are directly associated with an object (or objects, in the case of a collection response) that has an ``updated_at`` (or ``created_at``) field, that field's value can be used as the value of the header (WebOb will take care of turning the datetime object into a string timestamp). A ``util.pick_last_modified`` is available to help choose the most recent last-modified when traversing a collection of entities. If there is no directly associated object (for example, the output is the composite of several objects) then the ``Last-Modified`` time should be ``timeutils.utcnow(with_timezone=True)`` (the timezone must be set in order to be a valid HTTP timestamp). If a ``Last-Modified`` header is set, then a ``Cache-Control`` header with a value of ``no-cache`` must be set as well. This is to avoid user-agents inadvertently caching the responses. ",,18,0
openstack%2Fkolla-ansible~stable%2Fpike~I5654dbf391db7076c82aede5c2a4f8b7530b8381,openstack/kolla-ansible,stable/pike,I5654dbf391db7076c82aede5c2a4f8b7530b8381,Fix launch instance failed in trove,MERGED,2017-12-04 14:07:23.000000000,2017-12-13 05:21:53.000000000,2017-12-13 05:21:53.000000000,"[{'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-04 14:07:23.000000000', 'files': ['ansible/roles/trove/templates/trove.conf.j2', 'ansible/roles/trove/templates/trove-taskmanager.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/05cf49f55a468a98ec39f2bb78af3e25c3489be3', 'message': 'Fix launch instance failed in trove\n\n- remove useless *_url, which can be auto discovery\n- use internalURL instead of publicURL which make it works when\n  using self-signed SSL certification.\n- configure network_driver to Neutron\n- add network_label_regex to match all network name\n\nChange-Id: I5654dbf391db7076c82aede5c2a4f8b7530b8381\nCloses-Bug: #1734039\n(cherry picked from commit 0b931c9347d91de431a0bc85e7005f5f06082627)\n'}]",0,525201,05cf49f55a468a98ec39f2bb78af3e25c3489be3,7,3,1,7488,,,0,"Fix launch instance failed in trove

- remove useless *_url, which can be auto discovery
- use internalURL instead of publicURL which make it works when
  using self-signed SSL certification.
- configure network_driver to Neutron
- add network_label_regex to match all network name

Change-Id: I5654dbf391db7076c82aede5c2a4f8b7530b8381
Closes-Bug: #1734039
(cherry picked from commit 0b931c9347d91de431a0bc85e7005f5f06082627)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/01/525201/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/trove/templates/trove.conf.j2', 'ansible/roles/trove/templates/trove-taskmanager.conf.j2']",2,05cf49f55a468a98ec39f2bb78af3e25c3489be3,bug/1734039-stable/pike, nova_compute_endpoint_type = internalURL neutron_endpoint_type = internalURL neutron_endpoint_type = internalURL swift_endpoint_type = internalURL glance_endpoint_type = internalURL trove_endpoint_type = internalURL network_driver = trove.network.neutron.NeutronDriver,{% if enable_nova | bool %} nova_compute_url = {{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ nova_api_port }}/v2 {% endif %} {% if enable_cinder | bool %} cinder_url = {{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ cinder_api_port }}/v1 {% endif %} {% if enable_swift | bool %} swift_url = {{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ swift_proxy_server_port }}/v1/AUTH_ {% endif %},20,20
openstack%2Fkolla-ansible~master~I14ce4886ec7c6cf4ce284c9768493919dd65c83b,openstack/kolla-ansible,master,I14ce4886ec7c6cf4ce284c9768493919dd65c83b,Enable heat dashboard dynamically,MERGED,2017-12-11 07:32:43.000000000,2017-12-13 05:18:44.000000000,2017-12-13 05:18:44.000000000,"[{'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 20663}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 07:32:43.000000000', 'files': ['ansible/roles/horizon/defaults/main.yml', 'ansible/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4f1182a3c671226928bc66fecb1c8f3df33037fa', 'message': 'Enable heat dashboard dynamically\n\nheat dashboard is split from horizon code base in Queens cycle.[0][1]\n\n[0] https://review.openstack.org/#/c/523402/\n[1] https://github.com/openstack/heat-dashboard\n\nDepends-On: I920394b8cb6eb7027df9110fe88de6842d2bd8b3\nChange-Id: I14ce4886ec7c6cf4ce284c9768493919dd65c83b\nClose-Bug: #1737475\n'}]",0,527004,4f1182a3c671226928bc66fecb1c8f3df33037fa,9,5,1,7488,,,0,"Enable heat dashboard dynamically

heat dashboard is split from horizon code base in Queens cycle.[0][1]

[0] https://review.openstack.org/#/c/523402/
[1] https://github.com/openstack/heat-dashboard

Depends-On: I920394b8cb6eb7027df9110fe88de6842d2bd8b3
Change-Id: I14ce4886ec7c6cf4ce284c9768493919dd65c83b
Close-Bug: #1737475
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/04/527004/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/horizon/defaults/main.yml', 'ansible/group_vars/all.yml']",2,4f1182a3c671226928bc66fecb1c8f3df33037fa,bug/1737475,"enable_horizon_heat: ""{{ enable_heat | bool }}""",,2,0
openstack%2Fopenstack-zuul-jobs~master~I54a826f6ee6127c119e709f15209339f9f834237,openstack/openstack-zuul-jobs,master,I54a826f6ee6127c119e709f15209339f9f834237,"Revert ""Add in branch case for puppet-ceph stable/jewel""",ABANDONED,2017-12-12 17:22:53.000000000,2017-12-13 05:06:57.000000000,,"[{'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 17:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/7a97b582d2f677cb74e5c8a93116be660f0906a0', 'message': 'Revert ""Add in branch case for puppet-ceph stable/jewel""\n\n2 problems with this patch:\n\n- it only tries to solve puppet-unit-4.8 job but in fact\n  it affects ALL jobs running in puppet-ceph.\n  We\'ll try to fix the problem in our scripts.\n- this patch didn\'t help, see the result:\n  http://logs.openstack.org/59/518559/3/check/legacy-puppet-unit-4.8-centos-7/333192e/job-output.txt.gz#_2017-12-12_11_10_14_278536\n  We don\'t checkout stable/jewel anymore when doing\n  backports in puppet-ceph.\n\nI propose that we revert this patch and fix the issue\nin puppet-openstack-integration.\n\nThis reverts commit 174ecf50476d063566f43dddd77494406af920e0.\n\nChange-Id: I54a826f6ee6127c119e709f15209339f9f834237\n'}, {'number': 2, 'created': '2017-12-12 17:22:58.000000000', 'files': ['playbooks/legacy/puppet-unit-4.8-centos-7/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/31b35d01f866e46cb0d73b00b0f247bbddf41b9e', 'message': 'Revert ""Add in branch case for puppet-ceph stable/jewel""\n\n2 problems with this patch:\n\n- it only tries to solve puppet-unit-4.8 job but in fact\n  it affects ALL jobs running in puppet-ceph.\n  We\'ll try to fix the problem in our scripts.\n- this patch didn\'t help, see the result:\n  http://logs.openstack.org/59/518559/3/check/legacy-puppet-unit-4.8-centos-7/333192e/job-output.txt.gz#_2017-12-12_11_10_14_278536\n  We don\'t checkout stable/jewel anymore when doing\n  backports in puppet-ceph.\n\nI propose that we revert this patch and fix the issue\nin puppet-openstack-integration.\n\nThis reverts commit 174ecf50476d063566f43dddd77494406af920e0.\n\nChange-Id: I54a826f6ee6127c119e709f15209339f9f834237\n'}]",0,527467,31b35d01f866e46cb0d73b00b0f247bbddf41b9e,5,6,2,3153,,,0,"Revert ""Add in branch case for puppet-ceph stable/jewel""

2 problems with this patch:

- it only tries to solve puppet-unit-4.8 job but in fact
  it affects ALL jobs running in puppet-ceph.
  We'll try to fix the problem in our scripts.
- this patch didn't help, see the result:
  http://logs.openstack.org/59/518559/3/check/legacy-puppet-unit-4.8-centos-7/333192e/job-output.txt.gz#_2017-12-12_11_10_14_278536
  We don't checkout stable/jewel anymore when doing
  backports in puppet-ceph.

I propose that we revert this patch and fix the issue
in puppet-openstack-integration.

This reverts commit 174ecf50476d063566f43dddd77494406af920e0.

Change-Id: I54a826f6ee6127c119e709f15209339f9f834237
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/67/527467/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/puppet-unit-4.8-centos-7/run.yaml'],1,7a97b582d2f677cb74e5c8a93116be660f0906a0,fix-puppet-ceph-ci, /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \," ZUUL_BRANCH_REAL=${ZUUL_BRANCH:-master} # Workaround for puppet-ceph, where we need to checkout # puppet-openstack-integration from stable/pike when working on # stable/jewel. # Ceph Jewel works with Newton to Pike if [[ ""$ZUUL_BRANCH"" == ""stable/jewel"" ]]; then ZUUL_BRANCH_REAL='stable/pike' fi /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP \ --cache-dir /opt/git \ --zuul-branch $ZUUL_BRANCH_REAL \",1,11
openstack%2Fswift~master~I3a1b86368d363e67d1f91d7d8af4b391a0a53fff,openstack/swift,master,I3a1b86368d363e67d1f91d7d8af4b391a0a53fff,Ringbuilder: Forbid writing empty rings,MERGED,2017-12-04 13:54:10.000000000,2017-12-13 05:00:19.000000000,2017-12-13 05:00:18.000000000,"[{'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-04 13:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cf6cfd074e6522d197edc58aa309135ecbd2e1b8', 'message': ""Bugfix: get_ring method can make empty rings\n\nRingBuilder.get_ring now raises an Exception if the sum\nof all device weights is zero. Beyond that, the write_ring\nmethod of the ringbuilder cli now refuses to write the ring\nif it's empty.\n\nChange-Id: I3a1b86368d363e67d1f91d7d8af4b391a0a53fff\nCloses-Bug: #1396841\n""}, {'number': 2, 'created': '2017-12-07 13:50:44.000000000', 'files': ['swift/cli/ringbuilder.py', 'test/unit/cli/test_ringbuilder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/84ea58b8c81814a3c4d450145bfb9e70166dd60b', 'message': ""Ringbuilder: Forbid writing empty rings\n\nSwift definitely can't make any use of empty rings, so it should\nnot be allowed to write them.\n\nReplace warning with an error message & error exit.\n\nChange-Id: I3a1b86368d363e67d1f91d7d8af4b391a0a53fff\nCloses-Bug: #1396841\n""}]",0,525192,84ea58b8c81814a3c4d450145bfb9e70166dd60b,20,4,2,17245,,,0,"Ringbuilder: Forbid writing empty rings

Swift definitely can't make any use of empty rings, so it should
not be allowed to write them.

Replace warning with an error message & error exit.

Change-Id: I3a1b86368d363e67d1f91d7d8af4b391a0a53fff
Closes-Bug: #1396841
",git fetch https://review.opendev.org/openstack/swift refs/changes/92/525192/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/ring/builder.py', 'swift/cli/ringbuilder.py']",2,cf6cfd074e6522d197edc58aa309135ecbd2e1b8,bug/1396841, try: ring_data = builder.get_ring() except exceptions.EmptyRingError as e: print('Unable to write ring: %s' % e) exit(EXIT_ERROR) , ring_data = builder.get_ring() else: print('Warning: Writing an empty ring'),11,3
openstack%2Fheat~master~I111ea7ffa43a46d2a6fe360fb0c20d672df5771c,openstack/heat,master,I111ea7ffa43a46d2a6fe360fb0c20d672df5771c,Don't log PolicyNotRegistered when check resource type,MERGED,2017-12-07 10:59:58.000000000,2017-12-13 04:53:11.000000000,2017-12-13 04:53:11.000000000,"[{'_account_id': 7385}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 10:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9c7f019c6c2575d6e56879d0835d7a5cd0720f26', 'message': ""Don't log PolicyNotRegistered when check resource type\n\nSlience PolicyNotRegistered exception when checking resource type.\nWe do not consider PolicyNotRegistered as an error when checking\nresource type, so we shouldn't log the exception as well.\n\nChange-Id: I111ea7ffa43a46d2a6fe360fb0c20d672df5771c\n""}, {'number': 2, 'created': '2017-12-07 11:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0f40486df728baec557af83e48dbabd400a02e6b', 'message': ""Don't log PolicyNotRegistered when check resource type\n\nSilence PolicyNotRegistered exception when checking resource type.\nWe do not consider PolicyNotRegistered as an error when checking\nresource type, so we shouldn't log the exception as well.\n\nChange-Id: I111ea7ffa43a46d2a6fe360fb0c20d672df5771c\n""}, {'number': 3, 'created': '2017-12-09 18:24:53.000000000', 'files': ['heat/common/policy.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/abc850331c7b816d942c4e36658caac8849ee080', 'message': ""Don't log PolicyNotRegistered when check resource type\n\nSilence PolicyNotRegistered exception when checking resource type.\nWe do not consider PolicyNotRegistered as an error when checking\nresource type, so we shouldn't log the exception as well.\n\nDepends-On: I13f1906f53a89586bb51c0b70fa768a9500dfa26\nChange-Id: I111ea7ffa43a46d2a6fe360fb0c20d672df5771c\n""}]",5,526339,abc850331c7b816d942c4e36658caac8849ee080,43,3,3,12404,,,0,"Don't log PolicyNotRegistered when check resource type

Silence PolicyNotRegistered exception when checking resource type.
We do not consider PolicyNotRegistered as an error when checking
resource type, so we shouldn't log the exception as well.

Depends-On: I13f1906f53a89586bb51c0b70fa768a9500dfa26
Change-Id: I111ea7ffa43a46d2a6fe360fb0c20d672df5771c
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/526339/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/policy.py'],1,9c7f019c6c2575d6e56879d0835d7a5cd0720f26,silence-resource-type-policy-exc, self.log_not_registered = True if self.log_not_registered: with excutils.save_and_reraise_exception(): LOG.exception(_('Policy not registered.')) else: raise self.log_not_registered = False, with excutils.save_and_reraise_exception(): LOG.exception(_('Policy not registered.')),7,2
openstack%2Fnova~master~Icc04cac3a287955ab1a98b7813e3c7ec8183b120,openstack/nova,master,Icc04cac3a287955ab1a98b7813e3c7ec8183b120,api-ref: Fix a description for 'guest_format',MERGED,2017-12-06 07:47:23.000000000,2017-12-13 04:34:15.000000000,2017-12-13 04:31:09.000000000,"[{'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23419}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-12-06 07:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b22518cf443efffab027d29184e4197b7505297', 'message': ""api-ref: Fix a description for 'guest_format'\n\nThere is a wrong format 'ephemeral' in the description.\nSo remove it and valid formats ('ext2', 'ext3', 'ext4' and 'xfs')\nare added.\nThe parameter is optional, so fix it as well.\n\nChange-Id: Icc04cac3a287955ab1a98b7813e3c7ec8183b120\nCloses-Bug: #1736502\n""}, {'number': 2, 'created': '2017-12-12 04:53:32.000000000', 'files': ['api-ref/source/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/35dd1f9185bfac607bca1deff85af94033535cb6', 'message': ""api-ref: Fix a description for 'guest_format'\n\nThere is a wrong format 'ephemeral' in the description.\nSo remove it and valid formats ('ext2', 'ext3', 'ext4' and 'xfs')\nare added.\nThe parameter is optional, so fix it as well.\n\nChange-Id: Icc04cac3a287955ab1a98b7813e3c7ec8183b120\nCloses-Bug: #1736502\n""}]",1,525928,35dd1f9185bfac607bca1deff85af94033535cb6,39,16,2,7634,,,0,"api-ref: Fix a description for 'guest_format'

There is a wrong format 'ephemeral' in the description.
So remove it and valid formats ('ext2', 'ext3', 'ext4' and 'xfs')
are added.
The parameter is optional, so fix it as well.

Change-Id: Icc04cac3a287955ab1a98b7813e3c7ec8183b120
Closes-Bug: #1736502
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/525928/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/parameters.yaml'],1,6b22518cf443efffab027d29184e4197b7505297,bug/1736502," Specifies the guest server disk file system format, such as ``ext2``, ``ext3``, ``ext4``, ``xfs`` or ``swap``. This parameter affects only the libvirt virt driver. required: false"," Specifies the guest server disk file system format, such as ``ephemeral`` or ``swap``. required: true",4,2
openstack%2Fswift~master~Ib58ce03e2010f41e7eb11f1a6dc78b0b7f55d466,openstack/swift,master,Ib58ce03e2010f41e7eb11f1a6dc78b0b7f55d466,Refactor proxy-server conf loading to a helper function,MERGED,2017-12-05 18:39:16.000000000,2017-12-13 04:31:05.000000000,2017-12-13 04:31:05.000000000,"[{'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 18:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d0ec74a06585fc3e345460206a483b17a7c4945f', 'message': 'Refactor proxy-server conf loading to a utils function\n\nThere were two middlewares using a common pattern to load\nthe proxy-server app config section. This patch moves the\ncommon code to a utils helper function and adds some unit\ntests.\n\nChange-Id: Ib58ce03e2010f41e7eb11f1a6dc78b0b7f55d466\n'}, {'number': 2, 'created': '2017-12-07 18:25:25.000000000', 'files': ['swift/common/middleware/copy.py', 'swift/common/wsgi.py', 'test/unit/common/middleware/test_dlo.py', 'test/unit/common/middleware/test_copy.py', 'test/unit/common/test_wsgi.py', 'swift/common/middleware/dlo.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/dd113ab25a3089fa19c8e824c2d89db0ca3db0fa', 'message': ""Refactor proxy-server conf loading to a helper function\n\nThere were two middlewares using a common pattern to load\nthe proxy-server app config section. The existing pattern\nfails to recognise option overrides that are declared using\npaste-deploy's 'set' notation, as illustrated by the change\nto test_dlo.py in this patch.\n\nThis patch replaces the existing code with a helper function\nthat loads the proxy-server config using the paste-deploy loader.\nThe resulting config dict is therefore exactly the same as that\nused to initialise the proxy-server app.\n\nChange-Id: Ib58ce03e2010f41e7eb11f1a6dc78b0b7f55d466\n""}]",0,525728,dd113ab25a3089fa19c8e824c2d89db0ca3db0fa,14,5,2,7847,,,0,"Refactor proxy-server conf loading to a helper function

There were two middlewares using a common pattern to load
the proxy-server app config section. The existing pattern
fails to recognise option overrides that are declared using
paste-deploy's 'set' notation, as illustrated by the change
to test_dlo.py in this patch.

This patch replaces the existing code with a helper function
that loads the proxy-server config using the paste-deploy loader.
The resulting config dict is therefore exactly the same as that
used to initialise the proxy-server app.

Change-Id: Ib58ce03e2010f41e7eb11f1a6dc78b0b7f55d466
",git fetch https://review.opendev.org/openstack/swift refs/changes/28/525728/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'swift/common/middleware/copy.py', 'test/unit/common/test_utils.py', 'swift/common/middleware/dlo.py']",4,d0ec74a06585fc3e345460206a483b17a7c4945f,p-refactor-proxy-conf-loading," RateLimitedIterator, quote, close_if_possible, closing_if_possible,\ read_proxy_server_conf 'max_get_time' in conf): proxy_conf = read_proxy_server_conf(conf) if setting in proxy_conf: conf[setting] = proxy_conf[setting]","import osfrom six.moves.configparser import ConfigParser, NoSectionError, NoOptionError RateLimitedIterator, read_conf_dir, quote, close_if_possible, \ closing_if_possible 'max_get_time' in conf or '__file__' not in conf): cp = ConfigParser() if os.path.isdir(conf['__file__']): read_conf_dir(cp, conf['__file__']) else: cp.read(conf['__file__']) try: pipe = cp.get(""pipeline:main"", ""pipeline"") except (NoSectionError, NoOptionError): return proxy_name = pipe.rsplit(None, 1)[-1] proxy_section = ""app:"" + proxy_name try: conf[setting] = cp.get(proxy_section, setting) except (NoSectionError, NoOptionError): pass",94,47
openstack%2Fdevstack~master~I364e401227fe43e2bacf8a799e10286ee445f835,openstack/devstack,master,I364e401227fe43e2bacf8a799e10286ee445f835,Remove Cinder policy.json install,MERGED,2017-11-30 20:17:18.000000000,2017-12-13 04:31:01.000000000,2017-12-13 04:31:01.000000000,"[{'_account_id': 5046}, {'_account_id': 5196}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 14595}, {'_account_id': 22348}, {'_account_id': 23083}, {'_account_id': 25254}]","[{'number': 1, 'created': '2017-11-30 20:17:18.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1d127849121974fe6c8161eabe5ebd7151fa4f4d', 'message': 'Remove Cinder policy.json install\n\nCinder has now implemented ""policy in code"" and policy.json is\nonly needed for overriding default policies. The default policy.json\nfile has been removed in Cinder so we need to stop trying to copy\nit during Cinder setup.\n\nChange-Id: I364e401227fe43e2bacf8a799e10286ee445f835\n'}]",0,524335,1d127849121974fe6c8161eabe5ebd7151fa4f4d,15,9,1,11904,,,0,"Remove Cinder policy.json install

Cinder has now implemented ""policy in code"" and policy.json is
only needed for overriding default policies. The default policy.json
file has been removed in Cinder so we need to stop trying to copy
it during Cinder setup.

Change-Id: I364e401227fe43e2bacf8a799e10286ee445f835
",git fetch https://review.opendev.org/openstack/devstack refs/changes/35/524335/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,1d127849121974fe6c8161eabe5ebd7151fa4f4d,policy-and-docs-in-code,, cp -p $CINDER_DIR/etc/cinder/policy.json $CINDER_CONF_DIR ,0,2
openstack%2Fnova~stable%2Fpike~Id65e15a57175bbdd9c84851b1b6716e6a1f2cfb8,openstack/nova,stable/pike,Id65e15a57175bbdd9c84851b1b6716e6a1f2cfb8,Make TestRPC inherit from the base nova TestCase,MERGED,2017-10-13 13:20:44.000000000,2017-12-13 04:30:58.000000000,2017-12-13 04:30:58.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 12898}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23630}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-13 13:20:44.000000000', 'files': ['nova/test.py', 'nova/tests/unit/test_rpc.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d873550d3c357adb6f3544adbc43e8ab9b94cfbd', 'message': 'Make TestRPC inherit from the base nova TestCase\n\nBy not inheriting from the base nova test case, we\nlose things like timeouts.\n\nThis makes the TestRPC test class inherit from the\nbase test case and still avoid using the RPCFixture.\n\nChange-Id: Id65e15a57175bbdd9c84851b1b6716e6a1f2cfb8\nRelated-Bug: #1685333\n(cherry picked from commit 0534872abb78738993a35d24a6640c82b711deee)\n'}]",0,511842,d873550d3c357adb6f3544adbc43e8ab9b94cfbd,30,15,1,6873,,,0,"Make TestRPC inherit from the base nova TestCase

By not inheriting from the base nova test case, we
lose things like timeouts.

This makes the TestRPC test class inherit from the
base test case and still avoid using the RPCFixture.

Change-Id: Id65e15a57175bbdd9c84851b1b6716e6a1f2cfb8
Related-Bug: #1685333
(cherry picked from commit 0534872abb78738993a35d24a6640c82b711deee)
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/511842/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/test.py', 'nova/tests/unit/test_rpc.py']",2,d873550d3c357adb6f3544adbc43e8ab9b94cfbd,bug/1685333-stable/pike,class TestRPC(test.NoDBTestCase): # We're testing the rpc code so we can't use the RPCFixture. STUB_RPC = False ,import testtools# We can't import nova.test.TestCase because that sets up an RPCFixture # that pretty much nullifies all of this testing class TestRPC(testtools.TestCase):,11,5
openstack%2Fneutron~master~I97a00ee6d2672485334bba757706f107e052b551,openstack/neutron,master,I97a00ee6d2672485334bba757706f107e052b551,Tags: harden validations,MERGED,2017-12-06 08:33:51.000000000,2017-12-13 04:30:55.000000000,2017-12-13 04:30:55.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 17120}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 08:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6413b921dc523287fcecfbbef8618143b99c63d3', 'message': 'Tags: harden validations\n\nAn invalid input would cuase a server execption. We now validate\nthat the body in the tags validation is not None.\n\nTrivialFix\n\nChange-Id: I97a00ee6d2672485334bba757706f107e052b551\nCloses-Bug: #1736678\n'}, {'number': 2, 'created': '2017-12-07 16:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb915a35ecbab7633d9b8db7bb2cc4f6ffd03fff', 'message': 'Tags: harden validations\n\nAn invalid input would cause a server execption. We now validate\nthat the body in the tags validation is not None.\n\nTrivialFix\n\nChange-Id: I97a00ee6d2672485334bba757706f107e052b551\nCloses-Bug: #1736678\n'}, {'number': 3, 'created': '2017-12-10 06:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6fcf8c1d63b54cdb4bded2933177bb79703e724e', 'message': 'Tags: harden validations\n\nAn invalid input would cause a server execption. We now validate\nthat the body in the tags validation is not None.\n\nTrivialFix\n\nChange-Id: I97a00ee6d2672485334bba757706f107e052b551\nCloses-Bug: #1736678\n'}, {'number': 4, 'created': '2017-12-12 07:04:23.000000000', 'files': ['neutron/tests/unit/extensions/test_tag.py', 'neutron/extensions/tagging.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5da1a6f7c62893c2301f52f0f09b551b7fc8c525', 'message': 'Tags: harden validations\n\nAn invalid input would cause a server execption. We now validate\nthat the body in the tags validation is not None.\n\nTrivialFix\n\nChange-Id: I97a00ee6d2672485334bba757706f107e052b551\nCloses-Bug: #1736678\n'}]",4,525983,5da1a6f7c62893c2301f52f0f09b551b7fc8c525,58,10,4,1653,,,0,"Tags: harden validations

An invalid input would cause a server execption. We now validate
that the body in the tags validation is not None.

TrivialFix

Change-Id: I97a00ee6d2672485334bba757706f107e052b551
Closes-Bug: #1736678
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/525983/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_tag.py', 'neutron/extensions/tagging.py']",2,6413b921dc523287fcecfbbef8618143b99c63d3,tags, if not body or 'tags' not in body:, if 'tags' not in body:,7,1
openstack%2Fproject-config~master~I638cc127d3588d757a4da01984a2bd292a84413c,openstack/project-config,master,I638cc127d3588d757a4da01984a2bd292a84413c,Retire puppet-apps_site (1/3),MERGED,2017-12-10 19:41:39.000000000,2017-12-13 04:16:50.000000000,2017-12-13 04:16:50.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-10 19:41:39.000000000', 'files': ['gerritbot/channels.yaml', 'zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d583e7e439857b0d8af9fee1b97b5e7ef5dcadd9', 'message': 'Retire puppet-apps_site (1/3)\n\nWith the retirement of the app-catalog repos and the decommission\nearlier this year of the apps site, we can retire puppet-apps_site\nrepository as well.\n\nSee I52ce13057643d69a0fd87bce20ee460c6b7c2f17 for retirement of\napp-catalog repos.\n\nNeeded-By: I699aba4426db45f2a62b945a41304564e0724470\nNeeded-By: I6bb5740e622cbf214fd6d94847a5cf93cc01f1f8\nNeeded-By: I802957611fccf66a6cd74cb7e9a35c74cc875a8c\nChange-Id: I638cc127d3588d757a4da01984a2bd292a84413c\n'}]",0,526944,d583e7e439857b0d8af9fee1b97b5e7ef5dcadd9,8,3,1,6547,,,0,"Retire puppet-apps_site (1/3)

With the retirement of the app-catalog repos and the decommission
earlier this year of the apps site, we can retire puppet-apps_site
repository as well.

See I52ce13057643d69a0fd87bce20ee460c6b7c2f17 for retirement of
app-catalog repos.

Needed-By: I699aba4426db45f2a62b945a41304564e0724470
Needed-By: I6bb5740e622cbf214fd6d94847a5cf93cc01f1f8
Needed-By: I802957611fccf66a6cd74cb7e9a35c74cc875a8c
Change-Id: I638cc127d3588d757a4da01984a2bd292a84413c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/526944/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'zuul.d/projects.yaml']",2,d583e7e439857b0d8af9fee1b97b5e7ef5dcadd9,infra-xenial, - noop-jobs, - infra-puppet-check-jobs - infra-puppet-apply-jobs - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-xenial-infra,1,6
openstack%2Frequirements~master~Ib8d848fdcebfe3ec9d3c2c2d9a3b89a4d052d2de,openstack/requirements,master,Ib8d848fdcebfe3ec9d3c2c2d9a3b89a4d052d2de,update constraint for oslo.concurrency to new release 3.24.0,MERGED,2017-12-12 15:03:16.000000000,2017-12-13 04:09:53.000000000,2017-12-13 04:09:53.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 15:03:16.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e31a2077720bb7b95a16fb18d13011eeb592c126', 'message': 'update constraint for oslo.concurrency to new release 3.24.0\n\nChange-Id: Ib8d848fdcebfe3ec9d3c2c2d9a3b89a4d052d2de\nmeta:version: 3.24.0\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,527420,e31a2077720bb7b95a16fb18d13011eeb592c126,7,3,1,11131,,,0,"update constraint for oslo.concurrency to new release 3.24.0

Change-Id: Ib8d848fdcebfe3ec9d3c2c2d9a3b89a4d052d2de
meta:version: 3.24.0
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I26c7935d7c812e89af16f0d6ae11bd1bef13161f
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/20/527420/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e31a2077720bb7b95a16fb18d13011eeb592c126,new-release,oslo.concurrency===3.24.0,oslo.concurrency===3.23.0,1,1
openstack%2Fkolla~stable%2Focata~I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d,openstack/kolla,stable/ocata,I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d,implement deploy jobs in kolla,ABANDONED,2017-11-19 02:14:27.000000000,2017-12-13 04:03:12.000000000,,"[{'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 23825}]","[{'number': 1, 'created': '2017-11-19 02:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/64a395021bcc5bb99f29eb6795e939ba0ae768ce', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}, {'number': 2, 'created': '2017-11-19 03:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b5d12b00e158e7c39415393b8f7a93d26d6fff31', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nDepends-On: I0b131c2f65652cf3c61b33d8162097b047603923\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}, {'number': 3, 'created': '2017-11-19 12:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4b880c220e6de67fdd89db91a5b49641d9ce83e3', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nDepends-On: I0b131c2f65652cf3c61b33d8162097b047603923\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}, {'number': 4, 'created': '2017-11-19 15:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f934504df284ad833ab4a0cc0347ef644f7c3e7a', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nDepends-On: I0b131c2f65652cf3c61b33d8162097b047603923\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}, {'number': 5, 'created': '2017-11-20 03:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c1a34706db2ca35879dd527f81aded1aedd1534e', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nDepends-On: I0b131c2f65652cf3c61b33d8162097b047603923\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}, {'number': 6, 'created': '2017-12-12 01:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/153f254f993222d49078f519a5a62a8ce7fb8f89', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nDepends-On: I0b131c2f65652cf3c61b33d8162097b047603923\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}, {'number': 7, 'created': '2017-12-12 03:30:08.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6b0643f971b53576624b2f72371c3f415cb7f78a', 'message': 'implement deploy jobs in kolla\n\nPartial-Bug: #1720601\nDepends-On: I0b131c2f65652cf3c61b33d8162097b047603923\nChange-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d\n(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)\n'}]",0,521333,6b0643f971b53576624b2f72371c3f415cb7f78a,31,5,7,7488,,,0,"implement deploy jobs in kolla

Partial-Bug: #1720601
Depends-On: I0b131c2f65652cf3c61b33d8162097b047603923
Change-Id: I895b49d5d0d4cb3d3dbb1687b8cff0b52716259d
(cherry picked from commit fc7758aed9ec609b5cc1474bb7a4bd2faff5fd29)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/33/521333/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,64a395021bcc5bb99f29eb6795e939ba0ae768ce,bug/1720601, - kolla-ansible-centos-source: required-projects: - openstack/kolla-ansible - openstack/requirements - kolla-ansible-centos-binary: required-projects: - openstack/kolla-ansible - openstack/requirements - kolla-ansible-ubuntu-source: required-projects: - openstack/kolla-ansible - openstack/requirements - kolla-ansible-ubuntu-binary: required-projects: - openstack/kolla-ansible - openstack/requirements - kolla-ansible-oraclelinux-source: required-projects: - openstack/kolla-ansible - openstack/requirements - kolla-ansible-oraclelinux-binary: required-projects: - openstack/kolla-ansible - openstack/requirements,,24,0
openstack%2Fpython-zunclient~master~Ie279ba5eb93fae3fd36738d37d1c06a07e6fbf0e,openstack/python-zunclient,master,Ie279ba5eb93fae3fd36738d37d1c06a07e6fbf0e,Add support for image show,MERGED,2017-12-07 23:40:13.000000000,2017-12-13 03:53:14.000000000,2017-12-13 03:53:14.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 22406}]","[{'number': 1, 'created': '2017-12-07 23:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/a4a15bf065e926f3091e73aad90ba1ffed2db5e5', 'message': 'Add support for image show\n\nAdd support for show detail of specified image.Use case:\nzun image-show <image_id>\n\nChange-Id: Ie279ba5eb93fae3fd36738d37d1c06a07e6fbf0e\n'}, {'number': 2, 'created': '2017-12-08 03:29:36.000000000', 'files': ['zunclient/tests/unit/v1/test_images_shell.py', 'zunclient/v1/images_shell.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/8657881757cac81dd7d9e49a5fcacc4be5eb17ea', 'message': 'Add support for image show\n\nAdd support for show detail of specified image.Use case:\nzun image-show <image_id>\n\nChange-Id: Ie279ba5eb93fae3fd36738d37d1c06a07e6fbf0e\n'}]",0,526545,8657881757cac81dd7d9e49a5fcacc4be5eb17ea,9,3,2,17812,,,0,"Add support for image show

Add support for show detail of specified image.Use case:
zun image-show <image_id>

Change-Id: Ie279ba5eb93fae3fd36738d37d1c06a07e6fbf0e
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/45/526545/1 && git format-patch -1 --stdout FETCH_HEAD,"['zunclient/tests/unit/v1/test_images_shell.py', 'zunclient/v1/images_shell.py']",2,a4a15bf065e926f3091e73aad90ba1ffed2db5e5,bug/1721448,"@utils.arg('id', metavar='<IMAGE_ID>', help='ID of image to describe.') def do_image_show(cs, args): """"""Describe a specific image."""""" image = cs.images.get(args.id) _show_image(image) ",,18,0
openstack%2Foslo.messaging~master~I9373c0ba4017f8db732c0eb9c5cf0d129726f315,openstack/oslo.messaging,master,I9373c0ba4017f8db732c0eb9c5cf0d129726f315,Remove pbr version from setup.py,MERGED,2017-09-07 04:58:49.000000000,2017-12-13 03:46:46.000000000,2017-12-13 03:46:46.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 9796}, {'_account_id': 14758}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-09-07 04:58:49.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5ef5c7fc26f26d158e3b7732d55b5a71f2b04910', 'message': 'Remove pbr version from setup.py\n\nUsing pbr version in setup_requires is no longer recommended by Pbr.\n\nChange-Id: I9373c0ba4017f8db732c0eb9c5cf0d129726f315\n'}]",0,501565,5ef5c7fc26f26d158e3b7732d55b5a71f2b04910,10,5,1,14758,,,0,"Remove pbr version from setup.py

Using pbr version in setup_requires is no longer recommended by Pbr.

Change-Id: I9373c0ba4017f8db732c0eb9c5cf0d129726f315
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/65/501565/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,5ef5c7fc26f26d158e3b7732d55b5a71f2b04910,remove-pbr-version," setup_requires=['pbr'],"," setup_requires=['pbr>=2.0.0'],",1,1
openstack%2Fopenstack-ansible~master~I09590659a2b2f1b7dfec577b97be91b1a294a7fd,openstack/openstack-ansible,master,I09590659a2b2f1b7dfec577b97be91b1a294a7fd,Add pip config to lxc_hosts,MERGED,2017-12-12 05:47:20.000000000,2017-12-13 03:42:10.000000000,2017-12-13 03:42:10.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-12 05:47:20.000000000', 'files': ['playbooks/lxc-hosts-setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b5079c15413d445ce971735690cf5c46b645ab98', 'message': ""Add pip config to lxc_hosts\n\nIf this playbook is run on it's own, prior to a full stack being\ndeployed, tasks will fail due to pip being configured incorrectly.\nThis change adds the required common tasks to fix the potential\nsituation.\n\nChange-Id: I09590659a2b2f1b7dfec577b97be91b1a294a7fd\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,527308,b5079c15413d445ce971735690cf5c46b645ab98,13,6,1,7353,,,0,"Add pip config to lxc_hosts

If this playbook is run on it's own, prior to a full stack being
deployed, tasks will fail due to pip being configured incorrectly.
This change adds the required common tasks to fix the potential
situation.

Change-Id: I09590659a2b2f1b7dfec577b97be91b1a294a7fd
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/08/527308/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/lxc-hosts-setup.yml'],1,b5079c15413d445ce971735690cf5c46b645ab98,, - include: common-tasks/set-upper-constraints.yml - include: common-tasks/set-pip-upstream-url.yml vars_files: - defaults/repo_packages/openstack_services.yml,,4,0
openstack%2Fnetworking-ovn~master~Idb51a347ba76b3e449939721a4abc0184f915459,openstack/networking-ovn,master,Idb51a347ba76b3e449939721a4abc0184f915459,Optimize updating routes in _subnet_update,MERGED,2017-12-06 09:05:09.000000000,2017-12-13 03:38:06.000000000,2017-12-13 03:38:06.000000000,"[{'_account_id': 6773}, {'_account_id': 10237}, {'_account_id': 22348}, {'_account_id': 23458}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-12-06 09:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/805e59c0ef835406ec5f4555531c99e7e5b98624', 'message': ""Optimize updating routes in _subnet_update\n\nAfter patch[1] merged, multiple routes commands can be consolidated in\none transaction. This patch optimize _subnet_update for it.\nThis patch also adds some comments to test case because it's difficult\nto find its relevant test cases without comments.\n\n[1]https://review.openstack.org/#/c/515673/\n\nChange-Id: Idb51a347ba76b3e449939721a4abc0184f915459\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n""}, {'number': 2, 'created': '2017-12-08 06:35:14.000000000', 'files': ['networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/tests/unit/l3/test_l3_ovn.py', 'networking_ovn/l3/l3_ovn.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/d68083a05b5b87054a975accf7c35a50fd5d6400', 'message': ""Optimize updating routes in _subnet_update\n\nAfter patch[1] merged, multiple routes commands can be consolidated in\none transaction. This patch optimize _subnet_update for it.\nThis patch also adds some comments to test case because it's difficult\nto find its relevant test cases without comments.\n\n[1]https://review.openstack.org/#/c/515673/\n\nChange-Id: Idb51a347ba76b3e449939721a4abc0184f915459\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n""}]",0,525996,d68083a05b5b87054a975accf7c35a50fd5d6400,13,5,2,23458,,,0,"Optimize updating routes in _subnet_update

After patch[1] merged, multiple routes commands can be consolidated in
one transaction. This patch optimize _subnet_update for it.
This patch also adds some comments to test case because it's difficult
to find its relevant test cases without comments.

[1]https://review.openstack.org/#/c/515673/

Change-Id: Idb51a347ba76b3e449939721a4abc0184f915459
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/96/525996/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/tests/unit/l3/test_l3_ovn.py', 'networking_ovn/l3/l3_ovn.py']",3,805e59c0ef835406ec5f4555531c99e7e5b98624,ext_subnet_update," with l3plugin._ovn.transaction(check_error=True) as txn: for router_id in router_ids: l3plugin._ovn_client.update_router_routes( context, router_id, add, remove, txn)"," for router_id in router_ids: l3plugin._ovn_client.update_router_routes( context, router_id, add, remove)",7,4
openstack%2Fnova~master~If1277cde2aff44b5651154fc05c3cd4377237c60,openstack/nova,master,If1277cde2aff44b5651154fc05c3cd4377237c60,Add quiesce and unquiesce in support matrix,MERGED,2017-07-11 03:04:07.000000000,2017-12-13 03:34:14.000000000,2017-12-13 02:56:36.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 6062}, {'_account_id': 6125}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-07-11 03:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc5a2ac9a5ec680b692440fb0c2f347250f358de', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 2, 'created': '2017-07-12 07:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f89214ddaf316d66dcf7cb2898beca2dbfc654d', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 3, 'created': '2017-07-27 06:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cffb9cdff612c66fcc35062c5ca6953cbd52d41', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 4, 'created': '2017-07-28 08:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be74b4b52ff679a38a3a2f9cfe2ab1aef8573343', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 5, 'created': '2017-09-07 02:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cae882d60f332f01f4c2a06b561913ec459bc13', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 6, 'created': '2017-09-07 02:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e0d18f422adf6fbe8f6812fa93bbc4e0b940610', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 7, 'created': '2017-09-07 03:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09ed83f2d026f5c6935ef46a69d5a9628358c51e', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 8, 'created': '2017-09-21 01:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2abb16ea4abc103e1a90a7108193b0ed173153bc', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 9, 'created': '2017-10-09 08:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0dada534916946f8be25af903ea5b06229411e7', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 10, 'created': '2017-10-24 09:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/312a8d5f376849b6482d65e34a73b8f49a3e26a5', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 11, 'created': '2017-10-30 09:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03857479bc3573d10f85823f5ef113c32dbe1c71', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 12, 'created': '2017-11-12 07:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7de44a534ff3c8e0c16f89cc0764e85be234c6fd', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}, {'number': 13, 'created': '2017-12-11 08:27:05.000000000', 'files': ['doc/source/user/support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/f5dab6e379170ea1ac3023fa33bc8a011afb3935', 'message': 'Add quiesce and unquiesce in support matrix\n\nquiesce and unquiesce are virt driver and supported in libvirt\nwe need document those functions into the support matrix\nto let admin/user be able to refer to.\n\nChange-Id: If1277cde2aff44b5651154fc05c3cd4377237c60\n'}]",8,482390,f5dab6e379170ea1ac3023fa33bc8a011afb3935,121,19,13,6062,,,0,"Add quiesce and unquiesce in support matrix

quiesce and unquiesce are virt driver and supported in libvirt
we need document those functions into the support matrix
to let admin/user be able to refer to.

Change-Id: If1277cde2aff44b5651154fc05c3cd4377237c60
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/482390/7 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/support-matrix.ini'],1,dc5a2ac9a5ec680b692440fb0c2f347250f358de,enhance_support_matrix_3," [operation.quiesce] title=quiesce status=optional notes=Quiesce the specified instance to prepare for snapshots. For libvirt, guest filesystems will be freezed through qemu agent. cli= driver-impl-xenserver=missing driver-impl-libvirt-kvm-x86=complete driver-impl-libvirt-kvm-ppc64=complete driver-impl-libvirt-kvm-s390x=complete driver-impl-libvirt-qemu-x86=complete driver-impl-libvirt-lxc=missing driver-impl-libvirt-xen=missing driver-impl-vmware=missing driver-impl-hyperv=missing driver-impl-ironic=missing driver-impl-libvirt-vz-vm=missing driver-impl-libvirt-vz-ct=missing driver-impl-powervm=missing [operation.unquiesce] title=unquiesce status=optional notes=See notes for the quiesce operation cli= driver-impl-xenserver=missing driver-impl-libvirt-kvm-x86=complete driver-impl-libvirt-kvm-ppc64=complete driver-impl-libvirt-kvm-s390x=complete driver-impl-libvirt-qemu-x86=complete driver-impl-libvirt-lxc=missing driver-impl-libvirt-xen=missing driver-impl-vmware=missing driver-impl-hyperv=missing driver-impl-ironic=missing driver-impl-libvirt-vz-vm=missing driver-impl-libvirt-vz-ct=missing driver-impl-powervm=missing",,40,0
openstack%2Fopenstack-chef-repo~master~Ia5771dd44117524da4429c652ab48f797ffc5585,openstack/openstack-chef-repo,master,Ia5771dd44117524da4429c652ab48f797ffc5585,WIP: Removed mysql2 gem workaround,ABANDONED,2017-09-22 21:52:24.000000000,2017-12-13 03:21:34.000000000,,"[{'_account_id': 14790}, {'_account_id': 22348}, {'_account_id': 24734}]","[{'number': 1, 'created': '2017-09-22 21:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/87c831a823ef3db4d4a38e9b3d613445494ff848', 'message': 'WIP: Removed mysql2 gem workaround\n\nChange-Id: Ia5771dd44117524da4429c652ab48f797ffc5585\n'}, {'number': 2, 'created': '2017-09-23 01:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/6cb86bdaedfe4b8daeb775d06af01dacca2c3922', 'message': 'WIP: Removed mysql2 gem workaround\n\n- removed mysql2 gem workaround\n- added integration-centos7 environment file\n- removed yum/apt cookbook cruft\n\nChange-Id: Ia5771dd44117524da4429c652ab48f797ffc5585\n'}, {'number': 3, 'created': '2017-11-03 17:17:52.000000000', 'files': ['environments/integration-ubuntu16.json', 'Rakefile', 'environments/integration-centos7.json'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/a6520aad1d3450853bbb3f25f92fbc7f16cbbeb2', 'message': 'WIP: Removed mysql2 gem workaround\n\n- removed mysql2 gem workaround\n- added integration-centos7 environment file\n- removed yum/apt cookbook cruft\n\nChange-Id: Ia5771dd44117524da4429c652ab48f797ffc5585\n'}]",0,506792,a6520aad1d3450853bbb3f25f92fbc7f16cbbeb2,32,3,3,14790,,,0,"WIP: Removed mysql2 gem workaround

- removed mysql2 gem workaround
- added integration-centos7 environment file
- removed yum/apt cookbook cruft

Change-Id: Ia5771dd44117524da4429c652ab48f797ffc5585
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/92/506792/3 && git format-patch -1 --stdout FETCH_HEAD,['Rakefile'],1,87c831a823ef3db4d4a38e9b3d613445494ff848,,, # Install mysql2 gem to avoid hitting mirror issues sh %(wget https://rubygems.org/downloads/mysql2-0.4.5.gem) sh %(sudo apt-get install -y libmysqlclient-dev) sh %(chef exec gem install -N ./mysql2-0.4.5.gem) ,0,5
openstack%2Fsenlin-dashboard~master~I92eb3fc4771e945b9a944f23dd0912b3d62ba227,openstack/senlin-dashboard,master,I92eb3fc4771e945b9a944f23dd0912b3d62ba227,Imported Translations from Zanata,MERGED,2017-12-06 06:34:42.000000000,2017-12-13 03:16:09.000000000,2017-12-13 03:16:09.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 06:34:42.000000000', 'files': ['senlin_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/bb7bc5d5afce017d757fa1b3ebe7732d4c7274ef', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I92eb3fc4771e945b9a944f23dd0912b3d62ba227\n'}]",0,525899,bb7bc5d5afce017d757fa1b3ebe7732d4c7274ef,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I92eb3fc4771e945b9a944f23dd0912b3d62ba227
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/99/525899/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'],1,bb7bc5d5afce017d757fa1b3ebe7732d4c7274ef,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: senlin-dashboard 0.7.1.dev12\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2017-12-05 08:57+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-12-05 10:39+0000\n"" ""Last-Translator: Andi Chandler <andi@gowling.com>\n"" ""Language-Team: English (United Kingdom)\n"" ""Language: en-GB\n"" ""X-Generator: Zanata 3.9.6\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" msgid """" ""A policy is a set of rules that can be checked and/or enforced when an "" ""Action is performed on a Cluster."" msgstr """" ""A policy is a set of rules that can be checked and/or enforced when an "" ""Action is performed on a Cluster."" msgid ""A profile encodes the information needed for node creation."" msgstr ""A profile encodes the information needed for node creation."" msgid ""ACTIVE"" msgstr ""ACTIVE"" msgid ""Action"" msgstr ""Action"" msgid ""An arbitrary human-readable name."" msgstr ""An arbitrary human-readable name."" msgid ""CHECKING"" msgstr ""CHECKING"" msgid ""CREATING"" msgstr ""CREATING"" msgid ""CRITICAL"" msgstr ""CRITICAL"" msgid ""Channel"" msgstr ""Channel"" msgid ""Cluster"" msgstr ""Cluster"" #, python-format msgid ""Cluster %s was successfully created."" msgstr ""Cluster %s was successfully created."" #, python-format msgid ""Cluster %s was successfully updated."" msgstr ""Cluster %s was successfully updated."" msgid ""Cluster ID"" msgstr ""Cluster ID"" msgid ""Cluster Name"" msgstr ""Cluster Name"" msgid ""Cluster creation timeout in seconds."" msgstr ""Cluster creation timeout in seconds."" msgid ""Cluster for this node."" msgstr ""Cluster for this node."" #, python-format msgid ""Cluster scale-in %s was successfully accepted."" msgstr ""Cluster scale-in %s was successfully accepted."" #, python-format msgid ""Cluster scale-out %s was successfully accepted."" msgstr ""Cluster scale-out %s was successfully accepted."" msgid ""Clusters"" msgstr ""Clusters"" msgid ""Confirm Delete Cluster"" msgid_plural ""Confirm Delete Clusters"" msgstr[0] ""Confirm Delete Cluster"" msgstr[1] ""Confirm Delete Clusters"" msgid ""Confirm Delete Node"" msgid_plural ""Confirm Delete Nodes"" msgstr[0] ""Confirm Delete Node"" msgstr[1] ""Confirm Delete Nodes"" msgid ""Confirm Delete Policy"" msgid_plural ""Confirm Delete Policies"" msgstr[0] ""Confirm Delete Policy"" msgstr[1] ""Confirm Delete Policies"" msgid ""Confirm Delete Profile"" msgid_plural ""Confirm Delete Profiles"" msgstr[0] ""Confirm Delete Profile"" msgstr[1] ""Confirm Delete Profiles"" msgid ""Confirm Delete Receiver"" msgid_plural ""Confirm Delete Receivers"" msgstr[0] ""Confirm Delete Receiver"" msgstr[1] ""Confirm Delete Receivers"" msgid ""Create"" msgstr ""Create"" msgid ""Create At"" msgstr ""Create At"" msgid ""Create Cluster"" msgstr ""Create Cluster"" msgid ""Create Node"" msgstr ""Create Node"" msgid ""Create Policy"" msgstr ""Create Policy"" msgid ""Create Profile"" msgstr ""Create Profile"" msgid ""Create Receiver"" msgstr ""Create Receiver"" msgid ""Created"" msgstr ""Created"" msgid ""DELETING"" msgstr ""DELETING"" msgid ""Delete Cluster"" msgid_plural ""Delete Clusters"" msgstr[0] ""Delete Cluster"" msgstr[1] ""Delete Clusters"" msgid ""Delete Clusters"" msgstr ""Delete Clusters"" msgid ""Delete Node"" msgid_plural ""Delete Nodes"" msgstr[0] ""Delete Node"" msgstr[1] ""Delete Nodes"" msgid ""Delete Nodes"" msgstr ""Delete Nodes"" msgid ""Delete Policies"" msgstr ""Delete Policies"" msgid ""Delete Policy"" msgid_plural ""Delete Policies"" msgstr[0] ""Delete Policy"" msgstr[1] ""Delete Policies"" msgid ""Delete Profile"" msgid_plural ""Delete Profiles"" msgstr[0] ""Delete Profile"" msgstr[1] ""Delete Profiles"" msgid ""Delete Profiles"" msgstr ""Delete Profiles"" msgid ""Delete Receiver"" msgid_plural ""Delete Receivers"" msgstr[0] ""Delete Receiver"" msgstr[1] ""Delete Receivers"" msgid ""Delete Receivers"" msgstr ""Delete Receivers"" #, python-format msgid ""Deleted Cluster: %s."" msgid_plural ""Deleted Clusters: %s."" msgstr[0] ""Deleted Cluster: %s."" msgstr[1] ""Deleted Clusters: %s."" #, python-format msgid ""Deleted Node: %s."" msgid_plural ""Deleted Nodes: %s."" msgstr[0] ""Deleted Node: %s."" msgstr[1] ""Deleted Nodes: %s."" #, python-format msgid ""Deleted Policy: %s."" msgid_plural ""Deleted Policies: %s."" msgstr[0] ""Deleted Policy: %s."" msgstr[1] ""Deleted Policies: %s."" #, python-format msgid ""Deleted Profile: %s."" msgid_plural ""Deleted Profiles: %s."" msgstr[0] ""Deleted Profile: %s."" msgstr[1] ""Deleted Profiles: %s."" #, python-format msgid ""Deleted Receiver: %s."" msgid_plural ""Deleted Receivers: %s."" msgstr[0] ""Deleted Receiver: %s."" msgstr[1] ""Deleted Receivers: %s."" msgid ""Desired Capacity"" msgstr ""Desired Capacity"" msgid ""Desired capacity of the cluster. Default to 0."" msgstr ""Desired capacity of the cluster. Default to 0."" msgid ""ERROR"" msgstr ""ERROR"" msgid ""Event"" msgstr ""Event"" msgid ""Events"" msgstr ""Events"" msgid ""Generated"" msgstr ""Generated"" msgid ""ID"" msgstr ""ID"" msgid ""INIT"" msgstr ""INIT"" msgid ""Load Spec from File"" msgstr ""Load Spec from File"" msgid ""Load or specify spec of the policy in YAML format."" msgstr ""Load or specify spec of the policy in YAML format."" msgid ""Load or specify spec of the profile in YAML format."" msgstr ""Load or specify spec of the profile in YAML format."" msgid ""Load the spec yaml file and set to spec below."" msgstr ""Load the spec YAML file and set to spec below."" msgid ""Manage Policies"" msgstr ""Manage Policies"" msgid ""Max Size"" msgstr ""Max Size"" msgid ""Max size of the cluster. Default to -1 means unlimited."" msgstr ""Max size of the cluster. Default to -1 means unlimited."" msgid ""Message"" msgstr ""Message"" msgid ""Metadata"" msgstr ""Metadata"" msgid ""Metadata of the cluster in YAML format."" msgstr ""Metadata of the cluster in YAML format."" msgid ""Metadata of the node in YAML format."" msgstr ""Metadata of the node in YAML format."" msgid ""Metadata of the profile in YAML format."" msgstr ""Metadata of the profile in YAML format."" msgid ""Min Size"" msgstr ""Min Size"" msgid ""Min size of the cluster. Default to 0."" msgstr ""Min size of the cluster. Default to 0."" msgid ""Name"" msgstr ""Name"" msgid ""Name of the cluster."" msgstr ""Name of the cluster."" msgid ""Name of the node."" msgstr ""Name of the node."" msgid ""Name of the policy."" msgstr ""Name of the policy."" msgid ""Name of the profile."" msgstr ""Name of the profile."" msgid ""Name of the receiver."" msgstr ""Name of the receiver."" msgid ""Name or ID of the targeted action to be triggered."" msgstr ""Name or ID of the targeted action to be triggered."" msgid ""New timeout (in seconds) value for the cluster."" msgstr ""New timeout (in seconds) value for the cluster."" msgid ""Node"" msgstr ""Node"" #, python-format msgid ""Node %s was successfully created."" msgstr ""Node %s was successfully created."" #, python-format msgid ""Node %s was successfully updated."" msgstr ""Node %s was successfully updated."" msgid ""Node Count"" msgstr ""Node Count"" msgid ""Nodes"" msgstr ""Nodes"" msgid ""Object ID"" msgstr ""Object ID"" msgid ""Object Name"" msgstr ""Object Name"" msgid ""Overview"" msgstr ""Overview"" msgid ""Parameters"" msgstr ""Parameters"" msgid ""Parameters of the receiver in YAML format."" msgstr ""Parameters of the receiver in YAML format."" msgid ""Params"" msgstr ""Params"" msgid ""Physical ID"" msgstr ""Physical ID"" msgid ""Policies"" msgstr ""Policies"" msgid ""Policies for the cluster."" msgstr ""Policies for the cluster."" msgid ""Policies on the cluster were successfully updated."" msgstr ""Policies on the cluster were successfully updated."" msgid ""Policy"" msgstr ""Policy"" #, python-format msgid ""Policy %s was successfully created."" msgstr ""Policy %s was successfully created."" #, python-format msgid ""Policy %s was successfully updated."" msgstr ""Policy %s was successfully updated."" msgid ""Policy Spec Examples"" msgstr ""Policy Spec Examples"" msgid ""Profile"" msgstr ""Profile"" #, python-format msgid ""Profile %s was successfully created."" msgstr ""Profile %s was successfully created."" #, python-format msgid ""Profile %s was successfully updated."" msgstr ""Profile %s was successfully updated."" msgid ""Profile Name"" msgstr ""Profile Name"" msgid ""Profile Spec Examples"" msgstr ""Profile Spec Examples"" msgid ""Profile used for this cluster."" msgstr ""Profile used for this cluster."" msgid ""Profile used for this node."" msgstr ""Profile used for this node."" msgid ""Profiles"" msgstr ""Profiles"" msgid ""RECOVERING"" msgstr ""RECOVERING"" msgid ""RESIZING"" msgstr ""RESIZING"" msgid ""Receiver"" msgstr ""Receiver"" #, python-format msgid ""Receiver %s was successfully created."" msgstr ""Receiver %s was successfully created."" #, python-format msgid ""Receiver %s was successfully updated."" msgstr ""Receiver %s was successfully updated."" msgid ""Receivers"" msgstr ""Receivers"" msgid ""Role"" msgstr ""Role"" msgid ""Role for this node in the cluster."" msgstr ""Role for this node in the cluster."" msgid ""Role for this node in the specific cluster."" msgstr ""Role for this node in the specific cluster."" msgid ""Scale In the Cluster"" msgstr ""Scale In the Cluster"" msgid ""Scale Out the Cluster"" msgstr ""Scale Out the Cluster"" msgid ""Scale-In"" msgstr ""Scale-In"" msgid ""Scale-Out"" msgstr ""Scale-Out"" msgid ""Scale-in Cluster"" msgstr ""Scale-in Cluster"" msgid ""Scale-out Cluster"" msgstr ""Scale-out Cluster"" msgid ""Select action for the receiver."" msgstr ""Select action for the receiver."" msgid ""Select cluster for the node."" msgstr ""Select cluster for the node."" msgid ""Select cluster for the receiver."" msgstr ""Select cluster for the receiver."" msgid ""Select policies from the available policies below."" msgstr ""Select policies from the available policies below."" msgid ""Select profile for the cluster."" msgstr ""Select profile for the cluster."" msgid ""Select profile for the node."" msgstr ""Select profile for the node."" msgid ""Select the policy to apply to the cluster."" msgstr ""Select the policy to apply to the cluster."" msgid ""Select type for the receiver."" msgstr ""Select type for the receiver."" msgid ""Spec"" msgstr ""Spec"" msgid ""Specify node count for scale-in."" msgstr ""Specify node count for scale-in."" msgid ""Specify node count for scale-out."" msgstr ""Specify node count for scale-out."" msgid ""Status"" msgstr ""Status"" msgid ""Status Reason"" msgstr ""Status Reason"" msgid ""Targeted cluster for this receiver."" msgstr ""Targeted cluster for this receiver."" msgid ""The informations needed for cluster creation"" msgstr ""The information needed for cluster creation"" msgid ""The informations needed for node creation."" msgstr ""The information needed for node creation."" msgid ""The metadata yaml used to create the node."" msgstr ""The metadata yaml used to create the node."" msgid ""The metadata yaml used to create the profile."" msgstr ""The metadata YAML used to create the profile."" msgid ""The metadata yaml used to update the node."" msgstr ""The metadata yaml used to update the node."" msgid ""The metadata yaml used to update the profile."" msgstr ""The metadata yaml used to update the profile."" msgid """" ""The spec yaml used to create the policy. Edit loaded yaml from file using "" ""above 'Load Spec from File', or see samples from link below to write."" msgstr """" ""The spec YAML used to create the policy. Edit loaded YAML from file using "" ""above 'Load Spec from File', or see samples from link below to write."" msgid """" ""The spec yaml used to create the profile. Edit loaded yaml from file using "" ""above 'Load Spec from File', or see samples from link below to write."" msgstr """" ""The spec YAML used to create the profile. Edit loaded YAML from file using "" ""above 'Load Spec from File', or see samples from link below to write."" msgid ""Timeout"" msgstr ""Timeout"" msgid ""Type"" msgstr ""Type"" msgid ""Type of the receiver. Default to webhook"" msgstr ""Type of the receiver. Default to webhook"" msgid ""UPDATING"" msgstr ""UPDATING"" #, python-format msgid ""Unable to create the cluster with name: %(name)s"" msgstr ""Unable to create the cluster with name: %(name)s"" #, python-format msgid ""Unable to create the node with name: %(name)s"" msgstr ""Unable to create the node with name: %(name)s"" #, python-format msgid ""Unable to create the policy with name: %(name)s"" msgstr ""Unable to create the policy with name: %(name)s"" #, python-format msgid ""Unable to create the profile with name: %(name)s"" msgstr ""Unable to create the profile with name: %(name)s"" #, python-format msgid ""Unable to create the receiver with name: %(name)s"" msgstr ""Unable to create the receiver with name: %(name)s"" #, python-format msgid ""Unable to delete Cluster: %s."" msgid_plural ""Unable to delete Clusters: %s."" msgstr[0] ""Unable to delete Cluster: %s."" msgstr[1] ""Unable to delete Clusters: %s."" #, python-format msgid ""Unable to delete Node: %s."" msgid_plural ""Unable to delete Nodes: %s."" msgstr[0] ""Unable to delete Node: %s."" msgstr[1] ""Unable to delete Nodes: %s."" #, python-format msgid ""Unable to delete Policy: %s."" msgid_plural ""Unable to delete Policies: %s."" msgstr[0] ""Unable to delete Policy: %s."" msgstr[1] ""Unable to delete Policies: %s."" #, python-format msgid ""Unable to delete Profile: %s."" msgid_plural ""Unable to delete Profiles: %s."" msgstr[0] ""Unable to delete Profile: %s."" msgstr[1] ""Unable to delete Profiles: %s."" #, python-format msgid ""Unable to delete Receiver: %s."" msgid_plural ""Unable to delete Receivers: %s."" msgstr[0] ""Unable to delete Receiver: %s."" msgstr[1] ""Unable to delete Receivers: %s."" #, python-format msgid ""Unable to delete the cluster with id: %(id)s."" msgstr ""Unable to delete the cluster with id: %(id)s."" #, python-format msgid ""Unable to delete the node with id: %(id)s"" msgstr ""Unable to delete the node with id: %(id)s"" #, python-format msgid ""Unable to delete the policy with id: %(id)s."" msgstr ""Unable to delete the policy with id: %(id)s."" #, python-format msgid ""Unable to delete the profile with id: %(id)s."" msgstr ""Unable to delete the profile with id: %(id)s."" #, python-format msgid ""Unable to delete the receiver with id: %(id)s."" msgstr ""Unable to delete the receiver with id: %(id)s."" #, python-format msgid ""Unable to retrieve the cluster with id: %(id)s."" msgstr ""Unable to retrieve the cluster with id: %(id)s."" msgid ""Unable to retrieve the clusters."" msgstr ""Unable to retrieve the clusters."" #, python-format msgid ""Unable to retrieve the events with id: %(id)s."" msgstr ""Unable to retrieve the events with id: %(id)s."" #, python-format msgid ""Unable to retrieve the node with id: %(id)s."" msgstr ""Unable to retrieve the node with id: %(id)s."" msgid ""Unable to retrieve the nodes."" msgstr ""Unable to retrieve the nodes."" #, python-format msgid ""Unable to retrieve the policies of the cluster with id: %(id)s."" msgstr ""Unable to retrieve the policies of the cluster with id: %(id)s."" msgid ""Unable to retrieve the policies."" msgstr ""Unable to retrieve the policies."" #, python-format msgid ""Unable to retrieve the policy with id: %(id)s."" msgstr ""Unable to retrieve the policy with id: %(id)s."" #, python-format msgid ""Unable to retrieve the profile with id: %(id)s."" msgstr ""Unable to retrieve the profile with id: %(id)s."" msgid ""Unable to retrieve the profiles."" msgstr ""Unable to retrieve the profiles."" #, python-format msgid ""Unable to retrieve the receiver with id: %(id)s."" msgstr ""Unable to retrieve the receiver with id: %(id)s."" msgid ""Unable to retrieve the receivers."" msgstr ""Unable to retrieve the receivers."" #, python-format msgid ""Unable to scale-%(scale)s the cluster with name: %(name)s"" msgstr ""Unable to scale-%(scale)s the cluster with name: %(name)s"" msgid ""Unable to update policies of the cluster"" msgstr ""Unable to update policies of the cluster"" #, python-format msgid ""Unable to update the cluster with name: %(name)s"" msgstr ""Unable to update the cluster with name: %(name)s"" #, python-format msgid ""Unable to update the node with name: %(name)s"" msgstr ""Unable to update the node with name: %(name)s"" #, python-format msgid ""Unable to update the policy with name: %(name)s"" msgstr ""Unable to update the policy with name: %(name)s"" #, python-format msgid ""Unable to update the profile with name: %(name)s"" msgstr ""Unable to update the profile with name: %(name)s"" #, python-format msgid ""Unable to update the receiver with name: %(name)s"" msgstr ""Unable to update the receiver with name: %(name)s"" msgid ""Update"" msgstr ""Update"" msgid ""Update Cluster"" msgstr ""Update Cluster"" msgid ""Update Node"" msgstr ""Update Node"" msgid ""Update Policy"" msgstr ""Update Policy"" msgid ""Update Profile"" msgstr ""Update Profile"" msgid ""Update Receiver"" msgstr ""Update Receiver"" msgid ""Updated"" msgstr ""Updated"" msgid ""WARNING"" msgstr ""WARNING"" msgid ""Webhook"" msgstr ""Webhook"" msgid ""YAML formated metadata"" msgstr ""YAML formated metadata"" msgid """" ""YAML formatted parameters that will be passed to target action when the "" ""receiver is triggered."" msgstr """" ""YAML formatted parameters that will be passed to target action when the "" ""receiver is triggered."" #, python-format msgid ""You are not allowed to delete clusters: %s"" msgstr ""You are not allowed to delete clusters: %s"" #, python-format msgid ""You are not allowed to delete nodes: %s"" msgstr ""You are not allowed to delete nodes: %s"" #, python-format msgid ""You are not allowed to delete policies: %s"" msgstr ""You are not allowed to delete policies: %s"" #, python-format msgid ""You are not allowed to delete profiles: %s"" msgstr ""You are not allowed to delete profiles: %s"" #, python-format msgid ""You are not allowed to delete receivers: %s"" msgstr ""You are not allowed to delete receivers: %s"" #, python-format msgid ""You have selected \""%s\"". Deleted Cluster is not recoverable."" msgid_plural ""You have selected \""%s\"". Deleted Clusters are not recoverable."" msgstr[0] ""You have selected \""%s\"". Deleted Cluster is not recoverable."" msgstr[1] ""You have selected \""%s\"". Deleted Clusters are not recoverable."" #, python-format msgid ""You have selected \""%s\"". Deleted Node is not recoverable."" msgid_plural ""You have selected \""%s\"". Deleted Nodes are not recoverable."" msgstr[0] ""You have selected \""%s\"". Deleted Node is not recoverable."" msgstr[1] ""You have selected \""%s\"". Deleted Nodes are not recoverable."" #, python-format msgid ""You have selected \""%s\"". Deleted Policy is not recoverable."" msgid_plural ""You have selected \""%s\"". Deleted Policies are not recoverable."" msgstr[0] ""You have selected \""%s\"". Deleted Policy is not recoverable."" msgstr[1] ""You have selected \""%s\"". Deleted Policies are not recoverable."" #, python-format msgid ""You have selected \""%s\"". Deleted Profile is not recoverable."" msgid_plural ""You have selected \""%s\"". Deleted Profiles are not recoverable."" msgstr[0] ""You have selected \""%s\"". Deleted Profile is not recoverable."" msgstr[1] ""You have selected \""%s\"". Deleted Profiles are not recoverable."" #, python-format msgid ""You have selected \""%s\"". Deleted Receiver is not recoverable."" msgid_plural ""You have selected \""%s\"". Deleted Receivers are not recoverable."" msgstr[0] ""You have selected \""%s\"". Deleted Receiver is not recoverable."" msgstr[1] ""You have selected \""%s\"". Deleted Receivers are not recoverable."" msgid ""You may update the editable properties of your cluster here."" msgstr ""You may update the editable properties of your cluster here."" msgid ""You may update the editable properties of your node here."" msgstr ""You may update the editable properties of your node here."" msgid ""You may update the editable properties of your profile here."" msgstr ""You may update the editable properties of your profile here."" msgid ""in"" msgstr ""in"" msgid ""out"" msgstr ""out"" ",,754,0
openstack%2Foslo.middleware~master~Ib4707b55c190b117410212cef7f5afc789c91583,openstack/oslo.middleware,master,Ib4707b55c190b117410212cef7f5afc789c91583,add bandit to pep8 job,MERGED,2017-11-30 03:22:28.000000000,2017-12-13 03:11:38.000000000,2017-12-13 03:11:38.000000000,"[{'_account_id': 2472}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 03:22:28.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/e6a09f3ce70fb0de919752a09a2fb210f797f1e1', 'message': 'add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: Ib4707b55c190b117410212cef7f5afc789c91583\n'}]",0,524053,e6a09f3ce70fb0de919752a09a2fb210f797f1e1,7,3,1,9796,,,0,"add bandit to pep8 job

Add the bandit security scanner to the pep8 job.

Change-Id: Ib4707b55c190b117410212cef7f5afc789c91583
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/53/524053/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,e6a09f3ce70fb0de919752a09a2fb210f797f1e1,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_middleware -x tests -n5,commands = flake8,8,1
openstack%2Ftempest~master~I80e56a82a8bcd32769be643c678ee65fd43f9887,openstack/tempest,master,I80e56a82a8bcd32769be643c678ee65fd43f9887,Unskip test test_get_server_diagnostics_by_admin,ABANDONED,2016-02-16 09:45:57.000000000,2017-12-13 03:07:16.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7428}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 16425}, {'_account_id': 16437}]","[{'number': 1, 'created': '2016-02-16 09:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/743492ab400881c8f1e85499f8db528639e714ab', 'message': 'Unskip test test_get_server_diagnostics_by_admin\n\nUnskip test test_get_server_diagnostics_by_admin because 1240043\nhas been resolved since Juno release\n\nChange-Id: I80e56a82a8bcd32769be643c678ee65fd43f9887\n'}, {'number': 2, 'created': '2016-02-16 11:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d1d4f977fcaa0ce27f467cbc4c5ceaae2d050414', 'message': 'Unskip test test_get_server_diagnostics_by_admin\n\nUnskip test test_get_server_diagnostics_by_admin because 1240043\nhas been resolved since Juno release\n\nChange-Id: I80e56a82a8bcd32769be643c678ee65fd43f9887\n'}, {'number': 3, 'created': '2016-02-17 06:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9c8dc52adf72f6863b3a993189fd0a69cad38015', 'message': 'Unskip test test_get_server_diagnostics_by_admin\n\nUnskip test test_get_server_diagnostics_by_admin because 1240043\nhas been resolved since Juno release\n\nChange-Id: I80e56a82a8bcd32769be643c678ee65fd43f9887\n'}, {'number': 4, 'created': '2016-03-01 06:58:19.000000000', 'files': ['tempest/api/compute/admin/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/abc4ad50c5f8d164fd0190b36c35994566968a7f', 'message': 'Unskip test test_get_server_diagnostics_by_admin\n\nUnskip test test_get_server_diagnostics_by_admin because 1240043\nhas been resolved since Juno release\n\nChange-Id: I80e56a82a8bcd32769be643c678ee65fd43f9887\n'}]",0,280574,abc4ad50c5f8d164fd0190b36c35994566968a7f,41,7,4,16425,,,0,"Unskip test test_get_server_diagnostics_by_admin

Unskip test test_get_server_diagnostics_by_admin because 1240043
has been resolved since Juno release

Change-Id: I80e56a82a8bcd32769be643c678ee65fd43f9887
",git fetch https://review.opendev.org/openstack/tempest refs/changes/74/280574/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_servers.py'],1,743492ab400881c8f1e85499f8db528639e714ab,unskip_tests,," @decorators.skip_because(bug=""1240043"")",0,1
openstack%2Ftempest~master~Id9f24dec4045e9cd230dca2469d2b983b60f0f4b,openstack/tempest,master,Id9f24dec4045e9cd230dca2469d2b983b60f0f4b,Implement keystone v3 case test_authentication_with_invalid_domain,ABANDONED,2015-11-09 05:19:48.000000000,2017-12-13 03:06:38.000000000,,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 16425}, {'_account_id': 22692}]","[{'number': 1, 'created': '2015-11-09 05:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f4a7abe475dfe997ee38c60119d95ba609d6a04', 'message': 'Implement keystone v3 case test_authentication_with_invalid_domain\n\nUser authenticate with an invalid domain should fail\n\nChange-Id: Id9f24dec4045e9cd230dca2469d2b983b60f0f4b\nPartial-Bug: 1513748\n'}, {'number': 2, 'created': '2015-11-25 04:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c0b3599998e810d439ce98cb66bbb3f698a1b09d', 'message': 'Implement keystone v3 case test_authentication_with_invalid_domain\n\nUser authenticate with an invalid domain should fail\n\nChange-Id: Id9f24dec4045e9cd230dca2469d2b983b60f0f4b\nPartial-Bug: 1513748\n'}, {'number': 3, 'created': '2016-02-17 09:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/643081e4834e39809eb9f8548ec97c74ba198254', 'message': 'Implement keystone v3 case test_authentication_with_invalid_domain\n\nUser authenticate with an invalid domain should fail\n\nChange-Id: Id9f24dec4045e9cd230dca2469d2b983b60f0f4b\nPartial-Bug: 1513748\n'}, {'number': 4, 'created': '2016-10-13 11:55:22.000000000', 'files': ['tempest/api/identity/admin/v3/test_users_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c94a9d8c73b1230d604b72e51233178fe8ef722c', 'message': 'Implement keystone v3 case test_authentication_with_invalid_domain\n\nUser authenticate with an invalid domain should fail\n\nChange-Id: Id9f24dec4045e9cd230dca2469d2b983b60f0f4b\nPartial-Bug: 1513748\n'}]",0,242932,c94a9d8c73b1230d604b72e51233178fe8ef722c,26,7,4,16425,,,0,"Implement keystone v3 case test_authentication_with_invalid_domain

User authenticate with an invalid domain should fail

Change-Id: Id9f24dec4045e9cd230dca2469d2b983b60f0f4b
Partial-Bug: 1513748
",git fetch https://review.opendev.org/openstack/tempest refs/changes/32/242932/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/v3/test_users_negative.py'],1,5f4a7abe475dfe997ee38c60119d95ba609d6a04,bug/1513748,"# Copyright 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest_lib import exceptions as lib_exc from tempest.api.identity import base from tempest import test class UsersNegativeTest(base.BaseIdentityV3AdminTest): @test.attr(type=['negative']) @test.idempotent_id('7f86c682-56f6-4b08-8249-f56452e44dbd') def test_authentication_with_invalid_domain(self): # User's token for an invalid domain should not be authenticated self.data.setup_test_v3_user() self.data.setup_test_domain() self.assertRaises(lib_exc.Unauthorized, self.token.auth, self.data.test_user, self.data.test_password, domain_id=self.data.domain['id']) ",,33,0
openstack%2Foslo.i18n~master~I7b01e7edde84fb6c6860724c933b1dd70306c666,openstack/oslo.i18n,master,I7b01e7edde84fb6c6860724c933b1dd70306c666,add bandit to pep8 job,MERGED,2017-11-30 03:19:01.000000000,2017-12-13 03:04:24.000000000,2017-12-13 03:04:24.000000000,"[{'_account_id': 2472}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 03:19:01.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/7a84979365e116a598ba6dd0a1c7a20f54acdf17', 'message': 'add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: I7b01e7edde84fb6c6860724c933b1dd70306c666\n'}]",0,524052,7a84979365e116a598ba6dd0a1c7a20f54acdf17,7,3,1,9796,,,0,"add bandit to pep8 job

Add the bandit security scanner to the pep8 job.

Change-Id: I7b01e7edde84fb6c6860724c933b1dd70306c666
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/52/524052/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,7a84979365e116a598ba6dd0a1c7a20f54acdf17,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_i18n -x tests -n5,commands = flake8,9,1
openstack%2Foslo.cache~master~Ifd1414536ed2ffa1f0c9ebf012569b5869067793,openstack/oslo.cache,master,Ifd1414536ed2ffa1f0c9ebf012569b5869067793,add bandit to pep8 job,MERGED,2017-11-30 02:57:56.000000000,2017-12-13 03:01:40.000000000,2017-12-13 03:01:40.000000000,"[{'_account_id': 2472}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 02:57:56.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/a800709d936b87f777b7cf600d9f66ec96c6c3c1', 'message': 'add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: Ifd1414536ed2ffa1f0c9ebf012569b5869067793\n'}]",0,524049,a800709d936b87f777b7cf600d9f66ec96c6c3c1,7,3,1,9796,,,0,"add bandit to pep8 job

Add the bandit security scanner to the pep8 job.

Change-Id: Ifd1414536ed2ffa1f0c9ebf012569b5869067793
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/49/524049/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,a800709d936b87f777b7cf600d9f66ec96c6c3c1,bandit,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_cache -x tests -n5,commands = flake8,8,1
openstack%2Fpython-openstackclient~master~I0c596531a8af03da17d5ce39d75b12e941403aa5,openstack/python-openstackclient,master,I0c596531a8af03da17d5ce39d75b12e941403aa5,Send 'changes-since' instead of 'changes_since' query parameter,MERGED,2017-11-14 16:15:46.000000000,2017-12-13 02:57:49.000000000,2017-12-13 02:57:49.000000000,"[{'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 14374}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-14 16:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b0d5a7bec951305d3e0b225edbdc4a938b56b08f', 'message': ""Send 'changes-since' instead of 'changes_since' query parameter\n\nPer API reference, only 'changes-since' is accepted and the variant\nwith underscore is ignored, making the CLI functionality broken.\n\nChange-Id: I0c596531a8af03da17d5ce39d75b12e941403aa5\nCloses-Bug: 1732216\n""}, {'number': 2, 'created': '2017-11-14 19:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a55d78ca07d7a889d480335943395ac6891e72d2', 'message': ""Send 'changes-since' instead of 'changes_since' query parameter\n\nPer API reference, only 'changes-since' is accepted and the variant\nwith underscore is ignored, making the CLI functionality broken.\n\nChange-Id: I0c596531a8af03da17d5ce39d75b12e941403aa5\nCloses-Bug: 1732216\n""}, {'number': 3, 'created': '2017-12-12 00:08:12.000000000', 'files': ['openstackclient/tests/unit/compute/v2/test_server.py', 'releasenotes/notes/bug-1732216-b41bfedebff911e1.yaml', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/116526275d0953fda93c7ff8eacd8631c5af68d5', 'message': ""Send 'changes-since' instead of 'changes_since' query parameter\n\nPer API reference, only 'changes-since' is accepted and the variant\nwith underscore is ignored, making the CLI functionality broken.\n\n[dtroyer] added release note and fixed unit tests.\n\nChange-Id: I0c596531a8af03da17d5ce39d75b12e941403aa5\nCloses-Bug: 1732216\n""}]",0,519693,116526275d0953fda93c7ff8eacd8631c5af68d5,18,4,3,10338,,,0,"Send 'changes-since' instead of 'changes_since' query parameter

Per API reference, only 'changes-since' is accepted and the variant
with underscore is ignored, making the CLI functionality broken.

[dtroyer] added release note and fixed unit tests.

Change-Id: I0c596531a8af03da17d5ce39d75b12e941403aa5
Closes-Bug: 1732216
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/93/519693/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/server.py'],1,b0d5a7bec951305d3e0b225edbdc4a938b56b08f,bug/1732216," 'changes-since': parsed_args.changes_since, if search_opts['changes-since']: try: timeutils.parse_isotime(search_opts['changes-since']) '-since'])"," 'changes_since': parsed_args.changes_since, if search_opts['changes_since']: try: timeutils.parse_isotime(search_opts['changes_since']) '_since'])",4,4
openstack%2Fzun~master~I33a1c7a8becb37a249d8cb276b19c22f170fa186,openstack/zun,master,I33a1c7a8becb37a249d8cb276b19c22f170fa186,Set port device_id as uuid of the container,MERGED,2017-12-09 07:32:34.000000000,2017-12-13 02:36:17.000000000,2017-12-13 02:36:17.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 22406}, {'_account_id': 23055}]","[{'number': 1, 'created': '2017-12-09 07:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/4222a058103d85b895b89828804709e19491f20d', 'message': 'Set port device_id as uuid of the container\n\nThis patch sets the device_id as the UUID of the container when\ncreating the port.\n\nChange-Id: I33a1c7a8becb37a249d8cb276b19c22f170fa186\nCloses-Bug: #1737267\n'}, {'number': 2, 'created': '2017-12-11 01:22:25.000000000', 'files': ['zun/network/kuryr_network.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/c806a6ccbd56393e86ed1e38201d6faa2e313ef8', 'message': 'Set port device_id as uuid of the container\n\nThis patch sets the device_id as the UUID of the container when\ncreating or updating the port.\n\nChange-Id: I33a1c7a8becb37a249d8cb276b19c22f170fa186\nCloses-Bug: #1737267\n'}]",2,526826,c806a6ccbd56393e86ed1e38201d6faa2e313ef8,22,4,2,23055,,,0,"Set port device_id as uuid of the container

This patch sets the device_id as the UUID of the container when
creating or updating the port.

Change-Id: I33a1c7a8becb37a249d8cb276b19c22f170fa186
Closes-Bug: #1737267
",git fetch https://review.opendev.org/openstack/zun refs/changes/26/526826/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/network/kuryr_network.py'],1,4222a058103d85b895b89828804709e19491f20d,bug/1737267," 'device_id': container.uuid,",,1,0
openstack%2Fsushy~master~I984feb279774895efbe587b962afeda882c55e65,openstack/sushy,master,I984feb279774895efbe587b962afeda882c55e65,Avoid tox_install.sh for constraints support,MERGED,2017-12-02 06:33:48.000000000,2017-12-13 02:21:07.000000000,2017-12-13 02:21:07.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24441}]","[{'number': 1, 'created': '2017-12-02 06:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/f101038d5c5fce4d3e1709ec5044b647bc7479f1', 'message': 'Avoid tox_install.sh for constraints support\n\nWe do not need tox_install.sh, pip can handle constraints itself\nand install the project correctly. Thus update tox.ini and remove\nthe now obsolete tools/tox_install.sh file.\n\nThis follows https://review.openstack.org/#/c/508061 to remove\ntools/tox_install.sh.\n\nChange-Id: I984feb279774895efbe587b962afeda882c55e65\n'}, {'number': 2, 'created': '2017-12-02 16:55:43.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sushy/commit/5ebee30934fb086c69adc52d0643e913d00311e1', 'message': 'Avoid tox_install.sh for constraints support\n\nWe do not need tox_install.sh, pip can handle constraints itself\nand install the project correctly. Thus update tox.ini and remove\nthe now obsolete tools/tox_install.sh file.\n\nThis follows https://review.openstack.org/#/c/508061 to remove\ntools/tox_install.sh.\n\nChange-Id: I984feb279774895efbe587b962afeda882c55e65\n'}]",0,524806,5ebee30934fb086c69adc52d0643e913d00311e1,11,4,2,6547,,,0,"Avoid tox_install.sh for constraints support

We do not need tox_install.sh, pip can handle constraints itself
and install the project correctly. Thus update tox.ini and remove
the now obsolete tools/tox_install.sh file.

This follows https://review.openstack.org/#/c/508061 to remove
tools/tox_install.sh.

Change-Id: I984feb279774895efbe587b962afeda882c55e65
",git fetch https://review.opendev.org/openstack/sushy refs/changes/06/524806/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,f101038d5c5fce4d3e1709ec5044b647bc7479f1,rm-tox_install,install_command = pip install -U {opts} {packages} deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt,install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} deps = -r{toxinidir}/test-requirements.txt,5,58
openstack%2Fpython-openstackclient~master~Iecf61495664fb8413d35ef69f07ea929d190d002,openstack/python-openstackclient,master,Iecf61495664fb8413d35ef69f07ea929d190d002,Add support for endpoing filter commands,MERGED,2017-11-16 15:17:03.000000000,2017-12-13 02:18:43.000000000,2017-12-13 02:18:42.000000000,"[{'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-16 15:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b2c8fb026d17e9a493cc1ca818a1e6fa5d3ac70d', 'message': 'Add support for endpoing filter commands\n\nImplements: blueprint keystone-endpoint-filter\n\nChange-Id: Iecf61495664fb8413d35ef69f07ea929d190d002\n'}, {'number': 2, 'created': '2017-11-16 15:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/53ac24b9b84acd1e94a63f9603863ae25aa7e242', 'message': 'Add support for endpoing filter commands\n\nImplements the commands that allow to link and endpoint to\na project for endpoint filter management.\n\nImplements: blueprint keystone-endpoint-filter\n\nChange-Id: Iecf61495664fb8413d35ef69f07ea929d190d002\n'}, {'number': 3, 'created': '2017-11-17 09:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a4071bd6cd27c8d61ccf12e121b23acae86e2970', 'message': 'Add support for endpoing filter commands\n\nImplements the commands that allow to link and endpoint to\na project for endpoint filter management.\n\nImplements: blueprint keystone-endpoint-filter\n\nChange-Id: Iecf61495664fb8413d35ef69f07ea929d190d002\n'}, {'number': 4, 'created': '2017-11-20 09:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d1018bcde8bf7c8cd58dc8304e46276548521396', 'message': 'Add support for endpoing filter commands\n\nImplements the commands that allow to link and endpoint to\na project for endpoint filter management.\n\nImplements: blueprint keystone-endpoint-filter\n\nChange-Id: Iecf61495664fb8413d35ef69f07ea929d190d002\n'}, {'number': 5, 'created': '2017-11-20 15:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1893f8781ba8a96d00ad9bd4b59dc43de8849e0e', 'message': 'Add support for endpoing filter commands\n\nImplements the commands that allow to link and endpoint to\na project for endpoint filter management.\n\nImplements: blueprint keystone-endpoint-filter\n\nChange-Id: Iecf61495664fb8413d35ef69f07ea929d190d002\n'}, {'number': 6, 'created': '2017-11-21 07:05:30.000000000', 'files': ['openstackclient/identity/v3/endpoint.py', 'openstackclient/tests/functional/identity/v3/test_endpoint.py', 'releasenotes/notes/keystone-endpoint-filter-e930a7b72276fa2c.yaml', 'doc/source/cli/command-objects/endpoint.rst', 'openstackclient/tests/unit/identity/v3/test_endpoint.py', 'openstackclient/tests/unit/identity/v3/fakes.py', 'setup.cfg', 'openstackclient/tests/functional/identity/v3/common.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/12ee1861085144f43e6e535f82ba5d9b5d9a5632', 'message': 'Add support for endpoing filter commands\n\nImplements the commands that allow to link and endpoint to\na project for endpoint filter management.\n\nImplements: blueprint keystone-endpoint-filter\n\nChange-Id: Iecf61495664fb8413d35ef69f07ea929d190d002\n'}]",12,520614,12ee1861085144f43e6e535f82ba5d9b5d9a5632,26,3,6,5575,,,0,"Add support for endpoing filter commands

Implements the commands that allow to link and endpoint to
a project for endpoint filter management.

Implements: blueprint keystone-endpoint-filter

Change-Id: Iecf61495664fb8413d35ef69f07ea929d190d002
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/14/520614/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v3/endpoint.py', 'openstackclient/tests/functional/identity/v3/test_endpoint.py', 'doc/source/cli/command-objects/endpoint.rst', 'openstackclient/tests/unit/identity/v3/test_endpoint.py', 'openstackclient/tests/unit/identity/v3/fakes.py', 'setup.cfg', 'openstackclient/tests/functional/identity/v3/common.py']",7,b2c8fb026d17e9a493cc1ca818a1e6fa5d3ac70d,bp/keystone-endpoint-filter," ENDPOINT_LIST_PROJECT_HEADERS = ['ID', 'Name']",,416,16
openstack%2Fqinling~master~If57bd6da55df0e704739fbfb0d904d14069a5073,openstack/qinling,master,If57bd6da55df0e704739fbfb0d904d14069a5073,Admin user should not delete other project's function,MERGED,2017-12-13 01:39:26.000000000,2017-12-13 02:17:09.000000000,2017-12-13 02:17:09.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 01:39:26.000000000', 'files': ['qinling/api/controllers/v1/function.py', 'qinling/db/api.py', 'qinling_tempest_plugin/tests/api/test_functions.py'], 'web_link': 'https://opendev.org/openstack/qinling/commit/ddaa5fc471733d70c0c0d800a82a5a46c58429e7', 'message': ""Admin user should not delete other project's function\n\nChange-Id: If57bd6da55df0e704739fbfb0d904d14069a5073\n""}]",0,527558,ddaa5fc471733d70c0c0d800a82a5a46c58429e7,6,2,1,6732,,,0,"Admin user should not delete other project's function

Change-Id: If57bd6da55df0e704739fbfb0d904d14069a5073
",git fetch https://review.opendev.org/openstack/qinling refs/changes/58/527558/1 && git format-patch -1 --stdout FETCH_HEAD,"['qinling/api/controllers/v1/function.py', 'qinling/db/api.py', 'qinling_tempest_plugin/tests/api/test_functions.py']",3,ddaa5fc471733d70c0c0d800a82a5a46c58429e7,fix-delete-function," def _create_function(self): function_name = data_utils.rand_name('function', prefix=self.name_prefix) with open(self.python_zip_file, 'rb') as package_data: resp, body = self.client.create_function( {""source"": ""package""}, self.runtime_id, name=function_name, package_data=package_data, entry='%s.main' % self.base_name ) self.assertEqual(201, resp.status_code) function_id = body['id'] self.addCleanup(self.client.delete_resource, 'functions', function_id, ignore_notfound=True) return function_id function_id = self._create_function() function_id = self._create_function() @decorators.idempotent_id('5cb44ee4-6c0c-4ede-9e6c-e1b9109eaa2c') def test_delete_not_allowed(self): """"""Even admin user can not delete other project's function."""""" function_id = self._create_function() self.assertRaises( exceptions.Forbidden, self.admin_client.delete_resource, 'functions', function_id )"," function_name = data_utils.rand_name('function', prefix=self.name_prefix) with open(self.python_zip_file, 'rb') as package_data: resp, body = self.client.create_function( {""source"": ""package""}, self.runtime_id, name=function_name, package_data=package_data, entry='%s.main' % self.base_name ) function_id = body['id'] self.assertEqual(201, resp.status_code) self.addCleanup(self.client.delete_resource, 'functions', function_id, ignore_notfound=True) function_name = data_utils.rand_name('function', prefix=self.name_prefix) with open(self.python_zip_file, 'rb') as package_data: resp, body = self.client.create_function( {""source"": ""package""}, self.runtime_id, name=function_name, package_data=package_data, entry='%s.main' % self.base_name ) self.assertEqual(201, resp.status_code) function_id = body['id'] self.addCleanup(self.client.delete_resource, 'functions', function_id, ignore_notfound=True)",44,36
openstack%2Fmanila~master~I9a79b5ececc583e80129cc980930e162e805b246,openstack/manila,master,I9a79b5ececc583e80129cc980930e162e805b246,[policy in code] Add support for share resource [3/10],MERGED,2017-11-24 08:33:22.000000000,2017-12-13 02:05:58.000000000,2017-12-13 01:23:39.000000000,"[{'_account_id': 5046}, {'_account_id': 6491}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 13984}, {'_account_id': 14384}, {'_account_id': 15100}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23630}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-11-24 08:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ced107d0976f8144224bf9dcf833eea734d740db', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 2, 'created': '2017-11-24 08:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fd248e9509a6d69d8e05ad031dfd07a13ecd1664', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 3, 'created': '2017-11-24 08:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2a75be7cd301c221d0aa6c637b6f4f88317e268b', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 4, 'created': '2017-11-25 03:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2299b46f3b9da1d177d442b664a93c83bcab4547', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 5, 'created': '2017-11-28 03:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f7d9c120e2cacece8329923f2e9dfcc5af729210', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 6, 'created': '2017-11-28 03:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1436951cc899ec0b5d4ea4a26c534dd16442343e', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 7, 'created': '2017-12-11 02:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/42da4046c45d6ed8254aaf0db27e97b316ad3a8b', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}, {'number': 8, 'created': '2017-12-11 06:39:25.000000000', 'files': ['etc/manila/policy.json', 'manila/policy.py', 'manila/policies/shares.py', 'manila/policies/__init__.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/6184063a4ca2f908a9186f292b3f2c59e9e59e0d', 'message': '[policy in code] Add support for share resource [3/10]\n\nThis patch adds policy in code support for share\nresources.\n\nChange-Id: I9a79b5ececc583e80129cc980930e162e805b246\nPartial-Implements: blueprint policy-in-code\n'}]",39,522739,6184063a4ca2f908a9186f292b3f2c59e9e59e0d,67,20,8,15100,,,0,"[policy in code] Add support for share resource [3/10]

This patch adds policy in code support for share
resources.

Change-Id: I9a79b5ececc583e80129cc980930e162e805b246
Partial-Implements: blueprint policy-in-code
",git fetch https://review.opendev.org/openstack/manila refs/changes/39/522739/8 && git format-patch -1 --stdout FETCH_HEAD,"['etc/manila/policy.json', 'manila/policy.py', 'manila/policies/shares.py', 'manila/policies/__init__.py']",4,ced107d0976f8144224bf9dcf833eea734d740db,policy-and-docs-in-code,"from manila.policies import shares shares.list_rules(),",,323,23
openstack%2Fmurano~master~I5733dcc59c3c298dd85db9bb0a0df04fcc78b199,openstack/murano,master,I5733dcc59c3c298dd85db9bb0a0df04fcc78b199,Minor updates to encryption docs,MERGED,2017-12-06 11:52:26.000000000,2017-12-13 02:03:52.000000000,2017-12-13 02:03:52.000000000,"[{'_account_id': 1390}, {'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-12-06 11:52:26.000000000', 'files': ['doc/source/admin/appdev-guide/encrypting_properties.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/252445aba6b27b341d595e5974b49cc6afde7af1', 'message': 'Minor updates to encryption docs\n\n* Remove unnecessary quotes from the murano-engine example\n\n* Remove unnecessary <project_id> from murano-engine example\n\n* Add quotes in the dashboard example.\n\nChange-Id: I5733dcc59c3c298dd85db9bb0a0df04fcc78b199\n'}]",3,526039,252445aba6b27b341d595e5974b49cc6afde7af1,11,4,1,1390,,,0,"Minor updates to encryption docs

* Remove unnecessary quotes from the murano-engine example

* Remove unnecessary <project_id> from murano-engine example

* Add quotes in the dashboard example.

Change-Id: I5733dcc59c3c298dd85db9bb0a0df04fcc78b199
",git fetch https://review.opendev.org/openstack/murano refs/changes/39/526039/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/appdev-guide/encrypting_properties.rst'],1,252445aba6b27b341d595e5974b49cc6afde7af1,," auth_type = keystone_password 'auth_url': '<keystone_url>/v3', 'username': '<username>', 'user_domain_name': '<domain_name>', 'password': '<password>', 'project_name': '<project_name>', 'project_domain_name': '<domain_name>' } .. note:: Horizon config must be valid Python, so the quotes above are important. "," auth_type = 'keystone_password' project_id = <project_id> 'auth_url': <keystone_url>/v3', 'username': <username>, 'user_domain_name': <domain_name>, 'password': <password>, 'project_name': <project_name>, 'project_domain_name': <domain_name> } ",9,8
openstack%2Fsushy~master~If57184d71d244cdc6f04d3f66d56c374d4336d24,openstack/sushy,master,If57184d71d244cdc6f04d3f66d56c374d4336d24,Adds EthernetInterface to the library,MERGED,2017-04-02 10:50:12.000000000,2017-12-13 02:03:15.000000000,2017-10-09 16:37:32.000000000,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 11655}, {'_account_id': 16635}, {'_account_id': 18781}, {'_account_id': 19853}]","[{'number': 1, 'created': '2017-04-02 10:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/4f2c0fc4baeb3cfb9d46052f4119b93219349cfc', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 2, 'created': '2017-04-03 03:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/81ee481d3be526d45b0bdf70048e43ee5091b97c', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 3, 'created': '2017-04-03 05:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/aee623a19ec0f22747f39a1d028524a1211ede6d', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 4, 'created': '2017-06-19 19:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/fe5141156afea65c541a88c2152f280385f18ced', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 5, 'created': '2017-07-06 03:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/7bf3505ebfbae06e3bcb767cd6cb71dcd8b03367', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 6, 'created': '2017-07-06 13:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/b9d5d216bb11309c21b15bb5fd471c16ffcb3b42', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 7, 'created': '2017-07-07 10:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/dd59706683c5c521547cd314e8b2cec79f12de59', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 8, 'created': '2017-07-13 15:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/9a9b829be77af2b511c1951425f0fecad0cc2492', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 9, 'created': '2017-07-17 18:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/05b7c8b825404422c10f3f54a9f921915498ef5e', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 10, 'created': '2017-07-18 17:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/594b2a58c713f7d2f6f052f8349bf22fd0ef730c', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 11, 'created': '2017-07-19 15:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/39c14c62c7352f20757385b771a454ca0f7e0df3', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 12, 'created': '2017-07-19 15:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/f245fcbb46e24b8f0f0bd18455c3139f5cebea0c', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nThis has been tested on HPE Redfish hardware.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 13, 'created': '2017-09-22 03:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/bb4e6122939b0c102265a9bb4e6c1b9fd5727e80', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nThis has been tested on HPE Redfish hardware.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 14, 'created': '2017-09-22 03:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/922a30d0329c68bccb8df4cedcb1148bb65db194', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nThis has been tested on HPE Redfish hardware.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 15, 'created': '2017-10-06 05:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/1d3f994e028e51d0d3cf5dd16dfe2b9d0cc5680b', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nThis has been tested on HPE Redfish hardware.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}, {'number': 16, 'created': '2017-10-06 07:05:16.000000000', 'files': ['sushy/tests/unit/json_samples/ethernet_interfaces.json', 'sushy/resources/system/constants.py', 'sushy/tests/unit/json_samples/ethernet_interfaces_collection.json', 'sushy/utils.py', 'sushy/resources/system/system.py', 'sushy/tests/unit/resources/system/test_system.py', 'releasenotes/notes/add_ethernet_interface-df308f814f0e4bce.yaml', 'sushy/tests/unit/resources/system/test_ethernet_interfaces.py', 'sushy/resources/system/ethernet_interface.py', 'sushy/resources/system/mappings.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/8fe2904a62b0f56dc3fc3fefc5a5a746911ce891', 'message': 'Adds EthernetInterface to the library\n\nThis commit adds the EthernetInterface to the library.\nThis returns the MAC addresses and its status as a dictionary to\nits caller.\n\nThis has been tested on HPE Redfish hardware.\n\nChange-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24\n'}]",80,452532,8fe2904a62b0f56dc3fc3fefc5a5a746911ce891,64,9,16,11297,,,0,"Adds EthernetInterface to the library

This commit adds the EthernetInterface to the library.
This returns the MAC addresses and its status as a dictionary to
its caller.

This has been tested on HPE Redfish hardware.

Change-Id: If57184d71d244cdc6f04d3f66d56c374d4336d24
",git fetch https://review.opendev.org/openstack/sushy refs/changes/32/452532/11 && git format-patch -1 --stdout FETCH_HEAD,"['sushy/tests/unit/json_samples/ethernetinterfaces.json', 'sushy/resources/system/system.py', 'sushy/resources/system/ethernetinterfaces.py', 'sushy/tests/unit/resources/system/test_ethernetinterfaces.py', 'sushy/tests/unit/json_samples/ethernetinterfaces_collection.json']",5,4f2c0fc4baeb3cfb9d46052f4119b93219349cfc,eth_6_Oct,"{ ""@odata.type"": ""#EthernetInterfaceCollection.EthernetInterfaceCollection"", ""Name"": ""Ethernet Interface Collection"", ""Description"": ""System NICs on Contoso Servers"", ""Members@odata.count"": 1, ""Members"": [{ ""@odata.id"": ""/redfish/v1/Systems/437XR1138R2/EthernetInterfaces/12446A3B0411"" }], ""Oem"": {}, ""@odata.context"": ""/redfish/v1/$metadata#EthernetInterfaceCollection.EthernetInterfaceCollection"", ""@odata.id"": ""/redfish/v1/Systems/437XR1138R2/EthernetInterfaces"" } ",,290,0
openstack%2Fpython-qinlingclient~master~I2a9fc8367287a038709c577507074c2011a16ec6,openstack/python-qinlingclient,master,I2a9fc8367287a038709c577507074c2011a16ec6,Support function query filtering,MERGED,2017-12-13 01:12:47.000000000,2017-12-13 01:52:50.000000000,2017-12-13 01:52:50.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-13 01:12:47.000000000', 'files': ['qinlingclient/v1/function.py', 'qinlingclient/osc/v1/base.py'], 'web_link': 'https://opendev.org/openstack/python-qinlingclient/commit/d1158c2ceb3f10c4056ade8747837a3bffc07313', 'message': 'Support function query filtering\n\nChange-Id: I2a9fc8367287a038709c577507074c2011a16ec6\n'}]",0,527553,d1158c2ceb3f10c4056ade8747837a3bffc07313,6,2,1,6732,,,0,"Support function query filtering

Change-Id: I2a9fc8367287a038709c577507074c2011a16ec6
",git fetch https://review.opendev.org/openstack/python-qinlingclient refs/changes/53/527553/1 && git format-patch -1 --stdout FETCH_HEAD,"['qinlingclient/v1/function.py', 'qinlingclient/osc/v1/base.py']",2,d1158c2ceb3f10c4056ade8747837a3bffc07313,get-all-functions," 'project_id', 'created_at', 'updated_at' 'project_id', 'created_at', 'updated_at' action='append',"," 'created_at', 'updated_at' 'created_at', 'updated_at' nargs='*',",12,4
openstack%2Fzaqar-specs~master~I849ded5791bf9bd9ab5b1d3cb686fc02872b0815,openstack/zaqar-specs,master,I849ded5791bf9bd9ab5b1d3cb686fc02872b0815,Remove duplicate template.rst from Zaqar-Spec,MERGED,2017-11-22 01:35:10.000000000,2017-12-13 01:21:32.000000000,2017-12-13 01:21:31.000000000,"[{'_account_id': 6484}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 01:35:10.000000000', 'files': ['template.rst'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/1acf71d3163799065865dbb40f82b6f0735704f6', 'message': 'Remove duplicate template.rst from Zaqar-Spec\n\nNow there is two same template.rst under root folder\nand specs folder. Just remove the one from root folder\nto keep consistent with other projects.\n\nChange-Id: I849ded5791bf9bd9ab5b1d3cb686fc02872b0815\n'}]",0,522057,1acf71d3163799065865dbb40f82b6f0735704f6,6,2,1,8846,,,0,"Remove duplicate template.rst from Zaqar-Spec

Now there is two same template.rst under root folder
and specs folder. Just remove the one from root folder
to keep consistent with other projects.

Change-Id: I849ded5791bf9bd9ab5b1d3cb686fc02872b0815
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/57/522057/1 && git format-patch -1 --stdout FETCH_HEAD,['template.rst'],1,1acf71d3163799065865dbb40f82b6f0735704f6,remove-duplicate-template,,".. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/zaqar/+spec/awesome-thing should be named awesome-thing.rst. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ============================= The title of your blueprint ============================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/zaqar/+spec/example Introduction paragraph -- why are we doing anything? Problem description =================== A detailed description of the problem. Proposed change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? If your specification proposes any changes to the Zaqar REST API such as changing parameters which can be returned or accepted, or even the semantics of what happens when a client calls into the API, then you should add the APIImpact flag to the commit message. Specifications with the APIImpact flag can be found with the following query: https://review.openstack.org/#/q/status:open+project:openstack/zaqar-specs+message:apiimpact,n,z Alternatives ------------ This is an optional section, where it does apply we'd just like a demonstration that some thought has been put into why the proposed approach is the best one. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Can list additional ids if they intend on doing substantial implementation work on this blueprint. Milestones ---------- Target Milestone for completion: Juno-2 Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ - Include specific references to specs and/or blueprints in zaqar, or in other projects, that this one either depends on or is related to. .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",0,95
openstack%2Fkeystone-specs~master~I3eb124159dc9f6939e7a89d4613778c6dd752209,openstack/keystone-specs,master,I3eb124159dc9f6939e7a89d4613778c6dd752209,Update unified limits spec to clarify flat-ness,ABANDONED,2017-12-08 17:57:41.000000000,2017-12-13 01:18:06.000000000,,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 17:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/9f1013b619c9da618d59f167e69898ed6ab182be', 'message': 'Update unified limits spec to clarify flat-ness\n\nThis commit adds some more clarification about the initial model we\nwill be targeting for the Queens release. Additional models may be\nadded in the future that implement more sophisticated enforcement\nmodels with respect to project hierarchies.\n\nChange-Id: I3eb124159dc9f6939e7a89d4613778c6dd752209\n'}, {'number': 2, 'created': '2017-12-08 19:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/a7b348fcddd1d9ce2d990c6723507c55892242bc', 'message': 'Update unified limits spec to clarify flat-ness\n\nThis commit adds some more clarification about the initial model we\nwill be targeting for the Queens release. Additional models may be\nadded in the future that implement more sophisticated enforcement\nmodels with respect to project hierarchies.\n\nChange-Id: I3eb124159dc9f6939e7a89d4613778c6dd752209\n'}, {'number': 3, 'created': '2017-12-08 20:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/c2df5fa593df32f91a399fddd6b006a73b7288d3', 'message': 'Update unified limits spec to clarify flat-ness\n\nThis commit adds some more clarification about the initial model we\nwill be targeting for the Queens release. Additional models may be\nadded in the future that implement more sophisticated enforcement\nmodels with respect to project hierarchies.\n\nChange-Id: I3eb124159dc9f6939e7a89d4613778c6dd752209\n'}, {'number': 4, 'created': '2017-12-11 22:22:01.000000000', 'files': ['requirements.txt', 'specs/keystone/queens/limits-api.rst', 'doc/source/DejaVuSans.ttf', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/701c80ab0c303370ae7ff81e0006d443556ea994', 'message': 'Update unified limits spec to clarify flat-ness\n\nThis commit adds some more clarification about the initial model we\nwill be targeting for the Queens release. Additional models may be\nadded in the future that implement more sophisticated enforcement\nmodels with respect to project hierarchies.\n\nChange-Id: I3eb124159dc9f6939e7a89d4613778c6dd752209\n'}]",17,526745,701c80ab0c303370ae7ff81e0006d443556ea994,14,3,4,5046,,,0,"Update unified limits spec to clarify flat-ness

This commit adds some more clarification about the initial model we
will be targeting for the Queens release. Additional models may be
added in the future that implement more sophisticated enforcement
models with respect to project hierarchies.

Change-Id: I3eb124159dc9f6939e7a89d4613778c6dd752209
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/45/526745/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'specs/keystone/queens/limits-api.rst', 'doc/source/DejaVuSans.ttf', 'doc/source/conf.py']",4,9f1013b619c9da618d59f167e69898ed6ab182be,bp/unified-limits," 'sphinxcontrib.blockdiag',blockdiag_html_image_format = 'SVG' blockdiag_fontpath = 'DejaVuSans.ttf' ",,119,70
openstack%2Fneutron~master~I250e7f673a8fe9a202314f4cbfbd0ab8e51f6e33,openstack/neutron,master,I250e7f673a8fe9a202314f4cbfbd0ab8e51f6e33,test_metering_plugin: convert from Agent model to OVO,MERGED,2017-12-11 09:46:00.000000000,2017-12-13 01:15:48.000000000,2017-12-13 01:15:48.000000000,"[{'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 15471}, {'_account_id': 22348}, {'_account_id': 25903}, {'_account_id': 26072}]","[{'number': 1, 'created': '2017-12-11 09:46:00.000000000', 'files': ['neutron/tests/unit/services/metering/test_metering_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/64a2b56246a17d9afd652be41c8eb1a80a17554a', 'message': 'test_metering_plugin: convert from Agent model to OVO\n\nChange-Id: I250e7f673a8fe9a202314f4cbfbd0ab8e51f6e33\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n'}]",0,527038,64a2b56246a17d9afd652be41c8eb1a80a17554a,12,7,1,25903,,,0,"test_metering_plugin: convert from Agent model to OVO

Change-Id: I250e7f673a8fe9a202314f4cbfbd0ab8e51f6e33
Co-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>
Partially-Implements: blueprint adopt-oslo-versioned-objects-for-db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/527038/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/services/metering/test_metering_plugin.py'],1,64a2b56246a17d9afd652be41c8eb1a80a17554a,bp/adopt-oslo-versioned-objects-for-db,"from neutron.objects import agent as agent_obj agent1 = agent_obj.Agent(mock.ANY, host='agent1') agent2 = agent_obj.Agent(mock.ANY, host='agent2')",from neutron.db.models import agent as agent_model agent1 = agent_model.Agent(host='agent1') agent2 = agent_model.Agent(host='agent2'),3,3
openstack%2Fos-brick~master~I43828f47711118eba8d835222586db4faac93180,openstack/os-brick,master,I43828f47711118eba8d835222586db4faac93180,Avoid tox_install.sh for constraints support,MERGED,2017-12-01 13:43:57.000000000,2017-12-13 01:13:59.000000000,2017-12-13 01:13:59.000000000,"[{'_account_id': 5997}, {'_account_id': 6547}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19554}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24502}]","[{'number': 1, 'created': '2017-12-01 13:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6817f0ac3a834385ee208ccad8a338cd3d0a6216', 'message': 'Avoid tox_install.sh for constraints support\n\nWe do not need tox_install.sh, pip can handle constraints itself\nand install the project correctly. Thus update tox.ini and remove\nthe now obsolete tools/tox_install.sh file.\n\nThis follows https://review.openstack.org/#/c/508061 to remove\ntools/tox_install.sh.\n\nChange-Id: I43828f47711118eba8d835222586db4faac93180\n'}, {'number': 2, 'created': '2017-12-02 16:51:54.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/56d034ab10370853f1311f5e768f4aa258281ce2', 'message': 'Avoid tox_install.sh for constraints support\n\nWe do not need tox_install.sh, pip can handle constraints itself\nand install the project correctly. Thus update tox.ini and remove\nthe now obsolete tools/tox_install.sh file.\n\nThis follows https://review.openstack.org/#/c/508061 to remove\ntools/tox_install.sh.\n\nChange-Id: I43828f47711118eba8d835222586db4faac93180\n'}]",0,524603,56d034ab10370853f1311f5e768f4aa258281ce2,58,16,2,6547,,,0,"Avoid tox_install.sh for constraints support

We do not need tox_install.sh, pip can handle constraints itself
and install the project correctly. Thus update tox.ini and remove
the now obsolete tools/tox_install.sh file.

This follows https://review.openstack.org/#/c/508061 to remove
tools/tox_install.sh.

Change-Id: I43828f47711118eba8d835222586db4faac93180
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/03/524603/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,6817f0ac3a834385ee208ccad8a338cd3d0a6216,rm-tox_install,install_command = pip install -U {opts} {packages} deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txtdeps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txt, BRANCH_NAME=master CLIENT_NAME=os-brickinstall_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} deps = -r{toxinidir}/requirements.txtdeps = -r{toxinidir}/requirements.txt,7,35
openstack%2Fopenstack-ansible~stable%2Fpike~Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3,openstack/openstack-ansible,stable/pike,Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3,Only build ARA report when test fails,MERGED,2017-10-16 08:47:55.000000000,2017-12-13 00:57:18.000000000,2017-12-13 00:57:18.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 24468}, {'_account_id': 26576}]","[{'number': 1, 'created': '2017-10-16 08:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/713cd546099564865019697308b925a434636369', 'message': 'Only build ARA report when test fails\n\nIn order to reduce the quantity of unnecessary log content\nbeing kept in OpenStack-Infra we only generate the ARA report\nwhen the test result is a failure. The ARA sqlite database is\nstill available for self generation if desired for successful\ntests.\n\nChange-Id: Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3\n'}, {'number': 2, 'created': '2017-10-16 08:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/41b0d179a9b00f858c25a0a3cfe1663ba23d2ae5', 'message': 'Only build ARA report when test fails\n\nIn order to reduce the quantity of unnecessary log content\nbeing kept in OpenStack-Infra we only generate the ARA report\nwhen the test result is a failure. The ARA sqlite database is\nstill available for self generation if desired for successful\ntests.\n\nChange-Id: Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3\n(cherry picked from commit 03ace7a5bc6decea74b644b3bad1eacedf6e6de9)\n'}, {'number': 3, 'created': '2017-12-04 09:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f7002fec886cf9807c49467f4b0eb5cc51fee5fa', 'message': 'Only build ARA report when test fails\n\nIn order to reduce the quantity of unnecessary log content\nbeing kept in OpenStack-Infra we only generate the ARA report\nwhen the test result is a failure. The ARA sqlite database is\nstill available for self generation if desired for successful\ntests.\n\nChange-Id: Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3\n(cherry picked from commit 03ace7a5bc6decea74b644b3bad1eacedf6e6de9)\n'}, {'number': 4, 'created': '2017-12-12 13:49:05.000000000', 'files': ['scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e73d9b5788cf5553c8c2893d56bf8fbb0a0e0dcf', 'message': 'Only build ARA report when test fails\n\nIn order to reduce the quantity of unnecessary log content\nbeing kept in OpenStack-Infra we only generate the ARA report\nwhen the test result is a failure. The ARA sqlite database is\nstill available for self generation if desired for successful\ntests.\n\nChange-Id: Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3\n(cherry picked from commit 03ace7a5bc6decea74b644b3bad1eacedf6e6de9)\n'}]",0,512217,e73d9b5788cf5553c8c2893d56bf8fbb0a0e0dcf,39,7,4,6816,,,0,"Only build ARA report when test fails

In order to reduce the quantity of unnecessary log content
being kept in OpenStack-Infra we only generate the ARA report
when the test result is a failure. The ARA sqlite database is
still available for self generation if desired for successful
tests.

Change-Id: Ic0415ab79a1d0574d5b61a552bc20fc1f9c4e9d3
(cherry picked from commit 03ace7a5bc6decea74b644b3bad1eacedf6e6de9)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/17/512217/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,713cd546099564865019697308b925a434636369,infra-log-inode-reduction," # This environment variable captures the exit code # which was present when the trap was initiated. # This would be the success/failure of the test. export TEST_EXIT_CODE=$? # In order to reduce the quantity of unnecessary log content # being kept in OpenStack-Infra we only generate the ARA report # when the test result is a failure. if [[ ""${TEST_EXIT_CODE}"" != ""0"" ]]; then echo ""Generating ARA report due to non-zero exit code (${TEST_EXIT_CODE})."" /opt/ansible-runtime/bin/ara generate html ""${GATE_LOG_DIR}/ara"" || true else echo ""Not generating ARA report due to test pass."" fi # We still want the subunit report though, as that reflects # success/failure in OpenStack Health"," /opt/ansible-runtime/bin/ara generate html ""${GATE_LOG_DIR}/ara"" || true",16,1
openstack%2Ftripleo-heat-templates~master~I963aede41403ebbe3b9afb55a725b304a30a0cbb,openstack/tripleo-heat-templates,master,I963aede41403ebbe3b9afb55a725b304a30a0cbb,Add modulepath option when applying puppet inside docker.,MERGED,2017-12-07 15:56:03.000000000,2017-12-13 00:56:04.000000000,2017-12-13 00:56:04.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 18851}, {'_account_id': 20775}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-07 15:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8ed2e43190b1c99886c9cd9e7aa2d3254c823988', 'message': 'Add modulepath option when applying puppet inside docker.\n\nWhen new module are added, we may miss the symlinc in\n/etc/puppet/modules.  And for consistency and we mount the\n/usr/share/openstack-puppet/modules but currently don’t use it.\n\nChange-Id: I963aede41403ebbe3b9afb55a725b304a30a0cbb\nCloses-Bug: #1736980\n'}, {'number': 2, 'created': '2017-12-07 17:39:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e718804d0125ebaf1e0905ffa34d08b02125513', 'message': 'Add modulepath option when applying puppet inside docker.\n\nWhen new module are added, we may miss the symlinc in\n/etc/puppet/modules.  And for consistency and we mount the\n/usr/share/openstack-puppet/modules but currently don’t use it.\n\nChange-Id: I963aede41403ebbe3b9afb55a725b304a30a0cbb\nCloses-Bug: #1736980\n'}, {'number': 3, 'created': '2017-12-07 18:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2833d529a1fd7b395184e59ff3249ec7fbdc4641', 'message': 'Add modulepath option when applying puppet inside docker.\n\nWhen new module are added, we may miss the symlink in\n/etc/puppet/modules.  And for consistency as we mount the\n/usr/share/openstack-puppet/modules directory it’s better to add it\nto the modulepath.\n\nChange-Id: I963aede41403ebbe3b9afb55a725b304a30a0cbb\nCloses-Bug: #1736980\n'}, {'number': 4, 'created': '2017-12-07 19:09:25.000000000', 'files': ['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/haproxy.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4a708af34afb827ee067baf2f8eb3c4285aa26d7', 'message': 'Add modulepath option when applying puppet inside docker.\n\nWhen new module are added, we may miss the symlink in\n/etc/puppet/modules.  And for consistency as we mount the\n/usr/share/openstack-puppet/modules directory it’s better to add it\nto the modulepath.\n\nChange-Id: I963aede41403ebbe3b9afb55a725b304a30a0cbb\nCloses-Bug: #1736980\n'}]",0,526440,4a708af34afb827ee067baf2f8eb3c4285aa26d7,32,12,4,8297,,,0,"Add modulepath option when applying puppet inside docker.

When new module are added, we may miss the symlink in
/etc/puppet/modules.  And for consistency as we mount the
/usr/share/openstack-puppet/modules directory it’s better to add it
to the modulepath.

Change-Id: I963aede41403ebbe3b9afb55a725b304a30a0cbb
Closes-Bug: #1736980
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/526440/4 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,8ed2e43190b1c99886c9cd9e7aa2d3254c823988,bug/1736980, --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/usr/share/openstack-puppet/modules:/etc/puppet/modules $TAGS /etc/config.pp, --detailed-exitcodes --color=false --logdest syslog --logdest console $TAGS /etc/config.pp,2,1
openstack%2Fopenstack-ansible-galera_server~master~I943ea4dc8a2189dd766ff026cb44a00b9dd0f605,openstack/openstack-ansible-galera_server,master,I943ea4dc8a2189dd766ff026cb44a00b9dd0f605,Further simplify the upgrade check,MERGED,2017-11-30 07:26:32.000000000,2017-12-13 00:52:31.000000000,2017-12-13 00:52:30.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 07:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/6574d3be4ecedcf8593d49747ab0308cfd45fcc2', 'message': 'Further simplify the upgrade check\n\nThe upgrade check does not need to see if the node is running. If the on\ndisk version does not match what we expect and the ""galera_upgrade"" flag\nhas not been set simply, instruct the run to fail. If galera_upgrade has\nbeen set to ""true"" prep for the upgrade normally.\n\nChange-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-11-30 19:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/9b6e23c145372e49d4dc219a8d0a821299b20dc2', 'message': 'Further simplify the upgrade check\n\nThe upgrade check does not need to see if the node is running. If the on\ndisk version does not match what we expect and the ""galera_upgrade"" flag\nhas not been set simply, instruct the run to fail. If galera_upgrade has\nbeen set to ""true"" prep for the upgrade normally.\n\nChange-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2017-11-30 19:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/c9352ef461c13761fd134dca6b8dbe92171f425d', 'message': 'Further simplify the upgrade check\n\nThe upgrade check does not need to see if the node is running. If the on\ndisk version does not match what we expect and the ""galera_upgrade"" flag\nhas not been set simply, instruct the run to fail. If galera_upgrade has\nbeen set to ""true"" prep for the upgrade normally.\n\nChange-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2017-11-30 20:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/21e7cd6655f8129d4797c3c06ee65dcc7f492899', 'message': 'Further simplify the upgrade check\n\nThe upgrade check does not need to see if the node is running. If the on\ndisk version does not match what we expect and the ""galera_upgrade"" flag\nhas not been set simply, instruct the run to fail. If galera_upgrade has\nbeen set to ""true"" prep for the upgrade normally.\n\nChange-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2017-12-11 05:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/cfdb359d5a03928b14fba5c1bda5104ae42a790f', 'message': 'Further simplify the upgrade check\n\nThe upgrade check does not need to see if the node is running. If the on\ndisk version does not match what we expect and the ""galera_upgrade"" flag\nhas not been set simply, instruct the run to fail. If galera_upgrade has\nbeen set to ""true"" prep for the upgrade normally.\n\nChange-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2017-12-11 17:39:12.000000000', 'files': ['tasks/main.yml', 'tasks/galera_upgrade.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/a9fa402655247a03b5a5e5c46451982404bc941d', 'message': 'Further simplify the upgrade check\n\nThe upgrade check does not need to see if the node is running. If the on\ndisk version does not match what we expect and the ""galera_upgrade"" flag\nhas not been set simply, instruct the run to fail. If galera_upgrade has\nbeen set to ""true"" prep for the upgrade normally.\n\nChange-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,524086,a9fa402655247a03b5a5e5c46451982404bc941d,25,6,6,7353,,,0,"Further simplify the upgrade check

The upgrade check does not need to see if the node is running. If the on
disk version does not match what we expect and the ""galera_upgrade"" flag
has not been set simply, instruct the run to fail. If galera_upgrade has
been set to ""true"" prep for the upgrade normally.

Change-Id: I943ea4dc8a2189dd766ff026cb44a00b9dd0f605
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/86/524086/6 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_upgrade.yml'],1,6574d3be4ecedcf8593d49747ab0308cfd45fcc2,, - not galera_upgrade | bool - galera_upgrade | bool,- name: Check mysql running command: > systemctl status mysql register: mysql_running changed_when: false failed_when: false tags: - skip_ansible_lint - mysql_running.rc == 0 - (mysqladmin_version.rc != 0 and mysql_running.rc != 0) or galera_upgrade | bool,2,12
openstack%2Fpython-novaclient~master~I43a8435485751748ca6228f67d401945cb32652e,openstack/python-novaclient,master,I43a8435485751748ca6228f67d401945cb32652e,Move zuulv3 jobs to project repo,MERGED,2017-11-22 03:31:06.000000000,2017-12-13 00:43:59.000000000,2017-12-01 19:56:01.000000000,"[{'_account_id': 679}, {'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 11278}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-22 03:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/85f9d034842cbc949ea7695117e9538c81ca13be', 'message': 'Move zuulv3 jobs to project repo\n\nThis patch moves the zuulv3 jobs for python novaclient.\n\nChange-Id: I43a8435485751748ca6228f67d401945cb32652e\n'}, {'number': 2, 'created': '2017-11-22 03:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/5221ad8ac8b2ee0405887c139e518ba5d208b8a2', 'message': 'Move zuulv3 jobs to project repo\n\nThis patch moves the zuulv3 jobs for python novaclient.\n\nNeeded-By: I1508933ef77669754adf8032fc3d835960f78cb7\nNeeded-By: I37b02be0aeffc3a0f0516616b5294444012b8dea\n\nChange-Id: I43a8435485751748ca6228f67d401945cb32652e\n'}, {'number': 3, 'created': '2017-11-22 03:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/7035758385bb329ee0f9c83380c4e87080a1cb69', 'message': 'Move zuulv3 jobs to project repo\n\nThis patch moves the zuulv3 jobs for python novaclient.\n\nNeeded-By: I1508933ef77669754adf8032fc3d835960f78cb7\nNeeded-By: I37b02be0aeffc3a0f0516616b5294444012b8dea\n\nChange-Id: I43a8435485751748ca6228f67d401945cb32652e\n'}, {'number': 4, 'created': '2017-11-22 05:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ad3526274509bffa2370255f89ef359af6cc4d91', 'message': 'Move zuulv3 jobs to project repo\n\nThis patch moves the zuulv3 jobs for python novaclient.\n\nNeeded-By: I1508933ef77669754adf8032fc3d835960f78cb7\nNeeded-By: I37b02be0aeffc3a0f0516616b5294444012b8dea\n\nChange-Id: I43a8435485751748ca6228f67d401945cb32652e\n'}, {'number': 5, 'created': '2017-11-22 07:20:30.000000000', 'files': ['playbooks/legacy/novaclient-dsvm-functional-identity-v3-only/run.yaml', '.zuul.yaml', 'playbooks/legacy/novaclient-dsvm-functional-identity-v3-only/post.yaml', 'playbooks/legacy/novaclient-dsvm-functional-neutron/post.yaml', 'playbooks/legacy/novaclient-dsvm-functional-neutron/run.yaml'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/14ee2bcc4ea8296fb906db731139cd948e9e1102', 'message': 'Move zuulv3 jobs to project repo\n\nThis patch moves the zuulv3 jobs for python novaclient.\n\nNeeded-By: I1508933ef77669754adf8032fc3d835960f78cb7\nNeeded-By: I37b02be0aeffc3a0f0516616b5294444012b8dea\n\nChange-Id: I43a8435485751748ca6228f67d401945cb32652e\n'}]",4,522099,14ee2bcc4ea8296fb906db731139cd948e9e1102,32,6,5,8556,,,0,"Move zuulv3 jobs to project repo

This patch moves the zuulv3 jobs for python novaclient.

Needed-By: I1508933ef77669754adf8032fc3d835960f78cb7
Needed-By: I37b02be0aeffc3a0f0516616b5294444012b8dea

Change-Id: I43a8435485751748ca6228f67d401945cb32652e
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/99/522099/5 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/novaclient-dsvm-functional-neutron/post.yaml', 'playbooks/novaclient-dsvm-functional-identity-v3-only/post.yaml', '.zuul.yaml', 'playbooks/novaclient-dsvm-functional-identity-v3-only/run.yaml', 'playbooks/novaclient-dsvm-functional-neutron/run.yaml']",5,85f9d034842cbc949ea7695117e9538c81ca13be,zuulv3-novaclient,"- hosts: all name: Autoconverted job legacy-novaclient-dsvm-functional-neutron from old job gate-novaclient-dsvm-functional-neutron-ubuntu-xenial tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true export BRANCH_OVERRIDE=default export DEVSTACK_PROJECT_FROM_GIT=python-novaclient if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi # This ensures that if we set override branch to something # else, we still take python-novaclient from the zuul branch # name. So override branch can be 'stable/mitaka' but we can # test master changes. uc_project=`echo $DEVSTACK_PROJECT_FROM_GIT | tr [:lower:] [:upper:] | tr '-' '_' | sed 's/[^A-Z_]//'` export ""OVERRIDE_""$uc_project""_PROJECT_BRANCH""=$ZUUL_BRANCH function post_test_hook { # Configure and run functional tests $BASE/new/python-novaclient/novaclient/tests/functional/hooks/post_test_hook.sh } if [ ""-neutron"" == ""-identity-v3-only"" ] ; then export DEVSTACK_LOCAL_CONFIG=""ENABLE_IDENTITY_V2=False"" elif [ ""-neutron"" == ""-neutron"" ] ; then export DEVSTACK_GATE_NEUTRON=1 fi export -f post_test_hook cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",,310,0
openstack%2Fqinling~master~I7192c0006fd82e62f751323cc9707479040f5764,openstack/qinling,master,I7192c0006fd82e62f751323cc9707479040f5764,Support admin user get functions of other projects,MERGED,2017-12-12 02:30:49.000000000,2017-12-13 00:42:35.000000000,2017-12-13 00:42:35.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 02:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/5ecd9188ea8ceefdb37429af9aa3c628bab1c500', 'message': 'Support admin user get functions of other projects\n\nPartially implements: blueprint qinling-admin-operations\n\nChange-Id: I7192c0006fd82e62f751323cc9707479040f5764\n'}, {'number': 2, 'created': '2017-12-12 03:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/6262da39551a259abb87e2ca7c767250f0f7150b', 'message': 'Support admin user get functions of other projects\n\nPartially implements: blueprint qinling-admin-operations\nChange-Id: I7192c0006fd82e62f751323cc9707479040f5764\n'}, {'number': 3, 'created': '2017-12-12 08:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qinling/commit/f4fc87a20f047ad55243fc701c699eb1d5d39398', 'message': 'Support admin user get functions of other projects\n\nPartially implements: blueprint qinling-admin-operations\nChange-Id: I7192c0006fd82e62f751323cc9707479040f5764\n'}, {'number': 4, 'created': '2017-12-12 09:33:02.000000000', 'files': ['qinling/api/controllers/v1/function.py', 'qinling_tempest_plugin/post_test_hook.sh', 'qinling_tempest_plugin/tests/api/test_functions.py', 'qinling/db/base.py', 'etc/policy.json.sample', 'qinling/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/qinling/commit/2778c1cc3ba4a8dc71d3e0d49127c73bcf3b0ca1', 'message': 'Support admin user get functions of other projects\n\nPartially implements: blueprint qinling-admin-operations\nChange-Id: I7192c0006fd82e62f751323cc9707479040f5764\n'}]",0,527284,2778c1cc3ba4a8dc71d3e0d49127c73bcf3b0ca1,14,2,4,6732,,,0,"Support admin user get functions of other projects

Partially implements: blueprint qinling-admin-operations
Change-Id: I7192c0006fd82e62f751323cc9707479040f5764
",git fetch https://review.opendev.org/openstack/qinling refs/changes/84/527284/4 && git format-patch -1 --stdout FETCH_HEAD,"['qinling/api/controllers/v1/function.py', 'qinling_tempest_plugin/tests/api/test_functions.py', 'etc/policy.json.sample']",3,5ecd9188ea8ceefdb37429af9aa3c628bab1c500,bp/qinling-admin-operations," ""function:get_all:all_projects"": ""rule:context_is_admin"",",,80,3
openstack%2Fnetworking-generic-switch~stable%2Focata~I89ae9892f66441be9889658ffaa7c44a88da75c7,openstack/networking-generic-switch,stable/ocata,I89ae9892f66441be9889658ffaa7c44a88da75c7,zuul: add irrelevant-files section to job,MERGED,2017-12-11 15:29:52.000000000,2017-12-13 00:34:19.000000000,2017-12-13 00:34:19.000000000,"[{'_account_id': 6618}, {'_account_id': 9542}, {'_account_id': 14525}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 15:29:52.000000000', 'files': ['zuul.d/legacy-networking-generic-switch-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/33e0432210c132a0d11225ecdba7f4c429a66d88', 'message': ""zuul: add irrelevant-files section to job\n\nThis adds the 'irrelevant-files' section to the job\nnetworking-generic-switch-tempest-dsvm-dlm. If all the\nchanges are in this list, the job is not run.\n\nChange-Id: I89ae9892f66441be9889658ffaa7c44a88da75c7\n(cherry picked from commit 5f445ba99c817236efae59e61308f2604bff0575)\n""}]",0,527129,33e0432210c132a0d11225ecdba7f4c429a66d88,11,4,1,6618,,,0,"zuul: add irrelevant-files section to job

This adds the 'irrelevant-files' section to the job
networking-generic-switch-tempest-dsvm-dlm. If all the
changes are in this list, the job is not run.

Change-Id: I89ae9892f66441be9889658ffaa7c44a88da75c7
(cherry picked from commit 5f445ba99c817236efae59e61308f2604bff0575)
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/29/527129/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/legacy-networking-generic-switch-jobs.yaml'],1,33e0432210c132a0d11225ecdba7f4c429a66d88,zuul-clean-stable/ocata, irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^networking_generic_switch/tests/.*$ - ^setup.cfg$ - ^test-requirements.txt$ - ^tools/.*$ - ^tox.ini$,,8,0
openstack%2Fnova~master~I030cee9cebb0f030361aa6bbb612da5cd4202a7f,openstack/nova,master,I030cee9cebb0f030361aa6bbb612da5cd4202a7f,VMware: fix memory stats,MERGED,2017-10-31 12:10:03.000000000,2017-12-13 00:32:57.000000000,2017-12-13 00:32:57.000000000,"[{'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-31 12:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b42b5612e9940a5ce57ff710e4e02c06b592cf2', 'message': 'VMware: fix memory stats\n\nThe total memory for the vCenter cluster managed by Nova\nshould be the aggregated sum of total memory of each ESX host in the\ncluster. This is more accurate than using the available memory of the\nresource pool associated to the cluster.\n\nChange-Id: I030cee9cebb0f030361aa6bbb612da5cd4202a7f\n'}, {'number': 2, 'created': '2017-11-17 14:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42c625c0f8e50182f2fa6416294fcb3e06b540d9', 'message': 'VMware: fix memory stats\n\nThe total memory for the vCenter cluster managed by Nova\nshould be the aggregated sum of total memory of each ESX host in the\ncluster. This is more accurate than using the available memory of the\nresource pool associated to the cluster.\n\nChange-Id: I030cee9cebb0f030361aa6bbb612da5cd4202a7f\n'}, {'number': 3, 'created': '2017-11-22 14:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d28c756db4fbcaac244e960f8a79c5d38e8ba1f', 'message': 'VMware: fix memory stats\n\nThe total memory for the vCenter cluster managed by Nova\nshould be the aggregated sum of total memory of each ESX host in the\ncluster. This is more accurate than using the available memory of the\nresource pool associated to the cluster.\n\nChange-Id: I030cee9cebb0f030361aa6bbb612da5cd4202a7f\n'}, {'number': 4, 'created': '2017-12-12 08:12:21.000000000', 'files': ['nova/tests/unit/virt/vmwareapi/fake.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'releasenotes/notes/vmware-mem-stats-a9b6fac815d2bc57.yaml', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/93bd310b91f2ca6034fea04a48e8399270db1816', 'message': 'VMware: fix memory stats\n\nThe total memory for the vCenter cluster managed by Nova\nshould be the aggregated sum of total memory of each ESX host in the\ncluster. This is more accurate than using the available memory of the\nresource pool associated to the cluster.\n\nPartial-Bug: #1462957\nChange-Id: I030cee9cebb0f030361aa6bbb612da5cd4202a7f\n'}]",4,516634,93bd310b91f2ca6034fea04a48e8399270db1816,72,19,4,9172,,,0,"VMware: fix memory stats

The total memory for the vCenter cluster managed by Nova
should be the aggregated sum of total memory of each ESX host in the
cluster. This is more accurate than using the available memory of the
resource pool associated to the cluster.

Partial-Bug: #1462957
Change-Id: I030cee9cebb0f030361aa6bbb612da5cd4202a7f
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/516634/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/vmwareapi/fake.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_vm_util.py', 'nova/virt/vmwareapi/vm_util.py']",4,3b42b5612e9940a5ce57ff710e4e02c06b592cf2,bug/1462957," used_mem_mb = 0 total_mem_mb = 0 [""summary.hardware"", ""summary.runtime"", ""summary.quickStats""]) for obj in result.objects: host_props = propset_dict(obj.propSet) hardware_summary = host_props['summary.hardware'] runtime_summary = host_props['summary.runtime'] stats_summary = host_props['summary.quickStats'] threads = hardware_summary.numCpuThreads vcpus += threads used_mem_mb += stats_summary.overallMemoryUsage mem_mb = hardware_summary.memorySize / units.Mi total_mem_mb += mem_mb stats = {'vcpus': vcpus, 'mem': {'total': total_mem_mb, 'free': total_mem_mb - used_mem_mb}}"," mem_info = {'total': 0, 'free': 0} [""summary.hardware"", ""summary.runtime""]) for obj in result.objects: hardware_summary = obj.propSet[0].val runtime_summary = obj.propSet[1].val vcpus += hardware_summary.numCpuThreads res_mor = prop_dict.get('resourcePool') if res_mor: res_usage = session._call_method(vutil, ""get_object_property"", res_mor, ""summary.runtime.memory"") if res_usage: # maxUsage is the memory limit of the cluster available to VM's mem_info['total'] = int(res_usage.maxUsage / units.Mi) # overallUsage is the hypervisor's view of memory usage by VM's consumed = int(res_usage.overallUsage / units.Mi) mem_info['free'] = mem_info['total'] - consumed stats = {'vcpus': vcpus, 'mem': mem_info}",44,36
openstack%2Fproject-config~master~Id48bb17ef2dcb7e906624b2b7ee4b5428a39f824,openstack/project-config,master,Id48bb17ef2dcb7e906624b2b7ee4b5428a39f824,Add node requests graph to zuul dashboard,MERGED,2017-12-12 23:22:30.000000000,2017-12-13 00:25:16.000000000,2017-12-13 00:25:16.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 23:22:30.000000000', 'files': ['grafana/zuul-status.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a5c9e1bb3585a2060b660dee2f18fcb48c8958db', 'message': 'Add node requests graph to zuul dashboard\n\nThis is perhaps the most useful of the indicators which might show\nour backlog.\n\nChange-Id: Id48bb17ef2dcb7e906624b2b7ee4b5428a39f824\n'}]",0,527540,a5c9e1bb3585a2060b660dee2f18fcb48c8958db,9,4,1,1,,,0,"Add node requests graph to zuul dashboard

This is perhaps the most useful of the indicators which might show
our backlog.

Change-Id: Id48bb17ef2dcb7e906624b2b7ee4b5428a39f824
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/527540/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/zuul-status.yaml'],1,a5c9e1bb3585a2060b660dee2f18fcb48c8958db,," - title: Node Requests span: 4 targets: - target: alias(stats.gauges.zuul.nodepool.current_requests, 'Requests') type: graph",,5,0
openstack%2Fproject-config~master~I6a18de708bd6b692ac03924a4f0db42aef1403d5,openstack/project-config,master,I6a18de708bd6b692ac03924a4f0db42aef1403d5,Import ansible-role-redhat-subscription (Part 2),MERGED,2017-12-11 19:41:18.000000000,2017-12-13 00:23:17.000000000,2017-12-13 00:23:17.000000000,"[{'_account_id': 3153}, {'_account_id': 4162}, {'_account_id': 9061}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27253}]","[{'number': 1, 'created': '2017-12-11 19:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/807c6d5513d2cbc6c996937da96a2e191ac09d63', 'message': ""Import ansible-role-redhat-subscription\n\nAfter discussing with the Ansible role author, Sam Doran, we would like\nto move ansible-role-redhat-subscription to OpenStack namespace, so we\ncan use Infra resources (CI, code review, etc) instead of Github where\nit seems there is no central place for Ansible roles at this time.\n\nThis role will be consumed by TripleO but can be consumed by anyone\nwithout any dependency on TripleO, that's why we don't want it under\nTripleO's governance.\n\nSam Doran will remain the main maintainer for now and will be part of\nansible-role-redhat-subscription-core in Gerrit.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n""}, {'number': 2, 'created': '2017-12-11 19:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3dbcdf341052a64808b289f8df37b3819b36ece3', 'message': ""Import ansible-role-redhat-subscription\n\nAfter discussing with the Ansible role author, Sam Doran, we would like\nto move ansible-role-redhat-subscription to OpenStack namespace, so we\ncan use Infra resources (CI, code review, etc) instead of Github where\nit seems there is no central place for Ansible roles at this time.\n\nThis role will be consumed by TripleO but can be consumed by anyone\nwithout any dependency on TripleO, that's why we don't want it under\nTripleO's governance.\n\nSam Doran will remain the main maintainer for now and will be part of\nansible-role-redhat-subscription-core in Gerrit.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n""}, {'number': 3, 'created': '2017-12-11 19:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2ddf06545dfe22355948e3fbd073b743aa9437a9', 'message': 'Import ansible-role-redhat-subscription (Part 2)\n\nAdding IRC notifications and CI jobs.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n'}, {'number': 4, 'created': '2017-12-11 20:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b7adc5b3655fc155a49e6ea5be1d641a030f5d6a', 'message': 'Import ansible-role-redhat-subscription (Part 2)\n\nAdding IRC notifications and CI jobs.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n'}, {'number': 5, 'created': '2017-12-11 20:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ecacea71652a4e5574a10490daecf6c4dfb0f3d7', 'message': 'Import ansible-role-redhat-subscription (Part 2)\n\nAdding IRC notifications and CI jobs.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n'}, {'number': 6, 'created': '2017-12-11 22:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2c8308b8ec44fa7b1386562308fbc32b52be80f4', 'message': 'Import ansible-role-redhat-subscription (Part 2)\n\nAdding IRC notifications and CI jobs.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n'}, {'number': 7, 'created': '2017-12-12 21:50:15.000000000', 'files': ['gerritbot/channels.yaml', 'zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/21d0fe0be9c9ada2051ad05367170cf8333dd7b1', 'message': 'Import ansible-role-redhat-subscription (Part 2)\n\nAdding IRC notifications and CI jobs.\n\nChange-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5\n'}]",0,527226,21d0fe0be9c9ada2051ad05367170cf8333dd7b1,23,6,7,3153,,,0,"Import ansible-role-redhat-subscription (Part 2)

Adding IRC notifications and CI jobs.

Change-Id: I6a18de708bd6b692ac03924a4f0db42aef1403d5
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/527226/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml']",4,807c6d5513d2cbc6c996937da96a2e191ac09d63,import/ansible-role-rhsm, - openstack/ansible-role-redhat-subscription,,11,0
openstack%2Fopenstack-ansible-os_nova~master~Ie43d5a8990f2982b708ad9b8cae8f710cdbb3329,openstack/openstack-ansible-os_nova,master,Ie43d5a8990f2982b708ad9b8cae8f710cdbb3329,Updated from OpenStack Ansible Tests,MERGED,2017-12-06 00:06:29.000000000,2017-12-13 00:12:21.000000000,2017-12-13 00:12:21.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-06 00:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/c7064a6ae1f995d6b182c3653671eb79746e0f68', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ie43d5a8990f2982b708ad9b8cae8f710cdbb3329\n'}, {'number': 2, 'created': '2017-12-12 15:15:38.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/3cfc8fd9c94e283bae41a27bc02e7264d21f8e27', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ie43d5a8990f2982b708ad9b8cae8f710cdbb3329\n'}]",0,525821,3cfc8fd9c94e283bae41a27bc02e7264d21f8e27,20,6,2,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ie43d5a8990f2982b708ad9b8cae8f710cdbb3329
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/21/525821/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,c7064a6ae1f995d6b182c3653671eb79746e0f68,openstack/openstack-ansible-tests/sync-tests,# The gcc compiler gcc libffi-devel [platform:rpm] openssl-devel [platform:rpm],gcc [platform:dpkg]gcc [platform:rpm]libffi-devel [platform:rpm !platform:opensuseproject-42] libffi-devel-gcc5 [platform:opensuseproject-42] openssl-devel [platform:redhat] libopenssl-devel [platform:suse],5,6
openstack%2Fopenstack-ansible-tests~stable%2Fpike~Ic12bb7efa6e841108d56a9368917157c4e104c77,openstack/openstack-ansible-tests,stable/pike,Ic12bb7efa6e841108d56a9368917157c4e104c77,test-log-collect.sh: Collect all environment variables,MERGED,2017-12-11 16:36:37.000000000,2017-12-12 23:57:22.000000000,2017-12-12 23:57:22.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 16:36:37.000000000', 'files': ['test-log-collect.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/f7f1f69d170e9fd612f0bd0838b1f6eded2a6854', 'message': ""test-log-collect.sh: Collect all environment variables\n\nWe export many variables throughout the CI jobs so it's helpful to\ncollect them all as part of the job results.\n\nChange-Id: Ic12bb7efa6e841108d56a9368917157c4e104c77\n(cherry picked from commit db570376ec442b64c64e234f1a2e29c85c12ecf3)\n""}]",0,527155,f7f1f69d170e9fd612f0bd0838b1f6eded2a6854,13,3,1,23163,,,0,"test-log-collect.sh: Collect all environment variables

We export many variables throughout the CI jobs so it's helpful to
collect them all as part of the job results.

Change-Id: Ic12bb7efa6e841108d56a9368917157c4e104c77
(cherry picked from commit db570376ec442b64c64e234f1a2e29c85c12ecf3)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/55/527155/1 && git format-patch -1 --stdout FETCH_HEAD,['test-log-collect.sh'],1,f7f1f69d170e9fd612f0bd0838b1f6eded2a6854,collect-environment-stable/pike,"# Collect job environment env > ""${WORKING_DIR}/logs/environment.txt"" || true ",,3,0
openstack%2Fnetworking-ovn~master~Ie930fc448d65545ed1a39d15a55c6ead563095e5,openstack/networking-ovn,master,Ie930fc448d65545ed1a39d15a55c6ead563095e5,Refactor subnet dhcp options methods,MERGED,2017-12-07 16:23:35.000000000,2017-12-12 23:56:12.000000000,2017-12-12 23:56:12.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23458}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-12-07 16:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5357629dec6df08cf9c4896d74acbfbbe9a92bf8', 'message': 'Refactor subnet dhcp options methods\n\nThis patch is refactoring some the subnet dhcp options methods to make\nit simpler to implement the database sync work [0].\n\nThe get_subnet_dhcp_options() method has extended to also be able to\nreturn the dhcp options referent to the ports with a new\n``with_ports`` parameter.\n\nThe return value of the get_subnet_dhcp_options() also changed to a\ndictionary containing two keys: ``subnet`` and ``ports`` where each\nvalue is the DHCP_Options referent to those resources.\n\nOn the update_subnets() method, start the transction on the higher level\nmethod and have the helper methods to just add the OVSDB commands to it.\nThis sill later simplify the place where the revision_number comparison\nwill happen (at the higher level method).\n\nTwo methods are no longer needed and have been removed:\n\n* get_subnet_and_ports_dhcp_options\n* compose_dhcp_options_commands\n\n[0] https://review.openstack.org/#/c/490834/\n\nChange-Id: Ie930fc448d65545ed1a39d15a55c6ead563095e5\n'}, {'number': 2, 'created': '2017-12-11 14:37:40.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/tests/functional/test_ovn_db_resources.py', 'networking_ovn/tests/unit/ovsdb/test_impl_idl_ovn.py', 'networking_ovn/tests/unit/fakes.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7f8fe077984d75ea596f04b4e181a5c6b76cd022', 'message': 'Refactor subnet dhcp options methods\n\nThis patch is refactoring some the subnet dhcp options methods to make\nit simpler to implement the database sync work [0].\n\nThe get_subnet_dhcp_options() method has extended to also be able to\nreturn the dhcp options referent to the ports with a new\n``with_ports`` parameter.\n\nThe return value of the get_subnet_dhcp_options() also changed to a\ndictionary containing two keys: ``subnet`` and ``ports`` where each\nvalue is the DHCP_Options referent to those resources.\n\nOn the update_subnets() method, start the transction on the higher level\nmethod and have the helper methods to just add the OVSDB commands to it.\nThis sill later simplify the place where the revision_number comparison\nwill happen (at the higher level method).\n\nTwo methods are no longer needed and have been removed:\n\n* get_subnet_and_ports_dhcp_options\n* compose_dhcp_options_commands\n\n[0] https://review.openstack.org/#/c/490834/\n\nChange-Id: Ie930fc448d65545ed1a39d15a55c6ead563095e5\n'}]",4,526445,7f8fe077984d75ea596f04b4e181a5c6b76cd022,20,4,2,6773,,,0,"Refactor subnet dhcp options methods

This patch is refactoring some the subnet dhcp options methods to make
it simpler to implement the database sync work [0].

The get_subnet_dhcp_options() method has extended to also be able to
return the dhcp options referent to the ports with a new
``with_ports`` parameter.

The return value of the get_subnet_dhcp_options() also changed to a
dictionary containing two keys: ``subnet`` and ``ports`` where each
value is the DHCP_Options referent to those resources.

On the update_subnets() method, start the transction on the higher level
method and have the helper methods to just add the OVSDB commands to it.
This sill later simplify the place where the revision_number comparison
will happen (at the higher level method).

Two methods are no longer needed and have been removed:

* get_subnet_and_ports_dhcp_options
* compose_dhcp_options_commands

[0] https://review.openstack.org/#/c/490834/

Change-Id: Ie930fc448d65545ed1a39d15a55c6ead563095e5
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/45/526445/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/tests/functional/test_ovn_db_sync.py', 'networking_ovn/tests/functional/test_ovn_db_resources.py', 'networking_ovn/tests/unit/ovsdb/test_impl_idl_ovn.py', 'networking_ovn/tests/unit/fakes.py']",8,5357629dec6df08cf9c4896d74acbfbbe9a92bf8,subnet-transaction," self.get_subnet_dhcp_options.return_value = { 'subnet': None, 'ports': []}", self.get_subnet_dhcp_options.return_value = {} self.get_subnet_and_ports_dhcp_options = mock.Mock() self.get_subnet_and_ports_dhcp_options.return_value = [] self.compose_dhcp_options_commands = mock.MagicMock(),163,204
openstack%2Fblazar~master~I4305ead55995ca04aeae34c4c489e4865391f8a1,openstack/blazar,master,I4305ead55995ca04aeae34c4c489e4865391f8a1,Move wsgi app class to api directory,MERGED,2017-11-20 06:00:02.000000000,2017-12-12 23:54:34.000000000,2017-12-12 23:54:34.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-11-20 06:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/1a01f17ff9eaccef19dbafbe3610a290af448959', 'message': ""Move wsgi app class to common directory\n\nThis commit divides wsgi application class from cmd/api.py to\ncommon/app.py. This bp enables admins to deploy blazar-api via WSGI.\nIt's good to place the class outside of cmd directory.\n\nPatially Implements: blueprint deploy-api-in-wsgi\n\nChange-Id: I4305ead55995ca04aeae34c4c489e4865391f8a1\n""}, {'number': 2, 'created': '2017-12-04 07:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/34a25e3d1a9b71a25775c29a92db1852e909a81b', 'message': ""Move wsgi app class to api directory\n\nThis commit divides wsgi application class from cmd/api.py to\napi/app.py. This bp enables admins to deploy blazar-api via WSGI.\nIt's good to place the class outside of cmd directory.\n\nPatially Implements: blueprint deploy-api-in-wsgi\n\nChange-Id: I4305ead55995ca04aeae34c4c489e4865391f8a1\n""}, {'number': 3, 'created': '2017-12-05 10:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/3fe9947a6884748b2c6c782eb7f745b1903c423f', 'message': 'Move wsgi app class to api directory\n\nThis commit divides wsgi application class from cmd/api.py to\napi/app.py. This enables admins to deploy blazar-api via WSGI.\nIt is good to place the class outside of the cmd directory.\n\nPartially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I4305ead55995ca04aeae34c4c489e4865391f8a1\n'}, {'number': 4, 'created': '2017-12-12 11:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/520c5f451a7855cf9efe03d82d7fbe440af57ce9', 'message': 'Move wsgi app class to api directory\n\nThis commit divides wsgi application class from cmd/api.py to\napi/app.py. This enables admins to deploy blazar-api via WSGI.\nIt is good to place the class outside of the cmd directory.\n\nPartially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I4305ead55995ca04aeae34c4c489e4865391f8a1\n'}, {'number': 5, 'created': '2017-12-12 11:01:38.000000000', 'files': ['blazar/cmd/api.py', 'blazar/api/app.py', 'blazar/tests/api/test_version_selector.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/774b519342532acadb4429670b399376ac462a56', 'message': 'Move wsgi app class to api directory\n\nThis commit moves the wsgi application class from cmd/api.py to\napi/app.py. This enables admins to deploy blazar-api via WSGI. It is\ngood to place the class outside of the cmd directory.\n\nPartially Implements: blueprint deploy-api-in-wsgi\nChange-Id: I4305ead55995ca04aeae34c4c489e4865391f8a1\n'}]",2,521422,774b519342532acadb4429670b399376ac462a56,24,4,5,8878,,,0,"Move wsgi app class to api directory

This commit moves the wsgi application class from cmd/api.py to
api/app.py. This enables admins to deploy blazar-api via WSGI. It is
good to place the class outside of the cmd directory.

Partially Implements: blueprint deploy-api-in-wsgi
Change-Id: I4305ead55995ca04aeae34c4c489e4865391f8a1
",git fetch https://review.opendev.org/openstack/blazar refs/changes/22/521422/4 && git format-patch -1 --stdout FETCH_HEAD,"['blazar/common/app.py', 'blazar/cmd/api.py', 'blazar/tests/api/test_version_selector.py', 'blazar/common/__init__.py']",4,1a01f17ff9eaccef19dbafbe3610a290af448959,goal-deploy-api-in-wsgi,,,62,44
openstack%2Fopenstack-ansible~stable%2Fnewton~If8a213e2b2826f7d57fef812e7992d06b97fccfa,openstack/openstack-ansible,stable/newton,If8a213e2b2826f7d57fef812e7992d06b97fccfa,Bump roles SHA,ABANDONED,2017-12-07 16:05:50.000000000,2017-12-12 23:54:24.000000000,,"[{'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 16:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/09da8663af4b6006624c3228e70810281012bcd9', 'message': ""Bump roles SHA\n\nThis patch updates the keystone role to its latest available stable SHA's.\n\nThis update is done out of the release cycle to pull down stability\nfixes within the roles. The change is required to ensure we're\nnot being faced with pyldap breakage when building dependencies.\n\nThis PR also aggregates the new release notes from the updated roles.\n\nChange-Id: If8a213e2b2826f7d57fef812e7992d06b97fccfa\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 2, 'created': '2017-12-07 16:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7983d1eacde8de551ba9ffa9dd10647058aa138e', 'message': ""Bump roles SHA\n\nThis patch updates the keystone role to its latest available stable SHA's.\n\nThis update is done out of the release cycle to pull down stability\nfixes within the roles. The change is required to ensure we're\nnot being faced with pyldap breakage when building dependencies.\n\nThis PR also aggregates the new release notes from the updated roles.\n\nChange-Id: If8a213e2b2826f7d57fef812e7992d06b97fccfa\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 3, 'created': '2017-12-07 16:08:08.000000000', 'files': ['ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4288644c14eebe1fd0cc1e5050acceb165f7cf27', 'message': 'Bump roles SHA\n\nThis update is done out of the release cycle to pull down stability\nfixes within the roles. \n\nChange-Id: If8a213e2b2826f7d57fef812e7992d06b97fccfa\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,526441,4288644c14eebe1fd0cc1e5050acceb165f7cf27,8,3,3,7353,,,0,"Bump roles SHA

This update is done out of the release cycle to pull down stability
fixes within the roles. 

Change-Id: If8a213e2b2826f7d57fef812e7992d06b97fccfa
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/41/526441/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/inventory/group_vars/all.yml', 'ansible-role-requirements.yml']",2,09da8663af4b6006624c3228e70810281012bcd9,bug/1736241, version: bc7f4ab3d5dbc49c135bc00d4fc3d27374b56bea- name: openstack-ansible-security scm: git src: https://git.openstack.org/openstack/openstack-ansible-security version: e9e425247ec00b8b2613560c84bdb8404900029c version: 9f68a396abc8a0ecc7bc7dc1f360ec9afabaa452 version: 5dc386dd14ebf52c766cbb92ad30f0392840b0a4 version: 77e2a2547bd403565ce6581696b1db88fc6d1692 version: d3a4f1d1f1d3ab9437c8705e6c9dbc115de8da48, version: fb8b357a0ca29d241d6d14a8dcc64707eeba55d4 version: cd1b71a3a1185e1d19c85f033f732281e1cd5afb version: 87778470bd20dca457d397923fb3af64608222bb version: 16bb9734888476189bb1fa98751d29632490c0c8 version: 776bb05646e151a9019dd252bfdfa25862a81e0c,10,5
openstack%2Fpatrole~master~I82eb09c719583572573a490162383d15e78235c3,openstack/patrole,master,I82eb09c719583572573a490162383d15e78235c3,Complete coverage for volume transfers policies,MERGED,2017-12-09 04:56:41.000000000,2017-12-12 23:52:12.000000000,2017-12-12 23:52:12.000000000,"[{'_account_id': 17896}, {'_account_id': 22348}, {'_account_id': 23185}]","[{'number': 1, 'created': '2017-12-09 04:56:41.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_volume_transfers_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/087c010776a3f3a98d7d95c95d17645fa9d68fb7', 'message': 'Complete coverage for volume transfers policies\n\nThis PS adds the last endpoint which enforces ""volume:get_all_transfers"":\n\'/os-volume-transfer/detail\' [0].\n\n[0] https://github.com/openstack/cinder/blob/4ca4f644008f4c89edc472cacda19050367ba54a/cinder/policies/volume_transfer.py#L40\n\nChange-Id: I82eb09c719583572573a490162383d15e78235c3\n'}]",0,526820,087c010776a3f3a98d7d95c95d17645fa9d68fb7,7,3,1,23186,,,0,"Complete coverage for volume transfers policies

This PS adds the last endpoint which enforces ""volume:get_all_transfers"":
'/os-volume-transfer/detail' [0].

[0] https://github.com/openstack/cinder/blob/4ca4f644008f4c89edc472cacda19050367ba54a/cinder/policies/volume_transfer.py#L40

Change-Id: I82eb09c719583572573a490162383d15e78235c3
",git fetch https://review.opendev.org/openstack/patrole refs/changes/20/526820/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_volume_transfers_rbac.py'],1,087c010776a3f3a98d7d95c95d17645fa9d68fb7,transfer-volume-test," @decorators.idempotent_id('e84e45b0-9872-40bf-bf44-971266161a86') @rbac_rule_validation.action(service=""cinder"", rule=""volume:get_all_transfers"") def test_list_volume_transfers_details(self): with self.rbac_utils.override_role(self): self.transfers_client.list_volume_transfers(detail=True) ",,7,0
openstack%2Fnova~master~I93deeb6dfba523900a491843704e353582ce1426,openstack/nova,master,I93deeb6dfba523900a491843704e353582ce1426,Remove the Pike migration code for flavor migration,ABANDONED,2017-08-16 13:34:39.000000000,2017-12-12 23:46:31.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-08-16 13:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be338d8dd0e28f71c3a38450e1a6ff7a9bda4134', 'message': ""Remove the Pike migration code for flavor migration\n\nCode was added to the Pike release to migrate the flavor of any\nIronic instances to include the node's resource_class in its\nextra_specs. In Queens the resource_class will be required in all Ironic\nflavors, so this code will no longer be needed.\n\nBlueprint: custom-resource-classes-in-flavors\n\nChange-Id: I93deeb6dfba523900a491843704e353582ce1426\n""}, {'number': 2, 'created': '2017-10-19 15:49:49.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0067ec1e7d2049a139a7179cafebb6c9d54cb0a2', 'message': ""Remove the Pike migration code for flavor migration\n\nCode was added to the Pike release to migrate the flavor of any\nIronic instances to include the node's resource_class in its\nextra_specs. In Queens the resource_class will be required in all Ironic\nflavors, so this code will no longer be needed.\n\nBlueprint: custom-resource-classes-in-flavors\n\nChange-Id: I93deeb6dfba523900a491843704e353582ce1426\n""}]",0,494206,0067ec1e7d2049a139a7179cafebb6c9d54cb0a2,35,18,2,1063,,,0,"Remove the Pike migration code for flavor migration

Code was added to the Pike release to migrate the flavor of any
Ironic instances to include the node's resource_class in its
extra_specs. In Queens the resource_class will be required in all Ironic
flavors, so this code will no longer be needed.

Blueprint: custom-resource-classes-in-flavors

Change-Id: I93deeb6dfba523900a491843704e353582ce1426
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/494206/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py']",2,be338d8dd0e28f71c3a38450e1a6ff7a9bda4134,bp/custom-resource-classes-in-flavors,,"from tooz import hashring as hash_ring from nova.api.metadata import base as instance_metadatafrom nova.console import type as console_typefrom nova.tests import fixturesfrom nova.tests.unit import matchers as nova_matchers class IronicDriverSyncTestCase(IronicDriverTestCase): def setUp(self): super(IronicDriverSyncTestCase, self).setUp() self.driver.node_cache = {} # Since the code we're testing runs in a spawn_n green thread, ensure # that the thread completes. self.useFixture(fixtures.SpawnIsSynchronousFixture()) @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(objects.Instance, 'save') def test_pike_flavor_migration(self, mock_save, mock_get_by_uuid, mock_get_uuids_by_host, mock_svc_by_hv, mock_get_node_list): node1_uuid = uuidutils.generate_uuid() node2_uuid = uuidutils.generate_uuid() hostname = ""ironic-compute"" fake_flavor1 = objects.Flavor() fake_flavor1.extra_specs = {} fake_flavor2 = objects.Flavor() fake_flavor2.extra_specs = {} inst1 = fake_instance.fake_instance_obj(self.ctx, node=node1_uuid, host=hostname, flavor=fake_flavor1) inst2 = fake_instance.fake_instance_obj(self.ctx, node=node2_uuid, host=hostname, flavor=fake_flavor2) node1 = ironic_utils.get_test_node(uuid=node1_uuid, instance_uuid=inst1.uuid, instance_type_id=1, resource_class=""first"", network_interface=""flat"") node2 = ironic_utils.get_test_node(uuid=node2_uuid, instance_uuid=inst2.uuid, instance_type_id=2, resource_class=""second"", network_interface=""flat"") inst_dict = {inst1.uuid: inst1, inst2.uuid: inst2} mock_get_uuids_by_host.return_value = [inst1.uuid, inst2.uuid] mock_svc_by_hv.return_value = [] self.driver.node_cache = {} mock_get_node_list.return_value = [node1, node2] def fake_inst_by_uuid(ctx, uuid, expected_attrs=None): return inst_dict.get(uuid) mock_get_by_uuid.side_effect = fake_inst_by_uuid self.assertEqual({}, inst1.flavor.extra_specs) self.assertEqual({}, inst2.flavor.extra_specs) self.driver._refresh_cache() self.assertEqual(2, mock_save.call_count) expected_specs = {""resources:CUSTOM_FIRST"": ""1""} self.assertEqual(expected_specs, inst1.flavor.extra_specs) expected_specs = {""resources:CUSTOM_SECOND"": ""1""} self.assertEqual(expected_specs, inst2.flavor.extra_specs) @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(objects.Instance, 'save') def test_pike_flavor_migration_instance_migrated(self, mock_save, mock_get_by_uuid, mock_get_uuids_by_host, mock_svc_by_hv, mock_get_node_list): node1_uuid = uuidutils.generate_uuid() node2_uuid = uuidutils.generate_uuid() hostname = ""ironic-compute"" fake_flavor1 = objects.Flavor() fake_flavor1.extra_specs = {""resources:CUSTOM_FIRST"": ""1""} fake_flavor2 = objects.Flavor() fake_flavor2.extra_specs = {} inst1 = fake_instance.fake_instance_obj(self.ctx, node=node1_uuid, host=hostname, flavor=fake_flavor1) inst2 = fake_instance.fake_instance_obj(self.ctx, node=node2_uuid, host=hostname, flavor=fake_flavor2) node1 = ironic_utils.get_test_node(uuid=node1_uuid, instance_uuid=inst1.uuid, instance_type_id=1, resource_class=""first"", network_interface=""flat"") node2 = ironic_utils.get_test_node(uuid=node2_uuid, instance_uuid=inst2.uuid, instance_type_id=2, resource_class=""second"", network_interface=""flat"") inst_dict = {inst1.uuid: inst1, inst2.uuid: inst2} mock_get_uuids_by_host.return_value = [inst1.uuid, inst2.uuid] self.driver.node_cache = {} mock_get_node_list.return_value = [node1, node2] mock_svc_by_hv.return_value = [] def fake_inst_by_uuid(ctx, uuid, expected_attrs=None): return inst_dict.get(uuid) mock_get_by_uuid.side_effect = fake_inst_by_uuid self.driver._refresh_cache() # Since one instance already had its extra_specs updated with the # custom resource_class, only the other one should be updated and # saved. self.assertEqual(1, mock_save.call_count) expected_specs = {""resources:CUSTOM_FIRST"": ""1""} self.assertEqual(expected_specs, inst1.flavor.extra_specs) expected_specs = {""resources:CUSTOM_SECOND"": ""1""} self.assertEqual(expected_specs, inst2.flavor.extra_specs) @mock.patch.object(ironic_driver.LOG, 'warning') @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(objects.Instance, 'save') def test_pike_flavor_migration_missing_rc(self, mock_save, mock_get_by_uuid, mock_get_uuids_by_host, mock_svc_by_hv, mock_get_node_list, mock_warning): node1_uuid = uuidutils.generate_uuid() node2_uuid = uuidutils.generate_uuid() hostname = ""ironic-compute"" fake_flavor1 = objects.Flavor() fake_flavor1.extra_specs = {} fake_flavor2 = objects.Flavor() fake_flavor2.extra_specs = {} inst1 = fake_instance.fake_instance_obj(self.ctx, node=node1_uuid, host=hostname, flavor=fake_flavor1) inst2 = fake_instance.fake_instance_obj(self.ctx, node=node2_uuid, host=hostname, flavor=fake_flavor2) node1 = ironic_utils.get_test_node(uuid=node1_uuid, instance_uuid=inst1.uuid, instance_type_id=1, resource_class=None, network_interface=""flat"") node2 = ironic_utils.get_test_node(uuid=node2_uuid, instance_uuid=inst2.uuid, instance_type_id=2, resource_class=""second"", network_interface=""flat"") inst_dict = {inst1.uuid: inst1, inst2.uuid: inst2} mock_get_uuids_by_host.return_value = [inst1.uuid, inst2.uuid] mock_svc_by_hv.return_value = [] self.driver.node_cache = {} mock_get_node_list.return_value = [node1, node2] def fake_inst_by_uuid(ctx, uuid, expected_attrs=None): return inst_dict.get(uuid) mock_get_by_uuid.side_effect = fake_inst_by_uuid self.driver._refresh_cache() # Since one instance was on a node with no resource class set, # only the other one should be updated and saved. self.assertEqual(1, mock_save.call_count) expected_specs = {} self.assertEqual(expected_specs, inst1.flavor.extra_specs) expected_specs = {""resources:CUSTOM_SECOND"": ""1""} self.assertEqual(expected_specs, inst2.flavor.extra_specs) # Verify that the LOG.warning was called correctly self.assertEqual(1, mock_warning.call_count) self.assertIn(""does not have its resource_class set."", mock_warning.call_args[0][0]) self.assertEqual({""node"": node1.uuid}, mock_warning.call_args[0][1]) @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(objects.Instance, 'save') def test_pike_flavor_migration_refresh_called_again(self, mock_save, mock_get_by_uuid, mock_get_uuids_by_host, mock_svc_by_hv, mock_get_node_list): node1_uuid = uuidutils.generate_uuid() node2_uuid = uuidutils.generate_uuid() hostname = ""ironic-compute"" fake_flavor1 = objects.Flavor() fake_flavor1.extra_specs = {} fake_flavor2 = objects.Flavor() fake_flavor2.extra_specs = {} inst1 = fake_instance.fake_instance_obj(self.ctx, node=node1_uuid, host=hostname, flavor=fake_flavor1) inst2 = fake_instance.fake_instance_obj(self.ctx, node=node2_uuid, host=hostname, flavor=fake_flavor2) node1 = ironic_utils.get_test_node(uuid=node1_uuid, instance_uuid=inst1.uuid, instance_type_id=1, resource_class=""first"", network_interface=""flat"") node2 = ironic_utils.get_test_node(uuid=node2_uuid, instance_uuid=inst2.uuid, instance_type_id=2, resource_class=""second"", network_interface=""flat"") inst_dict = {inst1.uuid: inst1, inst2.uuid: inst2} mock_get_uuids_by_host.return_value = [inst1.uuid, inst2.uuid] mock_svc_by_hv.return_value = [] self.driver.node_cache = {} mock_get_node_list.return_value = [node1, node2] def fake_inst_by_uuid(ctx, uuid, expected_attrs=None): return inst_dict.get(uuid) mock_get_by_uuid.side_effect = fake_inst_by_uuid self.driver._refresh_cache() self.assertEqual(2, mock_get_by_uuid.call_count) # Refresh the cache again. The mock for getting an instance by uuid # should not be called again. mock_get_by_uuid.reset_mock() self.driver._refresh_cache() mock_get_by_uuid.assert_not_called() @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(objects.Instance, 'save') def test_pike_flavor_migration_no_node_change(self, mock_save, mock_get_by_uuid, mock_get_uuids_by_host, mock_svc_by_hv, mock_get_node_list): node1_uuid = uuidutils.generate_uuid() node2_uuid = uuidutils.generate_uuid() hostname = ""ironic-compute"" fake_flavor1 = objects.Flavor() fake_flavor1.extra_specs = {""resources:CUSTOM_FIRST"": ""1""} fake_flavor2 = objects.Flavor() fake_flavor2.extra_specs = {""resources:CUSTOM_SECOND"": ""1""} inst1 = fake_instance.fake_instance_obj(self.ctx, node=node1_uuid, host=hostname, flavor=fake_flavor1) inst2 = fake_instance.fake_instance_obj(self.ctx, node=node2_uuid, host=hostname, flavor=fake_flavor2) node1 = ironic_utils.get_test_node(uuid=node1_uuid, instance_uuid=inst1.uuid, instance_type_id=1, resource_class=""first"", network_interface=""flat"") node2 = ironic_utils.get_test_node(uuid=node2_uuid, instance_uuid=inst2.uuid, instance_type_id=2, resource_class=""second"", network_interface=""flat"") inst_dict = {inst1.uuid: inst1, inst2.uuid: inst2} mock_get_uuids_by_host.return_value = [inst1.uuid, inst2.uuid] self.driver.node_cache = {node1_uuid: node1, node2_uuid: node2} self.driver._migrated_instance_uuids = set([inst1.uuid, inst2.uuid]) mock_get_node_list.return_value = [node1, node2] mock_svc_by_hv.return_value = [] def fake_inst_by_uuid(ctx, uuid, expected_attrs=None): return inst_dict.get(uuid) mock_get_by_uuid.side_effect = fake_inst_by_uuid self.driver._refresh_cache() # Since the nodes did not change in the call to _refresh_cache(), and # their instance_uuids were in the cache, none of the mocks in the # migration script should have been called. self.assertFalse(mock_get_by_uuid.called) self.assertFalse(mock_save.called) @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') @mock.patch.object(objects.Instance, 'get_by_uuid') @mock.patch.object(objects.Instance, 'save') def test_pike_flavor_migration_just_instance_change(self, mock_save, mock_get_by_uuid, mock_get_uuids_by_host, mock_svc_by_hv, mock_get_node_list): node1_uuid = uuidutils.generate_uuid() node2_uuid = uuidutils.generate_uuid() node3_uuid = uuidutils.generate_uuid() hostname = ""ironic-compute"" fake_flavor1 = objects.Flavor() fake_flavor1.extra_specs = {} fake_flavor2 = objects.Flavor() fake_flavor2.extra_specs = {} fake_flavor3 = objects.Flavor() fake_flavor3.extra_specs = {} inst1 = fake_instance.fake_instance_obj(self.ctx, node=node1_uuid, host=hostname, flavor=fake_flavor1) inst2 = fake_instance.fake_instance_obj(self.ctx, node=node2_uuid, host=hostname, flavor=fake_flavor2) inst3 = fake_instance.fake_instance_obj(self.ctx, node=node3_uuid, host=hostname, flavor=fake_flavor3) node1 = ironic_utils.get_test_node(uuid=node1_uuid, instance_uuid=inst1.uuid, instance_type_id=1, resource_class=""first"", network_interface=""flat"") node2 = ironic_utils.get_test_node(uuid=node2_uuid, instance_uuid=inst2.uuid, instance_type_id=2, resource_class=""second"", network_interface=""flat"") inst_dict = {inst1.uuid: inst1, inst2.uuid: inst2, inst3.uuid: inst3} mock_get_uuids_by_host.return_value = [inst1.uuid, inst2.uuid] self.driver.node_cache = {node1_uuid: node1, node2_uuid: node2} mock_get_node_list.return_value = [node1, node2] mock_svc_by_hv.return_value = [] def fake_inst_by_uuid(ctx, uuid, expected_attrs=None): return inst_dict.get(uuid) mock_get_by_uuid.side_effect = fake_inst_by_uuid self.driver._refresh_cache() # Since this is a fresh driver, neither will be in the migration cache, # so the migration mocks should have been called. self.assertTrue(mock_get_by_uuid.called) self.assertTrue(mock_save.called) # Now call _refresh_cache() again. Since neither the nodes nor their # instances change, none of the mocks in the migration script should # have been called. mock_get_by_uuid.reset_mock() mock_save.reset_mock() self.driver._refresh_cache() self.assertFalse(mock_get_by_uuid.called) self.assertFalse(mock_save.called) # Now change the node on node2 to inst3 node2.instance_uuid = inst3.uuid mock_get_uuids_by_host.return_value = [inst1.uuid, inst3.uuid] # Call _refresh_cache() again. Since the instance on node2 changed, the # migration mocks should have been called. mock_get_by_uuid.reset_mock() mock_save.reset_mock() self.driver._refresh_cache() self.assertTrue(mock_get_by_uuid.called) self.assertTrue(mock_save.called) @mock.patch.object(fields.ResourceClass, 'normalize_name') @mock.patch.object(ironic_driver.IronicDriver, '_node_from_cache') def test_pike_flavor_migration_empty_node(self, mock_node_from_cache, mock_normalize): mock_node_from_cache.return_value = None self.driver._pike_flavor_migration([uuids.node]) mock_normalize.assert_not_called() @mock.patch.object(fields.ResourceClass, 'normalize_name') @mock.patch.object(ironic_driver.IronicDriver, '_node_from_cache') def test_pike_flavor_migration_already_migrated(self, mock_node_from_cache, mock_normalize): node1 = ironic_utils.get_test_node(uuid=uuids.node1, instance_uuid=uuids.instance, instance_type_id=1, resource_class=""first"", network_interface=""flat"") mock_node_from_cache.return_value = node1 self.driver._migrated_instance_uuids = set([uuids.instance]) self.driver._pike_flavor_migration([uuids.node1]) mock_normalize.assert_not_called() @mock.patch.object(instance_metadata, 'InstanceMetadata') @mock.patch.object(configdrive, 'ConfigDriveBuilder') class IronicDriverGenerateConfigDriveTestCase(test.NoDBTestCase): @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(cw, 'IronicClientWrapper', lambda *_: FAKE_CLIENT_WRAPPER) def setUp(self, mock_services): super(IronicDriverGenerateConfigDriveTestCase, self).setUp() self.driver = ironic_driver.IronicDriver(None) self.driver.virtapi = fake.FakeVirtAPI() self.ctx = nova_context.get_admin_context() node_uuid = uuidutils.generate_uuid() self.node = ironic_utils.get_test_node(driver='fake', uuid=node_uuid) self.instance = fake_instance.fake_instance_obj(self.ctx, node=node_uuid) self.network_info = utils.get_test_network_info() def test_generate_configdrive(self, mock_cd_builder, mock_instance_meta): mock_instance_meta.return_value = 'fake-instance' mock_make_drive = mock.MagicMock(make_drive=lambda *_: None) mock_cd_builder.return_value.__enter__.return_value = mock_make_drive network_metadata_mock = mock.Mock() self.driver._get_network_metadata = network_metadata_mock self.driver._generate_configdrive(None, self.instance, self.node, self.network_info) mock_cd_builder.assert_called_once_with(instance_md='fake-instance') mock_instance_meta.assert_called_once_with( self.instance, content=None, extra_md={}, network_info=self.network_info, network_metadata=network_metadata_mock.return_value, request_context=None) def test_generate_configdrive_fail(self, mock_cd_builder, mock_instance_meta): mock_cd_builder.side_effect = exception.ConfigDriveMountFailed( operation='foo', error='error') mock_instance_meta.return_value = 'fake-instance' mock_make_drive = mock.MagicMock(make_drive=lambda *_: None) mock_cd_builder.return_value.__enter__.return_value = mock_make_drive network_metadata_mock = mock.Mock() self.driver._get_network_metadata = network_metadata_mock self.assertRaises(exception.ConfigDriveMountFailed, self.driver._generate_configdrive, None, self.instance, self.node, self.network_info) mock_cd_builder.assert_called_once_with(instance_md='fake-instance') mock_instance_meta.assert_called_once_with( self.instance, content=None, extra_md={}, network_info=self.network_info, network_metadata=network_metadata_mock.return_value, request_context=None) @mock.patch.object(FAKE_CLIENT.node, 'list_ports') @mock.patch.object(FAKE_CLIENT.portgroup, 'list') def _test_generate_network_metadata(self, mock_portgroups, mock_ports, address=None, vif_internal_info=True): internal_info = ({'tenant_vif_port_id': utils.FAKE_VIF_UUID} if vif_internal_info else {}) extra = ({'vif_port_id': utils.FAKE_VIF_UUID} if not vif_internal_info else {}) portgroup = ironic_utils.get_test_portgroup( node_uuid=self.node.uuid, address=address, extra=extra, internal_info=internal_info, properties={'bond_miimon': 100, 'xmit_hash_policy': 'layer3+4'} ) port1 = ironic_utils.get_test_port(uuid=uuidutils.generate_uuid(), node_uuid=self.node.uuid, address='00:00:00:00:00:01', portgroup_uuid=portgroup.uuid) port2 = ironic_utils.get_test_port(uuid=uuidutils.generate_uuid(), node_uuid=self.node.uuid, address='00:00:00:00:00:02', portgroup_uuid=portgroup.uuid) mock_ports.return_value = [port1, port2] mock_portgroups.return_value = [portgroup] metadata = self.driver._get_network_metadata(self.node, self.network_info) pg_vif = metadata['links'][0] self.assertEqual('bond', pg_vif['type']) self.assertEqual('active-backup', pg_vif['bond_mode']) self.assertEqual(address if address else utils.FAKE_VIF_MAC, pg_vif['ethernet_mac_address']) self.assertEqual('layer3+4', pg_vif['bond_xmit_hash_policy']) self.assertEqual(100, pg_vif['bond_miimon']) self.assertEqual([port1.uuid, port2.uuid], pg_vif['bond_links']) self.assertEqual([{'id': port1.uuid, 'type': 'phy', 'ethernet_mac_address': port1.address}, {'id': port2.uuid, 'type': 'phy', 'ethernet_mac_address': port2.address}], metadata['links'][1:]) # assert there are no duplicate links link_ids = [link['id'] for link in metadata['links']] self.assertEqual(len(set(link_ids)), len(link_ids), 'There are duplicate link IDs: %s' % link_ids) def test_generate_network_metadata_with_pg_address(self, mock_cd_builder, mock_instance_meta): self._test_generate_network_metadata(address='00:00:00:00:00:00') def test_generate_network_metadata_no_pg_address(self, mock_cd_builder, mock_instance_meta): self._test_generate_network_metadata() def test_generate_network_metadata_vif_in_extra(self, mock_cd_builder, mock_instance_meta): self._test_generate_network_metadata(vif_internal_info=False) @mock.patch.object(FAKE_CLIENT.node, 'list_ports') @mock.patch.object(FAKE_CLIENT.portgroup, 'list') def test_generate_network_metadata_ports_only(self, mock_portgroups, mock_ports, mock_cd_builder, mock_instance_meta): address = self.network_info[0]['address'] port = ironic_utils.get_test_port( node_uuid=self.node.uuid, address=address, internal_info={'tenant_vif_port_id': utils.FAKE_VIF_UUID}) mock_ports.return_value = [port] mock_portgroups.return_value = [] metadata = self.driver._get_network_metadata(self.node, self.network_info) self.assertEqual(port.address, metadata['links'][0]['ethernet_mac_address']) self.assertEqual('phy', metadata['links'][0]['type']) class HashRingTestCase(test.NoDBTestCase): @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') @mock.patch.object(servicegroup, 'API', autospec=True) def setUp(self, mock_sg, mock_services): super(HashRingTestCase, self).setUp() self.driver = ironic_driver.IronicDriver(None) self.driver.virtapi = fake.FakeVirtAPI() self.ctx = nova_context.get_admin_context() self.mock_is_up = ( self.driver.servicegroup_api.service_is_up) @mock.patch.object(ironic_driver.IronicDriver, '_refresh_hash_ring') def test_hash_ring_refreshed_on_init(self, mock_hr): ironic_driver.IronicDriver(None) mock_hr.assert_called_once_with(mock.ANY) @mock.patch.object(hash_ring, 'HashRing') @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') def _test__refresh_hash_ring(self, services, expected_hosts, mock_services, mock_hash_ring): services = [_make_compute_service(host) for host in services] is_up_calls = [mock.call(svc) for svc in services] self.flags(host='host1') mock_services.return_value = services mock_hash_ring.return_value = SENTINEL self.driver._refresh_hash_ring(self.ctx) mock_services.assert_called_once_with( mock.ANY, self.driver._get_hypervisor_type()) mock_hash_ring.assert_called_once_with(expected_hosts, partitions=32) self.assertEqual(SENTINEL, self.driver.hash_ring) self.mock_is_up.assert_has_calls(is_up_calls) def test__refresh_hash_ring_one_compute(self): services = ['host1'] expected_hosts = {'host1'} self.mock_is_up.return_value = True self._test__refresh_hash_ring(services, expected_hosts) def test__refresh_hash_ring_many_computes(self): services = ['host1', 'host2', 'host3'] expected_hosts = {'host1', 'host2', 'host3'} self.mock_is_up.return_value = True self._test__refresh_hash_ring(services, expected_hosts) def test__refresh_hash_ring_one_compute_new_compute(self): services = [] expected_hosts = {'host1'} self.mock_is_up.return_value = True self._test__refresh_hash_ring(services, expected_hosts) def test__refresh_hash_ring_many_computes_new_compute(self): services = ['host2', 'host3'] expected_hosts = {'host1', 'host2', 'host3'} self.mock_is_up.return_value = True self._test__refresh_hash_ring(services, expected_hosts) def test__refresh_hash_ring_some_computes_down(self): services = ['host1', 'host2', 'host3', 'host4'] expected_hosts = {'host1', 'host2', 'host4'} self.mock_is_up.side_effect = [True, True, False, True] self._test__refresh_hash_ring(services, expected_hosts) class NodeCacheTestCase(test.NoDBTestCase): @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') def setUp(self, mock_services): super(NodeCacheTestCase, self).setUp() self.driver = ironic_driver.IronicDriver(None) self.driver.virtapi = fake.FakeVirtAPI() self.ctx = nova_context.get_admin_context() self.host = 'host1' self.flags(host=self.host) @mock.patch.object(ironic_driver.IronicDriver, '_refresh_hash_ring') @mock.patch.object(hash_ring.HashRing, 'get_nodes') @mock.patch.object(ironic_driver.IronicDriver, '_get_node_list') @mock.patch.object(objects.InstanceList, 'get_uuids_by_host') def _test__refresh_cache(self, instances, nodes, hosts, mock_instances, mock_nodes, mock_hosts, mock_hash_ring): mock_instances.return_value = instances mock_nodes.return_value = nodes mock_hosts.side_effect = hosts self.driver.node_cache = {} self.driver.node_cache_time = None self.driver._refresh_cache() mock_hash_ring.assert_called_once_with(mock.ANY) mock_instances.assert_called_once_with(mock.ANY, self.host) mock_nodes.assert_called_once_with(detail=True, limit=0) self.assertIsNotNone(self.driver.node_cache_time) def test__refresh_cache(self): # normal operation, one compute service instances = [] nodes = [ ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ] hosts = [self.host, self.host, self.host] self._test__refresh_cache(instances, nodes, hosts) expected_cache = {n.uuid: n for n in nodes} self.assertEqual(expected_cache, self.driver.node_cache) def test__refresh_cache_multiple_services(self): # normal operation, many compute services instances = [] nodes = [ ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ] hosts = [self.host, 'host2', 'host3'] self._test__refresh_cache(instances, nodes, hosts) expected_cache = {n.uuid: n for n in nodes[0:1]} self.assertEqual(expected_cache, self.driver.node_cache) def test__refresh_cache_our_instances(self): # we should manage a node we have an instance for, even if it doesn't # map to us instances = [uuidutils.generate_uuid()] nodes = [ ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=instances[0]), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ] # only two calls, having the instance will short-circuit the first node hosts = [{self.host}, {self.host}] self._test__refresh_cache(instances, nodes, hosts) expected_cache = {n.uuid: n for n in nodes} self.assertEqual(expected_cache, self.driver.node_cache) def test__refresh_cache_their_instances(self): # we should never manage a node that another compute service has # an instance for, even if it maps to us instances = [] nodes = [ ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=uuidutils.generate_uuid()), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ironic_utils.get_test_node(uuid=uuidutils.generate_uuid(), instance_uuid=None), ] hosts = [self.host, self.host] # only two calls, having the instance will short-circuit the first node self._test__refresh_cache(instances, nodes, hosts) expected_cache = {n.uuid: n for n in nodes[1:]} self.assertEqual(expected_cache, self.driver.node_cache) @mock.patch.object(FAKE_CLIENT, 'node') class IronicDriverConsoleTestCase(test.NoDBTestCase): @mock.patch.object(cw, 'IronicClientWrapper', lambda *_: FAKE_CLIENT_WRAPPER) @mock.patch.object(objects.ServiceList, 'get_all_computes_by_hv_type') def setUp(self, mock_services): super(IronicDriverConsoleTestCase, self).setUp() self.driver = ironic_driver.IronicDriver(fake.FakeVirtAPI()) self.ctx = nova_context.get_admin_context() node_uuid = uuidutils.generate_uuid() self.node = ironic_utils.get_test_node(driver='fake', uuid=node_uuid) self.instance = fake_instance.fake_instance_obj(self.ctx, node=node_uuid) # mock retries configs to avoid sleeps and make tests run quicker CONF.set_default('api_max_retries', default=1, group='ironic') CONF.set_default('api_retry_interval', default=0, group='ironic') self.stub_out('nova.virt.ironic.driver.IronicDriver.' '_validate_instance_and_node', lambda _, inst: self.node) def _create_console_data(self, enabled=True, console_type='socat', url='tcp://127.0.0.1:10000'): return { 'console_enabled': enabled, 'console_info': { 'type': console_type, 'url': url } } def test__get_node_console_with_reset_success(self, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode']) def _fake_set_console_mode(node_uuid, mode): # Set it up so that _fake_get_console() returns 'mode' temp_data['target_mode'] = mode mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode expected = self._create_console_data()['console_info'] result = self.driver._get_node_console_with_reset(self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertEqual(self.node.uuid, result['node'].uuid) self.assertThat(result['console_info'], nova_matchers.DictMatches(expected)) @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test__get_node_console_with_reset_console_disabled(self, mock_log, mock_node): def _fake_log_debug(msg, *args, **kwargs): regex = r'Console is disabled for instance .*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.return_value = \ self._create_console_data(enabled=False) mock_log.debug.side_effect = _fake_log_debug self.assertRaises(exception.ConsoleNotAvailable, self.driver._get_node_console_with_reset, self.instance) mock_node.get_console.assert_called_once_with(self.node.uuid) mock_node.set_console_mode.assert_not_called() self.assertTrue(mock_log.debug.called) @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test__get_node_console_with_reset_set_mode_failed(self, mock_log, mock_node): def _fake_log_error(msg, *args, **kwargs): regex = r'Failed to set console mode .*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.return_value = self._create_console_data() mock_node.set_console_mode.side_effect = exception.NovaException() mock_log.error.side_effect = _fake_log_error self.assertRaises(exception.ConsoleNotAvailable, self.driver._get_node_console_with_reset, self.instance) mock_node.get_console.assert_called_once_with(self.node.uuid) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertTrue(mock_log.error.called) @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test__get_node_console_with_reset_wait_failed(self, mock_log, mock_node): def _fake_get_console(node_uuid): if mock_node.set_console_mode.called: # After the call to set_console_mode(), then _wait_state() # will call _get_console() to check the result. raise exception.NovaException() else: return self._create_console_data() def _fake_log_error(msg, *args, **kwargs): regex = r'Failed to acquire console information for instance .*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.side_effect = _fake_get_console mock_log.error.side_effect = _fake_log_error self.assertRaises(exception.ConsoleNotAvailable, self.driver._get_node_console_with_reset, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertTrue(mock_log.error.called) @mock.patch.object(ironic_driver, '_CONSOLE_STATE_CHECKING_INTERVAL', 0.05) @mock.patch.object(loopingcall, 'BackOffLoopingCall') @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test__get_node_console_with_reset_wait_timeout(self, mock_log, mock_looping, mock_node): CONF.set_override('serial_console_state_timeout', 1, group='ironic') temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode']) def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = not mode def _fake_log_error(msg, *args, **kwargs): regex = r'Timeout while waiting for console mode to be set .*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode mock_log.error.side_effect = _fake_log_error mock_timer = mock_looping.return_value mock_event = mock_timer.start.return_value mock_event.wait.side_effect = loopingcall.LoopingCallTimeOut self.assertRaises(exception.ConsoleNotAvailable, self.driver._get_node_console_with_reset, self.instance) self.assertEqual(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertTrue(mock_log.error.called) mock_timer.start.assert_called_with(starting_interval=0.05, timeout=1, jitter=0.5) def test_get_serial_console_socat(self, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode']) def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = mode mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode result = self.driver.get_serial_console(self.ctx, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertIsInstance(result, console_type.ConsoleSerial) self.assertEqual('127.0.0.1', result.host) self.assertEqual(10000, result.port) def test_get_serial_console_socat_disabled(self, mock_node): mock_node.get_console.return_value = \ self._create_console_data(enabled=False) self.assertRaises(exception.ConsoleTypeUnavailable, self.driver.get_serial_console, self.ctx, self.instance) mock_node.get_console.assert_called_once_with(self.node.uuid) mock_node.set_console_mode.assert_not_called() @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test_get_serial_console_socat_invalid_url(self, mock_log, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode'], url='an invalid url') def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = mode def _fake_log_error(msg, *args, **kwargs): regex = r'Invalid Socat console URL .*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode mock_log.error.side_effect = _fake_log_error self.assertRaises(exception.ConsoleTypeUnavailable, self.driver.get_serial_console, self.ctx, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertTrue(mock_log.error.called) @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test_get_serial_console_socat_invalid_url_2(self, mock_log, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode'], url='http://abcxyz:1a1b') def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = mode def _fake_log_error(msg, *args, **kwargs): regex = r'Invalid Socat console URL .*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode mock_log.error.side_effect = _fake_log_error self.assertRaises(exception.ConsoleTypeUnavailable, self.driver.get_serial_console, self.ctx, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertTrue(mock_log.error.called) @mock.patch.object(ironic_driver, 'LOG', autospec=True) def test_get_serial_console_socat_unsupported_scheme(self, mock_log, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode'], url='ssl://127.0.0.1:10000') def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = mode def _fake_log_warning(msg, *args, **kwargs): regex = r'Socat serial console only supports \""tcp\"".*' self.assertThat(msg, matchers.MatchesRegex(regex)) mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode mock_log.warning.side_effect = _fake_log_warning self.assertRaises(exception.ConsoleTypeUnavailable, self.driver.get_serial_console, self.ctx, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertTrue(mock_log.warning.called) def test_get_serial_console_socat_tcp6(self, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode'], url='tcp://[::1]:10000') def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = mode mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode result = self.driver.get_serial_console(self.ctx, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count) self.assertIsInstance(result, console_type.ConsoleSerial) self.assertEqual('::1', result.host) self.assertEqual(10000, result.port) def test_get_serial_console_shellinabox(self, mock_node): temp_data = {'target_mode': True} def _fake_get_console(node_uuid): return self._create_console_data(enabled=temp_data['target_mode'], console_type='shellinabox') def _fake_set_console_mode(node_uuid, mode): temp_data['target_mode'] = mode mock_node.get_console.side_effect = _fake_get_console mock_node.set_console_mode.side_effect = _fake_set_console_mode self.assertRaises(exception.ConsoleTypeUnavailable, self.driver.get_serial_console, self.ctx, self.instance) self.assertGreater(mock_node.get_console.call_count, 1) self.assertEqual(2, mock_node.set_console_mode.call_count)",0,1064
openstack%2Fnova~master~I6ca9aeba78f7d939a3921a368d36612f8ede44da,openstack/nova,master,I6ca9aeba78f7d939a3921a368d36612f8ede44da,Remove direct usage of glance.generate_image_url,MERGED,2017-10-12 06:42:31.000000000,2017-12-12 23:40:22.000000000,2017-12-12 23:40:22.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 27076}]","[{'number': 1, 'created': '2017-10-12 06:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/480b07a806321a7b86ce3807ecddab7f533f7283', 'message': 'Remove usage of glance.generate_image_url\n\nwe should use image.generate_image_url instead of\nglance.generate_image_url in nova side to consume image API\nthis patch changes the usage\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 2, 'created': '2017-10-12 07:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/801c0a2765ccf731ddc782975aa33c6a5aa740d0', 'message': 'Remove usage of glance.generate_image_url\n\nwe should use image.generate_image_url instead of\nglance.generate_image_url in nova side to consume image API\nthis patch changes the usage\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 3, 'created': '2017-10-12 07:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f031589c433e653632b11c65cd9a3cc81be92da', 'message': 'Remove usage of glance.generate_image_url\n\nwe should use image.generate_image_url instead of\nglance.generate_image_url in nova side to consume image API\nthis patch changes the usage\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 4, 'created': '2017-10-13 03:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9dd68c662735c61a134164f4da1e6fee06194adc', 'message': 'Remove usage of glance.generate_image_url\n\nwe should use image.generate_image_url instead of\nglance.generate_image_url in nova side to consume image API\nthis patch changes the usage\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 5, 'created': '2017-10-13 06:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f42fd145eecde0534ed95fc7a368aa5349f1020', 'message': 'Remove usage of glance.generate_image_url\n\nwe should use image.generate_image_url instead of\nglance.generate_image_url in nova side to consume image API\nthis patch changes the usage\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 6, 'created': '2017-10-19 02:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71f59a01bd9ca2949d7ac74cc4fac029cd1e1e22', 'message': 'Remove usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder directly usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 7, 'created': '2017-10-30 09:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd2c58deb75fdd31f57f6eff7147aec99358292d', 'message': 'Remove usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder directly usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 8, 'created': '2017-10-30 09:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a64d7e43872c7d4a6a2a7d85e9d69ea1a6286b47', 'message': 'Remove usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder directly usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 9, 'created': '2017-10-31 08:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b165c5f0d59e0fdbd33ffcdbd5ffdd20bd82df3', 'message': 'Remove direct usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder direct usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 10, 'created': '2017-11-01 09:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60cbed502d4f108e095da65a1ae57110fe5ecc12', 'message': 'Remove direct usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder direct usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 11, 'created': '2017-11-02 01:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffb08d6e4cd9710a83a9ee883300e7ffc02e53b2', 'message': 'Remove direct usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder direct usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 12, 'created': '2017-12-01 05:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27502dd4d2d31a56fdb8010eec55698ec1970564', 'message': 'Remove direct usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder direct usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 13, 'created': '2017-12-04 04:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38699da183e962fe0e8a751f7c0243033845d129', 'message': 'Remove direct usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder direct usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}, {'number': 14, 'created': '2017-12-06 05:35:50.000000000', 'files': ['nova/notifications/base.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/image/glance.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7833ada4fd8e42a773cb6849449708fcb20cbc0c', 'message': 'Remove direct usage of glance.generate_image_url\n\nwe abstract image (as well as volume etc) to image api and\nvolume api instead of glance and cinder direct usage, so\nin most nova code we should use image.generate_image_url instead of\nglance.generate_image_url. Thus we can utlize generic api of\nimage API instead of call glance client wrapper function directly.\n\nChange-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da\n'}]",12,511397,7833ada4fd8e42a773cb6849449708fcb20cbc0c,189,22,14,6062,,,0,"Remove direct usage of glance.generate_image_url

we abstract image (as well as volume etc) to image api and
volume api instead of glance and cinder direct usage, so
in most nova code we should use image.generate_image_url instead of
glance.generate_image_url. Thus we can utlize generic api of
image API instead of call glance client wrapper function directly.

Change-Id: I6ca9aeba78f7d939a3921a368d36612f8ede44da
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/511397/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/notifications/base.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/api/openstack/compute/servers.py']",4,480b07a806321a7b86ce3807ecddab7f533f7283,remove_glance_import_2,from nova import images self.image_api = image.API() image_ref = self.image_api.generate_image_url(image_id),from nova.image import glance image_ref = glance.generate_image_url(image_id),22,17
openstack%2Ftripleo-common~master~I05b173001a542df19abda0cb235a1cb839b9eb7d,openstack/tripleo-common,master,I05b173001a542df19abda0cb235a1cb839b9eb7d,Remove duplicate dictionary in zuul config,MERGED,2017-12-11 18:40:27.000000000,2017-12-12 23:37:24.000000000,2017-12-11 21:01:38.000000000,"[{'_account_id': 1}, {'_account_id': 3153}, {'_account_id': 5263}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 18:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fad779b55e144080d44153831e1d6c89def54b54', 'message': 'Remove duplicate dictionary in zuul config\n\nThe second jobs stanza was overwriting the first.  Unfortunately,\nthis is not detected by the YAML parser.\n\nChange-Id: I05b173001a542df19abda0cb235a1cb839b9eb7d\n'}, {'number': 2, 'created': '2017-12-11 18:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6742eabf468e9e31db3681d4f9752fa6207c6bb7', 'message': 'Remove duplicate dictionary in zuul config\n\nThe second jobs stanza was overwriting the first.  Unfortunately,\nthis is not detected by the YAML parser.\n\nChange-Id: I05b173001a542df19abda0cb235a1cb839b9eb7d\n'}, {'number': 3, 'created': '2017-12-11 18:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2aadfdddd0d8ef3678f4d21ccbebf031cc3c18b3', 'message': 'Remove duplicate dictionary in zuul config\n\nThe second jobs stanza was overwriting the first.  Unfortunately,\nthis is not detected by the YAML parser.\n\nChange-Id: I05b173001a542df19abda0cb235a1cb839b9eb7d\n'}, {'number': 4, 'created': '2017-12-11 18:47:13.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7f3e8df345bd8be9fbbf709658b5fe6d38e68692', 'message': 'Remove duplicate dictionary in zuul config\n\nThe second jobs stanza was overwriting the first.  Unfortunately,\nthis is not detected by the YAML parser.\n\nChange-Id: I05b173001a542df19abda0cb235a1cb839b9eb7d\n'}]",2,527208,7f3e8df345bd8be9fbbf709658b5fe6d38e68692,22,6,4,1,,,0,"Remove duplicate dictionary in zuul config

The second jobs stanza was overwriting the first.  Unfortunately,
this is not detected by the YAML parser.

Change-Id: I05b173001a542df19abda0cb235a1cb839b9eb7d
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/08/527208/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,fad779b55e144080d44153831e1d6c89def54b54,527208,, jobs: jobs:,0,2
openstack%2Fmonasca-ceilometer~stable%2Focata~Ie54cc051829cc2370cab9cd3a7d9542e2abc51ab,openstack/monasca-ceilometer,stable/ocata,Ie54cc051829cc2370cab9cd3a7d9542e2abc51ab,Using fixtures instead of deprecated mockpatch module,MERGED,2017-12-07 01:11:15.000000000,2017-12-12 23:30:22.000000000,2017-12-12 23:30:22.000000000,"[{'_account_id': 7052}, {'_account_id': 10311}, {'_account_id': 11580}, {'_account_id': 22255}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 01:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/91794e1badcf1e462978e1940ec1ee409c0cd2c5', 'message': 'Using fixtures instead of deprecated mockpatch module\n\nThis module mockpatch of oslotest[1] is deprecated since version 1.13\nand may be removed in version 2.0. Use fixtures.Mock* classes instead[2]\n\n[1]OpenStack Testing Framework and Utilities\n[2]https://docs.openstack.org/developer/oslotest/api/oslotest.mockpatch.html#module-oslotest.mockpatch\n\nChange-Id: Ie54cc051829cc2370cab9cd3a7d9542e2abc51ab\n'}, {'number': 2, 'created': '2017-12-08 23:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/d5e6568029486225b4075e8b61ce2b651e1edc11', 'message': 'Using fixtures instead of deprecated mockpatch module\n\nThis module mockpatch of oslotest[1] is deprecated since version 1.13\nand may be removed in version 2.0. Use fixtures.Mock* classes instead[2]\n\n[1]OpenStack Testing Framework and Utilities\n[2]https://docs.openstack.org/developer/oslotest/api/oslotest.mockpatch.html#module-oslotest.mockpatch\n\nChange-Id: Ie54cc051829cc2370cab9cd3a7d9542e2abc51ab\n'}, {'number': 3, 'created': '2017-12-12 00:16:05.000000000', 'files': ['ceilosca/ceilometer/tests/unit/ceilosca_mapping/test_ceilosca_mapping.py', 'ceilosca/ceilometer/tests/unit/ceilosca_mapping/test_static_ceilometer_mapping.py'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/a5ed7dfd6b9a55563311b606343a592b8a25b58c', 'message': 'Using fixtures instead of deprecated mockpatch module\n\nThis module mockpatch of oslotest[1] is deprecated since version 1.13\nand may be removed in version 2.0. Use fixtures.Mock* classes instead[2]\n\n[1]OpenStack Testing Framework and Utilities\n[2]https://docs.openstack.org/developer/oslotest/api/oslotest.mockpatch.html#module-oslotest.mockpatch\n\nChange-Id: Ie54cc051829cc2370cab9cd3a7d9542e2abc51ab\n'}]",0,526244,a5ed7dfd6b9a55563311b606343a592b8a25b58c,11,5,3,10311,,,0,"Using fixtures instead of deprecated mockpatch module

This module mockpatch of oslotest[1] is deprecated since version 1.13
and may be removed in version 2.0. Use fixtures.Mock* classes instead[2]

[1]OpenStack Testing Framework and Utilities
[2]https://docs.openstack.org/developer/oslotest/api/oslotest.mockpatch.html#module-oslotest.mockpatch

Change-Id: Ie54cc051829cc2370cab9cd3a7d9542e2abc51ab
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/44/526244/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilosca/ceilometer/tests/unit/ceilosca_mapping/test_ceilosca_mapping.py', 'ceilosca/ceilometer/tests/unit/ceilosca_mapping/test_static_ceilometer_mapping.py']",2,91794e1badcf1e462978e1940ec1ee409c0cd2c5,catch-up-to-newton,"import fixtures self.useFixture(fixtures.MockPatchObject(self.CONF, 'find_file', return_value=None))","from oslotest import mockpatch self.useFixture(mockpatch.PatchObject(self.CONF, 'find_file', return_value=None))",8,6
openstack%2Fkolla~master~I920394b8cb6eb7027df9110fe88de6842d2bd8b3,openstack/kolla,master,I920394b8cb6eb7027df9110fe88de6842d2bd8b3,Add heat dashboard to horizon image,MERGED,2017-12-11 05:59:22.000000000,2017-12-12 23:22:11.000000000,2017-12-12 23:22:11.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 17261}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 05:59:22.000000000', 'files': ['docker/horizon/Dockerfile.j2', 'docker/horizon/extend_start.sh', 'kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2ece1a513ae36dc4284e7d82f4e81f2137dde236', 'message': 'Add heat dashboard to horizon image\n\nheat dashboard is split from horizon code base in Queens cycle.[0][1]\n\n[0] https://review.openstack.org/#/c/523402/\n[1] https://github.com/openstack/heat-dashboard\n\nCloses-Bug: #1737475\nChange-Id: I920394b8cb6eb7027df9110fe88de6842d2bd8b3\n'}]",0,526986,2ece1a513ae36dc4284e7d82f4e81f2137dde236,16,7,1,7488,,,0,"Add heat dashboard to horizon image

heat dashboard is split from horizon code base in Queens cycle.[0][1]

[0] https://review.openstack.org/#/c/523402/
[1] https://github.com/openstack/heat-dashboard

Closes-Bug: #1737475
Change-Id: I920394b8cb6eb7027df9110fe88de6842d2bd8b3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/86/526986/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/horizon/Dockerfile.j2', 'docker/horizon/extend_start.sh', 'kolla/common/config.py']",3,2ece1a513ae36dc4284e7d82f4e81f2137dde236,bug/1737475," 'horizon-plugin-heat-dashboard': { 'type': 'url', 'location': ('$tarballs_base/heat-dashboard/' 'heat-dashboard-master.tar.gz')},",,15,2
openstack%2Fkolla~master~I8af4ae921ecca51a99886d5208abeb1a4eb42c83,openstack/kolla,master,I8af4ae921ecca51a99886d5208abeb1a4eb42c83,Add Dockerfile for networking-ovn-metadata-agent,MERGED,2017-10-11 12:47:00.000000000,2017-12-12 23:22:10.000000000,2017-12-12 23:22:10.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 6681}, {'_account_id': 8788}, {'_account_id': 10237}, {'_account_id': 11869}, {'_account_id': 13039}, {'_account_id': 19316}, {'_account_id': 20775}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 23825}, {'_account_id': 24072}, {'_account_id': 26553}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-10-11 12:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/80266f44b299e6d945a0afee1916ff0cb4096501', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 2, 'created': '2017-10-11 15:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7c115d1781cad20d58b74b540e3e8d196d9ff7de', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 3, 'created': '2017-10-11 15:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c16cf015c4c3abc7ee3d864961d1667d3fc4473f', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 4, 'created': '2017-10-13 11:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/aac770f2b1c503fecd3673dd747159c53b842531', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 5, 'created': '2017-10-13 11:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/87cee931f50c79ef51ecc3a6547cea368f7cae32', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 6, 'created': '2017-10-18 12:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6507a16dc62bc252890ae6f1c1f34a8d06925eb0', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 7, 'created': '2017-10-18 12:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/49512e8f088f608575be6bdb9e07fbaadb9495fc', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 8, 'created': '2017-11-02 13:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2a79cd926d4a2b08c02fba31d86828740c6050da', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 9, 'created': '2017-12-07 10:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f40abd988dc043f838223f08ff99b9cddcbda12f', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 10, 'created': '2017-12-07 16:05:41.000000000', 'files': ['docker/neutron/neutron-metadata-agent-ovn/Dockerfile.j2', 'releasenotes/notes/new_networking_ovn_metadata_agent_kolla_image-6f87ef59cf62cb8f.yaml', 'kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e24f02a706f6e812b6f6f15a1773ca2585e96838', 'message': 'Add Dockerfile for networking-ovn-metadata-agent\n\nThis patch adds a new Dockerfile for the metadata agent in\nnetworking-ovn so that we can have a Kolla image to be deployed in\nOVN containerized environments.\n\nChange-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}]",28,511225,e24f02a706f6e812b6f6f15a1773ca2585e96838,63,16,10,23804,,,0,"Add Dockerfile for networking-ovn-metadata-agent

This patch adds a new Dockerfile for the metadata agent in
networking-ovn so that we can have a Kolla image to be deployed in
OVN containerized environments.

Change-Id: I8af4ae921ecca51a99886d5208abeb1a4eb42c83
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/25/511225/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/neutron/neutron-metadata-agent-ovn/Dockerfile.j2'],1,80266f44b299e6d945a0afee1916ff0cb4096501,ovn-metadata-agent,"FROM {{ namespace }}/{{ image_prefix }}neutron-base:{{ tag }} LABEL maintainer=""{{ maintainer }}"" name=""{{ image_name }}"" build-date=""{{ build_date }}"" {% block neutron_metadata_agent_ovn_header %}{% endblock %} {% import ""macros.j2"" as macros with context %} {% if base_distro in ['centos', 'rhel'] %} {% if install_type == 'binary' %} {% set neutron_metadata_agent_ovn_packages = [ 'python-networking-ovn-metadata-agent' ] %} {% endif %} {% endif %} {{ macros.install_packages(neutron_metadata_agent_ovn_packages | customizable(""packages"")) }} {% block neutron_metadata_agent_ovn_footer %}{% endblock %} {% block footer %}{% endblock %} USER neutron ",,23,0
openstack%2Fkolla~stable%2Focata~Ifefb96bcbcc9c6840cf865f7786b43a43fae4c17,openstack/kolla,stable/ocata,Ifefb96bcbcc9c6840cf865f7786b43a43fae4c17,Improve gate post jobs,MERGED,2017-11-30 16:06:09.000000000,2017-12-12 23:04:48.000000000,2017-12-12 23:04:48.000000000,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 23825}, {'_account_id': 24072}]","[{'number': 1, 'created': '2017-11-30 16:06:09.000000000', 'files': ['tests/templates/kolla-build.conf.j2', '.zuul.yaml', 'tests/playbooks/publish.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/dd3413a0cc15b879337a55b7f638cbad11e996fa', 'message': 'Improve gate post jobs\n\n- Reuse build jobs to publish images\n- Add binary jobs in periodic pipeline\n- Push all image to dockerhub\n- Use branch name for image tag\n\nChange-Id: Ifefb96bcbcc9c6840cf865f7786b43a43fae4c17\n(cherry picked from commit 9846a27a6b453d4591979653d7ac0d52f7930fc7)\n(cherry picked from commit 5792277b8e38fdd8dbeed12f1d27b84d0808a8fa)\n'}]",0,524227,dd3413a0cc15b879337a55b7f638cbad11e996fa,15,5,1,7488,,,0,"Improve gate post jobs

- Reuse build jobs to publish images
- Add binary jobs in periodic pipeline
- Push all image to dockerhub
- Use branch name for image tag

Change-Id: Ifefb96bcbcc9c6840cf865f7786b43a43fae4c17
(cherry picked from commit 9846a27a6b453d4591979653d7ac0d52f7930fc7)
(cherry picked from commit 5792277b8e38fdd8dbeed12f1d27b84d0808a8fa)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/27/524227/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/templates/kolla-build.conf.j2', '.zuul.yaml', 'tests/playbooks/publish.yml']",3,dd3413a0cc15b879337a55b7f638cbad11e996fa,, when: - publisher when: - publisher,,64,40
openstack%2Fironic~master~I1160401ae21c761a300bd508e3ace1a3e5b67125,openstack/ironic,master,I1160401ae21c761a300bd508e3ace1a3e5b67125,WIP/DNM: Move ironic_tempest_plugin to new repo,ABANDONED,2017-01-24 22:12:07.000000000,2017-12-12 23:04:27.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-01-24 22:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a145b87f4715da0d20c6423045d75de14ea6f28e', 'message': 'WIP/DNR: Move ironic_tempest_plugin to a new repo\n\nChange-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125\nDepends-On: I54513211abc5281d1c23e71a79fa84c84605aa66\nDepends-On: If5bf0d38e163a494fbd7bf4c454b970cc8f1a091\n'}, {'number': 2, 'created': '2017-01-24 22:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d993a66ac0c123868644f9b7e16d5f8de935ea1', 'message': 'WIP/DNR: Move ironic_tempest_plugin to a new repo\n\nChange-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125\nDepends-On: I54513211abc5281d1c23e71a79fa84c84605aa66\nDepends-On: If5bf0d38e163a494fbd7bf4c454b970cc8f1a091\n'}, {'number': 3, 'created': '2017-01-31 22:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4b7301d04ed527f31627252b427f758663f9cfcd', 'message': 'WIP/DNM: Move ironic_tempest_plugin to new repo\n\nFirst dependent patch below is the change in openstack/devstack-gate\nto point to the new tempest repo and update the locat path. Second\none, points to latest patch in openstack/ironic-tempest-plugin, which\nis now synced up with openstack/ironic/ironic_tempest_plugin.\n\nDepends-On: I54513211abc5281d1c23e71a79fa84c84605aa66\nDepends-On: I249d55fe2ce3f3b51e21ad013f0bfb9c7834da5f\n\nChange-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125\n'}, {'number': 4, 'created': '2017-01-31 22:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0cd89d40852c17011b97bdefdf7735b0193668d5', 'message': 'WIP/DNM: Move ironic_tempest_plugin to new repo\n\nFirst dependent patch below is the change in openstack/devstack-gate\nto point to the new tempest repo and update the locat path. Second\none, points to latest patch in openstack/ironic-tempest-plugin, which\nis now synced up with openstack/ironic/ironic_tempest_plugin.\n\nDepends-On: I54513211abc5281d1c23e71a79fa84c84605aa66\nDepends-On: I249d55fe2ce3f3b51e21ad013f0bfb9c7834da5f\n\nChange-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125\n'}, {'number': 5, 'created': '2017-02-08 17:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6e663919f8c48fbfe1a68f66b7c151358991a6a1', 'message': 'WIP/DNM: Move ironic_tempest_plugin to new repo\n\nFirst dependent patch below is the change in openstack/devstack-gate\nto point to the new tempest repo and update the locat path. Second\none, points to latest patch in openstack/ironic-tempest-plugin, which\nis now synced up with openstack/ironic/ironic_tempest_plugin.\n\nDepends-On: I54513211abc5281d1c23e71a79fa84c84605aa66\nDepends-On: I249d55fe2ce3f3b51e21ad013f0bfb9c7834da5f\n\nChange-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125\n'}, {'number': 6, 'created': '2017-02-08 18:38:16.000000000', 'files': ['ironic_tempest_plugin/tests/scenario/baremetal_manager.py', 'ironic_tempest_plugin/services/__init__.py', 'ironic_tempest_plugin/tests/api/admin/__init__.py', 'ironic_tempest_plugin/tests/api/admin/api_microversion_fixture.py', 'ironic_tempest_plugin/__init__.py', 'ironic_tempest_plugin/services/baremetal/base.py', 'ironic_tempest_plugin/common/waiters.py', 'ironic_tempest_plugin/tests/api/admin/test_drivers.py', 'ironic_tempest_plugin/tests/api/admin/test_nodestates.py', 'ironic_tempest_plugin/common/__init__.py', 'ironic_tempest_plugin/config.py', 'ironic_tempest_plugin/tests/scenario/test_baremetal_basic_ops.py', 'ironic_tempest_plugin/plugin.py', 'ironic_tempest_plugin/tests/scenario/test_baremetal_multitenancy.py', 'ironic_tempest_plugin/README.rst', 'ironic_tempest_plugin/services/baremetal/v1/json/__init__.py', 'ironic_tempest_plugin/tests/api/__init__.py', 'doc/source/conf.py', 'ironic_tempest_plugin/tests/api/admin/test_api_discovery.py', 'ironic_tempest_plugin/services/baremetal/__init__.py', 'ironic_tempest_plugin/tests/api/admin/test_nodes.py', 'ironic_tempest_plugin/clients.py', 'ironic_tempest_plugin/tests/api/admin/test_ports_negative.py', 'ironic_tempest_plugin/services/baremetal/v1/__init__.py', 'ironic_tempest_plugin/services/baremetal/v1/json/baremetal_client.py', 'ironic_tempest_plugin/tests/api/admin/test_chassis.py', 'ironic_tempest_plugin/tests/__init__.py', 'ironic_tempest_plugin/tests/api/admin/test_ports.py', 'setup.cfg', 'ironic_tempest_plugin/tests/scenario/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c2f4734a54cd1e4f8cb4dd3c2c024216d449c03b', 'message': 'WIP/DNM: Move ironic_tempest_plugin to new repo\n\nFirst dependent patch below is the change in openstack/devstack-gate\nto point to the new tempest repo and update the locat path. Second\none, points to latest patch in openstack/ironic-tempest-plugin, which\nis now synced up with openstack/ironic/ironic_tempest_plugin.\n\nDepends-On: I54513211abc5281d1c23e71a79fa84c84605aa66\nDepends-On: Id9455779156147e9d3001985d8ab9a367095bcce\n\nChange-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125\n'}]",0,424874,c2f4734a54cd1e4f8cb4dd3c2c024216d449c03b,35,7,6,22860,,,0,"WIP/DNM: Move ironic_tempest_plugin to new repo

First dependent patch below is the change in openstack/devstack-gate
to point to the new tempest repo and update the locat path. Second
one, points to latest patch in openstack/ironic-tempest-plugin, which
is now synced up with openstack/ironic/ironic_tempest_plugin.

Depends-On: I54513211abc5281d1c23e71a79fa84c84605aa66
Depends-On: Id9455779156147e9d3001985d8ab9a367095bcce

Change-Id: I1160401ae21c761a300bd508e3ace1a3e5b67125
",git fetch https://review.opendev.org/openstack/ironic refs/changes/74/424874/4 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a145b87f4715da0d20c6423045d75de14ea6f28e,plugin-migration,, ironic_tempest_plugintempest.test_plugins = ironic_tests = ironic_tempest_plugin.plugin:IronicTempestPlugin ironic_tempest_plugin.*,0,5
openstack%2Foslo.serialization~master~I1bd306757a04e6c81b2717c656f71a9e6c9d0d32,openstack/oslo.serialization,master,I1bd306757a04e6c81b2717c656f71a9e6c9d0d32,Add bandit to pep8 job,MERGED,2017-12-07 05:56:19.000000000,2017-12-12 22:59:45.000000000,2017-12-12 22:59:45.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 05:56:19.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/019c7d574487db82271906651a69dfefec4ff45b', 'message': 'Add bandit to pep8 job\n\nAdd the bandit security scanner to the pep8 job.\n\nChange-Id: I1bd306757a04e6c81b2717c656f71a9e6c9d0d32\n'}]",0,526286,019c7d574487db82271906651a69dfefec4ff45b,6,2,1,9796,,,0,"Add bandit to pep8 job

Add the bandit security scanner to the pep8 job.

Change-Id: I1bd306757a04e6c81b2717c656f71a9e6c9d0d32
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/86/526286/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,019c7d574487db82271906651a69dfefec4ff45b,,deps = -r{toxinidir}/test-requirements.txt commands = flake8 # Run security linter bandit -r oslo_serialization tests -n5,commands = flake8,9,1
openstack%2Fosc-lib~master~Ife59ea35f5fad05173d3405718c9615ca97915fa,openstack/osc-lib,master,Ife59ea35f5fad05173d3405718c9615ca97915fa,Add utils for better column handling,MERGED,2017-11-24 20:00:38.000000000,2017-12-12 22:54:42.000000000,2017-12-12 22:54:42.000000000,"[{'_account_id': 841}, {'_account_id': 970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-24 20:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/5ee5f9709b9f2414ef9e373e7d0250da134f7637', 'message': 'Add utils for better column handling\n\nIn most OSC and plugin codes, we have column definitions for\nlist operations but some better way of column definitions helps\ndevelopers. This commit proposes some utility functions.\nWe can define column definitions in more meaningful way.\n\nIt also potentially helps us if we would like to show same\nfield names in the list and show operations. At now,\nthe list operation replaces API attribute names, but the show\noperation shows API attribute names without modification.\n\nA sample usage of these functions are found at:\nhttps://github.com/openstack/python-neutronclient/blob/master/neutronclient/osc/v2/fwaas/firewallgroup.py\n\nThis commit moves osc_lib/utils.py to a subdirectory.\nThe file is now a bit long and it would be nice if the module\nis split into meaningful pieces.\n\nChange-Id: Ife59ea35f5fad05173d3405718c9615ca97915fa\n'}, {'number': 2, 'created': '2017-11-24 22:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/35cd9165360b3fce6d5aa7d2b94a4e739a88802c', 'message': 'Add utils for better column handling\n\nIn most OSC and plugin codes, we have column definitions for\nlist operations but some better way of column definitions helps\ndevelopers. This commit proposes some utility functions.\nWe can define column definitions in more meaningful way.\n\nIt also potentially helps us if we would like to show same\nfield names in the list and show operations. At now,\nthe list operation replaces API attribute names, but the show\noperation shows API attribute names without modification.\n\nA sample usage of these functions are found at:\nhttps://github.com/openstack/python-neutronclient/blob/master/neutronclient/osc/v2/fwaas/firewallgroup.py\n\nThis commit moves osc_lib/utils.py to a subdirectory.\nThe file is now a bit long and it would be nice if the module\nis split into meaningful pieces.\n\nChange-Id: Ife59ea35f5fad05173d3405718c9615ca97915fa\n'}, {'number': 3, 'created': '2017-11-24 22:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/05b06d0a711465a25eaced1c5922ebf98a8a5971', 'message': 'Add utils for better column handling\n\nIn most OSC and plugin codes, we have column definitions for\nlist operations but some better way of column definitions helps\ndevelopers. This commit proposes some utility functions.\nWe can define column definitions in more meaningful way.\n\nIt also potentially helps us if we would like to show same\nfield names in the list and show operations. At now,\nthe list operation replaces API attribute names, but the show\noperation shows API attribute names without modification.\n\nA sample usage of these functions are found at:\nhttps://github.com/openstack/python-neutronclient/blob/master/neutronclient/osc/v2/fwaas/firewallgroup.py\n\nThis commit moves osc_lib/utils.py to a subdirectory.\nThe file is now a bit long and it would be nice if the module\nis split into meaningful pieces.\n\nChange-Id: Ife59ea35f5fad05173d3405718c9615ca97915fa\n'}, {'number': 4, 'created': '2017-12-12 13:44:40.000000000', 'files': ['osc_lib/utils/__init__.py', 'osc_lib/tests/test_utils.py', 'osc_lib/utils/columns.py'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/75700a7b4247773cf1f919b40e70ba89ba92bddb', 'message': 'Add utils for better column handling\n\nIn most OSC and plugin codes, we have column definitions for\nlist operations but some better way of column definitions helps\ndevelopers. This commit proposes some utility functions.\nWe can define column definitions in more meaningful way.\n\nIt also potentially helps us if we would like to show same\nfield names in the list and show operations. At now,\nthe list operation replaces API attribute names, but the show\noperation shows API attribute names without modification.\n\nA sample usage of these functions are found at:\nhttps://github.com/openstack/python-neutronclient/blob/master/neutronclient/osc/v2/fwaas/firewallgroup.py\n\nThis commit moves osc_lib/utils.py to a subdirectory.\nThe file is now a bit long and it would be nice if the module\nis split into meaningful pieces.\n\nChange-Id: Ife59ea35f5fad05173d3405718c9615ca97915fa\n'}]",0,522890,75700a7b4247773cf1f919b40e70ba89ba92bddb,15,3,4,841,,,0,"Add utils for better column handling

In most OSC and plugin codes, we have column definitions for
list operations but some better way of column definitions helps
developers. This commit proposes some utility functions.
We can define column definitions in more meaningful way.

It also potentially helps us if we would like to show same
field names in the list and show operations. At now,
the list operation replaces API attribute names, but the show
operation shows API attribute names without modification.

A sample usage of these functions are found at:
https://github.com/openstack/python-neutronclient/blob/master/neutronclient/osc/v2/fwaas/firewallgroup.py

This commit moves osc_lib/utils.py to a subdirectory.
The file is now a bit long and it would be nice if the module
is split into meaningful pieces.

Change-Id: Ife59ea35f5fad05173d3405718c9615ca97915fa
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/90/522890/2 && git format-patch -1 --stdout FETCH_HEAD,"['osc_lib/utils/__init__.py', 'osc_lib/tests/test_utils.py', 'osc_lib/utils/columns.py']",3,5ee5f9709b9f2414ef9e373e7d0250da134f7637,column-definitions,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import operator LIST_BOTH = 'both' LIST_SHORT_ONLY = 'short_only' LIST_LONG_ONLY = 'long_only' def get_column_definitions(attr_map, long_listing): """"""Return table headers and column names for a listing table. :param attr_map: a list of table entry definitions. Each entry should be a tuple consisting of (API attribute name, header name, listing mode). For example: (('id', 'ID', LIST_BOTH), ('name', 'Name', LIST_BOTH), ('tenant_id', 'Project', LIST_LONG_ONLY)) The third field of each tuple must be one of LIST_BOTH, LIST_LONG_ONLY (a corresponding column is shown only in a long mode), or LIST_SHORT_ONLY (a corresponding column is shown only in a short mode). :param long_listing: A boolean value which indicates a long listing or not. In most cases, parsed_args.long is passed to this argument. :return: A tuple of a list of table headers and a list of column names. """""" if long_listing: headers = [hdr for col, hdr, listing_mode in attr_map if listing_mode in (LIST_BOTH, LIST_LONG_ONLY)] columns = [col for col, hdr, listing_mode in attr_map if listing_mode in (LIST_BOTH, LIST_LONG_ONLY)] else: headers = [hdr for col, hdr, listing_mode in attr_map if listing_mode if listing_mode in (LIST_BOTH, LIST_SHORT_ONLY)] columns = [col for col, hdr, listing_mode in attr_map if listing_mode if listing_mode in (LIST_BOTH, LIST_SHORT_ONLY)] return headers, columns def get_columns(item, attr_map=None): """"""Return pair of resource attributes and corresponding display names. Assume the following item and attr_map are passed. item: {'id': 'myid', 'name': 'myname', 'foo': 'bar', 'tenant_id': 'mytenan'} attr_map: (('id', 'ID', LIST_BOTH), ('name', 'Name', LIST_BOTH), ('tenant_id', 'Project', LIST_LONG_ONLY)) This method returns: (('id', 'name', 'tenant_id', 'foo'), # attributes ('ID', 'Name', 'Project', 'foo') # display names Both tuples of attributes and display names are sorted by display names in the alphabetical order. Attributes not found in a given attr_map are kept as-is. :param item: a dictionary which represents a resource. Keys of the dictionary are expected to be attributes of the resource. Values are not referred to by this method. :param attr_map: a list of mapping from attribute to display name. The same format is used as for get_column_definitions attr_map. :return: A pair of tuple of attributes and tuple of display names. """""" attr_map = attr_map or tuple([]) _attr_map_dict = dict((col, hdr) for col, hdr, listing_mode in attr_map) columns = [(column, _attr_map_dict.get(column, column)) for column in item.keys()] columns = sorted(columns, key=operator.itemgetter(1)) return (tuple(col[0] for col in columns), tuple(col[1] for col in columns)) ",,129,0
openstack%2Fosc-lib~master~I2c497d851e51fbe32d4aa09876b415d92d15ce8f,openstack/osc-lib,master,I2c497d851e51fbe32d4aa09876b415d92d15ce8f,Updated from global requirements,MERGED,2017-12-05 03:27:14.000000000,2017-12-12 22:52:12.000000000,2017-12-12 22:52:12.000000000,"[{'_account_id': 970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 03:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/2890415fc4c47529f304b412e41ba8687a4c459d', 'message': 'Updated from global requirements\n\nChange-Id: I2c497d851e51fbe32d4aa09876b415d92d15ce8f\n'}, {'number': 2, 'created': '2017-12-10 07:37:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/5ef4081ea4be2a20ebad29058382caaaf819ae88', 'message': 'Updated from global requirements\n\nChange-Id: I2c497d851e51fbe32d4aa09876b415d92d15ce8f\n'}]",0,525389,5ef4081ea4be2a20ebad29058382caaaf819ae88,14,2,2,11131,,,0,"Updated from global requirements

Change-Id: I2c497d851e51fbe32d4aa09876b415d92d15ce8f
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/89/525389/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2890415fc4c47529f304b412e41ba8687a4c459d,openstack/requirements,keystoneauth1>=3.3.0 # Apache-2.0,keystoneauth1>=3.2.0 # Apache-2.0,1,1
openstack%2Freleases~master~Idf44a6b006f91e5d392e83a30377121df66858d5,openstack/releases,master,Idf44a6b006f91e5d392e83a30377121df66858d5,Release monasca-grafana-datasource 1.2.1,MERGED,2017-12-11 17:02:32.000000000,2017-12-12 22:51:07.000000000,2017-12-12 22:51:07.000000000,"[{'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 17:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/d5ecb3ba0f836bd93f1a89452bae4d196ec616b6', 'message': 'Release monasca-grafana-datasource 1.2.1\n\nChange-Id: Idf44a6b006f91e5d392e83a30377121df66858d5\n'}, {'number': 2, 'created': '2017-12-12 09:22:57.000000000', 'files': ['deliverables/_independent/monasca-grafana-datasource.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/0ed2e618ea28102313af16489d5ce267d904b9c6', 'message': 'Release monasca-grafana-datasource 1.2.1\n\nAdd release-type tag.\n\nChange-Id: Idf44a6b006f91e5d392e83a30377121df66858d5\n'}]",0,527167,0ed2e618ea28102313af16489d5ce267d904b9c6,14,4,2,16222,,,0,"Release monasca-grafana-datasource 1.2.1

Add release-type tag.

Change-Id: Idf44a6b006f91e5d392e83a30377121df66858d5
",git fetch https://review.opendev.org/openstack/releases refs/changes/67/527167/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/monasca-grafana-datasource.yaml'],1,d5ecb3ba0f836bd93f1a89452bae4d196ec616b6,527167, - projects: - hash: 7f0b8621cbd39341bd948ffd28e3beb5a4f12084 repo: openstack/monasca-grafana-datasource version: 1.2.1,,4,0
openstack%2Ftripleo-quickstart~master~I26ac71b1249c6b88d6a5f1f139a53e1ffef83ae2,openstack/tripleo-quickstart,master,I26ac71b1249c6b88d6a5f1f139a53e1ffef83ae2,Fix the tripleo-ui patchset used for ovb gating,MERGED,2017-12-11 10:51:51.000000000,2017-12-12 22:47:50.000000000,2017-12-12 22:47:50.000000000,"[{'_account_id': 8652}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-11 10:51:51.000000000', 'files': ['ci-scripts/full-deploy-ovb.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e2f81772df4f7023eaa9602e6bc22da4e424ff36', 'message': 'Fix the tripleo-ui patchset used for ovb gating\n\nThe change we use for testing package building on quickstart jobs were\nrebased, but this script still refers to patchset4, which does not build\nin our current CI. Updating the reference should fix that.\n\nChange-Id: I26ac71b1249c6b88d6a5f1f139a53e1ffef83ae2\n'}]",0,527057,e2f81772df4f7023eaa9602e6bc22da4e424ff36,19,7,1,8652,,,0,"Fix the tripleo-ui patchset used for ovb gating

The change we use for testing package building on quickstart jobs were
rebased, but this script still refers to patchset4, which does not build
in our current CI. Updating the reference should fix that.

Change-Id: I26ac71b1249c6b88d6a5f1f139a53e1ffef83ae2
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/57/527057/1 && git format-patch -1 --stdout FETCH_HEAD,['ci-scripts/full-deploy-ovb.sh'],1,e2f81772df4f7023eaa9602e6bc22da4e424ff36,fix-ovb, export ZUUL_CHANGES=openstack/tripleo-ui:master:refs/changes/25/422025/6, export ZUUL_CHANGES=openstack/tripleo-ui:master:refs/changes/25/422025/4,1,1
openstack%2Fpuppet-tripleo~master~I0a7cd7687feb2caa80e74329260ba3b063d223ee,openstack/puppet-tripleo,master,I0a7cd7687feb2caa80e74329260ba3b063d223ee,In compute IHA make no_shared_storage a class parameter,MERGED,2017-12-08 08:14:58.000000000,2017-12-12 22:47:49.000000000,2017-12-12 22:47:49.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-08 08:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/3d788fa3239412acac767b7958297303bb8dad27', 'message': 'In compute IHA make no_shared_storage a class parameter\n\nThis was suggested in I4d1908242e9513a225d2b1da06ed4ee769ee10f7\nand it makes the no_shared_storage a class parameter so it can\nbe parametrized more easily.\n\nChange-Id: I0a7cd7687feb2caa80e74329260ba3b063d223ee\n'}, {'number': 2, 'created': '2017-12-11 11:56:23.000000000', 'files': ['manifests/profile/base/pacemaker/instance_ha.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8247745c6f688bea7b5fc8b8835493cc75dd8e3d', 'message': 'In compute IHA make no_shared_storage a class parameter\n\nThis was suggested in I4d1908242e9513a225d2b1da06ed4ee769ee10f7\nand it makes the no_shared_storage a class parameter so it can\nbe parametrized more easily.\n\nChange-Id: I0a7cd7687feb2caa80e74329260ba3b063d223ee\n'}]",0,526619,8247745c6f688bea7b5fc8b8835493cc75dd8e3d,14,4,2,20172,,,0,"In compute IHA make no_shared_storage a class parameter

This was suggested in I4d1908242e9513a225d2b1da06ed4ee769ee10f7
and it makes the no_shared_storage a class parameter so it can
be parametrized more easily.

Change-Id: I0a7cd7687feb2caa80e74329260ba3b063d223ee
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/19/526619/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/pacemaker/instance_ha.pp'],1,3d788fa3239412acac767b7958297303bb8dad27,instanceha-storage-param," $no_shared_storage = hiera('tripleo::instanceha::no_shared_storage', true), if $no_shared_storage {"," if hiera('tripleo::instanceha::no_shared_storage', true) {",2,1
openstack%2Fpython-tripleoclient~master~Iff55d3b83ac4ad042a5b596c5b435877b588fe5c,openstack/python-tripleoclient,master,Iff55d3b83ac4ad042a5b596c5b435877b588fe5c,Remove dead code & variables,MERGED,2017-12-06 19:31:17.000000000,2017-12-12 22:47:49.000000000,2017-12-12 22:47:49.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 19:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d9a5c7d79ae4308875f2f47a45067aceddb2ee44', 'message': ""constants: remove SERVICE_LIST (unused)\n\nSERVICE_LIST is not used anywhere, let's drop it.\n\nChange-Id: Iff55d3b83ac4ad042a5b596c5b435877b588fe5c\n""}, {'number': 2, 'created': '2017-12-07 17:41:00.000000000', 'files': ['tripleoclient/constants.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f6e130da1db0bdf4c7aa21a14b4e54bced5be69a', 'message': ""Remove dead code & variables\n\n- SERVICE_LIST is not used anywhere, let's drop it.\n- Same for _get_password, _get_base_service_data and\n  _get_endpoint_data\n\nChange-Id: Iff55d3b83ac4ad042a5b596c5b435877b588fe5c\n""}]",0,526152,f6e130da1db0bdf4c7aa21a14b4e54bced5be69a,24,6,2,3153,,,0,"Remove dead code & variables

- SERVICE_LIST is not used anywhere, let's drop it.
- Same for _get_password, _get_base_service_data and
  _get_endpoint_data

Change-Id: Iff55d3b83ac4ad042a5b596c5b435877b588fe5c
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/52/526152/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/constants.py'],1,d9a5c7d79ae4308875f2f47a45067aceddb2ee44,cleanup,,"SERVICE_LIST = { 'aodh': {'password_field': 'AodhPassword'}, 'ceilometer': {'password_field': 'CeilometerPassword'}, 'cinder': {'password_field': 'CinderPassword'}, 'cinderv2': {'password_field': 'CinderPassword'}, 'glance': {'password_field': 'GlancePassword'}, 'gnocchi': {'password_field': 'GnocchiPassword'}, 'heat': {'password_field': 'HeatPassword'}, 'heatcfn': {}, 'ironic': {'password_field': 'IronicPassword'}, 'neutron': {'password_field': 'NeutronPassword'}, 'nova': {'password_field': 'NovaPassword'}, 'panko': {'password_field': 'PankoPassword'}, 'swift': {'password_field': 'SwiftPassword'}, 'sahara': {'password_field': 'SaharaPassword'}, 'trove': {'password_field': 'TrovePassword'}, } ",0,18
openstack%2Fpuppet-tripleo~master~Ia2d0a49567f51b8e6ecdf1967c515ef0dfe81567,openstack/puppet-tripleo,master,Ia2d0a49567f51b8e6ecdf1967c515ef0dfe81567,Allow vhost socket directory user/group as configurable from template,MERGED,2017-12-01 12:22:04.000000000,2017-12-12 22:47:48.000000000,2017-12-12 22:47:48.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-01 12:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/823629e2263e30f16d691f85a3e27339cb42963d', 'message': 'Allow vhost socket directory user/group as configurable from template\n\nFor ovs2.8 version, it is required to modify the vhost socket directory\npermissions as openvswitch:hugetlbfs instead of the earlier hardcoded\nvalues qemu:qemu. Making these values as input which could be configured\nfrom templates.\n\nChange-Id: Ia2d0a49567f51b8e6ecdf1967c515ef0dfe81567\n'}, {'number': 2, 'created': '2017-12-04 08:23:03.000000000', 'files': ['spec/classes/tripleo_profile_base_neutron_ovs_spec.rb', 'manifests/profile/base/neutron/ovs.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/361785f14d9965b0f81706dfbe3a01550a110b1a', 'message': 'Allow vhost socket directory user/group as configurable from template\n\nFor ovs2.8 version, it is required to modify the vhost socket directory\npermissions as openvswitch:hugetlbfs instead of the earlier hardcoded\nvalues qemu:qemu. Making these values as input which could be configured\nfrom templates.\n\nChange-Id: Ia2d0a49567f51b8e6ecdf1967c515ef0dfe81567\n'}]",0,524575,361785f14d9965b0f81706dfbe3a01550a110b1a,14,4,2,18575,,,0,"Allow vhost socket directory user/group as configurable from template

For ovs2.8 version, it is required to modify the vhost socket directory
permissions as openvswitch:hugetlbfs instead of the earlier hardcoded
values qemu:qemu. Making these values as input which could be configured
from templates.

Change-Id: Ia2d0a49567f51b8e6ecdf1967c515ef0dfe81567
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/75/524575/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/neutron/ovs.pp'],1,823629e2263e30f16d691f85a3e27339cb42963d,vhost_sock_dir_permission," $step = Integer(hiera('step')), $vhostuser_socket_dir = hiera('neutron::agents::ml2::ovs::vhostuser_socket_dir', undef), $vhostuser_socket_group = hiera('vhostuser_socket_group', 'qemu'), $vhostuser_socket_user = hiera('vhostuser_socket_user', 'qemu'), owner => $vhostuser_socket_user, group => $vhostuser_socket_group,"," $step = Integer(hiera('step')), $vhostuser_socket_dir = hiera('neutron::agents::ml2::ovs::vhostuser_socket_dir', undef) owner => 'qemu', group => 'qemu',",6,4
openstack%2Finstack-undercloud~stable%2Fpike~I65b906aaa7ea4f79e2c041009cf7055d2d1fe403,openstack/instack-undercloud,stable/pike,I65b906aaa7ea4f79e2c041009cf7055d2d1fe403,Run the swift object expirer in the undercloud,MERGED,2017-12-09 13:38:42.000000000,2017-12-12 22:47:47.000000000,2017-12-12 22:47:47.000000000,"[{'_account_id': 7385}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-09 13:38:42.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/397c1c56f49f95a7ac3b6f2f957f0fb7819be7f6', 'message': 'Run the swift object expirer in the undercloud\n\nThis includes the expirer module to enable the service, otherwise swift\nobjects are never cleaned up in the undercloud.\n\nChange-Id: I65b906aaa7ea4f79e2c041009cf7055d2d1fe403\nCloses-Bug: #1722279\n(cherry picked from commit 17e80bf88c97447209553a4f0d59cc1853607bd2)\n'}]",0,526845,397c1c56f49f95a7ac3b6f2f957f0fb7819be7f6,13,4,1,7385,,,0,"Run the swift object expirer in the undercloud

This includes the expirer module to enable the service, otherwise swift
objects are never cleaned up in the undercloud.

Change-Id: I65b906aaa7ea4f79e2c041009cf7055d2d1fe403
Closes-Bug: #1722279
(cherry picked from commit 17e80bf88c97447209553a4f0d59cc1853607bd2)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/45/526845/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,397c1c56f49f95a7ac3b6f2f957f0fb7819be7f6,bug/1722279-stable/pike,include ::swift::objectexpirer,,1,0
openstack%2Foctavia~master~Ia54864d4ad9a2621ddcf49b19766c44b68c18667,openstack/octavia,master,Ia54864d4ad9a2621ddcf49b19766c44b68c18667,Move loading the network driver into the flows,MERGED,2017-12-05 23:55:23.000000000,2017-12-12 22:46:02.000000000,2017-12-12 22:46:02.000000000,"[{'_account_id': 2245}, {'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 22348}, {'_account_id': 25239}]","[{'number': 1, 'created': '2017-12-05 23:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f0b46e78358007860b83e3f564968d4ba1248675', 'message': 'Move loading the network driver into the flows\n\nThis way if it fails at some stage, rollbacks will run correctly.\n\nChange-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667\n'}, {'number': 2, 'created': '2017-12-06 00:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/07241280d41ce232b9e82c5f2e345291f21f03c3', 'message': 'Move loading the network driver into the flows\n\nThis way if it fails at some stage, rollbacks will run correctly.\n\nChange-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667\n'}, {'number': 3, 'created': '2017-12-06 19:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b92060bd4673d33fceed4e5ea35dfb977534f285', 'message': 'Move loading the network driver into the flows\n\nThis way if it fails at some stage, rollbacks will run correctly.\nAlso adding some missing unit tests.\n\nChange-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667\n'}, {'number': 4, 'created': '2017-12-07 23:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/eea7d08269bc7485b679872f5f6b78fceb851515', 'message': 'Move loading the network driver into the flows\n\nThis way if it fails at some stage, rollbacks will run correctly.\nAlso adding some missing unit tests.\n\nChange-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667\n'}, {'number': 5, 'created': '2017-12-08 21:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/922805b890fc5f780d8ba08753a18eac18b57c6e', 'message': 'Move loading the network driver into the flows\n\nThis way if it fails at some stage, rollbacks will run correctly.\nAlso adding some missing unit tests.\n\nChange-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667\n'}, {'number': 6, 'created': '2017-12-11 22:09:41.000000000', 'files': ['octavia/tests/unit/network/drivers/neutron/test_base.py', 'octavia/controller/worker/tasks/network_tasks.py', 'octavia/tests/common/constants.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f46d992640595a918ccedb7c5fe4075686ada2e6', 'message': 'Move loading the network driver into the flows\n\nThis way if it fails at some stage, rollbacks will run correctly.\nAlso adding some missing unit tests.\n\nChange-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667\n'}]",10,525790,f46d992640595a918ccedb7c5fe4075686ada2e6,42,6,6,10273,,,0,"Move loading the network driver into the flows

This way if it fails at some stage, rollbacks will run correctly.
Also adding some missing unit tests.

Change-Id: Ia54864d4ad9a2621ddcf49b19766c44b68c18667
",git fetch https://review.opendev.org/openstack/octavia refs/changes/90/525790/4 && git format-patch -1 --stdout FETCH_HEAD,['octavia/controller/worker/tasks/network_tasks.py'],1,f0b46e78358007860b83e3f564968d4ba1248675,525790, network_driver = None if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver() if not self.network_driver: self.network_driver = utils.get_network_driver()," def __init__(self, **kwargs): super(BaseNetworkTask, self).__init__(**kwargs) self.network_driver = utils.get_network_driver()",45,7
openstack%2Fironic-lib~master~I775712a592bcdc01a6d0373d42971a8a53616112,openstack/ironic-lib,master,I775712a592bcdc01a6d0373d42971a8a53616112,tox: Use the default version of Python 3 for tox tests,MERGED,2017-12-11 15:30:10.000000000,2017-12-12 22:37:35.000000000,2017-12-12 22:37:35.000000000,"[{'_account_id': 6618}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 15:30:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/7e578f1570a35493d0699dff9b770cd4ad6c241c', 'message': 'tox: Use the default version of Python 3 for tox tests\n\nWhen running the tox tests, use the default version of Python 3. Instead\nof having to update the Python 3 version as we move from\n    py34 -> py35 -> py36 -> py37 -> py38\n\nJust use the default version of Python 3 on the system.\n\nThis will not affect what gets run in the gate, as the version is\nexplicitly specified when it runs there. This is for developers who run\nthe tests locally.\n\nChange-Id: I775712a592bcdc01a6d0373d42971a8a53616112\n'}]",0,527130,7e578f1570a35493d0699dff9b770cd4ad6c241c,7,3,1,14760,,,0,"tox: Use the default version of Python 3 for tox tests

When running the tox tests, use the default version of Python 3. Instead
of having to update the Python 3 version as we move from
    py34 -> py35 -> py36 -> py37 -> py38

Just use the default version of Python 3 on the system.

This will not affect what gets run in the gate, as the version is
explicitly specified when it runs there. This is for developers who run
the tests locally.

Change-Id: I775712a592bcdc01a6d0373d42971a8a53616112
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/30/527130/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7e578f1570a35493d0699dff9b770cd4ad6c241c,,"envlist = py3,py27,pep8","envlist = py35,py27,pep8",1,1
openstack%2Fironic-lib~stable%2Focata~I0534be1ff4ac4d3d2e40f282966683c7b60fc7ba,openstack/ironic-lib,stable/ocata,I0534be1ff4ac4d3d2e40f282966683c7b60fc7ba,zuul: Centralize irrelevant-files in legacy-ironic-lib-dsvm-base,MERGED,2017-11-21 19:54:36.000000000,2017-12-12 22:37:35.000000000,2017-12-12 22:37:34.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 14760}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-21 19:54:36.000000000', 'files': ['zuul.d/legacy-ironic-lib-jobs.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/ad8d213b61d94e4ec52e5ce59aeaeff3fb81c03c', 'message': ""zuul: Centralize irrelevant-files in legacy-ironic-lib-dsvm-base\n\nCreate a new base job: legacy-ironic-lib-dsvm-base\n\nDefine 'irrelevant-files' in legacy-ironic-lib-dsvm-base and remove\nthem from project.yaml. This means we only define 'irrelevant-files'\nonce. Also makes project.yaml much easier to read.\n\nFix the 'irrelevant-files' section to make sure we do test when\nchanges are made to 'requirements.txt'.\n\nSort the jobs lists in project.yaml.\n\nConflicts:\n  zuul.d/legacy-ironic-lib-jobs.yaml\n  zuul.d/project.yaml\n\nChange-Id: I0534be1ff4ac4d3d2e40f282966683c7b60fc7ba\n(cherry picked from commit bff1d93438a014bc7bf1d0d20753d90fa27a5019)\n""}]",0,521993,ad8d213b61d94e4ec52e5ce59aeaeff3fb81c03c,15,4,1,6618,,,0,"zuul: Centralize irrelevant-files in legacy-ironic-lib-dsvm-base

Create a new base job: legacy-ironic-lib-dsvm-base

Define 'irrelevant-files' in legacy-ironic-lib-dsvm-base and remove
them from project.yaml. This means we only define 'irrelevant-files'
once. Also makes project.yaml much easier to read.

Fix the 'irrelevant-files' section to make sure we do test when
changes are made to 'requirements.txt'.

Sort the jobs lists in project.yaml.

Conflicts:
  zuul.d/legacy-ironic-lib-jobs.yaml
  zuul.d/project.yaml

Change-Id: I0534be1ff4ac4d3d2e40f282966683c7b60fc7ba
(cherry picked from commit bff1d93438a014bc7bf1d0d20753d90fa27a5019)
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/93/521993/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/legacy-ironic-lib-jobs.yaml', 'zuul.d/project.yaml']",2,ad8d213b61d94e4ec52e5ce59aeaeff3fb81c03c,ocata, - ironic-lib-tempest-partition-agent_ipmitool - ironic-lib-tempest-partition-pxe_ipmitool - ironic-lib-tempest-wholedisk-agent_ipmitool - ironic-lib-tempest-wholedisk-pxe_ipmitool - ironic-lib-tempest-partition-agent_ipmitool - ironic-lib-tempest-partition-pxe_ipmitool - ironic-lib-tempest-wholedisk-agent_ipmitool - ironic-lib-tempest-wholedisk-pxe_ipmitool , - openstack-tox-cover - ironic-lib-tempest-wholedisk-agent_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-wholedisk-pxe_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-partition-agent_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-partition-pxe_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-wholedisk-agent_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-partition-agent_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-wholedisk-pxe_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ironic-lib-tempest-partition-pxe_ipmitool: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^ironic_lib/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ post: jobs: - openstack-tox-cover,46,105
openstack%2Ftaskflow~master~I8b2f327dadbf038cd050f05fbc46a428282a3d82,openstack/taskflow,master,I8b2f327dadbf038cd050f05fbc46a428282a3d82,Avoid log warning when closing is underway (on purpose),MERGED,2016-03-18 05:50:09.000000000,2017-12-12 22:33:40.000000000,2017-12-12 22:33:40.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 9648}, {'_account_id': 9796}, {'_account_id': 10584}, {'_account_id': 22348}]","[{'number': 1, 'created': '2016-03-18 05:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c764f78905cd6ceb64ef010f75f5b8a3b6452c4e', 'message': 'Avoid log warning when closing is underway (on purpose)\n\nRelated-Bug: #1557107\n\nChange-Id: I8b2f327dadbf038cd050f05fbc46a428282a3d82\n'}, {'number': 2, 'created': '2016-05-03 17:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/be16e2c1fc1658aa8935384f567ec520bf4cbd28', 'message': 'Avoid log warning when closing is underway (on purpose)\n\nRelated-Bug: #1557107\n\nChange-Id: I8b2f327dadbf038cd050f05fbc46a428282a3d82\n'}, {'number': 3, 'created': '2016-05-10 22:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5d267d3d5b6c41ca51677e24eba4b1ca95445548', 'message': 'Avoid log warning when closing is underway (on purpose)\n\nRelated-Bug: #1557107\n\nChange-Id: I8b2f327dadbf038cd050f05fbc46a428282a3d82\n'}, {'number': 4, 'created': '2017-07-11 03:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a57cade7986bd5ce9c9b4437c612aa29a4590b8a', 'message': 'Avoid log warning when closing is underway (on purpose)\n\nRelated-Bug: #1557107\n\nChange-Id: I8b2f327dadbf038cd050f05fbc46a428282a3d82\n'}, {'number': 5, 'created': '2017-08-01 11:28:26.000000000', 'files': ['taskflow/jobs/backends/impl_zookeeper.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c985dbb63de2b2890d1b4a050171195bbb123771', 'message': 'Avoid log warning when closing is underway (on purpose)\n\nRelated-Bug: #1557107\n\nChange-Id: I8b2f327dadbf038cd050f05fbc46a428282a3d82\n'}]",2,294399,c985dbb63de2b2890d1b4a050171195bbb123771,32,7,5,1297,,,0,"Avoid log warning when closing is underway (on purpose)

Related-Bug: #1557107

Change-Id: I8b2f327dadbf038cd050f05fbc46a428282a3d82
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/99/294399/4 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/jobs/backends/impl_zookeeper.py'],1,c764f78905cd6ceb64ef010f75f5b8a3b6452c4e,bug/1557107," self._closing = False # When the client is itself closing itself down this will be # triggered, but in that case we expect it, so we don't need # to emit a warning message. if not self._closing: LOG.warn(""Connection to zookeeper has been lost"") old_closing = self._closing self._closing = True try: kazoo_utils.finalize_client(self._client) except Exception: with excutils.save_and_reraise_exception(): # Restore the old value of closing, as didn't actually # close it for some reason... self._closing = old_closing self._closing = False"," LOG.warn(""Connection to zookeeper has been lost"") kazoo_utils.finalize_client(self._client)",16,2
openstack%2Fmonasca-ceilometer~stable%2Focata~I1190c51ccb4b541b75b37033add2680f04e9f7dd,openstack/monasca-ceilometer,stable/ocata,I1190c51ccb4b541b75b37033add2680f04e9f7dd,Fix a typo,MERGED,2017-12-07 01:11:15.000000000,2017-12-12 22:31:24.000000000,2017-12-12 22:31:24.000000000,"[{'_account_id': 7052}, {'_account_id': 10311}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 01:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/2b9bb972231845b6e7dbbde081f6b420309c6e71', 'message': 'Fix a typo\n\nChange-Id: I1190c51ccb4b541b75b37033add2680f04e9f7dd\n'}, {'number': 2, 'created': '2017-12-08 23:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/666b734f1bbc503c124449d8cd386342503bd2d3', 'message': 'Fix a typo\n\nChange-Id: I1190c51ccb4b541b75b37033add2680f04e9f7dd\n'}, {'number': 3, 'created': '2017-12-12 00:16:05.000000000', 'files': ['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/3631166f2c2877d7314cd15b7f185bea8c48c20b', 'message': 'Fix a typo\n\nChange-Id: I1190c51ccb4b541b75b37033add2680f04e9f7dd\n'}]",0,526243,3631166f2c2877d7314cd15b7f185bea8c48c20b,11,3,3,10311,,,0,"Fix a typo

Change-Id: I1190c51ccb4b541b75b37033add2680f04e9f7dd
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/43/526243/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py']",2,2b9bb972231845b6e7dbbde081f6b420309c6e71,catch-up-to-newton," 'filter must be specified',"," 'fitler must be specified',",2,2
openstack%2Fcloudkitty~master~If1816b6926e8048ff05908a15fc0870050a5718a,openstack/cloudkitty,master,If1816b6926e8048ff05908a15fc0870050a5718a,Ensure compatibility with all versions of gnocchiclient.,MERGED,2017-12-06 10:36:09.000000000,2017-12-12 22:31:11.000000000,2017-12-12 22:31:11.000000000,"[{'_account_id': 9642}, {'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 23173}]","[{'number': 1, 'created': '2017-12-06 10:36:09.000000000', 'files': ['cloudkitty/storage/gnocchi/__init__.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/cfc53b4883a83e9d8f68ec3ea514fdf02034e900', 'message': 'Ensure compatibility with all versions of gnocchiclient.\n\nThis makes sure that the gnocchi storage backend is compatible with all\nversions of gnocchiclient. Starting with version 5.0.0 (which is not stable\nyet), it returns python datetime objects instead of timestamps\n(see https://github.com/gnocchixyz/python-gnocchiclient/commit/c14f5a484dd00c14854f56150fca5eee5c42a8b7).\n\nAs soon as a gnocchiclient version > to 4.0 is considered stable, the try/except\nblock can be removed and a constraint python-gnocchiclient>=5.0 may be set in\nrequirements.txt.\n\nChange-Id: If1816b6926e8048ff05908a15fc0870050a5718a\n'}]",0,526023,cfc53b4883a83e9d8f68ec3ea514fdf02034e900,13,4,1,23060,,,0,"Ensure compatibility with all versions of gnocchiclient.

This makes sure that the gnocchi storage backend is compatible with all
versions of gnocchiclient. Starting with version 5.0.0 (which is not stable
yet), it returns python datetime objects instead of timestamps
(see https://github.com/gnocchixyz/python-gnocchiclient/commit/c14f5a484dd00c14854f56150fca5eee5c42a8b7).

As soon as a gnocchiclient version > to 4.0 is considered stable, the try/except
block can be removed and a constraint python-gnocchiclient>=5.0 may be set in
requirements.txt.

Change-Id: If1816b6926e8048ff05908a15fc0870050a5718a
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/23/526023/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/storage/gnocchi/__init__.py'],1,cfc53b4883a83e9d8f68ec3ea514fdf02034e900,gnocchiclient-compatibility," # NOTE(lukapeschke) Since version 5.0.0, gnocchiclient returns a # datetime object instead of a timestamp. This fixture is made # to ensure compatibility with all versions try: # (aolwas) According http://gnocchi.xyz/rest.html#metrics, # gnocchi always returns measures ordered by timestamp return ck_utils.dt2ts(dateutil.parser.parse(r[-1][0])) except TypeError: return ck_utils.dt2ts(r[-1][0]) # NOTE(lukapeschke) Since version 5.0.0, gnocchiclient returns a # datetime object instead of a timestamp. This fixture is made # to ensure compatibility with all versions try: begin = dateutil.parser.parse(measure[0]) end = (dateutil.parser.parse(measure[0]) + datetime.timedelta(seconds=self._period)) except TypeError: begin = measure[0] end = begin + datetime.timedelta(seconds=self._period)"," # (aolwas) According http://gnocchi.xyz/rest.html#metrics, # gnocchi always returns measures ordered by timestamp return ck_utils.dt2ts(dateutil.parser.parse(r[-1][0])) begin = dateutil.parser.parse(measure[0]) end = (dateutil.parser.parse(measure[0]) + datetime.timedelta(seconds=self._period))",19,6
openstack%2Fopenstack-ansible~master~I9a2337f0e2b908a59e8d0f3cddf2b61cc48a49a8,openstack/openstack-ansible,master,I9a2337f0e2b908a59e8d0f3cddf2b61cc48a49a8,Remove is_metal from playbooks,MERGED,2017-12-11 13:10:10.000000000,2017-12-12 22:16:03.000000000,2017-12-12 22:16:03.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-11 13:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/90e0b9b00a9353c2e5204733d8eacf658a5a3f91', 'message': 'Remove is_metal from playbooks\n\nThe is_metal variable is set in group_vars/all/all.yml so\nit does not need to also be set in every playbook.\n\nChange-Id: I9a2337f0e2b908a59e8d0f3cddf2b61cc48a49a8\n'}, {'number': 2, 'created': '2017-12-11 13:20:19.000000000', 'files': ['playbooks/rsyslog-install.yml', 'playbooks/rabbitmq-install.yml', 'playbooks/os-magnum-install.yml', 'playbooks/os-octavia-install.yml', 'playbooks/os-swift-install.yml', 'playbooks/ceph-install.yml', 'playbooks/lxc-containers-create.yml', 'playbooks/os-swift-sync.yml', 'playbooks/os-sahara-install.yml', 'playbooks/os-horizon-install.yml', 'playbooks/os-trove-install.yml', 'playbooks/os-tempest-install.yml', 'playbooks/utility-install.yml', 'playbooks/os-aodh-install.yml', 'playbooks/repo-server.yml', 'playbooks/galera-install.yml', 'playbooks/os-gnocchi-install.yml', 'playbooks/os-heat-install.yml', 'playbooks/os-molteniron-install.yml', 'playbooks/os-tacker-install.yml', 'playbooks/os-ceilometer-install.yml', 'playbooks/memcached-install.yml', 'playbooks/os-designate-install.yml', 'playbooks/etcd-install.yml', 'playbooks/os-ironic-install.yml', 'playbooks/unbound-install.yml', 'playbooks/os-barbican-install.yml', 'playbooks/haproxy-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/def5292a85a72ff919930ea7717eaf105a8d4a96', 'message': 'Remove is_metal from playbooks\n\nThe is_metal variable is set in group_vars/all/all.yml so\nit does not need to also be set in every playbook.\n\nChange-Id: I9a2337f0e2b908a59e8d0f3cddf2b61cc48a49a8\n'}]",0,527081,def5292a85a72ff919930ea7717eaf105a8d4a96,15,6,2,6816,,,0,"Remove is_metal from playbooks

The is_metal variable is set in group_vars/all/all.yml so
it does not need to also be set in every playbook.

Change-Id: I9a2337f0e2b908a59e8d0f3cddf2b61cc48a49a8
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/527081/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/rsyslog-install.yml', 'playbooks/rabbitmq-install.yml', 'playbooks/os-magnum-install.yml', 'playbooks/os-octavia-install.yml', 'playbooks/os-swift-install.yml', 'playbooks/ceph-install.yml', 'playbooks/lxc-containers-create.yml', 'playbooks/os-swift-sync.yml', 'playbooks/os-sahara-install.yml', 'playbooks/os-horizon-install.yml', 'playbooks/os-trove-install.yml', 'playbooks/os-tempest-install.yml', 'playbooks/utility-install.yml', 'playbooks/os-aodh-install.yml', 'playbooks/repo-server.yml', 'playbooks/galera-install.yml', 'playbooks/os-gnocchi-install.yml', 'playbooks/os-heat-install.yml', 'playbooks/os-molteniron-install.yml', 'playbooks/os-tacker-install.yml', 'playbooks/os-ceilometer-install.yml', 'playbooks/memcached-install.yml', 'playbooks/os-designate-install.yml', 'playbooks/etcd-install.yml', 'playbooks/os-ironic-install.yml', 'playbooks/unbound-install.yml', 'playbooks/os-barbican-install.yml', 'playbooks/haproxy-install.yml']",28,90e0b9b00a9353c2e5204733d8eacf658a5a3f91,remove-is_metal-in-playbooks,," is_metal: ""{{ properties.is_metal|default(false) }}"" is_metal: ""{{ properties.is_metal|default(false) }}""",0,30
openstack%2Fopenstack-ansible~stable%2Fpike~I91e5505408e53271155ac80e2997595ddf3b8781,openstack/openstack-ansible,stable/pike,I91e5505408e53271155ac80e2997595ddf3b8781,Avoid using 'roles' reserved variable,MERGED,2017-12-11 17:01:05.000000000,2017-12-12 22:16:00.000000000,2017-12-12 22:16:00.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-11 17:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1510fd67238c54d736d203876eb001bbed81a684', 'message': ""Avoid using 'roles' reserved variable\n\nThis patch clears up an Ansible warning that is thrown each time the\n`get-ansible-role-requirements.yml` playbook runs. The playbook has\na variable called `roles`, but that's a reserved variable name.\n\nThe patch changes the variable name to `required_roles` to avoid the\nwarning.\n\nCloses-Bug: 1735781\nChange-Id: I91e5505408e53271155ac80e2997595ddf3b8781\n(cherry picked from commit 98d1b58b94c80a70f0e0053644e6f10b30feb63e)\n""}, {'number': 2, 'created': '2017-12-11 18:12:41.000000000', 'files': ['tests/get-ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7a2e0369c3cda13e2fc6a9ea2ee34ddc0f4c73eb', 'message': ""Avoid using 'roles' reserved variable\n\nThis patch clears up an Ansible warning that is thrown each time the\n`get-ansible-role-requirements.yml` playbook runs. The playbook has\na variable called `roles`, but that's a reserved variable name.\n\nThe patch changes the variable name to `required_roles` to avoid the\nwarning.\n\nCombined backport of:\n- https://review.openstack.org/524660\n- https://review.openstack.org/527201\n\nCloses-Bug: 1735781\nChange-Id: I91e5505408e53271155ac80e2997595ddf3b8781\n""}]",0,527166,7a2e0369c3cda13e2fc6a9ea2ee34ddc0f4c73eb,15,6,2,6816,,,0,"Avoid using 'roles' reserved variable

This patch clears up an Ansible warning that is thrown each time the
`get-ansible-role-requirements.yml` playbook runs. The playbook has
a variable called `roles`, but that's a reserved variable name.

The patch changes the variable name to `required_roles` to avoid the
warning.

Combined backport of:
- https://review.openstack.org/524660
- https://review.openstack.org/527201

Closes-Bug: 1735781
Change-Id: I91e5505408e53271155ac80e2997595ddf3b8781
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/66/527166/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/get-ansible-role-requirements.yml'],1,1510fd67238c54d736d203876eb001bbed81a684,bug/1735781-stable/pike," with_items: ""{{ required_roles }}"" with_items: ""{{ required_roles }}"" required_roles: ""{{ lookup('file', role_file) | from_yaml }}"""," with_items: ""{{ roles }}"" with_items: ""{{ roles }}"" roles: ""{{ lookup('file', role_file) | from_yaml }}""",3,3
openstack%2Fopenstack-ansible~stable%2Focata~Iba714e1e20e1a27b1a5bb58a714dee3916faba8f,openstack/openstack-ansible,stable/ocata,Iba714e1e20e1a27b1a5bb58a714dee3916faba8f,Fix crontab errors on CentOS/SUSE,MERGED,2017-12-05 15:32:00.000000000,2017-12-12 22:16:00.000000000,2017-12-12 22:16:00.000000000,"[{'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 24441}, {'_account_id': 24468}]","[{'number': 1, 'created': '2017-12-05 15:32:00.000000000', 'files': ['playbooks/roles/system_crontab_coordination/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/765cbc2ba03f3836fd4ef2a60a84183ad9af1df6', 'message': ""Fix crontab errors on CentOS/SUSE\n\nCentOS comes with a default empty crontab file that is fine for\nmost deployers. It also lacks the `--report` option for `run-parts`\nthat Ubuntu has.\n\nSUSE doesn't have run-parts at all.\n\nThis causes the server administrator to receive emails with errors\nfrom cron on a regular basis. This patch limits the crontab\ndeployment to Ubuntu only and skips CentOS/SUSE hosts.\n\nCloses-Bug: 1732762\nChange-Id: Iba714e1e20e1a27b1a5bb58a714dee3916faba8f\n(cherry picked from commit c4d12eba1b5b6c27b318b84a58a442ee80aa9db0)\n""}]",0,525652,765cbc2ba03f3836fd4ef2a60a84183ad9af1df6,16,6,1,538,,,0,"Fix crontab errors on CentOS/SUSE

CentOS comes with a default empty crontab file that is fine for
most deployers. It also lacks the `--report` option for `run-parts`
that Ubuntu has.

SUSE doesn't have run-parts at all.

This causes the server administrator to receive emails with errors
from cron on a regular basis. This patch limits the crontab
deployment to Ubuntu only and skips CentOS/SUSE hosts.

Closes-Bug: 1732762
Change-Id: Iba714e1e20e1a27b1a5bb58a714dee3916faba8f
(cherry picked from commit c4d12eba1b5b6c27b318b84a58a442ee80aa9db0)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/52/525652/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/system_crontab_coordination/tasks/main.yml'],1,765cbc2ba03f3836fd4ef2a60a84183ad9af1df6,bug/1732762-stable/pike-stable/ocata, when: - ansible_os_family == 'Debian',,2,0
openstack%2Fnova~stable%2Focata~I386df03f406dd0f1847a0d091e070df7786f616e,openstack/nova,stable/ocata,I386df03f406dd0f1847a0d091e070df7786f616e,Skip test_rebuild_server_in_error_state for cells v1,MERGED,2017-08-22 18:42:29.000000000,2017-12-12 22:08:07.000000000,2017-12-12 22:08:06.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12898}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 17130}, {'_account_id': 21279}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-08-22 18:42:29.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/1bfc26bd9c79c55d000e5ce59285c1d6e66dc31b', 'message': ""Skip test_rebuild_server_in_error_state for cells v1\n\nThis test randomly fails due to a timeout in cells v1\njobs and is a latent issue. Since cells v1 is deprecated\nand we aren't fixing latent bugs, let's just skip this.\n\nChange-Id: I386df03f406dd0f1847a0d091e070df7786f616e\nRelated-Bug: #1709985\n(cherry picked from commit 9e2a0163d36fd0c2152b39a714e028752d70677b)\n""}]",0,496359,1bfc26bd9c79c55d000e5ce59285c1d6e66dc31b,19,14,1,6873,,,0,"Skip test_rebuild_server_in_error_state for cells v1

This test randomly fails due to a timeout in cells v1
jobs and is a latent issue. Since cells v1 is deprecated
and we aren't fixing latent bugs, let's just skip this.

Change-Id: I386df03f406dd0f1847a0d091e070df7786f616e
Related-Bug: #1709985
(cherry picked from commit 9e2a0163d36fd0c2152b39a714e028752d70677b)
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/496359/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,1bfc26bd9c79c55d000e5ce59285c1d6e66dc31b,bug/1709985,"# Bug 1709985: rebuild randomly times out, probably due to sync issues # tempest.api.compute.admin.test_servers.ServersAdminTestJSON.test_rebuild_server_in_error_state r=""$r|(?:.*id\-682cb127\-e5bb\-4f53\-87ce\-cb9003604442.*)""",,3,0
openstack%2Fnova~master~I921f60513a55d0e0f126a0e34b48137f8e5b82e6,openstack/nova,master,I921f60513a55d0e0f126a0e34b48137f8e5b82e6,remove reserve_quota_delta,MERGED,2017-11-20 09:54:10.000000000,2017-12-12 22:06:09.000000000,2017-12-12 22:06:09.000000000,"[{'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 19853}, {'_account_id': 19944}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-20 09:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c971f7a84cc334498ea5567a21f90cca96e6eff8', 'message': 'WIP: remove reserve_quota_delta\n\nChange-Id: I921f60513a55d0e0f126a0e34b48137f8e5b82e6\n'}, {'number': 2, 'created': '2017-11-21 05:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09e07a308a9bd1b07463b890eac06485ba385d28', 'message': 'WIP: remove reserve_quota_delta\n\nChange-Id: I921f60513a55d0e0f126a0e34b48137f8e5b82e6\n'}, {'number': 3, 'created': '2017-12-04 05:02:09.000000000', 'files': ['nova/tests/unit/compute/test_compute_cells.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9ebf12b32c41343d694cac3b7c6c51d18ef4dd54', 'message': 'remove reserve_quota_delta\n\nreserve_quota_delta is not used anymore\n\nChange-Id: I921f60513a55d0e0f126a0e34b48137f8e5b82e6\n'}]",1,521469,9ebf12b32c41343d694cac3b7c6c51d18ef4dd54,51,18,3,6062,,,0,"remove reserve_quota_delta

reserve_quota_delta is not used anymore

Change-Id: I921f60513a55d0e0f126a0e34b48137f8e5b82e6
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/521469/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_cells.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/compute/utils.py']",3,c971f7a84cc334498ea5567a21f90cca96e6eff8,remove_quota_2,,"def reserve_quota_delta(context, deltas, instance): """"""If there are deltas to reserve, construct a Quotas object and reserve the deltas for the given project. :param context: The nova request context. :param deltas: A dictionary of the proposed delta changes. :param instance: The instance we're operating on, so that quotas can use the correct project_id/user_id. :return: nova.objects.quotas.Quotas """""" quotas = objects.Quotas(context=context) if deltas: project_id, user_id = objects.quotas.ids_from_instance(context, instance) quotas.reserve(project_id=project_id, user_id=user_id, **deltas) return quotas ",1,39
openstack%2Fcloudkitty~master~I257e8cefc2b699fc979c717531cd9ba77233d94b,openstack/cloudkitty,master,I257e8cefc2b699fc979c717531cd9ba77233d94b,Policy in code,MERGED,2017-09-05 10:16:46.000000000,2017-12-12 22:03:15.000000000,2017-12-12 22:03:14.000000000,"[{'_account_id': 3}, {'_account_id': 2376}, {'_account_id': 5046}, {'_account_id': 7042}, {'_account_id': 7923}, {'_account_id': 8358}, {'_account_id': 9642}, {'_account_id': 11564}, {'_account_id': 11904}, {'_account_id': 18898}, {'_account_id': 19554}, {'_account_id': 21797}, {'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 23173}, {'_account_id': 26767}]","[{'number': 1, 'created': '2017-09-05 10:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/ec6f39748fb223a916c16b6a48d072c841b66fed', 'message': 'Policy in code for rating API\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\n'}, {'number': 2, 'created': '2017-09-05 11:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/03fa97f4c4fd9faac08ff912e39a8482ea855283', 'message': 'Policy in code for rating API\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\n'}, {'number': 3, 'created': '2017-09-05 12:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/739fdde17217f82ee6f1ef641a416d8eab329792', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo and test if policies works.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\n'}, {'number': 4, 'created': '2017-09-05 12:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/ba6b228f16f9844d562438eb4de93ee190733d7e', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo and test if policies works.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nPartially Implements: blueprint policy-in-code\n'}, {'number': 5, 'created': '2017-09-06 01:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/5cdc253f0448008bb5a2c53f873cce28f7cf05b7', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nPartially Implements: blueprint policy-in-code\n'}, {'number': 6, 'created': '2017-09-06 03:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/2a9a0514a43585b8d5801992398c38942a5c0785', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nPartially Implements: blueprint policy-in-code\n'}, {'number': 7, 'created': '2017-10-09 04:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/a6f36083f50f3b3aaff5367e3aad31c629b300d2', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nPartially Implements: blueprint policy-in-code\n'}, {'number': 8, 'created': '2017-10-19 03:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/a7295df194fb1472fc2c31f02189470331685cde', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 9, 'created': '2017-10-19 12:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/20e87faba832e8f49c3fe4611f283cad7e2705b9', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 10, 'created': '2017-10-19 14:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/ef924aeb2040435b741b8076ffc399bf16148e05', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 11, 'created': '2017-10-20 02:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/3587bcfb82999948d2e7bcddbe60d28dc7807b93', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 12, 'created': '2017-10-20 02:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/02426bdbdc9feb8190b67df1a8610f3eda49902a', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 13, 'created': '2017-10-27 08:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/c09b4fd4931053424e9b221edbccf23bce891bed', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 14, 'created': '2017-10-27 08:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/55c27f72b8c2221bc2f1c6a3a3d1282b16ac1c63', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 15, 'created': '2017-10-27 09:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/8d6623668137265b7e1aa1254239ea563ba34b7b', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 16, 'created': '2017-10-28 04:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/acbd8ee20b522dd7b4e5a75585f401ef052a3cce', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nPartially Implements: blueprint policy-in-code\n'}, {'number': 17, 'created': '2017-11-28 01:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/a23324922a28a79a6110ea53c64ee9478ada0b0c', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nImplements: blueprint policy-in-code\n'}, {'number': 18, 'created': '2017-11-30 03:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/177724c6725d8c64ec65e6b78421c19abcc94965', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nImplements: blueprint policy-in-code\n'}, {'number': 19, 'created': '2017-11-30 03:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/550fe939a8c00836fc0c2b9d2a22bbb608f81d6b', 'message': 'Policy in code part2\n\nThis patch registeres policies in code for:\n - collector\n - rating\n - report\n - storage\n\nDelete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nDepends-On: I3d9889c59f75db360815cf66004949b22085e123\nImplements: blueprint policy-in-code\n'}, {'number': 20, 'created': '2017-11-30 10:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/c26e68f6078634056f81888911493939bedcee58', 'message': ""Policy in code\n\nThis patch introduces the implementation for registering\ndefault policy rules in code. Default rules are defined under\ncloudkitty.common.policies. Each API's policies are defined in a\nsub-folder under that path and __init__.py contains all the\ndefault policies in code which are registered in the ``init``\nenforcer function in cloudkitty/common/policy.py.\n\nThis commit does the following:\n - Creates the ``policies`` module that contains all the default\n   policies in code.\n - Adds the base policy rules into code (context_is_admin,\n   admin_or_owner and default rules).\n - Add policies in code for current APIs\n - Add a tox env to generate default policy sample file\n - Delete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nImplements: blueprint policy-in-code\n""}, {'number': 21, 'created': '2017-12-01 01:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/26b056725adea4ac0cce32fb47faf9804dccfd30', 'message': ""Policy in code\n\nThis patch introduces the implementation for registering\ndefault policy rules in code. Default rules are defined under\ncloudkitty.common.policies. Each API's policies are defined in a\nsub-folder under that path and __init__.py contains all the\ndefault policies in code which are registered in the ``init``\nenforcer function in cloudkitty/common/policy.py.\n\nThis commit does the following:\n - Creates the ``policies`` module that contains all the default\n   policies in code.\n - Adds the base policy rules into code (context_is_admin,\n   admin_or_owner and default rules).\n - Add policies in code for current APIs\n - Add a tox env to generate default policy sample file\n - Delete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nImplements: blueprint policy-in-code\n""}, {'number': 22, 'created': '2017-12-08 16:45:13.000000000', 'files': ['cloudkitty/rating/__init__.py', '.gitignore', 'cloudkitty/api/v1/controllers/storage.py', 'cloudkitty/api/v1/controllers/report.py', 'cloudkitty/common/policies/__init__.py', 'cloudkitty/utils.py', 'cloudkitty/common/policies/base.py', 'cloudkitty/common/policies/collector.py', 'cloudkitty/common/policies/rating.py', 'cloudkitty/common/policies/info.py', 'doc/source/configuration/policy.rst', 'doc/source/sample_policy.rst', 'devstack/plugin.sh', 'doc/source/conf.py', 'cloudkitty/common/policies/storage.py', 'doc/source/configuration/samples/policy-yaml.rst', 'cloudkitty/api/v1/controllers/collector.py', 'doc/source/configuration/samples/index.rst', 'etc/cloudkitty/policy.json', 'cloudkitty/common/policies/report.py', 'cloudkitty/tests/test_policy.py', 'cloudkitty/api/v1/controllers/rating.py', 'cloudkitty/api/v1/controllers/info.py', 'cloudkitty/common/policy.py', 'setup.cfg', 'tox.ini', 'etc/oslo-policy-generator/cloudkitty.conf'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/7eca6726453b8c07acbb67bc276b77ec32e5ec1b', 'message': ""Policy in code\n\nThis patch introduces the implementation for registering\ndefault policy rules in code. Default rules are defined under\ncloudkitty.common.policies. Each API's policies are defined in a\nsub-folder under that path and __init__.py contains all the\ndefault policies in code which are registered in the ``init``\nenforcer function in cloudkitty/common/policy.py.\n\nThis commit does the following:\n - Creates the ``policies`` module that contains all the default\n   policies in code.\n - Adds the base policy rules into code (context_is_admin,\n   admin_or_owner and default rules).\n - Add policies in code for current APIs\n - Add a tox env to generate default policy sample file\n - Delete policy.json from repo as policies in code will be used.\n\nChange-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b\nImplements: blueprint policy-in-code\n""}]",19,500764,7eca6726453b8c07acbb67bc276b77ec32e5ec1b,80,16,22,21797,,,0,"Policy in code

This patch introduces the implementation for registering
default policy rules in code. Default rules are defined under
cloudkitty.common.policies. Each API's policies are defined in a
sub-folder under that path and __init__.py contains all the
default policies in code which are registered in the ``init``
enforcer function in cloudkitty/common/policy.py.

This commit does the following:
 - Creates the ``policies`` module that contains all the default
   policies in code.
 - Adds the base policy rules into code (context_is_admin,
   admin_or_owner and default rules).
 - Add policies in code for current APIs
 - Add a tox env to generate default policy sample file
 - Delete policy.json from repo as policies in code will be used.

Change-Id: I257e8cefc2b699fc979c717531cd9ba77233d94b
Implements: blueprint policy-in-code
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/64/500764/7 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cloudkitty/policy.json', 'cloudkitty/common/policies/rating.py', 'cloudkitty/common/policies/__init__.py']",3,ec6f39748fb223a916c16b6a48d072c841b66fed,policy-and-docs-in-code,"from cloudkitty.common.policies import rating info.list_rules(), rating.list_rules()", info.list_rules(),56,8
openstack%2Fcloudkitty~master~Ie229edf736ef80b70d66649a1b26d68c69758e45,openstack/cloudkitty,master,Ie229edf736ef80b70d66649a1b26d68c69758e45,Remove deprecated APIs and method in cloudkitty,MERGED,2017-03-02 09:31:06.000000000,2017-12-12 21:56:35.000000000,2017-12-12 21:56:35.000000000,"[{'_account_id': 3}, {'_account_id': 7923}, {'_account_id': 8358}, {'_account_id': 9642}, {'_account_id': 21797}, {'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 23173}]","[{'number': 1, 'created': '2017-03-02 09:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/443fcfac901245be5c55f703b88c42ef8e7fe852', 'message': 'Remove deprecated APIs and method in cloudkitty\n\nRemove deprecated model `ModuleEnablueState` and use\n`ModuleInfo` instead.\n\nAlso remove code of billingController, billingProcess\nand billing datemodels.\n\nChange-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45\n'}, {'number': 2, 'created': '2017-11-07 09:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/a723502f59d629e98f3b6285e06e29e821cdd552', 'message': 'Remove deprecated APIs and method in cloudkitty\n\nRemove deprecated model `ModuleEnablueState` and use\n`ModuleInfo` instead.\n\nAlso remove code of billingController, billingProcess\nand billing datemodels.\n\nChange-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45\n'}, {'number': 3, 'created': '2017-11-15 10:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/eb888a603a0c4ec7fbb3b253c530742ba61839de', 'message': 'Remove deprecated APIs and method in cloudkitty\n\nRemove deprecated model `ModuleEnablueState` and use\n`ModuleInfo` instead.\n\nAlso remove code of billingController, billingProcess\nand billing datemodels.\n\nChange-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45\n'}, {'number': 4, 'created': '2017-11-15 10:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/36cc95b1d14c1dac2b6fc58f9c3adaccc7544f2a', 'message': 'Remove deprecated APIs and method in cloudkitty\n\nRemove deprecated model `ModuleEnableState` and use\n`ModuleInfo` instead.\n\nAlso remove code of billingController, billingProcess\nand billing datemodels.\n\nChange-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45\n'}, {'number': 5, 'created': '2017-11-16 10:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/d46d50e4a13f26de32f9fdf83d0ecab35637d631', 'message': 'Remove deprecated APIs and method in cloudkitty\n\nRemove deprecated model `ModuleEnableState` and use\n`ModuleInfo` instead.\n\nAlso remove code of billingController, billingProcess\nand billing datemodels.\n\nChange-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45\n'}, {'number': 6, 'created': '2017-11-29 09:50:18.000000000', 'files': ['cloudkitty/billing/hash/datamodels/mapping.py', 'cloudkitty/rating/__init__.py', 'cloudkitty/billing/hash/datamodels/__init__.py', 'cloudkitty/db/api.py', 'cloudkitty/billing/hash/__init__.py', 'cloudkitty/billing/hash/controllers/field.py', 'cloudkitty/billing/hash/db/sqlalchemy/models.py', 'cloudkitty/billing/hash/datamodels/group.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/billing/hash/db/api.py', 'cloudkitty/api/v1/datamodels/billing.py', 'releasenotes/notes/remove-deprecated-api-endpoints-26606e322b8a225e.yaml', 'cloudkitty/billing/hash/controllers/group.py', 'cloudkitty/billing/hash/controllers/__init__.py', 'cloudkitty/billing/hash/db/sqlalchemy/migration.py', 'cloudkitty/billing/hash/db/sqlalchemy/__init__.py', 'cloudkitty/billing/hash/controllers/mapping.py', 'cloudkitty/billing/hash/db/__init__.py', 'cloudkitty/collector/meta.py', 'cloudkitty/billing/hash/datamodels/service.py', 'cloudkitty/billing/hash/controllers/root.py', 'cloudkitty/billing/hash/db/sqlalchemy/api.py', 'cloudkitty/api/v1/controllers/billing.py', 'cloudkitty/billing/noop.py', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/billing/hash/controllers/service.py', 'cloudkitty/tests/test_rating.py', 'cloudkitty/billing/hash/datamodels/field.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/e6f5c28e0ebdac8e9b00c16ad9917107648e8b8f', 'message': 'Remove deprecated APIs and method in cloudkitty\n\nRemove deprecated model `ModuleEnableState` and use\n`ModuleInfo` instead.\n\nAlso remove code of billingController, billingProcess\nand billing datemodels.\n\nChange-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45\n'}]",0,440252,e6f5c28e0ebdac8e9b00c16ad9917107648e8b8f,26,8,6,15917,,,0,"Remove deprecated APIs and method in cloudkitty

Remove deprecated model `ModuleEnableState` and use
`ModuleInfo` instead.

Also remove code of billingController, billingProcess
and billing datemodels.

Change-Id: Ie229edf736ef80b70d66649a1b26d68c69758e45
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/52/440252/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/billing/hash/datamodels/mapping.py', 'cloudkitty/rating/__init__.py', 'cloudkitty/billing/hash/datamodels/__init__.py', 'cloudkitty/db/api.py', 'cloudkitty/billing/hash/__init__.py', 'cloudkitty/billing/hash/controllers/field.py', 'cloudkitty/billing/hash/db/sqlalchemy/models.py', 'cloudkitty/billing/hash/datamodels/group.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/billing/hash/db/api.py', 'cloudkitty/api/v1/datamodels/billing.py', 'cloudkitty/billing/hash/controllers/group.py', 'cloudkitty/billing/hash/controllers/__init__.py', 'cloudkitty/billing/hash/db/sqlalchemy/migration.py', 'cloudkitty/billing/hash/db/sqlalchemy/__init__.py', 'cloudkitty/billing/hash/controllers/mapping.py', 'cloudkitty/billing/hash/db/__init__.py', 'cloudkitty/collector/meta.py', 'cloudkitty/billing/hash/datamodels/service.py', 'cloudkitty/billing/hash/controllers/root.py', 'cloudkitty/billing/hash/db/sqlalchemy/api.py', 'cloudkitty/api/v1/controllers/billing.py', 'cloudkitty/billing/noop.py', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/billing/hash/controllers/service.py', 'cloudkitty/tests/test_rating.py', 'cloudkitty/billing/hash/datamodels/field.py']",27,443fcfac901245be5c55f703b88c42ef8e7fe852,delete/deprecated_code,,"# -*- coding: utf-8 -*- # Copyright 2015 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stéphane Albert # from cloudkitty.rating.hash.datamodels.field import * # noqa ",51,582
openstack%2Fmonasca-ceilometer~stable%2Focata~I8d7f5e1b87a1de6078b4d397e96dab624fde42bb,openstack/monasca-ceilometer,stable/ocata,I8d7f5e1b87a1de6078b4d397e96dab624fde42bb,Support jsonpath definitions in monasca_field_definitions.yaml,MERGED,2017-12-07 01:11:15.000000000,2017-12-12 21:56:03.000000000,2017-12-12 21:56:03.000000000,"[{'_account_id': 7052}, {'_account_id': 10311}, {'_account_id': 11580}, {'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-07 01:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/59923f41da7dd8dd64b3f15d9b44c5ce93afa1a3', 'message': 'Support jsonpath definitions in monasca_field_definitions.yaml\n\nTo enhance flexibility when mapping a ceilometer sample to the\nmonasca fields, add support for jsonpath parsing of metadata.\nFor example, the cinder samples have metadata stored in lists,\nwhich the current parsing (including . notation) cannot handle.\nSimilar requests have been made in the past, and this should\ngive enough power to meet most requests.\n\nFor a jsonpath that does not resolve to a simple leaf (string\nvalue), a CeiloscaMappingDefinitionException is raised.\n\nSee https://storyboard.openstack.org/#!/story/2000954\n\nChange-Id: I8d7f5e1b87a1de6078b4d397e96dab624fde42bb\n'}, {'number': 2, 'created': '2017-12-08 23:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/f6a05ccd74da97453bb3fc8305743907f29ead24', 'message': 'Support jsonpath definitions in monasca_field_definitions.yaml\n\nTo enhance flexibility when mapping a ceilometer sample to the\nmonasca fields, add support for jsonpath parsing of metadata.\nFor example, the cinder samples have metadata stored in lists,\nwhich the current parsing (including . notation) cannot handle.\nSimilar requests have been made in the past, and this should\ngive enough power to meet most requests.\n\nFor a jsonpath that does not resolve to a simple leaf (string\nvalue), a CeiloscaMappingDefinitionException is raised.\n\nSee https://storyboard.openstack.org/#!/story/2000954\n\nChange-Id: I8d7f5e1b87a1de6078b4d397e96dab624fde42bb\n'}, {'number': 3, 'created': '2017-12-12 00:16:05.000000000', 'files': ['ceilosca/ceilometer/publisher/monasca_data_filter.py', 'ceilosca/ceilometer/tests/unit/publisher/test_monasca_data_filter.py'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/e4569607765441033fc0ca788a2b172613f41d7a', 'message': 'Support jsonpath definitions in monasca_field_definitions.yaml\n\nTo enhance flexibility when mapping a ceilometer sample to the\nmonasca fields, add support for jsonpath parsing of metadata.\nFor example, the cinder samples have metadata stored in lists,\nwhich the current parsing (including . notation) cannot handle.\nSimilar requests have been made in the past, and this should\ngive enough power to meet most requests.\n\nFor a jsonpath that does not resolve to a simple leaf (string\nvalue), a CeiloscaMappingDefinitionException is raised.\n\nSee https://storyboard.openstack.org/#!/story/2000954\n\nChange-Id: I8d7f5e1b87a1de6078b4d397e96dab624fde42bb\n'}]",0,526242,e4569607765441033fc0ca788a2b172613f41d7a,25,5,3,10311,,,0,"Support jsonpath definitions in monasca_field_definitions.yaml

To enhance flexibility when mapping a ceilometer sample to the
monasca fields, add support for jsonpath parsing of metadata.
For example, the cinder samples have metadata stored in lists,
which the current parsing (including . notation) cannot handle.
Similar requests have been made in the past, and this should
give enough power to meet most requests.

For a jsonpath that does not resolve to a simple leaf (string
value), a CeiloscaMappingDefinitionException is raised.

See https://storyboard.openstack.org/#!/story/2000954

Change-Id: I8d7f5e1b87a1de6078b4d397e96dab624fde42bb
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/42/526242/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilosca/ceilometer/publisher/monasca_data_filter.py', 'ceilosca/ceilometer/tests/unit/publisher/test_monasca_data_filter.py']",2,59923f41da7dd8dd64b3f15d9b44c5ce93afa1a3,catch-up-to-newton,"from ceilometer.ceilosca_mapping.ceilosca_mapping import ( CeiloscaMappingDefinitionException) self._field_mappings_cinder = { 'dimensions': ['resource_id', 'project_id', 'user_id', 'geolocation', 'region', 'source', 'availability_zone'], 'metadata': { 'common': ['event_type', 'audit_period_beginning', 'audit_period_ending', 'arbitrary_new_field'], 'volume.create.end': ['size', 'status', {'metering.prn_name': ""$.metadata[?(@.key = 'metering.prn_name')].value""}, {'metering.prn_type': ""$.metadata[?(@.key = 'metering.prn_type')].value""}, 'volume_type', 'created_at', 'host'], 'volume': ['status'], 'volume.size': ['status'], } } self._field_mappings_bad_format = { 'dimensions': ['resource_id', 'project_id', 'user_id', 'geolocation', 'region', 'source', 'availability_zone'], 'metadata': { 'common': ['event_type', 'audit_period_beginning', 'audit_period_ending', 'arbitrary_new_field'], 'volume.create.end': ['size', 'status', {'metering.prn_name': ""$.metadata[?(@.key = 'metering.prn_name')].value"", 'metering.prn_type': ""$.metadata[?(@.key = 'metering.prn_type')].value""}, 'volume_type', 'created_at', 'host'], 'volume': ['status'], 'volume.size': ['status'], } } prefix = prefix + '.' if prefix else """" self.convert_dict_to_list(v, prefix + k, outlst) outlst[prefix + k] = v else: outlst[prefix + k] = 'None' ) self.assertTrue(set(self.convert_dict_to_list( s.resource_metadata ).items()).issubset(set(r['value_meta'].items()))) ) self.assertTrue(set(self.convert_dict_to_list( s.resource_metadata ).items()).issubset(set(r['value_meta'].items()))) ) self.assertTrue(set(self.convert_dict_to_list( s.resource_metadata ).items()).issubset(set(r['value_meta'].items()))) ['base_url3'])) def test_process_sample_metadata_with_jsonpath(self): """"""Test meter sample in a format produced by cinder."""""" s = sample.Sample( name='volume.create.end', type=sample.TYPE_CUMULATIVE, unit='', volume=1, user_id='test', project_id='test', resource_id='test_run_tasks', source='', timestamp=datetime.datetime.utcnow().isoformat(), resource_metadata={'event_type': 'volume.create.end', 'status': 'available', 'volume_type': None, # 'created_at': '2017-03-21T21:05:44+00:00', 'host': 'testhost', # this ""value: , key: "" format is # how cinder reports metadata 'metadata': [{'value': 'aaa0001', 'key': 'metering.prn_name'}, {'value': 'Cust001', 'key': 'metering.prn_type'}], 'size': 0}, ) to_patch = (""ceilometer.publisher.monasca_data_filter."" ""MonascaDataFilter._get_mapping"") # use the cinder specific mapping with mock.patch(to_patch, side_effect=[self._field_mappings_cinder]): data_filter = mdf.MonascaDataFilter() r = data_filter.process_sample_for_monasca(s) self.assertEqual(s.name, r['name']) self.assertIsNotNone(r.get('value_meta')) # Using convert_dict_to_list is too simplistic for this self.assertEqual(r.get('value_meta')['event_type'], s.resource_metadata.get('event_type'), ""Failed to match common element."") self.assertEqual(r.get('value_meta')['host'], s.resource_metadata.get('host'), ""Failed to match meter specific element."") self.assertEqual(r.get('value_meta')['size'], s.resource_metadata.get('size'), ""Unable to handle an int."") self.assertEqual(r.get('value_meta')['metering.prn_name'], 'aaa0001', ""Failed to extract a value "" ""using specified jsonpath."") def test_process_sample_metadata_with_jsonpath_nomatch(self): """"""Test meter sample in a format produced by cinder. Behavior when no matching element is found for the specified jsonpath """""" s = sample.Sample( name='volume.create.end', type=sample.TYPE_CUMULATIVE, unit='', volume=1, user_id='test', project_id='test', resource_id='test_run_tasks', source='', timestamp=datetime.datetime.utcnow().isoformat(), resource_metadata={'event_type': 'volume.create.end', 'status': 'available', 'volume_type': None, # 'created_at': '2017-03-21T21:05:44+00:00', 'host': 'testhost', 'metadata': [{'value': 'aaa0001', 'key': 'metering.THISWONTMATCH'}], 'size': 0}, ) to_patch = (""ceilometer.publisher.monasca_data_filter."" ""MonascaDataFilter._get_mapping"") # use the cinder specific mapping with mock.patch(to_patch, side_effect=[self._field_mappings_cinder]): data_filter = mdf.MonascaDataFilter() r = data_filter.process_sample_for_monasca(s) self.assertEqual(s.name, r['name']) self.assertIsNotNone(r.get('value_meta')) # Using convert_dict_to_list is too simplistic for this self.assertEqual(r.get('value_meta')['event_type'], s.resource_metadata.get('event_type'), ""Failed to match common element."") self.assertEqual(r.get('value_meta')['host'], s.resource_metadata.get('host'), ""Failed to match meter specific element."") self.assertEqual(r.get('value_meta')['size'], s.resource_metadata.get('size'), ""Unable to handle an int."") self.assertEqual(r.get('value_meta')['metering.prn_name'], 'None', ""This metadata should fail to match "" ""and then return 'None'."") def test_process_sample_metadata_with_jsonpath_value_not_str(self): """"""Test where jsonpath is used but result is not a simple string"""""" s = sample.Sample( name='volume.create.end', type=sample.TYPE_CUMULATIVE, unit='', volume=1, user_id='test', project_id='test', resource_id='test_run_tasks', source='', timestamp=datetime.datetime.utcnow().isoformat(), resource_metadata={'event_type': 'volume.create.end', 'status': 'available', 'volume_type': None, # 'created_at': '2017-03-21T21:05:44+00:00', 'host': 'testhost', 'metadata': [{'value': ['aaa0001', 'bbbb002'], 'key': 'metering.prn_name'}], 'size': 0}, ) to_patch = (""ceilometer.publisher.monasca_data_filter."" ""MonascaDataFilter._get_mapping"") # use the cinder specific mapping with mock.patch(to_patch, side_effect=[self._field_mappings_cinder]): data_filter = mdf.MonascaDataFilter() try: # Don't assign to a variable, this should raise data_filter.process_sample_for_monasca(s) except CeiloscaMappingDefinitionException as e: self.assertEqual( 'Metadata format mismatch, value should be ' 'a simple string. [\'aaa0001\', \'bbbb002\']', e.message) def test_process_sample_metadata_with_jsonpath_value_is_int(self): """"""Test meter sample where jsonpath result is an int."""""" s = sample.Sample( name='volume.create.end', type=sample.TYPE_CUMULATIVE, unit='', volume=1, user_id='test', project_id='test', resource_id='test_run_tasks', source='', timestamp=datetime.datetime.utcnow().isoformat(), resource_metadata={'event_type': 'volume.create.end', 'status': 'available', 'volume_type': None, # 'created_at': '2017-03-21T21:05:44+00:00', 'host': 'testhost', 'metadata': [{'value': 13, 'key': 'metering.prn_name'}], 'size': 0}, ) to_patch = (""ceilometer.publisher.monasca_data_filter."" ""MonascaDataFilter._get_mapping"") # use the cinder specific mapping with mock.patch(to_patch, side_effect=[self._field_mappings_cinder]): data_filter = mdf.MonascaDataFilter() r = data_filter.process_sample_for_monasca(s) self.assertEqual(s.name, r['name']) self.assertIsNotNone(r.get('value_meta')) # Using convert_dict_to_list is too simplistic for this self.assertEqual(r.get('value_meta')['event_type'], s.resource_metadata.get('event_type'), ""Failed to match common element."") self.assertEqual(r.get('value_meta')['host'], s.resource_metadata.get('host'), ""Failed to match meter specific element."") self.assertEqual(r.get('value_meta')['size'], s.resource_metadata.get('size'), ""Unable to handle an int."") self.assertEqual(r.get('value_meta')['metering.prn_name'], 13, ""Unable to handle an int "" ""through the jsonpath processing"") def test_process_sample_metadata_with_jsonpath_bad_format(self): """"""Test handling of definition that is not written correctly"""""" s = sample.Sample( name='volume.create.end', type=sample.TYPE_CUMULATIVE, unit='', volume=1, user_id='test', project_id='test', resource_id='test_run_tasks', source='', timestamp=datetime.datetime.utcnow().isoformat(), resource_metadata={'event_type': 'volume.create.end', 'status': 'available', 'volume_type': None, # 'created_at': '2017-03-21T21:05:44+00:00', 'host': 'testhost', 'metadata': [{'value': 13, 'key': 'metering.prn_name'}], 'size': 0}, ) to_patch = (""ceilometer.publisher.monasca_data_filter."" ""MonascaDataFilter._get_mapping"") # use the bad mapping with mock.patch(to_patch, side_effect=[self._field_mappings_bad_format]): data_filter = mdf.MonascaDataFilter() try: # Don't assign to a variable as this should raise data_filter.process_sample_for_monasca(s) except CeiloscaMappingDefinitionException as e: # Make sure we got the right kind of error # Cannot check the whole message text, as python # may reorder a dict when producing a string version self.assertIn( 'Field definition format mismatch, should ' 'have only one key:value pair.', e.message, ""Did raise exception but wrong message - %s"" % e.message)"," prefix = prefix+'.' if prefix else """" self.convert_dict_to_list(v, prefix+k, outlst) outlst[prefix+k] = v else: outlst[prefix+k] = 'None' ) self.assertTrue(set(self.convert_dict_to_list(s.resource_metadata). items()).issubset(set(r['value_meta'].items()))) ) self.assertTrue(set(self.convert_dict_to_list(s.resource_metadata). items()).issubset(set(r['value_meta'].items()))) ) self.assertTrue(set(self.convert_dict_to_list(s.resource_metadata). items()).issubset(set(r['value_meta'].items()))) ['base_url3']))",387,46
openstack%2Fironic-inspector~master~I2f7b8d3172f375cf65e759c9b881fcf41649c2f0,openstack/ironic-inspector,master,I2f7b8d3172f375cf65e759c9b881fcf41649c2f0,Allow concurrect updating of dnsmasq configuration,MERGED,2017-09-15 15:35:15.000000000,2017-12-12 21:56:02.000000000,2017-12-12 21:56:02.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 13636}, {'_account_id': 18653}, {'_account_id': 22348}, {'_account_id': 26340}]","[{'number': 1, 'created': '2017-09-15 15:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ad978b13d58fcfd52edd79fa3c852a4876c87fa2', 'message': 'Fcntl.flock writing\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\n'}, {'number': 2, 'created': '2017-09-19 09:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/a44aa607ff91a723cc346de780bbf988480bba06', 'message': 'Fcntl.flock writing\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\n'}, {'number': 3, 'created': '2017-10-09 15:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/b0944c1d026e4b291439fde8ac25fe0fbdf6aa6b', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 4, 'created': '2017-10-19 15:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/79437b9d0918a127f89b2429db71be801c8ad967', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 5, 'created': '2017-10-30 21:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ee40f64b4862b416d07d97f35ebaec336007ff51', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 6, 'created': '2017-11-10 15:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/06cbbb2c4eb940e0f9bf4e555298f2455e06b6f2', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 7, 'created': '2017-11-10 17:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/9effdf8f11850b3d69d7a85bf26c42bb828d8c65', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 8, 'created': '2017-11-10 17:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c97c9e1bcc3108a176bea8efb21a665fe9d54911', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 9, 'created': '2017-11-15 15:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c5057a171b95b008e9e0907072735f9ee7062760', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 10, 'created': '2017-11-22 14:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ca39ef3b7ec200b158768e65606e477af61ff07e', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}, {'number': 11, 'created': '2017-11-27 17:55:52.000000000', 'files': ['ironic_inspector/test/unit/test_dnsmasq_pxe_filter.py', 'ironic_inspector/pxe_filter/dnsmasq.py', 'ironic_inspector/conf.py', 'example.conf'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/4ff0213e8770de2139f3ec68e65447a9dfcfac1f', 'message': 'Allow concurrect updating of dnsmasq configuration\n\nThis allows multiple instances of inspector to try updating dnsmasq\nconfiguration simultaneously.  The goal is to be able to (test) run an HA\ninspector on a single node.\n\nA new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to\nbe able to disable purging of the dhcp hosts directory in case multiple\ninspector instances are expected to run on the same node.\n\nChange-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0\nCloses-Bug: #1722267\n'}]",44,504438,4ff0213e8770de2139f3ec68e65447a9dfcfac1f,42,7,11,18653,,,0,"Allow concurrect updating of dnsmasq configuration

This allows multiple instances of inspector to try updating dnsmasq
configuration simultaneously.  The goal is to be able to (test) run an HA
inspector on a single node.

A new config option `dnsmasq_pxe_filter.purge_dhcp_hostsdir` is introduced to
be able to disable purging of the dhcp hosts directory in case multiple
inspector instances are expected to run on the same node.

Change-Id: I2f7b8d3172f375cf65e759c9b881fcf41649c2f0
Closes-Bug: #1722267
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/38/504438/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/test/unit/test_dnsmasq_pxe_filter.py', 'ironic_inspector/pxe_filter/dnsmasq.py']",2,ad978b13d58fcfd52edd79fa3c852a4876c87fa2,rebasing_filter,"import fcntl import iodef _exclusive_write_or_pass(path, buf): """"""Write exclusively or pass if path locked. The intention is to be able to run multiple instances of the filter on the same node in multiple inspector processes. :param path: where to write to :param buf: the content to write :raises: FileNotFoundError, IOError :returns: the number of bytes written. """""" # NOTE(milan) line-buffering enforced to ensure dnsmasq record update # through inotify, which reacts on f.close() with open(path, 'w', 1) as f: try: fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB) return f.write(buf) except io.BlockingIOError: LOG.debug('%s locked; will try again later', path) finally: fcntl.flock(f, fcntl.LOCK_UN) _exclusive_write_or_pass(path, '%s,ignore\n' % mac) # remove the ,ignore directive _exclusive_write_or_pass(path, '%s\n' % mac)"," # NOTE(milan) line-buffering enforced to ensure dnsmasq record update # through inotify, which reacts on f.close() with open(path, 'w', 1) as f: f.write('%s,ignore\n' % mac) with open(path, 'w', 1) as f: # remove the ,ignore directive f.write('%s\n' % mac)",74,19
openstack%2Fhorizon~master~I7459e990cac4c6df79c4972e2d5b5b4dee9eb428,openstack/horizon,master,I7459e990cac4c6df79c4972e2d5b5b4dee9eb428,"Fix ""Open Console"" issue on network topology",MERGED,2017-07-03 23:22:42.000000000,2017-12-12 21:53:08.000000000,2017-12-12 21:14:28.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6484}, {'_account_id': 11885}, {'_account_id': 12826}, {'_account_id': 14151}, {'_account_id': 16628}, {'_account_id': 19853}, {'_account_id': 22348}, {'_account_id': 23037}, {'_account_id': 25747}]","[{'number': 1, 'created': '2017-07-03 23:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e40f85d735635095ee3c5e75106036f516b52a54', 'message': 'Fix ""Open Console"" issue on network topology\n\nNow when user click the link ""Open Console"" on the instance balloon of network\n\ntopology panel, two windows will be opened. This patch fixes that.\n\nCloses-Bug: #1702189\n\nChange-Id: I7459e990cac4c6df79c4972e2d5b5b4dee9eb428\n'}, {'number': 2, 'created': '2017-11-29 21:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/89642451a6aa5167cce70c0578a49915b8b6e514', 'message': 'Fix ""Open Console"" issue on network topology\n\nNow when user click the link ""Open Console"" on the instance balloon of network\n\ntopology panel, two windows will be opened. This patch fixes that.\n\nCloses-Bug: #1702189\n\nChange-Id: I7459e990cac4c6df79c4972e2d5b5b4dee9eb428\n'}, {'number': 3, 'created': '2017-11-29 21:41:56.000000000', 'files': ['openstack_dashboard/static/js/horizon.flatnetworktopology.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/db4c47d2528dddf657794a9ebb6b722deaa5d1fe', 'message': 'Fix ""Open Console"" issue on network topology\n\nNow when user click the link ""Open Console"" on the instance balloon of\nnetwork topology panel, two windows will be opened. This patch fixes\nthat.\n\nCloses-Bug: #1702189\n\nChange-Id: I7459e990cac4c6df79c4972e2d5b5b4dee9eb428\n'}]",1,479960,db4c47d2528dddf657794a9ebb6b722deaa5d1fe,28,11,3,6484,,,0,"Fix ""Open Console"" issue on network topology

Now when user click the link ""Open Console"" on the instance balloon of
network topology panel, two windows will be opened. This patch fixes
that.

Closes-Bug: #1702189

Change-Id: I7459e990cac4c6df79c4972e2d5b5b4dee9eb428
",git fetch https://review.opendev.org/openstack/horizon refs/changes/60/479960/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/js/horizon.flatnetworktopology.js'],1,e40f85d735635095ee3c5e75106036f516b52a54,bug/1702189, e.stopImmediatePropagation();,,1,0
openstack%2Fdragonflow~master~Iab6d8ba2d8724b20a1cd4fc910f87147201aef2f,openstack/dragonflow,master,Iab6d8ba2d8724b20a1cd4fc910f87147201aef2f,'tenant_id' field is deprecated,MERGED,2017-12-11 12:48:03.000000000,2017-12-12 21:48:00.000000000,2017-12-12 21:48:00.000000000,"[{'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 23235}, {'_account_id': 26131}]","[{'number': 1, 'created': '2017-12-11 12:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ae15126a4d3766d0321b34e839ea0aa6e14fc1a8', 'message': ""'tenant_id' field is deprecated\n\nsee : https://specs.openstack.org/openstack/neutron-specs/specs/newton/moving-to-keystone-v3.html\nand https://developer.openstack.org/api-ref/network/v2/index.html#api-guide\n\nChange-Id: Iab6d8ba2d8724b20a1cd4fc910f87147201aef2f\n""}, {'number': 2, 'created': '2017-12-11 17:26:45.000000000', 'files': ['dragonflow/common/utils.py', 'dragonflow/neutron/db/models/l3.py', 'dragonflow/neutron/db/models/secgroups.py', 'dragonflow/neutron/services/bgp/bgp_plugin.py', 'dragonflow/neutron/db/models/l2.py', 'dragonflow/neutron/ml2/dhcp_module.py', 'dragonflow/neutron/ml2/mech_driver.py', 'dragonflow/neutron/services/l3_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/46f37ad7ee346f6007ef200cc3c065e1ba0c2278', 'message': ""'tenant_id' field is deprecated\n\nsee : https://specs.openstack.org/openstack/neutron-specs/specs/newton/moving-to-keystone-v3.html\nand https://developer.openstack.org/api-ref/network/v2/index.html#api-guide\n\nChange-Id: Iab6d8ba2d8724b20a1cd4fc910f87147201aef2f\n""}]",6,527078,46f37ad7ee346f6007ef200cc3c065e1ba0c2278,14,4,2,26131,,,0,"'tenant_id' field is deprecated

see : https://specs.openstack.org/openstack/neutron-specs/specs/newton/moving-to-keystone-v3.html
and https://developer.openstack.org/api-ref/network/v2/index.html#api-guide

Change-Id: Iab6d8ba2d8724b20a1cd4fc910f87147201aef2f
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/78/527078/2 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/common/utils.py', 'dragonflow/neutron/db/models/l3.py', 'dragonflow/neutron/db/models/secgroups.py', 'dragonflow/neutron/services/bgp/bgp_plugin.py', 'dragonflow/neutron/db/models/l2.py', 'dragonflow/neutron/ml2/dhcp_module.py', 'dragonflow/neutron/ml2/mech_driver.py', 'dragonflow/neutron/services/l3_router_plugin.py']",8,ae15126a4d3766d0321b34e839ea0aa6e14fc1a8,,"from dragonflow.common import utils as df_utils topic = df_utils.get_obj_topic(floatingip) l3.FloatingIp(id=fip_id, topic=topic), port_topic = df_utils.get_obj_topic(port) topic=port_topic)) router_topic = df_utils.get_obj_topic(router) topic=router_topic)) topic = df_utils.get_obj_topic(router) id=router_id, topic=topic))"," l3.FloatingIp(id=fip_id, topic=floatingip['tenant_id']), topic=port['tenant_id'])) topic=router['tenant_id'])) id=router_id, topic=router['tenant_id']))",92,37
openstack%2Fceilometer~master~I80999b077f867f4c60a918e1c9b80956daebe3de,openstack/ceilometer,master,I80999b077f867f4c60a918e1c9b80956daebe3de,split partitioning polling tests,MERGED,2017-12-11 17:34:11.000000000,2017-12-12 21:45:17.000000000,2017-12-12 21:45:17.000000000,"[{'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 17:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d92ceba8ee154d9db24feef12570dee313a2a995', 'message': 'split partitioning polling tests\n\nonly setup partitioning when the test requires it\n\nChange-Id: I80999b077f867f4c60a918e1c9b80956daebe3de\n'}, {'number': 2, 'created': '2017-12-11 17:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/319fb221f7b35e6e92735a73ecf2e5666ee366d4', 'message': 'split partitioning polling tests\n\nonly setup partitioning when the test requires it\n\nChange-Id: I80999b077f867f4c60a918e1c9b80956daebe3de\n'}, {'number': 3, 'created': '2017-12-11 17:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0f9c3c11d7762fe01e7d398d45df85e073ae67e6', 'message': 'split partitioning polling tests\n\nonly setup partitioning when the test requires it\n\nCloses-Bug: #1732228\nChange-Id: I80999b077f867f4c60a918e1c9b80956daebe3de\n'}, {'number': 4, 'created': '2017-12-11 17:39:10.000000000', 'files': ['ceilometer/tests/unit/polling/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9eb1638dcc86aef6d933624c42304f8e313a4bce', 'message': 'split partitioning polling tests\n\nonly setup partitioning when the test requires it\n\nCloses-Bug: #1732228\nChange-Id: I80999b077f867f4c60a918e1c9b80956daebe3de\n'}]",0,527187,9eb1638dcc86aef6d933624c42304f8e313a4bce,10,3,4,6537,,,0,"split partitioning polling tests

only setup partitioning when the test requires it

Closes-Bug: #1732228
Change-Id: I80999b077f867f4c60a918e1c9b80956daebe3de
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/87/527187/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/unit/polling/test_manager.py'],1,d92ceba8ee154d9db24feef12570dee313a2a995,bug/1732228,"class BaseAgent(base.BaseTestCase): super(BaseAgent, self).setUp() super(BaseAgent, self).tearDown() class TestPollingAgent(BaseAgent): def setUp(self): super(TestPollingAgent, self).setUp() self.mgr = self.create_manager() self.mgr.extensions = self.create_extension_list() self.setup_polling() class TestPollingAgentPartitioned(BaseAgent): def setUp(self): super(TestPollingAgentPartitioned, self).setUp() self.CONF.set_override(""backend_url"", ""zake://"", ""coordination"") self.hashring = mock.MagicMock() self.hashring.belongs_to_self = mock.MagicMock() self.hashring.belongs_to_self.return_value = True self.mgr = self.create_manager() self.mgr.extensions = self.create_extension_list() self.mgr.hashrings = mock.MagicMock() self.mgr.hashrings.__getitem__.return_value = self.hashring self.setup_polling() ","class TestPollingAgent(base.BaseTestCase): super(TestPollingAgent, self).setUp() self.CONF.set_override(""backend_url"", ""zake://"", ""coordination"") self.mgr = self.create_manager() self.mgr.extensions = self.create_extension_list() self.hashring = mock.MagicMock() self.hashring.belongs_to_self = mock.MagicMock() self.hashring.belongs_to_self.return_value = True self.mgr.hashrings = mock.MagicMock() self.mgr.hashrings.__getitem__.return_value = self.hashring self.setup_polling() super(TestPollingAgent, self).tearDown()",28,14
openstack%2Fnetworking-ovn~master~I53a4c1ba47785f6600b2794a6ad0172895802917,openstack/networking-ovn,master,I53a4c1ba47785f6600b2794a6ad0172895802917,networking-ovn hides some other xtrace logs improperly,MERGED,2017-12-06 07:09:56.000000000,2017-12-12 21:43:31.000000000,2017-12-12 21:43:31.000000000,"[{'_account_id': 6773}, {'_account_id': 10237}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-12-06 07:09:56.000000000', 'files': ['devstack/plugin.sh', 'devstack/lib/networking-ovn'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/900242aebf64826255ee9da5204d84905fe374a9', 'message': 'networking-ovn hides some other xtrace logs improperly\n\nplugin.sh and lib/networking-ovn use variable of same name XTRACE,\nlib/networking-ovn overrides it and then plugin.sh restores the shell\nenvironment recorded by lib/networking-ovn with xtrace off which is\nnot what we want.\n\nChange-Id: I53a4c1ba47785f6600b2794a6ad0172895802917\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",0,525917,900242aebf64826255ee9da5204d84905fe374a9,8,4,1,23458,,,0,"networking-ovn hides some other xtrace logs improperly

plugin.sh and lib/networking-ovn use variable of same name XTRACE,
lib/networking-ovn overrides it and then plugin.sh restores the shell
environment recorded by lib/networking-ovn with xtrace off which is
not what we want.

Change-Id: I53a4c1ba47785f6600b2794a6ad0172895802917
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/17/525917/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/networking-ovn', 'devstack/plugin.sh']",2,900242aebf64826255ee9da5204d84905fe374a9,xtrace,_XTRACE_OVN_PLUGIN=$(set +o | grep xtrace)$_XTRACE_OVN_PLUGIN,XTRACE=$(set +o | grep xtrace)$XTRACE,6,3
openstack%2Frequirements~stable%2Fpike~I02fe619f7d6a45ca64e88dab5f541c1b2e23cbc5,openstack/requirements,stable/pike,I02fe619f7d6a45ca64e88dab5f541c1b2e23cbc5,update constraint for oslo.messaging to new release 5.30.2,MERGED,2017-12-11 21:56:36.000000000,2017-12-12 21:39:42.000000000,2017-12-12 21:39:42.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 21:56:36.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fcb62087aba68d2eb4948f4977e3cc16aaf1bfba', 'message': 'update constraint for oslo.messaging to new release 5.30.2\n\nChange-Id: I02fe619f7d6a45ca64e88dab5f541c1b2e23cbc5\nmeta:version: 5.30.2\nmeta:diff-start: -\nmeta:series: pike\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nmeta:release:Change-Id: I5ab414eea74bd4ab8dedb59a5f30de23d42b8211\nmeta:release:Code-Review+1: Ken Giusti <kgiusti@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Code-Review+1: gordon chung <gord@live.ca>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,527250,fcb62087aba68d2eb4948f4977e3cc16aaf1bfba,8,3,1,11131,,,0,"update constraint for oslo.messaging to new release 5.30.2

Change-Id: I02fe619f7d6a45ca64e88dab5f541c1b2e23cbc5
meta:version: 5.30.2
meta:diff-start: -
meta:series: pike
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Commit: ChangBo Guo(gcb) <eric.guo@easystack.cn>
meta:release:Change-Id: I5ab414eea74bd4ab8dedb59a5f30de23d42b8211
meta:release:Code-Review+1: Ken Giusti <kgiusti@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Code-Review+1: gordon chung <gord@live.ca>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/50/527250/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,fcb62087aba68d2eb4948f4977e3cc16aaf1bfba,new-release,oslo.messaging===5.30.2,oslo.messaging===5.30.1,1,1
openstack%2Fnova~stable%2Fpike~I6874567a14beb9b029765bf49067af6de17f2bd2,openstack/nova,stable/pike,I6874567a14beb9b029765bf49067af6de17f2bd2,[placement] Fix foreign key constraint error,MERGED,2017-12-05 14:17:03.000000000,2017-12-12 21:39:36.000000000,2017-12-12 21:39:36.000000000,"[{'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 6125}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 26580}]","[{'number': 1, 'created': '2017-12-05 14:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db49d9a1a7c5411c1e60327f6e486d986e07f748', 'message': ""[placement] Fix foreign key constraint error\n\nWhen deleting a resource provider,\nif there are traits on the resource provider,\na foreign key constraint error occurs.\n\nSo add deleting trait associations for the resource provider\n(records in the 'resource_provider_traits' table)\nwhen deleting the resource provider.\n\nConflicts:\n      nova/objects/resource_provider.py\n\nNOTE(mriedem): The conflict is due to changes introduced by\nb10f11d7e8e1afb7a12a470f92c42bf3c23eca95 in Queens which\nare not needed in Pike. The test also needed to change since\n1df5aad91017b4a7ef51fb6efac29e671f7cc7eb is not in Pike.\n\nChange-Id: I6874567a14beb9b029765bf49067af6de17f2bd2\nCloses-Bug: #1727719\n(cherry picked from commit 5de3317d68df8fdc6fdaff62baa62822c669bb93)\n""}, {'number': 2, 'created': '2017-12-05 23:37:06.000000000', 'files': ['nova/objects/resource_provider.py', 'nova/tests/unit/objects/test_resource_provider.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fc225f16a12471bfde9d5d0d378e69fba201e58a', 'message': ""[placement] Fix foreign key constraint error\n\nWhen deleting a resource provider,\nif there are traits on the resource provider,\na foreign key constraint error occurs.\n\nSo add deleting trait associations for the resource provider\n(records in the 'resource_provider_traits' table)\nwhen deleting the resource provider.\n\nConflicts:\n      nova/objects/resource_provider.py\n\nNOTE(mriedem): The conflict is due to changes introduced by\nb10f11d7e8e1afb7a12a470f92c42bf3c23eca95 in Queens which\nare not needed in Pike. The test also needed to change since\n1df5aad91017b4a7ef51fb6efac29e671f7cc7eb is not in Pike.\n\nChange-Id: I6874567a14beb9b029765bf49067af6de17f2bd2\nCloses-Bug: #1727719\n(cherry picked from commit 5de3317d68df8fdc6fdaff62baa62822c669bb93)\n""}]",2,525620,fc225f16a12471bfde9d5d0d378e69fba201e58a,35,15,2,6873,,,0,"[placement] Fix foreign key constraint error

When deleting a resource provider,
if there are traits on the resource provider,
a foreign key constraint error occurs.

So add deleting trait associations for the resource provider
(records in the 'resource_provider_traits' table)
when deleting the resource provider.

Conflicts:
      nova/objects/resource_provider.py

NOTE(mriedem): The conflict is due to changes introduced by
b10f11d7e8e1afb7a12a470f92c42bf3c23eca95 in Queens which
are not needed in Pike. The test also needed to change since
1df5aad91017b4a7ef51fb6efac29e671f7cc7eb is not in Pike.

Change-Id: I6874567a14beb9b029765bf49067af6de17f2bd2
Closes-Bug: #1727719
(cherry picked from commit 5de3317d68df8fdc6fdaff62baa62822c669bb93)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/525620/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/resource_provider.py', 'nova/tests/unit/objects/test_resource_provider.py']",2,db49d9a1a7c5411c1e60327f6e486d986e07f748,bug/1727719," def test_destroy_with_traits(self): """"""Test deleting a resource provider that has a trait successfully. """""" rp = resource_provider.ResourceProvider(self.context, uuid=uuids.rp, name='fake_rp1') rp.create() custom_trait = resource_provider.Trait(self.context, uuid=uuids.trait, name='CUSTOM_TRAIT_1') custom_trait.create() rp.set_traits([custom_trait]) trl = rp.get_traits() self.assertEqual(1, len(trl)) # Delete a resource provider that has a trait assosiation. rp.destroy() # Assert the record has been deleted # in 'resource_provider_traits' table # after Resource Provider object has been destroyed. trl = rp.get_traits() self.assertEqual(0, len(trl)) # Assert that NotFound exception is raised. self.assertRaises(exception.NotFound, resource_provider.ResourceProvider.get_by_uuid, self.context, uuids.rp) ",,35,2
openstack%2Fpython-zaqarclient~master~Id5de420cbccc27ced25a595b9502b9d13b77b373,openstack/python-zaqarclient,master,Id5de420cbccc27ced25a595b9502b9d13b77b373,Remove -U from pip install,MERGED,2017-12-02 18:20:22.000000000,2017-12-12 21:33:17.000000000,2017-12-12 21:33:17.000000000,"[{'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 7385}, {'_account_id': 8846}, {'_account_id': 12321}, {'_account_id': 15054}, {'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-02 18:20:22.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/a827823aed8b76a9dfe45a39c6b43210a108ffb3', 'message': ""Remove -U from pip install\n\n'pip install -U' ugrades specified packages, this is not necessary\nsince we use constraints, remove the parameter '-U' from the line.\n\nWith tools/tox_install.sh - which a previous change of mine removed -\nthe -U was not harmful, but with the current set up, it might cause\nupgrades, so remove it.\n\nChange-Id: Id5de420cbccc27ced25a595b9502b9d13b77b373\n""}]",0,524885,a827823aed8b76a9dfe45a39c6b43210a108ffb3,6,10,1,6547,,,0,"Remove -U from pip install

'pip install -U' ugrades specified packages, this is not necessary
since we use constraints, remove the parameter '-U' from the line.

With tools/tox_install.sh - which a previous change of mine removed -
the -U was not harmful, but with the current set up, it might cause
upgrades, so remove it.

Change-Id: Id5de420cbccc27ced25a595b9502b9d13b77b373
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/85/524885/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a827823aed8b76a9dfe45a39c6b43210a108ffb3,rm-tox_install,install_command = pip install {opts} {packages},install_command = pip install -U {opts} {packages},1,1
openstack%2Fhorizon~master~Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9,openstack/horizon,master,Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9,Allow to skip API calls to Neutron in instance tables,MERGED,2017-10-10 01:32:49.000000000,2017-12-12 21:28:20.000000000,2017-12-12 21:28:20.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 6484}, {'_account_id': 11885}, {'_account_id': 12826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-10 01:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5e5cc47a01d20a3d8849d12cc4afdce204c41514', 'message': ""Remove useless API calls to Neutron\n\nNow instance panel is sending API calls to Neutron to get the addresses\ninfo about network. But actually, the response from Nova server list\nwith detailed API call has already got the addresses information. So\nit's not necessary to call the function.\n\nCloses-Bug: #1722417\n\nChange-Id: Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9\n""}, {'number': 2, 'created': '2017-10-10 01:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ce2855e5bebd6da8d5f00d586b5e383c89c5456f', 'message': ""Remove useless API calls to Neutron\n\nNow instance panel is sending API calls to Neutron to get the addresses\ninfo about network. But actually, the response from Nova server list\nwith detailed API call has already got the addresses information. So\nit's not necessary to call the function.\n\nCloses-Bug: #1722417\n\nChange-Id: Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9\n""}, {'number': 3, 'created': '2017-12-02 19:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b72c75a9c0a803c05b86849b4a345a926b5d9f43', 'message': 'Allow to skip API calls to Neutron in instance tables\n\nNow instance panel is sending API calls to Neutron to get the addresses\ninfo about network. It take some time until Nova network info cache is\nsynced when IP address operation like floating IP association is made\nin Neutron. The API calls to Neutron exist from this reason.\n\nHowever, it retrieves a full list of port, so it can potentially leads\nto performance issues in large deployments. This commit adds a setting\nflag to control whether API calls to Neutron is used or skipped in\nthe project instance table.\n\nThis commits drops a call of servers_update_addresses() in the admin\ninstance table. In the admin instance table there is no need to retrieve\nIP addresses from neutron because the main purpose of the admin panel is\nto see all instances and IP addresses in nova network info cache will be\nsynced soon.\n\nCloses-Bug: #1722417\nCo-Authored-By: Akihiro Motoki <amotoki@gmail.com>\nChange-Id: Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9\n'}, {'number': 4, 'created': '2017-12-11 12:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0a4e64332401fe32db19363240e1b6164fed51f8', 'message': 'Allow to skip API calls to Neutron in instance tables\n\nNow instance panel is sending API calls to Neutron to get the addresses\ninfo about network. It take some time until Nova network info cache is\nsynced when IP address operation like floating IP association is made\nin Neutron. The API calls to Neutron exist from this reason.\n\nHowever, it retrieves a full list of port, so it can potentially leads\nto performance issues in large deployments. This commit adds a setting\nflag to control whether API calls to Neutron is used or skipped in\nthe project instance table.\n\nThis commits drops a call of servers_update_addresses() in the admin\ninstance table. In the admin instance table there is no need to retrieve\nIP addresses from neutron because the main purpose of the admin panel is\nto see all instances and IP addresses in nova network info cache will be\nsynced soon.\n\nCloses-Bug: #1722417\nCo-Authored-By: Akihiro Motoki <amotoki@gmail.com>\nChange-Id: Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9\n'}, {'number': 5, 'created': '2017-12-11 14:19:19.000000000', 'files': ['releasenotes/notes/setting-retrieve-instance-ip-addresses-b9db6703d8b010c8.yaml', 'doc/source/configuration/settings.rst', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/admin/instances/views.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/project/instances/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a42f58de50c84235f649d957ac925780d365e3db', 'message': 'Allow to skip API calls to Neutron in instance tables\n\nNow instance panel is sending API calls to Neutron to get the addresses\ninfo about network. It take some time until Nova network info cache is\nsynced when IP address operation like floating IP association is made\nin Neutron. The API calls to Neutron exist from this reason.\n\nHowever, it retrieves a full list of port, so it can potentially leads\nto performance issues in large deployments. This commit adds a setting\nflag to control whether API calls to Neutron is used or skipped in\nthe project instance table.\n\nThis commits drops a call of servers_update_addresses() in the admin\ninstance table. In the admin instance table there is no need to retrieve\nIP addresses from neutron because the main purpose of the admin panel is\nto see all instances and IP addresses in nova network info cache will be\nsynced soon.\n\nCloses-Bug: #1722417\nCo-Authored-By: Akihiro Motoki <amotoki@gmail.com>\nChange-Id: Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9\n'}]",4,510718,a42f58de50c84235f649d957ac925780d365e3db,35,8,5,6484,,,0,"Allow to skip API calls to Neutron in instance tables

Now instance panel is sending API calls to Neutron to get the addresses
info about network. It take some time until Nova network info cache is
synced when IP address operation like floating IP association is made
in Neutron. The API calls to Neutron exist from this reason.

However, it retrieves a full list of port, so it can potentially leads
to performance issues in large deployments. This commit adds a setting
flag to control whether API calls to Neutron is used or skipped in
the project instance table.

This commits drops a call of servers_update_addresses() in the admin
instance table. In the admin instance table there is no need to retrieve
IP addresses from neutron because the main purpose of the admin panel is
to see all instances and IP addresses in nova network info cache will be
synced soon.

Closes-Bug: #1722417
Co-Authored-By: Akihiro Motoki <amotoki@gmail.com>
Change-Id: Ie16784eb6352f70ab644dc8b6ea03fc6a881d3f9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/18/510718/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/views.py']",2,5e5cc47a01d20a3d8849d12cc4afdce204c41514,bug/1722417,," try: api.network.servers_update_addresses(self.request, instances) except Exception: exceptions.handle( self.request, message=_('Unable to retrieve IP addresses from Neutron.'), ignore=True) def _task_update_addresses(): try: api.network.servers_update_addresses(self.request, [instance]) except Exception: msg = _('Unable to retrieve IP addresses from Neutron for ' 'instance ""%(name)s"" (%(id)s).') \ % {'name': instance.name, 'id': instance_id} exceptions.handle(self.request, msg, ignore=True) e.submit(fn=_task_update_addresses)",24,118
openstack%2Fheat~master~If0c98ffcfceae395ab2443356aea3904edaf7b4e,openstack/heat,master,If0c98ffcfceae395ab2443356aea3904edaf7b4e,[policy in code] part 5 (software-*),MERGED,2017-10-06 11:26:14.000000000,2017-12-12 21:28:03.000000000,2017-12-12 21:28:03.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 5046}, {'_account_id': 7385}, {'_account_id': 12404}, {'_account_id': 19741}, {'_account_id': 19930}, {'_account_id': 22348}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-10-06 11:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/82472ca9a6476f38856ef5ce4812c7d286ae0a50', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 2, 'created': '2017-10-06 18:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/18e994e54b7681c8f93d8ded33292a1835a0d4c3', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 3, 'created': '2017-10-11 12:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c872e022e201c3c76d6591f1088913453e85d4b1', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 4, 'created': '2017-10-17 16:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d38434c4ed0fe6fe9f210c71ee6c9f8d92b90d43', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 5, 'created': '2017-11-16 02:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4d0428105247a822c6fdf3ef7aae768c7c3356e3', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 6, 'created': '2017-11-21 08:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e1ad435bad44a982cff598dbc8db65335619648f', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 7, 'created': '2017-11-30 18:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1c3bd741095aa44019a11ba990905a2e9bc844e6', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}, {'number': 8, 'created': '2017-12-07 01:11:49.000000000', 'files': ['heat/policies/__init__.py', 'heat/policies/software_deployments.py', 'heat/policies/software_configs.py', 'heat/api/openstack/v1/software_deployments.py', 'etc/heat/policy.json', 'heat/api/openstack/v1/software_configs.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0e45db46baf8b99951a2d6f7eb4cb0b0aba6e84a', 'message': '[policy in code] part 5 (software-*)\n\nAdd software_deployments rules, software_configs rules.\nPartially-Implements: bp policy-in-code\n\nChange-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e\n'}]",0,510076,0e45db46baf8b99951a2d6f7eb4cb0b0aba6e84a,43,9,8,12404,,,0,"[policy in code] part 5 (software-*)

Add software_deployments rules, software_configs rules.
Partially-Implements: bp policy-in-code

Change-Id: If0c98ffcfceae395ab2443356aea3904edaf7b4e
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/510076/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/policies/__init__.py', 'heat/policies/software_deployments.py', 'heat/policies/software_configs.py', 'heat/api/openstack/v1/software_deployments.py', 'etc/heat/policy.json', 'heat/api/openstack/v1/software_configs.py']",6,82472ca9a6476f38856ef5ce4812c7d286ae0a50,policy-and-docs-in-code, @util.registered_policy_enforce @util.registered_policy_enforce @util.registered_policy_enforce @util.registered_policy_enforce @util.registered_policy_enforce, @util.policy_enforce @util.policy_enforce @util.policy_enforce @util.policy_enforce @util.policy_enforce,186,24
openstack%2Fopenstack-helm~master~I2577d9c435be3688fc6ebc02dc97d809861b00da,openstack/openstack-helm,master,I2577d9c435be3688fc6ebc02dc97d809861b00da,[zuul] Make openstack-helm-dev-deploy job gated,MERGED,2017-12-11 23:39:19.000000000,2017-12-12 21:25:41.000000000,2017-12-12 20:36:40.000000000,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-12-11 23:39:19.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/df2f510a4d11d17aa9933fc15975fa4b6a6f6336', 'message': '[zuul] Make openstack-helm-dev-deploy job gated\n\nThis PS updates .zuul.yaml to make the voting job\nopenstack-helm-dev-deploy a gate check, as that is the infra\nconvention [0]:\n\n""Non-voting jobs should only be added to check queues."" (So\nvoting jobs should be added to both.)\n\nWhile there are currently openstack-health statistics for the\njob yet, going off the following data:\n\n    http://zuulv3.openstack.org/builds.html?job_name=openstack-helm-dev-deploy\n\nthe job currently has a roughly ~83% success rate\n(11 fail, 25 pass, 36 total).\n\n[0] https://docs.openstack.org/infra/manual/creators.html#non-voting-jobs\n\nChange-Id: I2577d9c435be3688fc6ebc02dc97d809861b00da\n'}]",0,527265,df2f510a4d11d17aa9933fc15975fa4b6a6f6336,12,4,1,23186,,,0,"[zuul] Make openstack-helm-dev-deploy job gated

This PS updates .zuul.yaml to make the voting job
openstack-helm-dev-deploy a gate check, as that is the infra
convention [0]:

""Non-voting jobs should only be added to check queues."" (So
voting jobs should be added to both.)

While there are currently openstack-health statistics for the
job yet, going off the following data:

    http://zuulv3.openstack.org/builds.html?job_name=openstack-helm-dev-deploy

the job currently has a roughly ~83% success rate
(11 fail, 25 pass, 36 total).

[0] https://docs.openstack.org/infra/manual/creators.html#non-voting-jobs

Change-Id: I2577d9c435be3688fc6ebc02dc97d809861b00da
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/65/527265/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,df2f510a4d11d17aa9933fc15975fa4b6a6f6336,zuul-v3-update, - openstack-helm-dev-deploy,,1,0
openstack%2Fopenstack-ansible-tests~stable%2Fpike~I4475e4dfe13acb4c88444f1f7aa88272bf87f6ee,openstack/openstack-ansible-tests,stable/pike,I4475e4dfe13acb4c88444f1f7aa88272bf87f6ee,Skip failures when collecting nic setups,MERGED,2017-12-08 21:07:54.000000000,2017-12-12 21:11:30.000000000,2017-12-12 21:11:30.000000000,"[{'_account_id': 538}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-08 21:07:54.000000000', 'files': ['test-log-collect.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/5b2bad09402d37bf225bd1ce607b037e8ee79dbd', 'message': 'Skip failures when collecting nic setups\n\nThe ethtool command can fail when run against some devices in some\nconfigurations. This change simply makes the test collections pass\nno matter the interface configuration.\n\nChange-Id: I4475e4dfe13acb4c88444f1f7aa88272bf87f6ee\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit f0f9f32975bce6f698a1934564c7d7e50c33eb82)\n'}]",0,526775,5b2bad09402d37bf225bd1ce607b037e8ee79dbd,9,4,1,7353,,,0,"Skip failures when collecting nic setups

The ethtool command can fail when run against some devices in some
configurations. This change simply makes the test collections pass
no matter the interface configuration.

Change-Id: I4475e4dfe13acb4c88444f1f7aa88272bf87f6ee
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit f0f9f32975bce6f698a1934564c7d7e50c33eb82)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/75/526775/1 && git format-patch -1 --stdout FETCH_HEAD,['test-log-collect.sh'],1,5b2bad09402d37bf225bd1ce607b037e8ee79dbd,," ethtool -k ${interface} > ""${WORKING_DIR}/logs/ethtool-${interface}-cfg.txt"" || true echo ""No ethtool available"" | tee -a ""${WORKING_DIR}/logs/ethtool-${interface}-cfg.txt"""," ethtool -k ${interface} > ""${WORKING_DIR}/logs/ethtool-${interface}-cfg.txt"" echo ""No ethtool available"" | tee -a ""${WORKING_DIR}/logs/no-ethtool.txt""",2,3
openstack%2Fopenstack-manuals~stable%2Focata~I9a0aea36a25f5cd298a92601a8f6de14476f2e21,openstack/openstack-manuals,stable/ocata,I9a0aea36a25f5cd298a92601a8f6de14476f2e21,"[tools] Build user-guide, admin-guide and cli-reference",MERGED,2017-12-11 21:28:02.000000000,2017-12-12 21:09:54.000000000,2017-12-12 21:09:54.000000000,"[{'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 21:28:02.000000000', 'files': ['tools/build-all-rst.sh'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/87d94ae93ba756c6ae4520cdb31be3db220276b3', 'message': '[tools] Build user-guide, admin-guide and cli-reference\n\nChange-Id: I9a0aea36a25f5cd298a92601a8f6de14476f2e21\nImplements: blueprint retention-policy\n'}]",0,527247,87d94ae93ba756c6ae4520cdb31be3db220276b3,7,3,1,20156,,,0,"[tools] Build user-guide, admin-guide and cli-reference

Change-Id: I9a0aea36a25f5cd298a92601a8f6de14476f2e21
Implements: blueprint retention-policy
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/527247/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-all-rst.sh'],1,87d94ae93ba756c6ae4520cdb31be3db220276b3,bp/retention-policy,for guide in user-guide admin-guide cli-reference networking-guide config-reference; do,for guide in networking-guide config-reference; do,1,1
openstack%2Fkolla~master~Iefeb4658b6633c694495e1de3aa26af63693cb29,openstack/kolla,master,Iefeb4658b6633c694495e1de3aa26af63693cb29,neutron-server-opendaylight: make it buildable on non-x86,MERGED,2017-12-04 13:43:38.000000000,2017-12-12 21:09:21.000000000,2017-12-12 21:09:21.000000000,"[{'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 24043}, {'_account_id': 26556}]","[{'number': 1, 'created': '2017-12-04 13:43:38.000000000', 'files': ['docker/neutron/neutron-server-opendaylight/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7a170f8930411379923131039831147bdcff1c61', 'message': 'neutron-server-opendaylight: make it buildable on non-x86\n\nWhen built from source JPEG headers are needed on !x86-64 architectures.\n\nChange-Id: Iefeb4658b6633c694495e1de3aa26af63693cb29\n'}]",0,525183,7a170f8930411379923131039831147bdcff1c61,12,6,1,24072,,,0,"neutron-server-opendaylight: make it buildable on non-x86

When built from source JPEG headers are needed on !x86-64 architectures.

Change-Id: Iefeb4658b6633c694495e1de3aa26af63693cb29
",git fetch https://review.opendev.org/openstack/kolla refs/changes/83/525183/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/neutron/neutron-server-opendaylight/Dockerfile.j2'],1,7a170f8930411379923131039831147bdcff1c61,to-merge/neutron-source-nonx86," {% if base_arch not in ['x86_64'] %} {% if base_distro in ['centos', 'oraclelinux', 'rhel'] %} {% set neutron_server_opendaylight_packages = [ 'libjpeg-devel' ] %} {% elif base_distro in ['debian', 'ubuntu'] %} {% set neutron_server_opendaylight_packages = [ 'libjpeg-dev' ] %} {% endif %} {{ macros.install_packages(neutron_server_opendaylight_packages | customizable(""packages"")) }} {% endif %} ",,14,0
openstack%2Fironic-python-agent~master~Id0223ef1417f6e419770ceb56b2a3b80c6118a85,openstack/ironic-python-agent,master,Id0223ef1417f6e419770ceb56b2a3b80c6118a85,Catch OSError thrown when hexdump is missing,MERGED,2017-11-15 22:17:45.000000000,2017-12-12 21:08:13.000000000,2017-12-12 21:08:13.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 13689}, {'_account_id': 14760}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-15 22:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0c1d6804765763bf9014c9748a8055244e4fec79', 'message': 'Catch OSError thrown when hexdump is missing\n\nPatch I89597fe4a704686fe31c064c3443fd8404a300e5 introduced\na new requirement via a pre-existing ironic-lib method being\ncalled that utilizes hexdump. Hexdump is not always present\nand since we did not explicitly call it out as a new\nrequirement, we should at least somewhat gracefully handle\nthe exception.\n\nChange-Id: Id0223ef1417f6e419770ceb56b2a3b80c6118a85\nCloses-Bug: #1732470\n'}, {'number': 2, 'created': '2017-11-18 17:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4d426292c242d53b1a7c1207ec17786971b2a7e9', 'message': 'Catch OSError thrown when hexdump is missing\n\nPatch I89597fe4a704686fe31c064c3443fd8404a300e5 introduced\na new requirement via a pre-existing ironic-lib method being\ncalled that utilizes hexdump. Hexdump is not always present\nand since we did not explicitly call it out as a new\nrequirement, we should at least somewhat gracefully handle\nthe exception.\n\nChange-Id: Id0223ef1417f6e419770ceb56b2a3b80c6118a85\nCloses-Bug: #1732470\n'}, {'number': 3, 'created': '2017-11-19 06:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/937c6c078b2ffc039c562b7e09d4488aa96167f4', 'message': 'Catch OSError thrown when hexdump is missing\n\nChange c5bf7b088f1ec776b788a81f2775e1b2577720e8 introduced\na new requirement via a pre-existing ironic-lib method being\ncalled that utilizes hexdump. Hexdump is not always present\nand since we did not explicitly call it out as a new\nrequirement, we should at least somewhat gracefully handle\nthe exception.\n\nChange-Id: Id0223ef1417f6e419770ceb56b2a3b80c6118a85\nCloses-Bug: #1732470\n'}, {'number': 4, 'created': '2017-11-21 18:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/179abd3c097a2ce799e10127dc8d645991c3a5ba', 'message': 'Catch OSError thrown when hexdump is missing\n\nChange c5bf7b088f1ec776b788a81f2775e1b2577720e8 introduced\na new requirement via a pre-existing ironic-lib method being\ncalled that utilizes hexdump. Hexdump is not always present\nand since we did not explicitly call it out as a new\nrequirement, we should at least somewhat gracefully handle\nthe exception.\n\nChange-Id: Id0223ef1417f6e419770ceb56b2a3b80c6118a85\nCloses-Bug: #1732470\n'}, {'number': 5, 'created': '2017-12-11 22:12:08.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_standby.py', 'ironic_python_agent/extensions/standby.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/71fda732d26b519cad11b1629a92f5c916a3df80', 'message': 'Catch OSError thrown when hexdump is missing\n\nChange c5bf7b088f1ec776b788a81f2775e1b2577720e8 introduced\na new requirement via a pre-existing ironic-lib method being\ncalled that utilizes hexdump. Hexdump is not always present\nand since we did not explicitly call it out as a new\nrequirement, we should at least somewhat gracefully handle\nthe exception.\n\nChange-Id: Id0223ef1417f6e419770ceb56b2a3b80c6118a85\nCloses-Bug: #1732470\n'}]",7,520223,71fda732d26b519cad11b1629a92f5c916a3df80,27,6,5,11655,,,0,"Catch OSError thrown when hexdump is missing

Change c5bf7b088f1ec776b788a81f2775e1b2577720e8 introduced
a new requirement via a pre-existing ironic-lib method being
called that utilizes hexdump. Hexdump is not always present
and since we did not explicitly call it out as a new
requirement, we should at least somewhat gracefully handle
the exception.

Change-Id: Id0223ef1417f6e419770ceb56b2a3b80c6118a85
Closes-Bug: #1732470
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/23/520223/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/extensions/standby.py'],1,0c1d6804765763bf9014c9748a8055244e4fec79,bug/1732470," try: # NOTE(TheJulia): ironic-lib disk_utils.get_disk_identifier # can raise OSError if hexdump is not found. root_uuid = disk_utils.get_disk_identifier(device) result_msg = msg + 'root_uuid={}' message = result_msg.format(image_info['id'], device, root_uuid) except OSError as e: LOG.info('Failed to call get_disk_identifier: possibly hexdump ' 'is not present: {}').format(e) message = result_msg.format(image_info['id'], device)"," root_uuid = disk_utils.get_disk_identifier(device) result_msg = msg + 'root_uuid={}' message = result_msg.format(image_info['id'], device, root_uuid)",10,3
openstack%2Fproject-config~master~Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a,openstack/project-config,master,Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a,Import ansible-role-redhat-subscription (Part 1),MERGED,2017-12-11 19:50:49.000000000,2017-12-12 21:07:43.000000000,2017-12-12 21:07:43.000000000,"[{'_account_id': 3153}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27253}]","[{'number': 1, 'created': '2017-12-11 19:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f449018974f5199762530ea5716798a9a4d122d2', 'message': 'Add ansible-role-redhat-subscription to zuul/main\n\n... so we can import the repo later and run some zuul jobs.\n\nChange-Id: Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a\n'}, {'number': 2, 'created': '2017-12-11 19:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f8f919b243d2af686e509aa1963c683263f82792', 'message': ""Import ansible-role-redhat-subscription (Part 1)\n\nAfter discussing with the Ansible role author, Sam Doran, we would like\nto move ansible-role-redhat-subscription to OpenStack namespace, so we\ncan use Infra resources (CI, code review, etc) instead of Github where\nit seems there is no central place for Ansible roles at this time.\n\nThis role will be consumed by TripleO but can be consumed by anyone\nwithout any dependency on TripleO, that's why we don't want it under\nTripleO's governance.\n\nSam Doran will remain the main maintainer for now and will be part of\nansible-role-redhat-subscription-core in Gerrit.\n\nChange-Id: Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a\n""}, {'number': 3, 'created': '2017-12-11 20:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2e152caba352a103241d2d5cb2055379092d2568', 'message': ""Import ansible-role-redhat-subscription (Part 1)\n\nAfter discussing with the Ansible role author, Sam Doran, we would like\nto move ansible-role-redhat-subscription to OpenStack namespace, so we\ncan use Infra resources (CI, code review, etc) instead of Github where\nit seems there is no central place for Ansible roles at this time.\n\nThis role will be consumed by TripleO but can be consumed by anyone\nwithout any dependency on TripleO, that's why we don't want it under\nTripleO's governance.\n\nSam Doran will remain the main maintainer for now and will be part of\nansible-role-redhat-subscription-core in Gerrit.\n\nChange-Id: Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a\n""}, {'number': 4, 'created': '2017-12-11 20:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a285798ada2f871d68e3713771340060f4003492', 'message': ""Import ansible-role-redhat-subscription (Part 1)\n\nAfter discussing with the Ansible role author, Sam Doran, we would like\nto move ansible-role-redhat-subscription to OpenStack namespace, so we\ncan use Infra resources (CI, code review, etc) instead of Github where\nit seems there is no central place for Ansible roles at this time.\n\nThis role will be consumed by TripleO but can be consumed by anyone\nwithout any dependency on TripleO, that's why we don't want it under\nTripleO's governance.\n\nSam Doran will remain the main maintainer for now and will be part of\nansible-role-redhat-subscription-core in Gerrit.\n\nChange-Id: Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a\n""}, {'number': 5, 'created': '2017-12-11 22:10:16.000000000', 'files': ['gerrit/acls/openstack/ansible-role-redhat-subscription.config', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1520b43bd74b0b853f5ab30f8ffc5b7102264477', 'message': ""Import ansible-role-redhat-subscription (Part 1)\n\nAfter discussing with the Ansible role author, Sam Doran, we would like\nto move ansible-role-redhat-subscription to OpenStack namespace, so we\ncan use Infra resources (CI, code review, etc) instead of Github where\nit seems there is no central place for Ansible roles at this time.\n\nThis role will be consumed by TripleO but can be consumed by anyone\nwithout any dependency on TripleO, that's why we don't want it under\nTripleO's governance.\n\nSam Doran will remain the main maintainer for now and will be part of\nansible-role-redhat-subscription-core in Gerrit.\n\nChange-Id: Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a\n""}]",3,527229,1520b43bd74b0b853f5ab30f8ffc5b7102264477,27,7,5,3153,,,0,"Import ansible-role-redhat-subscription (Part 1)

After discussing with the Ansible role author, Sam Doran, we would like
to move ansible-role-redhat-subscription to OpenStack namespace, so we
can use Infra resources (CI, code review, etc) instead of Github where
it seems there is no central place for Ansible roles at this time.

This role will be consumed by TripleO but can be consumed by anyone
without any dependency on TripleO, that's why we don't want it under
TripleO's governance.

Sam Doran will remain the main maintainer for now and will be part of
ansible-role-redhat-subscription-core in Gerrit.

Change-Id: Ic66b155d7c81cef2ce0b1c580c7e61b9ac1dce6a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/29/527229/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul/main.yaml'],1,f449018974f5199762530ea5716798a9a4d122d2,import/ansible-role-rhsm, - openstack/ansible-role-redhat-subscription,,1,0
openstack%2Fmanila~master~I9aee96b9f0c471b96226369721a348bf0fa58a95,openstack/manila,master,I9aee96b9f0c471b96226369721a348bf0fa58a95,Extend .gitignore for linux swap files range,MERGED,2017-12-11 15:26:15.000000000,2017-12-12 21:07:40.000000000,2017-12-12 21:07:40.000000000,"[{'_account_id': 14384}, {'_account_id': 15100}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-12-11 15:26:15.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/manila/commit/de2411dc990f19104fcc034aeb8ada38d1605d1b', 'message': 'Extend .gitignore for linux swap files range\n\nTrivalFix\nUsually, the .swo file will be generated when edit file in linux\nenvrionment, so this is to extend .gitignore for linux swap files\nrange from .saa to .swp.\n\nChange-Id: I9aee96b9f0c471b96226369721a348bf0fa58a95\n'}]",0,527125,de2411dc990f19104fcc034aeb8ada38d1605d1b,16,10,1,25456,,,0,"Extend .gitignore for linux swap files range

TrivalFix
Usually, the .swo file will be generated when edit file in linux
envrionment, so this is to extend .gitignore for linux swap files
range from .saa to .swp.

Change-Id: I9aee96b9f0c471b96226369721a348bf0fa58a95
",git fetch https://review.opendev.org/openstack/manila refs/changes/25/527125/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,de2411dc990f19104fcc034aeb8ada38d1605d1b,trivial-fix,# Linux swap files range from .saa to .swp *.s[a-w][a-p],*.swp,2,1
openstack%2Fceilometer~master~I8b1a4e840e32e1a4052351569aec12f365d39710,openstack/ceilometer,master,I8b1a4e840e32e1a4052351569aec12f365d39710,drop base polling test separation,MERGED,2017-12-11 17:14:12.000000000,2017-12-12 21:07:39.000000000,2017-12-12 21:07:39.000000000,"[{'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 17:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1a49c3a7c2a9d218d6d710f3bdb05deaaf2339d3', 'message': ""drop base polling test separation\n\nwe only have one polling agent and it's difficult to make edits\nhaving half the code in one place and the other half in another\n\nChange-Id: I8b1a4e840e32e1a4052351569aec12f365d39710\n""}, {'number': 2, 'created': '2017-12-11 17:39:10.000000000', 'files': ['ceilometer/tests/unit/polling/agentbase.py', 'ceilometer/tests/unit/polling/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98204af682916f60199e84df047e05048311e012', 'message': ""drop base polling test separation\n\nwe only have one polling agent and it's difficult to make edits\nhaving half the code in one place and the other half in another\n\nChange-Id: I8b1a4e840e32e1a4052351569aec12f365d39710\n""}]",0,527170,98204af682916f60199e84df047e05048311e012,10,4,2,6537,,,0,"drop base polling test separation

we only have one polling agent and it's difficult to make edits
having half the code in one place and the other half in another

Change-Id: I8b1a4e840e32e1a4052351569aec12f365d39710
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/70/527170/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/unit/polling/agentbase.py', 'ceilometer/tests/unit/polling/test_manager.py']",2,1a49c3a7c2a9d218d6d710f3bdb05deaaf2339d3,bug/1732228,"import copy import datetime from keystoneauth1 import exceptions as ka_exceptionsfrom ceilometer import samplefrom ceilometer.tests import basedef default_test_data(name='test'): return sample.Sample( name=name, type=sample.TYPE_CUMULATIVE, unit='', volume=1, user_id='test', project_id='test', resource_id='test_run_tasks', timestamp=datetime.datetime.utcnow().isoformat(), resource_metadata={'name': 'Pollster'}) class TestPollster(plugin_base.PollsterBase): test_data = default_test_data() discovery = None @property def default_discovery(self): return self.discovery def get_samples(self, manager, cache, resources): resources = resources or [] self.samples.append((manager, resources)) self.resources.extend(resources) c = copy.deepcopy(self.test_data) c.resource_metadata['resources'] = resources return [c] class TestPollsterBuilder(TestPollster): TestPollster(self.conf)), self.assertIsInstance(ext.obj, TestPollster) class BatchTestPollster(TestPollster): test_data = default_test_data() discovery = None @property def default_discovery(self): return self.discovery def get_samples(self, manager, cache, resources): resources = resources or [] self.samples.append((manager, resources)) self.resources.extend(resources) for resource in resources: c = copy.deepcopy(self.test_data) c.timestamp = datetime.datetime.utcnow().isoformat() c.resource_id = resource c.resource_metadata['resource'] = resource yield c class TestPollsterKeystone(TestPollster):class TestPollsterPollingException(TestPollster):class TestDiscovery(plugin_base.DiscoveryBase): def discover(self, manager, param=None): self.params.append(param) return self.resources class TestDiscoveryException(plugin_base.DiscoveryBase): def discover(self, manager, param=None): self.params.append(param) raise Exception() class TestPollingAgent(base.BaseTestCase): class Pollster(TestPollster): samples = [] resources = [] test_data = default_test_data() class BatchPollster(BatchTestPollster): samples = [] resources = [] test_data = default_test_data() class PollsterAnother(TestPollster): samples = [] resources = [] test_data = default_test_data('testanother') test_data = default_test_data('testkeystone') test_data = default_test_data('testpollingexception') class Discovery(TestDiscovery): params = [] resources = [] class DiscoveryAnother(TestDiscovery): params = [] resources = [] @property def group_id(self): return 'another_group' class DiscoveryException(TestDiscoveryException): params = [] def setup_polling(self, poll_cfg=None): name = self.cfg2file(poll_cfg or self.polling_cfg) self.CONF.set_override('cfg_file', name, group='polling') self.mgr.polling_manager = manager.PollingManager(self.CONF) super(TestPollingAgent, self).setUp() self.useFixture(fixtures.MockPatch('keystoneclient.v2_0.client.Client', return_value=mock.Mock())) self.CONF = service.prepare_service([], []) self.CONF.set_override(""backend_url"", ""zake://"", ""coordination"") self.CONF.set_override( 'cfg_file', self.path_get('etc/ceilometer/polling_all.yaml'), group='polling' ) self.mgr = self.create_manager() self.mgr.extensions = self.create_extension_list() self.hashring = mock.MagicMock() self.hashring.belongs_to_self = mock.MagicMock() self.hashring.belongs_to_self.return_value = True self.mgr.hashrings = mock.MagicMock() self.mgr.hashrings.__getitem__.return_value = self.hashring self.polling_cfg = { 'sources': [{ 'name': 'test_polling', 'interval': 60, 'meters': ['test'], 'resources': ['test://']}] } self.setup_polling() self.Pollster.samples = [] self.Pollster.discovery = [] self.PollsterAnother.samples = [] self.PollsterAnother.discovery = [] self.Pollster.resources = [] self.PollsterAnother.resources = [] self.Discovery.params = [] self.DiscoveryAnother.params = [] self.DiscoveryException.params = [] self.Discovery.resources = [] self.DiscoveryAnother.resources = [] super(TestPollingAgent, self).tearDown() return [extension.Extension('test', None, None, self.Pollster(self.CONF), ), extension.Extension('testbatch', None, None, self.BatchPollster(self.CONF), ), extension.Extension('testanother', None, None, self.PollsterAnother(self.CONF), ), extension.Extension('testkeystone', None, None, self.PollsterKeystone(self.CONF), ), extension.Extension('testpollingexception', None, None, self.PollsterPollingException(self.CONF), ) ] def create_discoveries(self): return extension.ExtensionManager.make_test_instance( [ extension.Extension( 'testdiscovery', None, None, self.Discovery(self.CONF), ), extension.Extension( 'testdiscoveryanother', None, None, self.DiscoveryAnother(self.CONF), ), extension.Extension( 'testdiscoveryexception', None, None, self.DiscoveryException(self.CONF), ), ], ) @mock.patch('ceilometer.polling.manager.PollingManager') def test_start(self, poll_manager): self.mgr.setup_polling_tasks = mock.MagicMock() self.mgr.run() poll_manager.assert_called_once_with(self.CONF) self.mgr.setup_polling_tasks.assert_called_once_with() self.mgr.terminate() def test_setup_polling_tasks(self): polling_tasks = self.mgr.setup_polling_tasks() self.assertEqual(1, len(polling_tasks)) self.assertIn(60, polling_tasks.keys()) per_task_resources = polling_tasks[60].resources self.assertEqual(1, len(per_task_resources)) self.assertEqual(set(self.polling_cfg['sources'][0]['resources']), set(per_task_resources['test_polling-test'].get({}))) def test_setup_polling_tasks_multiple_interval(self): self.polling_cfg['sources'].append({ 'name': 'test_polling_1', 'interval': 10, 'meters': ['test'], 'resources': ['test://'], }) self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.assertEqual(2, len(polling_tasks)) self.assertIn(60, polling_tasks.keys()) self.assertIn(10, polling_tasks.keys()) def test_setup_polling_tasks_mismatch_counter(self): self.polling_cfg['sources'].append({ 'name': 'test_polling_1', 'interval': 10, 'meters': ['test_invalid'], 'resources': ['invalid://'], }) polling_tasks = self.mgr.setup_polling_tasks() self.assertEqual(1, len(polling_tasks)) self.assertIn(60, polling_tasks.keys()) self.assertNotIn(10, polling_tasks.keys()) def test_setup_polling_task_same_interval(self): self.polling_cfg['sources'].append({ 'name': 'test_polling_1', 'interval': 60, 'meters': ['testanother'], 'resources': ['testanother://'], }) self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.assertEqual(1, len(polling_tasks)) pollsters = polling_tasks.get(60).pollster_matches self.assertEqual(2, len(pollsters)) per_task_resources = polling_tasks[60].resources self.assertEqual(2, len(per_task_resources)) key = 'test_polling-test' self.assertEqual(set(self.polling_cfg['sources'][0]['resources']), set(per_task_resources[key].get({}))) key = 'test_polling_1-testanother' self.assertEqual(set(self.polling_cfg['sources'][1]['resources']), set(per_task_resources[key].get({}))) def test_agent_manager_start(self): mgr = self.create_manager() mgr.extensions = self.mgr.extensions mgr.create_polling_task = mock.MagicMock() mgr.run() self.addCleanup(mgr.terminate) mgr.create_polling_task.assert_called_once_with() def _verify_discovery_params(self, expected): self.assertEqual(expected, self.Discovery.params) self.assertEqual(expected, self.DiscoveryAnother.params) self.assertEqual(expected, self.DiscoveryException.params) def _do_test_per_pollster_discovery(self, discovered_resources, static_resources): self.Pollster.discovery = 'testdiscovery' self.mgr.discoveries = self.create_discoveries() self.Discovery.resources = discovered_resources self.DiscoveryAnother.resources = [d[::-1] for d in discovered_resources] if static_resources: # just so we can test that static + pre_polling amalgamated # override per_pollster self.polling_cfg['sources'][0]['discovery'] = [ 'testdiscoveryanother', 'testdiscoverynonexistent', 'testdiscoveryexception'] self.polling_cfg['sources'][0]['resources'] = static_resources self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) if static_resources: self.assertEqual(set(static_resources + self.DiscoveryAnother.resources), set(self.Pollster.resources)) else: self.assertEqual(set(self.Discovery.resources), set(self.Pollster.resources)) # Make sure no duplicated resource from discovery for x in self.Pollster.resources: self.assertEqual(1, self.Pollster.resources.count(x)) def test_per_pollster_discovery(self): self._do_test_per_pollster_discovery(['discovered_1', 'discovered_2'], []) def test_per_pollster_discovery_overridden_by_per_polling_discovery(self): # ensure static+per_source_discovery overrides per_pollster_discovery self._do_test_per_pollster_discovery(['discovered_1', 'discovered_2'], ['static_1', 'static_2']) def test_per_pollster_discovery_duplicated(self): self._do_test_per_pollster_discovery(['dup', 'discovered_1', 'dup'], []) def test_per_pollster_discovery_overridden_by_duplicated_static(self): self._do_test_per_pollster_discovery(['discovered_1', 'discovered_2'], ['static_1', 'dup', 'dup']) def test_per_pollster_discovery_caching(self): # ensure single discovery associated with multiple pollsters # only called once per polling cycle discovered_resources = ['discovered_1', 'discovered_2'] self.Pollster.discovery = 'testdiscovery' self.PollsterAnother.discovery = 'testdiscovery' self.mgr.discoveries = self.create_discoveries() self.Discovery.resources = discovered_resources self.polling_cfg['sources'][0]['meters'].append('testanother') self.polling_cfg['sources'][0]['resources'] = [] self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) self.assertEqual(1, len(self.Discovery.params)) self.assertEqual(discovered_resources, self.Pollster.resources) self.assertEqual(discovered_resources, self.PollsterAnother.resources) def _do_test_per_polling_discovery(self, discovered_resources, static_resources): self.mgr.discoveries = self.create_discoveries() self.Discovery.resources = discovered_resources self.DiscoveryAnother.resources = [d[::-1] for d in discovered_resources] self.polling_cfg['sources'][0]['discovery'] = [ 'testdiscovery', 'testdiscoveryanother', 'testdiscoverynonexistent', 'testdiscoveryexception'] self.polling_cfg['sources'][0]['resources'] = static_resources self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) discovery = self.Discovery.resources + self.DiscoveryAnother.resources # compare resource lists modulo ordering self.assertEqual(set(static_resources + discovery), set(self.Pollster.resources)) # Make sure no duplicated resource from discovery for x in self.Pollster.resources: self.assertEqual(1, self.Pollster.resources.count(x)) def test_per_polling_discovery_discovered_only(self): self._do_test_per_polling_discovery(['discovered_1', 'discovered_2'], []) def test_per_polling_discovery_static_only(self): self._do_test_per_polling_discovery([], ['static_1', 'static_2']) def test_per_polling_discovery_discovered_augmented_by_static(self): self._do_test_per_polling_discovery(['discovered_1', 'discovered_2'], ['static_1', 'static_2']) def test_per_polling_discovery_discovered_duplicated_static(self): self._do_test_per_polling_discovery(['discovered_1', 'pud'], ['dup', 'static_1', 'dup']) def test_multiple_pollings_different_static_resources(self): # assert that the individual lists of static and discovered resources # for each polling with a common interval are passed to individual # pollsters matching each polling self.polling_cfg['sources'][0]['resources'] = ['test://'] self.polling_cfg['sources'][0]['discovery'] = ['testdiscovery'] self.polling_cfg['sources'].append({ 'name': 'another_polling', 'interval': 60, 'meters': ['test'], 'resources': ['another://'], 'discovery': ['testdiscoveryanother'], }) self.mgr.discoveries = self.create_discoveries() self.Discovery.resources = ['discovered_1', 'discovered_2'] self.DiscoveryAnother.resources = ['discovered_3', 'discovered_4'] self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.assertEqual(1, len(polling_tasks)) self.assertIn(60, polling_tasks.keys()) self.mgr.interval_task(polling_tasks.get(60)) self.assertEqual([None], self.Discovery.params) self.assertEqual([None], self.DiscoveryAnother.params) self.assertEqual(2, len(self.Pollster.samples)) samples = self.Pollster.samples test_resources = ['test://', 'discovered_1', 'discovered_2'] another_resources = ['another://', 'discovered_3', 'discovered_4'] if samples[0][1] == test_resources: self.assertEqual(another_resources, samples[1][1]) elif samples[0][1] == another_resources: self.assertEqual(test_resources, samples[1][1]) else: self.fail('unexpected sample resources %s' % samples) def test_multiple_sources_different_discoverers(self): self.Discovery.resources = ['discovered_1', 'discovered_2'] self.DiscoveryAnother.resources = ['discovered_3', 'discovered_4'] sources = [{'name': 'test_source_1', 'interval': 60, 'meters': ['test'], 'discovery': ['testdiscovery']}, {'name': 'test_source_2', 'interval': 60, 'meters': ['testanother'], 'discovery': ['testdiscoveryanother']}] self.polling_cfg = {'sources': sources} self.mgr.discoveries = self.create_discoveries() self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.assertEqual(1, len(polling_tasks)) self.assertIn(60, polling_tasks.keys()) self.mgr.interval_task(polling_tasks.get(60)) self.assertEqual(1, len(self.Pollster.samples)) self.assertEqual(['discovered_1', 'discovered_2'], self.Pollster.resources) self.assertEqual(1, len(self.PollsterAnother.samples)) self.assertEqual(['discovered_3', 'discovered_4'], self.PollsterAnother.resources) @mock.patch('ceilometer.polling.manager.LOG') def test_polling_and_notify_with_resources(self, LOG): self.setup_polling() polling_task = list(self.mgr.setup_polling_tasks().values())[0] polling_task.poll_and_notify() LOG.info.assert_called_with( 'Polling pollster %(poll)s in the context of %(src)s', {'poll': 'test', 'src': 'test_polling'}) @mock.patch('ceilometer.polling.manager.LOG') def test_skip_polling_and_notify_with_no_resources(self, LOG): self.polling_cfg['sources'][0]['resources'] = [] self.setup_polling() polling_task = list(self.mgr.setup_polling_tasks().values())[0] pollster = list(polling_task.pollster_matches['test_polling'])[0] polling_task.poll_and_notify() LOG.debug.assert_called_with( 'Skip pollster %(name)s, no %(p_context)sresources found this ' 'cycle', {'name': pollster.name, 'p_context': ''}) @mock.patch('ceilometer.polling.manager.LOG') def test_skip_polling_polled_resources(self, LOG): self.polling_cfg['sources'].append({ 'name': 'test_polling_1', 'interval': 60, 'meters': ['test'], 'resources': ['test://'], }) self.setup_polling() polling_task = list(self.mgr.setup_polling_tasks().values())[0] polling_task.poll_and_notify() LOG.debug.assert_called_with( 'Skip pollster %(name)s, no %(p_context)sresources found this ' 'cycle', {'name': 'test', 'p_context': 'new '}) @mock.patch('oslo_utils.timeutils.utcnow') def test_polling_samples_timestamp(self, mock_utc): polled_samples = [] timestamp = '2222-11-22T00:11:22.333333' def fake_send_notification(samples): polled_samples.extend(samples) mock_utc.return_value = datetime.datetime.strptime( timestamp, ""%Y-%m-%dT%H:%M:%S.%f"") self.setup_polling() polling_task = list(self.mgr.setup_polling_tasks().values())[0] polling_task._send_notification = mock.Mock( side_effect=fake_send_notification) polling_task.poll_and_notify() self.assertEqual(timestamp, polled_samples[0]['timestamp']) class PollsterHardware(TestPollster): class PollsterHardwareAnother(TestPollster): def test_discovery_partitioning(self): discovered_resources = ['discovered_1', 'discovered_2'] self.Pollster.discovery = 'testdiscovery' self.mgr.discoveries = self.create_discoveries() self.Discovery.resources = discovered_resources self.polling_cfg['sources'][0]['discovery'] = [ 'testdiscovery', 'testdiscoveryanother', 'testdiscoverynonexistent', 'testdiscoveryexception'] self.polling_cfg['sources'][0]['resources'] = [] self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) self.hashring.belongs_to_self.assert_has_calls( [mock.call('discovered_1'), mock.call('discovered_2')]) def test_discovery_partitioning_unhashable(self): discovered_resources = [{'unhashable': True}] self.Pollster.discovery = 'testdiscovery' self.mgr.discoveries = self.create_discoveries() self.Discovery.resources = discovered_resources self.polling_cfg['sources'][0]['discovery'] = [ 'testdiscovery', 'testdiscoveryanother', 'testdiscoverynonexistent', 'testdiscoveryexception'] self.polling_cfg['sources'][0]['resources'] = [] self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) self.hashring.belongs_to_self.assert_has_calls( [mock.call('{\'unhashable\': True}')]) def test_static_resources_partitioning(self): static_resources = ['static_1', 'static_2'] static_resources2 = ['static_3', 'static_4'] self.polling_cfg['sources'][0]['resources'] = static_resources self.polling_cfg['sources'].append({ 'name': 'test_polling2', 'interval': 60, 'meters': ['test', 'test2'], 'resources': static_resources2, }) # have one polling without static resources defined self.polling_cfg['sources'].append({ 'name': 'test_polling3', 'interval': 60, 'meters': ['test', 'test2'], 'resources': [], }) self.setup_polling() polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) self.hashring.belongs_to_self.assert_has_calls([ mock.call('static_1'), mock.call('static_2'), mock.call('static_3'), mock.call('static_4'), ], any_order=True)","from keystoneauth1 import exceptions as ka_exceptionsfrom oslotest import basefrom ceilometer.tests.unit.polling import agentbaseclass TestPollsterBuilder(agentbase.TestPollster): agentbase.TestPollster( self.conf)), self.assertIsInstance(ext.obj, agentbase.TestPollster) class TestPollsterKeystone(agentbase.TestPollster):class TestPollsterPollingException(agentbase.TestPollster):class TestRunTasks(agentbase.BaseAgentManagerTestCase): test_data = agentbase.default_test_data('testkeystone') test_data = agentbase.default_test_data('testpollingexception') super(TestRunTasks, self).setUp() self.useFixture(fixtures.MockPatch( 'keystoneclient.v2_0.client.Client', return_value=mock.Mock())) super(TestRunTasks, self).tearDown() exts = super(TestRunTasks, self).create_extension_list() exts.extend([extension.Extension('testkeystone', None, None, self.PollsterKeystone(self.CONF), ), extension.Extension('testpollingexception', None, None, self.PollsterPollingException( self.CONF), )]) return exts class PollsterHardware(agentbase.TestPollster): class PollsterHardwareAnother(agentbase.TestPollster):",539,588
openstack%2Fceilometer~master~Iace637dd5ed8a852db79b23e99918ca3e5c6605e,openstack/ceilometer,master,Iace637dd5ed8a852db79b23e99918ca3e5c6605e,static resources not picked up,MERGED,2017-12-11 14:44:09.000000000,2017-12-12 21:07:38.000000000,2017-12-12 21:07:37.000000000,"[{'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 14:44:09.000000000', 'files': ['ceilometer/polling/manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/46c84ef7f7db3500e8864501bb517aca436003cb', 'message': 'static resources not picked up\n\npolling is still broken if backend_url is not set. switch to\ntooz hashrings caused it to be ignored.\n\nChange-Id: Iace637dd5ed8a852db79b23e99918ca3e5c6605e\nCloses-Bug: #1732147\n'}]",0,527108,46c84ef7f7db3500e8864501bb517aca436003cb,9,4,1,6537,,,0,"static resources not picked up

polling is still broken if backend_url is not set. switch to
tooz hashrings caused it to be ignored.

Change-Id: Iace637dd5ed8a852db79b23e99918ca3e5c6605e
Closes-Bug: #1732147
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/08/527108/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/polling/manager.py'],1,46c84ef7f7db3500e8864501bb517aca436003cb,bug/1732147, return [v for v in self._resources if not self.agent_manager.partition_coordinator or self.agent_manager.hashrings[ static_resources_group].belongs_to_self( six.text_type(v))] + source_discovery, if self.agent_manager.partition_coordinator: return [v for v in self._resources if self.agent_manager.hashrings[ static_resources_group].belongs_to_self( six.text_type(v))] + source_discovery,5,5
openstack%2Fceilometer~master~If69e8f358be774783471e5a0a6a44bcaa9f80008,openstack/ceilometer,master,If69e8f358be774783471e5a0a6a44bcaa9f80008,Move delayed out of utils,MERGED,2017-11-17 15:11:13.000000000,2017-12-12 21:07:36.000000000,2017-12-12 21:07:36.000000000,"[{'_account_id': 6537}, {'_account_id': 22348}, {'_account_id': 22752}, {'_account_id': 23037}, {'_account_id': 24061}, {'_account_id': 26159}]","[{'number': 1, 'created': '2017-11-17 15:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6dc6deccf4994806b0f23d07b8238beb2c7e3753', 'message': 'Move delayed out of utils\n\nThis is only used in one place.\n\nChange-Id: If69e8f358be774783471e5a0a6a44bcaa9f80008\n'}, {'number': 2, 'created': '2017-11-20 08:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/933dd44e1cfb3a7af69ca1b392a465ed9c83e2dd', 'message': 'Move delayed out of utils\n\nThis is only used in one place.\n\nChange-Id: If69e8f358be774783471e5a0a6a44bcaa9f80008\n'}, {'number': 3, 'created': '2017-11-27 22:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aa9fb6f0bbb70d2a24a6f7a86f2d46ceafcdacd3', 'message': 'Move delayed out of utils\n\nThis is only used in one place.\n\nChange-Id: If69e8f358be774783471e5a0a6a44bcaa9f80008\n'}, {'number': 4, 'created': '2017-12-08 14:51:37.000000000', 'files': ['ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py', 'ceilometer/utils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d2a2afff43dbdb71a6566461b0c3eff21c5e2d49', 'message': 'Move delayed out of utils\n\nThis is only used in one place.\n\nChange-Id: If69e8f358be774783471e5a0a6a44bcaa9f80008\n'}]",0,521101,d2a2afff43dbdb71a6566461b0c3eff21c5e2d49,17,6,4,1669,,,0,"Move delayed out of utils

This is only used in one place.

Change-Id: If69e8f358be774783471e5a0a6a44bcaa9f80008
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/01/521101/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/polling/manager.py', 'ceilometer/tests/unit/polling/test_manager.py', 'ceilometer/utils.py']",3,6dc6deccf4994806b0f23d07b8238beb2c7e3753,move-out-delayed,,"import timedef delayed(delay, target, *args, **kwargs): time.sleep(delay) return target(*args, **kwargs) ",8,9
openstack%2Fironic~master~Iab9cd250dafb42f775f50bec2c69eaa2daaab574,openstack/ironic,master,Iab9cd250dafb42f775f50bec2c69eaa2daaab574,tox: Use the default version of Python 3 for tox tests,MERGED,2017-12-11 15:30:46.000000000,2017-12-12 21:07:35.000000000,2017-12-12 21:07:34.000000000,"[{'_account_id': 6618}, {'_account_id': 9542}, {'_account_id': 10239}, {'_account_id': 14760}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 15:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/949b47db6706d036faf70ff3d2f8ac1efd3ad7da', 'message': 'tox: Use the default version of Python 3 for tox tests\n\nWhen running the tox tests, use the default version of Python 3. Instead\nof having to update the Python 3 version as we move from\n    py34 -> py35 -> py36 -> py37 -> py38\n\nJust use the default version of Python 3 on the system.\n\nThis will not affect what gets run in the gate, as the version is\nexplicitly specified when it runs there. This is for developers who run\nthe tests locally.\n\nChange-Id: Iab9cd250dafb42f775f50bec2c69eaa2daaab574\n'}, {'number': 2, 'created': '2017-12-11 16:13:27.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/701e3bf707d0adfe871bdbd07202f75189b1e3e8', 'message': 'tox: Use the default version of Python 3 for tox tests\n\nWhen running the tox tests, use the default version of Python 3. Instead\nof having to update the Python 3 version as we move from\n    py34 -> py35 -> py36 -> py37 -> py38\n\nJust use the default version of Python 3 on the system.\n\nThis will not affect what gets run in the gate, as the version is\nexplicitly specified when it runs there. This is for developers who run\nthe tests locally.\n\nChange-Id: Iab9cd250dafb42f775f50bec2c69eaa2daaab574\n'}]",2,527131,701e3bf707d0adfe871bdbd07202f75189b1e3e8,13,6,2,14760,,,0,"tox: Use the default version of Python 3 for tox tests

When running the tox tests, use the default version of Python 3. Instead
of having to update the Python 3 version as we move from
    py34 -> py35 -> py36 -> py37 -> py38

Just use the default version of Python 3 on the system.

This will not affect what gets run in the gate, as the version is
explicitly specified when it runs there. This is for developers who run
the tests locally.

Change-Id: Iab9cd250dafb42f775f50bec2c69eaa2daaab574
",git fetch https://review.opendev.org/openstack/ironic refs/changes/31/527131/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,949b47db6706d036faf70ff3d2f8ac1efd3ad7da,,"envlist = py3,py35,py27,pep8","envlist = py36,py35,py27,pep8",1,1
openstack%2Fnetworking-midonet~stable%2Fpike~I778ddb080cf1bdfffef52003632614dd43ae01ab,openstack/networking-midonet,stable/pike,I778ddb080cf1bdfffef52003632614dd43ae01ab,Add in-repo jobs,MERGED,2017-11-23 00:56:52.000000000,2017-12-12 21:02:53.000000000,2017-12-12 21:02:53.000000000,"[{'_account_id': 156}, {'_account_id': 9656}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 00:56:52.000000000', 'files': ['playbooks/tempest-multinode-ml2/post.yaml', 'playbooks/grenade-v2/post.yaml', 'playbooks/rally-v2/post.yaml', 'playbooks/rally-v2/run.yaml', 'playbooks/tempest-aio-v2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/run.yaml', 'playbooks/tempest-aio-v2-full/run.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/post.yaml', 'playbooks/rally-ml2/run.yaml', 'playbooks/tempest-aio-ml2-centos-7/post.yaml', 'playbooks/tempest-aio-ml2/post.yaml', 'playbooks/tempest-aio-v2-full/post.yaml', 'playbooks/grenade-ml2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/post.yaml', 'playbooks/tempest-aio-ml2/run.yaml', '.zuul.yaml', 'playbooks/rally-ml2/post.yaml', 'playbooks/tempest-multinode-ml2/run.yaml', 'playbooks/grenade-ml2/post.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/post.yaml', 'playbooks/grenade-v2/run.yaml', 'playbooks/tempest-aio-v2/post.yaml', 'playbooks/tempest-aio-ml2-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/run.yaml'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/c0af6b211b126fe6ac8adb7a67032da1ffe8b51b', 'message': 'Add in-repo jobs\n\nBased on the following versions:\n\n    project-config 3782b998e4514c510ebd3bf5956c853fed8eec9e\n    openstack-zuul-jobs be8c79d8b8af3f4f8304d9eca8291692bc9a7a6e\n\nCloses-Bug: #1728766\nChange-Id: I778ddb080cf1bdfffef52003632614dd43ae01ab\n(cherry picked from commit 062d0cf0dddf459231a31134589d426ce6f6d367)\n'}]",0,522414,c0af6b211b126fe6ac8adb7a67032da1ffe8b51b,8,3,1,6854,,,0,"Add in-repo jobs

Based on the following versions:

    project-config 3782b998e4514c510ebd3bf5956c853fed8eec9e
    openstack-zuul-jobs be8c79d8b8af3f4f8304d9eca8291692bc9a7a6e

Closes-Bug: #1728766
Change-Id: I778ddb080cf1bdfffef52003632614dd43ae01ab
(cherry picked from commit 062d0cf0dddf459231a31134589d426ce6f6d367)
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/14/522414/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/tempest-multinode-ml2/post.yaml', 'playbooks/grenade-v2/post.yaml', 'playbooks/rally-v2/post.yaml', 'playbooks/rally-v2/run.yaml', 'playbooks/tempest-aio-v2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/run.yaml', 'playbooks/tempest-aio-v2-full/run.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/post.yaml', 'playbooks/rally-ml2/run.yaml', 'playbooks/tempest-aio-ml2-centos-7/post.yaml', 'playbooks/tempest-aio-ml2/post.yaml', 'playbooks/tempest-aio-v2-full/post.yaml', 'playbooks/grenade-ml2/run.yaml', 'playbooks/tempest-aio-ml2-full-legacy/post.yaml', 'playbooks/tempest-aio-ml2/run.yaml', '.zuul.yaml', 'playbooks/rally-ml2/post.yaml', 'playbooks/tempest-multinode-ml2/run.yaml', 'playbooks/grenade-ml2/post.yaml', 'playbooks/tempest-aio-ml2-full-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/post.yaml', 'playbooks/grenade-v2/run.yaml', 'playbooks/tempest-aio-v2/post.yaml', 'playbooks/tempest-aio-ml2-centos-7/run.yaml', 'playbooks/tempest-aio-ml2-full/run.yaml']",25,c0af6b211b126fe6ac8adb7a67032da1ffe8b51b,bug/1728766-stable/pike,"- hosts: all name: Autoconverted job legacy-tempest-dsvm-networking-midonet-aio-ml2-full from old job gate-tempest-dsvm-networking-midonet-aio-ml2-full-ubuntu-xenial-nv tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST=1 export BRANCH_OVERRIDE=default if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_GATE_TOPOLOGY=aio # Because we are testing a non standard project, add # our project repository. This makes zuul do the right # reference magic for testing changes. export PROJECTS=""openstack/networking-midonet $PROJECTS"" export PROJECTS=""openstack/neutron-dynamic-routing $PROJECTS"" export PROJECTS=""openstack/networking-l2gw $PROJECTS"" export PROJECTS=""openstack/tap-as-a-service $PROJECTS"" function gate_hook { bash -xe $BASE/new/networking-midonet/devstack/ci/gate_hook.sh ml2-full } export -f gate_hook export DEVSTACK_GATE_SETTINGS=/opt/stack/new/networking-midonet/devstack/devstackgaterc cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",,1367,0
openstack%2Fnetworking-bgpvpn~master~I372bdbe6916ef7c5ace660c1bc7782a0ea8d82b6,openstack/networking-bgpvpn,master,I372bdbe6916ef7c5ace660c1bc7782a0ea8d82b6,Use SQL BigInteger type to store BGP LOCAL_PREF,MERGED,2017-11-23 18:29:57.000000000,2017-12-12 21:02:26.000000000,2017-12-12 21:02:26.000000000,"[{'_account_id': 55}, {'_account_id': 2888}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-23 18:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/2d480cb7c02e296ac8804ec8ca59bf43a0f2f2bc', 'message': 'Use SQL BigInteger type to store BGP LOCAL_PREF\n\nThe new route control API extension allows to define BGP LOCAL_PREF for\nthe routes that will be advertised. BGP LOCAL_PREF maximum value is\n2^32-1 and the SQL Integer type is limited to 2^31-1.\nCannot add a unit test as unit test framework uses an in-memory sqlite3\nDB and its Integer type maximum value is 2^64-1. Need to add a\nfunctional test.\n\nChange-Id: I372bdbe6916ef7c5ace660c1bc7782a0ea8d82b6\nPartial-Bug: #1733905\n'}, {'number': 2, 'created': '2017-11-24 11:42:58.000000000', 'files': ['networking_bgpvpn/neutron/db/migration/alembic_migrations/versions/queens/expand/9a6664f3b8d4_add_port_association_table.py', 'networking_bgpvpn/neutron/db/bgpvpn_db.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/db39605d2987dd59163ed0d603828fe743c1b332', 'message': 'Use SQL BigInteger type to store BGP LOCAL_PREF\n\nThe new route control API extension allows to define BGP LOCAL_PREF for\nthe routes that will be advertised. BGP LOCAL_PREF maximum value is\n2^32-1 and the SQL Integer type is limited to 2^31-1.\nCannot add a unit test as unit test framework uses an in-memory sqlite3\nDB and its Integer type maximum value is 2^64-1. Need to add a\nfunctional test.\n\nChange-Id: I372bdbe6916ef7c5ace660c1bc7782a0ea8d82b6\nPartial-Bug: #1733905\n'}]",0,522631,db39605d2987dd59163ed0d603828fe743c1b332,12,4,2,55,,,0,"Use SQL BigInteger type to store BGP LOCAL_PREF

The new route control API extension allows to define BGP LOCAL_PREF for
the routes that will be advertised. BGP LOCAL_PREF maximum value is
2^32-1 and the SQL Integer type is limited to 2^31-1.
Cannot add a unit test as unit test framework uses an in-memory sqlite3
DB and its Integer type maximum value is 2^64-1. Need to add a
functional test.

Change-Id: I372bdbe6916ef7c5ace660c1bc7782a0ea8d82b6
Partial-Bug: #1733905
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/31/522631/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bgpvpn/neutron/db/bgpvpn_db.py'],1,2d480cb7c02e296ac8804ec8ca59bf43a0f2f2bc,bug/1733905," local_pref = sa.Column(sa.BigInteger(),"," local_pref = sa.Column(sa.Integer(),",1,1
openstack%2Fnetworking-bgpvpn~master~Id28617cdf1ac870ae7afd53e0ecbb707ac558cf6,openstack/networking-bgpvpn,master,Id28617cdf1ac870ae7afd53e0ecbb707ac558cf6,devstack: fix linuxbridge configuration,MERGED,2017-11-27 15:55:57.000000000,2017-12-12 21:02:25.000000000,2017-12-12 21:02:24.000000000,"[{'_account_id': 55}, {'_account_id': 2888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-27 15:55:57.000000000', 'files': ['devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/9af443b42dbfb5dee1d567e612a8c8785c0e4a23', 'message': 'devstack: fix linuxbridge configuration\n\nWith linuxbridge, the l2population statement is not under\nthe same section than for OVS.\n\nThis was breaking BGPVPN L2 with linuxbridge.\n\n(+ minor cleanups)\n\nChange-Id: Id28617cdf1ac870ae7afd53e0ecbb707ac558cf6\n'}]",0,523154,9af443b42dbfb5dee1d567e612a8c8785c0e4a23,7,3,1,12021,,,0,"devstack: fix linuxbridge configuration

With linuxbridge, the l2population statement is not under
the same section than for OVS.

This was breaking BGPVPN L2 with linuxbridge.

(+ minor cleanups)

Change-Id: Id28617cdf1ac870ae7afd53e0ecbb707ac558cf6
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/54/523154/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'devstack/settings']",2,9af443b42dbfb5dee1d567e612a8c8785c0e4a23,devstack_cleanup,,"if is_service_enabled q-svc; then # l2pop is currently required for bagpipe driver if [[ -z ""$Q_ML2_PLUGIN_MECHANISM_DRIVERS"" ]]; then Q_ML2_PLUGIN_MECHANISM_DRIVERS=""l2population"" else Q_ML2_PLUGIN_MECHANISM_DRIVERS+="",l2population"" fi fi ",8,12
openstack%2Fnetworking-odl~master~I61f229c362010f4883f6bf8d1801b15148d89039,openstack/networking-odl,master,I61f229c362010f4883f6bf8d1801b15148d89039,Removing JournalCleanup class,MERGED,2017-12-05 11:45:02.000000000,2017-12-12 20:55:52.000000000,2017-12-12 20:55:52.000000000,"[{'_account_id': 333}, {'_account_id': 7921}, {'_account_id': 22348}, {'_account_id': 26507}]","[{'number': 1, 'created': '2017-12-05 11:45:02.000000000', 'files': ['networking_odl/journal/cleanup.py', 'networking_odl/tests/unit/journal/test_cleanup.py', 'networking_odl/tests/unit/ml2/test_mechanism_odl_v2.py', 'networking_odl/ml2/mech_driver_v2.py'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/cc6c98fd766c89a63a266fc416a1d3d1cff5eb6b', 'message': ""Removing JournalCleanup class\n\nThis class is rather unnecessary, as all it's two methods don't really\nhave anything to do with one another and are fine just sitting in the\nsame module.\nThe only thing the class was doing is caching config values, which isn't\nneeded and just bloats the code.\n\nChange-Id: I61f229c362010f4883f6bf8d1801b15148d89039\n""}]",0,525538,cc6c98fd766c89a63a266fc416a1d3d1cff5eb6b,9,4,1,7921,,,0,"Removing JournalCleanup class

This class is rather unnecessary, as all it's two methods don't really
have anything to do with one another and are fine just sitting in the
same module.
The only thing the class was doing is caching config values, which isn't
needed and just bloats the code.

Change-Id: I61f229c362010f4883f6bf8d1801b15148d89039
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/38/525538/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_odl/journal/cleanup.py', 'networking_odl/tests/unit/journal/test_cleanup.py', 'networking_odl/tests/unit/ml2/test_mechanism_odl_v2.py', 'networking_odl/ml2/mech_driver_v2.py']",4,cc6c98fd766c89a63a266fc416a1d3d1cff5eb6b,, self._periodic_task.register_operation(cleanup.delete_completed_rows) self._periodic_task.register_operation(cleanup.cleanup_processing_rows), cleanup_obj = cleanup.JournalCleanup() self._periodic_task.register_operation( cleanup_obj.delete_completed_rows) self._periodic_task.register_operation( cleanup_obj.cleanup_processing_rows),28,37
openstack%2Fopenstack-ansible-os_designate~master~I9ca9ac94d237e3c4f62e1408a2003f9303a9d045,openstack/openstack-ansible-os_designate,master,I9ca9ac94d237e3c4f62e1408a2003f9303a9d045,Handle Pike deprecations for designate,MERGED,2017-12-05 07:34:22.000000000,2017-12-12 20:53:59.000000000,2017-12-12 20:53:59.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 07:34:22.000000000', 'files': ['templates/designate.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_designate/commit/22fa91cd08c060592b2949f7c27155ccd69193fa', 'message': 'Handle Pike deprecations for designate\n\nFollow designate release notes for Pike:\nhttps://docs.openstack.org/releasenotes/designate/pike.html\n\nChange-Id: I9ca9ac94d237e3c4f62e1408a2003f9303a9d045\n'}]",0,525488,22fa91cd08c060592b2949f7c27155ccd69193fa,11,4,1,17068,,,0,"Handle Pike deprecations for designate

Follow designate release notes for Pike:
https://docs.openstack.org/releasenotes/designate/pike.html

Change-Id: I9ca9ac94d237e3c4f62e1408a2003f9303a9d045
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_designate refs/changes/88/525488/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/designate.conf.j2'],1,22fa91cd08c060592b2949f7c27155ccd69193fa,pike_deprecations,##Following https://docs.openstack.org/releasenotes/designate/pike.html#critical-issues #formatv4 = '%(octet0)s-%(octet1)s-%(octet2)s-%(octet3)s.%(zone)s' #formatv4 = '%(hostname)s.%(project)s.%(zone)s' #formatv4 = '%(hostname)s.%(zone)s' #formatv6 = '%(hostname)s.%(project)s.%(zone)s' #formatv6 = '%(hostname)s.%(zone)s'##Following https://docs.openstack.org/releasenotes/designate/pike.html#critical-issues #formatv4 = '%(octet0)s-%(octet1)s-%(octet2)s-%(octet3)s.%(zone)s' #formatv4 = '%(hostname)s.%(project)s.%(zone)s' #formatv4 = '%(hostname)s.%(zone)s' #formatv6 = '%(hostname)s.%(project)s.%(zone)s' #formatv6 = '%(hostname)s.%(zone)s',#format = '%(octet0)s-%(octet1)s-%(octet2)s-%(octet3)s.%(domain)s' #format = '%(hostname)s.%(domain)s'#format = '%(octet0)s-%(octet1)s-%(octet2)s-%(octet3)s.%(domain)s' #format = '%(hostname)s.%(domain)s',12,4
openstack%2Fironic-specs~master~I4ed0cedcadbee3c74ae8ccba29dc72804f229ccb,openstack/ironic-specs,master,I4ed0cedcadbee3c74ae8ccba29dc72804f229ccb,Amend ansible deploy interface spec,MERGED,2017-12-05 17:25:07.000000000,2017-12-12 20:51:26.000000000,2017-12-12 20:51:25.000000000,"[{'_account_id': 6618}, {'_account_id': 9542}, {'_account_id': 10239}, {'_account_id': 13689}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-05 17:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/fdab81ce4dfad28a91d362a5a7aab31da26d9bf7', 'message': 'Amend ansible deploy interface spec\n\nadd proposed config options for default values for ""ansible_*""\ndriver_info fields supported by this interface.\n\nChange-Id: I4ed0cedcadbee3c74ae8ccba29dc72804f229ccb\nRelated-Bug: #1736409\n'}, {'number': 2, 'created': '2017-12-06 10:26:04.000000000', 'files': ['specs/approved/ansible-deploy-driver.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9197c5b1624b4db1611b01ab417c493f428e16cb', 'message': 'Amend ansible deploy interface spec\n\nadd proposed config options for default values for ""ansible_*""\ndriver_info fields supported by this interface.\n\nChange-Id: I4ed0cedcadbee3c74ae8ccba29dc72804f229ccb\nRelated-Bug: #1736409\n'}]",5,525708,9197c5b1624b4db1611b01ab417c493f428e16cb,13,5,2,9542,,,0,"Amend ansible deploy interface spec

add proposed config options for default values for ""ansible_*""
driver_info fields supported by this interface.

Change-Id: I4ed0cedcadbee3c74ae8ccba29dc72804f229ccb
Related-Bug: #1736409
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/08/525708/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/approved/ansible-deploy-driver.rst'],1,fdab81ce4dfad28a91d362a5a7aab31da26d9bf7,bug/1736409,"default_ansible_deploy_username Name of the user to use for Ansible when connecting to the ramdisk over SSH. Default is 'ansible'. It may be overriden by per-node ``ansible_deploy_username`` option in node's ``driver_info`` field. default_ansible_deploy_key_file Absolute path to the private SSH key file to use by Ansible by default when connecting to the ramdisk over SSH. If none is provided (default), Ansible will use the default SSH keys configured for the user running ironic-conductor service. Also note that private keys with password must be pre-loaded into ``ssh-agent``. It may be overriden by per-node ``ansible_deploy_key_file`` option in node's ``driver_info`` field. default_ansible_deploy_playbook Path (relative to $playbooks_path or absolute) to the default playbook used for deployment. Default is 'deploy.yaml'. It may be overriden by per-node ``ansible_deploy_playbook`` option in node's ``driver_info`` field. default_ansible_shutdown_playbook Path (relative to $playbooks_path or absolute) to the default playbook used for graceful in-band node shutdown. Default is 'shutdown.yaml'. It may be overriden by per-node ``ansible_shutdown_playbook`` option in node's ``driver_info`` field. default_ansible_clean_playbook Path (relative to $playbooks_path or absolute) to the default playbook used for node cleaning. Default is 'clean.yaml'. It may be overriden by per-node ``ansible_clean_playbook`` option in node's ``driver_info`` field. default_ansible_clean_steps_config Path (relative to $playbooks_path or absolute) to the default auxiliary cleaning steps file used during the node cleaning. Default is 'clean_steps.yaml'. It may be overriden by per-node ``ansible_clean_steps_config`` option in node's ``driver_info`` field. These parameters can be provided with driver_info, all are optional and their default values can be set in the ironic configuration file:","These parameters can be provided with driver_info, all are optional: Default is ``deploy.yaml``. Default is ``shutdown.yaml``. Default is ``clean.yaml``. Default is ``clean_steps.yaml``.",45,5
openstack%2Fdesignate-tempest-plugin~master~I3e17a39d64835d49fcd882ec6b7b556b6acc4f17,openstack/designate-tempest-plugin,master,I3e17a39d64835d49fcd882ec6b7b556b6acc4f17,Do not create networks for API tests,MERGED,2017-05-11 21:52:23.000000000,2017-12-12 20:42:28.000000000,2017-12-12 20:42:28.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 748}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 13252}, {'_account_id': 15739}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-05-11 21:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/d1dbf3457fed296d3d4d9a8b04754e5854b485e2', 'message': 'Do not create networks for API tests\n\nWe do not need network resources for these tests.\n\nChange-Id: I3e17a39d64835d49fcd882ec6b7b556b6acc4f17\nCloses-Bug: #1689415\n'}, {'number': 2, 'created': '2017-09-05 21:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/087d84b131d49e56b79e6b704b2c60d8e559c6b2', 'message': 'Do not create networks for API tests\n\nWe do not need network resources for these tests.\n\nChange-Id: I3e17a39d64835d49fcd882ec6b7b556b6acc4f17\nCloses-Bug: #1689415\n'}, {'number': 3, 'created': '2017-12-05 00:47:39.000000000', 'files': ['designate_tempest_plugin/tests/base.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/6e03c58b7f4525b70fc447c2286e5b34bde624b0', 'message': 'Do not create networks for API tests\n\nWe do not need network resources for these tests.\n\nChange-Id: I3e17a39d64835d49fcd882ec6b7b556b6acc4f17\nCloses-Bug: #1689415\n'}]",0,464087,6e03c58b7f4525b70fc447c2286e5b34bde624b0,17,8,3,15736,,,0,"Do not create networks for API tests

We do not need network resources for these tests.

Change-Id: I3e17a39d64835d49fcd882ec6b7b556b6acc4f17
Closes-Bug: #1689415
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/87/464087/3 && git format-patch -1 --stdout FETCH_HEAD,['designate_tempest_plugin/tests/base.py'],1,d1dbf3457fed296d3d4d9a8b04754e5854b485e2,1689415," @classmethod def setup_credentials(cls): # Do not create network resources for these test. cls.set_network_resources() super(BaseDnsTest, cls).setup_credentials() ",,6,0
openstack%2Fopenstack-ansible-repo_server~master~Icc2ee264fc213b258642b5393dd78b1b26ef0542,openstack/openstack-ansible-repo_server,master,Icc2ee264fc213b258642b5393dd78b1b26ef0542,Set pypi-server to cache and use known built wheels,MERGED,2017-12-10 02:54:58.000000000,2017-12-12 20:23:08.000000000,2017-12-12 20:23:08.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-10 02:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/0c63b9fe2a6698562db9a6351183d63df8b4b998', 'message': 'Set pypi-server to cache and use known built wheels\n\nThe pypi server is able to use our existing built wheels. Because\nthe pypi-server recursivly scans the provided directory, all wheels\nfor from any source can be fed into the server making it a universal\nsolution for serving python packages; no matter the distro or archetecture.\n\nTo ensure system performance the pypi-server package has been changed to\ninclude  the optional cache functionality it provides. As noted in the server\ndocs,  enabling caching will greatly improve performance when serving\nthousands of packages.\n\nChange-Id: Icc2ee264fc213b258642b5393dd78b1b26ef0542\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-12-11 19:15:20.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/f34c4cce6eb710766959b28dfadb4c7c21700122', 'message': 'Set pypi-server to cache and use known built wheels\n\nThe pypi server is able to use our existing built wheels. Because\nthe pypi-server recursivly scans the provided directory, all wheels\nfor from any source can be fed into the server making it a universal\nsolution for serving python packages; no matter the distro or \narchetecture.\n\nTo ensure system performance the pypi-server package has been changed to\ninclude  the optional cache functionality it provides. As noted in the \nserver docs,  enabling caching will greatly improve performance when \nserving thousands of packages.\n\n> The documentation for pypi-server is all contained within the\n  application, use `pypi-server -h`. That said, under bullet point 4,\n  here - https://pypi.python.org/pypi/pypiserver#table-of-contents -\n  an online copy exists.\n\nChange-Id: Icc2ee264fc213b258642b5393dd78b1b26ef0542\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,526886,f34c4cce6eb710766959b28dfadb4c7c21700122,15,5,2,7353,,,0,"Set pypi-server to cache and use known built wheels

The pypi server is able to use our existing built wheels. Because
the pypi-server recursivly scans the provided directory, all wheels
for from any source can be fed into the server making it a universal
solution for serving python packages; no matter the distro or 
archetecture.

To ensure system performance the pypi-server package has been changed to
include  the optional cache functionality it provides. As noted in the 
server docs,  enabling caching will greatly improve performance when 
serving thousands of packages.

> The documentation for pypi-server is all contained within the
  application, use `pypi-server -h`. That said, under bullet point 4,
  here - https://pypi.python.org/pypi/pypiserver#table-of-contents -
  an online copy exists.

Change-Id: Icc2ee264fc213b258642b5393dd78b1b26ef0542
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/86/526886/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,0c63b9fe2a6698562db9a6351183d63df8b4b998,pypi-index," - ""pypiserver[cache]==1.2.0""repo_pypiserver_package_path: ""{{ repo_service_home_folder }}/pools"""," - ""pypiserver==1.2.0""repo_pypiserver_package_path: ""{{ repo_service_home_folder }}/repo/python_packages""",2,3
openstack%2Fopenstackdocstheme~master~I8d7cf745f3a75718e41dca97a552e4d72a2e5eb8,openstack/openstackdocstheme,master,I8d7cf745f3a75718e41dca97a552e4d72a2e5eb8,DNM: Testing releasenotes build,ABANDONED,2017-12-09 14:39:24.000000000,2017-12-12 20:21:41.000000000,,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-09 14:39:24.000000000', 'files': ['releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/2b66e926ac921a12d5adc1778c6412c57808052b', 'message': 'DNM: Testing releasenotes build\n\ndouble checking the dependent change.\n\nChange-Id: I8d7cf745f3a75718e41dca97a552e4d72a2e5eb8\nDepends-On: I6d461a69537d3f7dd44e9b9877f652df656eedd8\n'}]",0,526853,2b66e926ac921a12d5adc1778c6412c57808052b,7,2,1,6547,,,0,"DNM: Testing releasenotes build

double checking the dependent change.

Change-Id: I8d7cf745f3a75718e41dca97a552e4d72a2e5eb8
Depends-On: I6d461a69537d3f7dd44e9b9877f652df656eedd8
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/53/526853/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/index.rst'],1,2b66e926ac921a12d5adc1778c6412c57808052b,releasenotes-version,testing ,,2,0
openstack%2Fopenstack-helm-infra~master~I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a,openstack/openstack-helm-infra,master,I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a,Add Elasticsearch liveness/readiness probes,MERGED,2017-12-11 20:19:11.000000000,2017-12-12 20:20:31.000000000,2017-12-12 20:20:31.000000000,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-12-11 20:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6c16cff93a06977d3878dd082045981303b03c2f', 'message': 'Update Elasticsearch tests to accomodate retries\n\nThe elasticsearch tests fail in situations when the service takes\nlonger than expected to register the clientpoints. This introduces\na loop for performing the tests to give the endpoints time to\nstart serving requests\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n'}, {'number': 2, 'created': '2017-12-11 20:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3fd33c84d38633a861b4d00b21d48d406b0aa238', 'message': ""Add Elasticsearch liveliness/readiness probes and test loops\n\nThe elasticsearch tests fail because the pods don't have\nreadiness or liveliness probes in the templates. This adds those\ndefinitions to the templates, as well as introduces a looping\nmechanism to the elasticsearch tests to allow ample time for the\npods to register as ready to serve requests\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n""}, {'number': 3, 'created': '2017-12-11 20:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/894f53804d37805bba99d7efd17d9bdb3d50cd9b', 'message': ""Add Elasticsearch liveness/readiness probes\n\nThe elasticsearch tests fail because the pods don't have\nreadiness or liveliness probes in the templates. This adds those\ndefinitions\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n""}, {'number': 4, 'created': '2017-12-11 21:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/47bee526bc205d1754d2ff01a8663e5af2bc4965', 'message': ""Add Elasticsearch liveness/readiness probes\n\nThe elasticsearch tests fail because the pods don't have\nreadiness or liveliness probes in the templates. This adds those\ndefinitions\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n""}, {'number': 5, 'created': '2017-12-11 22:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c595a7a42e871d1af2b217b0d9233e70319be611', 'message': ""Add Elasticsearch liveness/readiness probes\n\nThe elasticsearch tests fail because the pods don't have\nreadiness or liveliness probes in the templates. This adds those\ndefinitions\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n""}, {'number': 6, 'created': '2017-12-11 23:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6cd499cf1867cfcd5842eb2390e965d633546cf4', 'message': ""Add Elasticsearch liveness/readiness probes\n\nThe elasticsearch tests fail because the pods don't have\nreadiness or liveliness probes in the templates. This adds those\ndefinitions\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n""}, {'number': 7, 'created': '2017-12-12 00:49:19.000000000', 'files': ['elasticsearch/templates/deployment-master.yaml', 'elasticsearch/templates/bin/_helm-tests.sh.tpl', 'elasticsearch/templates/deployment-client.yaml', 'elasticsearch/templates/statefulset-data.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bea44e53bf5c386a6efcbb3c02ebe67120cfe9ca', 'message': ""Add Elasticsearch liveness/readiness probes\n\nThe elasticsearch tests fail because the pods don't have\nreadiness or liveliness probes in the templates. This adds those\ndefinitions\n\nChange-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a\n""}]",5,527233,bea44e53bf5c386a6efcbb3c02ebe67120cfe9ca,20,4,7,17591,,,0,"Add Elasticsearch liveness/readiness probes

The elasticsearch tests fail because the pods don't have
readiness or liveliness probes in the templates. This adds those
definitions

Change-Id: I4fd25aec5ae02d89ae1b933d8b083a3e9cafc55a
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/33/527233/2 && git format-patch -1 --stdout FETCH_HEAD,['elasticsearch/templates/bin/_helm-tests.sh.tpl'],1,6c16cff93a06977d3878dd082045981303b03c2f,update_elasticsearch_tests," create_success=false while [ ""$create_success"" = ""false"" ]; do index_result=$(curl -XPUT ""${ELASTICSEARCH_ENDPOINT}/test_index?pretty"" -H 'Content-Type: application/json' -d' { ""settings"" : { ""index"" : { ""number_of_shards"" : 3, ""number_of_replicas"" : 2 } } } ' | python -c ""import sys, json; print json.load(sys.stdin)['acknowledged']"") if [ ""$index_result"" == ""True"" ]; then echo ""PASS: Test index created!""; create_success=true; else echo ""FAIL: Test index not created!""; sleep 10; fi done insert_success=false while [ ""$insert_success"" = ""false"" ]; do insert_result=$(curl -XPUT ""${ELASTICSEARCH_ENDPOINT}/sample_index/sample_type/123/_create?pretty"" -H 'Content-Type: application/json' -d' { ""name"" : ""Elasticsearch"", ""message"" : ""Test data text entry"" } ' | python -c ""import sys, json; print json.load(sys.stdin)['created']"") if [ ""$insert_result"" == ""True"" ]; then insert_success=true; echo ""PASS: Test data inserted into test index!""; else echo ""FAIL: Test data not inserted into test index!""; sleep 10; fi done hits_success=false while [ ""$hits_success"" = ""false"" ]; do total_hits=$(curl -XGET ""${ELASTICSEARCH_ENDPOINT}/_search?pretty"" -H 'Content-Type: application/json' -d' { ""query"" : { ""bool"": { ""must"": [ { ""match"": { ""name"": ""Elasticsearch"" }}, { ""match"": { ""message"": ""Test data text entry"" }} ] } } } ' | python -c ""import sys, json; print json.load(sys.stdin)['hits']['total']"") if [ ""$total_hits"" -gt 0 ]; then hits_success=true echo ""PASS: Successful hits on test data query!"" else echo ""FAIL: No hits on query for test data! Exiting""; sleep 10; fi done"," index_result=$(curl -XPUT ""${ELASTICSEARCH_ENDPOINT}/test_index?pretty"" -H 'Content-Type: application/json' -d' { ""settings"" : { ""index"" : { ""number_of_shards"" : 3, ""number_of_replicas"" : 2 } } } ' | python -c ""import sys, json; print json.load(sys.stdin)['acknowledged']"") if [ ""$index_result"" == ""True"" ]; then echo ""PASS: Test index created!"" else echo ""FAIL: Test index not created!""; exit 1; fi insert_result=$(curl -XPUT ""${ELASTICSEARCH_ENDPOINT}/sample_index/sample_type/123/_create?pretty"" -H 'Content-Type: application/json' -d' { ""name"" : ""Elasticsearch"", ""message"" : ""Test data text entry"" } ' | python -c ""import sys, json; print json.load(sys.stdin)['created']"") if [ ""$insert_result"" == ""True"" ]; then sleep 20 echo ""PASS: Test data inserted into test index!"" else echo ""FAIL: Test data not inserted into test index!""; exit 1; fi total_hits=$(curl -XGET ""${ELASTICSEARCH_ENDPOINT}/_search?pretty"" -H 'Content-Type: application/json' -d' { ""query"" : { ""bool"": { ""must"": [ { ""match"": { ""name"": ""Elasticsearch"" }}, { ""match"": { ""message"": ""Test data text entry"" }} ] } } } ' | python -c ""import sys, json; print json.load(sys.stdin)['hits']['total']"") if [ ""$total_hits"" -gt 0 ]; then echo ""PASS: Successful hits on test data query!"" else echo ""FAIL: No hits on query for test data! Exiting""; exit 1; fi",58,44
openstack%2Fbifrost~stable%2Focata~I81a0261093cacb636a5c958c32ca31bd7d4c0042,openstack/bifrost,stable/ocata,I81a0261093cacb636a5c958c32ca31bd7d4c0042,Install shade after ironic,MERGED,2017-12-11 19:00:21.000000000,2017-12-12 20:19:22.000000000,2017-12-12 20:19:22.000000000,"[{'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/73c2817b8aea85709769181a8cf50fe3c40fcc74', 'message': 'Install shade after ironic\n\nDue to a upper constraint, the installation of ironic is\nresulting in keystoneauth1 being downgraded. Since bifrost\nis about using shade from the current state of master for\ncompatability reasons, we need to change the install order.\n\nChange-Id: I81a0261093cacb636a5c958c32ca31bd7d4c0042\n'}, {'number': 2, 'created': '2017-12-11 20:50:45.000000000', 'files': ['playbooks/roles/bifrost-unprovision-node-dynamic/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/install.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/028f5b9cca89f0be1af6564e1eb6381cf7055ee8', 'message': 'Install shade after ironic\n\nDue to a upper constraint, the installation of ironic is\nresulting in keystoneauth1 being downgraded. Since bifrost\nis about using shade from the current state of master for\ncompatability reasons, we need to change the install order.\n\nAlso, in the course of discovering this, fixing what appears\nto be a bad conditional statement where the when was missing\nwhich resulted in an error when testing with a newer\nkeystoneauth1 library.\n\nChange-Id: I81a0261093cacb636a5c958c32ca31bd7d4c0042\n'}]",1,527213,028f5b9cca89f0be1af6564e1eb6381cf7055ee8,10,3,2,11655,,,0,"Install shade after ironic

Due to a upper constraint, the installation of ironic is
resulting in keystoneauth1 being downgraded. Since bifrost
is about using shade from the current state of master for
compatability reasons, we need to change the install order.

Also, in the course of discovering this, fixing what appears
to be a bad conditional statement where the when was missing
which resulted in an error when testing with a newer
keystoneauth1 library.

Change-Id: I81a0261093cacb636a5c958c32ca31bd7d4c0042
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/13/527213/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-ironic-install/tasks/install.yml'],1,73c2817b8aea85709769181a8cf50fe3c40fcc74,527213,"# NOTE(TheJulia): The upper constraint for ironic installs an older version of # keystoneauth1 which breaks shde, As such, install shade after so the library # is at the sufficent revision. - name: ""Shade - Install"" include: pip_install.yml package=shade state=latest sourcedir={{ shade_git_folder }} source_install={{ shade_source_install }} when: skip_install is not defined","- name: ""Shade - Install"" include: pip_install.yml package=shade state=latest sourcedir={{ shade_git_folder }} source_install={{ shade_source_install }} when: skip_install is not defined",10,7
openstack%2Fproject-config~master~I8b946fb50caf727fa6b7c6a8fa117cd712519515,openstack/project-config,master,I8b946fb50caf727fa6b7c6a8fa117cd712519515,Remove duplicate required-projects,MERGED,2017-12-12 19:52:00.000000000,2017-12-12 20:15:20.000000000,2017-12-12 20:15:19.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-12 19:52:00.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7f6f15740b95797dcb773881cad8bcb6c2ab2b4c', 'message': 'Remove duplicate required-projects\n\nThis is a yaml syntax error.\n\nChange-Id: I8b946fb50caf727fa6b7c6a8fa117cd712519515\n'}]",0,527507,7f6f15740b95797dcb773881cad8bcb6c2ab2b4c,8,4,1,1,,,0,"Remove duplicate required-projects

This is a yaml syntax error.

Change-Id: I8b946fb50caf727fa6b7c6a8fa117cd712519515
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/527507/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,7f6f15740b95797dcb773881cad8bcb6c2ab2b4c,,, required-projects: - openstack/neutron,0,2
openstack%2Fcharm-openstack-dashboard~master~Ida7949113594b9b859ab7b4ba8b2bb440bab6e7d,openstack/charm-openstack-dashboard,master,Ida7949113594b9b859ab7b4ba8b2bb440bab6e7d,Update HAProxy default timeout values,MERGED,2017-12-11 19:37:31.000000000,2017-12-12 20:11:26.000000000,2017-12-12 20:11:26.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:37:31.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'tests/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/core/host_factory/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/cad0fa0dcd42ac3e014cf192ca42e579676a3e6f', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: Ida7949113594b9b859ab7b4ba8b2bb440bab6e7d\n'}]",0,527224,cad0fa0dcd42ac3e014cf192ca42e579676a3e6f,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: Ida7949113594b9b859ab7b4ba8b2bb440bab6e7d
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/24/527224/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'tests/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/core/host_factory/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py']",14,cad0fa0dcd42ac3e014cf192ca42e579676a3e6f,bug/1736171, for pool in df['pools']: if pool['id'] == pool_id: pool_name = pool['name'] obj_count = pool['stats']['objects'] kb_used = pool['stats']['kb_used'] , pool_name = df['pools'][pool_id]['name'] obj_count = df['pools'][pool_id]['stats']['objects'] kb_used = df['pools'][pool_id]['stats']['kb_used'],111,27
openstack%2Fcharm-ceph-radosgw~master~I312dd56ecf55ad67485305e57f2807a5ea6975cd,openstack/charm-ceph-radosgw,master,I312dd56ecf55ad67485305e57f2807a5ea6975cd,Update HAProxy default timeout values,MERGED,2017-12-11 19:36:34.000000000,2017-12-12 20:10:19.000000000,2017-12-12 20:10:19.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:36:34.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'tests/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/core/host_factory/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/edad8b605412910aece9b9f9ae6806f70bd31be5', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I312dd56ecf55ad67485305e57f2807a5ea6975cd\n'}]",0,527218,edad8b605412910aece9b9f9ae6806f70bd31be5,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I312dd56ecf55ad67485305e57f2807a5ea6975cd
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/18/527218/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml', 'hooks/charmhelpers/contrib/storage/linux/lvm.py', 'tests/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/core/host_factory/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'tests/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py']",14,edad8b605412910aece9b9f9ae6806f70bd31be5,bug/1736171, for pool in df['pools']: if pool['id'] == pool_id: pool_name = pool['name'] obj_count = pool['stats']['objects'] kb_used = pool['stats']['kb_used'] , pool_name = df['pools'][pool_id]['name'] obj_count = df['pools'][pool_id]['stats']['objects'] kb_used = df['pools'][pool_id]['stats']['kb_used'],115,31
openstack%2Fopenstack-ansible-openstack_openrc~master~I5f296bfe6cab43ad782ae063ed9ed25414e316fc,openstack/openstack-ansible-openstack_openrc,master,I5f296bfe6cab43ad782ae063ed9ed25414e316fc,Add defaults for keystone insecure variables,MERGED,2017-12-11 17:38:03.000000000,2017-12-12 20:10:12.000000000,2017-12-12 20:10:12.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 17:38:03.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_openrc/commit/db09d4c96e4154b2409e9787354db398384f8dd8', 'message': ""Add defaults for keystone insecure variables\n\nThe default for 'openrc_insecure' was not working as expected. Both of\nthe inner variables were evaluated as booleans first and the expression\nwould fail if either was undefined.\n\nChange-Id: I5f296bfe6cab43ad782ae063ed9ed25414e316fc\n""}]",0,527194,db09d4c96e4154b2409e9787354db398384f8dd8,9,4,1,14805,,,0,"Add defaults for keystone insecure variables

The default for 'openrc_insecure' was not working as expected. Both of
the inner variables were evaluated as booleans first and the expression
would fail if either was undefined.

Change-Id: I5f296bfe6cab43ad782ae063ed9ed25414e316fc
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_openrc refs/changes/94/527194/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,db09d4c96e4154b2409e9787354db398384f8dd8,default_insecure_vars,openrc_insecure: >- {{ (keystone_service_adminuri_insecure | default(false) | bool or keystone_service_internaluri_insecure | default(false) | bool) }},"openrc_insecure: ""{{ (keystone_service_adminuri_insecure | bool or keystone_service_internaluri_insecure | bool) | default(false) }}"" ",3,2
openstack%2Fopenstack-ansible-lxc_hosts~stable%2Focata~I3fdc313a43daae938357230cf99e2992ede11e01,openstack/openstack-ansible-lxc_hosts,stable/ocata,I3fdc313a43daae938357230cf99e2992ede11e01,Remove LXC yum repo from containers,MERGED,2017-12-11 17:51:46.000000000,2017-12-12 20:06:32.000000000,2017-12-12 20:06:32.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-11 17:51:46.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e036bc58c28febd625ceb26eb3c061b289219ede', 'message': ""Remove LXC yum repo from containers\n\nThs LXC yum repository is being added to containers during the\ncach prep step on CentOS. This causes delays/failures in the\ncontainers and it's only needed on hosts.\n\nCloses-Bug: 1737202\nChange-Id: I3fdc313a43daae938357230cf99e2992ede11e01\n(cherry picked from commit 84c08cfe94ace0c5e753e14e7e8512a0a88abbb1)\n""}]",0,527196,e036bc58c28febd625ceb26eb3c061b289219ede,8,3,1,538,,,0,"Remove LXC yum repo from containers

Ths LXC yum repository is being added to containers during the
cach prep step on CentOS. This causes delays/failures in the
containers and it's only needed on hosts.

Closes-Bug: 1737202
Change-Id: I3fdc313a43daae938357230cf99e2992ede11e01
(cherry picked from commit 84c08cfe94ace0c5e753e14e7e8512a0a88abbb1)
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/96/527196/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,e036bc58c28febd625ceb26eb3c061b289219ede,bug/1737202, # The containers do not need the LXC repository (only hosts need it). rm -f /etc/yum.repos.d/thm-lxc2.0.repo,,2,0
openstack%2Fcharm-swift-proxy~master~I0aefed05d7b06162d21bb5ded216fc32935ef52e,openstack/charm-swift-proxy,master,I0aefed05d7b06162d21bb5ded216fc32935ef52e,Update HAProxy default timeout values,MERGED,2017-12-11 19:37:40.000000000,2017-12-12 20:06:11.000000000,2017-12-12 20:06:11.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:37:40.000000000', 'files': ['tests/charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/storage/linux/lvm.py', 'config.yaml', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/contrib/openstack/utils.py', 'tests/charmhelpers/contrib/storage/linux/lvm.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/4e9aa259b0afd71111395616d853009b9cb80e75', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I0aefed05d7b06162d21bb5ded216fc32935ef52e\n'}]",0,527225,4e9aa259b0afd71111395616d853009b9cb80e75,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I0aefed05d7b06162d21bb5ded216fc32935ef52e
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/25/527225/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/storage/linux/lvm.py', 'charmhelpers/contrib/openstack/context.py', 'config.yaml', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/contrib/openstack/utils.py', 'tests/charmhelpers/contrib/storage/linux/lvm.py']",10,4e9aa259b0afd71111395616d853009b9cb80e75,bug/1736171,"import functools def list_logical_volumes(select_criteria=None, path_mode=False): ''' List logical volumes :param select_criteria: str: Limit list to those volumes matching this criteria (see 'lvs -S help' for more details) :param path_mode: bool: return logical volume name in 'vg/lv' format, this format is required for some commands like lvextend :returns: [str]: List of logical volumes ''' lv_diplay_attr = 'lv_name' if path_mode: # Parsing output logic relies on the column order lv_diplay_attr = 'vg_name,' + lv_diplay_attr cmd = ['lvs', '--options', lv_diplay_attr, '--noheadings'] if select_criteria: cmd.extend(['--select', select_criteria]) lvs = [] for lv in check_output(cmd).decode('UTF-8').splitlines(): if not lv: continue if path_mode: lvs.append('/'.join(lv.strip().split())) else: lvs.append(lv.strip()) return lvs list_thin_logical_volume_pools = functools.partial( list_logical_volumes, select_criteria='lv_attr =~ ^t') list_thin_logical_volumes = functools.partial( list_logical_volumes, select_criteria='lv_attr =~ ^V') def extend_logical_volume_by_device(lv_name, block_device): ''' Extends the size of logical volume lv_name by the amount of free space on physical volume block_device. :param lv_name: str: name of logical volume to be extended (vg/lv format) :param block_device: str: name of block_device to be allocated to lv_name ''' cmd = ['lvextend', lv_name, block_device] check_call(cmd)",,137,15
openstack%2Fcharm-ceilometer~master~I2474ba8abbd77d89b82d2fefb51aef463c45169b,openstack/charm-ceilometer,master,I2474ba8abbd77d89b82d2fefb51aef463c45169b,Update HAProxy default timeout values,MERGED,2017-12-11 19:36:25.000000000,2017-12-12 20:03:04.000000000,2017-12-12 20:03:04.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:36:25.000000000', 'files': ['charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/a34db0aa8e3766d6af4af55dafd132c6d46df53b', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I2474ba8abbd77d89b82d2fefb51aef463c45169b\n'}]",0,527217,a34db0aa8e3766d6af4af55dafd132c6d46df53b,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I2474ba8abbd77d89b82d2fefb51aef463c45169b
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/17/527217/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml']",2,a34db0aa8e3766d6af4af55dafd132c6d46df53b,bug/1736171," configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 9000ms is used. configurations. If not provided, default value of 9000ms is used."," configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 5000ms is used. configurations. If not provided, default value of 5000ms is used.",8,8
openstack%2Fcharm-nova-cloud-controller~master~I0a3a8f0dd2dedcc8e02dd6af2f5486501698833e,openstack/charm-nova-cloud-controller,master,I0a3a8f0dd2dedcc8e02dd6af2f5486501698833e,Update HAProxy default timeout values,MERGED,2017-12-11 19:37:21.000000000,2017-12-12 20:03:00.000000000,2017-12-12 20:03:00.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:37:21.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/373158b5cfb827359a1d8c821c30c1f2a934ebb5', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I0a3a8f0dd2dedcc8e02dd6af2f5486501698833e\n'}]",0,527223,373158b5cfb827359a1d8c821c30c1f2a934ebb5,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I0a3a8f0dd2dedcc8e02dd6af2f5486501698833e
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/23/527223/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml']",2,373158b5cfb827359a1d8c821c30c1f2a934ebb5,bug/1736171," configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 9000ms is used. configurations. If not provided, default value of 9000ms is used."," configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 5000ms is used. configurations. If not provided, default value of 5000ms is used.",8,8
openstack%2Fcharm-neutron-api~master~I6651ecdb89af11e94c59f928c1eb4a89940f4679,openstack/charm-neutron-api,master,I6651ecdb89af11e94c59f928c1eb4a89940f4679,Update HAProxy default timeout values,MERGED,2017-12-11 19:37:12.000000000,2017-12-12 20:02:52.000000000,2017-12-12 20:02:51.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:37:12.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/00b52d10b1e1f085fea38ba84303f9f07cc7ad5d', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I6651ecdb89af11e94c59f928c1eb4a89940f4679\n'}]",0,527222,00b52d10b1e1f085fea38ba84303f9f07cc7ad5d,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I6651ecdb89af11e94c59f928c1eb4a89940f4679
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/22/527222/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml']",2,00b52d10b1e1f085fea38ba84303f9f07cc7ad5d,bug/1736171," configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 9000ms is used. configurations. If not provided, default value of 9000ms is used."," configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 5000ms is used. configurations. If not provided, default value of 5000ms is used.",8,8
openstack%2Fcharm-cinder~master~I342c06066b26ffa8240f076e0c9f461cae21b9c4,openstack/charm-cinder,master,I342c06066b26ffa8240f076e0c9f461cae21b9c4,Update HAProxy default timeout values,MERGED,2017-12-11 19:36:44.000000000,2017-12-12 20:02:37.000000000,2017-12-12 20:02:37.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:36:44.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/cf6cd15b24ad35faa287333c58e0661475a84708', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I342c06066b26ffa8240f076e0c9f461cae21b9c4\n'}]",0,527219,cf6cd15b24ad35faa287333c58e0661475a84708,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I342c06066b26ffa8240f076e0c9f461cae21b9c4
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/19/527219/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml']",2,cf6cd15b24ad35faa287333c58e0661475a84708,bug/1736171," configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 9000ms is used. configurations. If not provided, default value of 9000ms is used."," configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 5000ms is used. configurations. If not provided, default value of 5000ms is used.",8,8
openstack%2Fcharm-glance~master~I4d15d8ef0f2bfb9966a45ca1850721c5de4d3b08,openstack/charm-glance,master,I4d15d8ef0f2bfb9966a45ca1850721c5de4d3b08,Update HAProxy default timeout values,MERGED,2017-12-11 19:36:53.000000000,2017-12-12 20:01:52.000000000,2017-12-12 20:01:52.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:36:53.000000000', 'files': ['charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/c5048c78171d705d81680fb9902fc78baff73f72', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I4d15d8ef0f2bfb9966a45ca1850721c5de4d3b08\n'}]",0,527220,c5048c78171d705d81680fb9902fc78baff73f72,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I4d15d8ef0f2bfb9966a45ca1850721c5de4d3b08
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/20/527220/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/templates/haproxy.cfg', 'config.yaml']",2,c5048c78171d705d81680fb9902fc78baff73f72,bug/1736171," configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 90000ms is used. configurations. If not provided, default value of 9000ms is used. configurations. If not provided, default value of 9000ms is used."," configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 30000ms is used. configurations. If not provided, default value of 5000ms is used. configurations. If not provided, default value of 5000ms is used.",8,8
openstack%2Fcharm-keystone~master~I973962a5c1538b0d9afbebea8cebf50d938ecfb5,openstack/charm-keystone,master,I973962a5c1538b0d9afbebea8cebf50d938ecfb5,Update HAProxy default timeout values,MERGED,2017-12-11 19:37:03.000000000,2017-12-12 19:59:55.000000000,2017-12-12 19:59:55.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 19:37:03.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/lvm.py', 'config.yaml', 'charmhelpers/contrib/storage/linux/ceph.py', 'tests/charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/core/host_factory/ubuntu.py', 'charmhelpers/core/host.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/openstack/context.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/e1ac46f34264c11b56c571412bc40c42018370bb', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis charm-helpers sync pulls in the change to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: I973962a5c1538b0d9afbebea8cebf50d938ecfb5\n'}]",0,527221,e1ac46f34264c11b56c571412bc40c42018370bb,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This charm-helpers sync pulls in the change to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: I973962a5c1538b0d9afbebea8cebf50d938ecfb5
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/21/527221/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/lvm.py', 'config.yaml', 'charmhelpers/contrib/storage/linux/ceph.py', 'tests/charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/core/host_factory/ubuntu.py', 'tests/charmhelpers/core/host_factory/ubuntu.py', 'charmhelpers/core/host.py', 'tests/charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/openstack/context.py']",12,e1ac46f34264c11b56c571412bc40c42018370bb,bug/1736171," CompareOpenStackReleases, os_release, def __init__(self, ost_rel_check_pkg_name): self.ost_rel_check_pkg_name = ost_rel_check_pkg_name def __call__(self): ctxt = {'use_internal_endpoints': config('use-internal-endpoints')} rel = os_release(self.ost_rel_check_pkg_name, base='icehouse') if CompareOpenStackReleases(rel) >= 'pike': ctxt['volume_api_version'] = '3' else: ctxt['volume_api_version'] = '2' return ctxt", def __call__(self): return {'use_internal_endpoints': config('use-internal-endpoints')},95,19
openstack%2Fcharm-barbican~master~Id94f7b3e519f693df436ccc2b57f4e5e10b3c35e,openstack/charm-barbican,master,Id94f7b3e519f693df436ccc2b57f4e5e10b3c35e,Update HAProxy default timeout values,MERGED,2017-12-11 21:00:15.000000000,2017-12-12 19:59:38.000000000,2017-12-12 19:59:38.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-11 21:00:15.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-barbican/commit/db460e7de466251409594b815cea7d416a5a65d3', 'message': 'Update HAProxy default timeout values\n\nThe default HAProxy timeout values are fairly strict. On a busy cloud\nit is common to exceed one or more of these timeouts. The only\nindication that HAProxy has exceeded a timeout and dropped the\nconnection is errors such as ""BadStatusLine"" or ""EOF."" These can be\nvery difficult to diagnose when intermittent.\n\nThis source charm rebuild pulls in the changes to update the default\ntimeout values to more real world settings. These values have been\nextensively tested in ServerStack. Configured values will not be\noverridden.\n\nPartial Bug: #1736171\n\nChange-Id: Id94f7b3e519f693df436ccc2b57f4e5e10b3c35e\n'}]",0,527238,db460e7de466251409594b815cea7d416a5a65d3,8,3,1,20805,,,0,"Update HAProxy default timeout values

The default HAProxy timeout values are fairly strict. On a busy cloud
it is common to exceed one or more of these timeouts. The only
indication that HAProxy has exceeded a timeout and dropped the
connection is errors such as ""BadStatusLine"" or ""EOF."" These can be
very difficult to diagnose when intermittent.

This source charm rebuild pulls in the changes to update the default
timeout values to more real world settings. These values have been
extensively tested in ServerStack. Configured values will not be
overridden.

Partial Bug: #1736171

Change-Id: Id94f7b3e519f693df436ccc2b57f4e5e10b3c35e
",git fetch https://review.opendev.org/openstack/charm-barbican refs/changes/38/527238/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,db460e7de466251409594b815cea7d416a5a65d3,bug/1736171,45072308-deb6-11e7-b627-b3ecee1e829d,353fd330-a3c3-11e7-8d95-fa163e8aa73b,1,1
openstack%2Fceilometer~stable%2Fpike~Iadc755f2848b372e5bc71e94647f0f4608433ed2,openstack/ceilometer,stable/pike,Iadc755f2848b372e5bc71e94647f0f4608433ed2,hack around upper-constraints,ABANDONED,2017-12-12 14:07:58.000000000,2017-12-12 19:09:12.000000000,,"[{'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-12-12 14:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ca48745a07ba4e8ec0c8f8611a1391b57946c3a2', 'message': ""hack around upper-constraints\n\nthis is easier than getting -2'd.\n\nChange-Id: Iadc755f2848b372e5bc71e94647f0f4608433ed2\n""}, {'number': 2, 'created': '2017-12-12 14:08:56.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b5a8240e12597ff00c1437dd3a8e24de49976651', 'message': ""hack around upper-constraints\n\ntenacity requirement in gnocchi is blocked by global-reqs,\nthis is easier than getting -2'd.\n\nChange-Id: Iadc755f2848b372e5bc71e94647f0f4608433ed2\n""}]",0,527407,b5a8240e12597ff00c1437dd3a8e24de49976651,6,2,2,6537,,,0,"hack around upper-constraints

tenacity requirement in gnocchi is blocked by global-reqs,
this is easier than getting -2'd.

Change-Id: Iadc755f2848b372e5bc71e94647f0f4608433ed2
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/07/527407/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,ca48745a07ba4e8ec0c8f8611a1391b57946c3a2,pike-gate," pip_install -U -e $GNOCCHI_GIT_PATH[redis,${DATABASE_TYPE},keystone] uwsgi pip_install -U gnocchi[redis,${DATABASE_TYPE},keystone] uwsgi"," pip_install -e $GNOCCHI_GIT_PATH[redis,${DATABASE_TYPE},keystone] uwsgi pip_install gnocchi[redis,${DATABASE_TYPE},keystone] uwsgi",2,2
openstack%2Fironic~master~I92ad0aa7a2ca94aa91d928e2059a200c9c6c2606,openstack/ironic,master,I92ad0aa7a2ca94aa91d928e2059a200c9c6c2606,Remove XML response handling,ABANDONED,2017-12-12 17:38:45.000000000,2017-12-12 19:00:08.000000000,,"[{'_account_id': 9542}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-12-12 17:38:45.000000000', 'files': ['ironic/api/middleware/parsable_error.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/661a0bc5f9452facc6a58f3d6fae3a5f0afc4690', 'message': 'Remove XML response handling\n\nour API specifically states support for JSON only.\nThis patch removes XML response handling from ParsableError\napi middleware.\n\nChange-Id: I92ad0aa7a2ca94aa91d928e2059a200c9c6c2606\n'}]",0,527476,661a0bc5f9452facc6a58f3d6fae3a5f0afc4690,5,2,1,9542,,,0,"Remove XML response handling

our API specifically states support for JSON only.
This patch removes XML response handling from ParsableError
api middleware.

Change-Id: I92ad0aa7a2ca94aa91d928e2059a200c9c6c2606
",git fetch https://review.opendev.org/openstack/ironic refs/changes/76/527476/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/api/middleware/parsable_error.py'],1,661a0bc5f9452facc6a58f3d6fae3a5f0afc4690,no-xml-responses," if six.PY3: app_iter = [i.decode('utf-8') for i in app_iter] body = [json.dumps({'error_message': '\n'.join(app_iter)})] if six.PY3: body = [item.encode('utf-8') for item in body] state['headers'].append(('Content-Type', 'application/json'))","from xml import etree as etimport webob req = webob.Request(environ) if (req.accept.best_match(['application/json', 'application/xml']) == 'application/xml'): try: # simple check xml is valid body = [et.ElementTree.tostring( et.ElementTree.fromstring('<error_message>' + '\n'.join(app_iter) + '</error_message>'))] except et.ElementTree.ParseError as err: LOG.error('Error parsing HTTP response: %s', err) body = ['<error_message>%s' % state['status_code'] + '</error_message>'] state['headers'].append(('Content-Type', 'application/xml')) else: if six.PY3: app_iter = [i.decode('utf-8') for i in app_iter] body = [json.dumps({'error_message': '\n'.join(app_iter)})] if six.PY3: body = [item.encode('utf-8') for item in body] state['headers'].append(('Content-Type', 'application/json'))",6,23
openstack%2Fnova~master~I6bf6b47fb714af7721cd8cc848f49948df90f1e9,openstack/nova,master,I6bf6b47fb714af7721cd8cc848f49948df90f1e9,Added PCI NUMA policies,ABANDONED,2016-10-25 11:05:51.000000000,2017-12-12 17:33:16.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6125}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11353}, {'_account_id': 11604}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17920}, {'_account_id': 20040}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25625}, {'_account_id': 26515}]","[{'number': 1, 'created': '2016-10-25 11:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3fe1d8ff2b27a59157749e723ec5bcc9e0f287a6', 'message': '[WIP] PIC NUMA policy PoC\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 2, 'created': '2016-10-25 15:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6aac36b820ad82d35113cc1e8d75ab9a08262670', 'message': '[WIP] PIC NUMA policy PoC\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 3, 'created': '2016-10-31 12:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e413e6bcdebbcf87c671e8c503d2823355cf607', 'message': '[WIP] PIC NUMA policy PoC\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 4, 'created': '2017-03-13 12:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba3a3225f7262e7f38dc304a701dcb859f61f899', 'message': '[WIP] PIC NUMA policy PoC\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 5, 'created': '2017-03-13 13:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/449d044cd9f33a2e2cf39143379094bfb297cdb2', 'message': '[WIP] PIC NUMA policy PoC\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 6, 'created': '2017-03-28 10:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d98da4bbc3e3b827c4ea4899032d1d2127967fd1', 'message': '[WIP] PIC NUMA policy PoC\n\nSpec is still on review\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 7, 'created': '2017-03-28 11:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/231937b03c54080d06ac4196a941cd748e26eb4d', 'message': '[WIP] PIC NUMA policy PoC\n\nSpec is still on review\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n'}, {'number': 8, 'created': '2017-04-04 08:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/926505cd97f2482a563010d22925447d67c0aeb2', 'message': ""Added PIC NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* required - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* strict - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 9, 'created': '2017-04-04 09:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c20f3c5c702560ccf47269caa0f3567ea7092ef', 'message': ""Added PIC NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* required - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* strict - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 10, 'created': '2017-04-04 13:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/898d4a6e55290624d962791229deac8e793ed3eb', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* required - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* strict - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 11, 'created': '2017-04-11 11:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f45f73d79209e680ebbc6c9735998ae0b9dd1963', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* required - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* strict - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 12, 'created': '2017-05-02 14:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/702631b26eabb8496705e429acedd920ffe53a65', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* legacy - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* required - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 13, 'created': '2017-05-31 06:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ceab64ff227e19a26b854f448f7a184823a16b2c', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* legacy - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* required - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 14, 'created': '2017-06-04 11:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac2f7caf92cfe686da567e9c6e636ddcc78e2757', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor\n* metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n* legacy - this is the default value and it describes\n  the current nova behavior. Nova will boot VMs with PCI\n  device if the PCI device is associated with at least\n  one NUMA nodes on which the or there is no information\n  about PCI-NUMA association\n\n* required - nova will boot VMs with PCI devices *only*\n  if at least one of the NUMA node is associated with\n  these PCI devices.\n\n* preferred - nova will boot VMs ignoring association\n  of NUMA nodes and PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 15, 'created': '2017-11-22 16:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fea4ec90fd0c45f2951c054e4b8035108eee0b25', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n* extra spec 'hw:pci_numa_affinity_policy' for flavor * metadata field\n  'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n- legacy - this is the default value and it describes the current nova\n  behavior. Nova will boot VMs with PCI device if the PCI device is\n  associated with at least one NUMA nodes on which the or there is no\n  information about PCI-NUMA association\n\n- required - nova will boot VMs with PCI devices *only* if at least one\n  of the NUMA node is associated with these PCI devices.\n\n- preferred - nova will boot VMs ignoring association of NUMA nodes and\n  PCI devices.\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}, {'number': 16, 'created': '2017-11-23 18:16:27.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/objects/instance_numa_topology.py', 'nova/objects/fields.py', 'nova/tests/unit/objects/test_instance_numa_topology.py', 'nova/tests/unit/pci/test_stats.py', 'releasenotes/notes/share-pci-between-numa-nodes-0bd206eeca4ebcde.yaml', 'nova/tests/unit/objects/test_objects.py', 'nova/exception.py', 'nova/virt/hardware.py', 'nova/tests/unit/objects/test_image_meta.py', 'nova/objects/image_meta.py', 'nova/pci/stats.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7be4769f0fdc7a2b80e66ca0a2ea99806b4267b0', 'message': ""Added PCI NUMA policies\n\nThis patch adds new policies for PCI devices allocation.\n\nTo store policies following fields were added:\n\n- extra spec 'hw:pci_numa_affinity_policy' for flavor\n\n- metadata field 'hw_pci_numa_affinity_policy' for image\n\nThere are 3 policies:\n\n- legacy - this is the default value and it describes the current nova\n  behavior. Nova will boot VMs with PCI device if the PCI device is\n  associated with at least one NUMA node on which the instance should\n  be booted or there is no information about PCI-NUMA association\n\n- required - nova will boot VMs with PCI devices *only* if at least one\n  of the VM's NUMA node is associated with these PCI devices.\n\n- preferred - nova will boot VMs using best effort NUMA affinity\n\nbp share-pci-between-numa-nodes\n\nChange-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9\n""}]",36,390520,7be4769f0fdc7a2b80e66ca0a2ea99806b4267b0,257,29,16,9569,,,0,"Added PCI NUMA policies

This patch adds new policies for PCI devices allocation.

To store policies following fields were added:

- extra spec 'hw:pci_numa_affinity_policy' for flavor

- metadata field 'hw_pci_numa_affinity_policy' for image

There are 3 policies:

- legacy - this is the default value and it describes the current nova
  behavior. Nova will boot VMs with PCI device if the PCI device is
  associated with at least one NUMA node on which the instance should
  be booted or there is no information about PCI-NUMA association

- required - nova will boot VMs with PCI devices *only* if at least one
  of the VM's NUMA node is associated with these PCI devices.

- preferred - nova will boot VMs using best effort NUMA affinity

bp share-pci-between-numa-nodes

Change-Id: I6bf6b47fb714af7721cd8cc848f49948df90f1e9
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/390520/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/virt/hardware.py', 'nova/objects/instance_numa_topology.py', 'nova/objects/fields.py', 'nova/pci/stats.py']",5,3fe1d8ff2b27a59157749e723ec5bcc9e0f287a6,bp/share-pci-between-numa-nodes," def _filter_pools_for_numa_cells(pools, numa_cells, policy=None): if policy == 3: return pools numa_cells = [cell.id for cell in numa_cells] if policy == 2: numa_cells.append(None) "," def _filter_pools_for_numa_cells(pools, numa_cells): numa_cells = [None] + [cell.id for cell in numa_cells]",73,3
openstack%2Fopenstack-zuul-jobs~master~I1cf54bec08dd3253c394473daa34c125af67b410,openstack/openstack-zuul-jobs,master,I1cf54bec08dd3253c394473daa34c125af67b410,Add in branch case for puppet-ceph stable/jewel,MERGED,2017-11-08 17:29:02.000000000,2017-12-12 17:22:53.000000000,2017-11-09 09:58:09.000000000,"[{'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8297}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-08 17:29:02.000000000', 'files': ['playbooks/legacy/puppet-unit-4.8-centos-7/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/174ecf50476d063566f43dddd77494406af920e0', 'message': 'Add in branch case for puppet-ceph stable/jewel\n\nSince puppet-ceph does not follow the openstack naming conventions, we\nneed to add a special case so we get the right version of\npuppet-openstack-integration checked out. Until we can switch over to\nthe zuul v3 layout that has this in it as well, we need to update the\nlegacy job to handle a stable/jewel to stable/pike change\n\nChange-Id: I1cf54bec08dd3253c394473daa34c125af67b410\n'}]",0,518585,174ecf50476d063566f43dddd77494406af920e0,9,4,1,14985,,,0,"Add in branch case for puppet-ceph stable/jewel

Since puppet-ceph does not follow the openstack naming conventions, we
need to add a special case so we get the right version of
puppet-openstack-integration checked out. Until we can switch over to
the zuul v3 layout that has this in it as well, we need to update the
legacy job to handle a stable/jewel to stable/pike change

Change-Id: I1cf54bec08dd3253c394473daa34c125af67b410
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/85/518585/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/puppet-unit-4.8-centos-7/run.yaml'],1,174ecf50476d063566f43dddd77494406af920e0,fix-puppet-ceph-ci," ZUUL_BRANCH_REAL=${ZUUL_BRANCH:-master} # Workaround for puppet-ceph, where we need to checkout # puppet-openstack-integration from stable/pike when working on # stable/jewel. # Ceph Jewel works with Newton to Pike if [[ ""$ZUUL_BRANCH"" == ""stable/jewel"" ]]; then ZUUL_BRANCH_REAL='stable/pike' fi /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP \ --cache-dir /opt/git \ --zuul-branch $ZUUL_BRANCH_REAL \", /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \,11,1
openstack%2Frpm-packaging~master~If8f10976efc768569860fcdfda73983efc9ea241,openstack/rpm-packaging,master,If8f10976efc768569860fcdfda73983efc9ea241,osc-lib: Move to singlespec,MERGED,2017-12-06 08:50:59.000000000,2017-12-12 16:59:31.000000000,2017-12-12 10:17:39.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 08:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d8e255e8257f57d81f4c716801e97e3e970fd61b', 'message': 'osc-lib: Move to singlespec\n\nChange-Id: If8f10976efc768569860fcdfda73983efc9ea241\nDepends-On: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839\n'}, {'number': 2, 'created': '2017-12-06 08:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0b4c36f05cca06480911f5fcd23fb71b94bf0314', 'message': 'osc-lib: Move to singlespec\n\nChange-Id: If8f10976efc768569860fcdfda73983efc9ea241\nDepends-On: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839\n'}, {'number': 3, 'created': '2017-12-11 08:58:49.000000000', 'files': ['openstack/osc-lib/osc-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/76f2fda1d80c6a5a056627bac681ea1be80f390a', 'message': 'osc-lib: Move to singlespec\n\nChange-Id: If8f10976efc768569860fcdfda73983efc9ea241\nDepends-On: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839\n'}]",0,525991,76f2fda1d80c6a5a056627bac681ea1be80f390a,27,7,3,7102,,,0,"osc-lib: Move to singlespec

Change-Id: If8f10976efc768569860fcdfda73983efc9ea241
Depends-On: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/91/525991/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/osc-lib/osc-lib.spec.j2'],1,d8e255e8257f57d81f4c716801e97e3e970fd61b,singlespec,"{% set pypi_name = 'osc-lib' %} {% set upstream_version = upstream_version('1.7.0') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }}Source0: {{ source }}BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('Babel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('cliff', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('fixtures', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('keystoneauth1', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('mock', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('os-client-config', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('os-testr', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslo.i18n', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslo.utils', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslotest', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('osprofiler', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pbr', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('reno', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('requests-mock', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('simplejson', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('six', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('stevedore', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testrepository', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testtools', py_versions=['py2', 'py3']) }}%python_subpackages%package -n python-osc-lib-doc%description -h python-osc-lib-doc%autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }}%{python_build}%{python_install}%{python_expand rm -rf .testrepository $python setup.py testr } %files %{python_files}%{python_sitelib}/osc_lib %{python_sitelib}/*.egg-info %files -n python-osc-lib-doc",%global sname osc-lib Name: {{ py2name('osc-lib') }} Version: 1.7.0 Release: 0Source0: https://files.pythonhosted.org/packages/source/o/%{sname}/%{sname}-%{version}.tar.gzBuildRequires: {{ py2pkg('Babel') }} BuildRequires: {{ py2pkg('cliff') }} BuildRequires: {{ py2pkg('devel') }} BuildRequires: {{ py2pkg('fixtures') }} BuildRequires: {{ py2pkg('keystoneauth1') }} BuildRequires: {{ py2pkg('mock') }} BuildRequires: {{ py2pkg('os-client-config') }} BuildRequires: {{ py2pkg('os-testr') }} BuildRequires: {{ py2pkg('oslo.i18n') }} BuildRequires: {{ py2pkg('oslo.utils') }} BuildRequires: {{ py2pkg('oslotest') }} BuildRequires: {{ py2pkg('osprofiler') }} BuildRequires: {{ py2pkg('pbr') }} BuildRequires: {{ py2pkg('reno') }} BuildRequires: {{ py2pkg('requests-mock') }} BuildRequires: {{ py2pkg('simplejson') }} BuildRequires: {{ py2pkg('six') }} BuildRequires: {{ py2pkg('stevedore') }} BuildRequires: {{ py2pkg('testrepository') }} BuildRequires: {{ py2pkg('testtools') }}%package doc%description doc%autosetup -n %{sname}-%{version}%{__python2} setup.py build%{__python2} setup.py install --skip-build --root %{buildroot}%{__python2} setup.py testr %files%{python2_sitelib}/osc_lib %{python2_sitelib}/*.egg-info %files doc,42,36
openstack%2Frpm-packaging~master~Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839,openstack/rpm-packaging,master,Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839,osprofiler: Move to singlespec,MERGED,2017-12-06 07:56:47.000000000,2017-12-12 16:57:42.000000000,2017-12-12 10:17:38.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 17130}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-06 07:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fa742b228a71a9cb089629b48b93e79298436605', 'message': 'osprofiler: Move to singlespec\n\nChange-Id: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839\n'}, {'number': 2, 'created': '2017-12-06 08:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6e75aae97638553e83519b39405d9321f4797506', 'message': 'osprofiler: Move to singlespec\n\nDepends-On: I7e6028d6e77c415ec49e8bd0722bc815a8247335\nDepends-On: Iccb210ca98b48d1a371cbbeee2e2eddae82e68cc\nDepends-On: I1b3072b9a2cd76b0d0c31d88a9e36437048c035b\nChange-Id: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839\n'}, {'number': 3, 'created': '2017-12-11 08:58:41.000000000', 'files': ['openstack/osprofiler/osprofiler.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a33822fe6b1fe0f9d337394b740f4538723fcc67', 'message': 'osprofiler: Move to singlespec\n\nDepends-On: I7e6028d6e77c415ec49e8bd0722bc815a8247335\nDepends-On: Iccb210ca98b48d1a371cbbeee2e2eddae82e68cc\nDepends-On: I1b3072b9a2cd76b0d0c31d88a9e36437048c035b\nChange-Id: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839\n'}]",0,525932,a33822fe6b1fe0f9d337394b740f4538723fcc67,24,7,3,7102,,,0,"osprofiler: Move to singlespec

Depends-On: I7e6028d6e77c415ec49e8bd0722bc815a8247335
Depends-On: Iccb210ca98b48d1a371cbbeee2e2eddae82e68cc
Depends-On: I1b3072b9a2cd76b0d0c31d88a9e36437048c035b
Change-Id: Icf6ddd5d90c5cb477f8e43f69efa2a51358c6839
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/32/525932/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/osprofiler/osprofiler.spec.j2'],1,fa742b228a71a9cb089629b48b93e79298436605,singlespec,"{% set pypi_name = 'osprofiler' %} {% set upstream_version = upstream_version('1.14.0') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }}Source0: {{ source }}BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('WebOb', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('python-ceilometerclient', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('ddt', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('elasticsearch', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('mock', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslo.concurrency', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslo.config', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslo.log', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('oslo.utils', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pymongo', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('python-subunit', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('redis', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('six', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testrepository', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testtools', py_versions=['py2', 'py3']) }}%if 0%{?suse_version} Requires(post): update-alternatives Requires(postun): update-alternatives %else # on RDO, update-alternatives is in chkconfig Requires(post): chkconfig Requires(postun): chkconfig %endif %python_subpackages%package -n python-osprofiler-doc%description -n python-osprofiler-doc%autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }}%{python_build}%{python_install} %python_clone -a %{buildroot}%{_bindir}/osprofiler%post %python_install_alternative osprofiler %postun %python_uninstall_alternative osprofiler %check %{python_expand rm -rf .testrepository $python setup.py testr } %files %{python_files}%{python_sitelib}/osprofiler %{python_sitelib}/*.egg-info %python_alternative %{_bindir}/osprofiler %files -n python-osprofiler-doc",%global sname osprofiler Name: {{ py2name('osprofiler') }} Version: 1.14.0 Release: 0Source0: https://files.pythonhosted.org/packages/source/o/%{sname}/%{sname}-%{version}.tar.gzBuildRequires: {{ py2pkg('WebOb') }} BuildRequires: {{ py2pkg('python-ceilometerclient') }} BuildRequires: {{ py2pkg('ddt') }} BuildRequires: {{ py2pkg('devel') }} BuildRequires: {{ py2pkg('elasticsearch') }} BuildRequires: {{ py2pkg('mock') }} BuildRequires: {{ py2pkg('oslo.concurrency') }} BuildRequires: {{ py2pkg('oslo.config') }} BuildRequires: {{ py2pkg('oslo.log') }} BuildRequires: {{ py2pkg('oslo.utils') }} BuildRequires: {{ py2pkg('pymongo') }} BuildRequires: {{ py2pkg('python-subunit') }} BuildRequires: {{ py2pkg('redis') }} BuildRequires: {{ py2pkg('six') }} BuildRequires: {{ py2pkg('testrepository') }} BuildRequires: {{ py2pkg('testtools') }}%package doc%description doc%autosetup -n %{sname}-%{version}%{py2_build}%{py2_install}%check %{__python2} setup.py testr %files%{python2_sitelib}/osprofiler %{python2_sitelib}/*.egg-info %{_bindir}/osprofiler %files doc,55,33
openstack%2Frpm-packaging~master~Iaf90115dee4e0dfcc7a61f961964f7955a51d976,openstack/rpm-packaging,master,Iaf90115dee4e0dfcc7a61f961964f7955a51d976,Update python-mistralclient to 3.1.4,MERGED,2017-12-07 16:49:51.000000000,2017-12-12 16:56:42.000000000,2017-12-12 06:49:17.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-07 16:49:51.000000000', 'files': ['openstack/python-mistralclient/python-mistralclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4d9e72bad921e2babc3e806b2dcd871a587f07b0', 'message': 'Update python-mistralclient to 3.1.4\n\nChange-Id: Iaf90115dee4e0dfcc7a61f961964f7955a51d976\n'}]",0,526457,4d9e72bad921e2babc3e806b2dcd871a587f07b0,13,5,1,17130,,,0,"Update python-mistralclient to 3.1.4

Change-Id: Iaf90115dee4e0dfcc7a61f961964f7955a51d976
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/57/526457/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-mistralclient/python-mistralclient.spec.j2'],1,4d9e72bad921e2babc3e806b2dcd871a587f07b0,python-mistralclient,Version: 3.1.4,Version: 3.1.3,1,1
openstack%2Frpm-packaging~master~I5cdaa13001ffdf4981f3561cdf928806e9836c4a,openstack/rpm-packaging,master,I5cdaa13001ffdf4981f3561cdf928806e9836c4a,Update python-watcherclient to 1.5.0,MERGED,2017-12-08 14:43:44.000000000,2017-12-12 16:47:21.000000000,2017-12-11 22:12:02.000000000,"[{'_account_id': 6593}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-12-08 14:43:44.000000000', 'files': ['openstack/python-watcherclient/python-watcherclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/57dd454eed17d64ce5a705685f3d9b09ca5ca26f', 'message': 'Update python-watcherclient to 1.5.0\n\nDepends-on: I45de48c7730120d0ce9ac613b5371c7f70d19396\nChange-Id: I5cdaa13001ffdf4981f3561cdf928806e9836c4a\n'}]",0,526690,57dd454eed17d64ce5a705685f3d9b09ca5ca26f,14,5,1,17130,,,0,"Update python-watcherclient to 1.5.0

Depends-on: I45de48c7730120d0ce9ac613b5371c7f70d19396
Change-Id: I5cdaa13001ffdf4981f3561cdf928806e9836c4a
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/90/526690/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-watcherclient/python-watcherclient.spec.j2'],1,57dd454eed17d64ce5a705685f3d9b09ca5ca26f,python-watcherclient,Version: 1.5.0,Version: 1.4.0,1,1
openstack%2Ftripleo-quickstart-extras~master~I697caeb6b02edbf169a60d112d99570b61e6d6eb,openstack/tripleo-quickstart-extras,master,I697caeb6b02edbf169a60d112d99570b61e6d6eb,Handle overcloud_dns_servers as string too.,ABANDONED,2017-12-12 08:05:17.000000000,2017-12-12 16:04:11.000000000,,"[{'_account_id': 6926}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2017-12-12 08:05:17.000000000', 'files': ['roles/overcloud-prep-network/templates/overcloud-prep-network.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fcc96c2f24576dfe40772b8bd1c9e8e424cdfba6', 'message': ""Handle overcloud_dns_servers as string too.\n\nEven though the parameter overcloud_dns_servers\nis defined as a list in the documentation, the user\ncan easily specify the field as a single string if\nthere is only one dns ip address to include.\n\nIf that's the case, then the error from LP #173755\noccurs. So, in order to handle this case a new\ncondition has been added to differenciate when a list\nor a string is assigned to the variable.\n\nChange-Id: I697caeb6b02edbf169a60d112d99570b61e6d6eb\nCloses-Bug: #1737555\n""}]",0,527334,fcc96c2f24576dfe40772b8bd1c9e8e424cdfba6,10,4,1,26343,,,0,"Handle overcloud_dns_servers as string too.

Even though the parameter overcloud_dns_servers
is defined as a list in the documentation, the user
can easily specify the field as a single string if
there is only one dns ip address to include.

If that's the case, then the error from LP #173755
occurs. So, in order to handle this case a new
condition has been added to differenciate when a list
or a string is assigned to the variable.

Change-Id: I697caeb6b02edbf169a60d112d99570b61e6d6eb
Closes-Bug: #1737555
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/34/527334/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-prep-network/templates/overcloud-prep-network.sh.j2'],1,fcc96c2f24576dfe40772b8bd1c9e8e424cdfba6,bug/173755," {% if overcloud_dns_servers is iterable and overcloud_dns_servers is not string %} {% for nameserver in overcloud_dns_servers %} --dns-nameserver ""{{ nameserver }}"" {% endfor %} {% else %} --dns-nameserver ""{{overcloud_dns_servers}}"" {% endif %}"," {% for nameserver in overcloud_dns_servers %} --dns-nameserver ""{{ nameserver }}"" {% endfor %}",7,1
openstack%2Fnova~master~Ib1b6b223c9d04579828d47607006ecd98b472e5a,openstack/nova,master,Ib1b6b223c9d04579828d47607006ecd98b472e5a,Add new style volume attachment support to block_device.py,MERGED,2017-12-05 23:45:07.000000000,2017-12-12 15:57:18.000000000,2017-12-09 02:58:57.000000000,"[{'_account_id': 7}, {'_account_id': 782}, {'_account_id': 2243}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9562}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}]","[{'number': 1, 'created': '2017-12-05 23:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56964b0f2c8dc5b3218f363ccb3422c34eaf75c3', 'message': 'WIP: Add new style volume attachment support to block_device.py\n\nThis plumbs in the new-style volume attachment support to the\nvirt driver block device code which does the actual work of\nattaching the volume via the driver and completing the attachment\nwith cinder (the thing that makes the volume status ""in-use"").\n\nAt this point, none of the new flow is exercised outside of tests\nbecause we are not yet setting the attachment_id when attaching\nvolumes, that comes in a later change to the API.\n\nIt\'s worth noting that when nova creates a volume during boot\nfrom volume for a source_type=blank/image/snapshot BDM, we won\'t\nhave an attachment_id for that volume so we\'ll attach using the\nold flow. For now this is OK, but might be something we need to\nrevisit in the future when we eventually want to remove the old\nflow.\n\nCo-Authored-By: Matt Riedemann <mriedem.os@gmail.com>\n\nPart of blueprint cinder-new-attach-apis\n\nChange-Id: Ib1b6b223c9d04579828d47607006ecd98b472e5a\n'}, {'number': 2, 'created': '2017-12-06 20:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bb62fadf452e87a49ea6f508db9ea8a4288f3c0', 'message': 'Add new style volume attachment support to block_device.py\n\nThis plumbs in the new-style volume attachment support to the\nvirt driver block device code which does the actual work of\nattaching the volume via the driver and completing the attachment\nwith cinder (the thing that makes the volume status ""in-use"").\n\nAt this point, none of the new flow is exercised outside of tests\nbecause we are not yet setting the attachment_id when attaching\nvolumes, that comes in a later change to the API.\n\nIt\'s worth noting that when nova creates a volume during boot\nfrom volume for a source_type=blank/image/snapshot BDM, we won\'t\nhave an attachment_id for that volume so we\'ll attach using the\nold flow. For now this is OK, but might be something we need to\nrevisit in the future when we eventually want to remove the old\nflow.\n\nThe structure here is to separate the old/new attach flows into\nseparate methods, despite quite a bit of copy/paste code in both\nplaces. A single method using conditionals in different places\nis arguably uglier (as seen in the test code) and we could likely\nconsolidate some of the common code into helper methods later.\n\nNote that test_refresh_connection_info_with_attachment_id is\nremoved since it\'s now redundant with test_refresh_connection.\n\nCo-Authored-By: Matt Riedemann <mriedem.os@gmail.com>\n\nPart of blueprint cinder-new-attach-apis\n\nChange-Id: Ib1b6b223c9d04579828d47607006ecd98b472e5a\n'}, {'number': 3, 'created': '2017-12-06 21:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b53ae6b10ac253a178d030d09da05bdcca6e46a1', 'message': 'Add new style volume attachment support to block_device.py\n\nThis plumbs in the new-style volume attachment support to the\nvirt driver block device code which does the actual work of\nattaching the volume via the driver and completing the attachment\nwith cinder (the thing that makes the volume status ""in-use"").\n\nAt this point, none of the new flow is exercised outside of tests\nbecause we are not yet setting the attachment_id when attaching\nvolumes, that comes in a later change to the API.\n\nIt\'s worth noting that when nova creates a volume during boot\nfrom volume for a source_type=blank/image/snapshot BDM, we won\'t\nhave an attachment_id for that volume so we\'ll attach using the\nold flow. For now this is OK, but might be something we need to\nrevisit in the future when we eventually want to remove the old\nflow.\n\nThe structure here is to separate the old/new attach flows into\nseparate methods, despite quite a bit of copy/paste code in both\nplaces. A single method using conditionals in different places\nis arguably uglier (as seen in the test code) and we could likely\nconsolidate some of the common code into helper methods later.\n\nNote that test_refresh_connection_info_with_attachment_id is\nremoved since it\'s now redundant with test_refresh_connection.\n\nCo-Authored-By: Matt Riedemann <mriedem.os@gmail.com>\n\nPart of blueprint cinder-new-attach-apis\n\nChange-Id: Ib1b6b223c9d04579828d47607006ecd98b472e5a\n'}, {'number': 4, 'created': '2017-12-07 15:33:19.000000000', 'files': ['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2d68fbe56582cebf4b0d8286e9821f863e452699', 'message': 'Add new style volume attachment support to block_device.py\n\nThis plumbs in the new-style volume attachment support to the\nvirt driver block device code which does the actual work of\nattaching the volume via the driver and completing the attachment\nwith cinder (the thing that makes the volume status ""in-use"").\n\nAt this point, none of the new flow is exercised outside of tests\nbecause we are not yet setting the attachment_id when attaching\nvolumes, that comes in a later change to the API.\n\nIt\'s worth noting that when nova creates a volume during boot\nfrom volume for a source_type=blank/image/snapshot BDM, we won\'t\nhave an attachment_id for that volume so we\'ll attach using the\nold flow. For now this is OK, but might be something we need to\nrevisit in the future when we eventually want to remove the old\nflow.\n\nThe structure here is to separate the old/new attach flows into\nseparate methods, despite quite a bit of copy/paste code in both\nplaces. A single method using conditionals in different places\nis arguably uglier (as seen in the test code) and we could likely\nconsolidate some of the common code into helper methods later.\n\nNote that test_refresh_connection_info_with_attachment_id is\nremoved since it\'s now redundant with test_refresh_connection.\n\nCo-Authored-By: Matt Riedemann <mriedem.os@gmail.com>\n\nPart of blueprint cinder-new-attach-apis\n\nChange-Id: Ib1b6b223c9d04579828d47607006ecd98b472e5a\n'}]",36,525787,2d68fbe56582cebf4b0d8286e9821f863e452699,85,17,4,6873,,,0,"Add new style volume attachment support to block_device.py

This plumbs in the new-style volume attachment support to the
virt driver block device code which does the actual work of
attaching the volume via the driver and completing the attachment
with cinder (the thing that makes the volume status ""in-use"").

At this point, none of the new flow is exercised outside of tests
because we are not yet setting the attachment_id when attaching
volumes, that comes in a later change to the API.

It's worth noting that when nova creates a volume during boot
from volume for a source_type=blank/image/snapshot BDM, we won't
have an attachment_id for that volume so we'll attach using the
old flow. For now this is OK, but might be something we need to
revisit in the future when we eventually want to remove the old
flow.

The structure here is to separate the old/new attach flows into
separate methods, despite quite a bit of copy/paste code in both
places. A single method using conditionals in different places
is arguably uglier (as seen in the test code) and we could likely
consolidate some of the common code into helper methods later.

Note that test_refresh_connection_info_with_attachment_id is
removed since it's now redundant with test_refresh_connection.

Co-Authored-By: Matt Riedemann <mriedem.os@gmail.com>

Part of blueprint cinder-new-attach-apis

Change-Id: Ib1b6b223c9d04579828d47607006ecd98b472e5a
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/525787/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py']",2,56964b0f2c8dc5b3218f363ccb3422c34eaf75c3,bp/multi-attach-volume," def _legacy_volume_attach(self, context, volume, connector, instance, volume_api, virt_driver, do_driver_attach=False): def _volume_attach(self, context, volume, connector, instance, volume_api, virt_driver, attachment_id, do_driver_attach=False): # This is where we actually (finally) make a call down to the device # driver and actually create/establish the connection. We'll go from # here to block driver-->os-brick and back up. volume_id = volume['id'] # NOTE(jdg): For now we're assuming no multi-attach, so if # an attach_id exists, we use it and update the record # we can adapt this easily for multi-attach by inspecting # details like instance.id and connection_info. Only trick # is if we do ""multi-attach to same instance"" # We do this special handling for things like unshelve/migrate connector['mount_device'] = self['mount_device'] LOG.debug(""Updating existing attachment record: %s"", attachment_id) self['connection_info'] = volume_api.attachment_update( context, attachment_id, connector)['connection_info'] # # NOTE(ildikov): With the new attach flow Cinder stores the # # connection_info as well. In principle we would like to retrieve the # # information from Cinder, but it needs more refactoring in the code # # so we keep storing it in the BDM for now. # connection_info_string = jsonutils.dumps( # self['connection_info']) # self._bdm_obj.connection_info = connection_info_string if 'serial' not in self['connection_info']: self['connection_info']['serial'] = self.volume_id if self.volume_size is None: self.volume_size = volume.get('size') self._preserve_multipath_id(self['connection_info']) # FIXME(mriedem): Why don't we do this *after* the # virt_driver.attach_volume call is successful like in the legacy # flow? Otherwise we now have a BDM with connection_info set in Nova # even though we failed to connect the volume. self.save() if do_driver_attach: encryption = encryptors.get_encryption_metadata( context, volume_api, volume_id, self['connection_info']) try: virt_driver.attach_volume( context, self['connection_info'], instance, self['mount_device'], disk_bus=self['disk_bus'], device_type=self['device_type'], encryption=encryption) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(""Driver failed to attach volume "" ""%(volume_id)s at %(mountpoint)s"", {'volume_id': volume_id, 'mountpoint': self['mount_device']}, instance=instance) volume_api.attachment_delete(context, attachment_id) # TODO(mriedem): Do we need to handle a failure here and call # attachment_delete and/or driver_detach if do_driver_attach is True? # That's what the legacy flow does. volume_api.attachment_complete(context, attachment_id) @update_db def attach(self, context, instance, volume_api, virt_driver, do_driver_attach=False, **kwargs): volume = volume_api.get(context, self.volume_id) volume_api.check_availability_zone(context, volume, instance=instance) context = context.elevated() connector = virt_driver.get_volume_connector(instance) if not self['attachment_id']: self._legacy_volume_attach(context, volume, connector, instance, volume_api, virt_driver, do_driver_attach) else: self._volume_attach(context, volume, connector, instance, volume_api, virt_driver, self['attachment_id'], do_driver_attach) "," @update_db def attach(self, context, instance, volume_api, virt_driver, do_driver_attach=False, **kwargs): volume = volume_api.get(context, self.volume_id) volume_api.check_availability_zone(context, volume, instance=instance) context = context.elevated() connector = virt_driver.get_volume_connector(instance)",180,60
openstack%2Fopenstack-ansible-rsyslog_server~master~I30705db5716e9040c3d0d14e95c4c6cd1b568cf5,openstack/openstack-ansible-rsyslog_server,master,I30705db5716e9040c3d0d14e95c4c6cd1b568cf5,Updated from OpenStack Ansible Tests,MERGED,2017-12-06 00:07:06.000000000,2017-12-12 15:38:37.000000000,2017-12-12 15:38:37.000000000,"[{'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-06 00:07:06.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/ef3900adf832620ae854824439939b0f4e3f8c61', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I30705db5716e9040c3d0d14e95c4c6cd1b568cf5\n'}]",0,525837,ef3900adf832620ae854824439939b0f4e3f8c61,9,4,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I30705db5716e9040c3d0d14e95c4c6cd1b568cf5
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/37/525837/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,ef3900adf832620ae854824439939b0f4e3f8c61,openstack/openstack-ansible-tests/sync-tests,# The gcc compiler gcc libffi-devel [platform:rpm] openssl-devel [platform:rpm],gcc [platform:dpkg]gcc [platform:rpm]libffi-devel [platform:rpm !platform:opensuseproject-42] libffi-devel-gcc5 [platform:opensuseproject-42] openssl-devel [platform:redhat] libopenssl-devel [platform:suse],5,6
openstack%2Fironic-python-agent~master~I6599436609c4df313f06dd19f8059db4dfa2ff6f,openstack/ironic-python-agent,master,I6599436609c4df313f06dd19f8059db4dfa2ff6f,Warn if extension fails to load,ABANDONED,2016-02-24 17:52:33.000000000,2017-12-12 15:34:21.000000000,,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 13636}]","[{'number': 1, 'created': '2016-02-24 17:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/cb3ed101743e235ebbd5f4019d26edb992b6b2fe', 'message': 'Warn if extension fails to load\n\nOr should we explode? Probably the latter, but as a start... :)\n\nChange-Id: I6599436609c4df313f06dd19f8059db4dfa2ff6f\n'}, {'number': 2, 'created': '2016-08-11 11:26:03.000000000', 'files': ['ironic_python_agent/agent.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/91a94b9ddc1753e60b50780fc5a95ebb5b3215d0', 'message': 'Warn if extension fails to load\n\nOr should we explode? Probably the latter, but as a start... :)\n\nChange-Id: I6599436609c4df313f06dd19f8059db4dfa2ff6f\n'}]",4,284309,91a94b9ddc1753e60b50780fc5a95ebb5b3215d0,12,4,2,10343,,,0,"Warn if extension fails to load

Or should we explode? Probably the latter, but as a start... :)

Change-Id: I6599436609c4df313f06dd19f8059db4dfa2ff6f
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/09/284309/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/agent.py'],1,cb3ed101743e235ebbd5f4019d26edb992b6b2fe,284309,"LOG = log.getLogger(__name__) def _warn_ext_load_failure(manager, entrypoint, exc): LOG.warn('Extension %s failed to load with exception %s', entrypoint, exc) on_load_failure_callback=_warn_ext_load_failure,",,8,0
openstack%2Fironic~master~I7aa6e561a04f7f160456f9c3cd28f2c5dd84fee4,openstack/ironic,master,I7aa6e561a04f7f160456f9c3cd28f2c5dd84fee4,WIP: hacks for multinode without ironic on primary,ABANDONED,2017-03-02 19:28:08.000000000,2017-12-12 15:33:23.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-03-02 19:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/61874d10e48a4373affecae3af9e260f38e9350d', 'message': 'WIP: hacks for multinode without ironic on primary\n\nChange-Id: I7aa6e561a04f7f160456f9c3cd28f2c5dd84fee4\n'}, {'number': 2, 'created': '2017-03-31 13:10:32.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/87363f20b95c629ee3518303ccc8cf2c14f878a1', 'message': 'WIP: hacks for multinode without ironic on primary\n\nChange-Id: I7aa6e561a04f7f160456f9c3cd28f2c5dd84fee4\n'}]",0,440775,87363f20b95c629ee3518303ccc8cf2c14f878a1,14,6,2,10343,,,0,"WIP: hacks for multinode without ironic on primary

Change-Id: I7aa6e561a04f7f160456f9c3cd28f2c5dd84fee4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/75/440775/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,61874d10e48a4373affecae3af9e260f38e9350d,," net_id=$(openstack network show $IRONIC_PROVISION_NETWORK_NAME -f value -c id || true) if [[ ""$net_id"" == """" ]]; then fi if [[ ""$HOST_TOPOLOGY_ROLE"" != 'subnode' ]]; then #if [[ ""$HOST_TOPOLOGY_ROLE"" != ""subnode"" ]]; then #fi #if [[ ""$HOST_TOPOLOGY_ROLE"" != 'subnode' ]]; then #else # # NOTE(vsaienko) we enrolling IRONIC_VM_COUNT on each node. So on subnode # # we expect to have 2 x total_cpus # total_nodes=$(( total_nodes * 2 )) # total_cpus=$(( total_cpus * 2 )) #fi #wait_for_nova_resources ""count"" $total_nodes #wait_for_nova_resources ""vcpus"" $total_cpus #if [[ ""$HOST_TOPOLOGY_ROLE"" != 'subnode' ]]; then #else # IRONIC_DEPLOY_KERNEL_ID=$(openstack image show $ironic_deploy_kernel_name -f value -c id) # IRONIC_DEPLOY_RAMDISK_ID=$(openstack image show $ironic_deploy_ramdisk_name -f value -c id) #fi"," if [[ ""$HOST_TOPOLOGY_ROLE"" != 'subnode' ]]; then net_id=$(openstack network show $IRONIC_PROVISION_NETWORK_NAME -f value -c id) if [[ ""$HOST_TOPOLOGY_ROLE"" != ""subnode"" ]]; then fi if [[ ""$HOST_TOPOLOGY_ROLE"" != 'subnode' ]]; then else # NOTE(vsaienko) we enrolling IRONIC_VM_COUNT on each node. So on subnode # we expect to have 2 x total_cpus total_nodes=$(( total_nodes * 2 )) total_cpus=$(( total_cpus * 2 )) fi wait_for_nova_resources ""count"" $total_nodes wait_for_nova_resources ""vcpus"" $total_cpus if [[ ""$HOST_TOPOLOGY_ROLE"" != 'subnode' ]]; then else IRONIC_DEPLOY_KERNEL_ID=$(openstack image show $ironic_deploy_kernel_name -f value -c id) IRONIC_DEPLOY_RAMDISK_ID=$(openstack image show $ironic_deploy_ramdisk_name -f value -c id) fi",20,18
openstack%2Fironic~master~I13f43c386d3012080774e2aa561bffbaf8c90b20,openstack/ironic,master,I13f43c386d3012080774e2aa561bffbaf8c90b20,Move devstack settings to actual settings file,ABANDONED,2017-02-09 14:27:54.000000000,2017-12-12 15:33:12.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10379}, {'_account_id': 11878}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-02-09 14:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/06b05daf3c8da55f1f815c48a4f37e22d458fdd1', 'message': 'Move devstack settings to actual settings file\n\nThese belong over here, not in the actual lib/ironic file, so\nthat grenade and such can source them.\n\nChange-Id: I13f43c386d3012080774e2aa561bffbaf8c90b20\n'}, {'number': 2, 'created': '2017-02-09 14:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f5f48cdb6b840f7a4cffbddba820c1baa4a84dbe', 'message': 'Move devstack settings to actual settings file\n\nThese belong over here, not in the actual lib/ironic file, so\nthat grenade and such can source them.\n\nChange-Id: I13f43c386d3012080774e2aa561bffbaf8c90b20\n'}, {'number': 3, 'created': '2017-02-09 14:55:53.000000000', 'files': ['devstack/lib/ironic', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f41b41a54fa87a41fd91da3344e101df6f13ab86', 'message': 'Move devstack settings to actual settings file\n\nThese belong over here, not in the actual lib/ironic file, so\nthat grenade and such can source them.\n\nChange-Id: I13f43c386d3012080774e2aa561bffbaf8c90b20\n'}]",1,431572,f41b41a54fa87a41fd91da3344e101df6f13ab86,16,8,3,10343,,,0,"Move devstack settings to actual settings file

These belong over here, not in the actual lib/ironic file, so
that grenade and such can source them.

Change-Id: I13f43c386d3012080774e2aa561bffbaf8c90b20
",git fetch https://review.opendev.org/openstack/ironic refs/changes/72/431572/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/ironic', 'devstack/settings']",2,06b05daf3c8da55f1f815c48a4f37e22d458fdd1,unf-grenade," IRONIC_DIR=$DEST/ironic IRONIC_DEVSTACK_DIR=$IRONIC_DIR/devstack IRONIC_DEVSTACK_FILES_DIR=$IRONIC_DEVSTACK_DIR/files IRONIC_PYTHON_AGENT_DIR=$DEST/ironic-python-agent IRONIC_DATA_DIR=$DATA_DIR/ironic IRONIC_STATE_PATH=/var/lib/ironic IRONIC_AUTH_CACHE_DIR=${IRONIC_AUTH_CACHE_DIR:-/var/cache/ironic} IRONIC_CONF_DIR=${IRONIC_CONF_DIR:-/etc/ironic} IRONIC_CONF_FILE=$IRONIC_CONF_DIR/ironic.conf IRONIC_ROOTWRAP_CONF=$IRONIC_CONF_DIR/rootwrap.conf IRONIC_POLICY_JSON=$IRONIC_CONF_DIR/policy.json # Deploy callback timeout can be changed from its default (1800), if required. IRONIC_CALLBACK_TIMEOUT=${IRONIC_CALLBACK_TIMEOUT:-} # Deploy to hardware platform IRONIC_HW_NODE_CPU=${IRONIC_HW_NODE_CPU:-1} IRONIC_HW_NODE_RAM=${IRONIC_HW_NODE_RAM:-512} IRONIC_HW_NODE_DISK=${IRONIC_HW_NODE_DISK:-10} IRONIC_HW_EPHEMERAL_DISK=${IRONIC_HW_EPHEMERAL_DISK:-0} IRONIC_HW_ARCH=${IRONIC_HW_ARCH:-x86_64} # The file is composed of multiple lines, each line includes fields # separated by white space, in the format: # # <BMC address> <MAC address> <BMC username> <BMC password> [<driver specific fields>] # # For example: # # 192.168.110.107 00:1e:67:57:50:4c root otc123 # # Supported IRONIC_DEPLOY_DRIVERs: # *_ipmitool or ipmi: # <BMC address> <MAC address> <BMC username> <BMC password> # # *_cimc: # <BMC address> <MAC address> <BMC username> <BMC password> # # *_ucs: # <BMC address> <MAC address> <BMC username> <BMC password> <UCS service profile> # # *_oneview: # <Server Hardware URI> <Server Hardware Type URI> <Enclosure Group URI> <Server Profile Template URI> <MAC of primary connection> <Applied Server Profile URI> # # *_drac: # <BMC address> <MAC address> <BMC username> <BMC password> # IRONIC_HWINFO_FILE=${IRONIC_HWINFO_FILE:-$IRONIC_DATA_DIR/hardware_info} # Set up defaults for functional / integration testing IRONIC_NODE_UUID=${IRONIC_NODE_UUID:-`uuidgen`} IRONIC_SCRIPTS_DIR=${IRONIC_SCRIPTS_DIR:-$IRONIC_DEVSTACK_DIR/tools/ironic/scripts} IRONIC_TEMPLATES_DIR=${IRONIC_TEMPLATES_DIR:-$IRONIC_DEVSTACK_DIR/tools/ironic/templates} IRONIC_BAREMETAL_BASIC_OPS=$(trueorfalse False IRONIC_BAREMETAL_BASIC_OPS) IRONIC_SSH_USERNAME=${IRONIC_SSH_USERNAME:-`whoami`} IRONIC_SSH_TIMEOUT=${IRONIC_SSH_TIMEOUT:-15} IRONIC_SSH_ATTEMPTS=${IRONIC_SSH_ATTEMPTS:-5} IRONIC_SSH_KEY_DIR=${IRONIC_SSH_KEY_DIR:-$IRONIC_DATA_DIR/ssh_keys} IRONIC_SSH_KEY_FILENAME=${IRONIC_SSH_KEY_FILENAME:-ironic_key} IRONIC_KEY_FILE=${IRONIC_KEY_FILE:-$IRONIC_SSH_KEY_DIR/$IRONIC_SSH_KEY_FILENAME} IRONIC_SSH_VIRT_TYPE=${IRONIC_SSH_VIRT_TYPE:-virsh} IRONIC_TFTPBOOT_DIR=${IRONIC_TFTPBOOT_DIR:-$IRONIC_DATA_DIR/tftpboot} IRONIC_TFTPSERVER_IP=${IRONIC_TFTPSERVER_IP:-$HOST_IP} IRONIC_VM_SSH_PORT=${IRONIC_VM_SSH_PORT:-22} IRONIC_VM_SSH_ADDRESS=${IRONIC_VM_SSH_ADDRESS:-$HOST_IP} IRONIC_VM_COUNT=${IRONIC_VM_COUNT:-1} IRONIC_VM_SPECS_CPU=${IRONIC_VM_SPECS_CPU:-1} IRONIC_VM_SPECS_RAM=${IRONIC_VM_SPECS_RAM:-1280} IRONIC_VM_SPECS_CPU_ARCH=${IRONIC_VM_SPECS_CPU_ARCH:-'x86_64'} IRONIC_VM_SPECS_DISK=${IRONIC_VM_SPECS_DISK:-10} IRONIC_VM_SPECS_DISK_FORMAT=${IRONIC_VM_SPECS_DISK_FORMAT:-qcow2} IRONIC_VM_EPHEMERAL_DISK=${IRONIC_VM_EPHEMERAL_DISK:-0} IRONIC_VM_EMULATOR=${IRONIC_VM_EMULATOR:-'/usr/bin/qemu-system-x86_64'} IRONIC_VM_ENGINE=${IRONIC_VM_ENGINE:-qemu} IRONIC_VM_NETWORK_BRIDGE=${IRONIC_VM_NETWORK_BRIDGE:-brbm} IRONIC_VM_NETWORK_RANGE=${IRONIC_VM_NETWORK_RANGE:-192.0.2.0/24} IRONIC_VM_MACS_CSV_FILE=${IRONIC_VM_MACS_CSV_FILE:-$IRONIC_DATA_DIR/ironic_macs.csv} IRONIC_AUTHORIZED_KEYS_FILE=${IRONIC_AUTHORIZED_KEYS_FILE:-$HOME/.ssh/authorized_keys} IRONIC_CLEAN_NET_NAME=${IRONIC_CLEAN_NET_NAME:-${IRONIC_PROVISION_NETWORK_NAME:-${PRIVATE_NETWORK_NAME}}} IRONIC_EXTRA_PXE_PARAMS=${IRONIC_EXTRA_PXE_PARAMS:-} IRONIC_TTY_DEV=${IRONIC_TTY_DEV:-ttyS0} IRONIC_TEMPEST_BUILD_TIMEOUT=${IRONIC_TEMPEST_BUILD_TIMEOUT:-${BUILD_TIMEOUT:-}} if [[ -n ""$BUILD_TIMEOUT"" ]]; then echo ""WARNING: BUILD_TIMEOUT variable is renamed to IRONIC_TEMPEST_BUILD_TIMEOUT and will be deprecated in Pike."" fi # driver / hardware type options IRONIC_ENABLED_DRIVERS=${IRONIC_ENABLED_DRIVERS:-fake,pxe_ipmitool,agent_ipmitool} # TODO(jroll) add enabled/default interfaces here IRONIC_ENABLED_HARDWARE_TYPES=${IRONIC_ENABLED_HARDWARE_TYPES:-ipmi} # By default, baremetal VMs will console output to file. IRONIC_VM_LOG_CONSOLE=$(trueorfalse True IRONIC_VM_LOG_CONSOLE) IRONIC_VM_LOG_DIR=${IRONIC_VM_LOG_DIR:-$IRONIC_DATA_DIR/logs/} IRONIC_VM_LOG_ROTATE=$(trueorfalse True IRONIC_VM_LOG_ROTATE) # Set resource_classes for nodes to use Nova's placement engine IRONIC_USE_RESOURCE_CLASSES=$(trueorfalse False IRONIC_USE_RESOURCE_CLASSES) # Whether to build the ramdisk or download a prebuilt one. IRONIC_BUILD_DEPLOY_RAMDISK=$(trueorfalse True IRONIC_BUILD_DEPLOY_RAMDISK) # Ironic IPA ramdisk type, supported types are: IRONIC_SUPPORTED_RAMDISK_TYPES_RE=""^(coreos|tinyipa|dib)$"" IRONIC_RAMDISK_TYPE=${IRONIC_RAMDISK_TYPE:-tinyipa} # Confirm we have a supported ramdisk type or fail early. if [[ ! ""$IRONIC_RAMDISK_TYPE"" =~ $IRONIC_SUPPORTED_RAMDISK_TYPES_RE ]]; then die $LINENO ""Unrecognized IRONIC_RAMDISK_TYPE: $IRONIC_RAMDISK_TYPE. Expected 'coreos', 'tinyipa' or 'dib'"" fi # If present, these files are used as deploy ramdisk/kernel. # (The value must be an absolute path) IRONIC_DEPLOY_RAMDISK=${IRONIC_DEPLOY_RAMDISK:-$TOP_DIR/files/ir-deploy-$IRONIC_DEPLOY_DRIVER.initramfs} IRONIC_DEPLOY_KERNEL=${IRONIC_DEPLOY_KERNEL:-$TOP_DIR/files/ir-deploy-$IRONIC_DEPLOY_DRIVER.kernel} IRONIC_DEPLOY_ISO=${IRONIC_DEPLOY_ISO:-$TOP_DIR/files/ir-deploy-$IRONIC_DEPLOY_DRIVER.iso} # These parameters describe which image will be used to provision a node in # tempest tests if [[ -z ""$IRONIC_TEMPEST_WHOLE_DISK_IMAGE"" && ""$IRONIC_VM_EPHEMERAL_DISK"" == 0 ]]; then IRONIC_TEMPEST_WHOLE_DISK_IMAGE=True fi IRONIC_TEMPEST_WHOLE_DISK_IMAGE=$(trueorfalse False IRONIC_TEMPEST_WHOLE_DISK_IMAGE) # NOTE(jroll) this needs to be updated when stable branches are cut IPA_DOWNLOAD_BRANCH=${IPA_DOWNLOAD_BRANCH:-master} IPA_DOWNLOAD_BRANCH=$(echo $IPA_DOWNLOAD_BRANCH | tr / -) # Which deploy driver to use - valid choices right now # are ``pxe_ssh``, ``pxe_ipmitool``, ``agent_ssh``, ``agent_ipmitool``, # ``pxe_snmp`` and ``ipmi``. # # Additional valid choices if IRONIC_IS_HARDWARE == true are: # ``pxe_iscsi_cimc``, ``pxe_agent_cimc``, ``pxe_ucs``, ``pxe_cimc``, # ``*_pxe_oneview`` and ``pxe_drac`` IRONIC_DEPLOY_DRIVER=${IRONIC_DEPLOY_DRIVER:-pxe_ipmitool} # This refers the options for disk-image-create and the platform on which # to build the dib based ironic-python-agent ramdisk. # ""ubuntu"" is set as the default value. IRONIC_DIB_RAMDISK_OPTIONS=${IRONIC_DIB_RAMDISK_OPTIONS:-'ubuntu'} # Some drivers in Ironic require deploy ramdisk in bootable ISO format. # Set this variable to ""true"" to build an ISO for deploy ramdisk and # upload to Glance. IRONIC_DEPLOY_ISO_REQUIRED=$(trueorfalse False IRONIC_DEPLOY_ISO_REQUIRED) if [[ ""$IRONIC_DEPLOY_ISO_REQUIRED"" = ""True"" \ && ""$IRONIC_BUILD_DEPLOY_RAMDISK"" = ""False"" \ && -n ""$IRONIC_DEPLOY_ISO"" ]]; then die ""Prebuilt ISOs are not available, provide an ISO via IRONIC_DEPLOY_ISO \ or set IRONIC_BUILD_DEPLOY_RAMDISK=True to use ISOs"" fi # If the requested driver is not yet enable, enable it, if it is not it will fail anyway if [[ -z ""$(echo ${IRONIC_ENABLED_DRIVERS},${IRONIC_ENABLED_HARDWARE_TYPES} | grep -w ${IRONIC_DEPLOY_DRIVER})"" ]]; then die ""The deploy driver $IRONIC_DEPLOY_DRIVER is not in the list of enabled \ drivers $IRONIC_ENABLED_DRIVERS or hardware types $IRONIC_ENABLED_HARDWARE_TYPES"" fi # Support entry points installation of console scripts IRONIC_BIN_DIR=$(get_python_exec_prefix) # Ironic connection info. Note the port must be specified. IRONIC_SERVICE_PROTOCOL=${IRONIC_SERVICE_PROTOCOL:-$SERVICE_PROTOCOL} IRONIC_SERVICE_PORT=${IRONIC_SERVICE_PORT:-6385} IRONIC_HOSTPORT=${IRONIC_HOSTPORT:-$SERVICE_HOST:$IRONIC_SERVICE_PORT} # Enable iPXE IRONIC_IPXE_ENABLED=$(trueorfalse True IRONIC_IPXE_ENABLED) # Options below are only applied when IRONIC_IPXE_ENABLED is True IRONIC_IPXE_USE_SWIFT=$(trueorfalse False IRONIC_IPXE_USE_SWIFT) IRONIC_HTTP_DIR=${IRONIC_HTTP_DIR:-$IRONIC_DATA_DIR/httpboot} IRONIC_HTTP_PORT=${IRONIC_HTTP_PORT:-3928} # Whether DevStack will be setup for bare metal or VMs IRONIC_IS_HARDWARE=$(trueorfalse False IRONIC_IS_HARDWARE) # The first port in the range to bind the Virtual BMCs. The number of # ports that will be used depends on $IRONIC_VM_COUNT variable, e.g if # $IRONIC_VM_COUNT=3 the ports 6230, 6231 and 6232 will be used for the # Virtual BMCs, one for each VM. IRONIC_VBMC_PORT_RANGE_START=${IRONIC_VBMC_PORT_RANGE_START:-6230} IRONIC_VBMC_CONFIG_FILE=${IRONIC_VBMC_CONFIG_FILE:-$HOME/.vbmc/virtualbmc.conf} IRONIC_VBMC_LOGFILE=${IRONIC_VBMC_LOGFILE:-$IRONIC_VM_LOG_DIR/virtualbmc.log} # Virtual PDU configs IRONIC_VPDU_CONFIG_FILE=${IRONIC_VPDU_CONFIG_FILE:-$HOME/.vpdu/virtualpdu.conf} IRONIC_VPDU_PORT_RANGE_START=${IRONIC_VPDU_PORT_RANGE_START:-1} IRONIC_VPDU_LISTEN_PORT=${IRONIC_VPDU_LISTEN_PORT:-1161} IRONIC_VPDU_COMMUNITY=${IRONIC_VPDU_COMMUNITY:-private} IRONIC_VPDU_SNMPDRIVER=${IRONIC_VPDU_SNMPDRIVER:-apc_rackpdu} # To explicitly enable configuration of Glance with Swift # (which is required by some vendor drivers), set this # variable to true. IRONIC_CONFIGURE_GLANCE_WITH_SWIFT=$(trueorfalse False IRONIC_CONFIGURE_GLANCE_WITH_SWIFT) # The path to the libvirt hooks directory, used if IRONIC_VM_LOG_ROTATE is True IRONIC_LIBVIRT_HOOKS_PATH=${IRONIC_LIBVIRT_HOOKS_PATH:-/etc/libvirt/hooks/} # The authentication strategy used by ironic-api. Valid values are: # keystone and noauth. IRONIC_AUTH_STRATEGY=${IRONIC_AUTH_STRATEGY:-keystone} # By default, terminal SSL certificate is disabled. IRONIC_TERMINAL_SSL=$(trueorfalse False IRONIC_TERMINAL_SSL) IRONIC_TERMINAL_CERT_DIR=${IRONIC_TERMINAL_CERT_DIR:-$IRONIC_DATA_DIR/terminal_cert/} # This flag is used to allow adding Link-Local-Connection info # to ironic port-create command. LLC info is obtained from # IRONIC_{VM,HW}_NODES_FILE IRONIC_USE_LINK_LOCAL=$(trueorfalse False IRONIC_USE_LINK_LOCAL) # Allow selecting dhcp provider IRONIC_DHCP_PROVIDER=${IRONIC_DHCP_PROVIDER:-neutron} # This flag is used to specify enabled network drivers IRONIC_ENABLED_NETWORK_INTERFACES=${IRONIC_ENABLED_NETWORK_INTERFACES:-} # This is the network interface to use for a node IRONIC_NETWORK_INTERFACE=${IRONIC_NETWORK_INTERFACE:-} # Ironic provision network name IRONIC_PROVISION_NETWORK_NAME=${IRONIC_PROVISION_NETWORK_NAME:-} # Provision network provider type. Can be flat or vlan. IRONIC_PROVISION_PROVIDER_NETWORK_TYPE=${IRONIC_PROVISION_PROVIDER_NETWORK_TYPE:-'vlan'} # If IRONIC_PROVISION_PROVIDER_NETWORK_TYPE is vlan. VLAN_ID may be specified. If it is not set, # vlan will be allocated dynamically. IRONIC_PROVISION_SEGMENTATION_ID=${IRONIC_PROVISION_SEGMENTATION_ID:-} # Allocation network pool for provision network # Example: IRONIC_PROVISION_ALLOCATION_POOL=start=10.0.5.10,end=10.0.5.100 IRONIC_PROVISION_ALLOCATION_POOL=${IRONIC_PROVISION_ALLOCATION_POOL:-'start=10.0.5.10,end=10.0.5.100'} # Ironic provision subnet name. IRONIC_PROVISION_PROVIDER_SUBNET_NAME=${IRONIC_PROVISION_PROVIDER_SUBNET_NAME:-${IRONIC_PROVISION_NETWORK_NAME}-subnet} # With multinode case all ironic-conductors should have IP from provisioning network. # IRONIC_PROVISION_SUBNET_GATEWAY - is configured on primary node. # Ironic provision subnet gateway. IRONIC_PROVISION_SUBNET_GATEWAY=${IRONIC_PROVISION_SUBNET_GATEWAY:-'10.0.5.1'} IRONIC_PROVISION_SUBNET_SUBNODE_IP=${IRONIC_PROVISION_SUBNET_SUBNODE_IP:-'10.0.5.2'} # Ironic provision subnet prefix # Example: IRONIC_PROVISION_SUBNET_PREFIX=10.0.5.0/24 IRONIC_PROVISION_SUBNET_PREFIX=${IRONIC_PROVISION_SUBNET_PREFIX:-'10.0.5.0/24'} IRONIC_HTTP_SERVER=${IRONIC_HTTP_SERVER:-$IRONIC_TFTPSERVER_IP} # Retrieving logs from the deploy ramdisk # # IRONIC_DEPLOY_LOGS_COLLECT possible values are: # * always: Collect the ramdisk logs from the deployment on success or # failure (Default in DevStack for debugging purpose). # * on_failure: Collect the ramdisk logs upon a deployment failure # (Default in Ironic). # * never: Never collect the ramdisk logs. IRONIC_DEPLOY_LOGS_COLLECT=${IRONIC_DEPLOY_LOGS_COLLECT:-always} # IRONIC_DEPLOY_LOGS_STORAGE_BACKEND possible values are: # * local: To store the logs in the local filesystem (Default in Ironic and DevStack). # * swift: To store the logs in Swift. IRONIC_DEPLOY_LOGS_STORAGE_BACKEND=${IRONIC_DEPLOY_LOGS_STORAGE_BACKEND:-local} # The path to the directory where Ironic should put the logs when IRONIC_DEPLOY_LOGS_STORAGE_BACKEND is set to ""local"" IRONIC_DEPLOY_LOGS_LOCAL_PATH=${IRONIC_DEPLOY_LOGS_LOCAL_PATH:-$IRONIC_VM_LOG_DIR/deploy_logs} # Define baremetal min_microversion in tempest config. Default value None is picked from tempest. TEMPEST_BAREMETAL_MIN_MICROVERSION=${TEMPEST_BAREMETAL_MIN_MICROVERSION:-} # Define baremetal max_microversion in tempest config. No default value means that it is picked from tempest. TEMPEST_BAREMETAL_MAX_MICROVERSION=${TEMPEST_BAREMETAL_MAX_MICROVERSION:-} IRONIC_AUTOMATED_CLEAN_ENABLED=$(trueorfalse True IRONIC_AUTOMATED_CLEAN_ENABLED) # Whether configure the nodes to boot in Legacy BIOS or UEFI mode. Accepted # values are: ""bios"" or ""uefi"", defaults to ""bios"". # # WARNING: UEFI is EXPERIMENTAL. The CirrOS images uploaded by DevStack by # default WILL NOT WORK with UEFI. You will need to download the UEFI capable # images manually from [0] and upload it to Glance before deploying. IRONIC_BOOT_MODE=${IRONIC_BOOT_MODE:-bios} IRONIC_UEFI_FILES_DIR=${IRONIC_UEFI_FILES_DIR:-/var/lib/libvirt/images} UEFI_LOADER_PATH=$IRONIC_UEFI_FILES_DIR/OVMF_CODE.fd UEFI_NVRAM_PATH=$IRONIC_UEFI_FILES_DIR/OVMF_VARS.fd",,291,290
openstack%2Fironic~master~I0a6ade0c1e0c7d3b4096d96551af062cea15b76e,openstack/ironic,master,I0a6ade0c1e0c7d3b4096d96551af062cea15b76e,WIP: docs for dynamic drivers,ABANDONED,2017-01-30 16:03:33.000000000,2017-12-12 15:33:05.000000000,,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-01-30 16:03:33.000000000', 'files': ['doc/source/dev/drivers.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e3eef7cb1d81447757b5ac44007276047c1f6171', 'message': 'WIP: docs for dynamic drivers\n\nChange-Id: I0a6ade0c1e0c7d3b4096d96551af062cea15b76e\n'}]",0,426819,e3eef7cb1d81447757b5ac44007276047c1f6171,7,3,1,10343,,,0,"WIP: docs for dynamic drivers

Change-Id: I0a6ade0c1e0c7d3b4096d96551af062cea15b76e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/19/426819/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/drivers.rst'],1,e3eef7cb1d81447757b5ac44007276047c1f6171,driver-comp-docs,TODO add dynamic drivers ,,2,0
openstack%2Fironic-specs~master~Icb5d0eb36491b5eff9137173206654b002e3bd55,openstack/ironic-specs,master,Icb5d0eb36491b5eff9137173206654b002e3bd55,Add pluggable credentials storage,NEW,2015-05-27 16:07:48.000000000,2017-12-12 15:31:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 7005}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10662}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13295}, {'_account_id': 13362}, {'_account_id': 13719}, {'_account_id': 14614}]","[{'number': 1, 'created': '2015-05-27 16:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b1418766a328cbc7e19954214b389970429b37ed', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 2, 'created': '2015-05-29 16:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e6b6c9d7d88f11a0b98f3ef6f59c5873145edbb4', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 3, 'created': '2015-06-08 16:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/67bdfce62ce7b30569baa69a28e75d1dcab6dc4e', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 4, 'created': '2015-06-10 16:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/60a897a91e4040c563be49f672e406b8158db3a4', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 5, 'created': '2015-06-10 16:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/77028a137b275cf0758769850f241b613b89ec1c', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 6, 'created': '2015-06-11 12:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c4fba72bfee679e3f4598ed784b1044a3dc2caa3', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 7, 'created': '2015-06-18 17:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/79569f3646447d7e1afc7be1c7c1eab810650def', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 8, 'created': '2015-06-27 22:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6f62c1c00a3213bf426d5a86c8aa6f304c16f2d9', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 9, 'created': '2015-08-14 08:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4fdf0f8d63896a3fdd201cb849b5b509f0de54f2', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 10, 'created': '2015-08-25 16:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/04de38e7ca7af35f2db7bb2fb41a19bc9f42386c', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 11, 'created': '2015-08-25 16:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7d0785f43fbc1c213e88d17a2e4b951899469ab3', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 12, 'created': '2015-08-27 14:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/46b1ae1e6b11f1673e0dc1baeedb186d8e4795ae', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 13, 'created': '2015-10-29 10:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/617f5187ef34559b9cb6d47791b9ecc78cfeff0d', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 14, 'created': '2016-01-19 12:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/427490ffbeb6ac6e306ca174be25200399e41aba', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nRelated-Bug: #1526745\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 15, 'created': '2016-01-19 16:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7e7e3f921317a1371926e2c16a146c710e8a331e', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nRelated-Bug: #1526745\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 16, 'created': '2016-03-07 10:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/35dcbb790a5365aab046831c08cd533368ef9a8d', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nRelated-Bug: #1526745\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}, {'number': 17, 'created': '2016-06-14 12:33:04.000000000', 'files': ['specs/approved/pluggable-credential-storage.rst', 'specs/not-implemented/pluggable-credential-storage.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/3ce8c1dcd61a64f584dc23051b5b7172514214ad', 'message': 'Add pluggable credentials storage\n\nAdd the ability to store credentials in credentials storage.\n\nRelated-Bug: #1526745\n\nChange-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55\n'}]",124,186056,3ce8c1dcd61a64f584dc23051b5b7172514214ad,79,17,17,12356,,,0,"Add pluggable credentials storage

Add the ability to store credentials in credentials storage.

Related-Bug: #1526745

Change-Id: Icb5d0eb36491b5eff9137173206654b002e3bd55
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/56/186056/13 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/pluggable-credential-storage.rst'],1,b1418766a328cbc7e19954214b389970429b37ed,bp/pluggable-credential-storage,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Pluggable credential storage ============================ https://blueprints.launchpad.net/ironic/+spec/pluggable-credential-storage This spec proposes adding pluggable credentials storage for storing node's credentials. Problem description =================== Currently, Ironic stores credentials of all nodes in its database, which is insecure, because if one gains access to database, he will also have access to all the baremetal nodes. This task should be delegated to a service that can handle this task more securely. Proposed change =============== Credentials storage base class will be added, which all credential storage implementations should inherit from. Stevedore will load credentials storage module specified in Ironic configuration file using entrypoint in setup.cfg. If a driver has 'credentials_fields' field, defined in driver properties, it will be used to determine which fields should be uploaded to credentials storage. If there is no such field, credentials will be stored as usual in Ironic database. If a driver has 'credentials_fields' field, and prerequisites for using credentials storage provider are met, credentials will be uploaded to the storage in API, before saving them to database. Credentials fields that are set in HTTP request will be changed to some value (like '***') and saved to database to indicate that they were set, so that driver validation would not have to be changed. A link to credentials that were saved in storage will be written to driver_internal_info/credentials_id so that it won't be possible to change this field by updating it manually. Whenever driver needs credentials (e.g. to power node on/off, set boot device), they will be downloaded from credentials storage if driver_internal_info/credentials_id is specified, if not, they will be read from database. As part of this spec's implementation, Keystone's credentials storage will be added to demonstrate how the flow looks like. To use this storage, Keystone should support Identity API v3, and Ironic should be using it. It can be enabled in Ironic's configuration file in keystone_authtoken section. Alternatives ------------ Continue storing credentials in Ironic database. Data model impact ----------------- New key 'credentials_id' will be added to driver_internal_info dictionary. State Machine Impact -------------------- None REST API impact --------------- post, patch and delete node methods will be changed (although all request parameters will remain the same), as uploading, updating and deleting credentials will be performed in these methods, before credentials are saved to database. This implies reaching credentials storage in these methods to do such actions. All HTTP response codes for them will remain the same, as there seems to be only one case when new errors may appear - when there is no credentials data specified in the request and credentials should be created or updated, but it is easily solvable in API. API microversion may need to be incremented. No changes to client library or CLI are necessary. Client (CLI) impact ------------------- None RPC API impact -------------- ironic-api and ironic-conductor should be upgraded together if you want to use this new functionality, as changes should be made to both API and drivers. If you don't want to use it, you may upgrade ironic-api and ironic-conductor independently. For existing deployments, if you enabled some credentials storage provider, when you create or update a node, credentials will be uploaded to credentials storage and will be fetched from there after that. If not, they will be still read from database. Driver API impact ----------------- All drivers can support this feature after slightly changing their power and management interfaces to allow fetching credentials from credentials storage before connecting to BMC. If they won't do that, they will still be able to use credentials stored in database, so third-party drivers can be updated independently from this change Nova driver impact ------------------ None Security impact --------------- Security will be increased in this case, as if one would gain access to Ironic database, he won't be able to get credentials. This change involves uploading user-provided credentials to credentials storage directly at the API level. Other end user impact --------------------- None Scalability impact ------------------ This change adds additional network traffic because of calls to credentials storage to fetch, update or delete credentials. Performance Impact ------------------ Credentials storage will be reached every time Ironic needs to perform some power or management action. This may lead to significant load on it if many nodes are being created/updated/deployed at the same time. Other deployer impact --------------------- credentials_provider option is added to allow specifying credentials storage that will be used, with default value of 'none', meaning that credentials will be stored in database. Developer impact ---------------- credentials_fields list should be added to the existing drivers' properties to enable using this new functionality. Developers will be able to add new plugins for other credentials storages, as stevedore will be loading them using entrypoints specified in setup.cfg. Specifically, Barbican may be also used for this purpose. Implementation ============== Assignee(s) ----------- Primary assignee: vdrok Other contributors: None Work Items ---------- * Implement abstract base Credentials class; * Implement KeystoneCredentials class, which will enable storing credentials in Keystone; * Change existing drivers to support this new feature. Dependencies ============ Related to blueprint: https://blueprints.launchpad.net/ironic/+spec/credential-secure-storage Testing ======= It can be tested in gate if Identity API v3 will be enabled there, without any additional changes to existing scenarios/tests. Upgrades and Backwards Compatibility ==================================== This change is backwards compatible as it allows storing credentials inside database. Documentation Impact ==================== Documentation should be added for this feature. References ========== None ",,219,0
openstack%2Fironic-specs~master~I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67,openstack/ironic-specs,master,I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67,Amend dynamic iPXE configuration spec,NEW,2016-11-01 19:50:38.000000000,2017-12-12 15:29:37.000000000,,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 9542}, {'_account_id': 10239}, {'_account_id': 10453}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 14250}, {'_account_id': 22255}, {'_account_id': 22724}]","[{'number': 1, 'created': '2016-11-01 19:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/8598ab60bd19b507ca6462af869bac37343b5d78', 'message': 'Amend dynamic iPXE configuration spec\n\nthe spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 2, 'created': '2016-11-09 11:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/13e5b86335cfde8fa323855a4b24b01df9cebf0c', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 3, 'created': '2016-11-09 12:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d59707fa0ac85c05ecb294e7a4c8b65d912bc5ec', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 4, 'created': '2016-11-17 14:06:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b38237309f7c84363226ee35c4419fe171a1b29e', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 5, 'created': '2016-11-21 16:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4b584b603837b8b8a000dd752e0ffc2685ce369c', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 6, 'created': '2016-11-28 19:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ed9d26451bd50518175fbe265b4a5ce5e9fe3787', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 7, 'created': '2017-01-25 11:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/516f6d56f155a71d1e9415e71f35cafcfbefaf60', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}, {'number': 8, 'created': '2017-05-08 10:26:05.000000000', 'files': ['specs/approved/ipxe-dynamic-config.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/bfb953429375614b49468bec8f09b63bff399687', 'message': 'Amend dynamic iPXE configuration spec\n\nthe original spec is rather old, and a lot has changed in Ironic in-between.\n\nThis patch amends it with more detailed discussion on why and how to\nimplement this feature, with possible upgrade and security caveats.\n\nChange-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67\nRelated-Bug: #1526275\n'}]",163,392290,bfb953429375614b49468bec8f09b63bff399687,50,12,8,9542,,,0,"Amend dynamic iPXE configuration spec

the original spec is rather old, and a lot has changed in Ironic in-between.

This patch amends it with more detailed discussion on why and how to
implement this feature, with possible upgrade and security caveats.

Change-Id: I1968c4f5c62a7bf1e64db4aef0cc84e04728ed67
Related-Bug: #1526275
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/90/392290/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/approved/ipxe-dynamic-config.rst'],1,8598ab60bd19b507ca6462af869bac37343b5d78,bug/1526275,"Besides, actively managing files being used by other services (like TFTP or HTTP server) makes containerizing Ironic-conductor service more complicated. As iPXE supports fetching boot config and iPXE scripts via HTTP protocol, there is already an HTTP server in Ironic we could use - the Ironic API itself. The proposed implementation consists of creating a new top-level API for fetching iPXE boot script and boot config files, plus RPC and Driver API amendments. For more details and rationale, see the corresponding sections below.``http`` ([#]_, [#]_) as then the iPXE driver won't need to save any state on the disk and ironic-conductor will be almost stateless (especially so when only 'local' boot mode is used). It is proposed to implement both iPXE boot script and boot config endpoints as top-level API endpoints. iPXE boot script ~~~~~~~~~~~~~~~~ API request (synchronous) ``GET <ironic-api-endpoint>/v1/ipxe`` API response * 200(OK) together with the iPXE boot script attached to the response. * 404(NotFound) when this feature is disabled * 500(InternalServerError) on other failures As iPXE boot script is almost static, implementation (similar to ``lookup`` endpoint) could be made without RPC calls from ironic-api to ironic-conductor, rendering the Jinja template of boot script directly in API as only the knowledge of Ironic API endpoint would be required. When Neutron is used with iPXE enabled, Ironic will configure Neutron port's PXE-related DHCP options to make a boot request to this new endpoint. If an operator wants to have an external DHCP server (standalone version) but still benefit from dynamically generated iPXE config files (instead of using static files) it will be possible to serve the same (or similar) iPXE boot script through an external HTTP server or DHCP server itself. By expanding ``${mac}`` variable [#]_ this boot script will point the iPXE bootloader to the other form of this new API: iPXE boot config ~~~~~~~~~~~~~~~~ API request (synchronous) ``GET <ironic-api-endpoint>/v1/ipxe?mac=<MAC>`` API response * 200(OK) together with the iPXE boot config attached to the response. * 404(NotFound) when this feature is disabled * 500(InternalServerError) on other failures On this request Ironic API will: * find the node by the MAC address * check the ``provision_state`` of the node and generate the iPXE configuration file for that state: - for the ``DEPLOYING``, ``DEPLOYWAIT``, ``CLEANING``, ``CLEANWAIT`` and ``INSPECTING`` (and ``ACTIVE``) states, an iPXE configuration to boot the node is returned - (optionally) for inappropriate states an iPXE configuration file that prints out an error explaining the problem on the node's console log is returned and a warning message in the Ironic log. * make the RPC call to ironic-conductor that manages this given node * receive the template for iPXE boot config and parameters to render the template with * render the Jinja template and attach it to response. - for the ``netboot``-ed nodes in ``ACTIVE`` state, an iPXE configuration to boot from the image ramdisk and kernel is rendered and returned - for the node in other approporiate states, the iPXE configuration to boot from deploy kernel and ramdisk is rendered and returned - (optionally) nodes in other states follow the non-``ACTIVE`` case For the sake of backward compatibility with current in-tree iPXE boot script and boot config locations when saved to disk, the MAC address in the ``?mac=<MAC>`` URL query parameter must be in *dashed form*. Serving files over Ironic API as attached to response instead of in response body is already supported. Supporting switching PXE configs for ``netboot``-ed nodes will require more intelligent boot config templates. REST API version change ~~~~~~~~~~~~~~~~~~~~~~~ Contrary to the usual procedure, the API micro-version does not necessarily has to be bumped. Generally iPXE firmware can not insert custom HTTP headers in request, thus limiting such endpoint to only appropriate API micro-version will not work. Instead, the availability of such API must solely depend on the config option enabling this feature. For bookkeeping reasons, the API can be bumped though. The proposed new API endpoints are internal endpoints of Ironic service, and, similar to ``lookup`` and ``heartbeat``, should not be exposed over Python/CLI client. One new call() RPC API method must be added - ``get_ipxe_template``. It will be performed from ironic-api to the conductor managing a given node, and return a path to the template and all parameters necessary to render it on API side.Deploy interface ~~~~~~~~~~~~~~~~ A new abstract deploy interface mixin class will be created. It will contain a single abstract method ``get_ipxe_options`` that will be called from manager's ``get_ipxe_template`` RPC endpoint method. Deploy interfaces wishing to use the new dynamic iPXE boot capabilities must additionally inherit from this new mixin class, and implement the required method. It must return a dictionary with additional parameters to render the boot config file template with. For example, current version of AgentDeploy driver interface must return a dictionary with ``ipa-api-url`` key. Boot interface ~~~~~~~~~~~~~~ A new abstract boot interface mixin class will be created. It will contain a single abstract method ``get_ipxe_options`` that will be called from manager's ``get_ipxe_template`` RPC endpoint method. Deploy interfaces wishing to use the new dynamic iPXE boot capabilities must additionally inherit from this new mixin class, and implement the required method. It must return a full set of parameters needed to render such template on ironic-api side as well as the path to the template itself. Config file generation """""""""""""""""""""""""""""""""""""""""""" Currently (i)PXE config files are created from Jinja templates with a set of not used extra placeholders, which are then replaced on disk by regexp-based substitutions during switching the PXE config for the nodes doing ``netboot``. To support this new feature, the pipeline of creating and changing iPXE configs must be amended to allow fully dynamic template rendering without saving the templates to disk and instead returning the template and corresponding options to render it with. The most change must happen in ""switch PXE config"" part which is not currently using templating at all.NoneGenerally iPXE firmware can not insert custom HTTP headers in requests, thus these new API endpoints **must not require any form of authentication and not be micro-versioned**. Specific care has to be taken to secure access to them similar to currently suggested measures for ``lookup`` and ``heartbeat`` API endpoints [#]_. The iPXE boot script returned will (in most cases?) not contain any sensitive information apart from Ironic API endpoint which the possible attacker already has to know to make such request. Due to iPXE scripting the script returned will not contain the node's MAC address in clear text. On the other hand, the iPXE boot config can contain sensitive information, for example the open, unauthenticated URLs for deployment kernel and ramdisk images when using current ``ipxe_use_swift`` feature. Thus an attacker that performed a successful request to this API endpoint can potentially download those images despite them being private/not generally accessible for the attacker through Image Service or Object Storage service. Whether these images contain any sensitive information themselves must be assessed by the operator when enabling this new feature. The risk is somewhat mitigated by the fact that the attacker has to have a prior knowledge of at least one MAC of node's NICs. Security can also be improved by limiting access to this endpoint only for nodes in appropriate states similar to current ``[api]restrict_lookup`` config option, see discussion in `iPXE boot config`_ section. In any way, proper firewalling of ``v1/ipxe`` endpoint is strongly advised.Generally scalability should be improved as requests for boot scripts and boot config files will be made to a distributed, load-balanced ironic-api service instead of local HTTP server of a given ironic-conductor host. However the largest scalability improvement can be achieved when using feature together with ``ipxe_use_swift`` feature and ``localboot``-only nodes as this will make ironic-conductor almost stateless and for example could allow easier containerization of ironic-conductor service. The feature alone should not have any significant impact on performance: * performance is improved as ironic-conductor does not have to manipulate on disk files in HTTP root directory of its local HTTP server; * in the most promising scenario, Ironic-conductor host will not have to run some other, currently required, extra services - this can be achieved when using this new feature together with ``ipxe_use_swift`` feature and ``localboot``-only nodes as this will not require a separate HTTP server on each ironic-conductor host, limit disk operations to minimum and thus decrease the overall CPU/disk load on ironic-conductor host. * very small performance penalty for extra RPC call from API to conductor.* Two new config options - ``[pxe]ipxe_server_enabled`` (boolean, default is False) This option enables this new feature. It is proposed to create it with deprecated status right away. It sole purpose is to gradually introduce the new feature and give time for operators that use custom, out-of-tree iPXE boot scripts and boot configs and wishing to utilize this new functionality to change those scripts and configs to proper Jinja templates. Eventually this option should be merged into ``[pxe]ipxe_enabled`` option to make Dynamic iPXE configuration the default and only method for iPXE environments. - ``[api]restrict_ipxe`` (boolean, default is True) This option is similar to the ``[api]restrict_lookup`` by allowing access to the new endpoint only to nodes in appropriate states (see `iPXE boot config`_ section). * This change has no immediate effect. Enabling it is a conscious choice of the operator setting the proposed config option ``[pxe]ipxe_server_enabled`` to True. * When the following requirements are met, operators can simplify their deployments by not installing an HTTP and/or TFTP servers on ironic-conductor hosts: - nodes properly support iPXE from the box (otherwise TFTP server to serve the iPXE-enabled bootloader is still required, but generally can be placed elsewhere accessible from provisioning/cleaning networks); - ``[pxe]ipxe_use_swift`` option (or its analog for standalone case) is enabled (so deploy images do not have to be cached on ironic-conductor host to be served by per-conductor HTTP server); - there is no requirement to support ``netboot`` functionality, so that user image's kernel/ramdisk do not have to be cached either (for example, an Ironic deployment with network separation for baremetal nodes enabled).See `Driver API impact`_ section on how to utilize this new functionality in your drivers. Basically authors must inherit their boot and deploy interfaces from new mixin classes and implement a single method in each of those. Examples of PXEBoot and AgentDeploy interfaces will be available. Alternatives ------------ Continue doing what we are doing, generate the configuration files and saving it to the disk. As for alternative way of implementation, instead of adding a new top-level REST API, the existing ``vendor_passthru`` mechanism could potentially be used, but it has some drawbacks: * driver/node passthru methods currently do not support passing in parameters as part of URL query string, only as JSON request data. While this could probably be fixed as part of this change, * both driver and vendor passthru are inappropriate for standalone case: - using node passthru endpoint requires knowledge of node's UUID, which is not known to a standalone DHCP server - driver passthru endpoint currently contains a name of the *top-level* defined driver (e.g. ``agent_ipmitool``), not the name of the driver interface. Thus to able to use such endpoint in standalone mode all nodes effectively have to be using the same driver. * using vendor passthru means that the whole boot config has to be passed over RPC instead of passing only the template file name and options to render it * having unversioned, unauthenticated vendor passthru method makes it harder to cover it with appropriate firewall (``v1/node/<uuid>/vendor_passthru/<method>`` has to be covered instead of simply ``v1/ipxe``) pshchelo (Pavlo Shchelokovskyy)* amend create/change PXE config pipeline (at least for iPXE templates) - change iPXE boot scripts and boot configs to fully rendered Jinja templates * add dynamic ipxe mixin classes * add driver API methods - first implementation will target PXEBoot and AgentDeployMixin classes to cover both Agent and ISCSI deploy in iPXE environments * add RPC API methods, bump RPC version * add new REST API endpoints, optionally bump API version * add a way to configure this feature in Ironic's DevStack plugin * add API tests via Ironic's tempest plugin - amend fake driver to return meaningful responses to new API requests * switch at least one gate job to use this feature - preferably the one using ``netboot`` to cover more code paths - a job using virtualbmc + ipmitool is preferred - can be done with ``ipxe_use_swift`` enabled as well * add appropriate documentation (see `Documentation Impact`_)NoneNew API endpoints can be tested with appropriate tempest tests given fake interfaces of ``fake`` driver can be improved to return meaningful responses to the new API. No other specific coverage seems to be needed apart from enabling this new feature and drivers using it at least on one gate job.The feature has no immediate effect on existing installation as it must be manually enabled first. Those wishing to enable it must ensure that if using custom iPXE boot scripts and boot config templates (not the ones provided in Ironic tree), those are converted to proper Jinja2 templates first. Operators using an out-of-tree iPXE boot script should not be affected with this feature disabled, as the existing file will be rendered as-is by the templating engine.* API ref has to be updated with information on new API endpoints * Install Guide has to be updated with information on - why enabling this new feature - how to enable it + properly configure both ironic-api and ironic-conductor services, with options and file templates configured and placed in concert + changes to auxiliary services to be (not) deployed on ironic-conductor hosts and what affects such choice + properly securing the new API endpoints and other security considerations .. [#] https://specs.openstack.org/openstack/ironic-specs/specs/6.2/ipxe-swift-tempurls.html .. [#] http://ipxe.org/scripting#dynamic_scripts .. [#] http://developer.openstack.org/api-ref/baremetal/#utility","The proposed implementation consists of creating a new ``Driver Vendor Passthru`` method called ``ipxe_config`` that will dynamically generate the iPXE configuration files for a given node UUID or mac address depending on the node's provision state. When Neutron is used with iPXE enabled, it will configure the DHCP server to make a request to the ``Driver Vendor Passthru`` endpoint using the node's UUID when booting a node, e.g:: http://<Ironic API Address>:6385/v1/drivers/<driver_name>/vendor_passthru/ipxe_config?node_uuid=<node UUID> Ironic will then check the ``provision_state`` of the node and generate the iPXE configuration file for that state. Say, the node ``provision_state`` is DEPLOYING, we then will return an iPXE configuration to boot the deploy ramdisk and kernel. If the node ``provision_state`` is ACTIVE, we then return an iPXE configuration to boot from the image ramdisk and kernel (If local boot and/or full disk image is not specified). For an unknown ``provision_state`` we just return an iPXE configuration file that prints out an error explaining the problem on the node's console log and a warning message in the Ironic log. If an operator wants to have an external DHCP server (standalone version) but still benefit from dynamically generated iPXE script files (instead of using static files) it will be possible by making the same ``Driver Vendor Passthru`` endpoint to support passing the MAC address of one of the node's port as parameter, e.g:: http://<Ironic API Address>:6385/v1/drivers/<driver_name>/vendor_passthru/ipxe_config?port_address=<port address> When scripting iPXE allows `expanding variables <http://ipxe.org/scripting#dynamic_scripts>`_ so that an operator can create a single iPXE script pointing to the Ironic API (and expanding the ``${mac}`` variable) when configuring their external DHCP server allowing them to have dynamically generated iPXE configuration for their environment even when Neutron is not used.``http`` [#]_, as then the iPXE drive won't need to save any state on the disk. As a future work, it would be also possible to add support for creating a ``Swift Temporary URL`` when booting images being served by ``Glance`` with a ``Swift`` storage backend. Alternatives ------------ Continue doing what we are doing, generate the configuration files and saving it to the disk. A new ``Driver Vendor Passthru`` method called ``ipxe_config`` that supports GET HTTP.Currently the RPC method for ``vendor_passthru`` and ``driver_vendor_passthru`` returns a tuple with the return value and a boolean indicating if the method is asynchronous. We will need another flag to indicate if the value should be returned as a static file that will be served by the Ironic API instead of a response body message.NoneN/A .. NOTE: This section was not present at the time this spec was approved.The new ``Vendor Passthru`` method endpoint needs to be part of the public API, so that iPXE can get the configuration file from without authentication. This is the same as the methods ``heartbeat`` or ``lookup`` for the agent driver [#]_.NoneNoneNone lucasagomes <lucasagomes@gmail.com>* Create the new ``ipxe_config`` method for the PXEVendorPassthru interface. * Change the PXE configuration options passed to the DHCP server to point to the ``v1/drivers/<driver name>/vendor_passthru/ipxe_config?node_uuid=<node UUID>`` endpoint in the Ironic API instead of pointing to the URL to download the boot.ipxe script (the script won't be need anymore and will be deleted). * Extend the ``vendor_passthru`` and ``driver_vendor_passthru`` RPC methods to return a flag indicating whether the return value should be attached to the response object as a file or returned as a response message. * Update the methods ``prepare_ramdisk`` and ``clean_up_ramdisk`` from the **IPXEBoot** interface to not attempt to create or delete the iPXE configuration files.* `New boot interface <https://review.openstack.org/#/c/177726/6/specs/liberty/ipxe-dynamic-config.rst>`_: This spec is refactoring the boot logic out of the current Ironic ``deploy`` drivers into a new boot interface. Unittests will be added.NoneThe iPXE documentation will be updated to reflect the changes made by this spec... [#] https://github.com/openstack/ironic/blob/master/ironic/api/config.py",340,86
openstack%2Fopenstack-ansible-os_keystone~stable%2Fnewton~I55f1fcd928c70eff3488af50d3dddb588082eb43,openstack/openstack-ansible-os_keystone,stable/newton,I55f1fcd928c70eff3488af50d3dddb588082eb43,Remove python-ldap and add pyldap,ABANDONED,2017-12-05 14:22:22.000000000,2017-12-12 15:14:42.000000000,,"[{'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-05 14:22:22.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/60291df3510c69351a932d562df1d78c55ffc0f9', 'message': 'Remove python-ldap and add pyldap\n\nKeystone moved from python-ldap to pyldap in the Newton release and\npython-ldap now requires a version of pyasn1-modules that exceeds\nthe upper-constraint in Pike, which breaks repo builds.\n\nThis patch removes python-ldap and adds pyldap in its place.\n\nCloses-Bug: 1736241\nDepends-On: I1aa332ac0905bf80f80d8ff9b5c50746a85bfd59\nChange-Id: I55f1fcd928c70eff3488af50d3dddb588082eb43\n(cherry picked from commit ffc9c9b5e681748ff3e54e43f22c921e83342a51)\n'}]",0,525624,60291df3510c69351a932d562df1d78c55ffc0f9,8,4,1,13095,,,0,"Remove python-ldap and add pyldap

Keystone moved from python-ldap to pyldap in the Newton release and
python-ldap now requires a version of pyasn1-modules that exceeds
the upper-constraint in Pike, which breaks repo builds.

This patch removes python-ldap and adds pyldap in its place.

Closes-Bug: 1736241
Depends-On: I1aa332ac0905bf80f80d8ff9b5c50746a85bfd59
Change-Id: I55f1fcd928c70eff3488af50d3dddb588082eb43
(cherry picked from commit ffc9c9b5e681748ff3e54e43f22c921e83342a51)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/24/525624/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,60291df3510c69351a932d562df1d78c55ffc0f9,bug/1736241-stable/newton, - pyldap - PyMySQL, - PyMySQL - python-ldap,2,2
openstack%2Fkolla-ansible~stable%2Fpike~Id4e37001d910475f42b799038e53f9dfeb90055b,openstack/kolla-ansible,stable/pike,Id4e37001d910475f42b799038e53f9dfeb90055b,Just a minor alphabetize issue otherwise seems fine!,ABANDONED,2017-12-12 15:11:36.000000000,2017-12-12 15:12:13.000000000,,[],"[{'number': 1, 'created': '2017-12-12 15:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/18fd277da665ad3f77189874026f0ab7f34836f9', 'message': 'Just a minor alphabetize issue otherwise seems fine!\n\nChange-Id: Id4e37001d910475f42b799038e53f9dfeb90055b\n'}]",0,527424,18fd277da665ad3f77189874026f0ab7f34836f9,2,0,1,26880,,,0,"Just a minor alphabetize issue otherwise seems fine!

Change-Id: Id4e37001d910475f42b799038e53f9dfeb90055b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/24/527424/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,18fd277da665ad3f77189874026f0ab7f34836f9,bug/1719147-stable/pike,,,0,0
openstack%2Fnova~stable%2Fpike~Ic13324e9a6b8129c8b499f3c9d396d4f86e98780,openstack/nova,stable/pike,Ic13324e9a6b8129c8b499f3c9d396d4f86e98780,Re-use existing ComputeNode on ironic rebalance,ABANDONED,2017-11-06 11:30:54.000000000,2017-12-12 15:12:12.000000000,,"[{'_account_id': 782}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-06 11:30:54.000000000', 'files': ['nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.33/hypervisors-detail-resp.json.tpl', 'doc/api_samples/os-hypervisors/v2.53/hypervisors-detail-resp.json', 'nova/virt/fake.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'doc/api_samples/os-hypervisors/v2.33/hypervisors-list-resp.json', 'nova/tests/functional/api_sample_tests/test_hypervisors.py', 'nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.33/hypervisors-list-resp.json.tpl', 'doc/api_samples/os-hypervisors/v2.33/hypervisors-detail-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.53/hypervisors-detail-resp.json.tpl', 'doc/api_samples/os-hypervisors/v2.53/hypervisors-list-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.53/hypervisors-list-resp.json.tpl', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/243c41de49ed59e5d19dc9253cb5a11f14b2d2eb', 'message': 'Re-use existing ComputeNode on ironic rebalance\n\nWhen a nova-compute service dies that is one of several ironic based\nnova-compute services running, a node rebalance occurs to ensure there\nis still an active nova-compute service dealing with requests for the\ngiven instance that is running.\n\nToday, when this occurs, we create a new ComputeNode entry. This change\nalters that logic to detect the case of the ironic node rebalance and in\nthat case we re-use the existing ComputeNode entry, simply updating the\nhost field to match the new host it has been rebalanced onto.\n\nPreviously we hit problems with placement when we get a new\nComputeNode.uuid for the same ironic_node.uuid. This reusing of the\nexisting entry keeps the ComputeNode.uuid the same when the rebalance of\nthe ComputeNode occurs.\n\nWithout keeping the same ComputeNode.uuid placement errors out with a 409\nbecause we attempt to create a ResourceProvider that has the same name\nas an existing ResourceProvdier. Had that worked, we would have noticed\nthe race that occurs after we create the ResourceProvider but before we\nadd back the existing allocations for existing instances. Keeping the\nComputeNode.uuid the same means we simply look up the existing\nResourceProvider in placement, avoiding all this pain and tears.\n\nThere are functional test changes to ensure the fake driver reports\na different hypervisor hostname between the first and second fake\ncompute service that is being started. Also included are the matching\ndocs api-samples changes.\n\nCloses-Bug: #1714248\n\n(Cherry-picked from I4253cffca3dbf558c875eed7e77711a31e9e3406)\nDepends-on: I4253cffca3dbf558c875eed7e77711a31e9e3406\n\nNOTE: this backport is significantly different to the master patch\nto avoid the need to bump the compute node object.\n\nChange-Id: Ic13324e9a6b8129c8b499f3c9d396d4f86e98780\n'}]",0,517925,243c41de49ed59e5d19dc9253cb5a11f14b2d2eb,10,8,1,782,,,0,"Re-use existing ComputeNode on ironic rebalance

When a nova-compute service dies that is one of several ironic based
nova-compute services running, a node rebalance occurs to ensure there
is still an active nova-compute service dealing with requests for the
given instance that is running.

Today, when this occurs, we create a new ComputeNode entry. This change
alters that logic to detect the case of the ironic node rebalance and in
that case we re-use the existing ComputeNode entry, simply updating the
host field to match the new host it has been rebalanced onto.

Previously we hit problems with placement when we get a new
ComputeNode.uuid for the same ironic_node.uuid. This reusing of the
existing entry keeps the ComputeNode.uuid the same when the rebalance of
the ComputeNode occurs.

Without keeping the same ComputeNode.uuid placement errors out with a 409
because we attempt to create a ResourceProvider that has the same name
as an existing ResourceProvdier. Had that worked, we would have noticed
the race that occurs after we create the ResourceProvider but before we
add back the existing allocations for existing instances. Keeping the
ComputeNode.uuid the same means we simply look up the existing
ResourceProvider in placement, avoiding all this pain and tears.

There are functional test changes to ensure the fake driver reports
a different hypervisor hostname between the first and second fake
compute service that is being started. Also included are the matching
docs api-samples changes.

Closes-Bug: #1714248

(Cherry-picked from I4253cffca3dbf558c875eed7e77711a31e9e3406)
Depends-on: I4253cffca3dbf558c875eed7e77711a31e9e3406

NOTE: this backport is significantly different to the master patch
to avoid the need to bump the compute node object.

Change-Id: Ic13324e9a6b8129c8b499f3c9d396d4f86e98780
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/517925/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.33/hypervisors-detail-resp.json.tpl', 'doc/api_samples/os-hypervisors/v2.53/hypervisors-detail-resp.json', 'nova/virt/fake.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'doc/api_samples/os-hypervisors/v2.33/hypervisors-list-resp.json', 'nova/tests/functional/api_sample_tests/test_hypervisors.py', 'nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.33/hypervisors-list-resp.json.tpl', 'doc/api_samples/os-hypervisors/v2.33/hypervisors-detail-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.53/hypervisors-detail-resp.json.tpl', 'doc/api_samples/os-hypervisors/v2.53/hypervisors-list-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-hypervisors/v2.53/hypervisors-list-resp.json.tpl', 'nova/compute/resource_tracker.py']",12,243c41de49ed59e5d19dc9253cb5a11f14b2d2eb,bug/1714248," # Its possible ironic just did a node re-balance, so let's # check if there is a compute node that already has the correct # hypervisor_hostname. We can re-use that rather than create a # new one and have to move existing placement allocations # NOTE: master uses the new more efficient get_all_by_nodename call cn_candidates = [] cn_possibles = objects.ComputeNodeList.get_by_hypervisor( context, resources['hypervisor_type']) for cn_poss in cn_possibles: if cn_poss.hypervisor_hostname == nodename: cn_candidates.append(cn_poss) if len(cn_candidates) == 1: cn = cn_candidates[0] LOG.info(""ComputeNode %(name)s moving from %(old)s to %(new)s"", {""name"": nodename, ""old"": cn.host, ""new"": self.host}) cn.host = self.host self.compute_nodes[nodename] = cn self._copy_resources(cn, resources) self._setup_pci_tracker(context, cn, resources) self._update(context, cn) return if len(cn_candidates) > 1: LOG.error( ""Found more than one ComputeNode for nodename %s. "" ""Please clean up the orphaned ComputeNode records in your DB. "" ""Unable to auto-recover from ironic node re-balance."", nodename) ",,126,14
openstack%2Fnova~master~I947e927802f755ccb25a91efd82cac895779d19e,openstack/nova,master,I947e927802f755ccb25a91efd82cac895779d19e,Fix 'force' parameter in os-quota-sets PUT schema,MERGED,2017-11-27 18:59:54.000000000,2017-12-12 15:09:12.000000000,2017-12-08 19:27:24.000000000,"[{'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6125}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-11-27 18:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e31dd087fb090d0db70ad5dbf4e92eed416fc4ed', 'message': ""Fix 'force' parameter in os-quota-sets PUT schema\n\nA regression was introduced in the 2.36 API microversion where the\n'force' parameter was missing from the 'PUT /os-quota-sets/{tenant_id}'\nAPI request schema so users could not force quota updates with\nmicroversion 2.36 or later. The bug is now fixed so that the 'force'\nparameter can once again be specified during quota updates. There is\nno new microversion for this change since it is an admin-only API.\n\nChange-Id: I947e927802f755ccb25a91efd82cac895779d19e\nCloses-Bug: #1733886\n""}, {'number': 2, 'created': '2017-12-01 00:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/023e295e1cd95064db8b55b4a3ce28d067ffbf40', 'message': ""Fix 'force' parameter in os-quota-sets PUT schema\n\nA regression was introduced in the 2.36 API microversion where the\n'force' parameter was missing from the 'PUT /os-quota-sets/{tenant_id}'\nAPI request schema so users could not force quota updates with\nmicroversion 2.36 or later. The bug is now fixed so that the 'force'\nparameter can once again be specified during quota updates. There is\nno new microversion for this change since it is an admin-only API.\n\nChange-Id: I947e927802f755ccb25a91efd82cac895779d19e\nCloses-Bug: #1733886\n""}, {'number': 3, 'created': '2017-12-07 13:59:57.000000000', 'files': ['doc/api_samples/os-quota-sets/v2.36/user-quotas-update-post-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/user-quotas-show-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.36/quotas-show-get-resp.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-force-post-resp.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-force-post-req.json', 'releasenotes/notes/bug-1733886-os-quota-sets-force-2.36-5866924621ecc857.yaml', 'doc/api_samples/os-quota-sets/v2.36/user-quotas-update-post-req.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-post-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-post-req.json.tpl', 'nova/api/openstack/compute/rest_api_version_history.rst', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-show-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-show-defaults-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-post-req.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-show-detail-get-resp.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-show-defaults-get-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/quotas-update-force-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-force-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/user-quotas-update-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-force-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/user-quotas-update-post-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.36/user-quotas-show-get-resp.json', 'nova/tests/functional/api_sample_tests/test_quota_sets.py', 'nova/api/openstack/compute/schemas/quota_sets.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-show-detail-get-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/9ddbaa15cb55d1245a8a63d9414d134746fc2f3c', 'message': ""Fix 'force' parameter in os-quota-sets PUT schema\n\nA regression was introduced in the 2.36 API microversion where the\n'force' parameter was missing from the 'PUT /os-quota-sets/{tenant_id}'\nAPI request schema so users could not force quota updates with\nmicroversion 2.36 or later. The bug is now fixed so that the 'force'\nparameter can once again be specified during quota updates. There is\nno new microversion for this change since it is an admin-only API.\n\nChange-Id: I947e927802f755ccb25a91efd82cac895779d19e\nCloses-Bug: #1733886\n""}]",21,523194,9ddbaa15cb55d1245a8a63d9414d134746fc2f3c,74,20,3,6873,,,0,"Fix 'force' parameter in os-quota-sets PUT schema

A regression was introduced in the 2.36 API microversion where the
'force' parameter was missing from the 'PUT /os-quota-sets/{tenant_id}'
API request schema so users could not force quota updates with
microversion 2.36 or later. The bug is now fixed so that the 'force'
parameter can once again be specified during quota updates. There is
no new microversion for this change since it is an admin-only API.

Change-Id: I947e927802f755ccb25a91efd82cac895779d19e
Closes-Bug: #1733886
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/523194/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/os-quota-sets/v2.36/user-quotas-update-post-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/user-quotas-show-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.36/quotas-show-get-resp.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-force-post-resp.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-force-post-req.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-force-resp.json.tpl', 'releasenotes/notes/bug-1733886-os-quota-sets-force-2.36-5866924621ecc857.yaml', 'doc/api_samples/os-quota-sets/v2.36/user-quotas-update-post-req.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-post-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-show-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-show-defaults-get-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.36/quotas-update-post-req.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-show-detail-get-resp.json', 'doc/api_samples/os-quota-sets/v2.36/quotas-show-defaults-get-resp.json', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-force-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/user-quotas-update-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-update-force-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/user-quotas-update-post-resp.json.tpl', 'doc/api_samples/os-quota-sets/v2.36/user-quotas-show-get-resp.json', 'nova/tests/functional/api_sample_tests/test_quota_sets.py', 'nova/api/openstack/compute/schemas/quota_sets.py', 'nova/tests/functional/api_sample_tests/api_samples/os-quota-sets/v2.36/quotas-show-detail-get-resp.json.tpl']",24,e31dd087fb090d0db70ad5dbf4e92eed416fc4ed,bp/deprecate-file-injection,"{ ""quota_set"": { ""cores"": { ""in_use"": 0, ""limit"": 20, ""reserved"": 0 }, ""id"": ""fake_tenant"", ""injected_file_content_bytes"": { ""in_use"": 0, ""limit"": 10240, ""reserved"": 0 }, ""injected_file_path_bytes"": { ""in_use"": 0, ""limit"": 255, ""reserved"": 0 }, ""injected_files"": { ""in_use"": 0, ""limit"": 5, ""reserved"": 0 }, ""instances"": { ""in_use"": 0, ""limit"": 10, ""reserved"": 0 }, ""key_pairs"": { ""in_use"": 0, ""limit"": 100, ""reserved"": 0 }, ""metadata_items"": { ""in_use"": 0, ""limit"": 128, ""reserved"": 0 }, ""ram"": { ""in_use"": 0, ""limit"": 51200, ""reserved"": 0 }, ""server_group_members"": { ""in_use"": 0, ""limit"": 10, ""reserved"": 0 }, ""server_groups"": { ""in_use"": 0, ""limit"": 10, ""reserved"": 0 } } } ",,351,1
openstack%2Freviewday~master~I1b3f42430cb4ea363fd8716cd569ebd1d032b73d,openstack/reviewday,master,I1b3f42430cb4ea363fd8716cd569ebd1d032b73d,Fix change URL links with latest review.openstack.org gerrit,ABANDONED,2017-10-02 15:52:13.000000000,2017-12-12 14:46:24.000000000,,"[{'_account_id': 6873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-10-02 15:52:13.000000000', 'files': ['reviewday/mergeprop.py'], 'web_link': 'https://opendev.org/openstack/reviewday/commit/d7e0035018c3d5137f81ca116a23d3f718df3792', 'message': ""Fix change URL links with latest review.openstack.org gerrit\n\nWith the version of gerrit we're using in review.openstack.org\nnow, the change URLs in their current format, e.g.:\n\n  https://review.openstack.org/#change,463987\n\nDo not work properly.\n\nThis change simply removes the formatting of the URL since what\nwe get back should be the canonical form to reach the change.\n\nChange-Id: I1b3f42430cb4ea363fd8716cd569ebd1d032b73d\n""}]",0,508919,d7e0035018c3d5137f81ca116a23d3f718df3792,4,2,1,6873,,,0,"Fix change URL links with latest review.openstack.org gerrit

With the version of gerrit we're using in review.openstack.org
now, the change URLs in their current format, e.g.:

  https://review.openstack.org/#change,463987

Do not work properly.

This change simply removes the formatting of the URL since what
we get back should be the canonical form to reach the change.

Change-Id: I1b3f42430cb4ea363fd8716cd569ebd1d032b73d
",git fetch https://review.opendev.org/openstack/reviewday refs/changes/19/508919/1 && git format-patch -1 --stdout FETCH_HEAD,['reviewday/mergeprop.py'],1,d7e0035018c3d5137f81ca116a23d3f718df3792,fix-change-url, self.url = review['url']," self.url = '%s/#change,%s' % tuple(review['url'].rsplit('/', 1))",1,1
openstack%2Freviewday~master~If7c4fe732d3f272cbe31dabc375943559bb6afd9,openstack/reviewday,master,If7c4fe732d3f272cbe31dabc375943559bb6afd9,Fix reviewday URLs,MERGED,2017-12-08 14:23:51.000000000,2017-12-12 14:46:18.000000000,2017-12-09 13:12:11.000000000,"[{'_account_id': 360}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-12-08 14:23:51.000000000', 'files': ['reviewday/mergeprop.py'], 'web_link': 'https://opendev.org/openstack/reviewday/commit/c1c05b6338564100d88699de9cb46a1792ef089e', 'message': 'Fix reviewday URLs\n\nThe https://review.openstack.org/#change,123456 style links\nno longer seem to work correctly. This patch updates\nthe URL to use the new format:\n\nhttps://review.openstack.org/#/c/123456/ format which\nworks great.\n\nChange-Id: If7c4fe732d3f272cbe31dabc375943559bb6afd9\n'}]",0,526686,c1c05b6338564100d88699de9cb46a1792ef089e,9,2,1,360,,,0,"Fix reviewday URLs

The https://review.openstack.org/#change,123456 style links
no longer seem to work correctly. This patch updates
the URL to use the new format:

https://review.openstack.org/#/c/123456/ format which
works great.

Change-Id: If7c4fe732d3f272cbe31dabc375943559bb6afd9
",git fetch https://review.opendev.org/openstack/reviewday refs/changes/86/526686/1 && git format-patch -1 --stdout FETCH_HEAD,['reviewday/mergeprop.py'],1,c1c05b6338564100d88699de9cb46a1792ef089e,fix_url," self.url = '%s/#/c/%s' % tuple(review['url'].rsplit('/', 1))"," self.url = '%s/#change,%s' % tuple(review['url'].rsplit('/', 1))",1,1
openstack%2Fgovernance~master~I60beb5b191137f3108ddfd002cb2d0ed59deb446,openstack/governance,master,I60beb5b191137f3108ddfd002cb2d0ed59deb446,remove docs:follows-policy tag,MERGED,2017-11-30 15:43:13.000000000,2017-12-12 14:11:32.000000000,2017-12-12 14:11:32.000000000,"[{'_account_id': 308}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 3153}, {'_account_id': 4162}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 11564}, {'_account_id': 11904}, {'_account_id': 20156}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 15:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/5f8105179763ad4857e877cf0c3cabdb362a3d08', 'message': 'remove docs:follows-policy tag\n\nNo teams or deliverables are using the tag and the documentation team\nwants to reframe it based on the change to having project teams own\nmore of their documentation.\n\nChange-Id: I60beb5b191137f3108ddfd002cb2d0ed59deb446\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2017-12-11 19:20:05.000000000', 'files': ['reference/tags/index.rst', 'reference/tags/docs_follows-policy.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/1fdc8d90303cb7993edbeb566dc7e6df51223f12', 'message': 'remove docs:follows-policy tag\n\nNo teams or deliverables are using the tag and the documentation team\nwants to reframe it based on the change to having project teams own\nmore of their documentation.\n\nChange-Id: I60beb5b191137f3108ddfd002cb2d0ed59deb446\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,524217,1fdc8d90303cb7993edbeb566dc7e6df51223f12,26,11,2,2472,,,0,"remove docs:follows-policy tag

No teams or deliverables are using the tag and the documentation team
wants to reframe it based on the change to having project teams own
more of their documentation.

Change-Id: I60beb5b191137f3108ddfd002cb2d0ed59deb446
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/17/524217/2 && git format-patch -1 --stdout FETCH_HEAD,"['reference/tags/index.rst', 'reference/tags/docs_follows-policy.rst']",2,5f8105179763ad4857e877cf0c3cabdb362a3d08,formal-vote,,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. _`tag-docs:follows-policy`: =================== docs:follows-policy =================== This tag indicates that a deliverable’s documentation set is prepared in coordination with the OpenStack Documentation team, and follows their defined practices and policies for review and verification. It does not indicate that the documentation team has taken ownership of producing the documentation for the deliverable. Application to current projects =============================== .. tagged-projects:: docs:follows-policy Rationale ========= At present, the documentation team is responsible for all documentation in the openstack/openstack-manuals repo. Maintaining this documentation requires basic knowledge of all of the projects covered by the guides. However, being able to successfully maintain some of the more in-depth knowledge that is written in the guides is out of scope for the technical writers to handle on their own. Previously, the documentation team has worked alongside project teams to collaborate and share knowledge to ensure that the manuals document all necessary major bug fixes and enhancements. This approach no longer ensures that the documentation is sufficiently verified by the teams each release. The ""docs:follows-policy"" tag indicates that project teams are coordinating with the documentation team, so that contributions, bug reports, and timely reviews happen over the course of each release cycle. Detailed expectations are described in the doc-tag section of the Documentation Contributors' Guide: https://review.openstack.org/453642 . The documentation team recommends that project teams who maintain project-specific guides inside of the openstack-manuals repository (such as, nova, neutron, cinder, horizon, glance, and keystone), including teams maintaining projects outside of the starter-kit set, and deployment projects, apply for this tag. Having the tag indicates that the project teams commit to provide accurate documentation every release. In these cases, the documentation team will review the project team's guides, but won't necessarily contribute significantly to ongoing maintenance. Requirements ============ The structure outlined by the doc team in their policy (https://review.openstack.org/453642) is to be loosely followed, dependent on project circumstance. For all teams: 1. The team must `designate a liaison <https://wiki.openstack.org/wiki/CrossProjectLiaisons#Documentation>`_ to the documentation team. For project teams with deliverables covered by guides that are maintained by the documentation team: 1. The project team must provide summaries of new features, configuration changes, etc. that need to be reflected in the documentation. 2. The documentation liaison must follow the published review schedule, read the documentation, and open bugs appropriately, either providing information to the docs team on how to document these issues or submitting patches to fix them. For project teams with deliverables covered by documentation that is not maintained by the documentation team: 1. The project team must prepare their documentation using the standard tool set provided by the documentation team, and ensure the guides are published to docs.openstack.org. 2. The project team must prepare and update their documentation following the published review schedule, and coordinate with the documentation team to ensure that a review is performed. 3. The project team must actively manage their documentation, handling bug reports and publishing corrections as needed. 4. The project team must make the documentation team aware of any major changes to the guides that will impact the way the guides are published. Tag application process ======================= The tag will be applied for the first time for the Pike release. Members of project teams who want the tag associated with their deliverables should apply for it by adding it to the deliverables they want to cover. The documentation team PTL must approve the tag to show that the documentation team agrees that the relevant guides have been reviewed appropriately by the review deadline for each cycle as indicated by this tag. The tag is applied to deliverables in the governance repository. Each manual for a deliverable covered by the tag will be annotated to indicate the level of input or review from the documentation team so that users can easily discover who is responsible for maintining the content. Deprecation =========== This tag will be removed from deliverables when the required coordination and reviews are not performed for a cycle. Any existing documents annotated as having been reviewed will not be affected. A project team can re-apply to have the tag for the following cycle, after the relevant reviews are performed. ",0,120
