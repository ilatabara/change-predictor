id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fnova~master~Ie2e28a14ff4655e38a5db3925adcd605ac773843,openstack/nova,master,Ie2e28a14ff4655e38a5db3925adcd605ac773843,doc: cleanup pci.alias references,MERGED,2019-03-04 21:43:22.000000000,2019-03-07 07:24:46.000000000,2019-03-07 00:52:17.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-03-04 21:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa45d36727659f4183a89e0111364fd1721d19e6', 'message': 'doc: cleanup pci.alias references\n\nThe admin and user flavor docs on pci.alias were not super\nhelpful by just throwing the user to the config docs or\nflavor docs and letting them figure it out. This change\nhelps the reader by linking directly to the things being\nreferenced.\n\nChange-Id: Ie2e28a14ff4655e38a5db3925adcd605ac773843\n'}, {'number': 2, 'created': '2019-03-06 17:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c12d5bdbb9eda563ce732a9b91b44a71fe598e86', 'message': 'doc: cleanup pci.alias references\n\nThe admin and user flavor docs on pci.alias were not super\nhelpful by just throwing the user to the config docs or\nflavor docs and letting them figure it out. This change\nhelps the reader by linking directly to the things being\nreferenced.\n\nChange-Id: Ie2e28a14ff4655e38a5db3925adcd605ac773843\n'}, {'number': 3, 'created': '2019-03-06 17:59:28.000000000', 'files': ['doc/source/user/flavors.rst', 'doc/source/admin/pci-passthrough.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/fbfb1a25df63b314611161482a4c991040fed020', 'message': 'doc: cleanup pci.alias references\n\nThe admin and user flavor docs on pci.alias were not super\nhelpful by just throwing the user to the config docs or\nflavor docs and letting them figure it out. This change\nhelps the reader by linking directly to the things being\nreferenced.\n\nAlso cleans up a pci.passthrough config option reference\nwhile in here.\n\nChange-Id: Ie2e28a14ff4655e38a5db3925adcd605ac773843\n'}]",3,640882,fbfb1a25df63b314611161482a4c991040fed020,25,12,3,6873,,,0,"doc: cleanup pci.alias references

The admin and user flavor docs on pci.alias were not super
helpful by just throwing the user to the config docs or
flavor docs and letting them figure it out. This change
helps the reader by linking directly to the things being
referenced.

Also cleans up a pci.passthrough config option reference
while in here.

Change-Id: Ie2e28a14ff4655e38a5db3925adcd605ac773843
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/640882/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/flavors.rst', 'doc/source/admin/pci-passthrough.rst']",2,aa45d36727659f4183a89e0111364fd1721d19e6,docs-pci-passthrough-alias, Refer to :oslo.config:option:`pci.alias` for syntax information.:ref:`Flavors <extra-spec-pci-passthrough>`. Refer to :oslo.config:option:`pci.alias` for syntax information.," For more information about the syntax of ``alias``, refer to :doc:`/configuration/config`.:doc:`/user/flavors`. For more information about the syntax of ``alias``, refer to :doc:`/configuration/config`.",6,5
openstack%2Fcinder~master~I70e55cf43d2d71f533325b745070746ddfae547b,openstack/cinder,master,I70e55cf43d2d71f533325b745070746ddfae547b,Always run chmod privileged in remotefs drivers,ABANDONED,2019-03-06 08:19:45.000000000,2019-03-07 07:09:04.000000000,,"[{'_account_id': 24}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28710}, {'_account_id': 28801}]","[{'number': 1, 'created': '2019-03-06 08:19:45.000000000', 'files': ['cinder/tests/unit/volume/drivers/test_nfs.py', 'cinder/privsep/path.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f118cc62ffdeb723b8916d5f13884c87b62cd2c', 'message': 'Always run chmod privileged in remotefs drivers\n\nDue to the switch to privsep new files are always created\nwith owner root in the remotefs drivers.\nIn order to be able to chmod these files\nthe drivers have to run the follow up operations from\na privileged context.\nThis adds a chmod method to the path privsep class and\nmoves chmod ops in remotefs and related classes to this\nnew privsep op.\nAlso updates a comment on these ops being run for\nfilesystems, not only for NFS.\n\nCloses-Bug: #1818504\nChange-Id: I70e55cf43d2d71f533325b745070746ddfae547b\n'}]",0,641277,8f118cc62ffdeb723b8916d5f13884c87b62cd2c,30,28,1,13915,,,0,"Always run chmod privileged in remotefs drivers

Due to the switch to privsep new files are always created
with owner root in the remotefs drivers.
In order to be able to chmod these files
the drivers have to run the follow up operations from
a privileged context.
This adds a chmod method to the path privsep class and
moves chmod ops in remotefs and related classes to this
new privsep op.
Also updates a comment on these ops being run for
filesystems, not only for NFS.

Closes-Bug: #1818504
Change-Id: I70e55cf43d2d71f533325b745070746ddfae547b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/641277/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/test_nfs.py', 'cinder/privsep/path.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py']",5,8f118cc62ffdeb723b8916d5f13884c87b62cd2c,bug/1818504," """"""Sets access permissions for given filesystem path. cinder.privsep.path.chmod(path, permissions) cinder.privsep.path.chmod(path, 'ugo+rw') cinder.privsep.path.chmod(path, 'u+rw')"," """"""Sets access permissions for given NFS path. self._execute('chmod', permissions, path, run_as_root=self._execute_as_root) self._execute('chmod', 'ugo+rw', path, run_as_root=self._execute_as_root) self._execute('chmod', 'u+rw', path, run_as_root=self._execute_as_root)",35,18
openstack%2Fcharm-ceph-rbd-mirror~master~Ic7b0a724052b5d61694993c0728e7e4bdc0d9bfc,openstack/charm-ceph-rbd-mirror,master,Ic7b0a724052b5d61694993c0728e7e4bdc0d9bfc,Add configuration of public/cluster network,MERGED,2019-03-06 10:30:52.000000000,2019-03-07 07:08:15.000000000,2019-03-07 07:08:15.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 10:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/3e2c3f702d25eb248338d95b061b21fbc461ce21', 'message': 'Add configuration of public/cluster network\n\nFix syslog configuration.\n\nDepends-On: Ia49f4921e772376763be178e11d7777676ccc8da\nChange-Id: Ic7b0a724052b5d61694993c0728e7e4bdc0d9bfc\n'}, {'number': 2, 'created': '2019-03-06 10:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/5e5b9faf693c4017bdebc10d9a9ffc06b7f57ec7', 'message': 'Add configuration of public/cluster network\n\nFix syslog configuration.\n\nDepends-On: Ia49f4921e772376763be178e11d7777676ccc8da\nChange-Id: Ic7b0a724052b5d61694993c0728e7e4bdc0d9bfc\n'}, {'number': 3, 'created': '2019-03-06 12:33:16.000000000', 'files': ['src/templates/ceph.conf', 'src/metadata.yaml', 'src/templates/remote.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/64c84334eb73604e8241c677a042d7e1ea18c7c0', 'message': 'Add configuration of public/cluster network\n\nFix syslog configuration.\n\nDepends-On: Ia49f4921e772376763be178e11d7777676ccc8da\nChange-Id: Ic7b0a724052b5d61694993c0728e7e4bdc0d9bfc\n'}]",0,641307,64c84334eb73604e8241c677a042d7e1ea18c7c0,11,3,3,13686,,,0,"Add configuration of public/cluster network

Fix syslog configuration.

Depends-On: Ia49f4921e772376763be178e11d7777676ccc8da
Change-Id: Ic7b0a724052b5d61694993c0728e7e4bdc0d9bfc
",git fetch https://review.opendev.org/openstack/charm-ceph-rbd-mirror refs/changes/07/641307/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/templates/ceph.conf', 'src/metadata.yaml', 'src/templates/remote.conf']",3,3e2c3f702d25eb248338d95b061b21fbc461ce21,rbd-mirror,log to syslog = {{ options.use_syslog }} err to syslog = {{ options.use_syslog }} log to syslog = {{ options.use_syslog }} public network = {{ ceph_remote.public_network }} {% if ceph_remote.cluster_network %} cluster network = {{ ceph_remote.cluster_network }} {% endif -%},"log to syslog = {{ use_syslog }} err to syslog = {{ use_syslog }} clog to syslog = {{ use_syslog }} [client] {% if rbd_client_cache_settings -%} {% for key, value in rbd_client_cache_settings.items() -%} {{ key }} = {{ value }} {% endfor -%} {%- endif %}",17,18
openstack%2Fcharm-ceph-rbd-mirror~master~I9af983b37045f83a0a9703e2212b371b97dc3121,openstack/charm-ceph-rbd-mirror,master,I9af983b37045f83a0a9703e2212b371b97dc3121,Add actions,MERGED,2019-03-05 09:48:41.000000000,2019-03-07 07:00:21.000000000,2019-03-07 07:00:21.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 09:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/274fa9022f09ce6d669a40a1142389f35681c8b9', 'message': 'Add actions\n\n``demote`` is used to demote all images in all pools, used in\nconjunction with ``promote`` on other side for controlled fall back.\n\n``promote`` is used to promote all images in all pools, used for fail\nover.\n\n``refresh-pools`` is used to enable mirroring of pools created\nmanually without the use of the charm ceph broker protocol.\n\nChange-Id: I9af983b37045f83a0a9703e2212b371b97dc3121\n'}, {'number': 2, 'created': '2019-03-05 16:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/3f98509c2ff7e8cc2f435168cd80971bdaf7845b', 'message': 'Add actions\n\n``demote`` is used to demote all images in all pools, used for\noperator controlled fail over/fall back.\n\n``promote`` is used to promote all images in all pools, used for\noperator controlled or disaster recovery fail over/fall back.\n\n``refresh-pools`` is used to refresh list of eligible pools from\nlocal Ceph cluster.  Side effect is to enable mirroring of pools\ncreated manually without the use of the charm ceph broker protocol.\n\nChange-Id: I9af983b37045f83a0a9703e2212b371b97dc3121\n'}, {'number': 3, 'created': '2019-03-06 08:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/d516941d4b4bd309c1f6be8c98724034e555328a', 'message': 'Add actions\n\n``demote`` is used to demote all images in all pools, used for\noperator controlled fail over/fall back.\n\n``promote`` is used to promote all images in all pools, used for\noperator controlled or disaster recovery fail over/fall back.\n\n``refresh-pools`` is used to refresh list of eligible pools from\nlocal Ceph cluster.  Side effect is to enable mirroring of pools\ncreated manually without the use of the charm ceph broker protocol.\n\nChange-Id: I9af983b37045f83a0a9703e2212b371b97dc3121\n'}, {'number': 4, 'created': '2019-03-06 09:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/ea8afd40b0e8a879d9677b32d2f4080748d6bafc', 'message': 'Add actions\n\n``demote`` is used to demote all images in all pools, used for\noperator controlled fail over/fall back.\n\n``promote`` is used to promote all images in all pools, used for\noperator controlled or disaster recovery fail over/fall back.\n\n``refresh-pools`` is used to refresh list of eligible pools from\nlocal Ceph cluster.  Side effect is to enable mirroring of pools\ncreated manually without the use of the charm ceph broker protocol.\n\nChange-Id: I9af983b37045f83a0a9703e2212b371b97dc3121\nDepends-On: I97bfb9a2c0e30998566aee56d4630af6baa36d45\n'}, {'number': 5, 'created': '2019-03-06 10:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/8e58b02c3ae1519570b7bc4518369fd403e9a320', 'message': 'Add actions\n\n``demote`` is used to demote all images in all pools, used for\noperator controlled fail over/fall back.\n\n``promote`` is used to promote all images in all pools, used for\noperator controlled or disaster recovery fail over/fall back.\n\n``refresh-pools`` is used to refresh list of eligible pools from\nlocal Ceph cluster.  Side effect is to enable mirroring of pools\ncreated manually without the use of the charm ceph broker protocol.\n\nChange-Id: I9af983b37045f83a0a9703e2212b371b97dc3121\nDepends-On: I97bfb9a2c0e30998566aee56d4630af6baa36d45\n'}, {'number': 6, 'created': '2019-03-06 12:31:05.000000000', 'files': ['src/actions/demote', 'src/actions/refresh-pools', 'src/actions.yaml', 'unit_tests/test_actions.py', 'src/reactive/ceph_rbd_mirror_handlers.py', 'unit_tests/test_ceph_rbd_mirror_handlers.py', 'src/actions/actions.py', 'src/actions/promote'], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/2a645e9d0d2499c6b40334eae454eadc0bb8ab5f', 'message': 'Add actions\n\n``demote`` is used to demote all images in all pools, used for\noperator controlled fail over/fall back.\n\n``promote`` is used to promote all images in all pools, used for\noperator controlled or disaster recovery fail over/fall back.\n\n``refresh-pools`` is used to refresh list of eligible pools from\nlocal Ceph cluster.  Side effect is to enable mirroring of pools\ncreated manually without the use of the charm ceph broker protocol.\n\nChange-Id: I9af983b37045f83a0a9703e2212b371b97dc3121\nDepends-On: I97bfb9a2c0e30998566aee56d4630af6baa36d45\n'}]",0,640964,2a645e9d0d2499c6b40334eae454eadc0bb8ab5f,26,4,6,13686,,,0,"Add actions

``demote`` is used to demote all images in all pools, used for
operator controlled fail over/fall back.

``promote`` is used to promote all images in all pools, used for
operator controlled or disaster recovery fail over/fall back.

``refresh-pools`` is used to refresh list of eligible pools from
local Ceph cluster.  Side effect is to enable mirroring of pools
created manually without the use of the charm ceph broker protocol.

Change-Id: I9af983b37045f83a0a9703e2212b371b97dc3121
Depends-On: I97bfb9a2c0e30998566aee56d4630af6baa36d45
",git fetch https://review.opendev.org/openstack/charm-ceph-rbd-mirror refs/changes/64/640964/6 && git format-patch -1 --stdout FETCH_HEAD,"['src/actions/demote', 'src/actions/refresh-pools', 'src/actions.yaml', 'src/actions/actions.py', 'src/actions/promote']",5,274fa9022f09ce6d669a40a1142389f35681c8b9,rbd-mirror,actions.py,,111,0
openstack%2Fbarbican~master~If6f828ce0188ac0fb579c4555cf02c0c487742a4,openstack/barbican,master,If6f828ce0188ac0fb579c4555cf02c0c487742a4,add python 3.7 unit test job,MERGED,2019-02-15 18:26:42.000000000,2019-03-07 06:42:17.000000000,2019-03-07 06:42:17.000000000,"[{'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 18:26:42.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/barbican/commit/13b77e0f296260bb6b2bac4e4c9aaa6d4359d8fe', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: If6f828ce0188ac0fb579c4555cf02c0c487742a4\nStory: #2004073\nTask: #27403\n'}]",0,637244,13b77e0f296260bb6b2bac4e4c9aaa6d4359d8fe,11,3,1,11805,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: If6f828ce0188ac0fb579c4555cf02c0c487742a4
Story: #2004073
Task: #27403
",git fetch https://review.opendev.org/openstack/barbican refs/changes/44/637244/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,13b77e0f296260bb6b2bac4e4c9aaa6d4359d8fe,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fnova~master~I22e3166ef3b706add88c6b909af024022f2243a8,openstack/nova,master,I22e3166ef3b706add88c6b909af024022f2243a8,fakelibvirt: Add ability to generate fake PCI devices,MERGED,2019-03-01 15:55:57.000000000,2019-03-07 06:40:50.000000000,2019-03-07 06:40:50.000000000,"[{'_account_id': 7}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28714}]","[{'number': 1, 'created': '2019-03-01 15:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a159c91fe40a4b0a31628c1410d97ca08a9397e', 'message': 'WIP: fakelibvirt: Add ability to generate fake PCI devices\n\nWe already support generating fake PFs and VFs. Now add the ability to\ngenerate fake non-SR-IOV devices. This is mostly an exercise in\nrefactoring, as we remove a lot of unused configurability and generally\nclean things up as we go.\n\nChange-Id: I22e3166ef3b706add88c6b909af024022f2243a8\n'}, {'number': 2, 'created': '2019-03-04 14:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/165e2aa709e9c7fc5609a4a2b8ee7d5aaded6976', 'message': 'WIP: fakelibvirt: Add ability to generate fake PCI devices\n\nWe already support generating fake PFs and VFs. Now add the ability to\ngenerate fake non-SR-IOV devices. This is mostly an exercise in\nrefactoring, as we remove a lot of unused configurability and generally\nclean things up as we go.\n\nChange-Id: I22e3166ef3b706add88c6b909af024022f2243a8\n'}, {'number': 3, 'created': '2019-03-04 17:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb4e857f97d44bbbe6319faa59af5e42a27c7634', 'message': ""fakelibvirt: Add ability to generate fake PCI devices\n\nWe already support generating fake PFs and VFs. Now add the ability to\ngenerate fake non-SR-IOV devices. This is mostly an exercise in\nrefactoring, as we remove a lot of unused configurability and generally\nclean things up as we go.\n\nThis isn't used yet. We do that in a later patch.\n\nChange-Id: I22e3166ef3b706add88c6b909af024022f2243a8\n""}, {'number': 4, 'created': '2019-03-05 10:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/920d419e1546615141ea6f12aefeb6a8322babe7', 'message': ""fakelibvirt: Add ability to generate fake PCI devices\n\nWe already support generating fake PFs and VFs. Now add the ability to\ngenerate fake non-SR-IOV devices. This is mostly an exercise in\nrefactoring, as we remove a lot of unused configurability and generally\nclean things up as we go.\n\nThis isn't used yet. We do that in a later patch.\n\nChange-Id: I22e3166ef3b706add88c6b909af024022f2243a8\n""}, {'number': 5, 'created': '2019-03-06 11:06:21.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/test_fakelibvirt.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b927748c257e705903c2aa0ffa47b19914e31ede', 'message': ""fakelibvirt: Add ability to generate fake PCI devices\n\nWe already support generating fake PFs and VFs. Now add the ability to\ngenerate fake non-SR-IOV devices. This is mostly an exercise in\nrefactoring, as we remove a lot of unused configurability and generally\nclean things up as we go.\n\nThis isn't used yet. We do that in a later patch.\n\nChange-Id: I22e3166ef3b706add88c6b909af024022f2243a8\n""}]",5,640409,b927748c257e705903c2aa0ffa47b19914e31ede,38,13,5,15334,,,0,"fakelibvirt: Add ability to generate fake PCI devices

We already support generating fake PFs and VFs. Now add the ability to
generate fake non-SR-IOV devices. This is mostly an exercise in
refactoring, as we remove a lot of unused configurability and generally
clean things up as we go.

This isn't used yet. We do that in a later patch.

Change-Id: I22e3166ef3b706add88c6b909af024022f2243a8
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/640409/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/test_fakelibvirt.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py']",3,0a159c91fe40a4b0a31628c1410d97ca08a9397e,bug/1805891,"import textwrapPCI_PROD_ID = '1533' PCI_PROD_NAME = 'I210 Gigabit Network Connection' PCI_DRIVER_NAME = 'igb' PF_PROD_ID = '1528'PF_CAP_TYPE = 'virt_functions' VF_PROD_ID = '1515' VF_PROD_NAME = 'X540 Ethernet Controller Virtual Function'VF_CAP_TYPE = 'phys_function' class FakePCIDevice(object): """"""Generate a fake PCI device. Generate a fake PCI devices corresponding to one of the following real-world PCI devices. - I210 Gigabit Network Connection (8086:1533) - Ethernet Controller 10-Gigabit X540-AT2 (8086:1528) - X540 Ethernet Controller Virtual Function (8086:1515) """""" pci_device_template = textwrap.dedent("""""" <device> <name>pci_0000_81_%(slot)02x_%(function)d</name> <path>/sys/devices/pci0000:80/0000:80:01.0/0000:81:%(slot)02x.%(function)d</path> <parent>pci_0000_80_01_0</parent> <driver> <name>%(driver)s</name> </driver> <capability type='pci'> <domain>0</domain> <bus>129</bus> <slot>%(slot)d</slot> <function>%(function)d</function> <product id='0x%(prod_id)s'>%(prod_name)s</product> <vendor id='0x8086'>Intel Corporation</vendor> %(capability)s <iommuGroup number='%(iommu_group)d'> <address domain='0x0000' bus='0x81' slot='%(slot)#02x' function='0x%(function)d'/> </iommuGroup> <numa node='%(numa_node)s'/> <pci-express> <link validity='cap' port='0' speed='5' width='8'/> <link validity='sta' speed='5' width='8'/> </pci-express> </capability> </device>"""""".strip()) # noqa cap_templ = ""<capability type='%(cap_type)s'>%(addresses)s</capability>"" addr_templ = ""<address domain='0x0000' bus='0x81' slot='%(slot)#02x' function='%(function)#02x'/>"" # noqa def __init__(self, dev_type, slot, function, iommu_group, numa_node, vf_ratio=None): :param dev_type: (string) Indicates the type of the device (PCI, PF, VF). :param slot: (int) Slot number of the device. :param function: (int) Function number of the device. :param iommu_group: (int) IOMMU group ID. :param numa_node: (int) NUMA node of the device. :param vf_ratio: (int) Ratio of Virtual Functions on Physical. Only applicable if ``dev_type`` is one of: ``PF``, ``VF``. if dev_type == 'PCI': if vf_ratio: raise ValueError('vf_ratio does not apply for PCI devices') prod_id = PCI_PROD_ID prod_name = PCI_PROD_NAME driver = PCI_DRIVER_NAME capability = '' elif dev_type == 'PF': prod_id = PF_PROD_ID prod_name = PF_PROD_NAME driver = PF_DRIVER_NAME capability = self.cap_templ % { 'cap_type': PF_CAP_TYPE, 'addresses': '\n'.join([ self.addr_templ % {'slot': slot, 'function': x} for x in range(function * vf_ratio, (function + 1) * vf_ratio)]) } elif dev_type == 'VF': prod_id = VF_PROD_ID prod_name = VF_PROD_NAME driver = VF_DRIVER_NAME capability = self.cap_templ % { 'cap_type': PF_CAP_TYPE, 'addresses': [ self.addr_templ % { 'slot': slot, 'function': function // vf_ratio, } ] } else: raise ValueError('Expected one of: PCI, VF, PCI') self.pci_device = self.pci_device_template % { 'slot': slot, 'function': function, 'prod_id': prod_id, 'prod_name': prod_name, 'driver': driver, 'capability': capability, 'iommu_group': iommu_group, 'numa_node': numa_node, } return self.pci_device class HostPCIDevicesInfo(object): """"""Represent a pool of host PCI devices."""""" TOTAL_NUMA_NODES = 2 def __init__(self, num_pci=0, num_pfs=2, num_vfs=8, numa_node=None): """"""Create a new HostPCIDevicesInfo object. :param num_pci: (int) The number of (non-SR-IOV) PCI devices. :param num_pfs: (int) The number of PCI SR-IOV Physical Functions. :param num_vfs: (int) The number of PCI SR-IOV Virtual Functions. :param iommu_group: (int) Initial IOMMU group ID. :param numa_node: (int) NUMA node of the device; if set all of the devices will be assigned to the specified node else they will be split between ``$TOTAL_NUMA_NODES`` nodes. if num_vfs % num_pfs: raise ValueError('num_vfs must be a factor of num_pfs') slot = 0 function = 0 iommu_group = 40 # totally arbitrary number # Generate PCI devs for dev in range(num_pci): pci_dev_name = 'pci_0000_81_%(slot)02x_%(function)d' % { 'slot': slot, 'function': function} self.devices[pci_dev_name] = FakePCIDevice( dev_type='PCI', slot=slot, function=function, iommu_group=iommu_group, numa_node=self._calc_numa_node(dev, numa_node)) slot += 1 iommu_group += 1 vf_ratio = num_vfs / num_pfs if num_pfs else 0 function = 0 pci_dev_name = 'pci_0000_81_%(slot)02x_%(function)d' % { 'slot': slot, 'function': function} self.devices[pci_dev_name] = FakePCIDevice( dev_type='PF', slot=slot, function=function, iommu_group=iommu_group, numa_node=self._calc_numa_node(dev, numa_node), vf_ratio=vf_ratio) # Generate VFs for dev in range(num_vfs / num_pfs): slot += 1 function += 1 iommu_group += 1 pci_dev_name = 'pci_0000_81_%(slot)s_%(function)d' % { 'slot': slot, 'function': dev} self.devices[pci_dev_name] = FakePCIDevice( dev_type='VF', slot=slot, function=function, iommu_group=iommu_group, numa_node=self._calc_numa_node(dev, numa_node), vf_ratio=vf_ratio) slot += 1 @classmethod def _calc_numa_node(cls, dev, numa_node): return dev % cls.TOTAL_NUMA_NODES if numa_node is None else numa_node self.pci_info = pci_info or HostPCIDevicesInfo(num_pci=0, num_pfs=0, num_vfs=0)","PF_CAP_TYPE = 'virt_functions' VF_CAP_TYPE = 'phys_function'VF_PROD_NAME = 'X540 Ethernet Controller Virtual Function'VF_SLOT = '10' PF_SLOT = '00' class FakePciDevice(object): pci_dev_template = """"""<device> <name>pci_0000_81_%(slot)02x_%(dev)d</name> <path>/sys/devices/pci0000:80/0000:80:01.0/0000:81:%(slot)02x.%(dev)d</path> <parent>pci_0000_80_01_0</parent> <driver> <name>%(driver)s</name> </driver> <capability type='pci'> <domain>0</domain> <bus>129</bus> <slot>%(slot)d</slot> <function>%(dev)d</function> <product id='0x%(prod)d'>%(prod_name)s</product> <vendor id='0x8086'>Intel Corporation</vendor> <capability type='%(cap_type)s'> %(functions)s </capability> <iommuGroup number='%(group_id)d'> <address domain='0x0000' bus='0x81' slot='%(slot)#02x' function='0x%(dev)d'/> </iommuGroup> <numa node='%(numa_node)s'/> <pci-express> <link validity='cap' port='0' speed='5' width='8'/> <link validity='sta' speed='5' width='8'/> </pci-express> </capability> </device>"""""" def __init__(self, dev_type, vf_ratio, group, dev, product_id, numa_node): :param dev_type: (string) Indicates the type of the device (PF, VF) :param vf_ratio: (int) Ratio of Virtual Functions on Physical :param group: (int) iommu group id :param dev: (int) function number of the device :param product_id: (int) Device product ID :param numa_node: (int) NUMA node of the device addr_templ = ("" <address domain='0x0000' bus='0x81' slot='0x%(slot)s'"" "" function='0x%(dev)d'/>"") self.pci_dev = None if dev_type == 'PF': pf_caps = [addr_templ % {'dev': x, 'slot': VF_SLOT} for x in range(dev * vf_ratio, (dev + 1) * vf_ratio)] slot = int(str(PF_SLOT), 16) self.pci_dev = self.pci_dev_template % {'dev': dev, 'prod': product_id, 'group_id': group, 'functions': '\n'.join(pf_caps), 'slot': slot, 'cap_type': PF_CAP_TYPE, 'prod_name': PF_PROD_NAME, 'driver': PF_DRIVER_NAME, 'numa_node': numa_node} elif dev_type == 'VF': vf_caps = [addr_templ % {'dev': int(dev / vf_ratio), 'slot': PF_SLOT}] slot = int(str(VF_SLOT), 16) self.pci_dev = self.pci_dev_template % {'dev': dev, 'prod': product_id, 'group_id': group, 'functions': '\n'.join(vf_caps), 'slot': slot, 'cap_type': VF_CAP_TYPE, 'prod_name': VF_PROD_NAME, 'driver': VF_DRIVER_NAME, 'numa_node': numa_node} return self.pci_dev class HostPciSRIOVDevicesInfo(object): """"""Represent a pool of host SR-IOV devices."""""" def __init__(self, vf_product_id=1515, pf_product_id=1528, num_pfs=2, num_vfs=8, group=47, numa_node=None, total_numa_nodes=2): """"""Create a new HostPciSRIOVDevicesInfo object. :param vf_product_id: (int) Product ID of the Virtual Functions :param pf_product_id=1528: (int) Product ID of the Physical Functions :param num_pfs: (int) The number of the Physical Functions :param num_vfs: (int) The number of the Virtual Functions :param group: (int) Initial group id :param numa_node: (int) NUMA node of the device, if set all of the device will be created in the provided node :param total_numa_nodes: (int) total number of NUMA nodes def _calc_numa_node(dev): return dev % total_numa_nodes if numa_node is None else numa_node vf_ratio = num_vfs // num_pfs if num_pfs else 0 dev_group = group + dev + 1 pci_dev_name = 'pci_0000_81_%(slot)s_%(dev)d' % {'slot': PF_SLOT, 'dev': dev} self.devices[pci_dev_name] = FakePciDevice('PF', vf_ratio, dev_group, dev, pf_product_id, _calc_numa_node(dev)) # Generate VFs for dev in range(num_vfs): dev_group = group + dev + 1 pci_dev_name = 'pci_0000_81_%(slot)s_%(dev)d' % {'slot': VF_SLOT, 'dev': dev} self.devices[pci_dev_name] = FakePciDevice('VF', vf_ratio, dev_group, dev, vf_product_id, _calc_numa_node(dev)) self.pci_info = pci_info or HostPciSRIOVDevicesInfo(num_pfs=0, num_vfs=0)",185,105
openstack%2Frequirements~master~I228c6d83ad0f1032833103662356b475d7792558,openstack/requirements,master,I228c6d83ad0f1032833103662356b475d7792558,update constraint for python-magnumclient to new release 2.12.0,MERGED,2019-03-06 16:56:27.000000000,2019-03-07 06:40:46.000000000,2019-03-07 06:40:46.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 16:56:27.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b21e2affb63e67010777726f684d61808d5a62f2', 'message': 'update constraint for python-magnumclient to new release 2.12.0\n\nChange-Id: I228c6d83ad0f1032833103662356b475d7792558\nmeta:version: 2.12.0\nmeta:diff-start: -\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Feilong Wang <flwang@catalyst.net.nz>\nmeta:release:Commit: Feilong Wang <flwang@catalyst.net.nz>\nmeta:release:Change-Id: Ic63f62c97bec94ae5de3848d480a75aefa8e621b\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+1: Spyros Trigazis <strigazi@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,641441,b21e2affb63e67010777726f684d61808d5a62f2,8,2,1,11131,,,0,"update constraint for python-magnumclient to new release 2.12.0

Change-Id: I228c6d83ad0f1032833103662356b475d7792558
meta:version: 2.12.0
meta:diff-start: -
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Feilong Wang <flwang@catalyst.net.nz>
meta:release:Commit: Feilong Wang <flwang@catalyst.net.nz>
meta:release:Change-Id: Ic63f62c97bec94ae5de3848d480a75aefa8e621b
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+1: Spyros Trigazis <strigazi@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/41/641441/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,b21e2affb63e67010777726f684d61808d5a62f2,new-release,python-magnumclient===2.12.0,python-magnumclient===2.11.0,1,1
openstack%2Fneutron~master~I42c311f9111e0a0d1a6ea3a7aeab0fef8d77c549,openstack/neutron,master,I42c311f9111e0a0d1a6ea3a7aeab0fef8d77c549,Store journal log in functional tests results,MERGED,2019-03-05 21:17:54.000000000,2019-03-07 06:40:44.000000000,2019-03-07 06:40:44.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-03-05 21:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/302e35a455ef2ca1bcbd257740340e60b0ed60b8', 'message': 'Store journal log in functional tests results\n\nIt may helpdebug some issues related to keepalived and/or\ndnsmasq which are logging to journal only.\n\nChange-Id: I42c311f9111e0a0d1a6ea3a7aeab0fef8d77c549\n'}, {'number': 2, 'created': '2019-03-06 14:53:21.000000000', 'files': ['playbooks/legacy/neutron-functional/post.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/45a7a459612fb039c94706916d7d36719d206c83', 'message': 'Store journal log in functional tests results\n\nIt may helpdebug some issues related to keepalived and/or\ndnsmasq which are logging to journal only.\n\nChange-Id: I42c311f9111e0a0d1a6ea3a7aeab0fef8d77c549\n'}]",1,641127,45a7a459612fb039c94706916d7d36719d206c83,26,9,2,11975,,,0,"Store journal log in functional tests results

It may helpdebug some issues related to keepalived and/or
dnsmasq which are logging to journal only.

Change-Id: I42c311f9111e0a0d1a6ea3a7aeab0fef8d77c549
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/641127/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/agent/l3/.framework.py.swp', 'playbooks/legacy/neutron-functional/post.yaml']",2,302e35a455ef2ca1bcbd257740340e60b0ed60b8,store_journal_in_functional_tests, # TODO(slaweq): this should be moved to separate role and used in zuulv3 # jobs definitions also - name: Store journal logs in {{ ansible_user_dir }}/workspace/logs/journal.log become: yes shell: cmd: | /bin/journalctl -a > {{ ansible_user_dir }}/workspace/logs/journal.log - name: Set journal.log file permissions become: yes file: path: '{{ ansible_user_dir }}/workspace/logs/journal.log' owner: '{{ ansible_user }}' group: '{{ ansible_user }}' mode: 0644 ,,16,0
openstack%2Ftripleo-quickstart~master~I7fc9a880f15463fd7d95be5ae46c1c1d2f339448,openstack/tripleo-quickstart,master,I7fc9a880f15463fd7d95be5ae46c1c1d2f339448,pacemaker: force the use of docker for ContainerCli,MERGED,2019-03-04 23:44:44.000000000,2019-03-07 06:39:19.000000000,2019-03-07 06:39:19.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 10022}, {'_account_id': 17823}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 23:44:44.000000000', 'files': ['config/general_config/pacemaker.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/02e4a70f715506bdb4b9bf8a46648613bcebbc9e', 'message': ""pacemaker: force the use of docker for ContainerCli\n\nUntil we get CentOS8 to test Pacemaker with Podman, we need to keep\nusing Docker for ContainerCli now.\n\nLater, when CentOS8 is out, we'll have a conditional we only set this\nvariable to 'docker' on CentOS7.\n\nChange-Id: I7fc9a880f15463fd7d95be5ae46c1c1d2f339448\n""}]",0,640895,02e4a70f715506bdb4b9bf8a46648613bcebbc9e,22,7,1,3153,,,0,"pacemaker: force the use of docker for ContainerCli

Until we get CentOS8 to test Pacemaker with Podman, we need to keep
using Docker for ContainerCli now.

Later, when CentOS8 is out, we'll have a conditional we only set this
variable to 'docker' on CentOS7.

Change-Id: I7fc9a880f15463fd7d95be5ae46c1c1d2f339448
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/95/640895/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/pacemaker.yml'],1,02e4a70f715506bdb4b9bf8a46648613bcebbc9e,podman, # Switch this variable to 'podman' once we run OVB jobs on CentOS8. overcloud_container_cli: docker,,3,0
openstack%2Ftripleo-quickstart-extras~master~Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb,openstack/tripleo-quickstart-extras,master,Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb,Script to identify tests passing on FS021 but still on skip list,MERGED,2019-02-18 11:15:53.000000000,2019-03-07 06:36:50.000000000,2019-03-07 06:36:49.000000000,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-18 11:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/038db912722b6ab2164a90782459ae418fab426e', 'message': ""Script to identify tests passing on FS021 but still on skip list\n\nThis script checks a console log from a tempest run against a skip\nlist file in order to identify which tests are still in the skip list,\nbut it's already passing on featureset 021 (which run's full tempest\nwithout skiping tests)\n\nUsage:\ncheck_skip.py --log-url http://log.o.o/tempest.log --skip-file\npath/to/skip/list\n\nChange-Id: Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb\n""}, {'number': 2, 'created': '2019-02-18 11:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4fc3c5920d55c5b82458c77507f99dc5f0e0fa24', 'message': ""Script to identify tests passing on FS021 but still on skip list\n\nThis script checks a console log from a tempest run against a skip\nlist file in order to identify which tests are still in the skip list,\nbut it's already passing on featureset 021 (which run's full tempest\nwithout skiping tests)\n\nUsage:\ncheck_skip.py --log-url http://log.o.o/tempest.log --skip-file\npath/to/skip/list\n\nTaiga task: https://tree.taiga.io/project/tripleo-ci-board/task/718?kanban-status=1447276\nChange-Id: Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb\n""}, {'number': 3, 'created': '2019-02-18 15:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d690e17150eafd47d1c89f5bfad574dbc99009ed', 'message': ""Script to identify tests passing on FS021 but still on skip list\n\nThis script checks a console log from a tempest run against a skip\nlist file in order to identify which tests are still in the skip list,\nbut it's already passing on featureset 021 (which run's full tempest\nwithout skiping tests)\n\nUsage:\ncheck_skip.py --log-url http://log.o.o/tempest.log --skip-file\npath/to/skip/list\n\nTaiga task: https://tree.taiga.io/project/tripleo-ci-board/task/718?kanban-status=1447276\nChange-Id: Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb\n""}, {'number': 4, 'created': '2019-02-26 19:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/006173088772374d13b4af15ffddc4fb76fe31bd', 'message': ""Script to identify tests passing on FS021 but still on skip list\n\nThis script checks a console log from a tempest run against a skip\nlist file in order to identify which tests are still in the skip list,\nbut it's already passing on featureset 021 (which run's full tempest\nwithout skiping tests)\n\nUsage:\ncheck_skip.py --log-url http://log.o.o/tempest.log --skip-file\npath/to/skip/list\n\nTaiga task: https://tree.taiga.io/project/tripleo-ci-board/task/718?kanban-status=1447276\nChange-Id: Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb\n""}, {'number': 5, 'created': '2019-03-07 01:18:49.000000000', 'files': ['roles/validate-tempest/files/check-skip-list/__init__.py', 'roles/validate-tempest/files/check-skip-list/check_skip.py', 'roles/validate-tempest/files/check-skip-list/requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c0ec7f6d929e1ebe32644dcd078d0971b0b2c6d2', 'message': ""Script to identify tests passing on FS021 but still on skip list\n\nThis script checks a console log from a tempest run against a skip\nlist file in order to identify which tests are still in the skip list,\nbut it's already passing on featureset 021 (which run's full tempest\nwithout skiping tests)\n\nUsage:\ncheck_skip.py --log-url http://log.o.o/tempest.log --skip-file\npath/to/skip/list\n\nTaiga task: https://tree.taiga.io/project/tripleo-ci-board/task/718?kanban-status=1447276\nChange-Id: Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb\n""}]",14,637524,c0ec7f6d929e1ebe32644dcd078d0971b0b2c6d2,30,13,5,8367,,,0,"Script to identify tests passing on FS021 but still on skip list

This script checks a console log from a tempest run against a skip
list file in order to identify which tests are still in the skip list,
but it's already passing on featureset 021 (which run's full tempest
without skiping tests)

Usage:
check_skip.py --log-url http://log.o.o/tempest.log --skip-file
path/to/skip/list

Taiga task: https://tree.taiga.io/project/tripleo-ci-board/task/718?kanban-status=1447276
Change-Id: Ibd03cb2f7e4d2ca6301cad04e100be05fe7bfffb
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/24/637524/5 && git format-patch -1 --stdout FETCH_HEAD,"['roles/validate-tempest/files/check-skip-list/__init__.py', 'roles/validate-tempest/files/check-skip-list/check_skip.py', 'roles/validate-tempest/files/check-skip-list/requirements.txt']",3,038db912722b6ab2164a90782459ae418fab426e,fs021-script,PyYAML requests,,114,0
openstack%2Fautomaton~master~I2a34080d1c4dac57e5739e56b508f47f924f662f,openstack/automaton,master,I2a34080d1c4dac57e5739e56b508f47f924f662f,add python 3.7 unit test job,MERGED,2018-10-15 13:23:11.000000000,2019-03-07 06:27:29.000000000,2019-03-07 06:27:28.000000000,"[{'_account_id': 9796}, {'_account_id': 11805}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2018-10-15 13:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/d53564d307ad770c85824f6ca7f344c89b3c2c50', 'message': ""Change python3.5 job to python3.7 job on Stein+\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7 and drop the Python 3.5 unit test job.\n\npython3.5 was the only supported python3 version on Xenial. Now that\nwe have Bionic nodes supporting python3.6 and python3.7, let's switch\nto testing with python3.7 in addition to python3.6 in Stein and\nbeyond.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I2a34080d1c4dac57e5739e56b508f47f924f662f\nStory: #2004073\nTask: #27440\n""}, {'number': 2, 'created': '2019-02-15 21:06:43.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/automaton/commit/31bbf1eaa35fe2aced3b91af8d6e6601bd655832', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I2a34080d1c4dac57e5739e56b508f47f924f662f\nStory: #2004073\nTask: #27440\n'}]",1,610513,31bbf1eaa35fe2aced3b91af8d6e6601bd655832,14,5,2,11805,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I2a34080d1c4dac57e5739e56b508f47f924f662f
Story: #2004073
Task: #27440
",git fetch https://review.opendev.org/openstack/automaton refs/changes/13/610513/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d53564d307ad770c85824f6ca7f344c89b3c2c50,py37-job, - openstack-python37-jobs, - openstack-python35-jobs,1,1
openstack%2Fpython-ironicclient~master~I610836e5038774621690aca88b2aee25670f0262,openstack/python-ironicclient,master,I610836e5038774621690aca88b2aee25670f0262,pass endpoint interface to http client,MERGED,2019-03-01 19:13:37.000000000,2019-03-07 06:00:38.000000000,2019-03-06 20:28:00.000000000,"[{'_account_id': 1916}, {'_account_id': 6618}, {'_account_id': 8482}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11655}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 19:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/08cdfb8d1d623f270c06c6a3c6e1d5febc7265e9', 'message': 'convey endpoint interface to http client\n\nCurrennt, HTTP client does endpoint lookup from the service catalog using\nendpoint filter. The filter is constructed from the interface attribute, which\nis set to public interface by default. Unfortunately, we never convey\nthe interface when constructing the HTTP client. And consequently, we\nare unable to use any other interfaces other than just public. This is\na severe limitation and also incompatible with Pike configuration.\nThis patch re-enables the endpoint filtering functionality by setting\nthe interface argument when constructing the HTTP client.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\n'}, {'number': 2, 'created': '2019-03-01 21:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c46f2ff4204c08c4a9599aa5a7c3e4f6e61a6a02', 'message': 'convey endpoint interface to http client\n\nCurrennt, HTTP client does endpoint lookup from the service catalog using\nendpoint filter. The filter is constructed from the interface attribute, which\nis set to public interface by default. Unfortunately, we never convey\nthe interface when constructing the HTTP client. And consequently, we\nare unable to use any other interfaces other than just public. This is\na severe limitation and also incompatible with Pike configuration.\nThis patch re-enables the endpoint filtering functionality by setting\nthe interface argument when constructing the HTTP client.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\n'}, {'number': 3, 'created': '2019-03-02 06:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5e2a198b24336183be00063bc36594a1aafe5442', 'message': ""convey endpoint interface to http client\n\nCurrennt, HTTP client does endpoint lookup from the service catalog using\nendpoint filter. The filter is constructed from the interface attribute, which\nis set to public interface by default. Unfortunately, we never convey\nthe interface when constructing the HTTP client. And consequently, we\nare unable to use any other interfaces other than just public. This is\na severe limitation and also incompatible with Pike configuration.\nThis patch re-enables the endpoint filtering functionality by setting\nthe interface argument when constructing the HTTP client.\n\nThis patch also make sure the interface parameter is consistently\nspecified whenever it is needed. There's also no need to explicitly\nset the interface to 'publicURL' because that's already the default\nin keystoneauth.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\n""}, {'number': 4, 'created': '2019-03-04 16:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e7ea74c1bde174c7f83876d288c87f57c6be237e', 'message': ""pass endpoint interface to http client\n\nCurrennt, HTTP client does endpoint lookup from the service catalog using\nendpoint filter. The filter is constructed from the interface attribute, which\nis set to public interface by default. Unfortunately, we never convey\nthe interface when constructing the HTTP client. And consequently, we\nare unable to use any other interfaces other than just public. This is\na severe limitation and also incompatible with Pike configuration.\nThis patch re-enables the endpoint filtering functionality by setting\nthe interface argument when constructing the HTTP client.\n\nThis patch also make sure the interface parameter is consistently\nspecified whenever it is needed. There's also no need to explicitly\nset the interface to 'publicURL' because that's already the default\nin keystoneauth.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\ntask: 29802\n""}, {'number': 5, 'created': '2019-03-06 00:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/6b0c471ce7c95eed1be0e071ae2f71000695116d', 'message': ""pass endpoint interface to http client\n\nThe 'interface' argument was being ignored so that the HTTP client was\nalways using the public endpoint for Ironic. This fixes it so that the\n'valid_interfaces' or 'interface' (deprecated) argument is taken\ninto consideration.\n\nThere's also no need to explicitly set the interface to 'publicURL'\nbecause that's already the default in keystoneauth.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\ntask: 29802\n""}, {'number': 6, 'created': '2019-03-06 16:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e37677350726a570ccc2bad946f28ae0e78a8039', 'message': ""pass endpoint interface to http client\n\nThe 'interface' argument was being ignored so that the HTTP client was\nalways using the public endpoint for Ironic. This fixes it so that the\n'interface' argument is taken into consideration.\n\nThere's also no need to explicitly set the interface to 'publicURL'\nbecause that's already the default in keystoneauth.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\ntask: 29802\n""}, {'number': 7, 'created': '2019-03-06 17:16:55.000000000', 'files': ['ironicclient/tests/unit/test_client.py', 'releasenotes/notes/pass-interface-argument-deb92e3feb0bf051.yaml', 'ironicclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/d6eea403cbf0d11b06acbecc704f422a7e278462', 'message': ""pass endpoint interface to http client\n\nThe 'interface' argument was being ignored so that the HTTP client was\nalways using the public endpoint for Ironic. This fixes it so that the\n'interface' argument is taken into consideration.\n\nThere's also no need to explicitly set the interface to 'publicURL'\nbecause that's already the default in keystoneauth.\n\nChange-Id: I610836e5038774621690aca88b2aee25670f0262\nstory: 2005118\ntask: 29802\n""}]",29,640491,d6eea403cbf0d11b06acbecc704f422a7e278462,36,8,7,1916,,,0,"pass endpoint interface to http client

The 'interface' argument was being ignored so that the HTTP client was
always using the public endpoint for Ironic. This fixes it so that the
'interface' argument is taken into consideration.

There's also no need to explicitly set the interface to 'publicURL'
because that's already the default in keystoneauth.

Change-Id: I610836e5038774621690aca88b2aee25670f0262
story: 2005118
task: 29802
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/91/640491/3 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/convey-interface-argument-deb92e3feb0bf051.yaml', 'ironicclient/tests/unit/test_client.py', 'ironicclient/client.py']",3,08cdfb8d1d623f270c06c6a3c6e1d5febc7265e9,story-2005118," # Make sure we also convey the endpoint interface to the HTTP client. # NOTE(gyee): we are supposed to be using valid_interfaces as interface # is deprecated. interface = kwargs.get('valid_interfaces', kwargs.get('interface')) 'endpoint_override': endpoint, 'interface': interface", 'endpoint_override': endpoint,67,4
openstack%2Fcharm-layer-ceph~master~Ia9ed0f5e8e17d9d0ffdf3e650c76f2c36938244d,openstack/charm-layer-ceph,master,Ia9ed0f5e8e17d9d0ffdf3e650c76f2c36938244d,Add gate jobs,MERGED,2019-03-04 07:17:11.000000000,2019-03-07 05:47:36.000000000,2019-03-07 05:47:36.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 07:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-layer-ceph/commit/d42eab5a426043c1a2b4bbaf39ef9f075da1cd49', 'message': 'Add gate jobs\n\nChange-Id: Ia9ed0f5e8e17d9d0ffdf3e650c76f2c36938244d\n'}, {'number': 2, 'created': '2019-03-04 09:42:12.000000000', 'files': ['.gitreview', '.travis.yml', '.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-layer-ceph/commit/96b969b6c0ef0fe3869329cc25371ef3ae72e7ce', 'message': 'Add gate jobs\n\nSet ``toxworkdir`` to avoud charm-tools build recursion.\n\nChange-Id: Ia9ed0f5e8e17d9d0ffdf3e650c76f2c36938244d\n'}]",0,640682,96b969b6c0ef0fe3869329cc25371ef3ae72e7ce,8,2,2,13686,,,0,"Add gate jobs

Set ``toxworkdir`` to avoud charm-tools build recursion.

Change-Id: Ia9ed0f5e8e17d9d0ffdf3e650c76f2c36938244d
",git fetch https://review.opendev.org/openstack/charm-layer-ceph refs/changes/82/640682/2 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.travis.yml', '.zuul.yaml', 'tox.ini']",4,d42eab5a426043c1a2b4bbaf39ef9f075da1cd49,rbd-mirror,basepython = python3 /bin/mkdir -p {envdir}/tmp,basepython = python2.7 mkdir -p {envdir}/tmp[testenv:py27] basepython = python2.7 deps = -r{toxinidir}/test-requirements.txt # TODO: Need to write unit tests then remove the following command. commands = /bin/true [testenv:py34] basepython = python3.4 deps = -r{toxinidir}/test-requirements.txt # TODO: Need to write unit tests then remove the following command. commands = /bin/true [testenv:py35] basepython = python3.5 deps = -r{toxinidir}/test-requirements.txt # TODO: Need to write unit tests then remove the following command. commands = /bin/true [testenv:py36] basepython = python3.6 deps = -r{toxinidir}/test-requirements.txt # TODO: Need to write unit tests then remove the following command. commands = /bin/true ,9,35
openstack%2Fcharm-interface-ceph-rbd-mirror~master~Ia49f4921e772376763be178e11d7777676ccc8da,openstack/charm-interface-ceph-rbd-mirror,master,Ia49f4921e772376763be178e11d7777676ccc8da,Add ``public_network`` and ``cluster_network`` properties,MERGED,2019-03-06 10:30:16.000000000,2019-03-07 05:42:22.000000000,2019-03-07 05:42:22.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 10:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-rbd-mirror/commit/d54648d05aacf2823fedb47981f00caaddcc8a76', 'message': 'Add ``public_network`` and ``cluster_network`` properties\n\nChange-Id: Ia49f4921e772376763be178e11d7777676ccc8da\n'}, {'number': 2, 'created': '2019-03-06 14:26:22.000000000', 'files': ['requires.py', 'unit_tests/test_requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-rbd-mirror/commit/2677eb3a2ff2505d6dd5f4b75a3bf0a1bf16b10f', 'message': 'Add ``public_network`` and ``cluster_network`` properties\n\nChange-Id: Ia49f4921e772376763be178e11d7777676ccc8da\n'}]",0,641306,2677eb3a2ff2505d6dd5f4b75a3bf0a1bf16b10f,11,3,2,13686,,,0,"Add ``public_network`` and ``cluster_network`` properties

Change-Id: Ia49f4921e772376763be178e11d7777676ccc8da
",git fetch https://review.opendev.org/openstack/charm-interface-ceph-rbd-mirror refs/changes/06/641306/1 && git format-patch -1 --stdout FETCH_HEAD,"['requires.py', 'unit_tests/test_requires.py']",2,d54648d05aacf2823fedb47981f00caaddcc8a76,rbd-mirror," def test_public_network(self): self.patch_requires_class('_all_joined_units') self._all_joined_units.received.__getitem__.return_value = '192.0.2.1' self.patch_object(requires.ch_ip, 'resolve_network_cidr') self.resolve_network_cidr.return_value = '192.0.2.0/24' self.assertEqual(self.requires_class.public_network, '192.0.2.0/24') self._all_joined_units.received.__getitem__.assert_called_once_with( 'ceph-public-address') self.resolve_network_cidr.assert_called_once_with('192.0.2.1') def test_cluster_network(self): self.patch_requires_class('_all_joined_units') self._all_joined_units.received.__getitem__.return_value = '192.0.2.1' self.patch_object(requires.ch_ip, 'resolve_network_cidr') self.resolve_network_cidr.return_value = '192.0.2.0/24' self.assertEqual(self.requires_class.cluster_network, '192.0.2.0/24') self._all_joined_units.received.__getitem__.assert_called_once_with( 'ceph-cluster-address') self.resolve_network_cidr.assert_called_once_with('192.0.2.1')",,45,2
openstack%2Fcharm-interface-ceph-rbd-mirror~master~I97bfb9a2c0e30998566aee56d4630af6baa36d45,openstack/charm-interface-ceph-rbd-mirror,master,I97bfb9a2c0e30998566aee56d4630af6baa36d45,Add ``refresh_pools``,MERGED,2019-03-06 09:17:56.000000000,2019-03-07 05:42:22.000000000,2019-03-07 05:42:22.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 09:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-rbd-mirror/commit/d3891b2c313d64fc73b18f83abf13030d014a929', 'message': 'Add ``refresh_pools``\n\nChange-Id: I97bfb9a2c0e30998566aee56d4630af6baa36d45\n'}, {'number': 2, 'created': '2019-03-06 14:26:22.000000000', 'files': ['requires.py', 'unit_tests/test_requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-rbd-mirror/commit/e7fb14440e2c2701e8263a846902f347775dd27e', 'message': 'Add ``refresh_pools``\n\nChange-Id: I97bfb9a2c0e30998566aee56d4630af6baa36d45\n'}]",1,641284,e7fb14440e2c2701e8263a846902f347775dd27e,11,3,2,13686,,,0,"Add ``refresh_pools``

Change-Id: I97bfb9a2c0e30998566aee56d4630af6baa36d45
",git fetch https://review.opendev.org/openstack/charm-interface-ceph-rbd-mirror refs/changes/84/641284/2 && git format-patch -1 --stdout FETCH_HEAD,"['requires.py', 'unit_tests/test_requires.py']",2,d3891b2c313d64fc73b18f83abf13030d014a929,rbd-mirror," def test_refresh_pools(self): self.patch_object(requires.uuid, 'uuid4') self.uuid4.return_value = 'FAKE-UUID' to_publish = self.patch_topublish() self.requires_class.refresh_pools() to_publish.__setitem__.assert_called_with('nonce', 'FAKE-UUID') ",,25,2
openstack%2Fbarbican~master~I1d269beabb67580796394a8da75ead6562839b6c,openstack/barbican,master,I1d269beabb67580796394a8da75ead6562839b6c,Use the Octavia Barbican integration check gate,MERGED,2019-02-16 22:46:24.000000000,2019-03-07 05:42:11.000000000,2019-03-07 05:42:11.000000000,"[{'_account_id': 9914}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 22:46:24.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/barbican/commit/fe2fbb5ba288ba2e86fe87bdeebfe141b0efb3d7', 'message': 'Use the Octavia Barbican integration check gate\n\nThis patch switches the Octavia check gate from octavia-v2-dsvm-scenario\nto a Barbican targeted Octavia integration scenario test job.\nThis job will not only run faster but will cover all of the Barbican\nand Octavia touch points.\n\nChange-Id: I1d269beabb67580796394a8da75ead6562839b6c\n'}]",0,637406,fe2fbb5ba288ba2e86fe87bdeebfe141b0efb3d7,9,2,1,11628,,,0,"Use the Octavia Barbican integration check gate

This patch switches the Octavia check gate from octavia-v2-dsvm-scenario
to a Barbican targeted Octavia integration scenario test job.
This job will not only run faster but will cover all of the Barbican
and Octavia touch points.

Change-Id: I1d269beabb67580796394a8da75ead6562839b6c
",git fetch https://review.opendev.org/openstack/barbican refs/changes/06/637406/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,fe2fbb5ba288ba2e86fe87bdeebfe141b0efb3d7,, - octavia-v2-dsvm-tls-barbican:, - octavia-v2-dsvm-scenario: voting: false - octavia-v2-dsvm-py2-scenario:,1,3
openstack%2Fcharm-interface-ceph-rbd-mirror~master~I801843f81d5fbe9838142b8fba96d93bbdfc91e4,openstack/charm-interface-ceph-rbd-mirror,master,I801843f81d5fbe9838142b8fba96d93bbdfc91e4,Avoid duplicate ``create-pool`` requests for same pool,MERGED,2019-03-06 14:26:22.000000000,2019-03-07 05:42:10.000000000,2019-03-07 05:42:10.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 14:26:22.000000000', 'files': ['requires.py', 'unit_tests/test_requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-rbd-mirror/commit/65415824d01299f2f5cd233a154a913eb6dee01b', 'message': 'Avoid duplicate ``create-pool`` requests for same pool\n\nChange-Id: I801843f81d5fbe9838142b8fba96d93bbdfc91e4\n'}]",1,641388,65415824d01299f2f5cd233a154a913eb6dee01b,7,3,1,13686,,,0,"Avoid duplicate ``create-pool`` requests for same pool

Change-Id: I801843f81d5fbe9838142b8fba96d93bbdfc91e4
",git fetch https://review.opendev.org/openstack/charm-interface-ceph-rbd-mirror refs/changes/88/641388/1 && git format-patch -1 --stdout FETCH_HEAD,"['requires.py', 'unit_tests/test_requires.py']",2,65415824d01299f2f5cd233a154a913eb6dee01b,rbd-mirror," def test_create_replicated_pool(self): self.patch_requires_class('_relations') relation = mock.MagicMock() relation.relation_id = 'some-endpoint:42' self._relations.__iter__.return_value = [relation] self.patch_object(requires.ch_ceph, 'get_previous_request') broker_req = mock.MagicMock() broker_req.ops = [{'op': 'create-pool', 'name': 'rbd'}] self.get_previous_request.return_value = broker_req self.requires_class.create_replicated_pool('rbd') self.assertFalse(broker_req.add_op_create_replicated_pool.called) self.get_previous_request.return_value = None self.patch_object(requires.ch_ceph, 'CephBrokerRq') self.CephBrokerRq.return_value = broker_req self.requires_class.create_replicated_pool('rbd') self.CephBrokerRq.assert_called_with() self.assertFalse(broker_req.add_op_create_replicated_pool.called) broker_req = mock.MagicMock() self.CephBrokerRq.return_value = broker_req self.patch_object(requires.ch_ceph, 'send_request_if_needed') self.requires_class.create_replicated_pool('rbd') broker_req.add_op_create_replicated_pool.assert_called_once_with( app_name=None, group=None, max_bytes=None, max_objects=None, name='rbd', namespace=None, pg_num=None, replica_count=3, weight=None) self.send_request_if_needed.assert_called_once_with( broker_req, relation='some-endpoint') def test_create_erasure_pool(self): self.patch_requires_class('_relations') relation = mock.MagicMock() relation.relation_id = 'some-endpoint:42' self._relations.__iter__.return_value = [relation] self.patch_object(requires.ch_ceph, 'get_previous_request') broker_req = mock.MagicMock() broker_req.ops = [{'op': 'create-pool', 'name': 'rbd'}] self.get_previous_request.return_value = broker_req self.requires_class.create_erasure_pool('rbd') self.assertFalse(broker_req.add_op_create_erasure_pool.called) self.get_previous_request.return_value = None self.patch_object(requires.ch_ceph, 'CephBrokerRq') self.CephBrokerRq.return_value = broker_req self.requires_class.create_erasure_pool('rbd') self.CephBrokerRq.assert_called_with() self.assertFalse(broker_req.add_op_create_erasure_pool.called) broker_req = mock.MagicMock() self.CephBrokerRq.return_value = broker_req self.patch_object(requires.ch_ceph, 'send_request_if_needed') self.requires_class.create_erasure_pool('rbd') broker_req.add_op_create_erasure_pool.assert_called_once_with( app_name=None, erasure_profile=None, group=None, max_bytes=None, max_objects=None, name='rbd', weight=None) self.send_request_if_needed.assert_called_once_with( broker_req, relation='some-endpoint') ",,71,19
openstack%2Fbarbican~master~I4f136f5f356e3f25df09a513f0a7683082f5ce0f,openstack/barbican,master,I4f136f5f356e3f25df09a513f0a7683082f5ce0f,Enable KV mountpoint configuration for Vault,MERGED,2019-02-21 09:47:10.000000000,2019-03-07 05:33:33.000000000,2019-03-07 05:33:33.000000000,"[{'_account_id': 7973}, {'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 09:47:10.000000000', 'files': ['barbican/plugin/vault_secret_store.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/4e1d8ae5a03c1751ba57df5ef6eff23bfff11d69', 'message': 'Enable KV mountpoint configuration for Vault\n\nAdd configuration option to support end-user configuration of the\nKV store mountpoint used in Vault for storage of keys.\n\nChange-Id: I4f136f5f356e3f25df09a513f0a7683082f5ce0f\nRelated-Bug: 1797148\nDepends-On: I625a819c2b9b542677258de709a9c520fb86858b\n'}]",0,638375,4e1d8ae5a03c1751ba57df5ef6eff23bfff11d69,7,3,1,935,,,0,"Enable KV mountpoint configuration for Vault

Add configuration option to support end-user configuration of the
KV store mountpoint used in Vault for storage of keys.

Change-Id: I4f136f5f356e3f25df09a513f0a7683082f5ce0f
Related-Bug: 1797148
Depends-On: I625a819c2b9b542677258de709a9c520fb86858b
",git fetch https://review.opendev.org/openstack/barbican refs/changes/75/638375/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/vault_secret_store.py'],1,4e1d8ae5a03c1751ba57df5ef6eff23bfff11d69,bug/1797148,"DEFAULT_MOUNTPOINT = ""secret"" cfg.StrOpt('kv_mountpoint', default=DEFAULT_MOUNTPOINT, help='Mountpoint of KV store in Vault to use, for example: ' '{}'.format(DEFAULT_MOUNTPOINT)), vault_kv_mountpoint=conf.vault_plugin.kv_mountpoint,",,6,0
openstack%2Fbarbican~master~I2bafd06e2e2b1bfefe2b4c4bcbecf80d924db205,openstack/barbican,master,I2bafd06e2e2b1bfefe2b4c4bcbecf80d924db205,Enable AppRole authentication support for Vault,MERGED,2018-10-10 12:49:28.000000000,2019-03-07 05:33:29.000000000,2019-03-07 05:33:28.000000000,"[{'_account_id': 935}, {'_account_id': 7973}, {'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-10 12:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6f3d8c98eccf17c3be208e53e2b0336f93d29924', 'message': ""Enable AppRole authentication support for Vault\n\nExpose Castellan's AppRole configuration options in the vault_plugin\nsection to allow access to Vault to be managed using AppRoles which\nis better aligned to providing long term application access to Vault\nwith policy based ACL's.\n\nChange-Id: I2bafd06e2e2b1bfefe2b4c4bcbecf80d924db205\nRelated-Bug: 1796851\nStory: 2004017\nTask: 27003\nDepends-On: I59dfe31adb72712c53d49f66d9ac894e43e8bbad\n""}, {'number': 2, 'created': '2019-02-21 09:46:23.000000000', 'files': ['barbican/plugin/vault_secret_store.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/77d94ff6a99d8f45332b80ad8b9286d7b4e9c616', 'message': ""Enable AppRole authentication support for Vault\n\nExpose Castellan's AppRole configuration options in the vault_plugin\nsection to allow access to Vault to be managed using AppRoles which\nis better aligned to providing long term application access to Vault\nwith policy based ACL's.\n\nChange-Id: I2bafd06e2e2b1bfefe2b4c4bcbecf80d924db205\nRelated-Bug: 1796851\nStory: 2004017\nTask: 27003\nDepends-On: I59dfe31adb72712c53d49f66d9ac894e43e8bbad\n""}]",0,609396,77d94ff6a99d8f45332b80ad8b9286d7b4e9c616,10,4,2,935,,,0,"Enable AppRole authentication support for Vault

Expose Castellan's AppRole configuration options in the vault_plugin
section to allow access to Vault to be managed using AppRoles which
is better aligned to providing long term application access to Vault
with policy based ACL's.

Change-Id: I2bafd06e2e2b1bfefe2b4c4bcbecf80d924db205
Related-Bug: 1796851
Story: 2004017
Task: 27003
Depends-On: I59dfe31adb72712c53d49f66d9ac894e43e8bbad
",git fetch https://review.opendev.org/openstack/barbican refs/changes/96/609396/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/vault_secret_store.py'],1,6f3d8c98eccf17c3be208e53e2b0336f93d29924,bug/1796851," cfg.StrOpt('approle_role_id', help='AppRole role_id for authentication with vault'), cfg.StrOpt('approle_secret_id', help='AppRole secret_id for authentication with vault'), vault_approle_role_id=conf.vault_plugin.approle_role_id, vault_approle_secret_id=conf.vault_plugin.approle_secret_id,",,6,0
openstack%2Fcharm-interface-ceph-rbd-mirror~master~I6206237d1cc902a1e8e521b37c19d84267ae8d6d,openstack/charm-interface-ceph-rbd-mirror,master,I6206237d1cc902a1e8e521b37c19d84267ae8d6d,Add gate jobs,MERGED,2019-03-04 07:06:48.000000000,2019-03-07 05:32:35.000000000,2019-03-07 05:32:35.000000000,"[{'_account_id': 935}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 07:06:48.000000000', 'files': ['.gitignore', '.gitreview', '.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-rbd-mirror/commit/6a9d50c2dc4d436a4850b17a57e8dd908344a6c3', 'message': 'Add gate jobs\n\nAdd test coverage report\n\nChange-Id: I6206237d1cc902a1e8e521b37c19d84267ae8d6d\n'}]",0,640679,6a9d50c2dc4d436a4850b17a57e8dd908344a6c3,7,2,1,13686,,,0,"Add gate jobs

Add test coverage report

Change-Id: I6206237d1cc902a1e8e521b37c19d84267ae8d6d
",git fetch https://review.opendev.org/openstack/charm-interface-ceph-rbd-mirror refs/changes/79/640679/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview', '.zuul.yaml', 'tox.ini']",4,6a9d50c2dc4d436a4850b17a57e8dd908344a6c3,rbd-mirror,setenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage reportsetenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage reportsetenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage report[coverage:run] branch = True concurrency = multiprocessing parallel = True source = . omit = .tox/* unit_tests/* ,commands = stestr run {posargs}commands = stestr run {posargs}commands = stestr run {posargs},49,3
openstack%2Fcharm-ceph-rbd-mirror~master~I550473edf7c7253b96fdb323b8b4761049a1de88,openstack/charm-ceph-rbd-mirror,master,I550473edf7c7253b96fdb323b8b4761049a1de88,Add summary stats for mirrored pools and images in workload status,MERGED,2019-03-04 16:46:19.000000000,2019-03-07 05:32:30.000000000,2019-03-07 05:32:30.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 16:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/073d3bf44f6d9c94ec3c1dc0c9585dea8c8a7eed', 'message': 'Add summary stats for mirrored pools and images in workload status\n\nChange-Id: I550473edf7c7253b96fdb323b8b4761049a1de88\n'}, {'number': 2, 'created': '2019-03-04 16:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/3b3243e003f7faf67d460d6f16d757fd9c4e19ae', 'message': 'Add summary stats for mirrored pools and images in workload status\n\nChange-Id: I550473edf7c7253b96fdb323b8b4761049a1de88\n'}, {'number': 3, 'created': '2019-03-05 09:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/142e57ef42f285480bfec5acdefb9fe51b3712e6', 'message': 'Add summary stats for mirrored pools and images in workload status\n\nChange-Id: I550473edf7c7253b96fdb323b8b4761049a1de88\n'}, {'number': 4, 'created': '2019-03-05 11:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/56e965fd58110ebd2252d30586240c617ae94196', 'message': 'Add summary stats for mirrored pools and images in workload status\n\nChange-Id: I550473edf7c7253b96fdb323b8b4761049a1de88\n'}, {'number': 5, 'created': '2019-03-05 11:36:23.000000000', 'files': ['unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/d9cea01476f8b1f3f34c836eb3d4699ebe0001c7', 'message': 'Add summary stats for mirrored pools and images in workload status\n\nChange-Id: I550473edf7c7253b96fdb323b8b4761049a1de88\n'}]",0,640811,d9cea01476f8b1f3f34c836eb3d4699ebe0001c7,17,3,5,13686,,,0,"Add summary stats for mirrored pools and images in workload status

Change-Id: I550473edf7c7253b96fdb323b8b4761049a1de88
",git fetch https://review.opendev.org/openstack/charm-ceph-rbd-mirror refs/changes/11/640811/4 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py']",2,073d3bf44f6d9c94ec3c1dc0c9585dea8c8a7eed,rbd-mirror,"import collections stats = self.mirror_pools_summary( (pool for pool, attrs in endpoint.pools.items() if 'rbd' in attrs['applications'])) ch_core.hookenv.log('mirror_pools_summary = ""{}""' .format(stats), level=ch_core.hookenv.DEBUG) status = 'active' pool_msg = '' image_msg = '' for health, count in stats['pool_health'].items(): if not pool_msg: pool_msg = 'Mirroring Pools ' pool_msg += '{} ({}) '.format(health, count) if health != 'OK': status = 'blocked' for state, count in stats['image_states'].items(): if not image_msg: image_msg = 'Images ' if state == 'stopped': state_name = 'Primary' elif state == 'replaying': state_name = 'Secondary' else: state_name = state image_msg += '{} ({}) '.format(state_name, count) msg = '' if pool_msg: msg = pool_msg + image_msg else: status = 'waiting' msg = 'Waiting for pools to be created' return status, msg def mirror_pools_summary(self, pools): stats = {} stats['pool_health'] = collections.defaultdict(int) stats['image_states'] = collections.defaultdict(int) for pool in pools: pool_stat = self.mirror_pool_status(pool) stats['pool_health'][pool_stat['summary']['health']] += 1 for state, value in pool_stat['summary']['states'].items(): stats['image_states'][state] += value return stats "," for pool, attrs in endpoint.pools.items(): if 'rbd' in attrs['applications']: status = self.mirror_pool_status(pool) ch_core.hookenv.log('DEBUG: mirror_pool_status({}) = ""{}""' .format(pool, status), level=ch_core.hookenv.INFO) return 'active', 'Custom'",61,8
openstack%2Fcharm-ceph-rbd-mirror~master~Ie2233350cb4520b598dd127b24132fdb4ed42802,openstack/charm-ceph-rbd-mirror,master,Ie2233350cb4520b598dd127b24132fdb4ed42802,Make rbd tool use json formatted output,MERGED,2019-03-04 11:38:19.000000000,2019-03-07 05:32:08.000000000,2019-03-07 05:32:08.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 11:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/b68fa024062ea88ec7756cd3e850fc5784e7d9b4', 'message': 'Make rbd tool use json formatted output\n\nChange-Id: Ie2233350cb4520b598dd127b24132fdb4ed42802\n'}, {'number': 2, 'created': '2019-03-05 11:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/e94563af57e518e5b8a33ecbbdc390e24873369f', 'message': 'Make rbd tool use json formatted output\n\nChange-Id: Ie2233350cb4520b598dd127b24132fdb4ed42802\n'}, {'number': 3, 'created': '2019-03-05 11:36:23.000000000', 'files': ['unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/8e54055e92fbb9776195a43b0bd87c362873ec4c', 'message': 'Make rbd tool use json formatted output\n\nChange-Id: Ie2233350cb4520b598dd127b24132fdb4ed42802\n'}]",0,640735,8e54055e92fbb9776195a43b0bd87c362873ec4c,13,4,3,13686,,,0,"Make rbd tool use json formatted output

Change-Id: Ie2233350cb4520b598dd127b24132fdb4ed42802
",git fetch https://review.opendev.org/openstack/charm-ceph-rbd-mirror refs/changes/35/640735/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py']",2,b68fa024062ea88ec7756cd3e850fc5784e7d9b4,rbd-mirror,"import json 'mirror', 'pool', 'info', '--format', 'json', pool], return json.loads(output) return self._mirror_pool_info(pool).get('mode', None) == 'pool' return len(self._mirror_pool_info(pool).get('peers', [])) > 0 'mirror', 'pool', 'status', '--format', 'json', '--verbose', pool], return json.loads(output)"," 'mirror', 'pool', 'info', pool], return output return 'Mode: pool' in self._mirror_pool_info(pool) return 'Peers: none' not in self._mirror_pool_info(pool) 'mirror', 'pool', 'status', pool], result = {} for line in output.splitlines(): vp = line.split(':') result.update({vp[0]: vp[1].lstrip().rstrip()}) return result",32,23
openstack%2Ftripleo-heat-templates~master~Ic36e4459346daafd288f0767186e4df17f01a0b5,openstack/tripleo-heat-templates,master,Ic36e4459346daafd288f0767186e4df17f01a0b5,Remove environments/baremetal-services.yaml,MERGED,2018-12-28 12:25:12.000000000,2019-03-07 05:32:06.000000000,2019-03-07 05:32:06.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 11444}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-28 12:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f70c95529257d11a9f7b052eb7120f96b32898a3', 'message': ""Remove environments/baremetal-services.yaml\n\nDeploying services on baremetal isn't supported nor tested anymore, we\nshouldn't provide an environment that would confuse our users.\n\nThis patch removes the environment file so it doesn't confuse users, and\nalso so we don't have to maintain it anymore.\n\nChange-Id: Ic36e4459346daafd288f0767186e4df17f01a0b5\n""}, {'number': 2, 'created': '2019-01-11 13:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/85c3d3f3fd1479b1685b477c18dbfad52e2db98f', 'message': ""Remove environments/baremetal-services.yaml\n\nDeploying services on baremetal isn't supported nor tested anymore, we\nshouldn't provide an environment that would confuse our users.\n\nThis patch removes the environment file so it doesn't confuse users, and\nalso so we don't have to maintain it anymore.\n\nChange-Id: Ic36e4459346daafd288f0767186e4df17f01a0b5\n""}, {'number': 3, 'created': '2019-02-26 17:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f46b33ea962868f4f2c25d8ab8decb4f48b9858d', 'message': ""Remove environments/baremetal-services.yaml\n\nDeploying services on baremetal isn't supported nor tested anymore, we\nshouldn't provide an environment that would confuse our users.\n\nThis patch removes the environment file so it doesn't confuse users, and\nalso so we don't have to maintain it anymore.\n\nChange-Id: Ic36e4459346daafd288f0767186e4df17f01a0b5\n""}, {'number': 4, 'created': '2019-03-06 16:34:55.000000000', 'files': ['environments/baremetal-services.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/30968cedf10a5508009dab3fa56ce02465860b54', 'message': ""Remove environments/baremetal-services.yaml\n\nDeploying services on baremetal isn't supported nor tested anymore, we\nshouldn't provide an environment that would confuse our users.\n\nThis patch removes the environment file so it doesn't confuse users, and\nalso so we don't have to maintain it anymore.\n\nChange-Id: Ic36e4459346daafd288f0767186e4df17f01a0b5\n""}]",0,627632,30968cedf10a5508009dab3fa56ce02465860b54,27,9,4,3153,,,0,"Remove environments/baremetal-services.yaml

Deploying services on baremetal isn't supported nor tested anymore, we
shouldn't provide an environment that would confuse our users.

This patch removes the environment file so it doesn't confuse users, and
also so we don't have to maintain it anymore.

Change-Id: Ic36e4459346daafd288f0767186e4df17f01a0b5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/32/627632/4 && git format-patch -1 --stdout FETCH_HEAD,['environments/baremetal-services.yaml'],1,f70c95529257d11a9f7b052eb7120f96b32898a3,bm/cleanup,,"resource_registry: OS::TripleO::Services::Docker: OS::Heat::None OS::TripleO::Docker::NeutronMl2PluginBase: OS::Heat::None OS::TripleO::Services::AodhApi: ../deployment/aodh/aodh-api-container-puppet.yaml OS::TripleO::Services::AodhEvaluator: ../deployment/aodh/aodh-evaluator-container-puppet.yaml OS::TripleO::Services::AodhNotifier: ../deployment/aodh/aodh-notifier-container-puppet.yaml OS::TripleO::Services::AodhListener: ../deployment/aodh/aodh-listener-container-puppet.yaml OS::TripleO::Services::BlockStorageCinderVolume: ../puppet/services/cinder-volume.yaml OS::TripleO::Services::CeilometerAgentCentral: ../puppet/services/ceilometer-agent-central.yaml OS::TripleO::Services::CeilometerAgentIpmi: ../puppet/services/ceilometer-agent-ipmi.yaml OS::TripleO::Services::CeilometerAgentNotification: ../puppet/services/ceilometer-agent-notification.yaml OS::TripleO::Services::CinderApi: ../puppet/services/cinder-api.yaml OS::TripleO::Services::CinderScheduler: ../puppet/services/cinder-scheduler.yaml OS::TripleO::Services::CinderVolume: ../puppet/services/cinder-volume.yaml OS::TripleO::Services::ComputeCeilometerAgent: ../puppet/services/ceilometer-agent-compute.yaml OS::TripleO::Services::ComputeNeutronOvsAgent: ../puppet/services/neutron-ovs-agent.yaml OS::TripleO::Services::ContainersLogrotateCrond: OS::Heat::None OS::TripleO::Services::GlanceApi: ../deployment/glance/glance-api-container-puppet.yaml OS::TripleO::Services::GnocchiApi: ../puppet/services/gnocchi-api.yaml OS::TripleO::Services::GnocchiMetricd: ../puppet/services/gnocchi-metricd.yaml OS::TripleO::Services::GnocchiStatsd: ../puppet/services/gnocchi-statsd.yaml OS::TripleO::Services::HAproxy: ../puppet/services/haproxy.yaml OS::TripleO::Services::HeatApi: ../puppet/services/heat-api.yaml OS::TripleO::Services::HeatApiCfn: ../puppet/services/heat-api-cfn.yaml OS::TripleO::Services::HeatEngine: ../puppet/services/heat-engine.yaml OS::TripleO::Services::Horizon: ../puppet/services/horizon.yaml OS::TripleO::Services::Iscsid: ../puppet/services/iscsid.yaml OS::TripleO::Services::Keystone: ../puppet/services/keystone.yaml OS::TripleO::Services::Memcached: ../deployment/memcached/memcached-container-puppet.yaml OS::TripleO::Services::Multipathd: OS::Heat::None OS::TripleO::Services::MySQL: ../puppet/services/database/mysql.yaml OS::TripleO::Services::NeutronApi: ../puppet/services/neutron-api.yaml OS::TripleO::Services::NeutronCorePlugin: ../puppet/services/neutron-plugin-ml2.yaml OS::TripleO::Services::NeutronDhcpAgent: ../puppet/services/neutron-dhcp.yaml OS::TripleO::Services::NeutronL3Agent: ../puppet/services/neutron-l3.yaml OS::TripleO::Services::NeutronMetadataAgent: ../puppet/services/neutron-metadata.yaml OS::TripleO::Services::NeutronOvsAgent: ../puppet/services/neutron-ovs-agent.yaml OS::TripleO::Services::NeutronServer: ../puppet/services/neutron-api.yaml OS::TripleO::Services::NovaApi: ../puppet/services/nova-api.yaml OS::TripleO::Services::NovaCompute: ../puppet/services/nova-compute.yaml OS::TripleO::Services::NovaConductor: ../puppet/services/nova-conductor.yaml OS::TripleO::Services::NovaConsoleauth: ../puppet/services/nova-consoleauth.yaml OS::TripleO::Services::NovaLibvirt: ../puppet/services/nova-libvirt.yaml OS::TripleO::Services::NovaMetadata: ../puppet/services/nova-metadata.yaml OS::TripleO::Services::NovaMigrationTarget: ../puppet/services/nova-migration-target.yaml OS::TripleO::Services::NovaPlacement: ../puppet/services/nova-placement.yaml OS::TripleO::Services::NovaScheduler: ../puppet/services/nova-scheduler.yaml OS::TripleO::Services::NovaVncProxy: ../puppet/services/nova-vnc-proxy.yaml OS::TripleO::Services::PankoApi: ../puppet/services/panko-api.yaml OS::TripleO::Services::Qdr: OS::Heat::None OS::TripleO::Services::RabbitMQ: ../puppet/services/rabbitmq.yaml OS::TripleO::Services::Redis: ../puppet/services/database/redis.yaml OS::TripleO::Services::Sshd: ../puppet/services/sshd.yaml OS::TripleO::Services::SwiftDispersion: ../puppet/services/swift-dispersion.yaml OS::TripleO::Services::SwiftProxy: ../puppet/services/swift-proxy.yaml OS::TripleO::Services::SwiftRingBuilder: ../puppet/services/swift-ringbuilder.yaml OS::TripleO::Services::SwiftStorage: ../puppet/services/swift-storage.yaml # If SR-IOV is enabled on the compute nodes, it will need the SR-IOV # host configuration. OS::TripleO::Services::NeutronSriovHostConfig: OS::Heat::None ",0,63
openstack%2Ftripleo-heat-templates~master~I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3,openstack/tripleo-heat-templates,master,I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3,CI: force ContainerCli to Docker when needed,MERGED,2019-03-05 00:31:02.000000000,2019-03-07 05:32:04.000000000,2019-03-07 05:32:04.000000000,"[{'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 00:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fd2a106e77a30da9c09e601cc5b9a3efa2f6d0ba', 'message': ""CI: force ContainerCli to Docker when needed\n\nFor the CI scenarios which still run Pacemaker, let's force ContainerCli\nuntil we get them working with Podman.\n\nChange-Id: I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3\n""}, {'number': 2, 'created': '2019-03-05 00:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a1023a631c2ae728305a9bc37a9884c3dfed5a5', 'message': ""CI: force ContainerCli to Docker when needed\n\nFor the CI scenarios which still run Pacemaker, let's force ContainerCli\nuntil we get them working with Podman.\n\nChange-Id: I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3\n""}, {'number': 3, 'created': '2019-03-05 13:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4bbdf16fc5983bd5c2e82030d469ac49237630d', 'message': ""CI: force ContainerCli to Docker when needed\n\nFor the CI scenarios which still run Pacemaker, let's force ContainerCli\nuntil we get them working with Podman.\n\nChange-Id: I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3\n""}, {'number': 4, 'created': '2019-03-05 23:37:08.000000000', 'files': ['ci/environments/scenario010-multinode-containers.yaml', 'ci/environments/scenario012-multinode-containers.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/multinode-3nodes-registry.yaml', 'ci/environments/scenario007-multinode-containers.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'ci/environments/scenario004-multinode-containers.yaml', 'ci/environments/scenario012-standalone.yaml', 'ci/environments/scenario004-standalone.yaml', 'ci/environments/scenario000-multinode-containers.yaml', 'ci/environments/scenario006-multinode-containers.yaml', 'ci/environments/scenario003-multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ce23ccf532c1c471c5d1fb675a71de9003ff5e95', 'message': ""CI: force ContainerCli to Docker when needed\n\nFor the CI scenarios which still run Pacemaker, let's force ContainerCli\nuntil we get them working with Podman.\n\nChange-Id: I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3\n""}]",0,640902,ce23ccf532c1c471c5d1fb675a71de9003ff5e95,15,6,4,3153,,,0,"CI: force ContainerCli to Docker when needed

For the CI scenarios which still run Pacemaker, let's force ContainerCli
until we get them working with Podman.

Change-Id: I8405a00c7e4686b1569f6e68e3c1507f1e11b3a3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/640902/3 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario010-multinode-containers.yaml', 'ci/environments/scenario012-multinode-containers.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/multinode-3nodes-registry.yaml', 'ci/environments/scenario007-multinode-containers.yaml', 'ci/environments/scenario002-multinode-containers.yaml', 'ci/environments/scenario004-multinode-containers.yaml', 'ci/environments/scenario012-standalone.yaml', 'ci/environments/scenario004-standalone.yaml', 'ci/environments/scenario000-multinode-containers.yaml', 'ci/environments/scenario006-multinode-containers.yaml', 'ci/environments/scenario003-multinode-containers.yaml']",12,fd2a106e77a30da9c09e601cc5b9a3efa2f6d0ba,scenarios/defaults, # Remove ContainerCli once this scenario is tested on CentOS8 ContainerCli: docker,,24,0
openstack%2Ftripleo-heat-templates~master~Iabd65560c2fc28b3aeca07a21efa861c4c583c01,openstack/tripleo-heat-templates,master,Iabd65560c2fc28b3aeca07a21efa861c4c583c01,Rename docker_config_scripts to container_config_scripts,MERGED,2019-03-06 00:23:15.000000000,2019-03-07 05:32:02.000000000,2019-03-07 05:32:02.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 00:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d427b52d6b559d4c2540d27f8783c455cd84247', 'message': 'Rename docker_config_scripts to container_config_scripts\n\nChange-Id: Iabd65560c2fc28b3aeca07a21efa861c4c583c01\n'}, {'number': 2, 'created': '2019-03-06 14:05:54.000000000', 'files': ['deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/nova/nova-ironic-container-puppet.yaml', 'container_config_scripts/tests/test_nova_statedir_ownership.py', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'container_config_scripts/pyshim.sh', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'docker/services/containers-common.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'deployment/nova/nova-compute-common-container-puppet.yaml', 'deployment/swift/swift-proxy-container-puppet.yaml', 'common/services.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'container_config_scripts/__init__.py', 'docker/services/ovn-metadata.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'tools/yaml-validate.py', 'container_config_scripts/nova_cell_v2_discover_host.py', 'container_config_scripts/nova_wait_for_placement_service.py', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/neutron/neutron-l3-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/ironic/ironic-conductor-container-puppet.yaml', 'deployment/neutron/neutron-ovs-dpdk-agent-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'container_config_scripts/tests/__init__.py', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml', 'deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'common/deploy-steps-tasks.yaml', 'container_config_scripts/nova_statedir_ownership.py', 'tox.ini', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/160cddda3fea46fcb4cd94c94eb6d01e8df06b1a', 'message': 'Rename docker_config_scripts to container_config_scripts\n\nChange-Id: Iabd65560c2fc28b3aeca07a21efa861c4c583c01\n'}]",0,641172,160cddda3fea46fcb4cd94c94eb6d01e8df06b1a,15,5,2,3153,,,0,"Rename docker_config_scripts to container_config_scripts

Change-Id: Iabd65560c2fc28b3aeca07a21efa861c4c583c01
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/641172/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/nova/nova-ironic-container-puppet.yaml', 'container_config_scripts/tests/test_nova_statedir_ownership.py', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'container_config_scripts/pyshim.sh', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'docker/services/containers-common.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'deployment/nova/nova-compute-common-container-puppet.yaml', 'deployment/swift/swift-proxy-container-puppet.yaml', 'common/services.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'container_config_scripts/__init__.py', 'docker/services/ovn-metadata.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'tools/yaml-validate.py', 'container_config_scripts/nova_cell_v2_discover_host.py', 'container_config_scripts/nova_wait_for_placement_service.py', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/neutron/neutron-l3-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/ironic/ironic-conductor-container-puppet.yaml', 'deployment/neutron/neutron-ovs-dpdk-agent-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'container_config_scripts/tests/__init__.py', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml', 'deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'common/deploy-steps-tasks.yaml', 'container_config_scripts/nova_statedir_ownership.py', 'tox.ini', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml']",34,4d427b52d6b559d4c2540d27f8783c455cd84247,docker_config_scripts," container_config_scripts: {get_attr: [ContainersCommon, container_config_scripts]}"," docker_config_scripts: {get_attr: [ContainersCommon, docker_config_scripts]}",44,44
openstack%2Fcharm-ceph-rbd-mirror~master~Ic05c72f9e684f615b60a3975779e76526a0c9c64,openstack/charm-ceph-rbd-mirror,master,Ic05c72f9e684f615b60a3975779e76526a0c9c64,Add gate jobs,MERGED,2019-03-04 09:35:48.000000000,2019-03-07 05:30:46.000000000,2019-03-07 05:30:46.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 09:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/d8a66680c4f9881e75ee0b17dfbb3a3c232942d4', 'message': 'Add gate jobs\n\nFix a few discrepancies discovered during unit testing.\n\nAdd missing unit tests.\n\nAdd end to end functional test bundle.\n\nChange-Id: Ic05c72f9e684f615b60a3975779e76526a0c9c64\n'}, {'number': 2, 'created': '2019-03-04 11:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/9766176f05bd1c70364e21406dd372f1785d95ab', 'message': 'Add gate jobs\n\nFix a few discrepancies discovered during unit testing.\n\nAdd missing unit tests.\n\nAdd end to end functional test bundle.\n\nChange-Id: Ic05c72f9e684f615b60a3975779e76526a0c9c64\n'}, {'number': 3, 'created': '2019-03-05 11:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/31c6e86ca9fc272dbb7354a5b530263787ded602', 'message': 'Add gate jobs\n\nFix a few discrepancies discovered during unit testing.\n\nAdd missing unit tests.\n\nAdd end to end functional test bundle.\n\nChange-Id: Ic05c72f9e684f615b60a3975779e76526a0c9c64\n'}, {'number': 4, 'created': '2019-03-05 11:36:23.000000000', 'files': ['.gitignore', '.gitreview', 'test-requirements.txt', 'src/tests/bundles/bionic-queens-e2e.yaml', '.zuul.yaml', 'src/reactive/ceph_rbd_mirror_handlers.py', 'unit_tests/test_ceph_rbd_mirror_handlers.py', 'src/lib/charm/openstack/ceph_rbd_mirror.py', 'src/tests/tests.yaml', 'unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/tests/bundles/bionic-queens.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-ceph-rbd-mirror/commit/a17c896c296c8f69f428077725d9f3052f30daad', 'message': 'Add gate jobs\n\nFix a few discrepancies discovered during unit testing.\n\nAdd missing unit tests.\n\nAdd end to end functional test bundle.\n\nChange-Id: Ic05c72f9e684f615b60a3975779e76526a0c9c64\n'}]",0,640699,a17c896c296c8f69f428077725d9f3052f30daad,23,4,4,13686,,,0,"Add gate jobs

Fix a few discrepancies discovered during unit testing.

Add missing unit tests.

Add end to end functional test bundle.

Change-Id: Ic05c72f9e684f615b60a3975779e76526a0c9c64
",git fetch https://review.opendev.org/openstack/charm-ceph-rbd-mirror refs/changes/99/640699/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview', 'test-requirements.txt', 'unit_tests/test_lib_charm_openstack_ceph_rbd_mirror.py', 'src/tests/bundles/bionic-queens-e2e.yaml', '.zuul.yaml', 'src/reactive/ceph_rbd_mirror_handlers.py', 'unit_tests/test_ceph_rbd_mirror_handlers.py', 'src/tests/tests.yaml', 'tox.ini']",10,d8a66680c4f9881e75ee0b17dfbb3a3c232942d4,rbd-mirror,passenv = http_proxy https_proxysetenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage report setenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage reportsetenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage report[coverage:run] branch = True concurrency = multiprocessing parallel = True source = . omit = .tox/* unit_tests/* , LAYER_PATH={toxinidir}/layers INTERFACE_PATH={toxinidir}/interfaces JUJU_REPOSITORY={toxinidir}/build passenv = http_proxy https_proxy INTERFACE_PATHcommands = ostestr {posargs}commands = ostestr {posargs}commands = ostestr {posargs},433,19
openstack%2Fcharm-cinder~master~I36b5fb637b7daee782a54b02da676cf75ea19e8f,openstack/charm-cinder,master,I36b5fb637b7daee782a54b02da676cf75ea19e8f,Switched from ostestr -> stestr for tests.,MERGED,2019-03-06 19:55:45.000000000,2019-03-07 05:28:17.000000000,2019-03-07 05:28:17.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 19:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/f6e4545c4affb25ff97a43f105483bee053fabc6', 'message': 'Switched from ostestr -> stestr for tests.\n\nFixes breackage in python3.5 due to underlying system upgrade.\n\nChange-Id: I36b5fb637b7daee782a54b02da676cf75ea19e8f\n'}, {'number': 2, 'created': '2019-03-06 20:01:38.000000000', 'files': ['test-requirements.txt', '.testr.conf', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/04a0febd7968c41e7dfc65b34884203d3403d8b8', 'message': 'Switched from ostestr -> stestr for tests.\n\nFixes breackage in python3.5 due to underlying system upgrade.\n\nChange-Id: I36b5fb637b7daee782a54b02da676cf75ea19e8f\n'}]",0,641477,04a0febd7968c41e7dfc65b34884203d3403d8b8,9,3,2,26040,,,0,"Switched from ostestr -> stestr for tests.

Fixes breackage in python3.5 due to underlying system upgrade.

Change-Id: I36b5fb637b7daee782a54b02da676cf75ea19e8f
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/77/641477/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', '.testr.conf', 'tox.ini']",3,f6e4545c4affb25ff97a43f105483bee053fabc6,switch-to-stestr,commands = stestr run {posargs} stestr run {posargs},commands = ostestr {posargs} ostestr {posargs},3,11
openstack%2Foctavia~master~I5351a3bc4f1d80846ecbc7e1a77a47d9b91d7de7,openstack/octavia,master,I5351a3bc4f1d80846ecbc7e1a77a47d9b91d7de7,Remove outdated/incorrect certificate advice,MERGED,2019-03-06 23:29:22.000000000,2019-03-07 05:25:18.000000000,2019-03-07 05:25:18.000000000,"[{'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 23:29:22.000000000', 'files': ['etc/octavia.conf'], 'web_link': 'https://opendev.org/openstack/octavia/commit/838719a09a43c24f6369c2a425d3be4f6082d85f', 'message': 'Remove outdated/incorrect certificate advice\n\nThis was from when we thought Anchor was the future of our internal cert\nauthority configuration. Self-signed certs are perfectly acceptable for\nproduction deployments.\n\nChange-Id: I5351a3bc4f1d80846ecbc7e1a77a47d9b91d7de7\n'}]",0,641515,838719a09a43c24f6369c2a425d3be4f6082d85f,7,3,1,10273,,,0,"Remove outdated/incorrect certificate advice

This was from when we thought Anchor was the future of our internal cert
authority configuration. Self-signed certs are perfectly acceptable for
production deployments.

Change-Id: I5351a3bc4f1d80846ecbc7e1a77a47d9b91d7de7
",git fetch https://review.opendev.org/openstack/octavia refs/changes/15/641515/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/octavia.conf'],1,838719a09a43c24f6369c2a425d3be4f6082d85f,,# For local certificate signing:,# For local certificate signing (development only):,1,1
openstack%2Fopenstack-helm~master~I9ba18101a4566329f288d77677d4255646935dd5,openstack/openstack-helm,master,I9ba18101a4566329f288d77677d4255646935dd5,readOnlyFilesystem: true for neutron chart,MERGED,2019-02-26 21:16:39.000000000,2019-03-07 05:06:07.000000000,2019-03-07 05:06:07.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28208}, {'_account_id': 29144}, {'_account_id': 29161}]","[{'number': 1, 'created': '2019-02-26 21:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b9b75cc1b4028712e41bdb6f917a192474ea158f', 'message': 'Fix for adding readOnlyFilesystem: true flag at container\nlevel for neutron chart\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 2, 'created': '2019-02-27 01:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1dc183fee8f334f1a398ac39456785b086a0275a', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\n\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 3, 'created': '2019-02-27 17:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/575e4100df75e6ad0d992a2ffa6c78ba7cc82b59', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 4, 'created': '2019-03-04 19:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/84f991b8f1aa2c2a1f792e02eb9f8c83a432b69b', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 5, 'created': '2019-03-04 20:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1d53d69b05e367edddc705eaf55e8d0fb2aef60b', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 6, 'created': '2019-03-05 19:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/96f376895076a597e8a6e0d4d35035e3128fb867', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 7, 'created': '2019-03-06 16:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9d2a9f4e55c9dc170ec780bd88699375ed39aa08', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}, {'number': 8, 'created': '2019-03-07 03:48:39.000000000', 'files': ['neutron/templates/deployment-server.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6d7724c79071832008322a5b9c46f98a1e56dc43', 'message': 'readOnlyFilesystem: true for neutron chart\n\nFix for adding readOnlyFilesystem flag at pod level\n\nChange-Id: I9ba18101a4566329f288d77677d4255646935dd5\n'}]",1,639443,6d7724c79071832008322a5b9c46f98a1e56dc43,39,7,8,29144,,,0,"readOnlyFilesystem: true for neutron chart

Fix for adding readOnlyFilesystem flag at pod level

Change-Id: I9ba18101a4566329f288d77677d4255646935dd5
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/43/639443/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/templates/deployment-server.yaml'],1,b9b75cc1b4028712e41bdb6f917a192474ea158f,neutron, readOnlyRootFilesystem: true,,1,0
openstack%2Fcinder~master~I2b96530b32d7a32acb653d2b432e1421c12554bf,openstack/cinder,master,I2b96530b32d7a32acb653d2b432e1421c12554bf,Update required version of taskflow,MERGED,2019-03-05 16:02:41.000000000,2019-03-07 04:55:46.000000000,2019-03-06 18:46:06.000000000,"[{'_account_id': 1736}, {'_account_id': 5314}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 20284}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 28801}, {'_account_id': 29637}]","[{'number': 1, 'created': '2019-03-05 16:02:41.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/042b22a078bf2fce45fcf983bcd35ab0b1f71170', 'message': ""Update required version of taskflow\n\n2.16.0 is from a Queens release -- push things\nforward a bit to reduce the odds that we'll\nend up with issues related to dependency updates\n(such as networkx 2.0) or Python 3.\n\nChange-Id: I2b96530b32d7a32acb653d2b432e1421c12554bf\n""}]",0,641065,042b22a078bf2fce45fcf983bcd35ab0b1f71170,37,31,1,4523,,,0,"Update required version of taskflow

2.16.0 is from a Queens release -- push things
forward a bit to reduce the odds that we'll
end up with issues related to dependency updates
(such as networkx 2.0) or Python 3.

Change-Id: I2b96530b32d7a32acb653d2b432e1421c12554bf
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/641065/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,042b22a078bf2fce45fcf983bcd35ab0b1f71170,,taskflow==3.2.0,taskflow==2.16.0,2,2
openstack%2Fzun-ui~master~I6f11627eb90d2d12f433f88ce3b687db60eebf03,openstack/zun-ui,master,I6f11627eb90d2d12f433f88ce3b687db60eebf03,Imported Translations from Zanata,MERGED,2019-03-06 07:22:28.000000000,2019-03-07 04:53:04.000000000,2019-03-07 04:53:04.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 07:22:28.000000000', 'files': ['releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/zun-ui/commit/7af2deea4899e164c04a0c9205aaea1743714596', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I6f11627eb90d2d12f433f88ce3b687db60eebf03\n'}]",0,641258,7af2deea4899e164c04a0c9205aaea1743714596,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I6f11627eb90d2d12f433f88ce3b687db60eebf03
",git fetch https://review.opendev.org/openstack/zun-ui refs/changes/58/641258/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po'],1,7af2deea4899e164c04a0c9205aaea1743714596,zanata/translations,"# ByungYeol Woo <wby1089@gmail.com>, 2019. #zanata""POT-Creation-Date: 2019-02-26 06:04+0000\n""""PO-Revision-Date: 2019-03-05 12:41+0000\n"" ""Last-Translator: ByungYeol Woo <wby1089@gmail.com>\n""msgid ""0.2.0"" msgstr ""0.2.0"" msgid ""1.0.0"" msgstr ""1.0.0"" msgid ""1.0.0-18"" msgstr ""1.0.0-18"" msgid ""2.0.0"" msgstr ""2.0.0"" msgid """" ""Added Cloud Shell feature. See also [`Screen Shot <https://drive.google.com/"" ""file/d/0B1UFZO9xX8eweERNX2FWVGRrMXM/view>`_] and [`Short Video <https://"" ""youtu.be/lYt2U7qZG38>`_]."" msgstr """" ""클라우드 쉘 기능이 추가되었습니다. [`Screen Shot <https://drive.google.com/"" ""file/d/0B1UFZO9xX8eweERNX2FWVGRrMXM/view>`_] 그리고 [`Short Video <https://"" ""youtu.be/lYt2U7qZG38>`_] 를 살펴보세요."" ","""POT-Creation-Date: 2018-08-21 00:14+0000\n""""PO-Revision-Date: 2017-07-31 01:08+0000\n"" ""Last-Translator: minwook-shin <minwook0106@gmail.com>\n""",25,3
openstack%2Fopenstack-helm-infra~master~Ia89d42a5305c94da26337aaf716978c1defae503,openstack/openstack-helm-infra,master,Ia89d42a5305c94da26337aaf716978c1defae503,Add east-west ingress network policy to Prometheus,MERGED,2019-02-05 19:42:20.000000000,2019-03-07 04:44:10.000000000,2019-03-07 04:44:10.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28849}]","[{'number': 1, 'created': '2019-02-05 19:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f51fd7ba49060af322c99fa11c018f28db12a013', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 2, 'created': '2019-02-05 20:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/eba3ae8c1b9ade5240325162d5e9a6d121027add', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 3, 'created': '2019-02-06 15:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/843376bf5185361dd41e703e2ea1622d832bd0df', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 4, 'created': '2019-02-06 15:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/630b2091f0a3227bb717d0331e1fd64a2ba1d3b1', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 5, 'created': '2019-02-07 16:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a52de598190d2dff8e558f5ad69f45fe9afbd117', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 6, 'created': '2019-02-07 17:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e7ebe4e099bd938a681a107e96ee3030b8a6065e', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 7, 'created': '2019-02-07 17:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ec7dc4a1e2380c201a40bde8f122124d43865c1a', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 8, 'created': '2019-02-07 18:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ff3d503268fa1b61f825a144e6c8dc758b44045', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 9, 'created': '2019-02-07 21:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5b1bfea4b19404c1c6335c3cefc307d5feaaf4e7', 'message': 'WIP:Add east-west ingress network policy to Prometheus services\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 10, 'created': '2019-02-08 18:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/839dbe7ee75f8385d98c65aa33a375e268984ffe', 'message': 'Add east-west ingress network policy to Prometheus services\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 11, 'created': '2019-02-11 16:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/25b178129ff487ebf13a34f10f6c51ce74c7e2f8', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 12, 'created': '2019-02-11 17:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c223b75ba4b7c5c2bea5e36b2dab3e246fd8c47a', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 13, 'created': '2019-02-11 20:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cfd351ecc2084365e158436411e553ba628dde65', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 14, 'created': '2019-02-25 15:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7bdbb8f9bba3aa39d054986667cc5e2bf859e098', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 15, 'created': '2019-02-25 15:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bfc3802c4569e56fbaf8db34e1330c0d2ab31e04', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 16, 'created': '2019-02-25 15:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/442610b0f135a25734d89b6ce0d978934331c676', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 17, 'created': '2019-02-25 16:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/27d8fda39305755f3e92d20f9c4b763cb3f6ae5d', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 18, 'created': '2019-02-25 17:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6b8c0f87f3f55c6049f21345bdf0c701557c9b72', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 19, 'created': '2019-02-25 19:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4aea9aec53f4b3341c5bb589716668c2003802cd', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 20, 'created': '2019-02-26 16:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/43fefd341267ee3cadd3cac09b8d411bad44ce52', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}, {'number': 21, 'created': '2019-03-06 17:56:26.000000000', 'files': ['tools/deployment/network-policy/901-test-networkpolicy.sh', 'tools/deployment/network-policy/050-prometheus.sh', 'prometheus/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/243f6c76089ea81e72bbafc659767573b2f3c385', 'message': 'Add east-west ingress network policy to Prometheus\n\nThis adds an ingress policy to Prometheus and utilizes\nthe helm-toolkit used in openstack-helm\n\nChange-Id: Ia89d42a5305c94da26337aaf716978c1defae503\n'}]",1,635021,243f6c76089ea81e72bbafc659767573b2f3c385,60,5,21,28849,,,0,"Add east-west ingress network policy to Prometheus

This adds an ingress policy to Prometheus and utilizes
the helm-toolkit used in openstack-helm

Change-Id: Ia89d42a5305c94da26337aaf716978c1defae503
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/21/635021/21 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/network-policy/901-test-networkpolicy.sh', 'prometheus/values.yaml']",2,f51fd7ba49060af322c99fa11c018f28db12a013,Prometheus/ingress-network-policy,network_policy: prometheus: ingress: - from: - podSelector: matchLabels: application: prometheus - podSelector: matchLabels: application: elasticsearch-exporter - podSelector: matchLabels: application: elasticsearch - podSelector: matchLabels: application: grafana - podSelector: matchLabels: application: nagios - podSelector: matchLabels: application: ingress ports: - protocol: TCP port: 9093 - protocol: TCP port: 9090 - protocol: TCP port: 6783 - protocol: TCP port: 9108 - protocol: TCP port: 80 - protocol: TCP port: 443 network_policy: true, network_policy: false,43,1
openstack%2Fpython-ironicclient~master~I3b6fa53005f143d34f03bb1ed71c0aa04b7fce7b,openstack/python-ironicclient,master,I3b6fa53005f143d34f03bb1ed71c0aa04b7fce7b,Accept 'valid_interfaces' in client setup,MERGED,2019-03-06 17:14:56.000000000,2019-03-07 04:41:24.000000000,2019-03-07 04:41:24.000000000,"[{'_account_id': 10343}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-03-06 17:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e125e4a1e5035ec8ec5bc607973da89306ac6dc5', 'message': ""Accept 'valid_interfaces' in client setup\n\nThe consumer of ironicclient may be deriving their get_client kwargs\nfrom config inherited from ksa, where the 'interface' option has been\ndeprecated in favor of 'valid_interfaces'. To accomodate this, we accept\n'valid_interfaces' as a kwarg, giving it precedence over 'interface'.\nHowever, we still accept 'interface', as the consumer may be deriving\nkwargs from a non-conf source (such as an already-created ksa Adapter\nwhere 'valid_interfaces' has already been translated to 'interfaces'.\n\nCo-Authored-By: guang-yee <guang.yee@suse.com>\n\nChange-Id: I3b6fa53005f143d34f03bb1ed71c0aa04b7fce7b\n""}, {'number': 2, 'created': '2019-03-07 02:39:44.000000000', 'files': ['releasenotes/notes/accept-valid_interfaces-3b8f5e3e362e04cd.yaml', 'ironicclient/tests/unit/test_client.py', 'ironicclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/ae1743d2c194c690c4d4629e51e860b5f5b84252', 'message': ""Accept 'valid_interfaces' in client setup\n\nThe consumer of ironicclient may be deriving their get_client kwargs\nfrom config inherited from ksa, where the 'interface' option has been\ndeprecated in favor of 'valid_interfaces'. To accomodate this, we accept\n'valid_interfaces' as a kwarg, giving it precedence over 'interface'.\nHowever, we still accept 'interface', as the consumer may be deriving\nkwargs from a non-conf source (such as an already-created ksa Adapter\nwhere 'valid_interfaces' has already been translated to 'interfaces'.\n\nCo-Authored-By: guang-yee <guang.yee@suse.com>\n\nChange-Id: I3b6fa53005f143d34f03bb1ed71c0aa04b7fce7b\n""}]",0,641444,ae1743d2c194c690c4d4629e51e860b5f5b84252,10,4,2,14070,,,0,"Accept 'valid_interfaces' in client setup

The consumer of ironicclient may be deriving their get_client kwargs
from config inherited from ksa, where the 'interface' option has been
deprecated in favor of 'valid_interfaces'. To accomodate this, we accept
'valid_interfaces' as a kwarg, giving it precedence over 'interface'.
However, we still accept 'interface', as the consumer may be deriving
kwargs from a non-conf source (such as an already-created ksa Adapter
where 'valid_interfaces' has already been translated to 'interfaces'.

Co-Authored-By: guang-yee <guang.yee@suse.com>

Change-Id: I3b6fa53005f143d34f03bb1ed71c0aa04b7fce7b
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/44/641444/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/accept-valid_interfaces-3b8f5e3e362e04cd.yaml', 'ironicclient/tests/unit/test_client.py', 'ironicclient/client.py']",3,e125e4a1e5035ec8ec5bc607973da89306ac6dc5,story-2005118," # NOTE(gyee/efried): 'interface' in ksa config is deprecated in favor of # 'valid_interfaces'. So, since the caller may be deriving kwargs from # conf, accept 'valid_interfaces' first. But keep support for 'interface', # in case the caller is deriving kwargs from, say, an existing Adapter. interface = kwargs.get('valid_interfaces', kwargs.get('interface'))", # NOTE(gyee): we are supposed to be using valid_interfaces as interface # is deprecated. interface = kwargs.get('interface'),46,3
openstack%2Fopenstack-helm-infra~master~If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4,openstack/openstack-helm-infra,master,If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4,Add ingress network policy for Nagios,MERGED,2019-02-22 17:18:02.000000000,2019-03-07 04:36:14.000000000,2019-03-07 04:36:14.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 28849}]","[{'number': 1, 'created': '2019-02-22 17:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/df0e10b15f3e5b73cfa2f7188bca5a3f7e038e3e', 'message': 'Add ingress network policy for Nagios\n\nThis adds the ingress network policy to Nagios\nusing the helm-toolkit template\n\nChange-Id: If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4\n'}, {'number': 2, 'created': '2019-02-22 18:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ee0272b96da6a5ecc6b00f40f0f96c9e78519444', 'message': 'Add ingress network policy for Nagios\n\nThis adds the ingress network policy to Nagios\nusing the helm-toolkit template\n\nChange-Id: If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4\n'}, {'number': 3, 'created': '2019-02-25 15:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/becd3377fe9007c060c77f85c2dd97f9e9e05d34', 'message': 'Add ingress network policy for Nagios\n\nThis adds the ingress network policy to Nagios\nusing the helm-toolkit template\n\nChange-Id: If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4\n'}, {'number': 4, 'created': '2019-03-06 18:42:40.000000000', 'files': ['nagios/values.yaml', 'tools/deployment/network-policy/901-test-networkpolicy.sh', 'tools/deployment/network-policy/110-nagios.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/736af38c9c6cba6a80a33aa2e23ed21ee9e958fe', 'message': 'Add ingress network policy for Nagios\n\nThis adds the ingress network policy to Nagios\nusing the helm-toolkit template\n\nChange-Id: If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4\n'}]",0,638723,736af38c9c6cba6a80a33aa2e23ed21ee9e958fe,14,4,4,28849,,,0,"Add ingress network policy for Nagios

This adds the ingress network policy to Nagios
using the helm-toolkit template

Change-Id: If6cc66330b24c3f79f9b5c29a94ea904d1eb37d4
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/23/638723/1 && git format-patch -1 --stdout FETCH_HEAD,"['nagios/values.yaml', 'tools/deployment/network-policy/901-test-networkpolicy.sh', 'tools/deployment/network-policy/110-nagios.sh']",3,df0e10b15f3e5b73cfa2f7188bca5a3f7e038e3e,nagios/ingress-network-policy, --namespace=osh-infra,tee /tmp/nagios.yaml <<EOF manifests: network_policy: true network_policy: nagios: ingress: - from: - podSelector: matchLabels: application: nagios ports: - protocol: TCP port: 8000 - protocol: TCP port: 80 EOF --namespace=osh-infra \ --values=/tmp/nagios.yaml,25,24
openstack%2Fopenstack-helm~master~Idd883d4348a292c0de54c7ee47da98f11f36306f,openstack/openstack-helm,master,Idd883d4348a292c0de54c7ee47da98f11f36306f,Support rbd pool replication and crush ruleset for glance,MERGED,2019-02-04 19:56:00.000000000,2019-03-07 04:35:52.000000000,2019-03-07 04:35:52.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28208}, {'_account_id': 28883}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-02-04 19:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cd3ef62cb3f009408d2d81a4b07d386a3b70d0b4', 'message': 'Support rbd pool replication for glance\n\n- pass new pool replication parameter to the storage init script\n- set images pool replication in the storage init script\n\nChange-Id: Idd883d4348a292c0de54c7ee47da98f11f36306f\nStory: 2004921\nTask: 29282\nSigned-off-by: Irina Mihai <irina.mihai@windriver.com>\n'}, {'number': 2, 'created': '2019-02-22 14:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/992d3356dd1685a25d6ff589c1a0a4cbf5e0d085', 'message': 'Support rbd pool replication for glance\n\n- pass new pool replication parameter to the storage init script\n- set images pool replication in the storage init script\n\nChange-Id: Idd883d4348a292c0de54c7ee47da98f11f36306f\nStory: 2004921\nTask: 29282\nSigned-off-by: Irina Mihai <irina.mihai@windriver.com>\n'}, {'number': 3, 'created': '2019-02-27 22:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0f5d5d29c2ce415ebac80ce27019bba35dfd4123', 'message': 'Support rbd pool replication and crush ruleset for glance\n\n- pass new pool replication&crush ruleset parameter to the\n  storage init script\n- set images pool replication&crush ruleset in the storage init script\n\nChange-Id: Idd883d4348a292c0de54c7ee47da98f11f36306f\nStory: 2004921\nTask: 29282\nSigned-off-by: Irina Mihai <irina.mihai@windriver.com>\n'}, {'number': 4, 'created': '2019-02-28 15:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/97fc1a10724788223d35c613163465f47d069067', 'message': 'Support rbd pool replication and crush ruleset for glance\n\n- pass new pool replication&crush ruleset parameter to the\n  storage init script\n- set images pool replication&crush ruleset in the storage init script\n\nChange-Id: Idd883d4348a292c0de54c7ee47da98f11f36306f\nStory: 2004921\nTask: 29282\nSigned-off-by: Irina Mihai <irina.mihai@windriver.com>\n'}, {'number': 5, 'created': '2019-03-06 06:58:46.000000000', 'files': ['glance/templates/bin/_storage-init.sh.tpl', 'glance/templates/job-storage-init.yaml', 'glance/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/92b54f8352de062eff59b9407f866ae5b95621b0', 'message': 'Support rbd pool replication and crush ruleset for glance\n\n- pass new pool replication&crush ruleset parameter to the\n  storage init script\n- set images pool replication&crush ruleset in the storage init script\n\nChange-Id: Idd883d4348a292c0de54c7ee47da98f11f36306f\nStory: 2004921\nTask: 29282\nSigned-off-by: Irina Mihai <irina.mihai@windriver.com>\n'}]",5,634791,92b54f8352de062eff59b9407f866ae5b95621b0,26,7,5,28883,,,0,"Support rbd pool replication and crush ruleset for glance

- pass new pool replication&crush ruleset parameter to the
  storage init script
- set images pool replication&crush ruleset in the storage init script

Change-Id: Idd883d4348a292c0de54c7ee47da98f11f36306f
Story: 2004921
Task: 29282
Signed-off-by: Irina Mihai <irina.mihai@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/91/634791/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/templates/bin/_storage-init.sh.tpl', 'glance/templates/job-storage-init.yaml', 'glance/values.yaml']",3,cd3ef62cb3f009408d2d81a4b07d386a3b70d0b4,, rbd_store_replication: 1,,4,0
openstack%2Fopenstack-helm~master~I31263e9ce06d31773e961ae5d1252e062a38a4e5,openstack/openstack-helm,master,I31263e9ce06d31773e961ae5d1252e062a38a4e5,Add resource_filters.json to Cinder's configmap,MERGED,2019-03-05 01:38:57.000000000,2019-03-07 04:35:50.000000000,2019-03-07 04:35:50.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28459}]","[{'number': 1, 'created': '2019-03-05 01:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2864d0e6e46fed8fa825ce1ce090b1c37117eebb', 'message': ""Add resource_filters.json to Cinder's configmap\n\nDuring the Stein development cycle, Cinder removed the deprecated\nquery_volume_filters configuration option with\nIcd311db7f88c3c274d9a362eb96519e46c7e4d17.\n\nThis chart update will add resource_filters.json to the configmap and\nprovides the default values for the filter keys to enable filtering in\nthe list APIs.\n\nChange-Id: I31263e9ce06d31773e961ae5d1252e062a38a4e5\nSigned-off-by: Robert Church <robert.church@windriver.com>\n""}, {'number': 2, 'created': '2019-03-05 07:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/511d5f361679a43b69a2d57d4557b4f32f09a1a9', 'message': ""Add resource_filters.json to Cinder's configmap\n\nDuring the Stein development cycle, Cinder removed the deprecated\nquery_volume_filters configuration option with\nIcd311db7f88c3c274d9a362eb96519e46c7e4d17.\n\nThis chart update will add resource_filters.json to the configmap and\nprovides the default values for the filter keys to enable filtering in\nthe list APIs.\n\nChange-Id: I31263e9ce06d31773e961ae5d1252e062a38a4e5\nSigned-off-by: Robert Church <robert.church@windriver.com>\n""}, {'number': 3, 'created': '2019-03-06 04:34:53.000000000', 'files': ['cinder/templates/configmap-etc.yaml', 'cinder/values.yaml', 'cinder/templates/deployment-api.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d1fbf4ac145ae6a658123516b9f3ae1be598059e', 'message': ""Add resource_filters.json to Cinder's configmap\n\nDuring the Stein development cycle, Cinder removed the deprecated\nquery_volume_filters configuration option with\nIcd311db7f88c3c274d9a362eb96519e46c7e4d17.\n\nThis chart update will add resource_filters.json to the configmap and\nprovides the default values for the filter keys to enable filtering in\nthe list APIs.\n\nChange-Id: I31263e9ce06d31773e961ae5d1252e062a38a4e5\nSigned-off-by: Robert Church <robert.church@windriver.com>\n""}]",0,640915,d1fbf4ac145ae6a658123516b9f3ae1be598059e,14,4,3,28459,,,0,"Add resource_filters.json to Cinder's configmap

During the Stein development cycle, Cinder removed the deprecated
query_volume_filters configuration option with
Icd311db7f88c3c274d9a362eb96519e46c7e4d17.

This chart update will add resource_filters.json to the configmap and
provides the default values for the filter keys to enable filtering in
the list APIs.

Change-Id: I31263e9ce06d31773e961ae5d1252e062a38a4e5
Signed-off-by: Robert Church <robert.church@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/15/640915/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/templates/configmap-etc.yaml', 'cinder/values.yaml', 'cinder/templates/deployment-api.yaml']",3,2864d0e6e46fed8fa825ce1ce090b1c37117eebb,cinder_stein_changes, - name: cinder-etc mountPath: /etc/cinder/resource_filters.json subPath: resource_filters.json readOnly: true,,43,0
openstack%2Foctavia-dashboard~master~If698df8e5cea1b527477b9f546afd52bd37d8989,openstack/octavia-dashboard,master,If698df8e5cea1b527477b9f546afd52bd37d8989,Add load balancer flavor support,MERGED,2019-02-21 08:55:01.000000000,2019-03-07 04:32:39.000000000,2019-03-07 04:32:39.000000000,"[{'_account_id': 2245}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-21 08:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/69633e10dfa9ac2985ee49d7190fd324744e26b4', 'message': 'WIP: Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}, {'number': 2, 'created': '2019-02-22 07:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/16eebc89341fdf58cd5ff1b06b76ebca0c18963a', 'message': 'WIP: Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}, {'number': 3, 'created': '2019-02-26 06:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/7c465ec0390d32b7341d0c39fa3194c6520bf12c', 'message': 'WIP: Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}, {'number': 4, 'created': '2019-02-26 15:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/9a4cad64406a0dce060a070d2503e250bfea0c06', 'message': 'WIP: Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}, {'number': 5, 'created': '2019-02-28 05:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/2d8c99234c6e698305249b8ac79bf878cb973963', 'message': 'WIP: Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}, {'number': 6, 'created': '2019-02-28 06:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/17ddadad9da7c2806f449cecde6c245f7dd1578c', 'message': 'Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}, {'number': 7, 'created': '2019-03-06 21:56:05.000000000', 'files': ['octavia_dashboard/static/app/core/openstack-service-api/lbaasv2.service.js', 'octavia_dashboard/static/dashboard/project/lbaasv2/loadbalancers/loadbalancers.module.js', 'octavia_dashboard/static/app/core/openstack-service-api/lbaasv2.service.spec.js', 'octavia_dashboard/static/dashboard/project/lbaasv2/loadbalancers/details/detail.html', 'lower-constraints.txt', 'octavia_dashboard/static/dashboard/project/lbaasv2/workflow/model.service.spec.js', 'octavia_dashboard/static/dashboard/project/lbaasv2/workflow/model.service.js', 'octavia_dashboard/static/dashboard/project/lbaasv2/loadbalancers/details/drawer.html', 'octavia_dashboard/static/dashboard/project/lbaasv2/workflow/loadbalancer/loadbalancer.html', 'requirements.txt', 'octavia_dashboard/api/rest/lbaasv2.py', 'octavia_dashboard/static/dashboard/project/lbaasv2/workflow/loadbalancer/loadbalancer.controller.spec.js', 'releasenotes/notes/flavor-support-0195a486faa16b7f.yaml', 'octavia_dashboard/static/dashboard/project/lbaasv2/workflow/loadbalancer/loadbalancer.controller.js'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/38e835ceea39849a0789fc4f49cfd8aacf75527b', 'message': 'Add load balancer flavor support\n\nChange-Id: If698df8e5cea1b527477b9f546afd52bd37d8989\nDepends-On: https://review.openstack.org/634532\n'}]",0,638365,38e835ceea39849a0789fc4f49cfd8aacf75527b,25,4,7,2245,,,0,"Add load balancer flavor support

Change-Id: If698df8e5cea1b527477b9f546afd52bd37d8989
Depends-On: https://review.openstack.org/634532
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/65/638365/5 && git format-patch -1 --stdout FETCH_HEAD,['octavia_dashboard/api/rest/lbaasv2.py'],1,69633e10dfa9ac2985ee49d7190fd324744e26b4,flavor,"def create_flavor(request, **kwargs): """"""Create a new flavor. """""" data = request.DATA conn = _get_sdk_connection(request) flavor = conn.load_balancer.create_flavor( name=data['flavor']['name'], flavor_profile_id=data['flavor']['flavor_profile_id'], description=data['flavor'].get('description'), enabled=data['flavor'].get('enabled'), ) return _get_sdk_object_dict(flavor) def create_flavor_profile(request, **kwargs): """"""Create a new flavor profile. """""" data = request.DATA conn = _get_sdk_connection(request) flavor_profile = conn.load_balancer.create_flavor( name=data['flavor_profile']['name'], provider_name=data['flavor_profile']['provider_name'], flavor_data=data['flavor_profile']['flavor_data'], ) return _get_sdk_object_dict(flavor_profile) def update_flavor(request, **kwargs): """"""Update a flavor. """""" data = request.DATA flavor_id = data['flavor']['id'] conn = _get_sdk_connection(request) flavor = conn.load_balancer.update_flavor( flavor_id, name=data['flavor'].get('name'), description=data['flavor'].get('description'), enabled=data['flavor'].get('enabled'), ) return _get_sdk_object_dict(flavor) def update_flavor_profile(request, **kwargs): """"""Update a flavor profile. """""" data = request.DATA flavor_profile_id = data['flavor_profile']['id'] conn = _get_sdk_connection(request) flavor_profile = conn.load_balancer.update_flavor_profile( flavor_profile_id, name=data['flavor_profile'].get('name'), provider_name=data['flavor_profile'].get('provider_name'), flavor_data=data['flavor_profile'].get('flavor_data'), ) return _get_sdk_object_dict(flavor_profile) @urls.register class Flavors(generic.View): """"""API for load balancer flavors. """""" url_regex = r'lbaas/flavors/$' @rest_utils.ajax() def get(self, request): """"""List of flavors for the current project. The listing result is an object with property ""items"". """""" conn = _get_sdk_connection(request) flavor_list = _sdk_object_to_list( conn.load_balancer.flavors( project_id=request.user.project_id ) ) return {'items': flavor_list} @rest_utils.ajax() def post(self, request): """"""Create a new flavor. """""" kwargs = { 'flavor': request.DATA.get('flavor') } return create_flavor(request, **kwargs) @urls.register class Flavor(generic.View): """"""API for retrieving a single flavor. """""" url_regex = r'lbaas/flavors/(?P<flavor_id>[^/]+)/$' @rest_utils.ajax() def get(self, request, flavor_id): """"""Get a specific flavor. """""" conn = _get_sdk_connection(request) flavor = conn.load_balancer.find_flavor(flavor_id) return _get_sdk_object_dict(flavor) @rest_utils.ajax() def delete(self, request, flavor_id): """"""Delete a specific flavor. http://localhost/api/lbaas/flavors/3971d368-ca9b-4770-929a-3adca5bf89eb """""" conn = _get_sdk_connection(request) conn.load_balancer.delete_flavor(flavor_id, ignore_missing=True) @rest_utils.ajax() def put(self, request, flavor_id): """"""Edit a flavor. """""" update_flavor(request) @urls.register class FlavorProfiles(generic.View): """"""API for load balancer flavor profiles. """""" url_regex = r'lbaas/flavorprofiles/$' @rest_utils.ajax() def get(self, request): """"""List of flavor profiles for the current project. The listing result is an object with property ""items"". """""" conn = _get_sdk_connection(request) flavor_profile_list = _sdk_object_to_list( conn.load_balancer.flavor_profiles( project_id=request.user.project_id ) ) return {'items': flavor_profile_list} @rest_utils.ajax() def post(self, request): """"""Create a new flavor_profile. """""" kwargs = { 'flavor_profile': request.DATA.get('flavor_profile') } return create_flavor_profile(request, **kwargs) @urls.register class FlavorProfile(generic.View): """"""API for retrieving a single flavor profile. """""" url_regex = r'lbaas/flavorprofiles/(?P<flavor_profile_id>[^/]+)/$' @rest_utils.ajax() def get(self, request, flavor_profile_id): """"""Get a specific flavor profile. """""" conn = _get_sdk_connection(request) flavor_profile = conn.load_balancer.find_flavor_profile( flavor_profile_id) return _get_sdk_object_dict(flavor_profile) @rest_utils.ajax() def delete(self, request, flavor_profile_id): """"""Delete a specific flavor profile. http://localhost/api/lbaas/flavorprofiles/e8150eab-aefa-42cc-867e-3fb336da52bd """""" conn = _get_sdk_connection(request) conn.load_balancer.delete_flavor_profile(flavor_profile_id, ignore_missing=True) @rest_utils.ajax() def put(self, request, flavor_profile_id): """"""Edit a flavor profile. """""" update_flavor_profile(request)",,204,0
openstack%2Fnova~master~I528794b4b6f0007efc1238ad28dc402456664f86,openstack/nova,master,I528794b4b6f0007efc1238ad28dc402456664f86,Fix WeighedHost logging regression,MERGED,2019-03-05 22:18:49.000000000,2019-03-07 04:17:20.000000000,2019-03-06 12:25:50.000000000,"[{'_account_id': 935}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20634}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 27970}]","[{'number': 1, 'created': '2019-03-05 22:18:49.000000000', 'files': ['nova/scheduler/filter_scheduler.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/84533f5eb3c5b4ab7598d7c278b53524acc1c6e0', 'message': 'Fix WeighedHost logging regression\n\nChange I8666e0af3f057314f6b06939a108411b8a88d64b in Pike\nrefactored some code in the FilterScheduler which accidentally\nchanged how the list of weighed hosts are logged, which caused\nthe wrapped HostState objects to be logged rather than the\nWeighedHost objects, which contain the actual ""weight"" attribute\nwhich is useful for debugging weigher configuration and\nscheduling decisions.\n\nThis fixes the regression by logging the weighed hosts before\nstripping off the WeighedHost wrapper and adds a simple wrinkle\nto an existing test to assert we are logging the correct object.\n\nChange-Id: I528794b4b6f0007efc1238ad28dc402456664f86\nCloses-Bug: #1816360\n'}]",0,641143,84533f5eb3c5b4ab7598d7c278b53524acc1c6e0,22,14,1,6873,,,0,"Fix WeighedHost logging regression

Change I8666e0af3f057314f6b06939a108411b8a88d64b in Pike
refactored some code in the FilterScheduler which accidentally
changed how the list of weighed hosts are logged, which caused
the wrapped HostState objects to be logged rather than the
WeighedHost objects, which contain the actual ""weight"" attribute
which is useful for debugging weigher configuration and
scheduling decisions.

This fixes the regression by logging the weighed hosts before
stripping off the WeighedHost wrapper and adds a simple wrinkle
to an existing test to assert we are logging the correct object.

Change-Id: I528794b4b6f0007efc1238ad28dc402456664f86
Closes-Bug: #1816360
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/641143/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filter_scheduler.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py']",2,84533f5eb3c5b4ab7598d7c278b53524acc1c6e0,bug/1816360," @mock.patch('nova.scheduler.filter_scheduler.LOG.debug') def test_get_sorted_hosts(self, mock_filt, mock_weighed, mock_rand, debug): # Make sure that when logging the weighed hosts we are logging them # with the WeighedHost wrapper class rather than the HostState objects. def fake_debug(message, *args, **kwargs): if message.startswith('Weighed'): self.assertEqual(1, len(args)) for weighed_host in args[0]['hosts']: self.assertIsInstance(weighed_host, weights.WeighedHost) debug.side_effect = fake_debug debug.assert_called()"," def test_get_sorted_hosts(self, mock_filt, mock_weighed, mock_rand):",15,3
openstack%2Frequirements~master~Ib52b7b35aa64717de3489d4597bed1b2936429e1,openstack/requirements,master,Ib52b7b35aa64717de3489d4597bed1b2936429e1,Add Hashicorp Vault Python Client (hvac),MERGED,2019-02-27 19:28:20.000000000,2019-03-07 04:15:19.000000000,2019-03-07 04:15:19.000000000,"[{'_account_id': 7973}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2019-02-27 19:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/bd8f25fd77fdc696d6dd579beaeadf9cd5a8f141', 'message': 'Add Hashicorp Vault Python Client (hvac)\n\nThis library will be used in Castellan to enhance the Hashicorp\nVault backend.\n\nChange-Id: Ib52b7b35aa64717de3489d4597bed1b2936429e1\n'}, {'number': 2, 'created': '2019-03-04 03:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2b116a758396c51801c25d942e055180bfbc8bad', 'message': 'Add Hashicorp Vault Python Client (hvac)\n\nThis library will be used in Castellan to enhance the Hashicorp\nVault backend.\n\n[Q] Is the library actively maintained?\n[A]\n\n[Q] Is the library good code?\n[A]\n\n[Q] Is the library python 3 compatible?\n[A]\n\n[Q] Is the library license compatible?\n[A]\n\n[Q] Is the library already packaged in the distros we target (Ubuntu\n    latest / Fedora latest)?\n[A]\n\n[Q] Is the function of this library already covered by other libraries\n    in global-requirements.txt?\n[A]\n\n[Q] Is the library required for OpenStack project or related dev or\n    infrastructure setup? (Answer to this should be Yes, of course) Which?\n[A]\n\n[Q] If the library release is managed by the Openstack release process\n    does it use the cycle-with-intermediary release type?\n[A] N/A\n\nChange-Id: Ib52b7b35aa64717de3489d4597bed1b2936429e1\n'}, {'number': 3, 'created': '2019-03-04 13:22:42.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/be6cd3526ed32c4e07445583221e13b0aff4f7ff', 'message': 'Add Hashicorp Vault Python Client (hvac)\n\nThis library will be used in Castellan to enhance the Hashicorp\nVault backend.\n\n[Q] Is the library actively maintained?\n[A] They had 4 releases in the last 6 months.\n\n[Q] Is the library good code?\n[A] They have code coverage > 90% with around 600 unit tests;\n[A] They use Travis as CI;\n[A] They have over 500 commits, 30 releases and 60 contributors.\n\n[Q] Is the library python 3 compatible?\n[A] Yes, their travis runs against python 3.6\n\n[Q] Is the library license compatible?\n[A] hvac   # Apache-2.0\n[A] pyhcl  # Mozilla-2.0\n[A] ply    # BSD\n\n[Q] Is the library already packaged in the distros we target (Ubuntu\n    latest / Fedora latest)?\n[A] The library distributed through PyPI.\n\n[Q] Is the function of this library already covered by other libraries\n    in global-requirements.txt?\n[A] No, this functionality is only provided by hvac or async-hvac.\n\n[Q] Is the library required for OpenStack project or related dev or\n    infrastructure setup? (Answer to this should be Yes, of course) Which?\n[A] OpenStack project: Olso/Castellan.\n\n[Q] If the library release is managed by the Openstack release process\n    does it use the cycle-with-intermediary release type?\n[A] N/A\n\nChange-Id: Ib52b7b35aa64717de3489d4597bed1b2936429e1\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n'}]",0,639788,be6cd3526ed32c4e07445583221e13b0aff4f7ff,23,6,3,7973,,,0,"Add Hashicorp Vault Python Client (hvac)

This library will be used in Castellan to enhance the Hashicorp
Vault backend.

[Q] Is the library actively maintained?
[A] They had 4 releases in the last 6 months.

[Q] Is the library good code?
[A] They have code coverage > 90% with around 600 unit tests;
[A] They use Travis as CI;
[A] They have over 500 commits, 30 releases and 60 contributors.

[Q] Is the library python 3 compatible?
[A] Yes, their travis runs against python 3.6

[Q] Is the library license compatible?
[A] hvac   # Apache-2.0
[A] pyhcl  # Mozilla-2.0
[A] ply    # BSD

[Q] Is the library already packaged in the distros we target (Ubuntu
    latest / Fedora latest)?
[A] The library distributed through PyPI.

[Q] Is the function of this library already covered by other libraries
    in global-requirements.txt?
[A] No, this functionality is only provided by hvac or async-hvac.

[Q] Is the library required for OpenStack project or related dev or
    infrastructure setup? (Answer to this should be Yes, of course) Which?
[A] OpenStack project: Olso/Castellan.

[Q] If the library release is managed by the Openstack release process
    does it use the cycle-with-intermediary release type?
[A] N/A

Change-Id: Ib52b7b35aa64717de3489d4597bed1b2936429e1
Signed-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/88/639788/3 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,bd8f25fd77fdc696d6dd579beaeadf9cd5a8f141,Ib52b7b35aa64717de3489d4597bed1b2936429e1,hvac===0.7.2,,2,0
openstack%2Fopenstack-helm-images~master~I79a30cfb56b3c4c6dfbed057c1cca0d1b6544117,openstack/openstack-helm-images,master,I79a30cfb56b3c4c6dfbed057c1cca0d1b6544117,Do not pass the project name to bindep profiles,MERGED,2019-03-06 10:25:39.000000000,2019-03-07 04:15:18.000000000,2019-03-07 04:15:18.000000000,"[{'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-03-06 10:25:39.000000000', 'files': ['openstack/loci/build.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/cb6fc47ac50fb28f7290599759b506a2d55b12af', 'message': 'Do not pass the project name to bindep profiles\n\nLoci adds the project name automatically.\n\nChange-Id: I79a30cfb56b3c4c6dfbed057c1cca0d1b6544117\n'}]",0,641302,cb6fc47ac50fb28f7290599759b506a2d55b12af,12,5,1,9963,,,0,"Do not pass the project name to bindep profiles

Loci adds the project name automatically.

Change-Id: I79a30cfb56b3c4c6dfbed057c1cca0d1b6544117
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/02/641302/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/loci/build.sh'],1,cb6fc47ac50fb28f7290599759b506a2d55b12af,osh_suse_glance,"glance_profiles=${glance_profiles:-""'fluent ceph'""}cinder_profiles=${cinder_profiles:-""'fluent lvm ceph qemu'""}neutron_profiles=${neutron_profiles:-""'fluent linuxbridge openvswitch'""}nova_profiles=${nova_profiles:-""'fluent ceph linuxbridge openvswitch configdrive qemu apache'""}horizon_profiles=${horizon_profiles:-""'fluent apache'""}senlin_profiles=${senlin_profiles:-""fluent""}congress_profiles=${congress_profiles:-""fluent""}magnum_profiles=${magnum_profiles:-""fluent""}ironic_profiles=${ironic_profiles:-""'fluent ipxe ipmi qemu tftp'""}","glance_profiles=${glance_profiles:-""'fluent glance ceph'""}cinder_profiles=${cinder_profiles:-""'fluent cinder lvm ceph qemu'""}neutron_profiles=${neutron_profiles:-""'fluent neutron linuxbridge openvswitch'""}nova_profiles=${nova_profiles:-""'fluent nova ceph linuxbridge openvswitch configdrive qemu apache'""}horizon_profiles=${horizon_profiles:-""'fluent horizon apache'""}senlin_profiles=${senlin_profiles:-""'fluent senlin'""}congress_profiles=${congress_profiles:-""'fluent congress'""}magnum_profiles=${magnum_profiles:-""'fluent magnum'""}ironic_profiles=${ironic_profiles:-""'fluent ironic ipxe ipmi qemu tftp'""}",9,9
openstack%2Fpython-masakariclient~master~I02a48f2a3a14ed5588ad64ecaed0b35de7ea0b3e,openstack/python-masakariclient,master,I02a48f2a3a14ed5588ad64ecaed0b35de7ea0b3e,Deprecate masakari CLI,MERGED,2019-03-07 02:58:37.000000000,2019-03-07 04:11:49.000000000,2019-03-07 04:11:49.000000000,"[{'_account_id': 1011}, {'_account_id': 12950}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-07 02:58:37.000000000', 'files': ['masakariclient/shell.py', 'releasenotes/notes/deprecate-cli-9ffee25a5c3d1b3b.yaml'], 'web_link': 'https://opendev.org/openstack/python-masakariclient/commit/2da44c7b1ffd37d33595cb9726b63e7f6ca69e82', 'message': ""Deprecate masakari CLI\n\nAll Masakari supported APIs are now available in OSC so it's time to\ndeprecate python-masakariclient.\n\nThis point was discussed during Stein PTG [1] and\nmasakari weekly IRC meeting.\n\n[1]: https://etherpad.openstack.org/p/masakari-ptg-stein\n\nChange-Id: I02a48f2a3a14ed5588ad64ecaed0b35de7ea0b3e\n""}]",0,641544,2da44c7b1ffd37d33595cb9726b63e7f6ca69e82,7,3,1,20182,,,0,"Deprecate masakari CLI

All Masakari supported APIs are now available in OSC so it's time to
deprecate python-masakariclient.

This point was discussed during Stein PTG [1] and
masakari weekly IRC meeting.

[1]: https://etherpad.openstack.org/p/masakari-ptg-stein

Change-Id: I02a48f2a3a14ed5588ad64ecaed0b35de7ea0b3e
",git fetch https://review.opendev.org/openstack/python-masakariclient refs/changes/44/641544/1 && git format-patch -1 --stdout FETCH_HEAD,"['masakariclient/shell.py', 'releasenotes/notes/deprecate-cli-9ffee25a5c3d1b3b.yaml']",2,2da44c7b1ffd37d33595cb9726b63e7f6ca69e82,deprecate_masakari_command_lines,--- deprecations: - | The masakari CLI is now deprecated. This is the signal that it is time to start using the openstack CLI. No new features will be added to the masakari CLI. ,,11,0
openstack%2Fmagnum~master~I6c7a48b0a735b1fa34914cddfc19c303fff0f073,openstack/magnum,master,I6c7a48b0a735b1fa34914cddfc19c303fff0f073,[Docs] Fix some styles issue of user guide,ABANDONED,2018-08-20 09:48:54.000000000,2019-03-07 04:02:31.000000000,,"[{'_account_id': 13861}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-20 09:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c83a9d1f07963e8b6b87336a325614a9295ce3f2', 'message': ""[Docs] Fix issue of some styles\n\nAdd a pair of '*' for some definitions.\n\nChange-Id: I6c7a48b0a735b1fa34914cddfc19c303fff0f073\nStory: 2003489\nTask: 24764\n""}, {'number': 2, 'created': '2018-08-24 09:09:54.000000000', 'files': ['doc/source/user/index.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9e97cb207d0afdd787902b9c0c42f86788bdfb99', 'message': ""[Docs] Fix some styles issue of user guide\n\nAdd a pair of '*' for some definitions.\n\nChange-Id: I6c7a48b0a735b1fa34914cddfc19c303fff0f073\nStory: 2003489\nTask: 24764\n""}]",0,593564,9e97cb207d0afdd787902b9c0c42f86788bdfb99,5,3,2,28706,,,0,"[Docs] Fix some styles issue of user guide

Add a pair of '*' for some definitions.

Change-Id: I6c7a48b0a735b1fa34914cddfc19c303fff0f073
Story: 2003489
Task: 24764
",git fetch https://review.opendev.org/openstack/magnum refs/changes/64/593564/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/index.rst'],1,c83a9d1f07963e8b6b87336a325614a9295ce3f2,story/2003489,"*<name>**--coe <coe>**--image <image>**--keypair <keypair>**--external-network <external-network>**--public**--server-type <server-type>**--network-driver <network-driver>**--volume-driver <volume-driver>**--dns-nameserver <dns-nameserver>**--flavor <flavor>**--master-flavor <master-flavor>**--http-proxy <http-proxy>**--https-proxy <https-proxy>**--no-proxy <no-proxy>**--docker-volume-size <docker-volume-size>**--docker-storage-driver <docker-storage-driver>**--labels <KEY1=VALUE1,KEY2=VALUE2,KEY3=VALUE3...>**--tls-disabled**--registry-enabled**--master-lb-enabled**Servers**Identity**Network**Storage**Security**<name>**--cluster-template <cluster-template>**--keypair <keypair>**--node-count <node-count>**--master-count <master-count>**--discovery-url <discovery-url>**--timeout <timeout>**<cluster>**<op>**<attribute=value>*+------------+-------------------+ | COE | distro | +============+===================+ | Kubernetes | Fedora Atomic | +------------+-------------------+ | Kubernetes | CoreOS | +------------+-------------------+ | Swarm | Fedora Atomic | +------------+-------------------+ | Mesos | Ubuntu | +------------+-------------------+*driver.py**templates**template_def.py**version.py**image**api.py**monitor.py**scale.py**COE level**Container level**Number of masters (master-count)**Number of nodes (node-count)**Network driver (network-driver)**Volume driver (volume-driver)**Storage driver (docker-storage-driver)**Image (image)**TLS (tls-disabled)**What runs on the servers**Log into the servers**What runs on the servers**Number of managers (master-count)**Number of nodes (node-count)**Network driver (network-driver)**Volume driver (volume-driver)**Storage driver (docker-storage-driver)**Image (image)**TLS (tls-disabled)**Log into the servers**What runs on the servers**Number of master (master-count)**Number of agents (node-count)**Network driver (network-driver)**Volume driver (volume-driver)**Storage driver (docker-storage-driver)**Image (image)**TLS (tls-disabled)**Log into the servers*+------------+-----------------+ | COE | TLS support | +============+=================+ | Kubernetes | yes | +------------+-----------------+ | Swarm | yes | +------------+-----------------+ | Mesos | no | +------------+-----------------+*--dir <dirname>**--force**Client Key**Signed Certificate**Certificate Authority**Rotate Certificate**Barbican**Magnum database**Local store**external-network**fixed-network**dns-nameserver**http-proxy, https-proxy, no-proxy**network-driver**Kubernetes**Swarm**Mesos*","\<name\>--coe \<coe\>--image \<image\>--keypair \<keypair\>--external-network \<external-network\>--public--server-type \<server-type\>--network-driver \<network-driver\>--volume-driver \<volume-driver\>--dns-nameserver \<dns-nameserver\>--flavor \<flavor\>--master-flavor \<master-flavor\>--http-proxy \<http-proxy\>--https-proxy \<https-proxy\>--no-proxy \<no-proxy\>--docker-volume-size \<docker-volume-size\>--docker-storage-driver \<docker-storage-driver\>--labels \<KEY1=VALUE1,KEY2=VALUE2;KEY3=VALUE3...\>--tls-disabled--registry-enabled--master-lb-enabledServersIdentityNetworkStorageSecurity\<name\>--cluster-template \<cluster-template\>--keypair \<keypair\>--node-count \<node-count\>--master-count \<master-count\>--discovery-url \<discovery-url\>--timeout \<timeout\>\<cluster\>\<op\>\<attribute=value\>+------------+---------------+ | COE | distro | +============+===============+ | Kubernetes | Fedora Atomic | +------------+---------------+ | Kubernetes | CoreOS | +------------+---------------+ | Swarm | Fedora Atomic | +------------+---------------+ | Mesos | Ubuntu | +------------+---------------+driver.pytemplatestemplate_def.pyversion.pyimageapi.pymonitor.pyscale.pyCOE levelContainer levelNumber of masters (master-count)Number of nodes (node-count)Network driver (network-driver)Volume driver (volume-driver)Storage driver (docker-storage-driver)Image (image)TLS (tls-disabled)What runs on the serversLog into the serversWhat runs on the serversNumber of managers (master-count)Number of nodes (node-count)Network driver (network-driver)Volume driver (volume-driver)Storage driver (docker-storage-driver)Image (image)TLS (tls-disabled)Log into the serversWhat runs on the serversNumber of master (master-count)Number of agents (node-count)Network driver (network-driver)Volume driver (volume-driver)Storage driver (docker-storage-driver)Image (image)TLS (tls-disabled)Log into the servers+------------+-------------+ | COE | TLS support | +============+=============+ | Kubernetes | yes | +------------+-------------+ | Swarm | yes | +------------+-------------+ | Mesos | no | +------------+-------------+--dir \<dirname\>--forceClient KeySigned CertificateCertificate AuthorityRotate Certificate1. Barbican:2. Magnum database:3. Local store:external-networkfixed-networkdns-nameserverhttp-proxy, https-proxy, no-proxynetwork-driverKubernetesSwarmMesos",110,110
openstack%2Fcyborg~master~I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8,openstack/cyborg,master,I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8,Fix:add python-glanceclient to cyborg requirements,MERGED,2019-02-27 03:46:30.000000000,2019-03-07 03:33:40.000000000,2019-03-07 03:33:40.000000000,"[{'_account_id': 13629}, {'_account_id': 17813}, {'_account_id': 19316}, {'_account_id': 20722}, {'_account_id': 22348}, {'_account_id': 27458}, {'_account_id': 29344}, {'_account_id': 29745}]","[{'number': 1, 'created': '2019-02-27 03:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f6898342680679a1871c4530c98e0ad2693f513e', 'message': 'Fix:add python-glanceclient for cyborg\n\nChange-Id: I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8\nStory: 2005097\nTask: 29710\n'}, {'number': 2, 'created': '2019-02-27 03:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/2371ec02e377355f6a4bb9b99a57d35625c46630', 'message': 'Fix:add python-glanceclient for cyborg\n\nBecause in cyborg/image/glance.py line 33 hava ""import glanceclient""\nbut requirements.txt not have pyhton-glanceclient\n\nChange-Id: I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8\nStory: 2005097\nTask: 29710\n'}, {'number': 3, 'created': '2019-02-27 03:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/a9caead340c9ec2943d4bfdbae56008ac5c966f6', 'message': 'Fix:add python-glanceclient for cyborg\n\nBecause in cyborg/image/glance.py line 33 hava ""import glanceclient""\nbut requirements.txt not have pyhton-glanceclient\n\nChange-Id: I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8\nStory: 2005097\nTask: 29710\n'}, {'number': 4, 'created': '2019-02-27 04:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/d05b07af4a6b0359124e4afb0a340c8acdbdb2cf', 'message': 'Fix:add python-glanceclient for cyborg\n\nBecause in cyborg/image/glance.py line 33 hava ""import glanceclient""\nbut requirements.txt not have pyhton-glanceclient\n\nChange-Id: I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8\nStory: 2005097\nTask: 29710\n'}, {'number': 5, 'created': '2019-02-27 09:31:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/4bb248b260b5a072f3f9ee8ea3c5b683af8d1124', 'message': 'Fix:add python-glanceclient to cyborg requirements\n\nBecause in cyborg/image/glance.py line 33 hava ""import glanceclient""\nbut requirements.txt not have python-glanceclient\n\nChange-Id: I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8\nStory: 2005097\nTask: 29710\n'}]",2,639487,4bb248b260b5a072f3f9ee8ea3c5b683af8d1124,17,8,5,29344,,,0,"Fix:add python-glanceclient to cyborg requirements

Because in cyborg/image/glance.py line 33 hava ""import glanceclient""
but requirements.txt not have python-glanceclient

Change-Id: I3ba7b9eb87ed799ad5ea61f842dd1bbe08d533a8
Story: 2005097
Task: 29710
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/87/639487/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f6898342680679a1871c4530c98e0ad2693f513e,Bug2005097,python-glanceclient,,1,0
openstack%2Fironic~master~Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2,openstack/ironic,master,Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2,Allow building configdrive from JSON in the API,MERGED,2019-02-25 10:42:24.000000000,2019-03-07 03:30:49.000000000,2019-03-07 03:30:49.000000000,"[{'_account_id': 6618}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 28429}, {'_account_id': 29800}]","[{'number': 1, 'created': '2019-02-25 10:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ba7438ab9493ea37fbdcb5a39f020614db8814f2', 'message': '[WIP] Allow building configdrive from JSON in the API\n\nTODO:\n* API microversion\n* api-ref update\n* more unit tests\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 2, 'created': '2019-02-25 10:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/589b0457b3cffb034f1542adaa95e208421517b9', 'message': '[WIP] Allow building configdrive from JSON in the API\n\nTODO:\n* API microversion\n* api-ref update\n* more unit tests\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 3, 'created': '2019-02-25 11:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/749c749fe45af8d90f2c8c8e7a71d032c3007b53', 'message': '[WIP] Allow building configdrive from JSON in the API\n\nTODO:\n* API microversion\n* api-ref update\n* more unit tests\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 4, 'created': '2019-02-25 14:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d3a498422869bdf34be04142434269e5946301b3', 'message': 'Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data\nand user_data, where meta_data is a JSON object, and user_data is\neither a JSON object, a JSON array or raw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 5, 'created': '2019-02-25 14:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fd431aa170731ad68cc562baa430c48289bc7847', 'message': 'Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data\nand user_data, where meta_data is a JSON object, and user_data is\neither a JSON object, a JSON array or raw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 6, 'created': '2019-02-28 14:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5fd18a6fcd8e9e0b4c584cbf2bb0099a3c113971', 'message': '[WIP] Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data,\nnetwork_data and user_data, where meta_data and network_data are JSON\nobjects, and user_data is either a JSON object, a JSON array or\nraw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nTODO: adjust openstacksdk dependency to the new release.\n\nDepends-On: https://review.openstack.org/#/c/639149/\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 7, 'created': '2019-03-01 14:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/11d71dbbf5035a1f73a8b11be8988277adde989b', 'message': 'Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data,\nnetwork_data and user_data, where meta_data and network_data are JSON\nobjects, and user_data is either a JSON object, a JSON array or\nraw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 8, 'created': '2019-03-04 10:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/699dc352e58ab794fbdb8984c028bd2534060ff4', 'message': 'Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data,\nnetwork_data and user_data, where meta_data and network_data are JSON\nobjects, and user_data is either a JSON object, a JSON array or\nraw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 9, 'created': '2019-03-05 18:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9b043151d69108255b9a8a6a9a4b3aa471faaed6', 'message': 'Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data,\nnetwork_data and user_data, where meta_data and network_data are JSON\nobjects, and user_data is either a JSON object, a JSON array or\nraw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}, {'number': 10, 'created': '2019-03-05 18:15:07.000000000', 'files': ['api-ref/source/parameters.yaml', 'ironic/tests/unit/api/controllers/v1/test_utils.py', 'ironic/tests/unit/conductor/test_manager.py', 'lower-constraints.txt', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'requirements.txt', 'ironic/conductor/manager.py', 'ironic/api/controllers/v1/versions.py', 'api-ref/source/baremetal-api-v1-node-management.inc', 'ironic/conductor/utils.py', 'releasenotes/notes/build-configdrive-5b3b9095824faf4e.yaml', 'ironic/api/controllers/v1/utils.py', 'ironic/common/release_mappings.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3e1e0c9d5e6e5753d0fe2529901986ea36934971', 'message': 'Allow building configdrive from JSON in the API\n\nExtend the API with the ability to build config drives from meta_data,\nnetwork_data and user_data, where meta_data and network_data are JSON\nobjects, and user_data is either a JSON object, a JSON array or\nraw contents as a string.\n\nThis change uses openstacksdk (which is already an indirect dependency)\nfor building config drives.\n\nChange-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2\nStory: #2005083\nTask: #29663\n'}]",27,639050,3e1e0c9d5e6e5753d0fe2529901986ea36934971,127,12,10,10239,,,0,"Allow building configdrive from JSON in the API

Extend the API with the ability to build config drives from meta_data,
network_data and user_data, where meta_data and network_data are JSON
objects, and user_data is either a JSON object, a JSON array or
raw contents as a string.

This change uses openstacksdk (which is already an indirect dependency)
for building config drives.

Change-Id: Ie1f399a4cb6d4fe5afec79341d3bccc0f81204b2
Story: #2005083
Task: #29663
",git fetch https://review.opendev.org/openstack/ironic refs/changes/50/639050/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/api/controllers/v1/node.py']",3,ba7438ab9493ea37fbdcb5a39f020614db8814f2,story/2005083," types.jsontype, types.jsontype, wtypes.text,"," wtypes.text, types.jsontype, wtypes.text,",54,10
openstack%2Fcongress~master~Ie859e45ea03135aa21196fe19767f28627e76c3b,openstack/congress,master,Ie859e45ea03135aa21196fe19767f28627e76c3b,Add API header config to JSON ingester,MERGED,2019-03-06 19:35:59.000000000,2019-03-07 03:27:09.000000000,2019-03-07 03:27:09.000000000,"[{'_account_id': 18591}, {'_account_id': 22348}, {'_account_id': 25553}]","[{'number': 1, 'created': '2019-03-06 19:35:59.000000000', 'files': ['congress/datasources/json_ingester/exec_api.py', 'congress/datasources/json_ingester/json_ingester.py', 'congress/datasources/datasource_utils.py', 'etc/sample_json_ingesters/nova.yaml'], 'web_link': 'https://opendev.org/openstack/congress/commit/86a778ca5973eb83d4361d46d9b52e958525a38f', 'message': 'Add API header config to JSON ingester\n\nAdd the \'api_default_headers\' field which specifies a hash/dict\nof headers to pass with each API call w.r.t. that JSON ingester.\nMain usage is to specify API microversion. For example:\n\napi_default_headers:\n  X-OpenStack-Nova-API-Version: ""2.26""\n\nChange-Id: Ie859e45ea03135aa21196fe19767f28627e76c3b\npartially-implements: bp json-data-model\n'}]",0,641475,86a778ca5973eb83d4361d46d9b52e958525a38f,6,3,1,18591,,,0,"Add API header config to JSON ingester

Add the 'api_default_headers' field which specifies a hash/dict
of headers to pass with each API call w.r.t. that JSON ingester.
Main usage is to specify API microversion. For example:

api_default_headers:
  X-OpenStack-Nova-API-Version: ""2.26""

Change-Id: Ie859e45ea03135aa21196fe19767f28627e76c3b
partially-implements: bp json-data-model
",git fetch https://review.opendev.org/openstack/congress refs/changes/75/641475/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/datasources/json_ingester/exec_api.py', 'congress/datasources/json_ingester/json_ingester.py', 'congress/datasources/datasource_utils.py', 'etc/sample_json_ingesters/nova.yaml']",4,86a778ca5973eb83d4361d46d9b52e958525a38f,bp/json-data-model,"api_default_headers: X-OpenStack-Nova-API-Version: ""2.26""",,14,5
openstack%2Fcongress~master~I6391224c99249d16fe943b8f00fe12d1e6b7d8e6,openstack/congress,master,I6391224c99249d16fe943b8f00fe12d1e6b7d8e6,JSON ingester deployment enhancements,MERGED,2019-03-01 22:41:24.000000000,2019-03-07 03:22:08.000000000,2019-03-07 03:22:08.000000000,"[{'_account_id': 18591}, {'_account_id': 22348}, {'_account_id': 25553}]","[{'number': 1, 'created': '2019-03-01 22:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5d1d233f22b413d5670190df68785e5f5010982c', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 2, 'created': '2019-03-02 05:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/28a3d1f212bba68e511890eb8da81f17322ea0b1', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 3, 'created': '2019-03-02 18:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/ef44d02546582d136d28de492af238a2fc7357af', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 4, 'created': '2019-03-02 23:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/112072d56f2f4a32c988eb59760426d61c7d7a3e', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 5, 'created': '2019-03-03 04:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4e2cfd3d9e4ff3fc42891c8a4bdf6ef74fff95b3', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 6, 'created': '2019-03-03 05:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/05bf05073f6767fd280b545ab8edb85b4a0a7d70', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 7, 'created': '2019-03-04 04:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/ed490c51c2a880f7d9221046ebec3ac8383afce7', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 8, 'created': '2019-03-04 18:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/13112d93748adc3dd5d4be89dd5310c20405b681', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 9, 'created': '2019-03-04 20:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cc3063ce73a986e1df9075f26b718b9ec52edeb9', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 10, 'created': '2019-03-04 21:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/b920d6d831ecb0da5117287711e068d1d2fd3837', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 11, 'created': '2019-03-05 03:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/7e9a3810a5718286fbce269cc177c37df31423f0', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 12, 'created': '2019-03-05 06:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/043647703a37b9ffbffb7b875c5064ebb8ffe966', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 13, 'created': '2019-03-05 23:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/c347f06d0ff0a7b06c1dc6509f3f8533cf4f2ba4', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 14, 'created': '2019-03-05 23:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/78a3d3653d25d62b9f9547002a71d042e7e34014', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 15, 'created': '2019-03-06 01:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/b825afc1a1fcc734f185c69f5e4b9ed4e2ec7155', 'message': 'WIP - optionally enable JSON Ingester in devstack\n\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 16, 'created': '2019-03-06 06:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9e40077a937ca058bcd5ee7d8a680ca00e261b1c', 'message': 'JSON ingester deployment enhancements\n\nAllows json ingester config YAMLs to use the !ref tag to reference\npreviously defined reusable structures, which makes deployment much\nmore convenient.\n\nAllows devstack plugin to optionally enable JSON ingester feature.\n\nRenamed and reorganized the JSON ingester config options.\n\nAdds CI job which sets up JSON ingester.\n\npartially-implements: bp json-data-model\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}, {'number': 17, 'created': '2019-03-06 16:35:47.000000000', 'files': ['congress/utils.py', 'congress/common/config.py', 'congress/tests/test_utils.py', 'congress/datasources/json_ingester/exec_api.py', 'etc/config_reusables.yaml', '.zuul.yaml', 'devstack/plugin.sh', 'etc/sample_json_ingesters/nova.yaml', 'devstack/settings', 'congress/tests/datasources/json_ingester/test_json_ingester.py', 'congress/datasources/json_ingester/json_ingester.py', 'congress/harness.py', 'congress/tests/datasources/json_ingester/test_exec_api.py', 'congress/api/router.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/5da6e463ff6e5b2cf8182ebde7f61154157c12a2', 'message': 'JSON ingester deployment enhancements\n\nAllows json ingester config YAMLs to use the !ref tag to reference\npreviously defined reusable structures, which makes deployment much\nmore convenient.\n\nAllows devstack plugin to optionally enable JSON ingester feature.\n\nRenamed and reorganized the JSON ingester config options.\n\nAdds CI job which sets up JSON ingester.\n\npartially-implements: bp json-data-model\nChange-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6\n'}]",0,640550,5da6e463ff6e5b2cf8182ebde7f61154157c12a2,39,3,17,18591,,,0,"JSON ingester deployment enhancements

Allows json ingester config YAMLs to use the !ref tag to reference
previously defined reusable structures, which makes deployment much
more convenient.

Allows devstack plugin to optionally enable JSON ingester feature.

Renamed and reorganized the JSON ingester config options.

Adds CI job which sets up JSON ingester.

partially-implements: bp json-data-model
Change-Id: I6391224c99249d16fe943b8f00fe12d1e6b7d8e6
",git fetch https://review.opendev.org/openstack/congress refs/changes/50/640550/12 && git format-patch -1 --stdout FETCH_HEAD,"['congress/common/config.py', 'congress/datasources/json_ingester/exec_api.py', 'congress/datasources/json_ingester/json_ingester.py', 'congress/harness.py', '.zuul.yaml', 'devstack/plugin.sh', 'congress/api/router.py', 'devstack/settings']",8,5d1d233f22b413d5670190df68785e5f5010982c,bp/json-data-model,# Flag for enabling experimental JSON ingester # Requires DATABASE_TYPE: postgresql ENABLE_CONGRESS_JSON=$(trueorfalse False ENABLE_CONGRESS_JSON) CONGRESS_JSON_DB_NAME=${CONGRESS_JSON_DB_NAME:-congress_json} ,,52,19
openstack%2Fironic~master~I56768d7c8a577f267172de02d77e2cc2ead785ad,openstack/ironic,master,I56768d7c8a577f267172de02d77e2cc2ead785ad,Temporary marking ironic-standalone non-voting,MERGED,2019-03-06 16:02:15.000000000,2019-03-07 02:42:17.000000000,2019-03-06 19:40:45.000000000,"[{'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-03-06 16:02:15.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/790530f337d022b8c9b937b01250a3fc5fd6c847', 'message': 'Temporary marking ironic-standalone non-voting\n\nThe ironic-standalone job is failing because the most recent IPA\nimage has only python3 and ansible uses python 2 as default\ninterpreter, resulting in a /usr/bin/python not found error.\nMarking ironic-standalone non voting and removing it from the\ngate until we can run ansible with python3 on remote machines.\n\nChange-Id: I56768d7c8a577f267172de02d77e2cc2ead785ad\n'}]",0,641428,790530f337d022b8c9b937b01250a3fc5fd6c847,10,6,1,23851,,,0,"Temporary marking ironic-standalone non-voting

The ironic-standalone job is failing because the most recent IPA
image has only python3 and ansible uses python 2 as default
interpreter, resulting in a /usr/bin/python not found error.
Marking ironic-standalone non voting and removing it from the
gate until we can run ansible with python3 on remote machines.

Change-Id: I56768d7c8a577f267172de02d77e2cc2ead785ad
",git fetch https://review.opendev.org/openstack/ironic refs/changes/28/641428/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,790530f337d022b8c9b937b01250a3fc5fd6c847,ironic-standalone-non-voting, # making ironic-standalone non voting until we can run ansible # with python3 interpreter on remote machines - ironic-standalone: voting: false # removing ironic-standalone from gate until we can run ansible # with python3 interpreter on remote machines # - ironic-standalone, - ironic-standalone - ironic-standalone,7,2
openstack%2Fironic~master~I33be5426ce8ff2301d28096af11a1023b8048a15,openstack/ironic,master,I33be5426ce8ff2301d28096af11a1023b8048a15,Drop installing python-libvirt system package,MERGED,2019-03-01 17:41:29.000000000,2019-03-07 01:50:09.000000000,2019-03-07 01:50:09.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 13252}, {'_account_id': 14629}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 29800}]","[{'number': 1, 'created': '2019-03-01 17:41:29.000000000', 'files': ['bindep.txt', 'devstack/files/debs/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/296480961df82357eec448f8989baedaa471f888', 'message': 'Drop installing python-libvirt system package\n\nPip will install libvirt-python later in the process and with pip >= 10\nit will fail to remove the system version.\n\nChange-Id: I33be5426ce8ff2301d28096af11a1023b8048a15\nNeeded-By: https://review.openstack.org/#/c/561597\n'}]",0,640461,296480961df82357eec448f8989baedaa471f888,15,9,1,13252,,,0,"Drop installing python-libvirt system package

Pip will install libvirt-python later in the process and with pip >= 10
it will fail to remove the system version.

Change-Id: I33be5426ce8ff2301d28096af11a1023b8048a15
Needed-By: https://review.openstack.org/#/c/561597
",git fetch https://review.opendev.org/openstack/ironic refs/changes/61/640461/1 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'devstack/files/debs/ironic']",2,296480961df82357eec448f8989baedaa471f888,fix-pip-libvirt-python,,python-libvirt,0,3
openstack%2Felection~master~I79708dfec314dbed6de4f0bf821289e421c6b8cd,openstack/election,master,I79708dfec314dbed6de4f0bf821289e421c6b8cd,Add bnemec candidacy for Oslo,MERGED,2019-03-06 22:31:17.000000000,2019-03-07 01:37:25.000000000,2019-03-07 01:37:25.000000000,"[{'_account_id': 5263}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 22:31:17.000000000', 'files': ['candidates/train/Oslo/openstack@nemebean.com'], 'web_link': 'https://opendev.org/openstack/election/commit/a5276332e9d4daa4f0e85e60436baea60d5b9e59', 'message': 'Add bnemec candidacy for Oslo\n\nChange-Id: I79708dfec314dbed6de4f0bf821289e421c6b8cd\n'}]",0,641503,a5276332e9d4daa4f0e85e60436baea60d5b9e59,7,3,1,6928,,,0,"Add bnemec candidacy for Oslo

Change-Id: I79708dfec314dbed6de4f0bf821289e421c6b8cd
",git fetch https://review.opendev.org/openstack/election refs/changes/03/641503/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Oslo/openstack@nemebean.com'],1,a5276332e9d4daa4f0e85e60436baea60d5b9e59,oslo-train,"I am running for Oslo PTL in the Train cycle. I have been Oslo PTL for around a year now, and in that time we've been able to address a number of longstanding user requests, such as the removal of plaintext secrets from config files and a validator for config files. However, that doesn't mean our job is done. Here are some things I want to focus on for the next cycle: * Mentor new contributors. In the past cycle we had a number of our most experienced contributors pulled away to other projects, either in part or in total. The good news is we have some newer contributors who I believe can step in to fill those gaps. We need to make sure to help them along as much as possible. * Support cycle goals. In Stein we were able to add an Oslo library to make the goal implementation easier for all of the other OpenStack projects. We should continue to look for such opportunities with the new cycle goals for Train. * Storyboard migration. We've been discussing this pretty much since I became PTL, and I know some progress was made in Stein toward addressing some of my concerns with this. I think this is likely to be the cycle where we can go ahead with the move. * oslo.limit. I still very much want this to be a thing and will do whatever I can to help make it happen. I think that's it for now, but as always I am open to suggestions on things Oslo can do to make everyone's life easier. ",,13,0
openstack%2Fmurano~master~Ifa841399c4619bc2f678f3b2dc879f33dbb770e5,openstack/murano,master,Ifa841399c4619bc2f678f3b2dc879f33dbb770e5,Grenade: add the Grenade Heat plugin too,MERGED,2019-03-04 19:28:30.000000000,2019-03-07 01:32:21.000000000,2019-03-07 01:32:21.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 19:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/cbcc5edf6864af9cde4d61a4b153f5d1bf47d7e6', 'message': 'Grenade: add the Grenade Heat plugin too\n\nHeat is deployed by the Grenade job, so it should be upgraded as well.\n\nChange-Id: Ifa841399c4619bc2f678f3b2dc879f33dbb770e5\n'}, {'number': 2, 'created': '2019-03-04 20:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/005d2b5ae2495c536552a12b8fb358499bfaa37e', 'message': 'Grenade: add the Grenade Heat plugin too\n\nHeat is deployed by the Grenade job, so it should be upgraded as well.\n\nChange-Id: Ifa841399c4619bc2f678f3b2dc879f33dbb770e5\n'}, {'number': 3, 'created': '2019-03-06 11:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/146ca8b075d70f9c2b0d971dd9f4cec154b0a295', 'message': 'Grenade: add the Grenade Heat plugin too\n\nHeat is deployed by the Grenade job, so it should be upgraded as well.\n\nChange-Id: Ifa841399c4619bc2f678f3b2dc879f33dbb770e5\n'}, {'number': 4, 'created': '2019-03-06 12:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/120cd36694dd7439fe0fae96c4cba56d187a01aa', 'message': 'Grenade: add the Grenade Heat plugin too\n\nHeat is deployed by the Grenade job, so it should be upgraded as well.\n\nChange-Id: Ifa841399c4619bc2f678f3b2dc879f33dbb770e5\n'}, {'number': 5, 'created': '2019-03-06 16:20:30.000000000', 'files': ['.zuul.yaml', 'playbooks/legacy/grenade-devstack-murano/run.yaml'], 'web_link': 'https://opendev.org/openstack/murano/commit/41a173fce759430c2cb543a852e9cf6ae6a1652d', 'message': 'Grenade: add the Grenade Heat plugin too\n\nHeat is deployed by the Grenade job, so it should be upgraded as well.\n\nChange-Id: Ifa841399c4619bc2f678f3b2dc879f33dbb770e5\n'}]",0,640842,41a173fce759430c2cb543a852e9cf6ae6a1652d,14,2,5,10459,,,0,"Grenade: add the Grenade Heat plugin too

Heat is deployed by the Grenade job, so it should be upgraded as well.

Change-Id: Ifa841399c4619bc2f678f3b2dc879f33dbb770e5
",git fetch https://review.opendev.org/openstack/murano refs/changes/42/640842/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/grenade-devstack-murano/run.yaml'],1,cbcc5edf6864af9cde4d61a4b153f5d1bf47d7e6,grenade-heat-plugin," export GRENADE_PLUGINRC+=$'\n'""enable_grenade_plugin heat https://git.openstack.org/openstack/heat""",,1,0
openstack%2Fswift~master~I6478e7468237af07f9e681909f6aee19620097fe,openstack/swift,master,I6478e7468237af07f9e681909f6aee19620097fe,WIP: failing test for write_affinity POST,NEW,2019-03-07 00:45:45.000000000,2019-03-07 01:21:51.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-07 00:45:45.000000000', 'files': ['test/unit/proxy/controllers/test_obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/84207d24fd1bce5ad42aa61b11bc35b87c6bf05d', 'message': 'WIP: failing test for write_affinity POST\n\nRelated-Bug: 1818931\n\nChange-Id: I6478e7468237af07f9e681909f6aee19620097fe\n'}]",0,641528,84207d24fd1bce5ad42aa61b11bc35b87c6bf05d,2,1,1,1179,,,0,"WIP: failing test for write_affinity POST

Related-Bug: 1818931

Change-Id: I6478e7468237af07f9e681909f6aee19620097fe
",git fetch https://review.opendev.org/openstack/swift refs/changes/28/641528/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/proxy/controllers/test_obj.py'],1,84207d24fd1bce5ad42aa61b11bc35b87c6bf05d,bug/1818931," def test_POST_with_write_affinity(self): policy_index = 1 self.policy = POLICIES[policy_index] policy_conf = self.app.get_policy_options(self.policy) self.app.container_info['storage_policy'] = policy_index policy_conf.write_affinity_handoff_delete_count = \ self.replicas(self.policy) / 2 policy_conf.write_affinity_is_local_fn = ( lambda node: node['region'] == 1) self.app.post_quorum_timeout = 0.01 req = swift.common.swob.Request.blank('/v1/a/c/o', method='POST') # N.B. this is not ideal, by default we'd want a longer # post_quorum_timeout and more requests to local region handoffs codes = [204, FakeStatus(204, response_sleep=1), 404, 404] with mocked_http_conn(*codes): resp = req.get_response(self.app) self.assertEqual(resp.status_int, 204) ",,20,0
openstack%2Frequirements~master~I4b4d9f7dc37f001ffa3c3400fd1cb9a3bdefb4fc,openstack/requirements,master,I4b4d9f7dc37f001ffa3c3400fd1cb9a3bdefb4fc,update constraint for python-searchlightclient to new release 1.5.0,MERGED,2019-03-06 17:06:49.000000000,2019-03-07 00:52:25.000000000,2019-03-07 00:52:24.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 17:06:49.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3ab666436e58cc0ce9695db378853ed9b3d79dd8', 'message': 'update constraint for python-searchlightclient to new release 1.5.0\n\nChange-Id: I4b4d9f7dc37f001ffa3c3400fd1cb9a3bdefb4fc\nmeta:version: 1.5.0\nmeta:diff-start: -\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Trinh Nguyen <dangtrinhnt@gmail.com>\nmeta:release:Commit: Trinh Nguyen <dangtrinhnt@gmail.com>\nmeta:release:Change-Id: I52c4839475f50a56de6be95e3409f08870b2240d\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+1: sapd <saphi070@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,641443,3ab666436e58cc0ce9695db378853ed9b3d79dd8,7,3,1,11131,,,0,"update constraint for python-searchlightclient to new release 1.5.0

Change-Id: I4b4d9f7dc37f001ffa3c3400fd1cb9a3bdefb4fc
meta:version: 1.5.0
meta:diff-start: -
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Trinh Nguyen <dangtrinhnt@gmail.com>
meta:release:Commit: Trinh Nguyen <dangtrinhnt@gmail.com>
meta:release:Change-Id: I52c4839475f50a56de6be95e3409f08870b2240d
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+1: sapd <saphi070@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/43/641443/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,3ab666436e58cc0ce9695db378853ed9b3d79dd8,new-release,python-searchlightclient===1.5.0,python-searchlightclient===1.4.0,1,1
openstack%2Fpython-openstackclient~master~I48fda15b34283bb7c66ea18ed28262f48b9229fe,openstack/python-openstackclient,master,I48fda15b34283bb7c66ea18ed28262f48b9229fe,Add support for get details of Quota,MERGED,2017-10-26 13:05:05.000000000,2019-03-07 00:34:18.000000000,2019-03-07 00:34:18.000000000,"[{'_account_id': 841}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 6482}, {'_account_id': 8313}, {'_account_id': 9373}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 28239}]","[{'number': 1, 'created': '2017-10-26 13:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/783b462e7c079a2620c8f5b3db26d4d329339df3', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota show"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 2, 'created': '2017-11-02 22:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d20acfd65a27f8e9df857f057f800f00a9bcb3fa', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota show"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 3, 'created': '2017-12-04 15:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/51bfb91956b38546b53d22e8446e2e9f9b78a332', 'message': '[WIP] Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nTODO:\n* finish UT for list detailed quotas\n* add functional test\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 4, 'created': '2017-12-05 11:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0054fd5d30217f550d388294a87349e6446fa143', 'message': '[WIP] Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 5, 'created': '2017-12-05 11:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c96f4b7f9715207fd3a31abe6a62adc79d4f069d', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 6, 'created': '2017-12-05 12:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aaecbbffb310d8379a5135edea432e3f54a71046', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 7, 'created': '2017-12-05 14:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8ae59a23249a82b114e4a4b431446778f3f1ff0d', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 8, 'created': '2017-12-07 11:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5325a9da72c673d7065010f7eb885cbdf8f97ae4', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 9, 'created': '2017-12-08 09:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8b4e04c82ad06a7738cb8f896c8f524bb34fff56', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 10, 'created': '2017-12-08 09:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/00608c30059b72c2427bca4d96b6ee4ae470aad1', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 11, 'created': '2018-10-19 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/73d408a646c7aaee495b4487584c69246dc9e6c7', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 12, 'created': '2018-10-19 10:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d169bc70f7d7237f3de9733f8a5a0745462b4143', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 13, 'created': '2018-10-19 11:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0097be957fb317acd576e6b1cef262cc2b54bcdd', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 14, 'created': '2018-12-05 13:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7a2903a15b50146d7ce4c2bd704ec26633553d3f', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 15, 'created': '2019-02-04 21:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ecb76a3ffb73beb00c0716d7efe11a8ae58a5535', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 16, 'created': '2019-02-05 07:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4fef681c7109141a371540714a67d1ccdd2e4527', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 17, 'created': '2019-02-05 11:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4b8723d6c15f952022a8f988ce572f3b319e45f4', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 18, 'created': '2019-02-05 11:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/87cca13104587cf1fd1556dd8aa758949b83671b', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 19, 'created': '2019-02-06 09:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a9336b91285824d15aaae5e3bd903fcc80a1cbbd', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 20, 'created': '2019-02-12 12:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8632f11b34ec6d3bffade9b4220d5239631b6292', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 21, 'created': '2019-02-18 20:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8b55b65f0d5960813590e48b35e5fc74c67a01d8', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 22, 'created': '2019-02-24 09:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/797f257b9f0b936a5a50e9b6fa58e0352c31e15a', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}, {'number': 23, 'created': '2019-02-24 10:41:58.000000000', 'files': ['openstackclient/tests/unit/common/test_quota.py', 'openstackclient/tests/functional/common/test_quota.py', 'openstackclient/tests/unit/network/v2/fakes.py', 'doc/source/cli/command-objects/quota.rst', 'releasenotes/notes/list-detailed-quota-informations-1755129e1c68a252.yaml', 'openstackclient/common/quota.py', 'openstackclient/tests/unit/compute/v2/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/75cba9d1cbdd7b14b0d507af27f896c6c45e713e', 'message': 'Add support for get details of Quota\n\nWith passing ""--detail"" argument to ""openstack quota list"", details\nabout current usage should be returned.\nIt is currently supported by Nova and Neutron so details of\nresources from those projects can be returned.\n\nChange-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe\nRelated-Bug: #1716043\n'}]",25,515401,75cba9d1cbdd7b14b0d507af27f896c6c45e713e,84,10,23,11975,,,0,"Add support for get details of Quota

With passing ""--detail"" argument to ""openstack quota list"", details
about current usage should be returned.
It is currently supported by Nova and Neutron so details of
resources from those projects can be returned.

Change-Id: I48fda15b34283bb7c66ea18ed28262f48b9229fe
Related-Bug: #1716043
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/01/515401/17 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/common/test_quota.py', 'openstackclient/tests/functional/common/test_quota.py', 'doc/source/cli/command-objects/quota.rst', 'openstackclient/common/quota.py']",4,783b462e7c079a2620c8f5b3db26d4d329339df3,bug/1716043," type_group.add_argument( '--detail', dest='detail', action='store_true', default=False, help=_('Show detailed quota info for <project>') ) # NOTE(slaweq): as cinder client don't supports detail flag # we have to pass it only if it's True which means that # ""client"" will be NovaClient in fact if parsed_args.detail: quota = client.quotas.get(project, detail=True) else: quota = client.quotas.get(project) network_quota = client.get_quota(project, details=parsed_args.detail) # NOTE(slaweq): Cinder client don't support detailed quota if parsed_args.detail: volume_quota_info = {} else: volume_quota_info = self.get_compute_volume_quota(volume_client, parsed_args) "," quota = client.quotas.get(project) network_quota = client.get_quota(project) volume_quota_info = self.get_compute_volume_quota(volume_client, parsed_args)",73,14
openstack%2Fpython-openstackclient~master~Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4,openstack/python-openstackclient,master,Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4,Add possibility to filter images using member_status,MERGED,2019-02-18 09:47:59.000000000,2019-03-07 00:34:17.000000000,2019-03-07 00:34:17.000000000,"[{'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-02-18 09:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4bb74b8fc6ad6c486a937aa07be400135072b8ff', 'message': ""Add possibility to filter images using member_status\n\nIn order to see image sharing membership it is required to additionally\npass member_status filter to API. Otherwise only those with status 'all'\nwill be returned. Thus adding possibility to see images shared with\nproject to be approved or rejected.\n\nChange-Id: Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4\n""}, {'number': 2, 'created': '2019-02-18 11:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fcc465332c3debafdf7cb84bc211c5564ed5b0c8', 'message': ""Add possibility to filter images using member_status\n\nIn order to see image sharing membership it is required to additionally\npass member_status filter to API. Otherwise only those with status 'all'\nwill be returned. Thus adding possibility to see images shared with\nproject to be approved or rejected.\n\nChange-Id: Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4\n""}, {'number': 3, 'created': '2019-02-19 08:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a7552a06faee4b974929bdfbf1d21d8e7878356d', 'message': ""Add possibility to filter images using member_status\n\nIn order to see image sharing membership it is required to additionally\npass member_status filter to API. Otherwise only those with status 'all'\nwill be returned. Thus adding possibility to see images shared with\nproject to be approved or rejected.\n\nChange-Id: Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4\n""}, {'number': 4, 'created': '2019-02-26 10:14:34.000000000', 'files': ['doc/source/cli/command-objects/image.rst', 'openstackclient/tests/unit/image/v2/test_image.py', 'releasenotes/notes/add-member-status-filter-2e118b2c93151223.yaml', 'openstackclient/image/v2/image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/444a40c656b9f6007364ecd3bcf38964bbcd4556', 'message': ""Add possibility to filter images using member_status\n\nIn order to see image sharing membership it is required to additionally\npass member_status filter to API. Otherwise only those with status 'all'\nwill be returned. Thus adding possibility to see images shared with\nproject to be approved or rejected.\n\nChange-Id: Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4\n""}]",10,637508,444a40c656b9f6007364ecd3bcf38964bbcd4556,19,4,4,27900,,,0,"Add possibility to filter images using member_status

In order to see image sharing membership it is required to additionally
pass member_status filter to API. Otherwise only those with status 'all'
will be returned. Thus adding possibility to see images shared with
project to be approved or rejected.

Change-Id: Ifd6e13e5a4ef09fbc29e76d464c93fbdbb178ae4
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/08/637508/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/image/v2/test_image.py', 'openstackclient/image/v2/image.py']",2,4bb74b8fc6ad6c486a937aa07be400135072b8ff,637508,"MEMBER_STATUS_CHOISES = [""accepted"", ""pending"", ""rejected"", ""all""] '--member_status', metavar='<member_status>', default=None, type=lambda s: s.lower(), choices=MEMBER_STATUS_CHOISES, help=_(""Filter images based on member status. "" ""The supported options are: %s. "") % ', '.join(MEMBER_STATUS_CHOISES) ) parser.add_argument( if parsed_args.member_status: kwargs['member_status'] = parsed_args.member_status",,41,0
openstack%2Fsenlin~master~I767434f5d617d1eb0bdba625a052b16913d1849b,openstack/senlin,master,I767434f5d617d1eb0bdba625a052b16913d1849b,Add release note for hm fixes,MERGED,2019-03-05 20:24:29.000000000,2019-03-06 23:40:51.000000000,2019-03-06 23:40:51.000000000,"[{'_account_id': 22348}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-03-05 20:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/924c949a0fd6e335bf5ec7ab36c0d0fb29893769', 'message': 'Add release note for hm fixes\n\nTHis patch adds the missing releease notes for\nhttps://review.openstack.org/#/c/634811.\n\nChange-Id: I767434f5d617d1eb0bdba625a052b16913d1849b\n'}, {'number': 2, 'created': '2019-03-05 20:25:27.000000000', 'files': ['releasenotes/notes/health-manager-fixes-d5955f9af88102fc.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/27ce61f6df53d059b450aef5d828d82aff1e20ca', 'message': 'Add release note for hm fixes\n\nThis patch adds the missing releease notes for\nhttps://review.openstack.org/#/c/634811.\n\nChange-Id: I767434f5d617d1eb0bdba625a052b16913d1849b\n'}]",0,641116,27ce61f6df53d059b450aef5d828d82aff1e20ca,8,2,2,25674,,,0,"Add release note for hm fixes

This patch adds the missing releease notes for
https://review.openstack.org/#/c/634811.

Change-Id: I767434f5d617d1eb0bdba625a052b16913d1849b
",git fetch https://review.opendev.org/openstack/senlin refs/changes/16/641116/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/health-manager-fixes-d5955f9af88102fc.yaml'],1,924c949a0fd6e335bf5ec7ab36c0d0fb29893769,,--- fixes: - | Fixes the logic within the health manager to prevent duplicate health checks from running on the same cluster. other: - | Adds a configuration option to the health manager to control the maximum amount of threads that can be created by the health manager. ,,9,0
openstack%2Foctavia~master~If97b71c0f18215bf0ea599a0f856776644c2ce5d,openstack/octavia,master,If97b71c0f18215bf0ea599a0f856776644c2ce5d,DNM: Gate test for yappi g-r blacklist,ABANDONED,2019-02-19 20:36:03.000000000,2019-03-06 23:34:29.000000000,,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 20:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4c9709c48679cdbc5e33789eea9ec3c260fcc97e', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 2, 'created': '2019-02-19 23:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f88e1549f3ffdc886edac651e75f2994a60fce09', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 3, 'created': '2019-02-19 23:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/04d492f3f00244bed3c8e3cb5b8c245195c5d10f', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 4, 'created': '2019-02-20 00:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/29d0d46195de353da9f80b83ca0e190b987a8372', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 5, 'created': '2019-02-20 02:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e74a88fe2175576c2ee7f7c258cbd0b919c1521c', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 6, 'created': '2019-02-20 04:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/27d05d239280ee7bedc20efc863ca4b823eca7c5', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 7, 'created': '2019-02-20 06:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8846e4090ade2cdfb465ef16ff93b88443eaf8b7', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 8, 'created': '2019-02-20 08:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3c6d35594f40d443dff333b79fef9366facccf19', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 9, 'created': '2019-02-20 09:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a58f9588e10722a7803b99d050803df6b322611f', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}, {'number': 10, 'created': '2019-02-20 15:46:06.000000000', 'files': ['elements/amphora-agent/pre-install.d/1-fix-upper-constraints', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/70f4351c104680600e5f1f6c3629e323147e11d2', 'message': 'DNM: Gate test for yappi g-r blacklist\n\nDepends-On: https://review.openstack.org/637994\nChange-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d\n'}]",1,637995,70f4351c104680600e5f1f6c3629e323147e11d2,17,3,10,11628,,,0,"DNM: Gate test for yappi g-r blacklist

Depends-On: https://review.openstack.org/637994
Change-Id: If97b71c0f18215bf0ea599a0f856776644c2ce5d
",git fetch https://review.opendev.org/openstack/octavia refs/changes/95/637995/5 && git format-patch -1 --stdout FETCH_HEAD,['octavia/opts.py'],1,4c9709c48679cdbc5e33789eea9ec3c260fcc97e,,,,1,0
openstack%2Ftripleo-common~master~I9c54379925339eaaa9a0ee61cb823bddc95737c7,openstack/tripleo-common,master,I9c54379925339eaaa9a0ee61cb823bddc95737c7,Don't always validate heat stack when adding parameters,MERGED,2019-02-25 11:43:15.000000000,2019-03-06 23:31:19.000000000,2019-03-04 21:02:23.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-02-25 11:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/88c547c5d44ef7c86c7d826188e3710edc8d48f0', 'message': ""Don't always validate heat stack when adding parameters\n\nThere are certain cases we add parameters to plan environment\nwhen creating and updating a plan. As part of that action we\naslo try to validate the stack/template. However, validation\nwould fail, if we've resource mappings in user-environment that\nare not merged/added to the plan yet.\n\nThis adds new input flag to plan create and update workflows which\ncan then be changed in python-tripleoclient, so as not to imapct the\nUI workflows.\n\nChange-Id: I9c54379925339eaaa9a0ee61cb823bddc95737c7\nPartial-Bug: #1817539\n""}, {'number': 2, 'created': '2019-02-25 12:34:42.000000000', 'files': ['workbooks/plan_management.yaml', 'workbooks/swift_backup.yaml', 'tripleo_common/actions/parameters.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/762bf8c9e7bcfbbc4b6682e5f7c6347e213ad622', 'message': ""Don't always validate heat stack when adding parameters\n\nThere are certain cases we add parameters to plan environment\nwhen creating and updating a plan. As part of that action we\naslo try to validate the stack/template. However, validation\nwould fail, if we've resource mappings in user-environment that\nare not merged/added to the plan yet.\n\nThis adds new input flag to plan create and update workflows which\ncan then be changed in python-tripleoclient, so as not to imapct the\nUI workflows.\n\nChange-Id: I9c54379925339eaaa9a0ee61cb823bddc95737c7\nPartial-Bug: #1817539\n""}]",0,639072,762bf8c9e7bcfbbc4b6682e5f7c6347e213ad622,15,8,2,8833,,,0,"Don't always validate heat stack when adding parameters

There are certain cases we add parameters to plan environment
when creating and updating a plan. As part of that action we
aslo try to validate the stack/template. However, validation
would fail, if we've resource mappings in user-environment that
are not merged/added to the plan yet.

This adds new input flag to plan create and update workflows which
can then be changed in python-tripleoclient, so as not to imapct the
UI workflows.

Change-Id: I9c54379925339eaaa9a0ee61cb823bddc95737c7
Partial-Bug: #1817539
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/72/639072/2 && git format-patch -1 --stdout FETCH_HEAD,"['workbooks/plan_management.yaml', 'workbooks/swift_backup.yaml', 'tripleo_common/actions/parameters.py']",3,88c547c5d44ef7c86c7d826188e3710edc8d48f0,bug/1817539," key=constants.DEFAULT_PLAN_ENV_KEY, validate=True): self.validate = validate env = plan_utils.get_env(swift, self.container) if not validate: return env "," key=constants.DEFAULT_PLAN_ENV_KEY): env = plan_utils.get_env(swift, self.container)",14,2
openstack%2Fpython-tripleoclient~master~Ia2299698dfb5d7afb374e9ac2d7908c7cc6bbc22,openstack/python-tripleoclient,master,Ia2299698dfb5d7afb374e9ac2d7908c7cc6bbc22,Don't validate stack when creating/updating plan,MERGED,2019-02-25 12:35:08.000000000,2019-03-06 23:30:51.000000000,2019-03-05 02:25:06.000000000,"[{'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-25 12:35:08.000000000', 'files': ['tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/workflows/plan_management.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/v1/overcloud_plan.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/eae703d52d1fcacd3aa3e253dd2cb74a3abd0ca1', 'message': ""Don't validate stack when creating/updating plan\n\nThere may be resource mappings in user_environment.\n\nChange-Id: Ia2299698dfb5d7afb374e9ac2d7908c7cc6bbc22\nCloses-Bug: #1817539\nDepends-On: https://review.openstack.org/639072\n""}]",0,639080,eae703d52d1fcacd3aa3e253dd2cb74a3abd0ca1,16,5,1,8833,,,0,"Don't validate stack when creating/updating plan

There may be resource mappings in user_environment.

Change-Id: Ia2299698dfb5d7afb374e9ac2d7908c7cc6bbc22
Closes-Bug: #1817539
Depends-On: https://review.openstack.org/639072
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/80/639080/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/workflows/plan_management.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/v1/overcloud_plan.py', 'tripleoclient/v1/overcloud_deploy.py']",5,eae703d52d1fcacd3aa3e253dd2cb74a3abd0ca1,bug/1817539," type(self)._keep_env_on_update, validate_stack=False) parsed_args.networks_file, validate_stack=False)", type(self)._keep_env_on_update) parsed_args.networks_file),49,25
openstack%2Fbarbican~master~I7fd60d48802cc5e9071c39eaeb83351bec36cc41,openstack/barbican,master,I7fd60d48802cc5e9071c39eaeb83351bec36cc41,Set Tempest's service_availability setting for Barbican,MERGED,2019-02-25 16:43:45.000000000,2019-03-06 23:27:01.000000000,2019-03-06 23:27:00.000000000,"[{'_account_id': 7973}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 9914}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 16:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/609a76b5e76be69d1768b363c4e5fc66d1b72d9c', 'message': ""Set Tempest's service_availability setting for Barbican\n\nTempest's service_available config option includes all the service\navailability which is further used by tests to take decision of skip\nor run the test.\n\nFor example, [service_available].barbican is true then, barbican test will run\nor if [service_available].barbican is false then, all barbican related tests either\nin barbican tempest plugin or any other plugins[1] will be skipped.\n\nThis commit add the setting of barbican service[2] on aodh devstack plugin.\n\nCloses-Bug: #1743688\nRelated-Bug: #1817154\n\n[1] https://github.com/openstack/octavia-tempest-plugin/blob/0a0f9b342a73c924ba9e7142878a2889ac2061aa/octavia_tempest_plugin/tests/barbican_scenario/v2/test_tls_barbican.py#L53\n[2] https://github.com/openstack/barbican-tempest-plugin/blob/123dd7d4162c39a1cb4b4c1b09a5dceaee127eb6/barbican_tempest_plugin/config.py#L18\n\nChange-Id: I7fd60d48802cc5e9071c39eaeb83351bec36cc41\n""}, {'number': 2, 'created': '2019-02-26 12:04:48.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/b4fe45496cbb0ee6474e0cfe8501061c61782b2c', 'message': ""Set Tempest's service_availability setting for Barbican\n\nTempest's service_available config option includes all the service\navailability which is further used by tests to take decision of skip\nor run the test.\n\nFor example, [service_available].barbican is true then, barbican test will run\nor if [service_available].barbican is false then, all barbican related tests either\nin barbican tempest plugin or any other plugins[1] will be skipped.\n\nSo it is important that when barbican is installed via devstack plugin then,\nit set the service_available.barbican value to True in tempest conf.\n\nThis commit add the setting of barbican service[2] on barbican devstack plugin.\n\nRelated-Bug: #1743688\nRelated-Bug: #1817154\n\n[1] https://github.com/openstack/octavia-tempest-plugin/blob/0a0f9b342a73c924ba9e7142878a2889ac2061aa/octavia_tempest_plugin/tests/barbican_scenario/v2/test_tls_barbican.py#L53\n[2] https://github.com/openstack/barbican-tempest-plugin/blob/123dd7d4162c39a1cb4b4c1b09a5dceaee127eb6/barbican_tempest_plugin/config.py#L18\n\nChange-Id: I7fd60d48802cc5e9071c39eaeb83351bec36cc41\n""}]",0,639153,b4fe45496cbb0ee6474e0cfe8501061c61782b2c,12,6,2,8556,,,0,"Set Tempest's service_availability setting for Barbican

Tempest's service_available config option includes all the service
availability which is further used by tests to take decision of skip
or run the test.

For example, [service_available].barbican is true then, barbican test will run
or if [service_available].barbican is false then, all barbican related tests either
in barbican tempest plugin or any other plugins[1] will be skipped.

So it is important that when barbican is installed via devstack plugin then,
it set the service_available.barbican value to True in tempest conf.

This commit add the setting of barbican service[2] on barbican devstack plugin.

Related-Bug: #1743688
Related-Bug: #1817154

[1] https://github.com/openstack/octavia-tempest-plugin/blob/0a0f9b342a73c924ba9e7142878a2889ac2061aa/octavia_tempest_plugin/tests/barbican_scenario/v2/test_tls_barbican.py#L53
[2] https://github.com/openstack/barbican-tempest-plugin/blob/123dd7d4162c39a1cb4b4c1b09a5dceaee127eb6/barbican_tempest_plugin/config.py#L18

Change-Id: I7fd60d48802cc5e9071c39eaeb83351bec36cc41
",git fetch https://review.opendev.org/openstack/barbican refs/changes/53/639153/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,609a76b5e76be69d1768b363c4e5fc66d1b72d9c,bug/1743688, iniset $TEMPEST_CONFIG service_available barbican True,,1,0
openstack%2Ftripleo-heat-templates~master~Ie8924833a2410eea096fda955c8c6df9b1f0e207,openstack/tripleo-heat-templates,master,Ie8924833a2410eea096fda955c8c6df9b1f0e207,mistral-executor include host /etc/environment,MERGED,2019-03-05 02:32:02.000000000,2019-03-06 23:22:30.000000000,2019-03-06 23:22:29.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 02:32:02.000000000', 'files': ['deployment/mistral/mistral-executor-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9cb715a5e766909ad8ac4d2d949cc3c141d7923f', 'message': 'mistral-executor include host /etc/environment\n\nThe undercloud host file /etc/environment will be documented as where\nproxy environment variables will be set when the undercloud is behind\na proxy server.\n\nThese variables also need to be set inside the mistral_executor\ncontainer for the pre-deployment image prepare to access external\nregistries. This change will make that possible without any further\nchanges required from the deployer.\n\nChange-Id: Ie8924833a2410eea096fda955c8c6df9b1f0e207\nPartial-Bug: #1818590\n'}]",0,640925,9cb715a5e766909ad8ac4d2d949cc3c141d7923f,12,4,1,4571,,,0,"mistral-executor include host /etc/environment

The undercloud host file /etc/environment will be documented as where
proxy environment variables will be set when the undercloud is behind
a proxy server.

These variables also need to be set inside the mistral_executor
container for the pre-deployment image prepare to access external
registries. This change will make that possible without any further
changes required from the deployer.

Change-Id: Ie8924833a2410eea096fda955c8c6df9b1f0e207
Partial-Bug: #1818590
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/640925/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/mistral/mistral-executor-container-puppet.yaml'],1,9cb715a5e766909ad8ac4d2d949cc3c141d7923f,bug/1818590, env_file: /etc/environment,,1,0
openstack%2Fmanila~master~I730629ea460c316a02f8dffb4a55eea04ad619c9,openstack/manila,master,I730629ea460c316a02f8dffb4a55eea04ad619c9,Fix missing size value in snapshot instance,MERGED,2019-02-22 15:01:27.000000000,2019-03-06 23:17:37.000000000,2019-03-06 23:17:37.000000000,"[{'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 29632}]","[{'number': 1, 'created': '2019-02-22 15:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3f4f064f5697358e866b06206e1a4188d5625abe', 'message': '[NetApp] Fix python3 compatibility issues\n\nThis patch fixes a python3 bug while creating shares\nfrom snapshots.\n\nCloses-bug: #1815587\n\nChange-Id: I730629ea460c316a02f8dffb4a55eea04ad619c9\n'}, {'number': 2, 'created': '2019-03-05 17:04:25.000000000', 'files': ['manila/db/sqlalchemy/models.py', 'releasenotes/notes/fix-py3-netapp-a9815186ddc865d4.yaml', 'manila/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/785aa8369c5a7a04b5358ca2c66aa18a4f9637e1', 'message': 'Fix missing size value in snapshot instance\n\nThis patch fixes the size value not being present in share\nsnapshot instances, which causes drivers to not being able to access\nthis property unless they read the size from the snapshot model.\n\nCloses-bug: #1815587\nChange-Id: I730629ea460c316a02f8dffb4a55eea04ad619c9\n'}]",1,638681,785aa8369c5a7a04b5358ca2c66aa18a4f9637e1,28,13,2,29632,,,0,"Fix missing size value in snapshot instance

This patch fixes the size value not being present in share
snapshot instances, which causes drivers to not being able to access
this property unless they read the size from the snapshot model.

Closes-bug: #1815587
Change-Id: I730629ea460c316a02f8dffb4a55eea04ad619c9
",git fetch https://review.opendev.org/openstack/manila refs/changes/81/638681/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'releasenotes/notes/fix-py3-netapp-a9815186ddc865d4.yaml', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py']",3,3f4f064f5697358e866b06206e1a4188d5625abe,bug/1815587," 'hide_snapdir': True, 'can_get_size': False}) self, provider_location, size, hide_snapdir, can_get_size=True): if not can_get_size: fake_snapshot.pop('size') fake_snapshot['snapshot'] = {'size': original_snapshot_size} "," 'hide_snapdir': True}) self, provider_location, size, hide_snapdir):",15,3
openstack%2Ftripleo-heat-templates~master~I5c2d230f5cc63009c7b02272112b2d4af4669da7,openstack/tripleo-heat-templates,master,I5c2d230f5cc63009c7b02272112b2d4af4669da7,ci/environments/ovb-ha: force Docker for ContainerCli,MERGED,2019-03-05 00:10:42.000000000,2019-03-06 23:12:51.000000000,2019-03-06 23:12:51.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 00:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7aebfb9291ecb6bf523362dbd17f354ce59238ea', 'message': ""ci/environments/ovb-ha: force Docker for ContainerCli\n\nUntil we get CentOS8, we can't test Pacemaker + Podman together, so\nuntil then we'll force ContainerCli to be docker for OVB HA jobs.\n\nChange-Id: I5c2d230f5cc63009c7b02272112b2d4af4669da7\n""}, {'number': 2, 'created': '2019-03-05 00:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d8f901e6af8de365501046e5d300dcd3f4ac8cbc', 'message': ""ci/environments/ovb-ha: force Docker for ContainerCli\n\nUntil we get CentOS8, we can't test Pacemaker + Podman together, so\nuntil then we'll force ContainerCli to be docker for OVB HA jobs.\n\nDepends-On: I7fc9a880f15463fd7d95be5ae46c1c1d2f339448\nChange-Id: I5c2d230f5cc63009c7b02272112b2d4af4669da7\n""}, {'number': 3, 'created': '2019-03-05 13:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bd81c4704666e1db13d09afdc6710f4c2fe2064c', 'message': ""ci/environments/ovb-ha: force Docker for ContainerCli\n\nUntil we get CentOS8, we can't test Pacemaker + Podman together, so\nuntil then we'll force ContainerCli to be docker for OVB HA jobs.\n\nDepends-On: I7fc9a880f15463fd7d95be5ae46c1c1d2f339448\nChange-Id: I5c2d230f5cc63009c7b02272112b2d4af4669da7\n""}, {'number': 4, 'created': '2019-03-05 23:37:01.000000000', 'files': ['ci/environments/ovb-ha.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bb1a9ea628520c415643165241d2ac33cdd3360a', 'message': ""ci/environments/ovb-ha: force Docker for ContainerCli\n\nUntil we get CentOS8, we can't test Pacemaker + Podman together, so\nuntil then we'll force ContainerCli to be docker for OVB HA jobs.\n\nDepends-On: I2d8f484feb1b1fc2b88ab1f7b37b44324183643e\nChange-Id: I5c2d230f5cc63009c7b02272112b2d4af4669da7\n""}]",0,640897,bb1a9ea628520c415643165241d2ac33cdd3360a,21,7,4,3153,,,0,"ci/environments/ovb-ha: force Docker for ContainerCli

Until we get CentOS8, we can't test Pacemaker + Podman together, so
until then we'll force ContainerCli to be docker for OVB HA jobs.

Depends-On: I2d8f484feb1b1fc2b88ab1f7b37b44324183643e
Change-Id: I5c2d230f5cc63009c7b02272112b2d4af4669da7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/640897/4 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/ovb-ha.yaml'],1,7aebfb9291ecb6bf523362dbd17f354ce59238ea,podman/default, # Remove ContainerCli once OVB is tested on CentOS8 ContainerCli: docker,,2,0
openstack%2Ftripleo-quickstart-extras~master~Iab18d18187ada40773224d0c9cf283e01cec7130,openstack/tripleo-quickstart-extras,master,Iab18d18187ada40773224d0c9cf283e01cec7130,image build: temporarily add DIB debug flag,MERGED,2019-03-06 15:29:27.000000000,2019-03-06 23:12:50.000000000,2019-03-06 23:12:50.000000000,"[{'_account_id': 7118}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 15:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8dbf1af69096d91e04692bb20bbd9226436c8efb', 'message': ""image build: temporarily add DIB debug flag\n\nBug https://bugs.launchpad.net/tripleo/+bug/1818305 can't be easily replicated,\nand without additional information it's impossible to understand what's\nfailing.\nThis patch enables temporarily the debug flag that is usually excessively\nverbose to be kept enabled\n\nChange-Id: Iab18d18187ada40773224d0c9cf283e01cec7130\n""}, {'number': 2, 'created': '2019-03-06 15:33:04.000000000', 'files': ['roles/build-images/templates/overcloud-image-build.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0ec6046839890831b2fd85449e5ffdff1c9fe56a', 'message': ""image build: temporarily add DIB debug flag\n\nBug https://bugs.launchpad.net/tripleo/+bug/1818305 can't be easily replicated,\nand without additional information it's impossible to understand what's\nfailing.\nThis patch enables temporarily the debug flag that is usually excessively\nverbose to be kept enabled\n\nChange-Id: Iab18d18187ada40773224d0c9cf283e01cec7130\n""}]",1,641417,0ec6046839890831b2fd85449e5ffdff1c9fe56a,18,7,2,10022,,,0,"image build: temporarily add DIB debug flag

Bug https://bugs.launchpad.net/tripleo/+bug/1818305 can't be easily replicated,
and without additional information it's impossible to understand what's
failing.
This patch enables temporarily the debug flag that is usually excessively
verbose to be kept enabled

Change-Id: Iab18d18187ada40773224d0c9cf283e01cec7130
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/17/641417/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/build-images/templates/overcloud-image-build.sh.j2'],1,8dbf1af69096d91e04692bb20bbd9226436c8efb,enable-dib-logging,# TODO(gcerami): remove after https://bugs.launchpad.net/tripleo/+bug/1818305 # has a root cause export DIB_DEBUG_TRACE=1 ,,4,0
openstack%2Ftripleo-ci~master~I2d8f484feb1b1fc2b88ab1f7b37b44324183643e,openstack/tripleo-ci,master,I2d8f484feb1b1fc2b88ab1f7b37b44324183643e,ovb/CI: force ContainerCli to Docker,MERGED,2019-03-05 23:35:14.000000000,2019-03-06 23:12:49.000000000,2019-03-06 23:12:49.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 23:35:14.000000000', 'files': ['toci-quickstart/config/testenv/ovb.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ba77497ce22a1d098a4063f8a1b24f11b5128e27', 'message': ""ovb/CI: force ContainerCli to Docker\n\nFor the OVB jobs which still run Pacemaker, let's force ContainerCli until\nwe get them working with Podman.\n\nChange-Id: I2d8f484feb1b1fc2b88ab1f7b37b44324183643e\n""}]",0,641159,ba77497ce22a1d098a4063f8a1b24f11b5128e27,17,5,1,3153,,,0,"ovb/CI: force ContainerCli to Docker

For the OVB jobs which still run Pacemaker, let's force ContainerCli until
we get them working with Podman.

Change-Id: I2d8f484feb1b1fc2b88ab1f7b37b44324183643e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/59/641159/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/testenv/ovb.yml'],1,ba77497ce22a1d098a4063f8a1b24f11b5128e27,docker,# Remove ContainerCli once this scenario is tested on CentOS8 overcloud_container_cli: docker,,2,0
openstack%2Fpython-tripleoclient~stable%2Fqueens~Ieeeb88dbc10900aadba9c14200e0a154419ede8a,openstack/python-tripleoclient,stable/queens,Ieeeb88dbc10900aadba9c14200e0a154419ede8a,Handle workflow error for enable_ssh_admin,MERGED,2019-02-28 17:26:47.000000000,2019-03-06 23:07:03.000000000,2019-03-06 23:07:03.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-02-28 17:26:47.000000000', 'files': ['tripleoclient/workflows/deployment.py', 'tripleoclient/tests/workflows/test_deployment.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6b74184de3c39028b4549cad516a6e48dca9e692', 'message': 'Handle workflow error for enable_ssh_admin\n\nworkflow states can be FAILED or ERROR, we need to handle both.\n\nChange-Id: Ieeeb88dbc10900aadba9c14200e0a154419ede8a\nCloses-Bug: #1785621\n(cherry picked from commit d910d4a7a146b1e127f963f04c546b5c00c25305)\n'}]",0,640125,6b74184de3c39028b4549cad516a6e48dca9e692,12,6,1,25877,,,0,"Handle workflow error for enable_ssh_admin

workflow states can be FAILED or ERROR, we need to handle both.

Change-Id: Ieeeb88dbc10900aadba9c14200e0a154419ede8a
Closes-Bug: #1785621
(cherry picked from commit d910d4a7a146b1e127f963f04c546b5c00c25305)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/25/640125/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/deployment.py', 'tripleoclient/tests/workflows/test_deployment.py']",2,6b74184de3c39028b4549cad516a6e48dca9e692,bug/1785621,"from tripleoclient import exceptions @mock.patch('tripleoclient.workflows.deployment.wait_for_ssh_port') @mock.patch('tripleoclient.workflows.deployment.time.sleep') @mock.patch('tripleoclient.workflows.deployment.shutil.rmtree') @mock.patch('tripleoclient.workflows.deployment.open') @mock.patch('tripleoclient.workflows.deployment.tempfile') @mock.patch('tripleoclient.workflows.deployment.subprocess.check_call') def test_enable_ssh_admin_error(self, mock_check_call, mock_tempfile, mock_open, mock_rmtree, mock_sleep, mock_wait_for_ssh_port): log = mock.Mock() hosts = 'a', 'b', 'c' ssh_user = 'test-user' ssh_key = 'test-key' mock_tempfile.mkdtemp.return_value = '/foo' mock_read = mock.Mock() mock_read.read.return_value = 'key' mock_open.return_value = mock_read mock_state = mock.Mock() mock_state.state = 'ERROR' mock_state.to_dict.return_value = dict(state_info='an error') self.workflow.executions.get.return_value = mock_state self.assertRaises(exceptions.DeploymentError, deployment.enable_ssh_admin, log, self.app.client_manager, hosts, ssh_user, ssh_key)",,32,3
openstack%2Ftripleo-common~stable%2Fqueens~If1f35980a98a9015ca65f2c6a3e4db04725f1c10,openstack/tripleo-common,stable/queens,If1f35980a98a9015ca65f2c6a3e4db04725f1c10,Run NetworkDeployment as async task,MERGED,2019-02-14 14:55:53.000000000,2019-03-06 23:07:02.000000000,2019-03-06 23:07:02.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-02-14 14:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4267cae9908f859051561bbf58301268b96b8a27', 'message': 'Run NetworkDeployment as async task\n\nThis commit adds special handling of the NetworkDeployment such that it\nwill be run as an async task with ansible. This should prevent any\nissues where the network configuration causes the ssh connection to drop\nand the ansible task to either be unnecessarily retried or failed.\n\nAlso added are three variables that can be used to control the async\nbehavior:\n\nasync_deployment: boolean which will toggle running all deployments in\n                  async mode.\nasync_timeout:    timeout in seconds to wait for async tasks\nasync_poll:       interval in seconds to check async task status\n\nThese variables can only be set if running the config-download process\nmanually, however a future patch could wire them up to Heat parameters.\n\nChange-Id: If1f35980a98a9015ca65f2c6a3e4db04725f1c10\nCloses-Bug: #1792343\nUpstream-Rocky: https://review.openstack.org/#/c/611712/\n(cherry picked from commit ac4ac838e1a3eda32bbf8e9c0a61a89142688194)\n'}, {'number': 2, 'created': '2019-02-15 19:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3e05ffe0529db4b8709d7a165225e5bec26c86d5', 'message': 'Run NetworkDeployment as async task\n\nThis commit adds special handling of the NetworkDeployment such that it\nwill be run as an async task with ansible. This should prevent any\nissues where the network configuration causes the ssh connection to drop\nand the ansible task to either be unnecessarily retried or failed.\n\nAlso added are three variables that can be used to control the async\nbehavior:\n\nasync_deployment: boolean which will toggle running all deployments in\n                  async mode.\nasync_timeout:    timeout in seconds to wait for async tasks\nasync_poll:       interval in seconds to check async task status\n\nThese variables can only be set if running the config-download process\nmanually, however a future patch could wire them up to Heat parameters.\n\nChange-Id: If1f35980a98a9015ca65f2c6a3e4db04725f1c10\nCloses-Bug: #1792343\nUpstream-Rocky: https://review.openstack.org/#/c/611712/\n(cherry picked from commit ac4ac838e1a3eda32bbf8e9c0a61a89142688194)\n'}, {'number': 3, 'created': '2019-02-19 20:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/105ebaa13dc8780e0e7c6c8e53309125809abdc8', 'message': 'Run NetworkDeployment as async task\n\nThis commit adds special handling of the NetworkDeployment such that it\nwill be run as an async task with ansible. This should prevent any\nissues where the network configuration causes the ssh connection to drop\nand the ansible task to either be unnecessarily retried or failed.\n\nAlso added are three variables that can be used to control the async\nbehavior:\n\nasync_deployment: boolean which will toggle running all deployments in\n                  async mode.\nasync_timeout:    timeout in seconds to wait for async tasks\nasync_poll:       interval in seconds to check async task status\n\nThese variables can only be set if running the config-download process\nmanually, however a future patch could wire them up to Heat parameters.\n\nChange-Id: If1f35980a98a9015ca65f2c6a3e4db04725f1c10\nCloses-Bug: #1792343\n(cherry picked from commit ac4ac838e1a3eda32bbf8e9c0a61a89142688194)\n'}, {'number': 4, 'created': '2019-02-27 20:33:24.000000000', 'files': ['tripleo_common/templates/deployments.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a2550158e1aff6c0d6f23ec1bb7e19ab4c043b5e', 'message': 'Run NetworkDeployment as async task\n\nThis commit adds special handling of the NetworkDeployment such that it\nwill be run as an async task with ansible. This should prevent any\nissues where the network configuration causes the ssh connection to drop\nand the ansible task to either be unnecessarily retried or failed.\n\nAlso added are three variables that can be used to control the async\nbehavior:\n\nasync_deployment: boolean which will toggle running all deployments in\n                  async mode.\nasync_timeout:    timeout in seconds to wait for async tasks\nasync_poll:       interval in seconds to check async task status\n\nThese variables can only be set if running the config-download process\nmanually, however a future patch could wire them up to Heat parameters.\n\nChange-Id: If1f35980a98a9015ca65f2c6a3e4db04725f1c10\nCloses-Bug: #1792343\n(cherry picked from commit ac4ac838e1a3eda32bbf8e9c0a61a89142688194)\n'}]",4,636978,a2550158e1aff6c0d6f23ec1bb7e19ab4c043b5e,27,6,4,25877,,,0,"Run NetworkDeployment as async task

This commit adds special handling of the NetworkDeployment such that it
will be run as an async task with ansible. This should prevent any
issues where the network configuration causes the ssh connection to drop
and the ansible task to either be unnecessarily retried or failed.

Also added are three variables that can be used to control the async
behavior:

async_deployment: boolean which will toggle running all deployments in
                  async mode.
async_timeout:    timeout in seconds to wait for async tasks
async_poll:       interval in seconds to check async task status

These variables can only be set if running the config-download process
manually, however a future patch could wire them up to Heat parameters.

Change-Id: If1f35980a98a9015ca65f2c6a3e4db04725f1c10
Closes-Bug: #1792343
(cherry picked from commit ac4ac838e1a3eda32bbf8e9c0a61a89142688194)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/78/636978/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/templates/deployments.yaml'],1,4267cae9908f859051561bbf58301268b96b8a27,bug/1792343,"- name: Set fact for async_deployment set_fact: use_async_deployment: ""{{ (async_deployment | default(False)) or (item == 'NetworkDeployment') }}"" register: deployment_sync_result when: not use_async_deployment - name: ""Run async deployment {{ item }}"" shell: | /usr/libexec/os-refresh-config/configure.d/55-heat-config exit $(jq .deploy_status_code /var/lib/heat-config/deployed/{{ deployment_uuid }}.notify.json) become: true environment: HEAT_SHELL_CONFIG: /var/lib/heat-config/tripleo-config-download/{{ item ~ '-' ~ deployment_uuid }} register: deployment_async_result ignore_errors: yes when: use_async_deployment async: ""{{ async_timeout | default(300) }}"" poll: ""{{ async_poll | default(3) }}"" - name: ""Output for sync deployment {{ item }}"" - stderr: ""{{ deployment_sync_result.stderr.split('\n') }}"" - status_code: ""{{ deployment_sync_result.rc }}"" failed_when: deployment_sync_result.rc != 0 when: not ansible_check_mode and not use_async_deployment - name: ""Output for async deployment {{ item }}"" debug: msg: - stderr: ""{{ deployment_async_result.stderr.split('\n') }}"" - status_code: ""{{ deployment_async_result.rc }}"" tags: - output failed_when: deployment_async_result.rc != 0 when: not ansible_check_mode and use_async_deployment"," register: deployment_result - name: ""Output for {{ item }}"" - stderr: ""{{ deployment_result.stderr.split('\n') }}"" - status_code: ""{{ deployment_result.rc }}"" failed_when: deployment_result.rc != 0",34,5
openstack%2Ftripleo-quickstart-extras~master~Iea899b863b213095bed3b5a73a3943c8df309d2f,openstack/tripleo-quickstart-extras,master,Iea899b863b213095bed3b5a73a3943c8df309d2f,Adding test to skip list,MERGED,2019-03-06 16:02:35.000000000,2019-03-06 23:07:01.000000000,2019-03-06 23:07:01.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-03-06 16:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/dae4d9b73a9332d09a5695dcaf6f838a4a1e2308', 'message': 'Adding test to skip list\n\nundercloud containers job started to fail with this. A bug is opened,\nand while we work on the root cause, adding it to skip list.\n\nChange-Id: Iea899b863b213095bed3b5a73a3943c8df309d2f\nRelated-Bug: #1818860\n'}, {'number': 2, 'created': '2019-03-06 16:07:41.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6f66380490263ad4c55375509b878e38c6479604', 'message': 'Adding test to skip list\n\nundercloud containers job started to fail with this. A bug is opened,\nand while we work on the root cause, adding it to skip list.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/issue/829?kanban-status=2027734\n\nChange-Id: Iea899b863b213095bed3b5a73a3943c8df309d2f\nRelated-Bug: #1818860\n'}]",0,641429,6f66380490263ad4c55375509b878e38c6479604,13,11,2,8367,,,0,"Adding test to skip list

undercloud containers job started to fail with this. A bug is opened,
and while we work on the root cause, adding it to skip list.

https://tree.taiga.io/project/tripleo-ci-board/issue/829?kanban-status=2027734

Change-Id: Iea899b863b213095bed3b5a73a3943c8df309d2f
Related-Bug: #1818860
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/29/641429/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip_master.yml'],1,dae4d9b73a9332d09a5695dcaf6f838a4a1e2308,bug/1818860, - test: 'tempest.api.network.test_ports.PortsIpV6TestJSON.test_update_port_with_two_security_groups_and_extra_attributes' reason: 'Test is failing with SecurityGroupNotFound' lp: 'https://bugs.launchpad.net/tripleo/+bug/1818860',,3,0
openstack%2Ftripleo-quickstart~master~Ia6bb299171e7b7b44c898fa5907d30753859d0e9,openstack/tripleo-quickstart,master,Ia6bb299171e7b7b44c898fa5907d30753859d0e9,Add new nodes config for IPA job,MERGED,2019-03-04 10:38:23.000000000,2019-03-06 23:07:00.000000000,2019-03-06 23:07:00.000000000,"[{'_account_id': 8449}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}, {'_account_id': 28543}, {'_account_id': 29222}, {'_account_id': 29759}]","[{'number': 1, 'created': '2019-03-04 10:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8df1f368effcf1a011c35903cdd02198becd2021', 'message': 'Add new nodes config for IPA job\n\nChange-Id: Ia6bb299171e7b7b44c898fa5907d30753859d0e9\n'}, {'number': 2, 'created': '2019-03-04 11:20:06.000000000', 'files': ['config/nodes/1ctlr_2comp_1supp.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6d73679f5d590912f6d769fa836deed9e884acf3', 'message': 'Add new nodes config for IPA job\n\nChange-Id: Ia6bb299171e7b7b44c898fa5907d30753859d0e9\n'}]",1,640722,6d73679f5d590912f6d769fa836deed9e884acf3,27,9,2,10969,,,0,"Add new nodes config for IPA job

Change-Id: Ia6bb299171e7b7b44c898fa5907d30753859d0e9
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/22/640722/1 && git format-patch -1 --stdout FETCH_HEAD,['config/nodes/1ctlr_2comp_1supp.yml'],1,8df1f368effcf1a011c35903cdd02198becd2021,,# This config file is used to deploy a dedicated node on the virthost for TLS everywhere. # Define the controller node and compute nodes. # Create three controller nodes and one compute node. overcloud_nodes: - name: control_0 flavor: control virtualbmc_port: 6230 - name: compute_0 flavor: compute virtualbmc_port: 6231 - name: compute_1 flavor: compute virtualbmc_port: 6232 # Define the supplmental node to be used for the FreeIPA server. supplemental_node: name: ipa flavor: undercloud ,,21,0
openstack%2Ftripleo-heat-templates~master~Id1d671506d3ec827bc311b47d9363952e1239ce3,openstack/tripleo-heat-templates,master,Id1d671506d3ec827bc311b47d9363952e1239ce3,Do not restart bundles during a minor update,MERGED,2019-02-08 09:57:38.000000000,2019-03-06 23:06:58.000000000,2019-03-06 23:06:58.000000000,"[{'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 11090}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 09:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5ed8f0d3db8fdbb4bba6b2ca950c7eba3cf893df', 'message': 'WIP Do not restart rabbit bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway.\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n'}, {'number': 2, 'created': '2019-02-08 10:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/760e5cae054656c99698095c48661a14c3d10983', 'message': 'WIP Do not restart rabbit bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway.\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n'}, {'number': 3, 'created': '2019-02-19 17:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4f0672fb819661558a5fa06899ab09660f41136d', 'message': 'WIP Do not restart rabbit bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway.\n\nBy exporting the variable TRIPLEO_MINOR_UPDATE without a value we\ntell docker (and podman) to inherit this value from the host.\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n'}, {'number': 4, 'created': '2019-02-19 18:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6b2a85273c2ed6db202b31ff7b62bb3db74820dd', 'message': 'WIP Do not restart bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway. With change Ib3562adbd83f7162c2aeb450329b7cc4ab200fc2 we\ninject the TRIPLEO_MINOR_UDPATE variable into the update playbooks\nand we also push it (by default to false) inside the paunch start\ncontainer step.\n\nBy exporting the variable TRIPLEO_MINOR_UPDATE without a value we\ntell docker (and podman) to inherit this value from the host.\nWhen the env variable is set to true we avoid calling pcs inside\nthe containers to restart the bundles.\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n'}, {'number': 5, 'created': '2019-02-20 06:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/623b0af6d17663ea71dc0c36523be38c981b4e09', 'message': 'WIP Do not restart bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway. With change Ib3562adbd83f7162c2aeb450329b7cc4ab200fc2 we\ninject the TRIPLEO_MINOR_UDPATE variable into the update playbooks\nand we also push it (by default to false) inside the paunch start\ncontainer step.\n\nBy exporting the variable TRIPLEO_MINOR_UPDATE without a value we\ntell docker (and podman) to inherit this value from the host.\nWhen the env variable is set to true we avoid calling pcs inside\nthe containers to restart the bundles.\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n'}, {'number': 6, 'created': '2019-02-20 14:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8bbc1b7077866ab8c7ad562b4bef184de2d9176', 'message': ""Do not restart bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway. With change Ib3562adbd83f7162c2aeb450329b7cc4ab200fc2 we\ninject the TRIPLEO_MINOR_UDPATE variable into the update playbooks\nand we also push it (by default to false) inside the paunch start\ncontainer step.\n\nBy exporting the variable TRIPLEO_MINOR_UPDATE without a value we\ntell docker (and podman) to inherit this value from the host.\nWhen the env variable is set to true we avoid calling pcs inside\nthe containers to restart the bundles because at that point we\nknow that restarting the HA container would make no sense.\n\nWe tested the changes as follows:\nA) Ran a minor update (openstack overcloud update prepare + openstack\novercloud update run --roles Controller) and observed that there were no\nextra pcmk-managed bundles restarts (i.e. even when paunch decided to\ninvoke the <service>_restart_bundle it was a noop because\nTRIPLEO_MINOR_UDPATE was 'true')\nB) We ran a re-deploy without any changes and observed that no restart\nof pcmk-managed bundles took place\nC) We ran a re-deploy and forced some configuration changes and observed\nthat TRIPLEO_MINOR_UDPATE was false and that the\n<service>_restart_bundle was run by paunch and that it restarted the\nbundle that had the config changed.\n\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n""}, {'number': 7, 'created': '2019-03-01 17:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1b5f8dc34898cad436c35de76241a0feb26bba4c', 'message': ""Do not restart bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway. With change Ib3562adbd83f7162c2aeb450329b7cc4ab200fc2 we\ninject the TRIPLEO_MINOR_UDPATE variable into the update playbooks\nand we also push it (by default to false) inside the paunch start\ncontainer step.\n\nBy exporting the variable TRIPLEO_MINOR_UPDATE without a value we\ntell docker (and podman) to inherit this value from the host.\nWhen the env variable is set to true we avoid calling pcs inside\nthe containers to restart the bundles because at that point we\nknow that restarting the HA container would make no sense.\n\nWe tested the changes as follows:\nA) Ran a minor update (openstack overcloud update prepare + openstack\novercloud update run --roles Controller) and observed that there were no\nextra pcmk-managed bundles restarts (i.e. even when paunch decided to\ninvoke the <service>_restart_bundle it was a noop because\nTRIPLEO_MINOR_UDPATE was 'true')\nB) We ran a re-deploy without any changes and observed that no restart\nof pcmk-managed bundles took place\nC) We ran a re-deploy and forced some configuration changes and observed\nthat TRIPLEO_MINOR_UDPATE was false and that the\n<service>_restart_bundle was run by paunch and that it restarted the\nbundle that had the config changed.\n\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n""}, {'number': 8, 'created': '2019-03-06 07:41:16.000000000', 'files': ['deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e6ab4856d7982b208a16443dc3e7e0f3fd136113', 'message': ""Do not restart bundles during a minor update\n\nIt makes no sense since we are going to stop the cluster on the node\nanyway. With change Ib3562adbd83f7162c2aeb450329b7cc4ab200fc2 we\ninject the TRIPLEO_MINOR_UDPATE variable into the update playbooks\nand we also push it (by default to false) inside the paunch start\ncontainer step.\n\nBy exporting the variable TRIPLEO_MINOR_UPDATE without a value we\ntell docker (and podman) to inherit this value from the host.\nWhen the env variable is set to true we avoid calling pcs inside\nthe containers to restart the bundles because at that point we\nknow that restarting the HA container would make no sense.\n\nWe tested the changes as follows:\nA) Ran a minor update (openstack overcloud update prepare + openstack\novercloud update run --roles Controller) and observed that there were no\nextra pcmk-managed bundles restarts (i.e. even when paunch decided to\ninvoke the <service>_restart_bundle it was a noop because\nTRIPLEO_MINOR_UDPATE was 'true')\nB) We ran a re-deploy without any changes and observed that no restart\nof pcmk-managed bundles took place\nC) We ran a re-deploy and forced some configuration changes and observed\nthat TRIPLEO_MINOR_UDPATE was false and that the\n<service>_restart_bundle was run by paunch and that it restarted the\nbundle that had the config changed.\n\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\n\nChange-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3\n""}]",2,635731,e6ab4856d7982b208a16443dc3e7e0f3fd136113,38,7,8,20172,,,0,"Do not restart bundles during a minor update

It makes no sense since we are going to stop the cluster on the node
anyway. With change Ib3562adbd83f7162c2aeb450329b7cc4ab200fc2 we
inject the TRIPLEO_MINOR_UDPATE variable into the update playbooks
and we also push it (by default to false) inside the paunch start
container step.

By exporting the variable TRIPLEO_MINOR_UPDATE without a value we
tell docker (and podman) to inherit this value from the host.
When the env variable is set to true we avoid calling pcs inside
the containers to restart the bundles because at that point we
know that restarting the HA container would make no sense.

We tested the changes as follows:
A) Ran a minor update (openstack overcloud update prepare + openstack
overcloud update run --roles Controller) and observed that there were no
extra pcmk-managed bundles restarts (i.e. even when paunch decided to
invoke the <service>_restart_bundle it was a noop because
TRIPLEO_MINOR_UDPATE was 'true')
B) We ran a re-deploy without any changes and observed that no restart
of pcmk-managed bundles took place
C) We ran a re-deploy and forced some configuration changes and observed
that TRIPLEO_MINOR_UDPATE was false and that the
<service>_restart_bundle was run by paunch and that it restarted the
bundle that had the config changed.

Co-Authored-By: Damien Ciabrini <dciabrin@redhat.com>

Change-Id: Id1d671506d3ec827bc311b47d9363952e1239ce3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/31/635731/8 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml']",3,5ed8f0d3db8fdbb4bba6b2ca950c7eba3cf893df,minor-update-distinguish," '[ x""$TRIPLEO_MINOR_UPDATE"" != x""true"" ] && if /usr/sbin/pcs resource show rabbitmq-bundle; then /usr/sbin/pcs resource restart --wait=PCMKTIMEOUT rabbitmq-bundle; echo ""rabbitmq-bundle restart invoked""; fi'"," 'if /usr/sbin/pcs resource show rabbitmq-bundle; then /usr/sbin/pcs resource restart --wait=PCMKTIMEOUT rabbitmq-bundle; echo ""rabbitmq-bundle restart invoked""; fi'",3,3
openstack%2Fcinder~master~Ice7b6dbf46e545c669e9d581fa0dc785e9d18828,openstack/cinder,master,Ice7b6dbf46e545c669e9d581fa0dc785e9d18828,Update oslo.privsep minimum requirement,MERGED,2019-03-01 16:40:58.000000000,2019-03-06 22:58:02.000000000,2019-03-04 23:50:03.000000000,"[{'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 20284}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29637}]","[{'number': 1, 'created': '2019-03-01 16:40:58.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a9a6abe07303da8be35ae8a47713ee2f1b887c5f', 'message': ""Update oslo.privsep minimum requirement\n\nI should have done this as part of\nI59702c8b84bbcf21d32150ede0a3758d1a456bd6 since older releases don't\nhave the necessary entrypoint exposed.\n\nChange-Id: Ice7b6dbf46e545c669e9d581fa0dc785e9d18828\n""}]",0,640432,a9a6abe07303da8be35ae8a47713ee2f1b887c5f,34,27,1,6928,,,0,"Update oslo.privsep minimum requirement

I should have done this as part of
I59702c8b84bbcf21d32150ede0a3758d1a456bd6 since older releases don't
have the necessary entrypoint exposed.

Change-Id: Ice7b6dbf46e545c669e9d581fa0dc785e9d18828
",git fetch https://review.opendev.org/openstack/cinder refs/changes/32/640432/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,a9a6abe07303da8be35ae8a47713ee2f1b887c5f,privsep-config-generator,oslo.privsep==1.32.0,oslo.privsep==1.23.0,2,2
openstack%2Fpython-barbicanclient~master~Ib304b1240cefacf28e29064318db495aa6b8ec25,openstack/python-barbicanclient,master,Ib304b1240cefacf28e29064318db495aa6b8ec25,add python 3.7 unit test job,MERGED,2019-02-15 21:05:55.000000000,2019-03-06 22:57:59.000000000,2019-03-06 22:57:59.000000000,"[{'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 21:05:55.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/0d2e620fbbbb22c7cf4eec6383b9cd354bbf6a41', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: Ib304b1240cefacf28e29064318db495aa6b8ec25\nStory: #2004073\nTask: #27403\n'}]",0,637307,0d2e620fbbbb22c7cf4eec6383b9cd354bbf6a41,7,3,1,11805,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: Ib304b1240cefacf28e29064318db495aa6b8ec25
Story: #2004073
Task: #27403
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/07/637307/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0d2e620fbbbb22c7cf4eec6383b9cd354bbf6a41,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fos-net-config~master~I7c85ab380dc4f0377a65fc954fcce3e3d39f5029,openstack/os-net-config,master,I7c85ab380dc4f0377a65fc954fcce3e3d39f5029,Configure switchdev mode in SR-IOV in os-net-config,MERGED,2019-01-30 08:24:23.000000000,2019-03-06 22:52:02.000000000,2019-03-06 22:52:02.000000000,"[{'_account_id': 6926}, {'_account_id': 10873}, {'_account_id': 12171}, {'_account_id': 12398}, {'_account_id': 16690}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25241}, {'_account_id': 26682}]","[{'number': 1, 'created': '2019-01-30 08:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/00c98c85313e46dc4402a61c93f700875791aec2', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 2, 'created': '2019-02-04 12:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/539615fc53027b303223d7e2bcb1f85dd30247f3', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 3, 'created': '2019-02-25 09:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/ef16d3f452b5815a46fd337d8cb016e2aa453734', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 4, 'created': '2019-02-25 09:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/4665ee9c904acc31cffeff5d1fa377a35bf52913', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 5, 'created': '2019-02-26 08:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/6250885d5ef6246b195fe89c2f18bc1241b3ad9e', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 6, 'created': '2019-02-26 11:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/1d5a20e6d53ea510a31cece3f4c7856736f54acb', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 7, 'created': '2019-02-27 07:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/c63a8462e490fa5fa019e42f1fd72a8e1966290b', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 8, 'created': '2019-02-27 07:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/fb460afdeb0be1f5d16aafb0d6efd41c5dfdcef3', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 9, 'created': '2019-02-27 10:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/b8d976fb7b3cebd7a050a024cf17aa4f362a3267', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 10, 'created': '2019-02-27 10:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/2cb05700a2b609c2340fb43c4de2b2c0c7fe3a52', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\n'}, {'number': 11, 'created': '2019-02-28 08:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/e6b7a5370e78627a404b2848203cc0003e276553', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\nCloses-Bug: #1818034\n'}, {'number': 12, 'created': '2019-02-28 09:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/3b98ce9839cdb059bc89801794f5221e320dcce2', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\nCloses-Bug: #1818034\n'}, {'number': 13, 'created': '2019-02-28 10:01:45.000000000', 'files': ['os_net_config/schema.yaml', 'os_net_config/utils.py', 'os_net_config/tests/test_objects.py', 'os_net_config/tests/test_impl_ifcfg.py', 'os_net_config/tests/test_utils.py', 'os_net_config/impl_ifcfg.py', 'etc/os-net-config/samples/sriov_pf_switchdev.json', 'etc/os-net-config/samples/sriov_pf_switchdev.yaml', 'os_net_config/objects.py', 'os_net_config/sriov_config.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/3dcad07311be36161529069fdd14107aa2142ee2', 'message': 'Configure switchdev mode in SR-IOV in os-net-config\n\nWhile sriov vfs are created now using os-net-config,\nso doing some modification to configure switchdev mode there\n\nChange-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029\nCloses-Bug: #1818034\n'}]",9,633885,3dcad07311be36161529069fdd14107aa2142ee2,58,11,13,25241,,,0,"Configure switchdev mode in SR-IOV in os-net-config

While sriov vfs are created now using os-net-config,
so doing some modification to configure switchdev mode there

Change-Id: I7c85ab380dc4f0377a65fc954fcce3e3d39f5029
Closes-Bug: #1818034
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/85/633885/13 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/schema.yaml', 'os_net_config/utils.py', 'os_net_config/impl_ifcfg.py', 'os_net_config/objects.py', 'os_net_config/sriov_config.py']",5,00c98c85313e46dc4402a61c93f700875791aec2,bug/1818034,"import re unbind_file = ""/sys/bus/pci/drivers/mlx5_core/unbind"" # Configure switchdev mode vendor_path = (""/sys/class/net/%s/device/vendor"" % item['name']) vendor = get_file_data(vendor_path).strip() if item['link_mode'] == ""switchdev"" and vendor == ""0x15b3"": vf_pcis_list = get_vf_pcis_list(item['name']) for vf_pci in vf_pcis_list: vf_pci_path = ""/sys/bus/pci/devices/%s/driver"" % vf_pci if os.path.exists(vf_pci_path): with open(unbind_file, 'w') as f: f.write(""%s"" % vf_pci) configure_switchdev(item['name']) def configure_switchdev(pf_name): pf_pci = get_pf_pci(pf_name) pf_device_id = get_pf_device_id(pf_name) if pf_device_id == ""0x1013"" or pf_device_id == ""0x1015"": try: processutils.execute('/usr/sbin/devlink', 'dev', 'eswitch', 'set', 'pci/%s' % pf_pci, 'inline-mode', 'transport') except processutils.ProcessExecutionError: logger.error(""Failed to execute %s"" % ' '.join(cmd)) raise try: processutils.execute('/usr/sbin/devlink', 'dev', 'eswitch', 'set', 'pci/%s' % pf_pci, 'mode', 'switchdev') except processutils.ProcessExecutionError: logger.error(""Failed to execute %s"" % ' '.join(cmd)) raise try: processutils.execute('/usr/sbin/ethtool', '-K', pf_name, 'hw-tc-offload', 'on') except processutils.ProcessExecutionError: logger.error(""Failed to execute %s"" % ' '.join(cmd)) raise def get_pf_pci(pf_name): pf_pci_path = ""/sys/class/net/%s/device/uevent"" % pf_name pf_info = get_file_data(pf_pci_path) pf_pci = re.search(r'PCI_SLOT_NAME=(.*)',pf_info,re.MULTILINE).group(1) return pf_pci def get_pf_device_id(pf_name): pf_device_path = ""/sys/class/net/%s/device/device"" % pf_name pf_device_id = get_file_data(pf_device_path).strip() return pf_device_id def get_vf_pcis_list(pf_name): vf_pcis_list = [] listOfPfFiles = os.listdir(""/sys/class/net/%s/device/"" % pf_name) for pf_file in listOfPfFiles: if pf_file.startswith(""virtfn""): vf_info = get_file_data(""/sys/class/net/%s/device/%s/uevent"" % (pf_name, pf_file)) vf_pcis_list.append(re.search(r'PCI_SLOT_NAME=(.*)', vf_info,re.MULTILINE).group(1)) return vf_pcis_list ",,77,4
openstack%2Fmagnum~master~Ie8d73247ba95f20e24d6cae27963d18b35f8715a,openstack/magnum,master,Ie8d73247ba95f20e24d6cae27963d18b35f8715a,make sure to set node_affinity_policy for Mesos template definition,MERGED,2019-03-01 23:50:44.000000000,2019-03-06 22:38:49.000000000,2019-03-06 21:10:57.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 23:50:44.000000000', 'files': ['magnum/tests/unit/drivers/test_template_definition.py', 'releasenotes/notes/affinity-policy-for-mesos-template-def-82627eb231aa4d28.yaml', 'magnum/drivers/mesos_ubuntu_v1/template_def.py', 'magnum/tests/unit/conductor/handlers/test_mesos_cluster_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/a47f5a39944920f694114c0e1cb964bbf60c93ba', 'message': 'make sure to set node_affinity_policy for Mesos template definition\n\nFixes the problem with Mesos cluster creation where the\nnodes_affinity_policy was not properly conveyed as it is required\nin order to create the corresponding server group in Nova.\n\nChange-Id: Ie8d73247ba95f20e24d6cae27963d18b35f8715a\nstory: 2005116\n'}]",0,640556,a47f5a39944920f694114c0e1cb964bbf60c93ba,8,3,1,1916,,,0,"make sure to set node_affinity_policy for Mesos template definition

Fixes the problem with Mesos cluster creation where the
nodes_affinity_policy was not properly conveyed as it is required
in order to create the corresponding server group in Nova.

Change-Id: Ie8d73247ba95f20e24d6cae27963d18b35f8715a
story: 2005116
",git fetch https://review.opendev.org/openstack/magnum refs/changes/56/640556/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/drivers/test_template_definition.py', 'releasenotes/notes/affinity-policy-for-mesos-template-def-82627eb231aa4d28.yaml', 'magnum/drivers/mesos_ubuntu_v1/template_def.py', 'magnum/tests/unit/conductor/handlers/test_mesos_cluster_conductor.py']",4,a47f5a39944920f694114c0e1cb964bbf60c93ba,story-2005116, 'nodes_affinity_policy': 'soft-anti-affinity' 'nodes_affinity_policy': 'soft-anti-affinity' 'nodes_affinity_policy': 'soft-anti-affinity' 'nodes_affinity_policy': 'soft-anti-affinity' 'nodes_affinity_policy': 'soft-anti-affinity',,22,0
openstack%2Fopenstack-helm-infra~master~I44d24a5d8fa0517369d5cdfde8882d017278c547,openstack/openstack-helm-infra,master,I44d24a5d8fa0517369d5cdfde8882d017278c547,Add mariadb and postgresql backup and restore * backup script for mariadb and postgres * restore script for mariadb and postgres * cronjob for automated backup mariadb and postgres * add parameters to values.yaml,ABANDONED,2019-02-20 23:08:04.000000000,2019-03-06 22:32:43.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 29268}, {'_account_id': 29668}]","[{'number': 1, 'created': '2019-02-20 23:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6856e45c5baa2df839f7ef8f3920aca710664f9d', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 2, 'created': '2019-02-21 00:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b15bfc0c802aa40eeaca1017370ebba98cf209a9', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 3, 'created': '2019-02-21 01:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c26185d6636c7647938bf50406c08a636dfb3a57', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 4, 'created': '2019-02-21 04:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/689567f77717ee899a949f6e78eb533d984b6891', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 5, 'created': '2019-02-21 22:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/217f38feeb1aca44316f9dbcf4c176c4a514c201', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 6, 'created': '2019-03-05 01:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cccafb4daa871c9aca9ced0c45c7fcb75c4f544b', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 7, 'created': '2019-03-05 02:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7882c462caaa118ab184ec8b97c322ca6325eccf', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 8, 'created': '2019-03-05 15:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/25d3bb1aa79e331955c7c3bad929f141d81f8b2d', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 9, 'created': '2019-03-05 18:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9a85bfc696190ad44c4a869cdcbb9e8b4944592d', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}, {'number': 10, 'created': '2019-03-05 21:48:13.000000000', 'files': ['postgresql/templates/configmap-bin.yaml', 'postgresql/templates/bin/_backup_postgresql.sh.tpl', 'mariadb/templates/bin/_backup_mariadb.sh.tpl', 'mariadb/templates/cron-job-backup-mariadb.yaml', 'postgresql/templates/cron-job-backup-postgres.yaml', 'mariadb/values.yaml', 'mariadb/templates/configmap-bin.yaml', 'postgresql/values.yaml', 'tools/images/mariadb-backup/Dockerfile'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/757b8179e638166104963c3fe47aad472175e1e8', 'message': 'Add mariadb and postgresql backup and restore\n* backup script for mariadb and postgres\n* restore script for mariadb and postgres\n* cronjob for automated backup mariadb and postgres\n* add parameters to values.yaml\n\nChange-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547\nSigned-off-by: Koffi Nogbe <kn4078@att.com>\n'}]",4,638290,757b8179e638166104963c3fe47aad472175e1e8,25,4,10,28875,,,0,"Add mariadb and postgresql backup and restore
* backup script for mariadb and postgres
* restore script for mariadb and postgres
* cronjob for automated backup mariadb and postgres
* add parameters to values.yaml

Change-Id: I44d24a5d8fa0517369d5cdfde8882d017278c547
Signed-off-by: Koffi Nogbe <kn4078@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/90/638290/10 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/templates/configmap-bin.yaml', 'postgresql/templates/bin/_backup_postgresql.sh.tpl', 'mariadb/templates/bin/_backup_mariadb.sh.tpl', 'mariadb/templates/cron-job-backup-mariadb.yaml', 'postgresql/templates/cron-job-backup-postgres.yaml', 'mariadb/templates/configmap-bin.yaml', 'mariadb/values.yaml', 'postgresql/templates/bin/_restore_postgresql.sh.tpl', 'postgresql/values.yaml', 'mariadb/templates/bin/_restore_mariadb.sh.tpl']",10,6856e45c5baa2df839f7ef8f3920aca710664f9d,database-backup,"#!/bin/bash # Copyright 2018 The Openstack-Helm Authors. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. set -e #database info DBHOST=$MARIADB_SERVER_SERVICE_HOST DBUSER=$MARIADB_BACKUP_USER DBPASSWD=$MARIADB_BACKUP_PASSWORD NS=$MARIADB_POD_NAMESPACE set -xe DAYS_TO_KEEP=3 BASE_DIR=$MARIADB_BACKUP_BASE #Restore option: restoreonly, restoreandimport RESTORE_OPTION=restoreandimport BACKUPS_DIR=${BASE_DIR}/db/${NS}/mariadb/current ARCHIVE_DIR=${BASE_DIR}/db/${NS}/mariadb/archive RESTORE_DIR=${BASE_DIR}/db/${NS}/mariadb/restore DEFAULT_ARCHIVE= #Creating credential file to hide credential from command line #TODD: Credential will be retrieve from kubernetes secret doc later cat <<EOF >~/.my.cnf [client] user=$DBUSER password=$DBPASSWD host=$DBHOST EOF #Get the latest archive for restore LATEST_ARCHIVE=`ls -ltr ${ARCHIVE_DIR}/* | tail -1 | awk '{ print $9 }'` #Create the directory if not exist mkdir -p $RESTORE_DIR #Untar the backup to the restore directory tar zxvf $LATEST_ARCHIVE -C $RESTORE_DIR/ #list all databases backups cd $RESTORE_DIR DATABASE=`for f in *.sql; do printf '%s\n' ""${f%.sql}"" done` #restore all databases if [ ""$RESTORE_OPTION"" = ""restoreandimport"" ] then for db in $DATABASE; do echo ""Creating Database $db if it does not exist"" mysql -e ""CREATE DATABASE IF NOT EXISTS \`$db\`"" echo ""Importing data to database $db"" mysql $db < $RESTORE_DIR/$db.sql done echo ""Database Import complete."" fi ",,478,0
openstack%2Fbarbican-specs~master~If51b4bc139846f8315f228708d9b82df36723ed8,openstack/barbican-specs,master,If51b4bc139846f8315f228708d9b82df36723ed8,Create blueprint for restoring secrets,ABANDONED,2016-01-13 16:57:11.000000000,2019-03-06 22:30:52.000000000,,"[{'_account_id': 7973}, {'_account_id': 14926}, {'_account_id': 16046}, {'_account_id': 17579}]","[{'number': 1, 'created': '2016-01-13 16:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/9fc55a51537d60296219c76cb4f2a3621db5b03f', 'message': 'Create blueprint for restoring secrets\n\nA user may accidently delete their secret. This gives the barbican\nadmin to be able to restore their secret.\n\nChange-Id: If51b4bc139846f8315f228708d9b82df36723ed8\n'}, {'number': 2, 'created': '2016-01-13 17:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/8089e9017184355c50c35e29eb91f583f5d0f321', 'message': 'Create blueprint for restoring secrets\n\nA user may accidently delete their secret. This gives the barbican\nadmin to be able to restore their secret.\n\nChange-Id: If51b4bc139846f8315f228708d9b82df36723ed8\n'}, {'number': 3, 'created': '2016-02-03 15:04:30.000000000', 'files': ['doc/source/index.rst', 'specs/mitaka/restore-secrets.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/49371f7d443b65a674ee3ac016aa8b9db787db12', 'message': 'Create blueprint for restoring secrets\n\nA user may accidently delete their secret. This gives the barbican\nsystem admin to be able to restore their secret.\n\nChange-Id: If51b4bc139846f8315f228708d9b82df36723ed8\n'}]",15,267030,49371f7d443b65a674ee3ac016aa8b9db787db12,16,4,3,17579,,,0,"Create blueprint for restoring secrets

A user may accidently delete their secret. This gives the barbican
system admin to be able to restore their secret.

Change-Id: If51b4bc139846f8315f228708d9b82df36723ed8
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/30/267030/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/mitaka/restore-secrets.rst']",2,9fc55a51537d60296219c76cb4f2a3621db5b03f,bp/for,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================= Add feature for restoring user secrets ======================================= Blueprint: https://blueprints.launchpad.net/barbican/+spec/barbican-db-garbage-management Problem Description =================== Barbican can use soft-deletions in the database. This means that the entry is marked for deletion but not removed. A user may accidently delete a secret that contains their encryption key. They would not be able to recover an encrypted volume. Proposed Change =============== The barbican operator will have access to a script that can restore deleted secrets that have not been purged from the database. The barbican operator will be able use run a barbican-manage command to restore a secret by id. Example: barbican-manage db restore --secret-id <soft deleted secret_id> Alternatives ------------ 1. Add a REST API call (HTTP PATCH verb) for undeleting a secret and make this command available in the barbican-client. This would let the user to be able to undelete their accidents themselves. Data model impact ----------------- This script affects the secret model since it looks for secrets where 'deleted == 1'. REST API impact --------------- None Security impact --------------- The script should have valid barbican admin user permissions. No global user should be able to modify/run the script. Notifications & Audit Impact ---------------------------- A log should be kept that contains the information for which secret was undeleted. This information includes uuid of the secret, date when deleted, date when restored, and ID of who deleted the secret. Python and Command Line Client Impact ------------------------------------- None Other end user impact --------------------- User will have to go to the barbican operator and ask to have their secret undeleted. Performance Impact ------------------ Since this is a feature that should be used sparingly, it should not be too much of a performance impact. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: edtubill Other contributors: None Work Items ---------- Work Item 1: Create functionality and tests for restoring secret Work Item 2: Add documentation to a wiki. Dependencies ============ None Testing ======= Tests will be created to test out the restoration of secrets. Documentation Impact ==================== Documentation on usage of the undelete script will be created. This feature should be used when soft-deletion is enabled. References ========== https://blueprints.launchpad.net/barbican/+spec/barbican-db-garbage-management ",,157,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~If940f31316b3cc86df660f5600834ef5fb9d0379,openstack/tripleo-heat-templates,stable/queens,If940f31316b3cc86df660f5600834ef5fb9d0379,(Queens only) Remove privileged capabilities from nova-metadata,MERGED,2019-03-05 14:48:35.000000000,2019-03-06 22:30:03.000000000,2019-03-06 22:30:03.000000000,"[{'_account_id': 3153}, {'_account_id': 7973}, {'_account_id': 9098}, {'_account_id': 10873}, {'_account_id': 14250}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-03-05 14:48:35.000000000', 'files': ['docker/services/nova-metadata.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6d44ae7b6d20c883ee60862777b15d4cd62b2d8e', 'message': '(Queens only) Remove privileged capabilities from nova-metadata\n\nThis is unnecessary and a bad practice.\n\nChange-Id: If940f31316b3cc86df660f5600834ef5fb9d0379\nCloses-Bug: #1818675\n'}]",0,641025,6d44ae7b6d20c883ee60862777b15d4cd62b2d8e,12,11,1,10873,,,0,"(Queens only) Remove privileged capabilities from nova-metadata

This is unnecessary and a bad practice.

Change-Id: If940f31316b3cc86df660f5600834ef5fb9d0379
Closes-Bug: #1818675
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/641025/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/nova-metadata.yaml'],1,6d44ae7b6d20c883ee60862777b15d4cd62b2d8e,bug/1818675,, privileged: true,0,1
openstack%2Ftripleo-heat-templates~master~Ifcb5b0e940e73fb78cd1a9e659b4a22890688198,openstack/tripleo-heat-templates,master,Ifcb5b0e940e73fb78cd1a9e659b4a22890688198,Flatten and move logrotate-crond service container,MERGED,2019-03-06 10:06:27.000000000,2019-03-06 22:30:00.000000000,2019-03-06 22:30:00.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 10:06:27.000000000', 'files': ['environments/docker-uc-light.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'deployment/logrotate/logrotate-crond-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4453d1dc38d84e5cd29ae3d38d40b76627d06dfc', 'message': 'Flatten and move logrotate-crond service container\n\nChange-Id: Ifcb5b0e940e73fb78cd1a9e659b4a22890688198\n'}]",0,641290,4453d1dc38d84e5cd29ae3d38d40b76627d06dfc,8,4,1,28223,,,0,"Flatten and move logrotate-crond service container

Change-Id: Ifcb5b0e940e73fb78cd1a9e659b4a22890688198
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/641290/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/docker-uc-light.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'deployment/logrotate/logrotate-crond-container-puppet.yaml']",3,4453d1dc38d84e5cd29ae3d38d40b76627d06dfc,bp/services-yaml-flattening, type: ../../docker/services/containers-common.yaml, type: ./containers-common.yaml ,3,4
openstack%2Fhorizon~master~Ie85cf4be3da1ab446c10883a4580e20ea154b67c,openstack/horizon,master,Ie85cf4be3da1ab446c10883a4580e20ea154b67c,Add a upgrade_check management command,MERGED,2019-01-18 12:13:58.000000000,2019-03-06 22:28:31.000000000,2019-03-06 22:28:31.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-01-18 12:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9fecbb04dd4457072b9682dda61b0e429acce34e', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 2, 'created': '2019-01-18 14:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5852d9a1bc5ea734f7955b781725f75ba5509360', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 3, 'created': '2019-01-21 11:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c08323b007658937a59db0af2df22ea03bc115c6', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 4, 'created': '2019-01-21 11:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/60080095af1d1725c7d13e5b003ff7becca63838', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 5, 'created': '2019-01-21 11:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ac95df64f27bdd6aa61fbe620d4c69e7358c2990', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 6, 'created': '2019-01-21 12:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c4e5c97597583fa82d70499298d10998f3d4dbc6', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 7, 'created': '2019-01-21 13:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b5ffb94b72eb7aa5f95d333a14b02b5d05f4e9d', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 8, 'created': '2019-01-21 16:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/adaeafbd1ea9eebc4a84294e29e491a174279aa3', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\n'}, {'number': 9, 'created': '2019-01-23 12:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a056ccd81f160f54d2d8c0f58073988b2044303c', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26157\n'}, {'number': 10, 'created': '2019-01-24 09:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4cd14e4d510853c510d36b8661d0f6564a641b52', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}, {'number': 11, 'created': '2019-02-28 11:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c5ad60674643d8881c34901db999863ecbe6d0b1', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nThere is also a script in tools/find_settings.py that scans all python\nfiles for the potential new settings, which is supposed to make it\neasier to update the lists that the checks use.\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}, {'number': 12, 'created': '2019-02-28 11:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8590886279016ff0c77b0164b59f96ab330bce91', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nThere is also a script in tools/find_settings.py that scans all python\nfiles for the potential new settings, which is supposed to make it\neasier to update the lists that the checks use.\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}, {'number': 13, 'created': '2019-02-28 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a3e6db24c3cff22178022e0731a1244fe4057363', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nThere is also a script in tools/find_settings.py that scans all python\nfiles for the potential new settings, which is supposed to make it\neasier to update the lists that the checks use.\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}, {'number': 14, 'created': '2019-02-28 11:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d5869e510c4f6de1215cbc21a571d6ef3d6eecf4', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nThere is also a script in tools/find_settings.py that scans all python\nfiles for the potential new settings, which is supposed to make it\neasier to update the lists that the checks use.\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}, {'number': 15, 'created': '2019-03-01 13:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/375f8ef56f92c02f97d2235733b6d9b5d2c6ed4a', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nThere is also a script in tools/find_settings.py that scans all python\nfiles for the potential new settings, which is supposed to make it\neasier to update the lists that the checks use.\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}, {'number': 16, 'created': '2019-03-01 14:43:27.000000000', 'files': ['openstack_dashboard/management/commands/upgrade_check.py', 'requirements.txt', 'tools/executable_files.txt', 'lower-constraints.txt', 'releasenotes/notes/story-2003657-79dec309cb6fa060.yaml', 'tools/find_settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d7d6c0577cb507484ca3f21b1b110130a0fc1d15', 'message': 'Add a upgrade_check management command\n\nThis command checks the configuration for invalid and deprecated\nsettings, as described in\nhttps://governance.openstack.org/tc/goals/stein/upgrade-checkers.html\n\nThere is also a script in tools/find_settings.py that scans all python\nfiles for the potential new settings, which is supposed to make it\neasier to update the lists that the checks use.\n\nChange-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c\nStory: 2003657\nTask: 26132\n'}]",18,631785,d7d6c0577cb507484ca3f21b1b110130a0fc1d15,57,5,16,8648,,,0,"Add a upgrade_check management command

This command checks the configuration for invalid and deprecated
settings, as described in
https://governance.openstack.org/tc/goals/stein/upgrade-checkers.html

There is also a script in tools/find_settings.py that scans all python
files for the potential new settings, which is supposed to make it
easier to update the lists that the checks use.

Change-Id: Ie85cf4be3da1ab446c10883a4580e20ea154b67c
Story: 2003657
Task: 26132
",git fetch https://review.opendev.org/openstack/horizon refs/changes/85/631785/16 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/management/commands/upgrade_check.py'],1,9fecbb04dd4457072b9682dda61b0e429acce34e,upgrade-checkers,"from __future__ import print_function import prettytable import json from django.core.management.base import BaseCommand from django.conf import settings from django.utils.translation import ugettext_lazy as _ SUCCESS = 0 WARNING = 1 ERROR = 2 CODES = (_(""Success""), _(""Warning""), _(""Error"")) CHECKS = [] def register_check(name): def register(func): CHECKS.append((name, func)) return register @register_check(_(""Invalid Settings"")) def check_invalid_settings(): VALID_SETTINGS = { 'ABSOLUTE_URL_OVERRIDES', 'ADD_INSTALLED_APPS', 'ADD_TEMPLATE_LOADERS', 'ADMINS', 'ALLOWED_HOSTS', 'ALLOWED_PRIVATE_SUBNET_CIDR', 'ANGULAR_FEATURES', 'API_RESULT_LIMIT', 'API_RESULT_PAGE_SIZE', 'APPEND_SLASH', 'AUTHENTICATION_BACKENDS', 'AUTHENTICATION_URLS', 'AUTH_PASSWORD_VALIDATORS', 'AUTH_USER_MODEL', 'AVAILABLE_THEMES', 'CACHED_TEMPLATE_LOADERS', 'CACHES', 'CACHE_MIDDLEWARE_ALIAS', 'CACHE_MIDDLEWARE_KEY_PREFIX', 'CACHE_MIDDLEWARE_SECONDS', 'COMPRESS_CACHEABLE_PRECOMPILERS', 'COMPRESS_CACHE_BACKEND', 'COMPRESS_CACHE_KEY_FUNCTION', 'COMPRESS_CLEAN_CSS_ARGUMENTS', 'COMPRESS_CLEAN_CSS_BINARY', 'COMPRESS_CLOSURE_COMPILER_ARGUMENTS', 'COMPRESS_CLOSURE_COMPILER_BINARY', 'COMPRESS_CSS_COMPRESSOR', 'COMPRESS_CSS_FILTERS', 'COMPRESS_CSS_HASHING_METHOD', 'COMPRESS_DATA_URI_MAX_SIZE', 'COMPRESS_DEBUG_TOGGLE', 'COMPRESS_ENABLED', 'COMPRESS_JINJA2_GET_ENVIRONMENT', 'COMPRESS_JS_COMPRESSOR', 'COMPRESS_JS_FILTERS', 'COMPRESS_MINT_DELAY', 'COMPRESS_MTIME_DELAY', 'COMPRESS_OFFLINE', 'COMPRESS_OFFLINE_CONTEXT', 'COMPRESS_OFFLINE_MANIFEST', 'COMPRESS_OFFLINE_TIMEOUT', 'COMPRESS_OUTPUT_DIR', 'COMPRESS_PARSER', 'COMPRESS_PRECOMPILERS', 'COMPRESS_REBUILD_TIMEOUT', 'COMPRESS_ROOT', 'COMPRESS_STORAGE', 'COMPRESS_TEMPLATE_FILTER_CONTEXT', 'COMPRESS_URL', 'COMPRESS_URL_PLACEHOLDER', 'COMPRESS_VERBOSE', 'COMPRESS_YUGLIFY_BINARY', 'COMPRESS_YUGLIFY_CSS_ARGUMENTS', 'COMPRESS_YUGLIFY_JS_ARGUMENTS', 'COMPRESS_YUI_BINARY', 'COMPRESS_YUI_CSS_ARGUMENTS', 'COMPRESS_YUI_JS_ARGUMENTS', 'CSRF_COOKIE_AGE', 'CSRF_COOKIE_DOMAIN', 'CSRF_COOKIE_HTTPONLY', 'CSRF_COOKIE_NAME', 'CSRF_COOKIE_PATH', 'CSRF_COOKIE_SECURE', 'CSRF_FAILURE_VIEW', 'CSRF_HEADER_NAME', 'CSRF_TRUSTED_ORIGINS', 'CSRF_USE_SESSIONS', 'DATABASES', 'DATABASE_ROUTERS', 'DATA_UPLOAD_MAX_MEMORY_SIZE', 'DATA_UPLOAD_MAX_NUMBER_FIELDS', 'DATETIME_FORMAT', 'DATETIME_INPUT_FORMATS', 'DATE_FORMAT', 'DATE_INPUT_FORMATS', 'DEBUG', 'DEBUG_PROPAGATE_EXCEPTIONS', 'DECIMAL_SEPARATOR', 'DEFAULT_CHARSET', 'DEFAULT_CONTENT_TYPE', 'DEFAULT_EXCEPTION_REPORTER_FILTER', 'DEFAULT_FILE_STORAGE', 'DEFAULT_FROM_EMAIL', 'DEFAULT_INDEX_TABLESPACE', 'DEFAULT_TABLESPACE', 'DEFAULT_THEME', 'DISALLOWED_USER_AGENTS', 'DROPDOWN_MAX_ITEMS', 'EMAIL_BACKEND', 'EMAIL_HOST', 'EMAIL_HOST_PASSWORD', 'EMAIL_HOST_USER', 'EMAIL_PORT', 'EMAIL_SSL_CERTFILE', 'EMAIL_SSL_KEYFILE', 'EMAIL_SUBJECT_PREFIX', 'EMAIL_TIMEOUT', 'EMAIL_USE_LOCALTIME', 'EMAIL_USE_SSL', 'EMAIL_USE_TLS', 'FILE_CHARSET', 'FILE_UPLOAD_DIRECTORY_PERMISSIONS', 'FILE_UPLOAD_HANDLERS', 'FILE_UPLOAD_MAX_MEMORY_SIZE', 'FILE_UPLOAD_PERMISSIONS', 'FILE_UPLOAD_TEMP_DIR', 'FIRST_DAY_OF_WEEK', 'FIXTURE_DIRS', 'FORCE_SCRIPT_NAME', 'FORMAT_MODULE_PATH', 'FORM_RENDERER', 'HORIZON_COMPRESS_OFFLINE_CONTEXT_BASE', 'HORIZON_CONFIG', 'IGNORABLE_404_URLS', 'IMAGE_CUSTOM_PROPERTY_TITLES', 'IMAGE_RESERVED_CUSTOM_PROPERTIES', 'INSTALLED_APPS', 'INSTANCE_LOG_LENGTH', 'INTEGRATION_TESTS_SUPPORT', 'INTERNAL_IPS', 'LANGUAGES', 'LANGUAGES_BIDI', 'LANGUAGE_CODE', 'LANGUAGE_COOKIE_AGE', 'LANGUAGE_COOKIE_DOMAIN', 'LANGUAGE_COOKIE_NAME', 'LANGUAGE_COOKIE_PATH', 'LOCALE_PATHS', 'LOCAL_PATH', 'LOCAL_SETTINGS_DIR_PATH', 'LOGGING', 'LOGGING_CONFIG', 'LOGIN_ERROR', 'LOGIN_REDIRECT_URL', 'LOGIN_URL', 'LOGOUT_REDIRECT_URL', 'LOGOUT_URL', 'MANAGERS', 'MEDIA_ROOT', 'MEDIA_URL', 'MEMOIZED_MAX_SIZE_DEFAULT', 'MESSAGE_STORAGE', 'MIDDLEWARE', 'MIGRATION_MODULES', 'MONTH_DAY_FORMAT', 'NG_TEMPLATE_CACHE_AGE', 'NUMBER_GROUPING', 'OPENSTACK_CINDER_FEATURES', 'OPENSTACK_CLOUDS_YAML_NAME', 'OPENSTACK_CLOUDS_YAML_PROFILE', 'OPENSTACK_HEAT_STACK', 'OPENSTACK_HOST', 'OPENSTACK_HYPERVISOR_FEATURES', 'OPENSTACK_IMAGE_BACKEND', 'OPENSTACK_IMAGE_FORMATS', 'OPENSTACK_KEYSTONE_BACKEND', 'OPENSTACK_KEYSTONE_DEFAULT_ROLE', 'OPENSTACK_KEYSTONE_URL', 'OPENSTACK_NEUTRON_NETWORK', 'OPENSTACK_PROFILER', 'PASSWORD_HASHERS', 'PASSWORD_RESET_TIMEOUT_DAYS', 'POLICY_CHECK_FUNCTION', 'POLICY_DIRS', 'POLICY_FILES', 'POLICY_FILES_PATH', 'PREPEND_WWW', 'REST_API_REQUIRED_SETTINGS', 'ROOT_PATH', 'ROOT_URLCONF', 'SECRET_KEY', 'SECURE_BROWSER_XSS_FILTER', 'SECURE_CONTENT_TYPE_NOSNIFF', 'SECURE_HSTS_INCLUDE_SUBDOMAINS', 'SECURE_HSTS_PRELOAD', 'SECURE_HSTS_SECONDS', 'SECURE_PROXY_SSL_HEADER', 'SECURE_REDIRECT_EXEMPT', 'SECURE_SSL_HOST', 'SECURE_SSL_REDIRECT', 'SECURITY_GROUP_RULES', 'SELECTABLE_THEMES', 'SERVER_EMAIL', 'SESSION_CACHE_ALIAS', 'SESSION_COOKIE_AGE', 'SESSION_COOKIE_DOMAIN', 'SESSION_COOKIE_HTTPONLY', 'SESSION_COOKIE_MAX_SIZE', 'SESSION_COOKIE_NAME', 'SESSION_COOKIE_PATH', 'SESSION_COOKIE_SECURE', 'SESSION_ENGINE', 'SESSION_EXPIRE_AT_BROWSER_CLOSE', 'SESSION_FILE_PATH', 'SESSION_REFRESH', 'SESSION_SAVE_EVERY_REQUEST', 'SESSION_SERIALIZER', 'SESSION_TIMEOUT', 'SETTINGS_MODULE', 'SHORT_DATETIME_FORMAT', 'SHORT_DATE_FORMAT', 'SHOW_KEYSTONE_V2_RC', 'SHOW_OPENRC_FILE', 'SHOW_OPENSTACK_CLOUDS_YAML', 'SIGNING_BACKEND', 'SILENCED_SYSTEM_CHECKS', 'SITE_BRANDING', 'STATICFILES_DIRS', 'STATICFILES_FINDERS', 'STATICFILES_STORAGE', 'STATIC_ROOT', 'STATIC_URL', 'SWIFT_FILE_TRANSFER_CHUNK_SIZE', 'TEMPLATES', 'TEST_NON_SERIALIZED_APPS', 'TEST_RUNNER', 'THEME_COLLECTION_DIR', 'THEME_COOKIE_NAME', 'THOUSAND_SEPARATOR', 'TIME_FORMAT', 'TIME_INPUT_FORMATS', 'TIME_ZONE', 'USER_MENU_LINKS', 'USE_ETAGS', 'USE_I18N', 'USE_L10N', 'USE_THOUSAND_SEPARATOR', 'USE_TZ', 'USE_X_FORWARDED_HOST', 'USE_X_FORWARDED_PORT', 'WEBROOT', 'WEBSSO_CHOICES', 'WEBSSO_ENABLED', 'WEBSSO_IDP_MAPPING', 'WEBSSO_INITIAL_CHOICE', 'WSGI_APPLICATION', 'XSTATIC_MODULES', 'X_FRAME_OPTIONS', 'YEAR_MONTH_FORMAT' } invalid = [] for setting in dir(settings): if not setting.isupper() or setting.startswith(""_""): continue if setting not in VALID_SETTINGS: invalid.append(setting) if invalid: return WARNING, _(""Unknown settings: {}."").format(u"", "".join(invalid)) return SUCCESS, """" @register_check(_(""Deprecated Settings"")) def check_deprecated_settings(): DEPRECATED_SETTINGS = {'SHOW_KEYSTONE_V2_RC', 'ENABLE_FLAVOR_EDIT'} deprecated = [] for setting in dir(settings): if not setting.isupper() or setting.startswith(""_""): continue if setting in DEPRECATED_SETTINGS: deprecated.append(setting) if deprecated: return ERROR, _(""Deprecated settings: {}."").format( u"", "".join(deprecated)) return SUCCESS, """" class Command(BaseCommand): help = _(""Perform a check to see if the application is ready for upgrade."") def add_arguments(self, parser): parser.add_argument('-f', '--format', choices=['table', 'json'], default='table', help=_(""The output format"") ) def handle(self, *args, **options): output_format = options.pop('format') results = [] for check_name, check_func in CHECKS: check_code, check_details = check_func() results.append({ 'check': ""{}"".format(check_name), 'code': int(check_code), 'result': ""{}"".format(CODES[check_code]), 'details': ""{}"".format(check_details), }) if output_format == 'table': table = prettytable.PrettyTable( [_(u""Upgrade Check Results"")], hrules=prettytable.ALL ) table.align = ""l"" for result in results: cell = _(u""Check: {check}\n"" u""Result: {result}\n"" u""Details: {details}"").format(**result) table.add_row([cell]) print(table) elif output_format == 'json': print(json.dumps(results)) ",,178,0
openstack%2Fplacement~master~Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee,openstack/placement,master,Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee,Remove pep8 whitespace ignores,MERGED,2019-03-01 23:37:51.000000000,2019-03-06 22:20:23.000000000,2019-03-06 06:42:37.000000000,"[{'_account_id': 7634}, {'_account_id': 11224}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2019-03-01 23:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/7153ef0725358a961e92fc86045f6cfc91bb810e', 'message': ""Remove pep8 whitespace ignores\n\nWe had carried over the full list of pep8 whitespace ignores from nova.\nTrying to address them all in the entire nova repository would have been\ntoo big a task; but it's tenable here in placement.\n\nDo it now rather than letting these whitespace issues compound.\n\nThis change removes the E* whitespace ignores and fixes the pep8 issues\nthey were masking.\n\nChange-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee\n""}, {'number': 2, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/f213c72a01cc243be8c532e78984a2bea2553763', 'message': ""Remove pep8 whitespace ignores\n\nWe had carried over the full list of pep8 whitespace ignores from nova.\nTrying to address them all in the entire nova repository would have been\ntoo big a task; but it's tenable here in placement.\n\nDo it now rather than letting these whitespace issues compound.\n\nThis change removes the E* whitespace ignores and fixes the pep8 issues\nthey were masking.\n\nChange-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee\n""}, {'number': 3, 'created': '2019-03-02 00:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/bc30433f9705d25cae3c47f29b0d30d27d5e4694', 'message': ""Remove pep8 whitespace ignores\n\nWe had carried over the full list of pep8 whitespace ignores from nova.\nTrying to address them all in the entire nova repository would have been\ntoo big a task; but it's tenable here in placement.\n\nDo it now rather than letting these whitespace issues compound.\n\nThis change removes the E* whitespace ignores and fixes the pep8 issues\nthey were masking.\n\nChange-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee\n""}, {'number': 4, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/403ed8d395f682abe95a315d3f88808221f3f6f7', 'message': ""Remove pep8 whitespace ignores\n\nWe had carried over the full list of pep8 whitespace ignores from nova.\nTrying to address them all in the entire nova repository would have been\ntoo big a task; but it's tenable here in placement.\n\nDo it now rather than letting these whitespace issues compound.\n\nThis change removes the E* whitespace ignores and fixes the pep8 issues\nthey were masking.\n\nChange-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee\n""}, {'number': 5, 'created': '2019-03-04 15:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/30fcc350c783adfe05ac1a74c6ee7a3e0c896b8e', 'message': ""Remove pep8 whitespace ignores\n\nWe had carried over the full list of pep8 whitespace ignores from nova.\nTrying to address them all in the entire nova repository would have been\ntoo big a task; but it's tenable here in placement.\n\nDo it now rather than letting these whitespace issues compound.\n\nThis change removes the E* whitespace ignores and fixes the pep8 issues\nthey were masking.\n\nChange-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee\n""}, {'number': 6, 'created': '2019-03-06 00:18:45.000000000', 'files': ['placement/lib.py', 'placement/requestlog.py', 'placement/tests/unit/test_fault_wrap.py', 'placement/db/sqlalchemy/alembic/versions/b4ed3a175331_initial.py', 'placement/handlers/allocation.py', 'placement/tests/unit/cmd/test_manage.py', 'placement/tests/functional/db/test_allocation_candidates.py', 'placement/handlers/util.py', 'placement/tests/unit/objects/test_allocation.py', 'placement/conf/api.py', 'placement/tests/unit/test_microversion.py', 'placement/handlers/trait.py', 'placement/tests/functional/db/test_base.py', 'placement/conf/paths.py', 'placement/wsgi.py', 'api-ref/source/conf.py', 'placement/direct.py', 'placement/handlers/inventory.py', 'placement/db/sqlalchemy/models.py', 'placement/tests/functional/db/test_allocation.py', 'placement/handlers/usage.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/tests/functional/db/test_migrations.py', 'placement/schemas/usage.py', 'placement/tests/functional/db/test_reshape.py', 'placement/tests/functional/db/test_consumer.py', 'placement/tests/unit/test_util.py', 'placement/objects/allocation.py', 'placement/tests/unit/objects/test_resource_provider.py', 'placement/handler.py', 'placement/handlers/resource_provider.py', 'tox.ini', 'placement/tests/unit/objects/test_rp_candidates.py', 'placement/tests/unit/test_deploy.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/849c89d0e5a93cc392ae72a26f5da39230dacae0', 'message': ""Remove pep8 whitespace ignores\n\nWe had carried over the full list of pep8 whitespace ignores from nova.\nTrying to address them all in the entire nova repository would have been\ntoo big a task; but it's tenable here in placement.\n\nDo it now rather than letting these whitespace issues compound.\n\nThis change removes the E* whitespace ignores and fixes the pep8 issues\nthey were masking.\n\nChange-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee\n""}]",3,640554,849c89d0e5a93cc392ae72a26f5da39230dacae0,28,6,6,14070,,,0,"Remove pep8 whitespace ignores

We had carried over the full list of pep8 whitespace ignores from nova.
Trying to address them all in the entire nova repository would have been
too big a task; but it's tenable here in placement.

Do it now rather than letting these whitespace issues compound.

This change removes the E* whitespace ignores and fixes the pep8 issues
they were masking.

Change-Id: Icbabdb9b56fd5a3e9fd14ab537abf3d0d6456fee
",git fetch https://review.opendev.org/openstack/placement refs/changes/54/640554/5 && git format-patch -1 --stdout FETCH_HEAD,"['placement/lib.py', 'placement/requestlog.py', 'placement/tests/unit/test_fault_wrap.py', 'placement/db/sqlalchemy/alembic/versions/b4ed3a175331_initial.py', 'placement/handlers/allocation.py', 'placement/tests/unit/cmd/test_manage.py', 'placement/tests/functional/db/test_allocation_candidates.py', 'placement/handlers/util.py', 'placement/tests/unit/objects/test_allocation.py', 'placement/conf/api.py', 'placement/tests/unit/test_microversion.py', 'placement/handlers/trait.py', 'placement/tests/functional/db/test_base.py', 'placement/conf/paths.py', 'placement/wsgi.py', 'api-ref/source/conf.py', 'placement/direct.py', 'placement/handlers/inventory.py', 'placement/db/sqlalchemy/models.py', 'placement/tests/functional/db/test_allocation.py', 'placement/handlers/usage.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/tests/functional/db/test_migrations.py', 'placement/schemas/usage.py', 'placement/tests/functional/db/test_reshape.py', 'placement/tests/functional/db/test_consumer.py', 'placement/tests/unit/test_util.py', 'placement/objects/allocation.py', 'placement/tests/unit/objects/test_resource_provider.py', 'placement/handler.py', 'placement/handlers/resource_provider.py', 'tox.ini', 'placement/tests/unit/test_deploy.py']",34,7153ef0725358a961e92fc86045f6cfc91bb810e,scrub-Lists," conf_fixture.config( www_authenticate_uri=www_authenticate_uri, group='keystone_authtoken')"," conf_fixture.config(www_authenticate_uri=www_authenticate_uri, group='keystone_authtoken')",611,564
openstack%2Fpython-octaviaclient~master~If834d009599c20fd503f87c9f175275f6aa0c09b,openstack/python-octaviaclient,master,If834d009599c20fd503f87c9f175275f6aa0c09b,Add new options to HealthMonitor CLI,MERGED,2018-12-19 15:15:15.000000000,2019-03-06 22:11:06.000000000,2019-03-06 22:11:06.000000000,"[{'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-19 15:15:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/6e7b0a59af7aa19df089cb71276dfe7286a863c5', 'message': ""Add new options to HealthMonitor CLI\n\nThis patch adds 2 options into HealthMonitor CLI.\nThey are '--http-version' and '--domain-name'.\n\n'--http-version' can be 1.0 or 1.1\n'--domain-name' is a valid domain name string.\n\nAnd the '--domain-name' option will be just avaliable when http version\nis 1.1, otherwise the server side will raise ClientError.\n\nStory: 2002160\nDepends-On: https://review.openstack.org/#/c/626183/\nChange-Id: If834d009599c20fd503f87c9f175275f6aa0c09b\n""}, {'number': 2, 'created': '2018-12-20 04:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/021a4422ac8ae69981e4971e6bb30f6d93298c79', 'message': ""Add new options to HealthMonitor CLI\n\nThis patch adds 2 options into HealthMonitor CLI.\nThey are '--http-version' and '--domain-name'.\n\n'--http-version' can be 1.0 or 1.1\n'--domain-name' is a valid domain name string.\n\nAnd the '--domain-name' option will be just avaliable when http version\nis 1.1, otherwise the server side will raise ClientError.\n\nStory: 2002160\nDepends-On: https://review.openstack.org/#/c/626183/\nChange-Id: If834d009599c20fd503f87c9f175275f6aa0c09b\n""}, {'number': 3, 'created': '2019-03-06 00:51:39.000000000', 'files': ['octaviaclient/osc/v2/health_monitor.py', 'octaviaclient/tests/unit/osc/v2/constants.py', 'octaviaclient/tests/unit/osc/v2/test_health_monitor.py', 'octaviaclient/osc/v2/constants.py', 'octaviaclient/osc/v2/utils.py'], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/a2dfe7c0ea0ce01800feb3c0fdece99d93e541b4', 'message': ""Add new options to HealthMonitor CLI\n\nThis patch adds 2 options into HealthMonitor CLI.\nThey are '--http-version' and '--domain-name'.\n\n'--http-version' can be 1.0 or 1.1\n'--domain-name' is a valid domain name string.\n\nAnd the '--domain-name' option will be just avaliable when http version\nis 1.1, otherwise the server side will raise ClientError.\n\nStory: 2002160\nDepends-On: https://review.openstack.org/#/c/626183/\nChange-Id: If834d009599c20fd503f87c9f175275f6aa0c09b\n""}]",0,626190,a2dfe7c0ea0ce01800feb3c0fdece99d93e541b4,15,3,3,15309,,,0,"Add new options to HealthMonitor CLI

This patch adds 2 options into HealthMonitor CLI.
They are '--http-version' and '--domain-name'.

'--http-version' can be 1.0 or 1.1
'--domain-name' is a valid domain name string.

And the '--domain-name' option will be just avaliable when http version
is 1.1, otherwise the server side will raise ClientError.

Story: 2002160
Depends-On: https://review.openstack.org/#/c/626183/
Change-Id: If834d009599c20fd503f87c9f175275f6aa0c09b
",git fetch https://review.opendev.org/openstack/python-octaviaclient refs/changes/90/626190/3 && git format-patch -1 --stdout FETCH_HEAD,"['octaviaclient/osc/v2/health_monitor.py', 'octaviaclient/tests/unit/osc/v2/constants.py', 'octaviaclient/tests/unit/osc/v2/test_health_monitor.py', 'octaviaclient/osc/v2/constants.py', 'octaviaclient/osc/v2/utils.py']",5,6e7b0a59af7aa19df089cb71276dfe7286a863c5,http11_host_header_health_check," 'disable': ('admin_state_up', lambda x: False), 'http_version': ('http_version', float), 'domain_name': ('domain_name', str)"," 'disable': ('admin_state_up', lambda x: False)",33,5
openstack%2Fpython-manilaclient~master~If1403079b20471645bf869da74bf4db37d59811c,openstack/python-manilaclient,master,If1403079b20471645bf869da74bf4db37d59811c,Add CLI commands for Manage-Unmanage of Share Servers,MERGED,2019-02-08 18:49:22.000000000,2019-03-06 21:56:28.000000000,2019-03-06 21:56:28.000000000,"[{'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 18:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4901a9c6d21f652f9e208d26c9bcd44fc90365c7', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 2, 'created': '2019-02-13 10:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/7e044f8460a8cb2bb3d17afcce536d0ca167335a', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 3, 'created': '2019-02-19 11:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/b79dda78e52d04b4be0b0574c29b49e8b5ab074d', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 4, 'created': '2019-03-01 18:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/e8412bb50d8ec3b9fb42145e62d9ec403a78611a', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 5, 'created': '2019-03-03 21:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/3a62b1ddc019eab249b8ce89b15e0621af2fcc07', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 6, 'created': '2019-03-05 02:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/d97c18dbf2a2ab6aba510aac0d75dd0c26e29568', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 7, 'created': '2019-03-05 17:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/76f6eca24a66074599241195a932abb0211da3dd', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nDepends-On: https://review.openstack.org/#/c/635831/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 8, 'created': '2019-03-06 14:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/a18725346f078bd7a93463605ef5b24e5102485d', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}, {'number': 9, 'created': '2019-03-06 19:54:30.000000000', 'files': ['manilaclient/tests/unit/v2/test_shell.py', 'manilaclient/tests/functional/test_shares_listing.py', 'manilaclient/tests/unit/v2/fakes.py', 'manilaclient/v2/shares.py', 'manilaclient/v2/shell.py', 'contrib/ci/post_test_hook.sh', 'manilaclient/common/constants.py', 'manilaclient/tests/functional/test_share_servers.py', 'manilaclient/api_versions.py', 'manilaclient/config.py', 'manilaclient/v2/share_servers.py', 'releasenotes/notes/manage-unmanage-share-servers-8c7b27a1fe80e5fa.yaml', 'manilaclient/tests/functional/client.py', 'manilaclient/tests/unit/v2/test_share_servers.py', 'manilaclient/tests/functional/base.py', 'manilaclient/tests/unit/v2/test_shares.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/07564879ae4bdcb73e856b3aedcb79e4420fa7eb', 'message': 'Add CLI commands for Manage-Unmanage of Share Servers\n\n- Added CLI commands for managing and unmanaging share servers.\n- Updated CLI command for managing shares to accept\n  share_server_id parameter.\n\nAPI microversion has been bumped to 2.49.\n\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: If1403079b20471645bf869da74bf4db37d59811c\n'}]",87,635915,07564879ae4bdcb73e856b3aedcb79e4420fa7eb,56,4,9,14567,,,0,"Add CLI commands for Manage-Unmanage of Share Servers

- Added CLI commands for managing and unmanaging share servers.
- Updated CLI command for managing shares to accept
  share_server_id parameter.

API microversion has been bumped to 2.49.

Partially-implements: bp manage-unmanage-with-share-servers
Change-Id: If1403079b20471645bf869da74bf4db37d59811c
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/15/635915/8 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/tests/unit/v2/test_shell.py', 'manilaclient/tests/functional/test_shares_listing.py', 'manilaclient/tests/unit/v2/fakes.py', 'manilaclient/v2/shares.py', 'manilaclient/v2/shell.py', 'manilaclient/tests/functional/test_share_servers.py', 'manilaclient/api_versions.py', 'manilaclient/v2/share_servers.py', 'releasenotes/notes/manage-unmanage-share-servers-8c7b27a1fe80e5fa.yaml', 'manilaclient/tests/functional/client.py', 'manilaclient/tests/unit/v2/test_share_servers.py', 'manilaclient/tests/functional/base.py', 'manilaclient/tests/unit/v2/test_shares.py']",13,4901a9c6d21f652f9e208d26c9bcd44fc90365c7,bp/manage-unmanage-with-share-servers," (""2.49"", ""/shares/manage"", False, '1234'), def test_manage_share(self, microversion, resource_path, is_public=False, share_server_id=None): ""share_server_id"": share_server_id, if (version >= api_versions.APIVersion('2.8') and version != api_versions.APIVersion('2.49')): elif version == api_versions.APIVersion('2.49'): result = manager.manage( service_host, protocol, export_path, driver_options, share_type, name, description, is_public, share_server_id)"," def test_manage_share(self, microversion, resource_path, is_public=False): if version >= api_versions.APIVersion('2.8'):",510,33
openstack%2Felection~master~Ia9c4ecaf055f37f87a35f201b4ea0a0ad037f33a,openstack/election,master,Ia9c4ecaf055f37f87a35f201b4ea0a0ad037f33a,Train TC Election Statistics,MERGED,2019-03-06 02:07:08.000000000,2019-03-06 21:49:37.000000000,2019-03-06 21:49:37.000000000,"[{'_account_id': 6088}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 02:07:08.000000000', 'files': ['tools/tc-election-summary.py'], 'web_link': 'https://opendev.org/openstack/election/commit/8764b280703d4a1b1e9af4bd9ddbdec1273e766a', 'message': 'Train TC Election Statistics\n\nChange-Id: Ia9c4ecaf055f37f87a35f201b4ea0a0ad037f33a\n'}]",0,641185,8764b280703d4a1b1e9af4bd9ddbdec1273e766a,7,3,1,5263,,,0,"Train TC Election Statistics

Change-Id: Ia9c4ecaf055f37f87a35f201b4ea0a0ad037f33a
",git fetch https://review.opendev.org/openstack/election refs/changes/85/641185/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tc-election-summary.py'],1,8764b280703d4a1b1e9af4bd9ddbdec1273e766a,feb-2019-elections," { 'election': '03/2019', # Train 'electorate': 1390, 'votes_cast': 279, 'results': '%s?id=%s' % (CIVS_BASE, 'E_6c71f84caff2b37c') },",,6,0
openstack%2Fneutron-tempest-plugin~master~Ic7b6e80213aafac6df7b0a8b044fe45f60870483,openstack/neutron-tempest-plugin,master,Ic7b6e80213aafac6df7b0a8b044fe45f60870483,Fix neutron-tempest-plugin tox pep8 setup,MERGED,2019-03-01 17:24:12.000000000,2019-03-06 21:44:08.000000000,2019-03-06 21:44:08.000000000,"[{'_account_id': 1131}, {'_account_id': 8911}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 17:24:12.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/6b03ab1bb4dd7b09be97c6553378405357b9ae45', 'message': 'Fix neutron-tempest-plugin tox pep8 setup\n\nThe plugin pep8 setup was failing due to trying to use upper-constraints\nwith the pip install -e ., with a version constraint error. Grab\nthe setup commands from the neutron tox.ini to fix this.\n\nChange-Id: Ic7b6e80213aafac6df7b0a8b044fe45f60870483\n'}]",0,640453,6b03ab1bb4dd7b09be97c6553378405357b9ae45,9,5,1,10980,,,0,"Fix neutron-tempest-plugin tox pep8 setup

The plugin pep8 setup was failing due to trying to use upper-constraints
with the pip install -e ., with a version constraint error. Grab
the setup commands from the neutron tox.ini to fix this.

Change-Id: Ic7b6e80213aafac6df7b0a8b044fe45f60870483
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/53/640453/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6b03ab1bb4dd7b09be97c6553378405357b9ae45,fix-tox,install_command = pip install {opts} {packages} deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/test-requirements.txt,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}deps = -r{toxinidir}/test-requirements.txt,5,2
openstack%2Fneutron-tempest-plugin~master~I3a836c08aa700056597a3f72c2e314d3c43994c0,openstack/neutron-tempest-plugin,master,I3a836c08aa700056597a3f72c2e314d3c43994c0,Fix L3 agent scheduler tests in multinode environments,MERGED,2019-03-04 13:40:40.000000000,2019-03-06 21:44:07.000000000,2019-03-06 21:44:07.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 17120}, {'_account_id': 22348}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-03-04 13:40:40.000000000', 'files': ['neutron_tempest_plugin/api/admin/test_l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/39f25321181cf442863be7763e18e256db4bf613', 'message': 'Fix L3 agent scheduler tests in multinode environments\n\nTest will now first try to remove router from all agents on\nwhich it was hosted and then add it to one of agents again.\n\nChange-Id: I3a836c08aa700056597a3f72c2e314d3c43994c0\nCloses-Bug: #1817696\n'}]",0,640763,39f25321181cf442863be7763e18e256db4bf613,20,8,1,11975,,,0,"Fix L3 agent scheduler tests in multinode environments

Test will now first try to remove router from all agents on
which it was hosted and then add it to one of agents again.

Change-Id: I3a836c08aa700056597a3f72c2e314d3c43994c0
Closes-Bug: #1817696
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/63/640763/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/api/admin/test_l3_agent_scheduler.py'],1,39f25321181cf442863be7763e18e256db4bf613,bug/1817696," # First list agents which host router body = self.admin_client.list_l3_agents_hosting_router( self.router['id']) # Now remove router from all agents for agent in body['agents']: self.admin_client.remove_router_from_l3_agent( agent['id'], self.router['id']) # Now list agents which host router again - list should be empty body = self.admin_client.list_l3_agents_hosting_router( self.router['id']) self.assertEqual([], body['agents']) # Now add router to one of agents router_id=self.router['id']) # And check that router is hosted by this agent body = self.admin_client.list_l3_agents_hosting_router("," body = ( self.admin_client.list_l3_agents_hosting_router(self.router['id'])) body = self.admin_client.remove_router_from_l3_agent( self.agent['id'], self.router['id']) # NOTE(afazekas): The deletion not asserted, because neutron # is not forbidden to reschedule the router to the same agent",19,7
openstack%2Foctavia-lib~master~Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0,openstack/octavia-lib,master,Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0,Sync data models and import new constants from Octavia,MERGED,2019-03-04 17:26:20.000000000,2019-03-06 21:29:42.000000000,2019-03-06 21:29:42.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 10850}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 17:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-lib/commit/6fb149202c1e5131dfc7b8903711491279f8eca5', 'message': 'Sync data models and import new constants from Octavia\n\nRecent TLS encryptation work in Octavia [1] added a few new constants.\nThis patch imports those constants and updates the data models.\n\n[1] https://review.openstack.org/#/q/project:openstack/octavia+topic:tls_encryption\n\nChange-Id: Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0\n'}, {'number': 2, 'created': '2019-03-04 17:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-lib/commit/04f7e606ea1eaf5be67a6e7af9bd1e37aed73316', 'message': 'Sync data models and import new constants from Octavia\n\nRecent TLS encryptation work in Octavia [1] added a few new constants.\nThis patch imports those constants and updates the data models.\n\n[1] https://review.openstack.org/#/q/project:openstack/octavia+topic:tls_encryption\n\nChange-Id: Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0\n'}, {'number': 3, 'created': '2019-03-04 21:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-lib/commit/b4dcbe4e63077fa5ebfd12409c7da247f931f824', 'message': 'Sync data models and import new constants from Octavia\n\nRecent TLS encryption work in Octavia [1] added a few new constants.\nThis patch imports those constants and updates the data models.\n\n[1] https://review.openstack.org/#/q/project:openstack/octavia+topic:tls_encryption\n\nStory: 2005136\nTask: 29823\n\nChange-Id: Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0\n'}, {'number': 4, 'created': '2019-03-06 18:22:44.000000000', 'files': ['octavia_lib/common/constants.py', 'octavia_lib/tests/unit/api/drivers/test_data_models.py', 'octavia_lib/api/drivers/data_models.py'], 'web_link': 'https://opendev.org/openstack/octavia-lib/commit/6b55d6219612472e23674bdb4fcbff394022f5fc', 'message': 'Sync data models and import new constants from Octavia\n\nRecent TLS encryption, L7policy and health monitor work in Octavia added\na few new constants. This patch imports those constants and updates the\ndata models.\n\nStory: 2005136\nTask: 29823\n\nChange-Id: Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0\n'}]",0,640825,6b55d6219612472e23674bdb4fcbff394022f5fc,18,4,4,6469,,,0,"Sync data models and import new constants from Octavia

Recent TLS encryption, L7policy and health monitor work in Octavia added
a few new constants. This patch imports those constants and updates the
data models.

Story: 2005136
Task: 29823

Change-Id: Idcb87a69cdf725aa4c4ced4102d395149d5fa8d0
",git fetch https://review.opendev.org/openstack/octavia-lib refs/changes/25/640825/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_lib/common/constants.py', 'octavia_lib/api/drivers/data_models.py']",2,6fb149202c1e5131dfc7b8903711491279f8eca5,640825," timeout_tcp_inspect=Unset, client_ca_tls_container_ref=Unset, client_ca_tls_container_data=Unset, client_authentication=Unset, client_crl_container_ref=Unset, client_crl_container_data=Unset): self.client_ca_tls_container_ref = client_ca_tls_container_ref self.client_ca_tls_container_data = client_ca_tls_container_data self.client_authentication = client_authentication self.client_crl_container_ref = client_crl_container_ref self.client_crl_container_data = client_crl_container_data session_persistence=Unset, tls_container_ref=Unset, tls_container_data=Unset, ca_tls_container_ref=Unset, ca_tls_container_data=Unset, crl_container_ref=Unset, crl_container_data=Unset, tls_enabled=Unset): self.tls_container_ref = tls_container_ref self.tls_container_data = tls_container_data self.ca_tls_container_ref = ca_tls_container_ref self.ca_tls_container_data = ca_tls_container_data self.crl_container_ref = crl_container_ref self.crl_container_data = crl_container_data self.tls_enabled = tls_enabled", timeout_tcp_inspect=Unset): session_persistence=Unset):,33,3
openstack%2Fopenstack-helm~master~I542a38a08101b031633bfcb0810e00904ae58df5,openstack/openstack-helm,master,I542a38a08101b031633bfcb0810e00904ae58df5,OSH: Add ingress netpol for ceph-rgw pods,MERGED,2019-01-24 17:59:40.000000000,2019-03-06 21:26:20.000000000,2019-03-06 21:26:20.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22713}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 28592}, {'_account_id': 29106}, {'_account_id': 29132}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-24 17:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cdb4b197c0ade874be7d891986d7a1efed7ed595', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 2, 'created': '2019-01-24 18:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c4133037f50e364f78e699a54afb5e529bf8c7f1', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 3, 'created': '2019-01-24 21:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3095f79df5e3f8cf41cddeb4cdaebcee4607a63a', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 4, 'created': '2019-01-25 04:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c46456f4ae0e7cc420cdc4e673accae25cf04933', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 5, 'created': '2019-01-29 18:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f58e17fd3d236ce5a4adceeca6b5677468589441', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 6, 'created': '2019-01-29 18:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e187325c6d76e46b25ae2a157bf32b445ec2135e', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 7, 'created': '2019-01-30 17:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8a6993e8640638c1b4d1ceabd51f9130c95f16cb', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 8, 'created': '2019-01-31 17:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fb89afb79f0b9b68d202dfcb0dbde0e7db6bc8b3', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 9, 'created': '2019-02-04 21:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/85dceebdb1521a48450b609e94e19747ddb269e4', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 10, 'created': '2019-02-07 16:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7e6970d2372638dad35a06933d558bba4439535a', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 11, 'created': '2019-02-10 23:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bf85f0ca3c3fc6dc7def826f01159e091d049e71', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 12, 'created': '2019-02-18 19:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0d8d81d8e25ba68f94e3a60c87e070e3358616d6', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 13, 'created': '2019-02-25 03:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/199d96d072f84b1e82b0beb05e2a02701da30d01', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 14, 'created': '2019-02-28 03:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a7afbd78ab8c303c52c3d34fa181bfaff46bcdca', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 15, 'created': '2019-03-06 03:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bd29fd1f3ef32f11ddbff4dab4b86d0002b959ea', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}, {'number': 16, 'created': '2019-03-06 19:57:06.000000000', 'files': ['tools/deployment/developer/ceph/110-ceph-radosgateway.sh', 'tools/deployment/multinode/090-ceph-radosgateway.sh', 'tools/deployment/developer/common/030-ingress.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ff146ea9fda22dc920382d2dd63215637ebe18d5', 'message': 'OSH: Add ingress netpol for ceph-rgw pods\n\nThis is to enable ingress netpol for ceph-rgw pods\n\nDepends-On: https://review.openstack.org/#/c/632567/\n\nChange-Id: I542a38a08101b031633bfcb0810e00904ae58df5\n'}]",4,633045,ff146ea9fda22dc920382d2dd63215637ebe18d5,42,10,16,28372,,,0,"OSH: Add ingress netpol for ceph-rgw pods

This is to enable ingress netpol for ceph-rgw pods

Depends-On: https://review.openstack.org/#/c/632567/

Change-Id: I542a38a08101b031633bfcb0810e00904ae58df5
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/45/633045/16 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/developer/ceph/110-ceph-radosgateway.sh', 'tools/deployment/multinode/090-ceph-radosgateway.sh', 'tools/deployment/developer/common/030-ingress.sh']",3,cdb4b197c0ade874be7d891986d7a1efed7ed595,netpol-ceph-rgw, application: ceph - podSelector: matchLabels:,,5,0
openstack%2Foctavia~master~I3c52ed2154aac9ba4476c718ae921c7f2fbe4fba,openstack/octavia,master,I3c52ed2154aac9ba4476c718ae921c7f2fbe4fba,Trivial: Remove unused OCTAVIA_AMP_SUBNET_ID,MERGED,2019-03-06 00:44:42.000000000,2019-03-06 21:00:27.000000000,2019-03-06 21:00:27.000000000,"[{'_account_id': 6167}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 00:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3814784ff915ee45d3a22f412b06dfc9bf8cd642', 'message': ""Trivial: Remove unused OCTAVIA_AMP_SUBNET_ID\n\nOCTAVIA_AMP_SUBNET_ID is not used at all anywhere as\nhttp://codesearch.openstack.org/?q=OCTAVIA_AMP_SUBNET_ID&i=nope&files=&repos=\nSo let's remove it for cleanup.\n\nChange-Id: I3c52ed2154aac9ba4476c718ae921c7f2fbe4fba\n""}, {'number': 2, 'created': '2019-03-06 00:48:55.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/309ef2fb43ccbdd455eb7a67c35ed2200dd63285', 'message': ""Trivial: Remove unused OCTAVIA_AMP_SUBNET_ID\n\nOCTAVIA_AMP_SUBNET_ID is not used at all anywhere as\nhttp://codesearch.openstack.org/?q=OCTAVIA_AMP_SUBNET_ID&i=nope&files=&repos=\nIn addition, near OCTAVIA_AMP_NETWORK_ID also is unused.\nSo let's remove them for cleanup.\n\nChange-Id: I3c52ed2154aac9ba4476c718ae921c7f2fbe4fba\n""}]",0,641178,309ef2fb43ccbdd455eb7a67c35ed2200dd63285,14,4,2,6167,,,0,"Trivial: Remove unused OCTAVIA_AMP_SUBNET_ID

OCTAVIA_AMP_SUBNET_ID is not used at all anywhere as
http://codesearch.openstack.org/?q=OCTAVIA_AMP_SUBNET_ID&i=nope&files=&repos=
In addition, near OCTAVIA_AMP_NETWORK_ID also is unused.
So let's remove them for cleanup.

Change-Id: I3c52ed2154aac9ba4476c718ae921c7f2fbe4fba
",git fetch https://review.opendev.org/openstack/octavia refs/changes/78/641178/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,3814784ff915ee45d3a22f412b06dfc9bf8cd642,cleanup," openstack subnet create --subnet-range $OCTAVIA_MGMT_SUBNET --allocation-pool start=$OCTAVIA_MGMT_SUBNET_START,end=$OCTAVIA_MGMT_SUBNET_END --network lb-mgmt-net lb-mgmt-subnet"," OCTAVIA_AMP_SUBNET_ID=$(openstack subnet create --subnet-range $OCTAVIA_MGMT_SUBNET --allocation-pool start=$OCTAVIA_MGMT_SUBNET_START,end=$OCTAVIA_MGMT_SUBNET_END --network lb-mgmt-net lb-mgmt-subnet -f value -c id)",1,1
openstack%2Fnetworking-ovn~stable%2Frocky~I83701640625bdc40fa60a7c38bbb39278a155648,openstack/networking-ovn,stable/rocky,I83701640625bdc40fa60a7c38bbb39278a155648,Migration document update.,MERGED,2019-03-06 11:12:58.000000000,2019-03-06 20:56:23.000000000,2019-03-06 20:56:23.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 11:12:58.000000000', 'files': ['doc/source/install/migration.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/a3bff710b24f19bffd95c2b4c95d01fa1757da03', 'message': 'Migration document update.\n\nThis update makes the migration document more clear.\n\nChange-Id: I83701640625bdc40fa60a7c38bbb39278a155648\n(cherry picked from commit 87985182632199b4d240d8af9649c59ca57ccd7b)\n'}]",0,641323,a3bff710b24f19bffd95c2b4c95d01fa1757da03,7,3,1,8788,,,0,"Migration document update.

This update makes the migration document more clear.

Change-Id: I83701640625bdc40fa60a7c38bbb39278a155648
(cherry picked from commit 87985182632199b4d240d8af9649c59ca57ccd7b)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/23/641323/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/migration.rst'],1,a3bff710b24f19bffd95c2b4c95d01fa1757da03,,"This document details an in-place migration strategy from ML2/OVS to ML2/OVN in either ovs-firewall or ovs-hybrid mode for a TripleO OpenStack deployment.The migration process is orchestrated through the shell script ovn_migration.sh, which is provided with networking-ovn. The administrator uses ovn_migration.sh to perform readiness steps and migration from the undercloud node. The readiness steps, such as host inventory production, DHCP and MTU adjustments, prepare the environment for the procedure. Subsequent steps start the migration via Ansible. Plan for a 24-hour wait after the setup-mtu-t1 step to allow VMs to catch up with the new MTU size. The default neutron ML2/OVS configuration has a dhcp_lease_duration of 86400 seconds (24h). Also, if there are instances using static IP assignment, the administrator should be ready to update the MTU of those instances to the new value of 8 bytes less than the ML2/OVS (VXLAN) MTU value. For example, the typical 1500 MTU network value that makes VXLAN tenant networks use 1450 bytes of MTU will need to change to 1442 under Geneve. Or under the same overlay network, a GRE encapsulated tenant network would use a 1458 MTU, but again a 1442 MTU for Geneve. If there are instances which use DHCP but don't support lease update during the T1 period the administrator will need to reboot them to ensure that MTU is updated inside those instances. Steps for migration ------------------- Perform the following steps in the overcloud/undercloud ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1. Ensure that you have updated to the latest openstack/neutron version. Perform the following steps in the undercloud ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1. Install python-networking-ovn-migration-tool. .. code-block:: console yum install python-networking-ovn-migration-tool 2. Create a working directory on the undercloud, and copy the ansible playbooks .. code-block:: console mkdir ~/ovn_migration cd ~/ovn_migration cp -rfp /usr/share/ansible/networking-ovn-migration/playbooks . 3. Create or edit the ``overcloud-deploy-ovn.sh`` script in your ``$HOME``. This script must source your stackrc file, and then execute an ``openstack overcloud overcloud deploy`` with your original deployment parameters, plus the following environment files, added to the end of the command in the following order: When your network topology is DVR and your compute nodes have connectivity to the external network: .. code-block:: console -e /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-dvr-ha.yaml \ -e $HOME/ovn-extras.yaml When your compute nodes don't have external connectivity and you don't use DVR: .. code-block:: console -e /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-ha.yaml \ -e $HOME/ovn-extras.yaml Make sure that all users have execution privileges on the script, because it will be called by ovn_migration.sh/ansible during the migration process. .. code-block:: console $ chmod a+x ~/overcloud-deploy-ovn.sh 4. To configure the parameters of your migration you can set the environment variables that will be used by ``ovn_migration.sh``. You can skip setting any values matching the defaults. * STACKRC_FILE - must point to your stackrc file in your undercloud. Default: ~/stackrc * OVERCLOUDRC_FILE - must point to your overcloudrc file in your undercloud. Default: ~/overcloudrc * OVERCLOUD_OVN_DEPLOY_SCRIPT - must point to the script described in step 1.. Default: ~/overcloud-deploy-ovn.sh * PUBLIC_NETWORK_NAME - Name of your public network. Default: 'public'. To support migration validation, this network must have available floating IPs, and those floating IPs must be pingable from the undercloud. If that's not possible please configure VALIDATE_MIGRATION to False. * IMAGE_NAME - Name/ID of the glance image to us for booting a test server. Default:'cirros'. It will be automatically downloaded during the pre-validation / post-validation process. * VALIDATE_MIGRATION - Create migration resources to validate the migration. The migration script, before starting the migration, boot a server and validates that the server is reachable after the migration. Default: True. * SERVER_USER_NAME - User name to use for logging to the migration instances. Default: 'cirros'. * DHCP_RENEWAL_TIME - DHCP renewal time in seconds to configure in DHCP agent configuration file. Default: 30 .. warning:: Please note that VALIDATE_MIGRATION requires enough quota (2 available floating ips, 2 networks, 2 subnets, 2 instances, and 2 routers as admin). For example: .. code-block:: console $ export PUBLIC_NETWORK_NAME=my-public-network $ ovn_migration.sh ......... 5. Run ``ovn_migration.sh generate-inventory`` to generate the inventory file - ``hosts_for_migration`` and ``ansible.cfg``. Please review ``hosts_for_migration`` for correctness. .. code-block:: console $ ovn_migration.sh generate-inventory 6. Run ``ovn_migration.sh setup-mtu-t1``. This lowers the T1 parameter of the internal neutron DHCP servers configuring the ``dhcp_renewal_time`` in /var/lib/config-data/puppet-generated/neutron/etc/neutron/dhcp_agent.ini in all the nodes where DHCP agent is running. .. code-block:: console $ ovn_migration.sh setup-mtu-t1 7. If you are using VXLAN or GRE tenant networking, ``wait at least 24 hours`` before continuing. This will allow VMs to catch up with the new MTU size of the next step.` .. warning:: If you are using VXLAN or GRE networks, this 24-hour wait step is critical. If you are using VLAN tenant networks you can proceed to the next step without delay. .. warning:: If you have any instance with static IP assignation on VXLAN or GRE tenant networks, you must manually modify the configuration of those instances. If your instances don't honor the T1 parameter of DHCP they will need to be rebooted. to configure the new geneve MTU, which is the current VXLAN MTU minus 8 bytes. For instance, if the VXLAN-based MTU was 1450, change it to 1442. .. note:: 24 hours is the time based on default configuration. It actually depends on /var/lib/config-data/puppet-generated/neutron/etc/neutron/dhcp_agent.ini dhcp_renewal_time and /var/lib/config-data/puppet-generated/neutron/etc/neutron/neutron.conf dhcp_lease_duration parameters. (defaults to 86400 seconds) .. note:: Please note that migrating a deployment which uses VLAN for tenant/project networks is not recommended at this time because of a bug in core ovn, full support is being worked out here: https://mail.openvswitch.org/pipermail/ovs-dev/2018-May/347594.html One way to verify that the T1 parameter has propagated to existing VMs is to connect to one of the compute nodes, and run ``tcpdump`` over one of the VM taps attached to a tenant network. If T1 propegation was a success, you should see that requests happen on an interval of approximately 30 seconds. .. code-block:: console [heat-admin@overcloud-novacompute-0 ~]$ sudo tcpdump -i tap52e872c2-e6 port 67 or port 68 -n tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on tap52e872c2-e6, link-type EN10MB (Ethernet), capture size 262144 bytes 13:17:28.954675 IP 192.168.99.5.bootpc > 192.168.99.3.bootps: BOOTP/DHCP, Request from fa:16:3e:6b:41:3d, length 300 13:17:28.961321 IP 192.168.99.3.bootps > 192.168.99.5.bootpc: BOOTP/DHCP, Reply, length 355 13:17:56.241156 IP 192.168.99.5.bootpc > 192.168.99.3.bootps: BOOTP/DHCP, Request from fa:16:3e:6b:41:3d, length 300 13:17:56.249899 IP 192.168.99.3.bootps > 192.168.99.5.bootpc: BOOTP/DHCP, Reply, length 355 .. note:: This verification is not possible with cirros VMs. The cirros udhcpc implementation does not obey DHCP option 58 (T1). Please try this verification on a port that belongs to a full linux VM. We recommend you to check all the different types of workloads your system runs (Windows, different flavors of linux, etc..). 8. Run ``ovn_migration.sh reduce-mtu``. This lowers the MTU of the pre migration VXLAN and GRE networks. The tool will ignore non-VXLAN/GRE networks, so if you use VLAN for tenant networks it will be fine if you find this step not doing anything. .. code-block:: console $ ovn_migration.sh reduce-mtu This step will go network by network reducing the MTU, and tagging with ``adapted_mtu`` the networks which have been already handled. 9. Make Tripleo ``prepare the new container images`` for OVN. If your deployment didn't have a containers-prepare-parameter.yaml, you can create one with: .. code-block:: console $ test -f $HOME/containers-prepare-parameter.yaml || \ openstack tripleo container image prepare default \ --output-env-file $HOME/containers-prepare-parameter.yaml If you had to create the file, please make sure it's included at the end of your $HOME/overcloud-deploy-ovn.sh and $HOME/overcloud-deploy.sh Change the neutron_driver in the containers-prepare-parameter.yaml file to ovn: .. code-block:: console $ sed -i -E 's/neutron_driver:([ ]\w+)/neutron_driver: ovn/' $HOME/containers-prepare-parameter.yaml You can verify with: .. code-block:: console $ grep neutron_driver containers-prepare-parameter.yaml neutron_driver: ovn Then update the images: .. code-block:: console $ openstack tripleo container image prepare \ --environment-file /home/stack/containers-prepare-parameter.yaml .. note:: It's important to provide the full path to your containers-prepare-parameter.yaml otherwise the command will finish very quickly and won't work (current version doesn't seem to output any error). TripleO will validate the containers and push them to your local registry. 10. Run ``ovn_migration.sh start-migration`` to kick start the migration process. .. code-block:: console $ ovn_migration.sh start-migration Under the hood, this is what will happen: * Create pre-migration resources (network and VM) to validate existing deployment and final migration. * Update the overcloud stack to deploy OVN alongside reference implementation services using a temporary bridge ""br-migration"" instead of br-int. 2. clone the existing resources from br-int to br-migration, to ovn find the same resources UUIDS over br-migration 3. re-assign ovn-controller to br-int instead of br-migration 4. cleanup network namespaces (fip, snat, qrouter, qdhcp), 5. remove any unnecessary patch ports on br-int 6. remove br-tun and br-migration ovs bridges 7. delete qr-*, ha-* and qg-* ports from br-int (via neutron netns cleanup) * Delete neutron agents and neutron HA internal networks from the database via API.","This document details an in-place migration strategy from ML2/OVS in either ovs-firewall, or ovs-hybrid mode in a TripleO OpenStack deployment.The migration would be accomplished by following the steps: a. Administrator steps: * Updating to the latest openstack/neutron version * Reducing the DHCP T1 parameter on dhcp_agent.ini beforehand, which is controlled by the dhcp_renewal_time of /etc/neutron/dhcp_agent.ini Somewhere around 30 seconds would be enough (TODO: Data and calculations to back this value with precise information). * Waiting for at least dhcp_lease_duration (see /etc/neutron/neutron.conf or /etc/neutron/dhcp_agent.ini) time (default is 86400 seconds = 24 hours), that way all instances will grab the new new lease renewal time and start checking with the dhcp server periodically based on the T1 parameter. * Lowering the MTU of all VXLAN or GRE based networks down to make sure geneve works (a tool will be provided for that). The mtu must be set to ""max_tunneling_network_mtu - ovn_geneve_overhead"", that's generally ""1500 - ovn_geneve_overhead"", unless your network and any intermediate router hop between compute and network nodes is jumboframe capable). ovn_geneve_overhead is 58 bytes. VXLAN overhead is 50 bytes. So for the typical 1500 MTU tunneling network, we may need to assign 1442. b. Automated steps (via ansible) * Create pre-migration resources (network and VM) to validate final migration. * Update the overcloud stack (in the case of TripleO) to deploy OVN alongside reference implementation services using a temporary bridge ""br-migration"" instead of br-int. 2. re-assign ovn-controller to br-int instead of br-migration 3. cleanup network namespaces (fip, snat, qrouter, qdhcp), 4. remove any unnecessary patch ports on br-int 5. remove br-tun and br-migration ovs bridges 6. delete qr-*, ha-* and qg-* ports from br-int * Delete neutron agents and neutron HA internal networksSteps for migration ------------------- Carryout the below steps in the undercloud: 1. Create ``overcloud-deploy-ovn.sh`` script in /home/stack. Make sure the below environment files are added in the order mentioned below .. code-block:: console -e /usr/share/openstack-tripleo-heat-templates/environments/docker-ha.yaml \ -e /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-ha.yaml \ -e /home/stack/ovn-extras.yaml If compute nodes have external connectivity, then you can use the environment file - environments/services-docker/neutron-ovn-dvr-ha.yaml 2. Check the script ``ovn_migration.sh`` and override the environment variables if desired. Below are the environment variables * IS_DVR_ENABLED - If the existing ML2/OVS has DVR enabled, set it to True. Default value is False. * PUBLIC_NETWORK_NAME - Name of the public network. Default value is 'public'. * IMAGE_NAME - Name/ID of the glance image to us for booting a test server. Default value is 'cirros'. * VALIDATE_MIGRATION - Create migration resources to validate the migration. The migration script, before starting the migration, boots a server and validates that the server is reachable after the migration. Default value is True. * SERVER_USER_NAME - User name to use for logging to the migration server. Default value is 'cirros'. * DHCP_RENEWAL_TIME - DHCP renewal time to configure in dhcp agent configuration file. The default value is 30 seconds. 2. Run ``./ovn_migration.sh generate-inventory`` to generate the inventory file - hosts_for_migration. Please review this file for correctness and modify it if desired. 4. Run ``./ovn_migration.sh setup-mtu-t1``. This lowers the T1 parameter of the internal neutron DHCP servers configuring the ‘dhcp_renewal_time’ in /var/lib/config-data/puppet-generated/neutron/etc/neutron/dhcp_agent.ini in all the nodes where DHCP agent is running. 5. After the previous step we need to wait at least 24h before continuing if you are using VXLAN or GRE tenant networking. This will allow VMs to catch up with the new MTU size of the next step. .. warning:: This step is very important, never skip it if you are using VXLAN or GRE tenant networks. If you are using VLAN tenant networks you don't need to wait. .. warning:: If you have any instance with static IP assignation on VXLAN or GRE tenant networks, you will need to manually modify the configuration of those instances to configure the new geneve MTU, which is current VXLAN MTU minus 8 bytes, that is 1442 when VXLAN based MTU was 1450. .. note:: 24h is the time based on default configuration, it actually depends on /var/lib/config-data/puppet-generated/neutron/etc/neutron/dhcp_agent.ini dhcp_renewal_time and /var/lib/config-data/puppet-generated/neutron/etc/neutron/neutron.conf dhcp_lease_duration parameters. (defaults to 86400 seconds) .. note:: Please note that migrating a VLAN deployment is not recommended at this time because of a bug in core ovn, full support is being worked out here: https://mail.openvswitch.org/pipermail/ovs-dev/2018-May/347594.html One way of verifying that the T1 parameter has propated to existing VMs is going to one of the compute nodes, and run tcpdump over one of the VM taps attached to a tenant network, we should see that requests happen around every 30 seconds. .. code-block:: console [heat-admin@overcloud-novacompute-0 ~]$ sudo tcpdump -i tap52e872c2-e6 port 67 or port 68 -n tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on tap52e872c2-e6, link-type EN10MB (Ethernet), capture size 262144 bytes 13:17:28.954675 IP 192.168.99.5.bootpc > 192.168.99.3.bootps: BOOTP/DHCP, Request from fa:16:3e:6b:41:3d, length 300 13:17:28.961321 IP 192.168.99.3.bootps > 192.168.99.5.bootpc: BOOTP/DHCP, Reply, length 355 13:17:56.241156 IP 192.168.99.5.bootpc > 192.168.99.3.bootps: BOOTP/DHCP, Request from fa:16:3e:6b:41:3d, length 300 13:17:56.249899 IP 192.168.99.3.bootps > 192.168.99.5.bootpc: BOOTP/DHCP, Reply, length 355 .. note:: This verification is not possible with cirros VMs, due to cirros udhcpc implementation which won't obey DHCP option 58 (T1), if you have any cirros based instances you will need to reboot them. 6. Run ``./ovn_migration.sh reduce-mtu``. This lowers the MTU of the pre migration VXLAN and GRE networks. You can skip this step if you use VLAN tenant networks. It will be safe to execute in such case, because the tool will ignore non-VXLAN/GRE networks. 7. Set the below tripleo heat template parameters to point to the proper OVN docker images in appropriate environment file * DockerOvnControllerConfigImage * DockerOvnControllerImage * DockerOvnNorthdImage * DockerNeutronApiImage * DockerNeutronConfigImage * DockerOvnDbsImage * DockerOvnDbsConfigImage This can be done running the next command: .. code-block:: console PREPARE_ARGS=""-e /usr/share/openstack-tripleo-heat-templates/environments/docker.yaml \ -e /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-ha.yaml"" \ ~/overcloud-prep-containers.sh 8. Run ``./ovn_migration.sh start-migration`` to kick start the migration process. ",299,165
openstack%2Felection~master~I32c91f50ca981bd89df8014fe66a496a274c9d4f,openstack/election,master,I32c91f50ca981bd89df8014fe66a496a274c9d4f,Add Jeremy Freudberg candidacy for Sahara PTL,MERGED,2019-03-06 17:34:26.000000000,2019-03-06 20:47:11.000000000,2019-03-06 20:47:11.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 17:34:26.000000000', 'files': ['candidates/train/Sahara/jeremyfreudberg@gmail.com'], 'web_link': 'https://opendev.org/openstack/election/commit/06010252ca49831f5fd7474b39f3e4f0210ba593', 'message': 'Add Jeremy Freudberg candidacy for Sahara PTL\n\nChange-Id: I32c91f50ca981bd89df8014fe66a496a274c9d4f\n'}]",0,641450,06010252ca49831f5fd7474b39f3e4f0210ba593,7,3,1,23078,,,0,"Add Jeremy Freudberg candidacy for Sahara PTL

Change-Id: I32c91f50ca981bd89df8014fe66a496a274c9d4f
",git fetch https://review.opendev.org/openstack/election refs/changes/50/641450/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Sahara/jeremyfreudberg@gmail.com'],1,06010252ca49831f5fd7474b39f3e4f0210ba593,,"Hello all! This is an official announcement of my candidacy for PTL of Sahara for the Train development cycle. # Who I am My first introduction to Sahara was in the summer of 2016, as an operator. It wasn't long until I sent my first patch upstream. Following the first PTG in Atlanta in 2017 I became increasingly involved with the project and later that year I became a core reviewer for Sahara. I must emphasize that all of this was set off by a series of fortunate coincidences; regardless, it's still a nice story of OpenStack gaining a new (and lasting) contributor. My affiliations remain with Red Hat and the Massachusetts Open Cloud (both of which have at various times funded my work on Sahara). Like many 22-year-olds, I'm about to finish undergrad: I studied computer science and linguistics. # Goals for Train I am impressed with what we have accomplished in past cycles with such a small team. We've implemented big features (APIv2, out-of-tree plugins) and kept up with the pace of OpenStack as a whole. Looking at where we stand now I propose that we focus on the following areas during the Train cycle: * Castellan/Barbican integration: it's been broken for an embarrassing amount of time, yet it's a highly desirable feature. * Python support for Spark EDP jobs: many users come to Sahara expecting this but then leave disappointed... it's time to bite the bullet. * Finishing transition to sahara-image-pack: let's have support for all our plugins in a single tool, so that sahara-image-elements can be deprecated. * Rehoming sahara-extra: the code should be hosted in one place, and I believe that place should be Apache's repository, where it will receive proper care. I have chosen these goals as a strategic investment into the reduction of future maintainers' pain. The emphasis is on fixing existing features and cutting down the number of components to maintain. Any extra capacity should be directed towards plugin upgrades or towards increasing the breadth of scenarios tested in upstream CI. # Beyond Train It is hard to tell what the future will hold. The team is at its all-time smallest. I'd suggest that the focus on stability continues. # Acknowledgements We owe a massive debt of gratitude to Telles Nobrega, who heroically served as Sahara PTL for four exhausting-yet-rewarding cycles. I also want to thank all those who have ever contributed to Sahara (or to Savanna, or, for the trivia nerds, EHO). We wouldn't be here without you. # Conclusion I'm continously honored to be a part of the OpenStack community and of the Sahara team. Thanks for your consideration. Here's to a great cycle. Best, Jeremy ",,68,0
openstack%2Felection~master~I47bbf5d35e5487401ec0d5d115787395fe214747,openstack/election,master,I47bbf5d35e5487401ec0d5d115787395fe214747,Adding Tim Burke candidacy for Swift,MERGED,2019-03-06 16:57:45.000000000,2019-03-06 20:47:10.000000000,2019-03-06 20:47:10.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 16:57:45.000000000', 'files': ['candidates/train/Swift/tim@swiftstack.com'], 'web_link': 'https://opendev.org/openstack/election/commit/86bcf40a3b85941505e0d55afee1d0f002f8890e', 'message': 'Adding Tim Burke candidacy for Swift\n\nChange-Id: I47bbf5d35e5487401ec0d5d115787395fe214747\n'}]",0,641442,86bcf40a3b85941505e0d55afee1d0f002f8890e,7,3,1,15343,,,0,"Adding Tim Burke candidacy for Swift

Change-Id: I47bbf5d35e5487401ec0d5d115787395fe214747
",git fetch https://review.opendev.org/openstack/election refs/changes/42/641442/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Swift/tim@swiftstack.com'],1,86bcf40a3b85941505e0d55afee1d0f002f8890e,,"I'd like to announce my candidacy for Swift PTL. Within the Swift community, we have established traditions that ensure we move carefully, and with purpose. Somewhere out there, there is an out-of-date-node with data scribbled down in a legacy format that we must still make durable, or an old client written against a years-old version of Swift that continues to perform its business-critical function. By keeping these realities in mind, we have (out of necessity) featured rolling-upgrades since our first release. This is not to say that we must therefore move slowly (though we often do, particularly now that the hype wave has crested, crashed, and begun to ebb). Despite our conservatism, there are few signs of ossification: new use-cases and new workloads bring new demands, and Swift evolves to satisfy them with new features. We now approach a new transition: John, our long-serving PTL, is stepping down. I have no worries, however; the Swift community is accustomed to dealing with (and thinking in terms of) an array of mostly-independent actors, working to improve the state of the system. The Swift developers are among the best I've had the pleasure to work alongside, and I have no doubt that Swift will continue to improve. I believe the best way I can further that improvement is to serve as PTL; to listen to users; to engage with operators; to enable developers. We are working on great, ambitious projects: * Pete from Red Hat is driving us supporting Python 3. We've known for a while that this would be necessary; it's good to see it finally happening. * Alex and Romain from OVH are upstreaming their (already running in production!) alternate diskfile format to support small objects. * Clay at SwiftStack continues to make replication and reconstruction better. * Kazuhiro at NTT is reworking the object-expirer queue, turning it into a general task queue. There is a lot going on in Swift. I can't wait to see what we build. ",,38,0
openstack%2Felection~master~Iaf98f5839bc3944c79b7923da0a36c31da2cf744,openstack/election,master,Iaf98f5839bc3944c79b7923da0a36c31da2cf744,Add Sundar Nadathur candidacy for Cyborg PTL.,MERGED,2019-03-06 15:00:31.000000000,2019-03-06 20:47:09.000000000,2019-03-06 20:47:09.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 15:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/33fd4a3979f6df0dbd4cc502cdbacdfb80e1f398', 'message': 'Add Sundar Nadathur candidacy for Cyborg PTL.\n\nChange-Id: Iaf98f5839bc3944c79b7923da0a36c31da2cf744\n'}, {'number': 2, 'created': '2019-03-06 17:49:25.000000000', 'files': ['candidates/train/Cyborg/sundar.nadathur@intel.com'], 'web_link': 'https://opendev.org/openstack/election/commit/e12a0291078aa3cd317a3f2de9e6a7b36ba6652a', 'message': 'Add Sundar Nadathur candidacy for Cyborg PTL.\n\nChange-Id: Iaf98f5839bc3944c79b7923da0a36c31da2cf744\n'}]",0,641407,e12a0291078aa3cd317a3f2de9e6a7b36ba6652a,9,3,2,21672,,,0,"Add Sundar Nadathur candidacy for Cyborg PTL.

Change-Id: Iaf98f5839bc3944c79b7923da0a36c31da2cf744
",git fetch https://review.opendev.org/openstack/election refs/changes/07/641407/2 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Cyborg/sundar.nadathur@intel.com'],1,33fd4a3979f6df0dbd4cc502cdbacdfb80e1f398,,"Hello Stackers, I'd like to announce my candidacy for PTL role of Cyborg for the Train cycle. Cyborg got to a rolling start in 2018 led by Howard (Zhipeng) Huang. Under his leadership, we established the basic infrastructure for sustained growth, resulting in our official release in Rocky. During the Stein release, with Li Liu as the PTL, we have made substantial progress, particularly in defining a clean database schema and device model that will form the basis for future work. In both cycles, we had several illuminating discussions with Nova developers to define how Cyborg would interact with Nova. As we move forward, there is considerable potential in Cyborg, as evidenced by the interest shown by cloud/telco operators around the world. To realize this potential and deliver real-world use cases, here's what we'll aim to accomplish in the Train cycle: * Complete the integration with Nova, so that we can launch VMs with accelerators attached to them. * Enable consumption of accelerators either as raw devices or as offloaded functions. * Support a variety of devices, by enabling Cyborg drivers for them. * Lay the groundwork for features, such as performance monitoring and health monitoring, to enable usage in production. Thanks. Sundar Nadathur ",,27,0
openstack%2Felection~master~I1c4dfac507c220e07414350babd6e204283a7b5d,openstack/election,master,I1c4dfac507c220e07414350babd6e204283a7b5d,Adding Chris Dent candidacy for Placement,MERGED,2019-03-06 12:17:25.000000000,2019-03-06 20:47:08.000000000,2019-03-06 20:47:08.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 12:17:25.000000000', 'files': ['candidates/train/Placement/cdent@anticdent.org'], 'web_link': 'https://opendev.org/openstack/election/commit/02f96f32fd92ac9fdd10dbe3064613749e779f91', 'message': 'Adding Chris Dent candidacy for Placement\n\nChange-Id: I1c4dfac507c220e07414350babd6e204283a7b5d\n'}]",0,641339,02f96f32fd92ac9fdd10dbe3064613749e779f91,7,3,1,11564,,,0,"Adding Chris Dent candidacy for Placement

Change-Id: I1c4dfac507c220e07414350babd6e204283a7b5d
",git fetch https://review.opendev.org/openstack/election refs/changes/39/641339/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Placement/cdent@anticdent.org'],1,02f96f32fd92ac9fdd10dbe3064613749e779f91,," Hi, I'm announcing my candidacy for Placement PTL for Train. I've been working on the Placement service from the start. Helping it become a straightforward HTTP API for managing resources and their inventories, qualities, and use. I believe the primary focus of the project should be to fulfill the promise of the service — to make any variety of workload placement more reasonable-to-manage and correct-to-use — while keeping the straightforwardness. Just as important is making sure the project, being newly independent, settles in well. We will need time, attention and patience to find our way. What we do as a group should be decided by the group. The role of the PTL should be to help the group reach decisions smoothly and make sure the information needed to make decisions is shared broadly. To help understand how I think about Placement, here are some ideas on areas we may wish to focus (if we agree): * Get the house in order. Get bug and feature tracking systems in place and properly documented. Prepare the Forum and PTG. * Help other projects use Placement. Adding features to Placement is often easier than taking advantage of those new features. A lot of features exist that are not yet used to their full potential. * Attend to maintenance. Bug fixing, documentation, performance, refactoring, gate management, and keeping clients up to date need to have equal or greater attention than feature development. * Do what matters. Only add features that have clear customers and use cases, and have committed owners responsible for long-term maintenance. * Experiment. Contrary to the above, some of our time should be spent discovering what may matter in the future and sharing those discoveries: ""Placement can help with that."" Edge and multi-cloud related use cases have plenty of potential. * Document. Fill in the gaps in documentation for users and contributors. There's a lot of power in Placement and using it most effectively is not as well-documented as it could be. * Be welcoming, fun, nice, and encouraging to everyone. I hope my history with the project is solid evidence for my commitment to its success. I'm extremely proud of the work we've done and optimistic about the positive impact we will have in the future. Thanks. ",,54,0
openstack%2Felection~master~Id0ba5581a0ae31ed064b056ee3c7399cd7c2fbbc,openstack/election,master,Id0ba5581a0ae31ed064b056ee3c7399cd7c2fbbc,Add Daniel Mellado candidacy for Kuryr PTL,MERGED,2019-03-06 11:53:16.000000000,2019-03-06 20:47:08.000000000,2019-03-06 20:47:08.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 11:53:16.000000000', 'files': ['candidates/train/Kuryr/dmellado@redhat.com'], 'web_link': 'https://opendev.org/openstack/election/commit/372969e77843e1c4532cf00a978c0ed64191f263', 'message': 'Add Daniel Mellado candidacy for Kuryr PTL\n\nChange-Id: Id0ba5581a0ae31ed064b056ee3c7399cd7c2fbbc\n'}]",0,641332,372969e77843e1c4532cf00a978c0ed64191f263,7,3,1,14885,,,0,"Add Daniel Mellado candidacy for Kuryr PTL

Change-Id: Id0ba5581a0ae31ed064b056ee3c7399cd7c2fbbc
",git fetch https://review.opendev.org/openstack/election refs/changes/32/641332/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Kuryr/dmellado@redhat.com'],1,372969e77843e1c4532cf00a978c0ed64191f263,dmellado_kuryr_ptl_train,"Hi Kuryrs, I'm writing this in order to announce my candidacy for Kuryr PTL during the Train cycle, althought I expect no Train horns this time at Denver! It has been my pleaseure and nonor to act as PTL for Kuryr the past two cycles and I'd like like to run for this for another release. I'd like to thank you all on helping me deliver and run this project during all this time I think we have been doing an awesome job so far within the OpenStack community. During Stein, we had an great cycle, delivering most of the goals we set for it, and movign forward, these are some of the goals that I propose for the team during the Train cycle: * Network Policies: Although this is a feature we landed in last cycle, I'd like for it to be enhanced so it gets faster, so optimizing its performance would be one of the cycle goals. * Neutron pooling resource speedupts: Tied to the last topic, it'll still need to further improve the resource handling speed. * Release model: So far we've been catching up with two release models, OpenStack and Kubernetes, as this is quite an effort and could lead to an endless testing matrix, one of the goals that I'd like to settle in the cycle would be on how to deal with such circumstances. * SRIOV/DPDK upstream gate testing. * Further improve debugging and instrospection tools usign Kubernetes plugins. * Expand the Kuryr community by adding more contributors. Also, I'd like to coordinate integrating some features that we started last cycle, such as Native OVN Layer Load balancing and Multi device/net support. Outside of this key areas, my priority is also helping the community by acting as an interface for the cross-project sessions and further improve our presence in initiatives such as Openlab, OPNFV and Edge. Besides that, I've also sent an email with etherpad links for PTG planning[1] and forum sessions[2] at the Summit. [1] https://etherpad.openstack.org/p/kuryr-denver-train-ptg-planning [2] https://etherpad.openstack.org/p/DEN-train-forum-kuryr-brainstorming Thanks a lot! Daniel Mellado (dmellado) ",,47,0
openstack%2Felection~master~I6f151f4a093ad28c225590cebb52fdfa1a85a0b7,openstack/election,master,I6f151f4a093ad28c225590cebb52fdfa1a85a0b7,Add Stephen Finucane candidacy for Documentation PTL,MERGED,2019-03-06 10:55:43.000000000,2019-03-06 20:47:07.000000000,2019-03-06 20:47:07.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 10:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/3f5a74d8847ad551dc91f80bc08c3a29e46ffa40', 'message': 'Add Stephen Finucane candidacy for Documentation PTL\n\nChange-Id: I6f151f4a093ad28c225590cebb52fdfa1a85a0b7\n'}, {'number': 2, 'created': '2019-03-06 11:40:14.000000000', 'files': ['candidates/train/Documentation/sfinucan@redhat.com'], 'web_link': 'https://opendev.org/openstack/election/commit/aa011e77383e8cf3cfc33b7c74f6645eabb5e358', 'message': 'Add Stephen Finucane candidacy for Documentation PTL\n\nChange-Id: I6f151f4a093ad28c225590cebb52fdfa1a85a0b7\n'}]",0,641317,aa011e77383e8cf3cfc33b7c74f6645eabb5e358,9,3,2,15334,,,0,"Add Stephen Finucane candidacy for Documentation PTL

Change-Id: I6f151f4a093ad28c225590cebb52fdfa1a85a0b7
",git fetch https://review.opendev.org/openstack/election refs/changes/17/641317/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Documentation/stephenfin@redhat.com'],1,3f5a74d8847ad551dc91f80bc08c3a29e46ffa40,feb-2019-elections,"Hey, I'd like to announce my candidacy for Docs PTL for the Train cycle. I've been involved in the documentation project since the heady days of 2016, back when the documentation team centrally managed the user-facing docs of every core OpenStack project. My initial contributions mostly focused on correcting and expanding the documentation related to my primary focus area in OpenStack, NFV enablement, though this slowly expanded as I built up competence in all things docs. At some point, for many disparate reasons, *os-manuals-migration* happened [1]_, and each project began taking responsbility for their own documentation. I assisted with the migration of the nova docs in particular and have been continuously involved ever since. As a result of *os-manuals-migration*, today's documentation team is mainly intended to act as a liason to other teams, stepping in to help with various documentation-related questions and, where necessary, providing additional tooling. In my opinion, this is both a pragmatic and a sustainable approach and I would like to see the documentation project continue on this trajectory, changing course only if/when necessary. As such, my focus areas for the upcoming cycle would be continued work on making documentation easier to contribute to (or unnecessary, where docs can be generated from code), cleaning up the remaining warts in the existing documentation and documentation processes, and generally ensuring the documentation team is as helpful as possible for the projects that need us. I feel I am well equipped to handle this, and I hope you do too. Cheers, Stephen (stephenfin) .. [1] https://specs.openstack.org/openstack/docs-specs/specs/pike/os-manuals-migration.html ",,34,0
openstack%2Fopenstack-helm-infra~master~Ia9acd26adf781b4508ef7028f613350077f7a970,openstack/openstack-helm-infra,master,Ia9acd26adf781b4508ef7028f613350077f7a970,[ceph-osd] fix ceph journal partition creation,MERGED,2019-03-05 22:31:16.000000000,2019-03-06 20:44:34.000000000,2019-03-06 20:44:34.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22713}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 29132}, {'_account_id': 29268}, {'_account_id': 29974}]","[{'number': 1, 'created': '2019-03-05 22:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/09eefe5e2cbafe1edf92b7eb7806d49cc46dfb3e', 'message': '[ceph-osd] fix ceph jounral partition creation\n\nThis is to run partprobe command  right after ceph jounral\npartition creation.\n\nChange-Id: Ia9acd26adf781b4508ef7028f613350077f7a970\n'}, {'number': 2, 'created': '2019-03-06 05:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fdae5351ebccf5ac9e20adaa9cdc05f2b3b75340', 'message': '[ceph-osd] fix ceph jounral partition creation\n\nThis is to run partprobe command  right after ceph jounral\npartition creation.\n\nChange-Id: Ia9acd26adf781b4508ef7028f613350077f7a970\n'}, {'number': 3, 'created': '2019-03-06 05:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4c123804b174a2fd980e5be468eb7eb8084ed842', 'message': '[ceph-osd] fix ceph jounral partition creation\n\nThis is to run partprobe command after ceph journal\npartition creation.\n\nChange-Id: Ia9acd26adf781b4508ef7028f613350077f7a970\n'}, {'number': 4, 'created': '2019-03-06 13:57:14.000000000', 'files': ['ceph-osd/templates/bin/osd/_init.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6feb7d76243d2a70cbed7b0c5c438f4f2cb1a9ac', 'message': '[ceph-osd] fix ceph journal partition creation\n\nThis is to run partprobe command after ceph journal\npartition creation.\n\nChange-Id: Ia9acd26adf781b4508ef7028f613350077f7a970\n'}]",2,641148,6feb7d76243d2a70cbed7b0c5c438f4f2cb1a9ac,25,9,4,28372,,,0,"[ceph-osd] fix ceph journal partition creation

This is to run partprobe command after ceph journal
partition creation.

Change-Id: Ia9acd26adf781b4508ef7028f613350077f7a970
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/48/641148/4 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/osd/_init.sh.tpl'],1,09eefe5e2cbafe1edf92b7eb7806d49cc46dfb3e,, udev_settle,,1,0
openstack%2Fnova~master~I25454cd408e08589e5cfd6107dcbadd15bbb405f,openstack/nova,master,I25454cd408e08589e5cfd6107dcbadd15bbb405f,Validate PCI aliases early in resize,MERGED,2019-03-05 21:45:04.000000000,2019-03-06 20:34:03.000000000,2019-03-06 08:42:39.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-03-05 21:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2352a1c70b5bc491dbcfe87977b0f2c0b907a97', 'message': 'Validate PCI aliases early in resize\n\nAdd an early check to validate any PCI aliases in the requested flavor\nduring a resize.  This should ensure the user gets a useful error\nmessage.\n\nblueprint: flavor-extra-spec-image-property-validation\nChange-Id: I25454cd408e08589e5cfd6107dcbadd15bbb405f\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n'}, {'number': 2, 'created': '2019-03-05 22:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/569775ce0a7ffc693ef12dba1a867a690fac088c', 'message': 'Validate PCI aliases early in resize\n\nAdd an early check to validate any PCI aliases in the requested flavor\nduring a resize.  This should ensure the user gets a useful error\nmessage.\n\nblueprint: flavor-extra-spec-image-property-validation\nChange-Id: I25454cd408e08589e5cfd6107dcbadd15bbb405f\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n'}, {'number': 3, 'created': '2019-03-05 22:39:26.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb908e154d230907585b980c9ce45a4c335396de', 'message': 'Validate PCI aliases early in resize\n\nAdd an early check to validate any PCI aliases in the requested flavor\nduring a resize.  This should ensure the user gets a useful error\nmessage.\n\nblueprint: flavor-extra-spec-image-property-validation\nChange-Id: I25454cd408e08589e5cfd6107dcbadd15bbb405f\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n'}]",4,641131,fb908e154d230907585b980c9ce45a4c335396de,25,10,3,8768,,,0,"Validate PCI aliases early in resize

Add an early check to validate any PCI aliases in the requested flavor
during a resize.  This should ensure the user gets a useful error
message.

blueprint: flavor-extra-spec-image-property-validation
Change-Id: I25454cd408e08589e5cfd6107dcbadd15bbb405f
Signed-off-by: Chris Friesen <chris.friesen@windriver.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/641131/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/api.py']",3,e2352a1c70b5bc491dbcfe87977b0f2c0b907a97,bp/flavor-extra-spec-image-property-validation," root_bdm, validate_numa=True, validate_pci=False): """"""Validate the flavor and image. This is called from the API service to ensure that the flavor extra-specs and image properties are self-consistent and compatible with each other. :param validate_pci: Flag to indicate whether or not to validate the PCI-related metadata. See _validate_flavor_image() for full description. """""" if validate_pci: pci_request.get_pci_requests_from_flavor(instance_type) context, image, new_instance_type, root_bdm=None, validate_pci=True)"," root_bdm, validate_numa=True): context, image, new_instance_type, root_bdm=None)",37,3
openstack%2Ftripleo-common~stable%2Fqueens~Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704,openstack/tripleo-common,stable/queens,Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704,Specify Octavia amphora image hw_architecture property in Glance,MERGED,2019-03-05 02:19:24.000000000,2019-03-06 20:25:59.000000000,2019-03-06 20:25:59.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 02:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6ace4920b2d7cec8faee0313369a5ab5f7c412d0', 'message': 'Specify Octavia amphora image hw_architecture property in Glance\n\nIn the case of a multi-architecture cloud, Nova will try to schedule an\nAmphora to a non-x86_64 architecture compute node, which will fail the\nload balancer creation in Octavia.\n\nThis patch explicitly specifies the Amphora image hw_architecture\nproperty when the image is being uploaded to Glance. By doing so, it\nhints the Nova scheduler which compute nodes to take into\naccount when it schedules an Amphora instance.\n\nThe default for hw_architecture is x86_64, which resembles the current\nbehavior since this is the only image type that we ship.\n\nCloses-Bug: #1818563\n\nChange-Id: Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704\n'}, {'number': 2, 'created': '2019-03-06 08:29:18.000000000', 'files': ['playbooks/roles/common/defaults/main.yml', 'playbooks/roles/octavia-undercloud/tasks/image_mgmt.yml', 'workbooks/octavia_post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/17a050f13e836a1022e640f2e8a1c6f682c2a7b0', 'message': 'Specify Octavia amphora image hw_architecture property in Glance\n\nIn the case of a multi-architecture cloud, Nova will try to schedule an\nAmphora to a non-x86_64 architecture compute node, which will fail the\nload balancer creation in Octavia.\n\nThis patch explicitly specifies the Amphora image hw_architecture\nproperty when the image is being uploaded to Glance. By doing so, it\nhints the Nova scheduler which compute nodes to take into\naccount when it schedules an Amphora instance.\n\nThe default for hw_architecture is x86_64, which resembles the current\nbehavior since this is the only image type that we ship.\n\nCloses-Bug: #1818563\n\nChange-Id: Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704\n(cherry picked from commit 2f1c0b89ee15ad95e23e23995aa3340d8db59966)\n(cherry picked from commit ef5bf9deb83a81364cea39b12de0ba799aa8b8ee)\n'}]",2,640922,17a050f13e836a1022e640f2e8a1c6f682c2a7b0,12,6,2,6579,,,0,"Specify Octavia amphora image hw_architecture property in Glance

In the case of a multi-architecture cloud, Nova will try to schedule an
Amphora to a non-x86_64 architecture compute node, which will fail the
load balancer creation in Octavia.

This patch explicitly specifies the Amphora image hw_architecture
property when the image is being uploaded to Glance. By doing so, it
hints the Nova scheduler which compute nodes to take into
account when it schedules an Amphora instance.

The default for hw_architecture is x86_64, which resembles the current
behavior since this is the only image type that we ship.

Closes-Bug: #1818563

Change-Id: Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704
(cherry picked from commit 2f1c0b89ee15ad95e23e23995aa3340d8db59966)
(cherry picked from commit ef5bf9deb83a81364cea39b12de0ba799aa8b8ee)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/22/640922/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/common/defaults/main.yml', 'playbooks/roles/octavia-undercloud/tasks/image_mgmt.yml', 'workbooks/octavia_post.yaml']",3,6ace4920b2d7cec8faee0313369a5ab5f7c412d0,bug/1818563, - amp_hw_arch amp_hw_arch: <% $.amp_hw_arch %>,,4,0
openstack%2Ftripleo-common~stable%2Frocky~Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704,openstack/tripleo-common,stable/rocky,Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704,Specify Octavia amphora image hw_architecture property in Glance,MERGED,2019-03-05 02:18:45.000000000,2019-03-06 20:25:58.000000000,2019-03-06 20:25:58.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 02:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1c88be2bf5a4ea4a4924f2b66533cff217729053', 'message': 'Specify Octavia amphora image hw_architecture property in Glance\n\nIn the case of a multi-architecture cloud, Nova will try to schedule an\nAmphora to a non-x86_64 architecture compute node, which will fail the\nload balancer creation in Octavia.\n\nThis patch explicitly specifies the Amphora image hw_architecture\nproperty when the image is being uploaded to Glance. By doing so, it\nhints the Nova scheduler which compute nodes to take into\naccount when it schedules an Amphora instance.\n\nThe default for hw_architecture is x86_64, which resembles the current\nbehavior since this is the only image type that we ship.\n\nCloses-Bug: #1818563\n\nChange-Id: Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704\n'}, {'number': 2, 'created': '2019-03-06 08:27:55.000000000', 'files': ['playbooks/roles/common/defaults/main.yml', 'playbooks/roles/octavia-undercloud/tasks/image_mgmt.yml', 'workbooks/octavia_post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ef5bf9deb83a81364cea39b12de0ba799aa8b8ee', 'message': 'Specify Octavia amphora image hw_architecture property in Glance\n\nIn the case of a multi-architecture cloud, Nova will try to schedule an\nAmphora to a non-x86_64 architecture compute node, which will fail the\nload balancer creation in Octavia.\n\nThis patch explicitly specifies the Amphora image hw_architecture\nproperty when the image is being uploaded to Glance. By doing so, it\nhints the Nova scheduler which compute nodes to take into\naccount when it schedules an Amphora instance.\n\nThe default for hw_architecture is x86_64, which resembles the current\nbehavior since this is the only image type that we ship.\n\nCloses-Bug: #1818563\n\nChange-Id: Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704\n(cherry picked from commit 2f1c0b89ee15ad95e23e23995aa3340d8db59966)\n'}]",2,640921,ef5bf9deb83a81364cea39b12de0ba799aa8b8ee,13,6,2,6579,,,0,"Specify Octavia amphora image hw_architecture property in Glance

In the case of a multi-architecture cloud, Nova will try to schedule an
Amphora to a non-x86_64 architecture compute node, which will fail the
load balancer creation in Octavia.

This patch explicitly specifies the Amphora image hw_architecture
property when the image is being uploaded to Glance. By doing so, it
hints the Nova scheduler which compute nodes to take into
account when it schedules an Amphora instance.

The default for hw_architecture is x86_64, which resembles the current
behavior since this is the only image type that we ship.

Closes-Bug: #1818563

Change-Id: Ia7be6503a40e08d0d1f7f4d89132c9e9b5bd6704
(cherry picked from commit 2f1c0b89ee15ad95e23e23995aa3340d8db59966)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/21/640921/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/common/defaults/main.yml', 'playbooks/roles/octavia-undercloud/tasks/image_mgmt.yml', 'workbooks/octavia_post.yaml']",3,1c88be2bf5a4ea4a4924f2b66533cff217729053,bug/1818563, - amp_hw_arch amp_hw_arch: <% $.amp_hw_arch %>,,4,0
openstack%2Felection~master~Id5bf7b22ad803a6f05ed6024fd429f6eba54411e,openstack/election,master,Id5bf7b22ad803a6f05ed6024fd429f6eba54411e,Adding Trinh Nguyen candidacy for Searchlight PTL,MERGED,2019-03-06 03:33:22.000000000,2019-03-06 20:24:36.000000000,2019-03-06 20:24:36.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 12898}, {'_account_id': 15471}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 27488}, {'_account_id': 29228}]","[{'number': 1, 'created': '2019-03-06 03:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/ca523d453fa95fe9ed1d54f7ba6ac09106383c32', 'message': 'Adding Trinh Nguyen candidacy for Searchlight PTL\n\nChange-Id: Id5bf7b22ad803a6f05ed6024fd429f6eba54411e\n'}, {'number': 2, 'created': '2019-03-06 03:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/29820d7405f77d609be08871a62c0bcfb6a9280f', 'message': 'Adding Trinh Nguyen candidacy for Searchlight PTL\n\nChange-Id: Id5bf7b22ad803a6f05ed6024fd429f6eba54411e\n'}, {'number': 3, 'created': '2019-03-06 03:36:24.000000000', 'files': ['candidates/train/Searchlight/dangtrinhnt@gmail.com'], 'web_link': 'https://opendev.org/openstack/election/commit/24260e5ab8b3c94d6ff59dcb15410b85de28a444', 'message': 'Adding Trinh Nguyen candidacy for Searchlight PTL\n\nChange-Id: Id5bf7b22ad803a6f05ed6024fd429f6eba54411e\n'}]",0,641193,24260e5ab8b3c94d6ff59dcb15410b85de28a444,12,8,3,27068,,,0,"Adding Trinh Nguyen candidacy for Searchlight PTL

Change-Id: Id5bf7b22ad803a6f05ed6024fd429f6eba54411e
",git fetch https://review.opendev.org/openstack/election refs/changes/93/641193/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Searchlight/dangtrinhnt@gmail.com'],1,ca523d453fa95fe9ed1d54f7ba6ac09106383c32,,"Hello. I am hereby announcing my candidacy for Searchlight PTL for Train. I have been involved in OpenStack since the Queens cycle as it is needed for my research. Over the last three cycles, I learned a lot in both technical and organizational aspects. That is thank to the help of many community members, TCs, PTLs of the OpenStack projects that I am working on. That inspired me to take the role of Searchlight PTL to help survive the project. I could say I can commit my time for that responsibility with my current job. As many of you may know, at the end of the Rocky cycle, the TC intended to remove Searchlight from the Governance (OpenStack official projects). The reasons for that are because Searchlight has missed several milestones and lacked communication of the PTL. I couldn't stand the fact that a pretty cool project like Searchlight would be abandoned so I volunteered to be the PTL of Searchlight for the Stein cycle. I hoped that I could do something to revive it. With the help of some contributors, we finally could find a ""light"" for the project. In the first two milestones of Stein, Searchlight has identified itself as a useful tool in several use cases such as being a cloud resource lookup, a cloud resource repository, and a multi-cloud search solution [1]. We hope those use cases will attract more contributors and vendors to support and use Searchlight in the near future. Moroever, the team has developed a grand vision for Searchlight [2] to help sustain the project in alignment with the OpenStack Cloud Vision [3]. The very first thing to make that vision come true is building a strong foundation for Searchlight. I take that responsibility personally and passionately. Like many other OpenStack projects, there are always challenges in contributor participation. For that, I especially see the new contributor engagement is an important job of the PTL and always looking for opportunities to do that (e.g., conferences, meetup, training, etc.). That will not be changed whether you'll have me as the Searchlight PTL for Train or not. I will continue working on helping potential developers to come to Searchlight and build a strong community around it. I know that I knew nothing about Searchlight before Stein. I'm not trying to change things with big ideas here. I just want to help Searchlight succeed in Train and further if I can. Thank you for your consideration. Trinh Nguyen (dangtrinhnt) [1] https://docs.openstack.org/searchlight/latest/user/usecases.html [2] https://docs.openstack.org/searchlight/latest/contributor/searchlight-vision.html [3] https://docs.openstack.org/searchlight/latest/contributor/vision-reflection.html ",,46,0
openstack%2Felection~master~I02dcdfbb1efebe1823b51678251abff9f9a4ac15,openstack/election,master,I02dcdfbb1efebe1823b51678251abff9f9a4ac15,Add Thomas Bechtold for Packaging Rpm for the Train cycle,MERGED,2019-03-05 08:30:27.000000000,2019-03-06 20:22:56.000000000,2019-03-06 20:22:55.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 6593}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 08:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/422dab18d0c11a1403b363afba761bef46015c6d', 'message': 'Add Thomas Bechtold for Packaging Rpm for the Train cycle\n\nChange-Id: I02dcdfbb1efebe1823b51678251abff9f9a4ac15\n'}, {'number': 2, 'created': '2019-03-06 08:18:22.000000000', 'files': ['candidates/train/Packaging_Rpm/tbechtold@suse.com'], 'web_link': 'https://opendev.org/openstack/election/commit/f7d11905299bde63b80ec5de59f04628879b3377', 'message': 'Add Thomas Bechtold for Packaging Rpm for the Train cycle\n\nChange-Id: I02dcdfbb1efebe1823b51678251abff9f9a4ac15\n'}]",0,640951,f7d11905299bde63b80ec5de59f04628879b3377,11,4,2,7102,,,0,"Add Thomas Bechtold for Packaging Rpm for the Train cycle

Change-Id: I02dcdfbb1efebe1823b51678251abff9f9a4ac15
",git fetch https://review.opendev.org/openstack/election refs/changes/51/640951/1 && git format-patch -1 --stdout FETCH_HEAD,"['candidates/train/Packaging_Rpm/toabctl.txt', 'candidates/train/Packaging_Rpm/.placeholder']",2,422dab18d0c11a1403b363afba761bef46015c6d,640951,,,16,0
openstack%2Felection~master~I0a143671a024a85fe53e0ea8acbc6b8d832688fe,openstack/election,master,I0a143671a024a85fe53e0ea8acbc6b8d832688fe,Add Eric Fried candidacy for Nova PTL,MERGED,2019-03-06 00:44:08.000000000,2019-03-06 20:21:40.000000000,2019-03-06 20:21:40.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2019-03-06 00:44:08.000000000', 'files': ['candidates/train/Nova/openstack@fried.cc'], 'web_link': 'https://opendev.org/openstack/election/commit/76ef4b77aca8e4a284dbcff3a13b18489b0c385c', 'message': 'Add Eric Fried candidacy for Nova PTL\n\nChange-Id: I0a143671a024a85fe53e0ea8acbc6b8d832688fe\n'}]",0,641177,76ef4b77aca8e4a284dbcff3a13b18489b0c385c,7,4,1,14070,,,0,"Add Eric Fried candidacy for Nova PTL

Change-Id: I0a143671a024a85fe53e0ea8acbc6b8d832688fe
",git fetch https://review.opendev.org/openstack/election refs/changes/77/641177/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Nova/openstack@fried.cc'],1,76ef4b77aca8e4a284dbcff3a13b18489b0c385c,efried_nova_ptl,"Greetings. I am hereby announcing my candidacy for Nova PTL for Train. I am passionate about OpenStack, to the point where I (like many of you) changed companies so I wouldn't have to change jobs. My employer backs me as a 100% upstream developer and core in Nova and Placement, and fully supports my commitment to the role of Nova PTL if you'll have me. Nova is huge, in code as well as in history. I don't pretend to understand all (or even most) of it. It takes the cumulative skill of the whole team to make the project tick. I see the PTL as a facilitator and coordinator of that ""group brain"", making the whole greater than the sum of the parts. That takes organization, diplomacy, and patience: qualities I have demonstrated by running the nova-scheduler meetings, helping with the politics of extracting Placement, and engaging in tough and contentious design discussions in specs, PTGs, IRC, etc. As PTL, one of my main goals will be to keep those conversations moving and focused, avoiding unproductive tangents. We continue to face challenges in contributor (which includes reviewer!) participation. Partly this is due to the overall change in the character of the community; but I hope to break down barriers for new or part-time contributors who are willing and able to participate. In day-to-day operations this means being responsive and encouraging on IRC and gerrit. In forum and PTG sessions it means working to avoid the ""echo chamber effect"" and ceding the floor to these less-involved participants so they can be heard. I would also like to continue blueprint tracking including runways, which has been an effective way to ensure attention for efforts outside of our deemed main themes and priorities. Nova is on the cusp of being able to take advantage of advanced Placement features such as nested and sharing providers to solve some of the problems for which Placement was originally conceived. Nova will need to continue to work closely with Placement in its new position as an independent project. I intend to continue being an active Placement core regardless of the outcome of these elections to assist in that transition. We need to continue to foster our relationships with other teams, ensuring proper care and feeding of cross-project initiatives. This applies to the old guard (Cinder, Glance, Ironic, Keystone, Neutron, and Placement as noted) but also to nascent efforts such as Cyborg. This starts with forum and PTG logistics for Denver, and continues with constant communication during the cycle. I am aware that I am standing on the shoulders of giants. I'm not trying to do anything brilliantly new here. I want to follow the lead of my predecessors and continue to tap them for their expertise and experience to help Nova succeed in Train. Thank you for your consideration. Eric Fried (efried) (rhymes with 'deed', not with 'side') ",,52,0
openstack%2Fcinder~stable%2Fpike~Ia2773f930513a5c8914e40805291d015a2ecb130,openstack/cinder,stable/pike,Ia2773f930513a5c8914e40805291d015a2ecb130,Fix for auth version change in Brcd HTTP,MERGED,2019-03-02 04:43:28.000000000,2019-03-06 20:06:21.000000000,2019-03-06 20:06:21.000000000,"[{'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15296}, {'_account_id': 15670}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2019-03-02 04:43:28.000000000', 'files': ['cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py', 'cinder/tests/unit/zonemanager/test_brcd_http_fc_zone_client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dc6a56ddedf4bb3c2b6ca3eb0d354726330beb8f', 'message': 'Fix for auth version change in Brcd HTTP\n\nOn FOS 8.1.0b and greater firmwares, the authentication\nfor HTTP sessions has changed.  Add check to get\nthe auth version, then authenticate with identifier\nrather than randomno when authversion is not 1.\n\nAlso, the formatting of nsinfo.htm has changed,\nso now using the formatted nsinfo.html page\nto gather nport wwns from the name server.\n\nChange-Id: Ia2773f930513a5c8914e40805291d015a2ecb130\nCloses-Bug: #1810327\n(cherry picked from commit 28a696ea625e4113706e030b773fcf39cb1c49a1)\n'}]",0,640568,dc6a56ddedf4bb3c2b6ca3eb0d354726330beb8f,24,20,1,8757,,,0,"Fix for auth version change in Brcd HTTP

On FOS 8.1.0b and greater firmwares, the authentication
for HTTP sessions has changed.  Add check to get
the auth version, then authenticate with identifier
rather than randomno when authversion is not 1.

Also, the formatting of nsinfo.htm has changed,
so now using the formatted nsinfo.html page
to gather nport wwns from the name server.

Change-Id: Ia2773f930513a5c8914e40805291d015a2ecb130
Closes-Bug: #1810327
(cherry picked from commit 28a696ea625e4113706e030b773fcf39cb1c49a1)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/68/640568/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/zonemanager/drivers/brocade/fc_zone_constants.py', 'cinder/zonemanager/drivers/brocade/brcd_http_fc_zone_client.py', 'cinder/tests/unit/zonemanager/test_brcd_http_fc_zone_client.py']",3,dc6a56ddedf4bb3c2b6ca3eb0d354726330beb8f,bug/1810327-stable/pike,auth_version = ''--BEGIN DEVICEPORT 10:00:00:05:1e:7c:64:96 node.wwn=20:00:00:05:1e:7c:64:96 deviceport.portnum=9 deviceport.portid=300900 deviceport.portIndex=9 deviceport.porttype=N deviceport.portwwn=10:00:00:05:1e:7c:64:96 --END DEVICEPORT 10:00:00:05:1e:7c:64:96 self.auth_version = '',"--BEGIN NS INFO 2;8;020800;N ;10:00:00:05:1e:7c:64:96;20:00:00:05:1e:7c:64:96;[89]"""""" \ """"""Brocade-825 | 3.0.4.09 | DCM-X3650-94 | Microsoft Windows Server 2003 R2""""""\ """"""| Service Pack 2"";FCP ; 3;20:08:00:05:1e:89:54:a0;""""""\ """"""0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0;000000;port8""""""\ """""" --END NS INFO ",40,32
openstack%2Fnova~master~I8157b9e6e9da492a225cbb50a20f434f83a5fecb,openstack/nova,master,I8157b9e6e9da492a225cbb50a20f434f83a5fecb,Test live migration with config drive,MERGED,2018-05-11 13:37:00.000000000,2019-03-06 20:06:16.000000000,2019-03-06 20:06:16.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12356}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28203}]","[{'number': 1, 'created': '2018-05-11 13:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6c214ff881fbff79225df21c064047613c009e2', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 2, 'created': '2018-05-11 15:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19e7fdaa695278d9c540c5bd570bb0ff498b828c', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 3, 'created': '2018-05-11 16:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e82448bc8b9869acb06355c46dcb6151759fb18', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 4, 'created': '2018-05-11 17:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c43ab751ccf0997566567b6c7930b0b78ee43120', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 5, 'created': '2018-05-11 20:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef8588849900358934163e556ee3f0ffaff382b1', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 6, 'created': '2018-05-14 13:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b9564fee62cb5d7f33323c037647143ea8c3947', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 7, 'created': '2018-05-14 15:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/394be0353a23e0395b04aa45a5f6d8716ab5ca66', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nDepends-On: https://review.openstack.org/568317/\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 8, 'created': '2018-05-17 15:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c5a1c47abb0d25420b5ea18e5d049f525c57912', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nDepends-On: https://review.openstack.org/568317/\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 9, 'created': '2018-05-17 15:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/769c7b2db1bfbf5072e0c889cb34bdb46a1bd1c3', 'message': 'DNM: test raw image live migration with vfat config drive\n\nThis is just trying to recreate the reported bug.\n\nDepends-On: https://review.openstack.org/568317/\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}, {'number': 10, 'created': '2019-02-28 15:55:37.000000000', 'files': ['playbooks/legacy/nova-live-migration/run.yaml', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/00d9a3a2e6b4fbbffca359bf36480d902ae608cd', 'message': 'Test live migration with config drive\n\nTempest live migration tests do not create the server\nwith config drive so we do not, by default, have test\ncoverage of live migrating an instance with a config\ndrive. This change forces nova to create a config\ndrive for all instances in the nova-live-migration\njob which will also run evacuate tests with a config\ndrive attached.\n\nChange-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb\nRelated-Bug: #1770640\n'}]",1,567860,00d9a3a2e6b4fbbffca359bf36480d902ae608cd,67,18,10,6873,,,0,"Test live migration with config drive

Tempest live migration tests do not create the server
with config drive so we do not, by default, have test
coverage of live migrating an instance with a config
drive. This change forces nova to create a config
drive for all instances in the nova-live-migration
job which will also run evacuate tests with a config
drive attached.

Change-Id: I8157b9e6e9da492a225cbb50a20f434f83a5fecb
Related-Bug: #1770640
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/567860/9 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/nova-live-migration/run.yaml'],1,e6c214ff881fbff79225df21c064047613c009e2,bug/1770640," cat << 'EOF' >>""/tmp/dg-local.conf"" [[post-config|$NOVA_CPU_CONF]] [DEFAULT] config_drive_format=vfat [libvirt] images_type=raw EOF executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export DEVSTACK_GATE_CONFIGDRIVE=1", export DEVSTACK_GATE_CONFIGDRIVE=0,17,1
openstack%2Fsahara~master~I05223981bd44d5f467808576113c29fbb37a3191,openstack/sahara,master,I05223981bd44d5f467808576113c29fbb37a3191,Fixing policies inconsistencies,MERGED,2019-01-03 20:14:49.000000000,2019-03-06 20:01:33.000000000,2019-03-06 20:01:33.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2019-01-03 20:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/84303aee3d94b819dedb99ec5c7a000bb044eb34', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 2, 'created': '2019-01-10 15:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e881c8613650483ea4050ae72f436476d0ff7a91', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 3, 'created': '2019-01-10 17:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2c161daa31ca56de3a1d64fa5da37cb7bfee37d4', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 4, 'created': '2019-01-10 20:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b175e8953f7ec9e78892c6b65448039e8a581f06', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 5, 'created': '2019-01-10 20:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8b2cda69d00effee4c32d17b2b64aec12ec58160', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 6, 'created': '2019-01-10 21:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bafae45a5423629804c74b8faf4938cd5f5d19a8', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 7, 'created': '2019-01-10 22:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d3751ecb15bab01ce62716fd95a57895e5e50890', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 8, 'created': '2019-01-31 10:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0cb663bac19fb076cd05d227bd71aa05fb586348', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 9, 'created': '2019-03-04 11:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9a55293237bee28320a38930e5796d4f9e7908e7', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 10, 'created': '2019-03-05 13:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1914459543c985802191c407381b0cbe5ae47f39', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}, {'number': 11, 'created': '2019-03-06 16:50:45.000000000', 'files': ['releasenotes/notes/fixing-policy-inconsistencies-984020000cc3882a.yaml', 'sahara/common/policies/node_group_template.py', 'sahara/common/policies/cluster.py', 'sahara/common/policies/__init__.py', 'sahara/common/policies/job.py', 'sahara/common/policies/node_group_templates.py', 'sahara/common/policies/cluster_templates.py', 'sahara/common/policies/data_source.py', 'sahara/api/v2/jobs.py', 'sahara/common/policies/image.py', 'sahara/api/v2/job_binaries.py', 'sahara/api/v2/data_sources.py', 'sahara/common/policies/job_template.py', 'sahara/common/policies/base.py', 'sahara/common/policies/job_types.py', 'sahara/common/policies/plugins.py', 'sahara/api/v2/cluster_templates.py', 'sahara/api/v2/plugins.py', 'sahara/api/v2/node_group_templates.py', 'sahara/common/policies/data_sources.py', 'sahara/common/policies/images.py', 'sahara/common/policies/jobs.py', 'sahara/api/v2/clusters.py', 'sahara/api/v2/job_types.py', 'sahara/common/policies/clusters.py', 'sahara/common/policies/cluster_template.py', 'sahara/common/policies/plugin.py', 'sahara/common/policies/job_type.py', 'sahara/api/v2/job_templates.py', 'sahara/common/policies/job_binaries.py', 'sahara/common/policies/job_binary.py', 'sahara/api/v2/images.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/f422b31b81971014b6d7c4968892534752af6cda', 'message': 'Fixing policies inconsistencies\n\nFixing some jobs/job-templates/job-executions policy inconsistencies.\n\nChange-Id: I05223981bd44d5f467808576113c29fbb37a3191\nStory: #2004675\nTask: #28666\n'}]",34,628289,f422b31b81971014b6d7c4968892534752af6cda,40,4,11,8932,,,0,"Fixing policies inconsistencies

Fixing some jobs/job-templates/job-executions policy inconsistencies.

Change-Id: I05223981bd44d5f467808576113c29fbb37a3191
Story: #2004675
Task: #28666
",git fetch https://review.opendev.org/openstack/sahara refs/changes/89/628289/9 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/common/policies/job_executions.py', 'sahara/api/v2/job_templates.py', 'sahara/api/v2/jobs.py', 'sahara/common/policies/jobs.py']",4,84303aee3d94b819dedb99ec5c7a000bb044eb34,apiv2_policy," operations=[{'path': '/v1.1/{project_id}/jobs', 'method': 'GET'}]), ]),"," 'method': 'GET'}, {'path': '/v2/jobs/{job_id}', operations=[{'path': '/v1.1/{project_id}/jobs', 'method': 'GET'}, {'path': '/v2/jobs', 'method': 'GET'}]), 'method': 'PATCH'}, {'path': '/v2/jobs/{job_id}', {'path': '/v2/jobs/{job_id}', 'method': 'DELETE'}]),",20,16
openstack%2Fcinder~master~Ic37ea85f4ec778644bc9d49f513e58dc28c87907,openstack/cinder,master,Ic37ea85f4ec778644bc9d49f513e58dc28c87907,Use new target_* options in documentation,MERGED,2019-01-21 10:11:59.000000000,2019-03-06 19:59:59.000000000,2019-03-01 21:56:56.000000000,"[{'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14826}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-01-21 10:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/91af11e2df0b8962deb9be945d0b02f877a863d4', 'message': ""Use new target_* options in documentation\n\nVarious iscsi_* options were replaced with target_* options. The former\nwere initially deprecated and have now been removed.\n\nThis patch updates relevant documentation to use the new names.\n\nThere were some other hits in the documentation and code for these\nnames, but these appeared to be for third-party drivers, and I don't\nhave the context about which, if any, need to change.\n\nChange-Id: Ic37ea85f4ec778644bc9d49f513e58dc28c87907\n""}, {'number': 2, 'created': '2019-01-25 08:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4635617e21ac5a607b31da2efa58ededcfdd0cd2', 'message': ""Use new target_* options in documentation\n\nVarious iscsi_* options were replaced with target_* options. The former\nwere initially deprecated and have now been removed.\n\nThis patch updates relevant documentation to use the new names.\n\nThere were some other hits in the documentation and code for these\nnames, but these appeared to be for third-party drivers, and I don't\nhave the context about which, if any, need to change.\n\nChange-Id: Ic37ea85f4ec778644bc9d49f513e58dc28c87907\n""}, {'number': 3, 'created': '2019-02-22 16:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a57b17a7b1f4dcc589061a5bca2ccac1365a7fbc', 'message': ""Use new target_* options in documentation\n\nVarious iscsi_* options were replaced with target_* options. The former\nwere initially deprecated and have now been removed.\n\nThis patch updates relevant documentation to use the new names.\n\nThere were some other hits in the documentation and code for these\nnames, but these appeared to be for third-party drivers, and I don't\nhave the context about which, if any, need to change.\n\nChange-Id: Ic37ea85f4ec778644bc9d49f513e58dc28c87907\n""}, {'number': 4, 'created': '2019-03-01 09:52:49.000000000', 'files': ['doc/source/admin/blockstorage-multi-backend.rst', 'doc/source/install/cinder-storage-install-obs.rst', 'etc/cinder/rootwrap.d/volume.filters', 'doc/source/configuration/tables/cinder-storage.inc', 'doc/source/install/cinder-storage-install-ubuntu.rst', 'doc/source/install/cinder-storage-install-rdo.rst', 'doc/source/configuration/block-storage/drivers/lvm-volume-driver.rst', 'contrib/block-box/etc/cinder.conf.sf', 'contrib/block-box/etc/cinder.conf', 'doc/source/admin/blockstorage-lio-iscsi-support.rst', 'contrib/block-box/etc/cinder.conf.keystone'], 'web_link': 'https://opendev.org/openstack/cinder/commit/583bc0899c3d83de17c18420dfc72a041d2cbaeb', 'message': ""Use new target_* options in documentation\n\nVarious iscsi_* options were replaced with target_* options. The former\nwere initially deprecated and have now been removed.\n\nThis patch updates relevant documentation to use the new names.\n\nThere were some other hits in the documentation and code for these\nnames, but these appeared to be for third-party drivers, and I don't\nhave the context about which, if any, need to change.\n\nChange-Id: Ic37ea85f4ec778644bc9d49f513e58dc28c87907\n""}]",4,632055,583bc0899c3d83de17c18420dfc72a041d2cbaeb,163,41,4,14826,,,0,"Use new target_* options in documentation

Various iscsi_* options were replaced with target_* options. The former
were initially deprecated and have now been removed.

This patch updates relevant documentation to use the new names.

There were some other hits in the documentation and code for these
names, but these appeared to be for third-party drivers, and I don't
have the context about which, if any, need to change.

Change-Id: Ic37ea85f4ec778644bc9d49f513e58dc28c87907
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/632055/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/blockstorage-multi-backend.rst', 'doc/source/install/cinder-storage-install-obs.rst', 'etc/cinder/rootwrap.d/volume.filters', 'doc/source/configuration/tables/cinder-storage.inc', 'doc/source/install/cinder-storage-install-ubuntu.rst', 'doc/source/install/cinder-storage-install-rdo.rst', 'doc/source/configuration/block-storage/drivers/lvm-volume-driver.rst', 'contrib/block-box/etc/cinder.conf.sf', 'contrib/block-box/etc/cinder.conf', 'contrib/block-box/etc/cinder.conf.keystone', 'doc/source/admin/blockstorage-lio-iscsi-support.rst']",11,91af11e2df0b8962deb9be945d0b02f877a863d4,target-config-docs,The default mode for the ``target_helper`` tool is ``tgtadm``.``target_helper=lioadm`` in the ``cinder.conf`` file.,The default mode for the ``iscsi_helper`` tool is ``tgtadm``.``iscsi_helper=lioadm`` in the ``cinder.conf`` file.,22,22
openstack%2Fcharm-nova-cloud-controller~master~Idf1ddc01f891d58fecd7be119da9e8b1f124b5e0,openstack/charm-nova-cloud-controller,master,Idf1ddc01f891d58fecd7be119da9e8b1f124b5e0,Switch to direct execution of stestr for unit tests,MERGED,2019-03-06 12:35:23.000000000,2019-03-06 19:49:20.000000000,2019-03-06 19:49:20.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2019-03-06 12:35:23.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/dd3fdda86d3acc3def2373bbf3e8aa3c12f1dfac', 'message': 'Switch to direct execution of stestr for unit tests\n\nDrop dependency on ostestr, switch to using stestr run.\n\nChange-Id: Idf1ddc01f891d58fecd7be119da9e8b1f124b5e0\n'}]",0,641341,dd3fdda86d3acc3def2373bbf3e8aa3c12f1dfac,7,3,1,935,,,0,"Switch to direct execution of stestr for unit tests

Drop dependency on ostestr, switch to using stestr run.

Change-Id: Idf1ddc01f891d58fecd7be119da9e8b1f124b5e0
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/41/641341/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,dd3fdda86d3acc3def2373bbf3e8aa3c12f1dfac,switch-to-stestr,commands = stestr run {posargs} stestr run {posargs},commands = ostestr {posargs} ostestr {posargs},3,3
openstack%2Fcharm-nova-compute~master~I46b8a8453cdc045f10850958652af920c8a19660,openstack/charm-nova-compute,master,I46b8a8453cdc045f10850958652af920c8a19660,Add iSCSI to nova-compute AppArmor profile,MERGED,2019-02-11 21:54:26.000000000,2019-03-06 19:38:22.000000000,2019-03-06 19:37:40.000000000,"[{'_account_id': 2424}, {'_account_id': 6737}, {'_account_id': 7730}, {'_account_id': 8992}, {'_account_id': 17097}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 21:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/ff197dc471b339c96a05e12be9344f795eabc19e', 'message': 'Add iSCSI to nova-compute AppArmor profile\n\nWhen nova-compute is deployed with AppArmor in enforce mode, it\nfails to attach iSCSI volumes because it is being blocked.\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\n'}, {'number': 2, 'created': '2019-02-13 21:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/ff571ff5bbd9a1f936da4edd8fa5198f4bf6ae15', 'message': '[WIP] Add iSCSI to nova-compute AppArmor profile\n\nWhen nova-compute is deployed with AppArmor in enforce mode, it\nfails to attach iSCSI volumes because it is being blocked.\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\n'}, {'number': 3, 'created': '2019-02-14 13:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/a54dd7f4ccb817885851a115b6d769eadc91db4d', 'message': '[WIP] Add iSCSI to nova-compute AppArmor profile\n\nWhen nova-compute is deployed with AppArmor in enforce mode, it\nfails to attach iSCSI volumes because it is being blocked.\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\n'}, {'number': 4, 'created': '2019-02-14 18:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/433bd5bea28175bc9122d4862547b659aab00018', 'message': 'Add iSCSI to nova-compute AppArmor profile\n\nWhen nova-compute is deployed with AppArmor in enforce mode, it\nfails to attach iSCSI volumes because it is being blocked.\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\n'}, {'number': 5, 'created': '2019-02-18 13:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/d91c2cec05ceb9c5f5104a8c6c79c8bba8dfddf8', 'message': 'Add iSCSI to nova-compute AppArmor profile\n\nWhen nova-compute is deployed with AppArmor in enforce mode, it\nfails to attach iSCSI volumes because it is being blocked.\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\n'}, {'number': 6, 'created': '2019-02-18 14:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/6f0f470359573f7cbde52050dc8a48ad673720dc', 'message': 'Fix iSCSI not being able to attach\n\niSCSI volumes currently fail to attach for two differnt reasons:\n  - When nova-compute is deployed with AppArmor in enforce mode, it\nblocks iSCSI services;\n  - If iscsid is not running\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes. It also changes charm hooks to ensure that iscsid\nis running.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\nCloses-bug: #1816435\n'}, {'number': 7, 'created': '2019-02-19 12:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/c8cf84bb565b9931bc1f48641003b266095b8f1f', 'message': 'Fix iSCSI not being able to attach\n\niSCSI volumes currently fail to attach for two differnt reasons:\n  - When nova-compute is deployed with AppArmor in enforce mode, it\nblocks iSCSI services;\n  - If iscsid is not running\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes. It also changes charm hooks to ensure that iscsid\nis running.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\nCloses-bug: #1816435\n'}, {'number': 8, 'created': '2019-02-20 10:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/7625797d16d090f73d88258a152bf03be667ae14', 'message': 'Fix iSCSI not being able to attach\n\niSCSI volumes currently fail to attach for two differnt reasons:\n  - When nova-compute is deployed with AppArmor in enforce mode, it\nblocks iSCSI services;\n  - If iscsid is not running\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes. It also changes charm hooks to ensure that iscsid\nis running.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\nCloses-bug: #1816435\n'}, {'number': 9, 'created': '2019-02-20 10:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/e25b6c33f260ecd37f91d0a20eed633865c6d479', 'message': 'Fix iSCSI not being able to attach\n\niSCSI volumes currently fail to attach for two differnt reasons:\n  - When nova-compute is deployed with AppArmor in enforce mode, it\nblocks iSCSI services;\n  - If iscsid is not running\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes. It also changes charm hooks to ensure that iscsid\nis running.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\nCloses-bug: #1816435\n'}, {'number': 10, 'created': '2019-02-26 13:50:54.000000000', 'files': ['templates/usr.bin.nova-compute'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/ad8b38884e63ec31852031980dca94977a42b315', 'message': 'Add iSCSI to nova-compute AppArmor profile\n\nWhen nova-compute is deployed with AppArmor in enforce mode, it\nfails to attach iSCSI volumes because it is being blocked.\n\nThis patch fixes that by updating the nova-compute AppArmor profile\nto include the commands, paths and capabilities used to attach\niSCSI volumes.\n\nChange-Id: I46b8a8453cdc045f10850958652af920c8a19660\nCloses-bug: #1815519\n'}]",11,636226,ad8b38884e63ec31852031980dca94977a42b315,70,8,10,17097,,,0,"Add iSCSI to nova-compute AppArmor profile

When nova-compute is deployed with AppArmor in enforce mode, it
fails to attach iSCSI volumes because it is being blocked.

This patch fixes that by updating the nova-compute AppArmor profile
to include the commands, paths and capabilities used to attach
iSCSI volumes.

Change-Id: I46b8a8453cdc045f10850958652af920c8a19660
Closes-bug: #1815519
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/26/636226/5 && git format-patch -1 --stdout FETCH_HEAD,['templates/usr.bin.nova-compute'],1,ff197dc471b339c96a05e12be9344f795eabc19e,bug/1815519," network unix stream, /dev/disk/** r, /etc/iscsi/** rw, /etc/modprobe.d/ r, /etc/modprobe.d/** r, /proc/cmdline r, /run/lock/iscsi/ rw, /run/lock/iscsi/** rwl, /sbin/iscsiadm rix, /sys/class/iscsi_host/ r, /sys/class/iscsi_session/ r, /sys/class/iscsi_transport/ r, /sys/class/scsi_host/ r, /sys/devices/platform/** rw, /sys/devices/virtual/iscsi_transport/** r, /sys/module/scsi_transport_iscsi/** r, /sys/module/libiscsi/** r, /sys/module/libiscsi_tcp/** r, /sys/module/iscsi_tcp/** r,"," /etc/iscsi/initiatorname.iscsi r,",19,1
openstack%2Fopenstack-helm-infra~master~I33feb6dc0ca537b12448cb82ff7416bbfe2ea0a1,openstack/openstack-helm-infra,master,I33feb6dc0ca537b12448cb82ff7416bbfe2ea0a1,[CEPH] Increase the default number of PGs for pools,ABANDONED,2019-03-01 05:08:06.000000000,2019-03-06 19:34:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-01 05:08:06.000000000', 'files': ['ceph-osd/values.yaml', 'ceph-mon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ea78876e8d7a417e56d090c45cb51d1a6b717301', 'message': '[CEPH] Increase the default number of PGs for pools\n\nBy default we create pools with a minimum of 16 placement groups\nnow.\n\nChange-Id: I33feb6dc0ca537b12448cb82ff7416bbfe2ea0a1\n'}]",0,640260,ea78876e8d7a417e56d090c45cb51d1a6b717301,3,1,1,29268,,,0,"[CEPH] Increase the default number of PGs for pools

By default we create pools with a minimum of 16 placement groups
now.

Change-Id: I33feb6dc0ca537b12448cb82ff7416bbfe2ea0a1
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/60/640260/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-osd/values.yaml', 'ceph-mon/values.yaml']",2,ea78876e8d7a417e56d090c45cb51d1a6b717301,pg_default_change, osd_pool_default_pg_num: 16 osd_pool_default_pgp_num: 16,,4,0
openstack%2Fopenstack-helm-images~master~I441661e8338018f57275373efeb11134e9a7da0b,openstack/openstack-helm-images,master,I441661e8338018f57275373efeb11134e9a7da0b,[CEPH] Make the Ceph user run with an interactive bash shell,ABANDONED,2019-03-05 02:27:26.000000000,2019-03-06 19:33:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-05 02:27:26.000000000', 'files': ['ceph-daemon/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8424812a8d766150fb84dccf4bc7df48059b8303', 'message': '[CEPH] Make the Ceph user run with an interactive bash shell\n\nChange-Id: I441661e8338018f57275373efeb11134e9a7da0b\n'}]",0,640923,8424812a8d766150fb84dccf4bc7df48059b8303,3,1,1,29268,,,0,"[CEPH] Make the Ceph user run with an interactive bash shell

Change-Id: I441661e8338018f57275373efeb11134e9a7da0b
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/23/640923/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-daemon/Dockerfile.ubuntu_xenial'],1,8424812a8d766150fb84dccf4bc7df48059b8303,ceph_user, chsh -s /bin/bash ceph ;\,,1,0
openstack%2Fopenstack-zuul-jobs~master~I5dd7200b03e588d188fca0eadda56983cdcb28bb,openstack/openstack-zuul-jobs,master,I5dd7200b03e588d188fca0eadda56983cdcb28bb,Add puppet-vcsrepo as required project on puppet jobs,MERGED,2019-03-05 23:46:11.000000000,2019-03-06 19:24:06.000000000,2019-03-06 19:24:06.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 23:46:11.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/359c3fdf2409348195f3e9bf131027028488cbc6', 'message': 'Add puppet-vcsrepo as required project on puppet jobs\n\nWe want to install this repo as an integration module now so that we can\ninstall from HEAD but to do that our jobs need to include this repo as a\nrequired project so that testing works.\n\nChange-Id: I5dd7200b03e588d188fca0eadda56983cdcb28bb\n'}]",0,641161,359c3fdf2409348195f3e9bf131027028488cbc6,8,4,1,4146,,,0,"Add puppet-vcsrepo as required project on puppet jobs

We want to install this repo as an integration module now so that we can
install from HEAD but to do that our jobs need to include this repo as a
required project so that testing works.

Change-Id: I5dd7200b03e588d188fca0eadda56983cdcb28bb
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/61/641161/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'zuul.d/jobs.yaml']",2,359c3fdf2409348195f3e9bf131027028488cbc6,puppet-4, - openstack-infra/puppet-vcsrepo,,3,0
openstack%2Fcongress~master~I1bea6fd68921410724c8427167966752dbb6e947,openstack/congress,master,I1bea6fd68921410724c8427167966752dbb6e947,Mock rather than modify DataSourceDriver.TRANSLATORS in unit tests,MERGED,2019-01-29 01:26:24.000000000,2019-03-06 19:20:07.000000000,2019-03-06 19:20:07.000000000,"[{'_account_id': 18591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-29 01:26:24.000000000', 'files': ['congress/tests/datasources/test_datasource_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/6419ef18d05e673c2bf0b5eaa333d258980ac547', 'message': 'Mock rather than modify DataSourceDriver.TRANSLATORS in unit tests\n\nDirect modification of DataSourceDriver.TRANSLATORS constant for unit testing\ncauses some unit tests to affect one another. So we instead use contextual\nmocking.\n\nChange-Id: I1bea6fd68921410724c8427167966752dbb6e947\n'}]",0,633637,6419ef18d05e673c2bf0b5eaa333d258980ac547,6,2,1,18591,,,0,"Mock rather than modify DataSourceDriver.TRANSLATORS in unit tests

Direct modification of DataSourceDriver.TRANSLATORS constant for unit testing
causes some unit tests to affect one another. So we instead use contextual
mocking.

Change-Id: I1bea6fd68921410724c8427167966752dbb6e947
",git fetch https://review.opendev.org/openstack/congress refs/changes/37/633637/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/tests/datasources/test_datasource_driver.py'],1,6419ef18d05e673c2bf0b5eaa333d258980ac547,," @mock.patch('congress.datasources.datasource_driver.DataSourceDriver.' 'TRANSLATORS', [level1_translator]) def do_test(): driver = datasource_driver.DataSourceDriver('', None) # test schema schema = driver.get_schema() expected = {'level1': ({'name': 'id', 'desc': None},), 'level2': ({'name': 'level1_id', 'desc': None}, {'name': 'thing', 'desc': None})} self.assertEqual(schema, expected) # test data data = [{'id': 11, 'level2': {'thing': 'blah!'}}] row_data = driver.convert_objs(data, level1_translator) expected = [('level2', (11, 'blah!')), ('level1', (11,))] self.assertEqual(row_data, expected) do_test() @mock.patch('congress.datasources.datasource_driver.DataSourceDriver.' 'TRANSLATORS', [level1_translator]) def do_test(): driver = datasource_driver.DataSourceDriver('', None) # test schema schema = driver.get_schema() expected = {'level1': ({'name': 'id', 'desc': None},), 'level2': ('level1_id', 'id', 'value')} self.assertEqual(expected, schema) # test data data = [{'id': 11, 'level2': {'thing': 'blah!'}}] row_data = driver.convert_objs(data, level1_translator) expected = [('level2', (11, 'thing', 'blah!')), ('level1', (11,))] self.assertEqual(row_data, expected) do_test() @mock.patch('congress.datasources.datasource_driver.DataSourceDriver.' 'TRANSLATORS', [level1_translator]) def do_test(): driver = datasource_driver.DataSourceDriver('', None) # test schema schema = driver.get_schema() expected = {'level1': ({'name': 'id', 'desc': None},), 'level2': ({'name': 'level1_id', 'desc': 'level1_parent-desc'}, {'name': 'level_1_data', 'desc': 'level_1_desc'})} self.assertEqual(expected, schema) # test data data = [{'id': 11, 'level2': ['thing']}] row_data = driver.convert_objs(data, level1_translator) expected = [('level2', (11, 'thing')), ('level1', (11,))] self.assertEqual(row_data, expected) do_test()"," driver = datasource_driver.DataSourceDriver('', None) datasource_driver.DataSourceDriver.TRANSLATORS = [level1_translator] driver.register_translator(level1_translator) # test schema schema = driver.get_schema() expected = {'level1': ({'name': 'id', 'desc': None},), 'level2': ({'name': 'level1_id', 'desc': None}, {'name': 'thing', 'desc': None})} self.assertEqual(schema, expected) # test data data = [{'id': 11, 'level2': {'thing': 'blah!'}}] row_data = driver.convert_objs(data, level1_translator) expected = [('level2', (11, 'blah!')), ('level1', (11,))] self.assertEqual(row_data, expected) driver = datasource_driver.DataSourceDriver('', None) datasource_driver.DataSourceDriver.TRANSLATORS = [level1_translator] # test schema schema = driver.get_schema() expected = {'level1': ({'name': 'id', 'desc': None},), 'level2': ('level1_id', 'id', 'value')} self.assertEqual(expected, schema) # test data data = [{'id': 11, 'level2': {'thing': 'blah!'}}] row_data = driver.convert_objs(data, level1_translator) expected = [('level2', (11, 'thing', 'blah!')), ('level1', (11,))] self.assertEqual(row_data, expected) driver = datasource_driver.DataSourceDriver('', None) datasource_driver.DataSourceDriver.TRANSLATORS = [level1_translator] # test schema schema = driver.get_schema() expected = {'level1': ({'name': 'id', 'desc': None},), 'level2': ({'name': 'level1_id', 'desc': 'level1_parent-desc'}, {'name': 'level_1_data', 'desc': 'level_1_desc'})} self.assertEqual(expected, schema) # test data data = [{'id': 11, 'level2': ['thing']}] row_data = driver.convert_objs(data, level1_translator) expected = [('level2', (11, 'thing')), ('level1', (11,))] self.assertEqual(row_data, expected)",55,41
openstack%2Fnova~master~I8c47fe14773fc97b53141ce4145e7d60545caee3,openstack/nova,master,I8c47fe14773fc97b53141ce4145e7d60545caee3,Move additional IP address management to privsep.,MERGED,2018-12-12 07:09:07.000000000,2019-03-06 19:14:56.000000000,2019-03-06 10:21:20.000000000,"[{'_account_id': 2271}, {'_account_id': 4690}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e90827104044cb599c568220a01b35490a2cb34', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 2, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad4e86dfe8b6c7460e1d1761e6035c39e93231d4', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 3, 'created': '2019-02-05 04:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/433051aae831eff19e96d3df4dc5076edb91ada8', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 4, 'created': '2019-02-07 06:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f92674a80c8d76749067e86363370814b7f0429', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 5, 'created': '2019-02-13 00:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebbe541baaf41cd665e9be8fcf8f5f1108b1dd7e', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 6, 'created': '2019-02-20 02:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9a7aa7b336c21945f14cc2a6b44258e07b4a65b', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 7, 'created': '2019-02-26 09:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfb4ead5de77e9e626e352e26cd0276ff9d85a13', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}, {'number': 8, 'created': '2019-03-05 22:35:50.000000000', 'files': ['nova/tests/unit/network/test_linux_net.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/network/linux_net.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/99ad674c26fdacfff72d84624ee060cf0e33304b', 'message': 'Move additional IP address management to privsep.\n\nChange-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3\n'}]",0,624591,99ad674c26fdacfff72d84624ee060cf0e33304b,91,19,8,2271,,,0,"Move additional IP address management to privsep.

Change-Id: I8c47fe14773fc97b53141ce4145e7d60545caee3
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/624591/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/linux_net.py', 'nova/privsep/linux_net.py']",2,9e90827104044cb599c568220a01b35490a2cb34,my-own-personal-alternative-universe,"def lookup_ip(device): return processutils.execute('ip', 'addr', 'show', 'dev', device, 'scope', 'global') @nova.privsep.sys_admin_pctxt.entrypoint def change_ip(device, ip): processutils.execute('ip', '-f', 'inet6', 'addr', 'change', ip, 'dev', device) ",,14,7
openstack%2Fnetworking-baremetal~master~I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28,openstack/networking-baremetal,master,I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28,Zuulv3 - Use ironic-base job,MERGED,2019-02-08 12:29:58.000000000,2019-03-06 19:13:39.000000000,2019-03-06 19:13:39.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 12:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/cc392459579d1ad8f62944f9ecf3114a397b7102', 'message': 'Zuulv3 - Use ironic-base job\n\nDepends-On: https://review.openstack.org/#/c/630100/\nChange-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28\n'}, {'number': 2, 'created': '2019-02-14 10:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/9bc5df32200b60439baa21c7f24f1faf6d3b1d80', 'message': 'Zuulv3 - Use ironic-base job\n\nChange-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28\n'}, {'number': 3, 'created': '2019-02-18 13:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/d7bc2c2569df86185ef0af65b0fd3e5f09ed67e3', 'message': 'Zuulv3 - Use ironic-base job\n\nChange-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28\n'}, {'number': 4, 'created': '2019-02-21 15:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/3b2e2a6437aec231439473345ca4ba7bbff0cf96', 'message': 'Zuulv3 - Use ironic-base job\n\nChange-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28\n'}, {'number': 5, 'created': '2019-02-22 09:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/954eb28a7649b7da4d724c6083af9de2aa502c65', 'message': 'Zuulv3 - Use ironic-base job\n\nChange-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28\n'}, {'number': 6, 'created': '2019-02-22 12:36:43.000000000', 'files': ['zuul.d/networking-baremetal-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/2b0408c531b60fc32c8f4f4cc405bc0c6d0ef050', 'message': 'Zuulv3 - Use ironic-base job\n\nChange-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28\n'}]",4,635824,2b0408c531b60fc32c8f4f4cc405bc0c6d0ef050,32,4,6,15519,,,0,"Zuulv3 - Use ironic-base job

Change-Id: I1564788a2ec7a6bb00b74a7e17db5ba00f91aa28
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/24/635824/5 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/networking-baremetal-jobs.yaml'],1,cc392459579d1ad8f62944f9ecf3114a397b7102,zuulv3_ironic, parent: ironic-base devstack_localrc: devstack_services:," parent: devstack-tempest - openstack/ironic - openstack/ironic-python-agent - openstack/ironic-tempest-plugin - openstack/pyghmi - openstack/virtualbmc ironic: git://git.openstack.org/openstack/ironic tox_envlist: all tempest_concurrency: 1 tempest_test_regex: ironic_tempest_plugin.tests.scenario devstack_localrc: DEFAULT_INSTANCE_TYPE: baremetal IRONIC_BAREMETAL_BASIC_OPS: True IRONIC_BUILD_DEPLOY_RAMDISK: False IRONIC_ENABLED_DRIVERS: fake IRONIC_DEPLOY_DRIVER: ipmi IRONIC_RAMDISK_TYPE: tinyipa IRONIC_VM_SPECS_RAM: 384 IRONIC_CALLBACK_TIMEOUT: 600 IRONIC_VM_LOG_DIR: '{{ devstack_base_dir }}/ironic-bm-logs' Q_AGENT: openvswitch TEMPEST_CONCURRENCY: 1 TEMPEST_PLUGINS: ""'{{ ansible_user_dir }}/src/git.openstack.org/openstack/ironic-tempest-plugin'"" VIRT_DRIVER: ironic zuul_copy_output: '{{ devstack_base_dir }}/ironic-bm-logs': 'logs' devstack_services: dstat: True etcd3: True g-api: True g-reg: True key: True mysql: True n-api: True n-api-meta: True n-cauth: True n-cond: True n-cpu: True n-novnc: True n-obj: True n-sch: True placement-api: True q-agt: True q-dhcp: True q-l3: True q-meta: True q-svc: True rabbit: True tempest: True cinder: False c-api: False c-bak: False c-sch: False c-vol: False",2,52
openstack%2Fkeystonemiddleware~master~I2f2f8f4738f43648a6bda067efe605db5807eaff,openstack/keystonemiddleware,master,I2f2f8f4738f43648a6bda067efe605db5807eaff,Fix debug tox environment,MERGED,2019-02-28 20:18:52.000000000,2019-03-06 19:05:57.000000000,2019-03-06 19:05:57.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-28 20:18:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/a2f04771f6d10b2d2af8ddfe9b257917b2128539', 'message': 'Fix debug tox environment\n\nWithout this patch, inserting a breakpoint causes the debug tox\nenvironment to hang for a long time until the testenv timeout is\nreached. This patch modifies the testenv to use similar stdout/stderr\nsettings that we use in keystoneclient and keystoneauth, which seems to\nfix the issue, and removes other unnecessary settings.\n\nChange-Id: I2f2f8f4738f43648a6bda067efe605db5807eaff\n'}]",0,640183,a2f04771f6d10b2d2af8ddfe9b257917b2128539,15,4,1,8482,,,0,"Fix debug tox environment

Without this patch, inserting a breakpoint causes the debug tox
environment to hang for a long time until the testenv timeout is
reached. This patch modifies the testenv to use similar stdout/stderr
settings that we use in keystoneclient and keystoneauth, which seems to
fix the issue, and removes other unnecessary settings.

Change-Id: I2f2f8f4738f43648a6bda067efe605db5807eaff
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/83/640183/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a2f04771f6d10b2d2af8ddfe9b257917b2128539,fix-debug, OS_STDOUT_NOCAPTURE=False OS_STDERR_NOCAPTURE=False, OS_STDOUT_CAPTURE=1 OS_STDERR_CAPTURE=1 OS_TEST_TIMEOUT=60 TESTS_DIR=./keystonemiddleware/tests/unit/ ,2,5
openstack%2Fmanila~master~Ic57510271c5617115fa1018b09105ab480ce06e4,openstack/manila,master,Ic57510271c5617115fa1018b09105ab480ce06e4,[pylint] Fix Manage-Unmanage with DHSS=True pylint issues,MERGED,2019-03-06 00:13:03.000000000,2019-03-06 18:58:46.000000000,2019-03-06 03:06:33.000000000,"[{'_account_id': 12016}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-03-06 00:13:03.000000000', 'files': ['manila/db/migrations/alembic/versions/6a3fd2984bc31_add_is_auto_deletable_and_identifier_fields_for_share_servers.py', 'manila/api/v2/share_snapshots.py', 'manila/api/v2/shares.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/5f15de40f9f98ba264526434ff3881af524f87af', 'message': '[pylint] Fix Manage-Unmanage with DHSS=True pylint issues\n\nThere were some pylint issues in change\nhttps://review.openstack.org/635831. This patch\ncorrects those.\n\nChange-Id: Ic57510271c5617115fa1018b09105ab480ce06e4\n'}]",0,641167,5f15de40f9f98ba264526434ff3881af524f87af,14,8,1,14567,,,0,"[pylint] Fix Manage-Unmanage with DHSS=True pylint issues

There were some pylint issues in change
https://review.openstack.org/635831. This patch
corrects those.

Change-Id: Ic57510271c5617115fa1018b09105ab480ce06e4
",git fetch https://review.opendev.org/openstack/manila refs/changes/67/641167/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/migrations/alembic/versions/6a3fd2984bc31_add_is_auto_deletable_and_identifier_fields_for_share_servers.py', 'manila/api/v2/share_snapshots.py', 'manila/api/v2/shares.py']",3,5f15de40f9f98ba264526434ff3881af524f87af,," @wsgi.action('unmanage') def unmanage(self, req, id, body=None): # pylint: disable=function-redefined"," @wsgi.action('unmanage') # pylint: disable=function-redefined def unmanage(self, req, id, body=None):",7,4
openstack%2Fnetworking-ovn~stable%2Fqueens~Ic9068d4bbb4602aa9d8c5d9cce8457b39057c802,openstack/networking-ovn,stable/queens,Ic9068d4bbb4602aa9d8c5d9cce8457b39057c802,Support per network dns domain name in internal OVN dns,MERGED,2018-07-23 15:29:07.000000000,2019-03-06 18:52:01.000000000,2019-03-06 18:52:01.000000000,"[{'_account_id': 4694}, {'_account_id': 6773}, {'_account_id': 10237}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-23 15:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b58b7712e12f8841a699d468134450f8fa789012', 'message': ""Support per network dns domain name in internal OVN dns\n\nIf user has set network's dns_domain attribute, this patch stores an\nadditional record in the DNS.records column as\n<port host_name>.<net_dns_domain>=<IP ADDRESSES>\n\nThis patch doesn't handle the scenario when a network's dns_domain\nis updated. This is presently left as TODO and it will be supported\nas a follow up patch.\n\nHandling the DNS entries in the OVN NB DB seems to become more complicated\nand I think it is better if we store the dns name of a port in\nLogical_Switch_Port.options column and the dns domain name and network's domain\nname in Logical_Switch.options and let ovn-northd read these values and update\nthe OVN SB DB 'DNS' table. I will pursue this approach before addressing the\nabove TODO.\n\nChange-Id: Ic9068d4bbb4602aa9d8c5d9cce8457b39057c802\nPartial-bug: #1777978\n(cherry picked from commit fb1b29e74ae7bfe30894fc0a0b840da697fecaee)\n""}, {'number': 2, 'created': '2018-10-23 14:34:29.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/functional/test_ovn_db_resources.py', 'releasenotes/notes/network-dns-domain-support-85dd1e20d9c432c6.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/fdff1ffa5c64b4898f25cb99bbe6001ebcab3321', 'message': ""Support per network dns domain name in internal OVN dns\n\nIf user has set network's dns_domain attribute, this patch stores an\nadditional record in the DNS.records column as\n<port host_name>.<net_dns_domain>=<IP ADDRESSES>\n\nThis patch doesn't handle the scenario when a network's dns_domain\nis updated. This is presently left as TODO and it will be supported\nas a follow up patch.\n\nHandling the DNS entries in the OVN NB DB seems to become more complicated\nand I think it is better if we store the dns name of a port in\nLogical_Switch_Port.options column and the dns domain name and network's domain\nname in Logical_Switch.options and let ovn-northd read these values and update\nthe OVN SB DB 'DNS' table. I will pursue this approach before addressing the\nabove TODO.\n\nChange-Id: Ic9068d4bbb4602aa9d8c5d9cce8457b39057c802\nPartial-bug: #1777978\n(cherry picked from commit fb1b29e74ae7bfe30894fc0a0b840da697fecaee)\n""}]",0,584940,fdff1ffa5c64b4898f25cb99bbe6001ebcab3321,71,4,2,6773,,,0,"Support per network dns domain name in internal OVN dns

If user has set network's dns_domain attribute, this patch stores an
additional record in the DNS.records column as
<port host_name>.<net_dns_domain>=<IP ADDRESSES>

This patch doesn't handle the scenario when a network's dns_domain
is updated. This is presently left as TODO and it will be supported
as a follow up patch.

Handling the DNS entries in the OVN NB DB seems to become more complicated
and I think it is better if we store the dns name of a port in
Logical_Switch_Port.options column and the dns domain name and network's domain
name in Logical_Switch.options and let ovn-northd read these values and update
the OVN SB DB 'DNS' table. I will pursue this approach before addressing the
above TODO.

Change-Id: Ic9068d4bbb4602aa9d8c5d9cce8457b39057c802
Partial-bug: #1777978
(cherry picked from commit fb1b29e74ae7bfe30894fc0a0b840da697fecaee)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/40/584940/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/functional/test_ovn_db_resources.py', 'releasenotes/notes/network-dns-domain-support-85dd1e20d9c432c6.yaml']",5,b58b7712e12f8841a699d468134450f8fa789012,bug/1777978,--- fixes: - | Networking-ovn was not supporting the network's dns_domain option. This is now supported during network's creation. Updating 'dns_domain' during network update is not completely supported. All the existing ports are not updated with the new network's dns_domain in OVN Northbound db. ,,68,7
openstack%2Foctavia~master~Id3bf3962a02fbf77cf886c40ac64588cbacd3832,openstack/octavia,master,Id3bf3962a02fbf77cf886c40ac64588cbacd3832,Support Host header inject for healthmonitor HTTP 1.1 health check,MERGED,2018-12-19 14:52:54.000000000,2019-03-06 18:49:32.000000000,2019-03-06 18:49:32.000000000,"[{'_account_id': 8871}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 15309}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-19 14:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e3c3030a8cc26db6fa2802199bb104f42bb77627', 'message': ""Support Host header inject for healthmonitor HTTP 1.1 health check\n\nThis patch adds 2 new options for healthmonitor HTTP health check.\n'http_version' is for user to specify the HTTP version, 1.0 and 1.1 are\navailable.\n'domain_name' is for user to specify the HTTP host header inject to check\nthe HTTP backend health.\n'domain_name' only available when HTTP version is 1.1\n\nStory: 2002160\nTask: 20010\nChange-Id: Id3bf3962a02fbf77cf886c40ac64588cbacd3832\n""}, {'number': 2, 'created': '2018-12-20 04:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1e78287ecaa7bf1c51b564baf9ac3d8748383dc0', 'message': ""Support Host header inject for healthmonitor HTTP 1.1 health check\n\nThis patch adds 2 new options for healthmonitor HTTP health check.\n'http_version' is for user to specify the HTTP version, 1.0 and 1.1 are\navailable.\n'domain_name' is for user to specify the HTTP host header inject to check\nthe HTTP backend health.\n'domain_name' only available when HTTP version is 1.1\n\nStory: 2002160\nTask: 20010\nChange-Id: Id3bf3962a02fbf77cf886c40ac64588cbacd3832\n""}, {'number': 3, 'created': '2018-12-20 07:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b8e0b5ba41b348f9fec23764b6ca14ff806e80bd', 'message': ""Support Host header inject for healthmonitor HTTP 1.1 health check\n\nThis patch adds 2 new options for healthmonitor HTTP health check.\n'http_version' is for user to specify the HTTP version, 1.0 and 1.1 are\navailable.\n'domain_name' is for user to specify the HTTP host header inject to check\nthe HTTP backend health.\n'domain_name' only available when HTTP version is 1.1\n\nStory: 2002160\nTask: 20010\nChange-Id: Id3bf3962a02fbf77cf886c40ac64588cbacd3832\n""}, {'number': 4, 'created': '2019-03-06 00:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9fcbd7bd96873d9cb0a1f82b4009c7ac7d3e58bf', 'message': ""Support Host header inject for healthmonitor HTTP 1.1 health check\n\nThis patch adds 2 new options for healthmonitor HTTP health check.\n'http_version' is for user to specify the HTTP version, 1.0 and 1.1 are\navailable.\n'domain_name' is for user to specify the HTTP host header inject to check\nthe HTTP backend health.\n'domain_name' only available when HTTP version is 1.1\n\nStory: 2002160\nTask: 20010\nChange-Id: Id3bf3962a02fbf77cf886c40ac64588cbacd3832\n""}, {'number': 5, 'created': '2019-03-06 01:24:37.000000000', 'files': ['api-ref/source/parameters.yaml', 'releasenotes/notes/support-http-health-check-with-host-header-e2cf1f2a98d4114f.yaml', 'octavia/tests/functional/api/v2/test_health_monitor.py', 'api-ref/source/v2/examples/healthmonitor-create-request.json', 'octavia/tests/functional/api/test_root_controller.py', 'octavia/common/jinja/haproxy/jinja_cfg.py', 'octavia/common/jinja/haproxy/templates/macros.j2', 'api-ref/source/v2/examples/healthmonitor-show-response.json', 'octavia/tests/unit/common/jinja/haproxy/test_jinja_cfg.py', 'octavia/common/constants.py', 'octavia/db/migration/alembic_migrations/versions/7432f1d4ea83_add_http_host_head_inject_for_http_health_check.py', 'api-ref/source/v2/healthmonitor.inc', 'octavia/tests/unit/api/drivers/test_utils.py', 'api-ref/source/v2/examples/healthmonitor-update-curl', 'octavia/tests/unit/common/sample_configs/sample_configs.py', 'api-ref/source/v2/examples/healthmonitor-update-request.json', 'octavia/db/models.py', 'octavia/api/drivers/data_models.py', 'octavia/api/v2/controllers/health_monitor.py', 'api-ref/source/v2/examples/healthmonitor-create-curl', 'octavia/common/data_models.py', 'octavia/api/v2/types/health_monitor.py', 'api-ref/source/v2/examples/healthmonitor-update-response.json', 'octavia/api/root_controller.py', 'octavia/tests/unit/api/drivers/sample_data_models.py', 'api-ref/source/v2/examples/healthmonitors-list-response.json', 'api-ref/source/v2/examples/healthmonitor-create-response.json'], 'web_link': 'https://opendev.org/openstack/octavia/commit/44833d5d5eb885323377e0e7ea89adfedc86d2a0', 'message': ""Support Host header inject for healthmonitor HTTP 1.1 health check\n\nThis patch adds 2 new options for healthmonitor HTTP health check.\n'http_version' is for user to specify the HTTP version, 1.0 and 1.1 are\navailable.\n'domain_name' is for user to specify the HTTP host header inject to check\nthe HTTP backend health.\n'domain_name' only available when HTTP version is 1.1\n\nStory: 2002160\nTask: 20010\nChange-Id: Id3bf3962a02fbf77cf886c40ac64588cbacd3832\n""}]",17,626183,44833d5d5eb885323377e0e7ea89adfedc86d2a0,21,5,5,15309,,,0,"Support Host header inject for healthmonitor HTTP 1.1 health check

This patch adds 2 new options for healthmonitor HTTP health check.
'http_version' is for user to specify the HTTP version, 1.0 and 1.1 are
available.
'domain_name' is for user to specify the HTTP host header inject to check
the HTTP backend health.
'domain_name' only available when HTTP version is 1.1

Story: 2002160
Task: 20010
Change-Id: Id3bf3962a02fbf77cf886c40ac64588cbacd3832
",git fetch https://review.opendev.org/openstack/octavia refs/changes/83/626183/3 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'releasenotes/notes/support-http-health-check-with-host-header-e2cf1f2a98d4114f.yaml', 'octavia/tests/functional/api/v2/test_health_monitor.py', 'api-ref/source/v2/examples/healthmonitor-create-request.json', 'octavia/common/jinja/haproxy/jinja_cfg.py', 'octavia/common/jinja/haproxy/templates/macros.j2', 'api-ref/source/v2/examples/healthmonitor-show-response.json', 'octavia/tests/unit/common/jinja/haproxy/test_jinja_cfg.py', 'octavia/common/constants.py', 'octavia/db/migration/alembic_migrations/versions/7432f1d4ea83_add_http_host_head_inject_for_http_health_check.py', 'api-ref/source/v2/healthmonitor.inc', 'octavia/tests/unit/api/drivers/test_utils.py', 'api-ref/source/v2/examples/healthmonitor-update-curl', 'octavia/tests/unit/common/sample_configs/sample_configs.py', 'api-ref/source/v2/examples/healthmonitor-update-request.json', 'octavia/db/models.py', 'octavia/api/drivers/data_models.py', 'octavia/api/v2/controllers/health_monitor.py', 'api-ref/source/v2/examples/healthmonitor-create-curl', 'octavia/api/common/types.py', 'octavia/common/data_models.py', 'octavia/api/v2/types/health_monitor.py', 'api-ref/source/v2/examples/healthmonitor-update-response.json', 'octavia/tests/unit/api/drivers/sample_data_models.py', 'api-ref/source/v2/examples/healthmonitors-list-response.json', 'api-ref/source/v2/examples/healthmonitor-create-response.json']",26,e3c3030a8cc26db6fa2802199bb104f42bb77627,http11_host_header_health_check," ""tags"": [""test_tag""], ""http_version"": 1.1, ""domain_name"": ""testlab.com"""," ""tags"": [""test_tag""]",374,41
openstack%2Fnova~master~I3ace688d26a340dc44e34c7c5369463b9f98a230,openstack/nova,master,I3ace688d26a340dc44e34c7c5369463b9f98a230,Move route management to privsep.,MERGED,2018-12-10 22:43:19.000000000,2019-03-06 18:42:58.000000000,2019-03-06 05:00:31.000000000,"[{'_account_id': 4690}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-10 22:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d55738622b45dd675214d56683ae8b00ad9c81cd', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 2, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfd7a5d29e45c66740baaaaf940e1fc5232a315d', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 3, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2573ed404d8da16b42863347591af4212d492355', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 4, 'created': '2019-02-05 04:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d5aabfbe392465b0014aadd3a09044cb39d883a', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 5, 'created': '2019-02-07 06:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9298bb6e8432ecb7b72e35194f35bf08d25605e', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 6, 'created': '2019-02-13 00:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90232f906874c196272d6ca92ed309e6e7f1af66', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 7, 'created': '2019-02-20 02:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8c138df3c686a02ecb982ba3539a16750b2565b', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 8, 'created': '2019-02-26 09:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/409cfc4aa5278e8bfc62c07dac18de96a5eb6cd1', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}, {'number': 9, 'created': '2019-03-05 22:35:50.000000000', 'files': ['nova/tests/unit/network/test_linux_net.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/network/linux_net.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/144205fe1b0cb87daa98562cba3bfb22b63739df', 'message': 'Move route management to privsep.\n\nSome of this code is pretty terrible, but its pre-existing terrible\nand should be cleaned up outside of the privsep transition.\n\nChange-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230\n'}]",0,624232,144205fe1b0cb87daa98562cba3bfb22b63739df,109,18,9,2271,,,0,"Move route management to privsep.

Some of this code is pretty terrible, but its pre-existing terrible
and should be cleaned up outside of the privsep transition.

Change-Id: I3ace688d26a340dc44e34c7c5369463b9f98a230
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/624232/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_linux_net.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/network/linux_net.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py']",5,d55738622b45dd675214d56683ae8b00ad9c81cd,my-own-personal-alternative-universe," @mock.patch('nova.privsep.linux_net.routes_show', return_value=('', '')) def test_vpn_allocate_fixed_ip(self, mock_routes_show, mock_enabled, mock_add_bridge): @mock.patch('nova.privsep.linux_net.routes_show', return_value=('', '')) def test_allocate_fixed_ip(self, mock_routes_show, mock_enabled, mock_add_bridge): @mock.patch('nova.privsep.linux_net.routes_show', return_value=('fake', 0)) self, mock_routes_show, mock_enabled, mock_add_bridge): @mock.patch('nova.privsep.linux_net.routes_show', return_value=('', '')) def test_allocate_for_instance(self, mock_routes_show, mock_unbind, mock_bind, mock_set_macaddr, mock_set_enabled, mock_set_mtu, mock_add_bridge): @mock.patch('nova.privsep.linux_net.routes_show', return_value=('', '')) def test_allocate_for_instance_with_mac(self, mock_routes_show, mock_set_addr, mock_enabled, mock_set_mtu, mock_add_bridge):"," def test_vpn_allocate_fixed_ip(self, mock_enabled, mock_add_bridge): def test_allocate_fixed_ip(self, mock_enabled, mock_add_bridge): self, mock_enabled, mock_add_bridge): def test_allocate_for_instance(self, mock_unbind, mock_bind, mock_set_macaddr, mock_set_enabled, mock_set_mtu, mock_add_bridge): def test_allocate_for_instance_with_mac(self, mock_set_addr, mock_enabled, mock_set_mtu, mock_add_bridge):",90,38
openstack%2Fpython-saharaclient~master~I031fdb6f7754f6cf242bfae6f10ed05249c07dac,openstack/python-saharaclient,master,I031fdb6f7754f6cf242bfae6f10ed05249c07dac,"Add missing APIv2 features to client, OSC",MERGED,2019-02-28 02:10:05.000000000,2019-03-06 18:33:11.000000000,2019-03-06 18:33:11.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-28 02:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/3a204697f9b9a724c1514a483f3dcf8531e9b53a', 'message': '[WIP]Add missing APIv2 features to OSC\n\nChange-Id: I031fdb6f7754f6cf242bfae6f10ed05249c07dac\nStory: 2003092\nTask: 23183\n'}, {'number': 2, 'created': '2019-03-04 02:35:21.000000000', 'files': ['releasenotes/notes/api-v2-features-650eb8cc0f50a729.yaml', 'saharaclient/tests/unit/osc/v2/test_node_group_templates.py', 'saharaclient/osc/v2/node_group_templates.py', 'saharaclient/api/node_group_templates.py', 'saharaclient/osc/utils.py', 'saharaclient/osc/v1/clusters.py', 'saharaclient/api/clusters.py', 'saharaclient/osc/v2/clusters.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/25043cbdf1fdfdb37201f130bd03d3e96dcce330', 'message': 'Add missing APIv2 features to client, OSC\n\nNow in the basic client:\n- Boot from volume enhancements\n- Update keypair\n\nNow in OSC:\n- Force delete cluster\n- Update keypair\n- Boot from volume enhancements\n- Decommision specific node (only via --json)\n\nChange-Id: I031fdb6f7754f6cf242bfae6f10ed05249c07dac\nStory: 2003092\nTask: 23183\nTask: 29740\n'}]",0,639883,25043cbdf1fdfdb37201f130bd03d3e96dcce330,9,3,2,23078,,,0,"Add missing APIv2 features to client, OSC

Now in the basic client:
- Boot from volume enhancements
- Update keypair

Now in OSC:
- Force delete cluster
- Update keypair
- Boot from volume enhancements
- Decommision specific node (only via --json)

Change-Id: I031fdb6f7754f6cf242bfae6f10ed05249c07dac
Story: 2003092
Task: 23183
Task: 29740
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/83/639883/1 && git format-patch -1 --stdout FETCH_HEAD,"['saharaclient/osc/v1/clusters.py', 'saharaclient/osc/v2/clusters.py']",2,3a204697f9b9a724c1514a483f3dcf8531e9b53a,osc-more-apiv2," def get_parser(self, prog_name): parser = super(DeleteCluster, self).get_parser(prog_name) parser.add_argument( '--force', action='store_true', default=False, help='Force the deletion of the cluster', ) return parser def _choose_delete_mode(self, parsed_args): if parsed_args.force: return ""force_delete"" else: return ""delete""",,22,1
openstack%2Fopenstack-ansible-os_nova~master~I4698d04e08fd0aa162c81d4a4af37a42e938d4f1,openstack/openstack-ansible-os_nova,master,I4698d04e08fd0aa162c81d4a4af37a42e938d4f1,Remove vif_plugin_is_fatal and vif_plugin_timeout values,MERGED,2019-02-27 20:24:37.000000000,2019-03-06 18:29:11.000000000,2019-03-04 20:53:12.000000000,"[{'_account_id': 1004}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-27 20:24:37.000000000', 'files': ['templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/30952d23ec4a136db2fc741534172795c0086fac', 'message': ""Remove vif_plugin_is_fatal and vif_plugin_timeout values\n\nWe are setting these values to False and 10 seconds\nrespectively and by default it is set to True and 300\nseconds, which is the desirable because we don't want\nand instance to boot if there was timeout to plug in a\nVIF. Also, 10 seconds is a really short timeout for this\n\nChange-Id: I4698d04e08fd0aa162c81d4a4af37a42e938d4f1\n""}]",0,639811,30952d23ec4a136db2fc741534172795c0086fac,11,4,1,28008,,,0,"Remove vif_plugin_is_fatal and vif_plugin_timeout values

We are setting these values to False and 10 seconds
respectively and by default it is set to True and 300
seconds, which is the desirable because we don't want
and instance to boot if there was timeout to plug in a
VIF. Also, 10 seconds is a really short timeout for this

Change-Id: I4698d04e08fd0aa162c81d4a4af37a42e938d4f1
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/11/639811/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/nova.conf.j2'],1,30952d23ec4a136db2fc741534172795c0086fac,,,vif_plugging_timeout = 10 vif_plugging_is_fatal = False,0,2
openstack%2Foctavia-tempest-plugin~master~I2422d736cb8cbf0da0ee1c748a5f0ae867dbda70,openstack/octavia-tempest-plugin,master,I2422d736cb8cbf0da0ee1c748a5f0ae867dbda70,Add octavia-lib to the base job,ABANDONED,2019-03-04 21:09:10.000000000,2019-03-06 18:25:05.000000000,,"[{'_account_id': 6579}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 21:09:10.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/57aed17a45ab79926c3d2ce156f24ff4ba2457a4', 'message': 'Add octavia-lib to the base job\n\nChange-Id: I2422d736cb8cbf0da0ee1c748a5f0ae867dbda70\n'}]",0,640868,57aed17a45ab79926c3d2ce156f24ff4ba2457a4,6,2,1,6469,,,0,"Add octavia-lib to the base job

Change-Id: I2422d736cb8cbf0da0ee1c748a5f0ae867dbda70
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/68/640868/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,57aed17a45ab79926c3d2ce156f24ff4ba2457a4,, - openstack/octavia-lib,,1,0
openstack%2Fcharm-nova-compute~master~I9ff894e728e46b229068e91a290b84cde73eb09c,openstack/charm-nova-compute,master,I9ff894e728e46b229068e91a290b84cde73eb09c,Skip sysctl configuration in containers,MERGED,2019-03-05 12:20:50.000000000,2019-03-06 18:22:47.000000000,2019-03-06 18:22:47.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2019-03-05 12:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/29f374bcefbca6bb2a5e09199d780a4c0927e817', 'message': ""Skip sysctl configuration in containers\n\nSome testing use cases make use of containers to host nova-compute;\nsysctl options can't be tweaked in this use case so detect and\nskip if executing in a container.\n\nChange-Id: I9ff894e728e46b229068e91a290b84cde73eb09c\n""}, {'number': 2, 'created': '2019-03-06 17:20:05.000000000', 'files': ['unit_tests/test_nova_compute_hooks.py', 'hooks/nova_compute_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/954a86a895e59b417227988dc3adebbba78b4ecd', 'message': ""Skip sysctl configuration in containers\n\nSome testing use cases make use of containers to host nova-compute;\nsysctl options can't be tweaked in this use case so detect and\nskip if executing in a container.\n\nChange-Id: I9ff894e728e46b229068e91a290b84cde73eb09c\n""}]",0,640995,954a86a895e59b417227988dc3adebbba78b4ecd,13,3,2,935,,,0,"Skip sysctl configuration in containers

Some testing use cases make use of containers to host nova-compute;
sysctl options can't be tweaked in this use case so detect and
skip if executing in a container.

Change-Id: I9ff894e728e46b229068e91a290b84cde73eb09c
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/95/640995/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_compute_hooks.py', 'hooks/nova_compute_hooks.py']",2,29f374bcefbca6bb2a5e09199d780a4c0927e817,sysctl-skip-containers," is_container, if sysctl_settings and not is_container():", if sysctl_settings:,15,1
openstack%2Fcharm-nova-compute~master~Idf6554ce483e9172d5f334a39a6e5251da12f27c,openstack/charm-nova-compute,master,Idf6554ce483e9172d5f334a39a6e5251da12f27c,Switch to stestr for unit execution,MERGED,2019-03-06 17:20:05.000000000,2019-03-06 18:22:46.000000000,2019-03-06 18:22:46.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2019-03-06 17:20:05.000000000', 'files': ['test-requirements.txt', '.testr.conf', 'tox.ini', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/e6c592ebfedd85a9d899838ef404e0de7dae7cd5', 'message': 'Switch to stestr for unit execution\n\nChange-Id: Idf6554ce483e9172d5f334a39a6e5251da12f27c\n'}]",0,641448,e6c592ebfedd85a9d899838ef404e0de7dae7cd5,7,3,1,935,,,0,"Switch to stestr for unit execution

Change-Id: Idf6554ce483e9172d5f334a39a6e5251da12f27c
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/48/641448/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', '.testr.conf', 'tox.ini', '.stestr.conf']",4,e6c592ebfedd85a9d899838ef404e0de7dae7cd5,sysctl-skip-containers,[DEFAULT] test_path=./unit_tests top_dir=./ ,,6,11
openstack%2Fdiskimage-builder~master~Ia75cb86981dc2d4cbca41ae95afb007cca293ace,openstack/diskimage-builder,master,Ia75cb86981dc2d4cbca41ae95afb007cca293ace,[DNM] Clean the BSP partition for the EFI layout,NEW,2019-03-06 15:50:14.000000000,2019-03-06 18:10:30.000000000,,"[{'_account_id': 4146}, {'_account_id': 15197}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25733}]","[{'number': 1, 'created': '2019-03-06 15:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0e634dcddd816e057ef10982f853ca5baec517be', 'message': 'Clean the BSP partition for the EFI layout\n\n* The block-device-efi element ships an example layout with an empty,\n  uninitialised BSP partition.\n\n* When combining this element with the centos7 baseimage, the first\n  stage of the boot completes successfully, but systemd fails to\n  correctly determine the rootfs.\n\n* This is because blkid incorrectly associates the default\n  cloudimg-rootfs label with BSP partition too.\n\n* Zeroing out the BSP partition (either during image creation, or in the\n  rescue mode) fixes this issue.\n\nChange-Id: Ia75cb86981dc2d4cbca41ae95afb007cca293ace\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\n'}, {'number': 2, 'created': '2019-03-06 16:43:15.000000000', 'files': ['diskimage_builder/elements/block-device-efi/finalise.d/49-clean-bsp-partition'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6dd0656bdcbdbc7622349a34d102df75d9580aa1', 'message': '[DNM] Clean the BSP partition for the EFI layout\n\n* THIS BREAKS STUFF, notably this change as-is means the\n  block-device-efi element would be incompatible with dual EFI/BIOS boot.\n\n* The block-device-efi element ships an example layout with an empty,\n  uninitialised BSP partition.\n\n* When combining this element with the centos7 baseimage, the first\n  stage of the boot completes successfully, but systemd fails to\n  correctly determine the rootfs.\n\n* This is because blkid incorrectly associates the default\n  cloudimg-rootfs label with BSP partition too.\n\n* Zeroing out the BSP partition (either during image creation, or in the\n  rescue mode) fixes this issue.\n\nChange-Id: Ia75cb86981dc2d4cbca41ae95afb007cca293ace\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\n'}]",3,641426,6dd0656bdcbdbc7622349a34d102df75d9580aa1,11,6,2,25733,,,0,"[DNM] Clean the BSP partition for the EFI layout

* THIS BREAKS STUFF, notably this change as-is means the
  block-device-efi element would be incompatible with dual EFI/BIOS boot.

* The block-device-efi element ships an example layout with an empty,
  uninitialised BSP partition.

* When combining this element with the centos7 baseimage, the first
  stage of the boot completes successfully, but systemd fails to
  correctly determine the rootfs.

* This is because blkid incorrectly associates the default
  cloudimg-rootfs label with BSP partition too.

* Zeroing out the BSP partition (either during image creation, or in the
  rescue mode) fixes this issue.

Change-Id: Ia75cb86981dc2d4cbca41ae95afb007cca293ace
Signed-off-by: Jan Gutter <jan.gutter@netronome.com>
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/26/641426/2 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/block-device-efi/finalise.d/49-clean-bsp-partition'],1,0e634dcddd816e057ef10982f853ca5baec517be,zero-efi-bsp-partition,#!/bin/bash # Zero out the 'BSP' partition if [ ${DIB_DEBUG_TRACE:-1} -gt 0 ]; then set -x fi set -eu set -o pipefail # Get all available devices declare -A DEVICES eval DEVICES=( $IMAGE_BLOCK_DEVICES ) if [ -b ${DEVICES[BSP]} ]; then # zero out the entire partition with 512 byte writes # NOTE(jangutter): this command will exit with non-zero status after it has # filled the block device. dd if=/dev/zero of=${DEVICES[BSP]} bs=512 || : fi ,,20,0
openstack%2Fhorizon~master~I6d77ef7135b15cfa978677c858382a0914d92c5d,openstack/horizon,master,I6d77ef7135b15cfa978677c858382a0914d92c5d,Add Project Information column in group-snapshot table,MERGED,2019-03-02 08:09:39.000000000,2019-03-06 17:51:29.000000000,2019-03-06 17:51:29.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-03-02 08:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2410844f71de6f62241491795b8ca1b89ed20487', 'message': ""Add Project Information column in group-snapshot table\n\nThis patch add 'Project' column in group-snapshot table to the\nadmin panel.Now user would be able to list all group-snapshot\ncreated by admin or demo user.\n\nDepends-On: https://review.openstack.org/#/c/639314/\nChange-Id: I6d77ef7135b15cfa978677c858382a0914d92c5d\n""}, {'number': 2, 'created': '2019-03-05 08:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ea96d064e179048408cfdf1d9dbbd4fb073356af', 'message': ""Add Project Information column in group-snapshot table\n\nThis patch add 'Project' column in group-snapshot table to the\nadmin panel.Now user would be able to list all group-snapshot\ncreated by admin or demo user.\n\nDepends-On: https://review.openstack.org/#/c/639314/\nChange-Id: I6d77ef7135b15cfa978677c858382a0914d92c5d\n""}, {'number': 3, 'created': '2019-03-05 12:20:54.000000000', 'files': ['openstack_dashboard/dashboards/admin/vg_snapshots/views.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tests.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tables.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/templates/vg_snapshots/_detail_overview.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7cb4be82b5eeed0ebffc982b7940b2aa2f79a1da', 'message': ""Add Project Information column in group-snapshot table\n\nThis patch add 'Project' column in group-snapshot table to the\nadmin panel.Now user would be able to list all group-snapshot\ncreated by admin or demo user.\n\nDepends-On: https://review.openstack.org/#/c/639314/\nChange-Id: I6d77ef7135b15cfa978677c858382a0914d92c5d\n""}]",6,640588,7cb4be82b5eeed0ebffc982b7940b2aa2f79a1da,21,8,3,29313,,,0,"Add Project Information column in group-snapshot table

This patch add 'Project' column in group-snapshot table to the
admin panel.Now user would be able to list all group-snapshot
created by admin or demo user.

Depends-On: https://review.openstack.org/#/c/639314/
Change-Id: I6d77ef7135b15cfa978677c858382a0914d92c5d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/88/640588/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/vg_snapshots/views.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tests.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/tables.py', 'openstack_dashboard/dashboards/admin/vg_snapshots/templates/vg_snapshots/_detail_overview.html']",5,2410844f71de6f62241491795b8ca1b89ed20487,admin-column," <dt>{% trans ""Project ID"" %}</dt> <dd>{{ vg_snapshot.project_id|default:_(""-"") }}</dd>",,55,3
openstack%2Fnova~master~I46d610cf2b6c328a3b6430a51477dcb4e33e6134,openstack/nova,master,I46d610cf2b6c328a3b6430a51477dcb4e33e6134,Convert additional IP management calls to privsep.,MERGED,2018-12-10 22:43:19.000000000,2019-03-06 17:50:40.000000000,2019-03-06 05:00:22.000000000,"[{'_account_id': 4690}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28239}, {'_account_id': 28885}]","[{'number': 1, 'created': '2018-12-10 22:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9011fb25eba4c07c078843156508c1f0abccf9d4', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 2, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4810135db0fc8dd11e63d53723411dca3c6891a1', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 3, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a649f44541a8a6a743c4c77fd38c32651f7bf34', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 4, 'created': '2019-02-05 04:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/674a6baad458a9ffe2758ce5e8bce5c4331352a3', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 5, 'created': '2019-02-07 06:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d8d75120a43e4c6b8cde8d8f796948eac37d8ef', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 6, 'created': '2019-02-13 00:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce86e583d22a082c168a05e928fbf8e867877b77', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 7, 'created': '2019-02-20 02:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02ee9bfc2b03c2d7b64830b409c268ae2a79e85a', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 8, 'created': '2019-02-26 09:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab081fddccc4ca1913e767ac91ad5a820846a53d', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}, {'number': 9, 'created': '2019-03-05 22:35:50.000000000', 'files': ['nova/network/linux_net.py', 'nova/network/l3.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/41ada6be3590293ccf14c707fd15e759cdfc5964', 'message': 'Convert additional IP management calls to privsep.\n\nChange-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134\n'}]",2,624231,41ada6be3590293ccf14c707fd15e759cdfc5964,99,20,9,2271,,,0,"Convert additional IP management calls to privsep.

Change-Id: I46d610cf2b6c328a3b6430a51477dcb4e33e6134
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/624231/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/linux_net.py', 'nova/network/l3.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py']",4,9011fb25eba4c07c078843156508c1f0abccf9d4,my-own-personal-alternative-universe," @mock.patch('nova.privsep.linux_net.unbind_ip') self, unbind_ip, bind_ip, net_get, fixed_get): @mock.patch('nova.privsep.linux_net.unbind_ip') def test_allocate_for_instance(self, mock_unbind, mock_bind, mock_set_macaddr, mock_set_enabled, mock_set_mtu, mock_add_bridge): @mock.patch('nova.privsep.linux_net.unbind_ip') def test_deallocation_deleted_instance(self, mock_unbind_ip): @mock.patch('nova.privsep.linux_net.unbind_ip') def test_deallocation_duplicate_floating_ip(self, mock_unbind_ip):"," self, bind_ip, net_get, fixed_get): def test_allocate_for_instance(self, mock_bind, mock_set_macaddr, mock_set_enabled, mock_set_mtu, mock_add_bridge): def test_deallocation_deleted_instance(self): def test_deallocation_duplicate_floating_ip(self):",21,21
openstack%2Fmanila~master~Ifcc616a0e90e720e5ec5b02fb8c7dfa049e1c20b,openstack/manila,master,Ifcc616a0e90e720e5ec5b02fb8c7dfa049e1c20b,"Merge ""[pylint] Fix Manage-Unmanage with DHSS=True pylint issues""",ABANDONED,2019-03-06 14:17:40.000000000,2019-03-06 17:47:08.000000000,,"[{'_account_id': 10068}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}]","[{'number': 1, 'created': '2019-03-06 14:17:40.000000000', 'files': ['manila/share/manager.py', 'manila/share/.manager.py.un~', 'manila/share/manager.py~'], 'web_link': 'https://opendev.org/openstack/manila/commit/c554054e458b7cc0a83360632cff356ca582aa91', 'message': 'Merge ""[pylint] Fix Manage-Unmanage with DHSS=True pylint issues""\n\nAdds User Message in case of Shrinking Error\n\nWhen shrinking of a share fails, there is no User Message generated.\nThis change uses the Message API module and updates the user message\nlist suggesting an UNEXPECTED_NETWORK error, which corresponds to:\n\nUNEXPECTED_NETWORK = (\'003\', \'Driver does not expect share-network\n\tto be provided with current configuration.\')\n\nChange-Id: Ifcc616a0e90e720e5ec5b02fb8c7dfa049e1c20b\nCloses-Bug: #1802424\n'}]",0,641379,c554054e458b7cc0a83360632cff356ca582aa91,7,5,1,30021,,,0,"Merge ""[pylint] Fix Manage-Unmanage with DHSS=True pylint issues""

Adds User Message in case of Shrinking Error

When shrinking of a share fails, there is no User Message generated.
This change uses the Message API module and updates the user message
list suggesting an UNEXPECTED_NETWORK error, which corresponds to:

UNEXPECTED_NETWORK = ('003', 'Driver does not expect share-network
	to be provided with current configuration.')

Change-Id: Ifcc616a0e90e720e5ec5b02fb8c7dfa049e1c20b
Closes-Bug: #1802424
",git fetch https://review.opendev.org/openstack/manila refs/changes/79/641379/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/manager.py', 'manila/share/.manager.py.un~', 'manila/share/manager.py~']",3,c554054e458b7cc0a83360632cff356ca582aa91,bug/1802424,"# Copyright (c) 2014 NetApp Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""NAS share manager managers creating shares and access rights. **Related Flags** :share_driver: Used by :class:`ShareManager`. """""" import copy import datetime import functools import hashlib from oslo_config import cfg from oslo_log import log from oslo_serialization import jsonutils from oslo_service import periodic_task from oslo_utils import excutils from oslo_utils import importutils from oslo_utils import timeutils import six from manila.common import constants from manila import context from manila import coordination from manila.data import rpcapi as data_rpcapi from manila import exception from manila.i18n import _ from manila import manager from manila.message import api as message_api from manila.message import message_field from manila import quota from manila.share import access from manila.share import api import manila.share.configuration from manila.share import drivers_private_data from manila.share import migration from manila.share import rpcapi as share_rpcapi from manila.share import share_types from manila.share import snapshot_access from manila.share import utils as share_utils from manila import utils LOG = log.getLogger(__name__) share_manager_opts = [ cfg.StrOpt('share_driver', default='manila.share.drivers.generic.GenericShareDriver', help='Driver to use for share creation.'), cfg.ListOpt('hook_drivers', default=[], help='Driver(s) to perform some additional actions before and ' 'after share driver actions and on a periodic basis. ' 'Default is [].', deprecated_group='DEFAULT'), cfg.BoolOpt('delete_share_server_with_last_share', default=False, help='Whether share servers will ' 'be deleted on deletion of the last share.'), cfg.BoolOpt('unmanage_remove_access_rules', default=False, help='If set to True, then manila will deny access and remove ' 'all access rules on share unmanage.' 'If set to False - nothing will be changed.'), cfg.BoolOpt('automatic_share_server_cleanup', default=True, help='If set to True, then Manila will delete all share ' 'servers which were unused more than specified time .' 'If set to False - automatic deletion of share servers ' 'will be disabled.', deprecated_group='DEFAULT'), cfg.IntOpt('unused_share_server_cleanup_interval', default=10, help='Unallocated share servers reclamation time interval ' '(minutes). Minimum value is 10 minutes, maximum is 60 ' 'minutes. The reclamation function is run every ' '10 minutes and delete share servers which were unused ' 'more than unused_share_server_cleanup_interval option ' 'defines. This value reflects the shortest time Manila ' 'will wait for a share server to go unutilized before ' 'deleting it.', deprecated_group='DEFAULT', min=10, max=60), cfg.IntOpt('replica_state_update_interval', default=300, help='This value, specified in seconds, determines how often ' 'the share manager will poll for the health ' '(replica_state) of each replica instance.'), cfg.IntOpt('migration_driver_continue_update_interval', default=60, help='This value, specified in seconds, determines how often ' 'the share manager will poll the driver to perform the ' 'next step of migration in the storage backend, for a ' 'migrating share.'), cfg.IntOpt('share_usage_size_update_interval', default=300, help='This value, specified in seconds, determines how often ' 'the share manager will poll the driver to update the ' 'share usage size in the storage backend, for shares in ' 'that backend.'), cfg.BoolOpt('enable_gathering_share_usage_size', default=False, help='If set to True, share usage size will be polled for in ' 'the interval specified with ' '""share_usage_size_update_interval"". Usage data can be ' 'consumed by telemetry integration. If telemetry is not ' 'configured, this option must be set to False. ' 'If set to False - gathering share usage size will be' ' disabled.'), ] CONF = cfg.CONF CONF.register_opts(share_manager_opts) CONF.import_opt('periodic_hooks_interval', 'manila.share.hook') CONF.import_opt('periodic_interval', 'manila.service') # Drivers that need to change module paths or class names can add their # old/new path here to maintain backward compatibility. MAPPING = { 'manila.share.drivers.netapp.cluster_mode.NetAppClusteredShareDriver': 'manila.share.drivers.netapp.common.NetAppDriver', 'manila.share.drivers.hp.hp_3par_driver.HP3ParShareDriver': 'manila.share.drivers.hpe.hpe_3par_driver.HPE3ParShareDriver', 'manila.share.drivers.hitachi.hds_hnas.HDSHNASDriver': 'manila.share.drivers.hitachi.hnas.driver.HitachiHNASDriver', 'manila.share.drivers.glusterfs_native.GlusterfsNativeShareDriver': 'manila.share.drivers.glusterfs.glusterfs_native.' 'GlusterfsNativeShareDriver', 'manila.share.drivers.emc.driver.EMCShareDriver': 'manila.share.drivers.dell_emc.driver.EMCShareDriver', 'manila.share.drivers.cephfs.cephfs_native.CephFSNativeDriver': 'manila.share.drivers.cephfs.driver.CephFSDriver', } QUOTAS = quota.QUOTAS def locked_share_replica_operation(operation): """"""Lock decorator for share replica operations. Takes a named lock prior to executing the operation. The lock is named with the id of the share to which the replica belongs. Intended use: If a replica operation uses this decorator, it will block actions on all share replicas of the share until the named lock is free. This is used to protect concurrent operations on replicas of the same share e.g. promote ReplicaA while deleting ReplicaB, both belonging to the same share. """""" def wrapped(*args, **kwargs): share_id = kwargs.get('share_id') @coordination.synchronized( 'locked-share-replica-operation-for-share-%s' % share_id) def locked_replica_operation(*_args, **_kwargs): return operation(*_args, **_kwargs) return locked_replica_operation(*args, **kwargs) return wrapped def add_hooks(f): """"""Hook decorator to perform action before and after a share method call The hook decorator can perform actions before some share driver methods calls and after a call with results of driver call and preceding hook call. """""" @functools.wraps(f) def wrapped(self, *args, **kwargs): if not self.hooks: return f(self, *args, **kwargs) pre_hook_results = [] for hook in self.hooks: pre_hook_results.append( hook.execute_pre_hook( func_name=f.__name__, *args, **kwargs)) wrapped_func_results = f(self, *args, **kwargs) for i, hook in enumerate(self.hooks): hook.execute_post_hook( func_name=f.__name__, driver_action_results=wrapped_func_results, pre_hook_data=pre_hook_results[i], *args, **kwargs) return wrapped_func_results return wrapped class ShareManager(manager.SchedulerDependentManager): """"""Manages NAS storages."""""" RPC_API_VERSION = '1.19' def __init__(self, share_driver=None, service_name=None, *args, **kwargs): """"""Load the driver from args, or from flags."""""" self.configuration = manila.share.configuration.Configuration( share_manager_opts, config_group=service_name) super(ShareManager, self).__init__(service_name='share', *args, **kwargs) if not share_driver: share_driver = self.configuration.share_driver if share_driver in MAPPING: msg_args = {'old': share_driver, 'new': MAPPING[share_driver]} LOG.warning(""Driver path %(old)s is deprecated, update your "" ""configuration to the new path %(new)s"", msg_args) share_driver = MAPPING[share_driver] ctxt = context.get_admin_context() private_storage = drivers_private_data.DriverPrivateData( context=ctxt, backend_host=self.host, config_group=self.configuration.config_group ) self.driver = importutils.import_object( share_driver, private_storage=private_storage, configuration=self.configuration, ) backend_availability_zone = self.driver.configuration.safe_get( 'backend_availability_zone') self.availability_zone = ( backend_availability_zone or CONF.storage_availability_zone ) self.access_helper = access.ShareInstanceAccess(self.db, self.driver) self.snapshot_access_helper = ( snapshot_access.ShareSnapshotInstanceAccess(self.db, self.driver)) self.migration_wait_access_rules_timeout = ( CONF.migration_wait_access_rules_timeout) self.message_api = message_api.API() self.hooks = [] self._init_hook_drivers() def _init_hook_drivers(self): # Try to initialize hook driver(s). hook_drivers = self.configuration.safe_get(""hook_drivers"") for hook_driver in hook_drivers: self.hooks.append( importutils.import_object( hook_driver, configuration=self.configuration, host=self.host, ) ) def _ensure_share_instance_has_pool(self, ctxt, share_instance): pool = share_utils.extract_host(share_instance['host'], 'pool') if pool is None: # No pool name encoded in host, so this is a legacy # share created before pool is introduced, ask # driver to provide pool info if it has such # knowledge and update the DB. try: pool = self.driver.get_pool(share_instance) except Exception: LOG.exception(""Failed to fetch pool name for share: "" ""%(share)s."", {'share': share_instance['id']}) return if pool: new_host = share_utils.append_host( share_instance['host'], pool) self.db.share_instance_update( ctxt, share_instance['id'], {'host': new_host}) return pool @add_hooks def init_host(self): """"""Initialization for a standalone service."""""" ctxt = context.get_admin_context() driver_host_pair = ""{}@{}"".format( self.driver.__class__.__name__, self.host) # we want to retry to setup the driver. In case of a multi-backend # scenario, working backends are usable and the non-working ones (where # do_setup() or check_for_setup_error() fail) retry. @utils.retry(Exception, interval=2, backoff_rate=2, backoff_sleep_max=600, retries=0) def _driver_setup(): self.driver.initialized = False LOG.debug(""Start initialization of driver: '%s'"", driver_host_pair) try: self.driver.do_setup(ctxt) self.driver.check_for_setup_error() except Exception: LOG.exception(""Error encountered during initialization of "" ""driver %s"", driver_host_pair) raise else: self.driver.initialized = True _driver_setup() if (self.driver.driver_handles_share_servers and hasattr(self.driver, 'service_instance_manager')): (self.driver.service_instance_manager.network_helper. setup_connectivity_with_service_instances()) self.ensure_driver_resources(ctxt) self.publish_service_capabilities(ctxt) LOG.info(""Finished initialization of driver: '%(driver)s"" ""@%(host)s'"", {""driver"": self.driver.__class__.__name__, ""host"": self.host}) def ensure_driver_resources(self, ctxt): old_backend_info = self.db.backend_info_get(ctxt, self.host) old_backend_info_hash = (old_backend_info.get('info_hash') if old_backend_info is not None else None) new_backend_info = None new_backend_info_hash = None backend_info_implemented = True update_share_instances = [] try: new_backend_info = self.driver.get_backend_info(ctxt) except Exception as e: if not isinstance(e, NotImplementedError): LOG.exception( ""The backend %(host)s could not get backend info."", {'host': self.host}) raise else: backend_info_implemented = False LOG.debug( (""The backend %(host)s does not support get backend"" "" info method.""), {'host': self.host}) if new_backend_info: new_backend_info_hash = hashlib.sha1(six.text_type( sorted(new_backend_info.items())).encode('utf-8')).hexdigest() if (old_backend_info_hash == new_backend_info_hash and backend_info_implemented): LOG.debug( (""Ensure shares is being skipped because the %(host)s's old "" ""backend info is the same as its new backend info.""), {'host': self.host}) return share_instances = self.db.share_instances_get_all_by_host( ctxt, self.host) LOG.debug(""Re-exporting %s shares"", len(share_instances)) for share_instance in share_instances: share_ref = self.db.share_get(ctxt, share_instance['share_id']) if share_ref.is_busy: LOG.info( ""Share instance %(id)s: skipping export, "" ""because it is busy with an active task: %(task)s."", {'id': share_instance['id'], 'task': share_ref['task_state']}, ) continue if share_instance['status'] != constants.STATUS_AVAILABLE: LOG.info( ""Share instance %(id)s: skipping export, "" ""because it has '%(status)s' status."", {'id': share_instance['id'], 'status': share_instance['status']}, ) continue self._ensure_share_instance_has_pool(ctxt, share_instance) share_instance = self.db.share_instance_get( ctxt, share_instance['id'], with_share_data=True) share_instance_dict = self._get_share_replica_dict( ctxt, share_instance) update_share_instances.append(share_instance_dict) if update_share_instances: try: update_share_instances = self.driver.ensure_shares( ctxt, update_share_instances) or {} except Exception as e: if not isinstance(e, NotImplementedError): LOG.exception(""Caught exception trying ensure "" ""share instances."") else: self._ensure_share(ctxt, update_share_instances) if new_backend_info: self.db.backend_info_update( ctxt, self.host, new_backend_info_hash) for share_instance in share_instances: if share_instance['id'] not in update_share_instances: continue if update_share_instances[share_instance['id']].get('status'): self.db.share_instance_update( ctxt, share_instance['id'], {'status': ( update_share_instances[share_instance['id']]. get('status')), 'host': share_instance['host']} ) update_export_location = ( update_share_instances[share_instance['id']] .get('export_locations')) if update_export_location: self.db.share_export_locations_update( ctxt, share_instance['id'], update_export_location) share_server = self._get_share_server(ctxt, share_instance) if share_instance['access_rules_status'] != ( constants.STATUS_ACTIVE): try: # Cast any existing 'applying' rules to 'new' self.access_helper.reset_applying_rules( ctxt, share_instance['id']) self.access_helper.update_access_rules( ctxt, share_instance['id'], share_server=share_server) except Exception: LOG.exception( (""Unexpected error occurred while updating access "" ""rules for share instance %(s_id)s.""), {'s_id': share_instance['id']}, ) snapshot_instances = ( self.db.share_snapshot_instance_get_all_with_filters( ctxt, {'share_instance_ids': share_instance['id']}, with_share_data=True)) for snap_instance in snapshot_instances: rules = ( self.db. share_snapshot_access_get_all_for_snapshot_instance( ctxt, snap_instance['id'])) # NOTE(ganso): We don't invoke update_access for snapshots if # we don't have invalid rules or pending updates if any(r['state'] in (constants.ACCESS_STATE_DENYING, constants.ACCESS_STATE_QUEUED_TO_DENY, constants.ACCESS_STATE_APPLYING, constants.ACCESS_STATE_QUEUED_TO_APPLY) for r in rules): try: self.snapshot_access_helper.update_access_rules( ctxt, snap_instance['id'], share_server) except Exception: LOG.exception( ""Unexpected error occurred while updating "" ""access rules for snapshot instance %s."", snap_instance['id']) def _ensure_share(self, ctxt, share_instances): for share_instance in share_instances: try: export_locations = self.driver.ensure_share( ctxt, share_instance, share_server=share_instance['share_server']) except Exception: LOG.exception(""Caught exception trying ensure "" ""share '%(s_id)s'."", {'s_id': share_instance['id']}) continue if export_locations: self.db.share_export_locations_update( ctxt, share_instance['id'], export_locations) def _provide_share_server_for_share(self, context, share_network_id, share_instance, snapshot=None, share_group=None, create_on_backend=True): """"""Gets or creates share_server and updates share with its id. Active share_server can be deleted if there are no dependent shares on it. So we need avoid possibility to delete share_server in time gap between reaching active state for share_server and setting up share_server_id for share. It is possible, for example, with first share creation, which starts share_server creation. For this purpose used shared lock between this method and the one with deletion of share_server. :param context: Current context :param share_network_id: Share network where existing share server should be found or created. If share_network_id is None method use share_network_id from provided snapshot. :param share_instance: Share Instance model :param snapshot: Optional -- Snapshot model :param create_on_backend: Boolean. If True, driver will be asked to create the share server if no share server is available. :returns: dict, dict -- first value is share_server, that has been chosen for share schedule. Second value is share updated with share_server_id. """""" if not (share_network_id or snapshot): msg = _(""'share_network_id' parameter or 'snapshot'"" "" should be provided. "") raise ValueError(msg) parent_share_server = None def error(msg, *args): LOG.error(msg, *args) self.db.share_instance_update(context, share_instance['id'], {'status': constants.STATUS_ERROR}) if snapshot: parent_share_server_id = ( snapshot['share']['instance']['share_server_id']) try: parent_share_server = self.db.share_server_get( context, parent_share_server_id) except exception.ShareServerNotFound: with excutils.save_and_reraise_exception(): error(""Parent share server %s does not exist."", parent_share_server_id) if parent_share_server['status'] != constants.STATUS_ACTIVE: error_params = { 'id': parent_share_server_id, 'status': parent_share_server['status'], } error(""Parent share server %(id)s has invalid status "" ""'%(status)s'."", error_params) raise exception.InvalidShareServer( share_server_id=parent_share_server ) if parent_share_server and not share_network_id: share_network_id = parent_share_server['share_network_id'] def get_available_share_servers(): if parent_share_server: return [parent_share_server] else: return ( self.db.share_server_get_all_by_host_and_share_net_valid( context, self.host, share_network_id) ) @utils.synchronized(""share_manager_%s"" % share_network_id, external=True) def _wrapped_provide_share_server_for_share(): try: available_share_servers = get_available_share_servers() except exception.ShareServerNotFound: available_share_servers = None compatible_share_server = None if available_share_servers: try: compatible_share_server = ( self.driver.choose_share_server_compatible_with_share( context, available_share_servers, share_instance, snapshot=snapshot.instance if snapshot else None, share_group=share_group ) ) except Exception as e: with excutils.save_and_reraise_exception(): error(""Cannot choose compatible share server: %s"", e) if not compatible_share_server: compatible_share_server = self.db.share_server_create( context, { 'host': self.host, 'share_network_id': share_network_id, 'status': constants.STATUS_CREATING, } ) msg = (""Using share_server %(share_server)s for share instance"" "" %(share_instance_id)s"") LOG.debug(msg, { 'share_server': compatible_share_server['id'], 'share_instance_id': share_instance['id'] }) share_instance_ref = self.db.share_instance_update( context, share_instance['id'], {'share_server_id': compatible_share_server['id']}, with_share_data=True ) if create_on_backend: metadata = {'request_host': share_instance['host']} compatible_share_server = ( self._create_share_server_in_backend( context, compatible_share_server, metadata=metadata)) return compatible_share_server, share_instance_ref return _wrapped_provide_share_server_for_share() def _create_share_server_in_backend(self, context, share_server, metadata=None): """"""Perform setup_server on backend :param metadata: A dictionary, to be passed to driver's setup_server() """""" if share_server['status'] == constants.STATUS_CREATING: # Create share server on backend with data from db. share_server = self._setup_server(context, share_server, metadata=metadata) LOG.info(""Share server created successfully."") else: LOG.info(""Using preexisting share server: "" ""'%(share_server_id)s'"", {'share_server_id': share_server['id']}) return share_server def create_share_server(self, context, share_server_id): """"""Invoked to create a share server in this backend. This method is invoked to create the share server defined in the model obtained by the supplied id. :param context: The 'context.RequestContext' object for the request. :param share_server_id: The id of the server to be created. """""" share_server = self.db.share_server_get(context, share_server_id) self._create_share_server_in_backend(context, share_server) def provide_share_server(self, context, share_instance_id, share_network_id, snapshot_id=None): """"""Invoked to provide a compatible share server. This method is invoked to find a compatible share server among the existing ones or create a share server database instance with the share server properties that will be used to create the share server later. :param context: The 'context.RequestContext' object for the request. :param share_instance_id: The id of the share instance whose model attributes will be used to provide the share server. :param share_network_id: The id of the share network the share server to be provided has to be related to. :param snapshot_id: The id of the snapshot to be used to obtain the share server if applicable. :return: The id of the share server that is being provided. """""" share_instance = self.db.share_instance_get(context, share_instance_id, with_share_data=True) snapshot_ref = None if snapshot_id: snapshot_ref = self.db.share_snapshot_get(context, snapshot_id) share_group_ref = None if share_instance.get('share_group_id'): share_group_ref = self.db.share_group_get( context, share_instance['share_group_id']) share_server, share_instance = self._provide_share_server_for_share( context, share_network_id, share_instance, snapshot_ref, share_group_ref, create_on_backend=False) return share_server['id'] def _provide_share_server_for_share_group(self, context, share_network_id, share_group_ref, share_group_snapshot=None): """"""Gets or creates share_server and updates share group with its id. Active share_server can be deleted if there are no shares or share groups dependent on it. So we need avoid possibility to delete share_server in time gap between reaching active state for share_server and setting up share_server_id for share group. It is possible, for example, with first share group creation, which starts share_server creation. For this purpose used shared lock between this method and the one with deletion of share_server. :param context: Current context :param share_network_id: Share network where existing share server should be found or created. :param share_group_ref: Share Group model :param share_group_snapshot: Optional -- ShareGroupSnapshot model. If supplied, driver will use it to choose the appropriate share server. :returns: dict, dict -- first value is share_server, that has been chosen for share group schedule. Second value is share group updated with share_server_id. """""" if not share_network_id: msg = _(""'share_network_id' parameter should be provided. "") raise exception.InvalidInput(reason=msg) def error(msg, *args): LOG.error(msg, *args) self.db.share_group_update( context, share_group_ref['id'], {'status': constants.STATUS_ERROR}) @utils.synchronized(""share_manager_%s"" % share_network_id, external=True) def _wrapped_provide_share_server_for_share_group(): try: available_share_servers = ( self.db.share_server_get_all_by_host_and_share_net_valid( context, self.host, share_network_id)) except exception.ShareServerNotFound: available_share_servers = None compatible_share_server = None choose_share_server = ( self.driver.choose_share_server_compatible_with_share_group) if available_share_servers: try: compatible_share_server = choose_share_server( context, available_share_servers, share_group_ref, share_group_snapshot=share_group_snapshot, ) except Exception as e: with excutils.save_and_reraise_exception(): error(""Cannot choose compatible share-server: %s"", e) if not compatible_share_server: compatible_share_server = self.db.share_server_create( context, { 'host': self.host, 'share_network_id': share_network_id, 'status': constants.STATUS_CREATING } ) msg = (""Using share_server %(share_server)s for share "" ""group %(group_id)s"") LOG.debug(msg, { 'share_server': compatible_share_server['id'], 'group_id': share_group_ref['id'] }) updated_share_group = self.db.share_group_update( context, share_group_ref['id'], {'share_server_id': compatible_share_server['id']}, ) if compatible_share_server['status'] == constants.STATUS_CREATING: # Create share server on backend with data from db. compatible_share_server = self._setup_server( context, compatible_share_server) LOG.info(""Share server created successfully."") else: LOG.info(""Used preexisting share server "" ""'%(share_server_id)s'"", {'share_server_id': compatible_share_server['id']}) return compatible_share_server, updated_share_group return _wrapped_provide_share_server_for_share_group() def _get_share_server(self, context, share_instance): if share_instance['share_server_id']: return self.db.share_server_get( context, share_instance['share_server_id']) else: return None @utils.require_driver_initialized def connection_get_info(self, context, share_instance_id): share_instance = self.db.share_instance_get( context, share_instance_id, with_share_data=True) share_server = None if share_instance.get('share_server_id'): share_server = self.db.share_server_get( context, share_instance['share_server_id']) return self.driver.connection_get_info(context, share_instance, share_server) def _migration_start_driver( self, context, share_ref, src_share_instance, dest_host, writable, preserve_metadata, nondisruptive, preserve_snapshots, new_share_network_id, new_az_id, new_share_type_id): share_server = self._get_share_server(context, src_share_instance) share_api = api.API() request_spec, dest_share_instance = ( share_api.create_share_instance_and_get_request_spec( context, share_ref, new_az_id, None, dest_host, new_share_network_id, new_share_type_id)) self.db.share_instance_update( context, dest_share_instance['id'], {'status': constants.STATUS_MIGRATING_TO}) # refresh and obtain proxified properties dest_share_instance = self.db.share_instance_get( context, dest_share_instance['id'], with_share_data=True) helper = migration.ShareMigrationHelper( context, self.db, share_ref, self.access_helper) try: if dest_share_instance['share_network_id']: rpcapi = share_rpcapi.ShareAPI() # NOTE(ganso): Obtaining the share_server_id asynchronously so # we can wait for it to be ready. dest_share_server_id = rpcapi.provide_share_server( context, dest_share_instance, dest_share_instance['share_network_id']) rpcapi.create_share_server( context, dest_share_instance, dest_share_server_id) dest_share_server = helper.wait_for_share_server( dest_share_server_id) else: dest_share_server = None compatibility = self.driver.migration_check_compatibility( context, src_share_instance, dest_share_instance, share_server, dest_share_server) if not compatibility.get('compatible'): msg = _(""Destination host %(host)s is not compatible with "" ""share %(share)s's source backend for driver-assisted "" ""migration."") % { 'host': dest_host, 'share': share_ref['id'], } raise exception.ShareMigrationFailed(reason=msg) if (not compatibility.get('nondisruptive') and nondisruptive): msg = _(""Driver cannot perform a non-disruptive migration of "" ""share %s."") % share_ref['id'] raise exception.ShareMigrationFailed(reason=msg) if (not compatibility.get('preserve_metadata') and preserve_metadata): msg = _(""Driver cannot perform migration of share %s while "" ""preserving all metadata."") % share_ref['id'] raise exception.ShareMigrationFailed(reason=msg) if not compatibility.get('writable') and writable: msg = _(""Driver cannot perform migration of share %s while "" ""remaining writable."") % share_ref['id'] raise exception.ShareMigrationFailed(reason=msg) if (not compatibility.get('preserve_snapshots') and preserve_snapshots): msg = _(""Driver cannot perform migration of share %s while "" ""preserving snapshots."") % share_ref['id'] raise exception.ShareMigrationFailed(reason=msg) snapshot_mapping = {} src_snap_instances = [] src_snapshots = self.db.share_snapshot_get_all_for_share( context, share_ref['id']) if compatibility.get('preserve_snapshots'): # Make sure all snapshots are 'available' if any(x['status'] != constants.STATUS_AVAILABLE for x in src_snapshots): msg = _( ""All snapshots must have '%(status)s' status to be "" ""migrated by the driver along with share "" ""%(share)s."") % { 'share': share_ref['id'], 'status': constants.STATUS_AVAILABLE } raise exception.ShareMigrationFailed(reason=msg) src_snap_instances = [x.instance for x in src_snapshots] dest_snap_instance_data = { 'status': constants.STATUS_MIGRATING_TO, 'progress': '0%', 'share_instance_id': dest_share_instance['id'], } for snap_instance in src_snap_instances: snapshot_mapping[snap_instance['id']] = ( self.db.share_snapshot_instance_create( context, snap_instance['snapshot_id'], dest_snap_instance_data)) self.db.share_snapshot_instance_update( context, snap_instance['id'], {'status': constants.STATUS_MIGRATING}) else: if src_snapshots: msg = _(""Driver does not support preserving snapshots, "" ""driver-assisted migration cannot proceed while "" ""share %s has snapshots."") % share_ref['id'] raise exception.ShareMigrationFailed(reason=msg) if not compatibility.get('writable'): self._cast_access_rules_to_readonly( context, src_share_instance, share_server) LOG.debug(""Initiating driver migration for share %s."", share_ref['id']) self.db.share_update( context, share_ref['id'], {'task_state': ( constants.TASK_STATE_MIGRATION_DRIVER_STARTING)}) self.driver.migration_start( context, src_share_instance, dest_share_instance, src_snap_instances, snapshot_mapping, share_server, dest_share_server) self.db.share_update( context, share_ref['id'], {'task_state': ( constants.TASK_STATE_MIGRATION_DRIVER_IN_PROGRESS)}) except Exception: # NOTE(ganso): Cleaning up error'ed destination share instance from # database. It is assumed that driver cleans up leftovers in # backend when migration fails. self._migration_delete_instance(context, dest_share_instance['id']) self._restore_migrating_snapshots_status( context, src_share_instance['id']) # NOTE(ganso): Read only access rules and share instance status # will be restored in migration_start's except block. # NOTE(ganso): For now source share instance should remain in # migrating status for host-assisted migration. msg = _(""Driver-assisted migration of share %s "" ""failed."") % share_ref['id'] LOG.exception(msg) raise exception.ShareMigrationFailed(reason=msg) return True def _cast_access_rules_to_readonly(self, context, src_share_instance, share_server): self.db.share_instance_update( context, src_share_instance['id'], {'cast_rules_to_readonly': True}) # Set all 'applying' or 'active' rules to 'queued_to_apply'. Since the # share instance has its cast_rules_to_readonly attribute set to True, # existing rules will be cast to read/only. acceptable_past_states = (constants.ACCESS_STATE_APPLYING, constants.ACCESS_STATE_ACTIVE) new_state = constants.ACCESS_STATE_QUEUED_TO_APPLY conditionally_change = {k: new_state for k in acceptable_past_states} self.access_helper.get_and_update_share_instance_access_rules( context, share_instance_id=src_share_instance['id'], conditionally_change=conditionally_change) self.access_helper.update_access_rules( context, src_share_instance['id'], share_server=share_server) utils.wait_for_access_update( context, self.db, src_share_instance, self.migration_wait_access_rules_timeout) def _reset_read_only_access_rules( self, context, share, share_instance_id, supress_errors=True, helper=None): instance = self.db.share_instance_get(context, share_instance_id, with_share_data=True) if instance['cast_rules_to_readonly']: update = {'cast_rules_to_readonly': False} self.db.share_instance_update( context, share_instance_id, update) share_server = self._get_share_server(context, instance) if helper is None: helper = migration.ShareMigrationHelper( context, self.db, share, self.access_helper) if supress_errors: helper.cleanup_access_rules(instance, share_server) else: helper.revert_access_rules(instance, share_server) @periodic_task.periodic_task( spacing=CONF.migration_driver_continue_update_interval) @utils.require_driver_initialized def migration_driver_continue(self, context): """"""Invokes driver to continue migration of shares."""""" instances = self.db.share_instances_get_all_by_host(context, self.host) for instance in instances: if instance['status'] != constants.STATUS_MIGRATING: continue share = self.db.share_get(context, instance['share_id']) if share['task_state'] == ( constants.TASK_STATE_MIGRATION_DRIVER_IN_PROGRESS): share_api = api.API() src_share_instance_id, dest_share_instance_id = ( share_api.get_migrating_instances(share)) src_share_instance = instance dest_share_instance = self.db.share_instance_get( context, dest_share_instance_id, with_share_data=True) src_share_server = self._get_share_server( context, src_share_instance) dest_share_server = self._get_share_server( context, dest_share_instance) src_snap_instances, snapshot_mappings = ( self._get_migrating_snapshots(context, src_share_instance, dest_share_instance)) try: finished = self.driver.migration_continue( context, src_share_instance, dest_share_instance, src_snap_instances, snapshot_mappings, src_share_server, dest_share_server) if finished: self.db.share_update( context, instance['share_id'], {'task_state': (constants. TASK_STATE_MIGRATION_DRIVER_PHASE1_DONE)}) LOG.info(""Share Migration for share %s completed "" ""first phase successfully."", share['id']) else: share = self.db.share_get( context, instance['share_id']) if (share['task_state'] == constants.TASK_STATE_MIGRATION_CANCELLED): LOG.warning( ""Share Migration for share %s was cancelled."", share['id']) except Exception: # NOTE(ganso): Cleaning up error'ed destination share # instance from database. It is assumed that driver cleans # up leftovers in backend when migration fails. self._migration_delete_instance( context, dest_share_instance['id']) self._restore_migrating_snapshots_status( context, src_share_instance['id']) self._reset_read_only_access_rules( context, share, src_share_instance_id) self.db.share_instance_update( context, src_share_instance_id, {'status': constants.STATUS_AVAILABLE}) self.db.share_update( context, instance['share_id'], {'task_state': constants.TASK_STATE_MIGRATION_ERROR}) msg = _(""Driver-assisted migration of share %s "" ""failed."") % share['id'] LOG.exception(msg) def _get_migrating_snapshots( self, context, src_share_instance, dest_share_instance): dest_snap_instances = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'share_instance_ids': [dest_share_instance['id']]})) snapshot_mappings = {} src_snap_instances = [] if len(dest_snap_instances) > 0: src_snap_instances = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'share_instance_ids': [src_share_instance['id']]})) for snap in src_snap_instances: dest_snap_instance = next( x for x in dest_snap_instances if snap['snapshot_id'] == x['snapshot_id']) snapshot_mappings[snap['id']] = dest_snap_instance return src_snap_instances, snapshot_mappings def _restore_migrating_snapshots_status( self, context, src_share_instance_id, errored_dest_instance_id=None): filters = {'share_instance_ids': [src_share_instance_id]} status = constants.STATUS_AVAILABLE if errored_dest_instance_id: filters['share_instance_ids'].append(errored_dest_instance_id) status = constants.STATUS_ERROR snap_instances = ( self.db.share_snapshot_instance_get_all_with_filters( context, filters) ) for instance in snap_instances: if instance['status'] == constants.STATUS_MIGRATING: self.db.share_snapshot_instance_update( context, instance['id'], {'status': status}) elif (errored_dest_instance_id and instance['status'] == constants.STATUS_MIGRATING_TO): self.db.share_snapshot_instance_update( context, instance['id'], {'status': status}) @utils.require_driver_initialized def migration_start( self, context, share_id, dest_host, force_host_assisted_migration, preserve_metadata, writable, nondisruptive, preserve_snapshots, new_share_network_id=None, new_share_type_id=None): """"""Migrates a share from current host to another host."""""" LOG.debug(""Entered migration_start method for share %s."", share_id) self.db.share_update( context, share_id, {'task_state': constants.TASK_STATE_MIGRATION_IN_PROGRESS}) share_ref = self.db.share_get(context, share_id) share_instance = self._get_share_instance(context, share_ref) success = False host_value = share_utils.extract_host(dest_host) service = self.db.service_get_by_args( context, host_value, 'manila-share') new_az_id = service['availability_zone_id'] if not force_host_assisted_migration: try: success = self._migration_start_driver( context, share_ref, share_instance, dest_host, writable, preserve_metadata, nondisruptive, preserve_snapshots, new_share_network_id, new_az_id, new_share_type_id) except Exception as e: if not isinstance(e, NotImplementedError): LOG.exception( (""The driver could not migrate the share %(shr)s""), {'shr': share_id}) try: if not success: if (writable or preserve_metadata or nondisruptive or preserve_snapshots): msg = _(""Migration for share %s could not be "" ""performed because host-assisted migration is not "" ""allowed when share must remain writable, "" ""preserve snapshots and/or file metadata or be "" ""performed nondisruptively."") % share_id raise exception.ShareMigrationFailed(reason=msg) # We only handle shares without snapshots for now snaps = self.db.share_snapshot_get_all_for_share( context, share_id) if snaps: msg = _(""Share %s must not have snapshots in order to "" ""perform a host-assisted migration."") % share_id raise exception.ShareMigrationFailed(reason=msg) LOG.debug(""Starting host-assisted migration "" ""for share %s."", share_id) self.db.share_update( context, share_id, {'task_state': constants.TASK_STATE_MIGRATION_IN_PROGRESS}) self._migration_start_host_assisted( context, share_ref, share_instance, dest_host, new_share_network_id, new_az_id, new_share_type_id) except Exception: msg = _(""Host-assisted migration failed for share %s."") % share_id LOG.exception(msg) self.db.share_update( context, share_id, {'task_state': constants.TASK_STATE_MIGRATION_ERROR}) self._reset_read_only_access_rules( context, share_ref, share_instance['id']) self.db.share_instance_update( context, share_instance['id'], {'status': constants.STATUS_AVAILABLE}) raise exception.ShareMigrationFailed(reason=msg) def _migration_start_host_assisted( self, context, share, src_share_instance, dest_host, new_share_network_id, new_az_id, new_share_type_id): rpcapi = share_rpcapi.ShareAPI() helper = migration.ShareMigrationHelper( context, self.db, share, self.access_helper) share_server = self._get_share_server(context.elevated(), src_share_instance) self._cast_access_rules_to_readonly( context, src_share_instance, share_server) try: dest_share_instance = helper.create_instance_and_wait( share, dest_host, new_share_network_id, new_az_id, new_share_type_id) self.db.share_instance_update( context, dest_share_instance['id'], {'status': constants.STATUS_MIGRATING_TO}) except Exception: msg = _(""Failed to create instance on destination "" ""backend during migration of share %s."") % share['id'] LOG.exception(msg) raise exception.ShareMigrationFailed(reason=msg) ignore_list = self.driver.configuration.safe_get( 'migration_ignore_files') data_rpc = data_rpcapi.DataAPI() try: src_connection_info = self.driver.connection_get_info( context, src_share_instance, share_server) dest_connection_info = rpcapi.connection_get_info( context, dest_share_instance) LOG.debug(""Time to start copying in migration"" "" for share %s."", share['id']) data_rpc.migration_start( context, share['id'], ignore_list, src_share_instance['id'], dest_share_instance['id'], src_connection_info, dest_connection_info) except Exception: msg = _(""Failed to obtain migration info from backends or"" "" invoking Data Service for migration of "" ""share %s."") % share['id'] LOG.exception(msg) helper.cleanup_new_instance(dest_share_instance) raise exception.ShareMigrationFailed(reason=msg) def _migration_complete_driver( self, context, share_ref, src_share_instance, dest_share_instance): share_server = self._get_share_server(context, src_share_instance) dest_share_server = self._get_share_server( context, dest_share_instance) self.db.share_update( context, share_ref['id'], {'task_state': constants.TASK_STATE_MIGRATION_COMPLETING}) src_snap_instances, snapshot_mappings = ( self._get_migrating_snapshots(context, src_share_instance, dest_share_instance)) data_updates = self.driver.migration_complete( context, src_share_instance, dest_share_instance, src_snap_instances, snapshot_mappings, share_server, dest_share_server) or {} if data_updates.get('export_locations'): self.db.share_export_locations_update( context, dest_share_instance['id'], data_updates['export_locations']) snapshot_updates = data_updates.get('snapshot_updates') or {} dest_extra_specs = self._get_extra_specs_from_share_type( context, dest_share_instance['share_type_id']) for src_snap_ins, dest_snap_ins in snapshot_mappings.items(): model_update = snapshot_updates.get(dest_snap_ins['id']) or {} snapshot_export_locations = model_update.pop( 'export_locations', []) model_update['status'] = constants.STATUS_AVAILABLE model_update['progress'] = '100%' self.db.share_snapshot_instance_update( context, dest_snap_ins['id'], model_update) if dest_extra_specs['mount_snapshot_support']: for el in snapshot_export_locations: values = { 'share_snapshot_instance_id': dest_snap_ins['id'], 'path': el['path'], 'is_admin_only': el['is_admin_only'], } self.db.share_snapshot_instance_export_location_create( context, values) helper = migration.ShareMigrationHelper( context, self.db, share_ref, self.access_helper) helper.apply_new_access_rules(dest_share_instance) self.db.share_instance_update( context, dest_share_instance['id'], {'status': constants.STATUS_AVAILABLE}) self.db.share_instance_update(context, src_share_instance['id'], {'status': constants.STATUS_INACTIVE}) self._migration_delete_instance(context, src_share_instance['id']) def _migration_delete_instance(self, context, instance_id): # refresh the share instance model share_instance = self.db.share_instance_get( context, instance_id, with_share_data=True) rules = self.access_helper.get_and_update_share_instance_access_rules( context, share_instance_id=instance_id) self.access_helper.delete_share_instance_access_rules( context, rules, instance_id) snap_instances = self.db.share_snapshot_instance_get_all_with_filters( context, {'share_instance_ids': [instance_id]}) for instance in snap_instances: self.db.share_snapshot_instance_delete(context, instance['id']) self.db.share_instance_delete(context, instance_id) LOG.info(""Share instance %s: deleted successfully."", instance_id) self._check_delete_share_server(context, share_instance) @utils.require_driver_initialized def migration_complete(self, context, src_instance_id, dest_instance_id): src_share_instance = self.db.share_instance_get( context, src_instance_id, with_share_data=True) dest_share_instance = self.db.share_instance_get( context, dest_instance_id, with_share_data=True) share_ref = self.db.share_get(context, src_share_instance['share_id']) LOG.info(""Received request to finish Share Migration for "" ""share %s."", share_ref['id']) if share_ref['task_state'] == ( constants.TASK_STATE_MIGRATION_DRIVER_PHASE1_DONE): try: self._migration_complete_driver( context, share_ref, src_share_instance, dest_share_instance) except Exception: msg = _(""Driver migration completion failed for"" "" share %s."") % share_ref['id'] LOG.exception(msg) # NOTE(ganso): If driver fails during migration-complete, # all instances are set to error and it is up to the admin # to fix the problem to either complete migration # manually or clean it up. At this moment, data # preservation at the source backend cannot be # guaranteed. self._restore_migrating_snapshots_status( context, src_share_instance['id'], errored_dest_instance_id=dest_share_instance['id']) self.db.share_instance_update( context, src_instance_id, {'status': constants.STATUS_ERROR}) self.db.share_instance_update( context, dest_instance_id, {'status': constants.STATUS_ERROR}) self.db.share_update( context, share_ref['id'], {'task_state': constants.TASK_STATE_MIGRATION_ERROR}) raise exception.ShareMigrationFailed(reason=msg) else: try: self._migration_complete_host_assisted( context, share_ref, src_instance_id, dest_instance_id) except Exception: msg = _(""Host-assisted migration completion failed for"" "" share %s."") % share_ref['id'] LOG.exception(msg) self.db.share_update( context, share_ref['id'], {'task_state': constants.TASK_STATE_MIGRATION_ERROR}) self.db.share_instance_update( context, src_instance_id, {'status': constants.STATUS_AVAILABLE}) raise exception.ShareMigrationFailed(reason=msg) model_update = self._get_extra_specs_from_share_type( context, dest_share_instance['share_type_id']) model_update['task_state'] = constants.TASK_STATE_MIGRATION_SUCCESS self.db.share_update( context, dest_share_instance['share_id'], model_update) LOG.info(""Share Migration for share %s"" "" completed successfully."", share_ref['id']) def _get_extra_specs_from_share_type(self, context, share_type_id): share_type = share_types.get_share_type(context, share_type_id) share_api = api.API() return share_api.get_share_attributes_from_share_type(share_type) def _migration_complete_host_assisted(self, context, share_ref, src_instance_id, dest_instance_id): src_share_instance = self.db.share_instance_get( context, src_instance_id, with_share_data=True) dest_share_instance = self.db.share_instance_get( context, dest_instance_id, with_share_data=True) helper = migration.ShareMigrationHelper( context, self.db, share_ref, self.access_helper) task_state = share_ref['task_state'] if task_state in (constants.TASK_STATE_DATA_COPYING_ERROR, constants.TASK_STATE_DATA_COPYING_CANCELLED): msg = _(""Data copy of host assisted migration for share %s has not"" "" completed successfully."") % share_ref['id'] LOG.warning(msg) helper.cleanup_new_instance(dest_share_instance) cancelled = ( task_state == constants.TASK_STATE_DATA_COPYING_CANCELLED) suppress_errors = True if cancelled: suppress_errors = False self._reset_read_only_access_rules( context, share_ref, src_instance_id, supress_errors=suppress_errors, helper=helper) self.db.share_instance_update( context, src_instance_id, {'status': constants.STATUS_AVAILABLE}) if cancelled: self.db.share_update( context, share_ref['id'], {'task_state': constants.TASK_STATE_MIGRATION_CANCELLED}) LOG.info(""Share Migration for share %s"" "" was cancelled."", share_ref['id']) return else: raise exception.ShareMigrationFailed(reason=msg) elif task_state != constants.TASK_STATE_DATA_COPYING_COMPLETED: msg = _(""Data copy for migration of share %s has not completed"" "" yet."") % share_ref['id'] LOG.error(msg) raise exception.ShareMigrationFailed(reason=msg) self.db.share_update( context, share_ref['id'], {'task_state': constants.TASK_STATE_MIGRATION_COMPLETING}) try: helper.apply_new_access_rules(dest_share_instance) except Exception: msg = _(""Failed to apply new access rules during migration "" ""of share %s."") % share_ref['id'] LOG.exception(msg) helper.cleanup_new_instance(dest_share_instance) self._reset_read_only_access_rules( context, share_ref, src_instance_id, helper=helper, supress_errors=True) self.db.share_instance_update( context, src_instance_id, {'status': constants.STATUS_AVAILABLE}) raise exception.ShareMigrationFailed(reason=msg) self.db.share_instance_update( context, dest_share_instance['id'], {'status': constants.STATUS_AVAILABLE}) self.db.share_instance_update(context, src_instance_id, {'status': constants.STATUS_INACTIVE}) helper.delete_instance_and_wait(src_share_instance) @utils.require_driver_initialized def migration_cancel(self, context, src_instance_id, dest_instance_id): src_share_instance = self.db.share_instance_get( context, src_instance_id, with_share_data=True) dest_share_instance = self.db.share_instance_get( context, dest_instance_id, with_share_data=True) share_ref = self.db.share_get(context, src_share_instance['share_id']) if share_ref['task_state'] not in ( constants.TASK_STATE_DATA_COPYING_COMPLETED, constants.TASK_STATE_MIGRATION_DRIVER_PHASE1_DONE, constants.TASK_STATE_MIGRATION_DRIVER_IN_PROGRESS): msg = _(""Migration of share %s cannot be cancelled at this "" ""moment."") % share_ref['id'] raise exception.InvalidShare(reason=msg) share_server = self._get_share_server(context, src_share_instance) dest_share_server = self._get_share_server( context, dest_share_instance) helper = migration.ShareMigrationHelper( context, self.db, share_ref, self.access_helper) if share_ref['task_state'] == ( constants.TASK_STATE_DATA_COPYING_COMPLETED): self.db.share_instance_update( context, dest_share_instance['id'], {'status': constants.STATUS_INACTIVE}) helper.cleanup_new_instance(dest_share_instance) else: src_snap_instances, snapshot_mappings = ( self._get_migrating_snapshots(context, src_share_instance, dest_share_instance)) self.driver.migration_cancel( context, src_share_instance, dest_share_instance, src_snap_instances, snapshot_mappings, share_server, dest_share_server) self._migration_delete_instance(context, dest_share_instance['id']) self._restore_migrating_snapshots_status( context, src_share_instance['id']) self._reset_read_only_access_rules( context, share_ref, src_instance_id, supress_errors=False, helper=helper) self.db.share_instance_update( context, src_instance_id, {'status': constants.STATUS_AVAILABLE}) self.db.share_update( context, share_ref['id'], {'task_state': constants.TASK_STATE_MIGRATION_CANCELLED}) LOG.info(""Share Migration for share %s"" "" was cancelled."", share_ref['id']) @utils.require_driver_initialized def migration_get_progress(self, context, src_instance_id, dest_instance_id): src_share_instance = self.db.share_instance_get( context, src_instance_id, with_share_data=True) dest_share_instance = self.db.share_instance_get( context, dest_instance_id, with_share_data=True) share_ref = self.db.share_get(context, src_share_instance['share_id']) # Confirm that it is driver migration scenario if share_ref['task_state'] != ( constants.TASK_STATE_MIGRATION_DRIVER_IN_PROGRESS): msg = _(""Driver is not performing migration for"" "" share %s at this moment."") % share_ref['id'] raise exception.InvalidShare(reason=msg) share_server = None if share_ref.instance.get('share_server_id'): share_server = self.db.share_server_get( context, src_share_instance['share_server_id']) dest_share_server = None if dest_share_instance.get('share_server_id'): dest_share_server = self.db.share_server_get( context, dest_share_instance['share_server_id']) src_snap_instances, snapshot_mappings = ( self._get_migrating_snapshots(context, src_share_instance, dest_share_instance)) return self.driver.migration_get_progress( context, src_share_instance, dest_share_instance, src_snap_instances, snapshot_mappings, share_server, dest_share_server) def _get_share_instance(self, context, share): if isinstance(share, six.string_types): id = share else: id = share.instance['id'] return self.db.share_instance_get(context, id, with_share_data=True) @add_hooks @utils.require_driver_initialized def create_share_instance(self, context, share_instance_id, request_spec=None, filter_properties=None, snapshot_id=None): """"""Creates a share instance."""""" context = context.elevated() share_instance = self._get_share_instance(context, share_instance_id) share_id = share_instance.get('share_id') share_network_id = share_instance.get('share_network_id') share = self.db.share_get(context, share_id) self._notify_about_share_usage(context, share, share_instance, ""create.start"") if not share_instance['availability_zone']: share_instance = self.db.share_instance_update( context, share_instance_id, {'availability_zone': self.availability_zone}, with_share_data=True ) if share_network_id and not self.driver.driver_handles_share_servers: self.db.share_instance_update( context, share_instance_id, {'status': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.CREATE, share['project_id'], resource_type=message_field.Resource.SHARE, resource_id=share_id, detail=message_field.Detail.UNEXPECTED_NETWORK) raise exception.ManilaException(_( ""Creation of share instance %s failed: driver does not expect "" ""share-network to be provided with current "" ""configuration."") % share_instance_id) if snapshot_id is not None: snapshot_ref = self.db.share_snapshot_get(context, snapshot_id) parent_share_server_id = ( snapshot_ref['share']['instance']['share_server_id']) else: snapshot_ref = None parent_share_server_id = None share_group_ref = None if share_instance.get('share_group_id'): share_group_ref = self.db.share_group_get( context, share_instance['share_group_id']) if share_network_id or parent_share_server_id: try: share_server, share_instance = ( self._provide_share_server_for_share( context, share_network_id, share_instance, snapshot=snapshot_ref, share_group=share_group_ref, ) ) except Exception: with excutils.save_and_reraise_exception(): error = (""Creation of share instance %s failed: "" ""failed to get share server."") LOG.error(error, share_instance_id) self.db.share_instance_update( context, share_instance_id, {'status': constants.STATUS_ERROR} ) self.message_api.create( context, message_field.Action.CREATE, share['project_id'], resource_type=message_field.Resource.SHARE, resource_id=share_id, detail=message_field.Detail.NO_SHARE_SERVER) else: share_server = None try: if snapshot_ref: export_locations = self.driver.create_share_from_snapshot( context, share_instance, snapshot_ref.instance, share_server=share_server) else: export_locations = self.driver.create_share( context, share_instance, share_server=share_server) self.db.share_export_locations_update( context, share_instance['id'], export_locations) except Exception as e: with excutils.save_and_reraise_exception(): LOG.error(""Share instance %s failed on creation."", share_instance_id) detail_data = getattr(e, 'detail_data', {}) def get_export_location(details): if not isinstance(details, dict): return None return details.get('export_locations', details.get('export_location')) export_locations = get_export_location(detail_data) if export_locations: self.db.share_export_locations_update( context, share_instance['id'], export_locations) else: LOG.warning('Share instance information in exception ' 'can not be written to db because it ' 'contains %s and it is not a dictionary.', detail_data) self.db.share_instance_update( context, share_instance_id, {'status': constants.STATUS_ERROR} ) self.message_api.create( context, message_field.Action.CREATE, share['project_id'], resource_type=message_field.Resource.SHARE, resource_id=share_id, exception=e) else: LOG.info(""Share instance %s created successfully."", share_instance_id) updates = { 'status': constants.STATUS_AVAILABLE, 'launched_at': timeutils.utcnow(), } if share.get('replication_type'): updates['replica_state'] = constants.REPLICA_STATE_ACTIVE self.db.share_instance_update(context, share_instance_id, updates) self._notify_about_share_usage(context, share, share_instance, ""create.end"") def _update_share_replica_access_rules_state(self, context, share_replica_id, state): """"""Update the access_rules_status for the share replica."""""" self.access_helper.get_and_update_share_instance_access_rules_status( context, status=state, share_instance_id=share_replica_id) def _get_replica_snapshots_for_snapshot(self, context, snapshot_id, active_replica_id, share_replica_id, with_share_data=True): """"""Return dict of snapshot instances of active and replica instances. This method returns a dict of snapshot instances for snapshot referred to by snapshot_id. The dict contains the snapshot instance pertaining to the 'active' replica and the snapshot instance pertaining to the replica referred to by share_replica_id. """""" filters = { 'snapshot_ids': snapshot_id, 'share_instance_ids': (share_replica_id, active_replica_id), } instance_list = self.db.share_snapshot_instance_get_all_with_filters( context, filters, with_share_data=with_share_data) snapshots = { 'active_replica_snapshot': self._get_snapshot_instance_dict( context, list(filter(lambda x: x['share_instance_id'] == active_replica_id, instance_list))[0]), 'share_replica_snapshot': self._get_snapshot_instance_dict( context, list(filter(lambda x: x['share_instance_id'] == share_replica_id, instance_list))[0]), } return snapshots @add_hooks @utils.require_driver_initialized @locked_share_replica_operation def create_share_replica(self, context, share_replica_id, share_id=None, request_spec=None, filter_properties=None): """"""Create a share replica."""""" context = context.elevated() share_replica = self.db.share_replica_get( context, share_replica_id, with_share_data=True, with_share_server=True) if not share_replica['availability_zone']: share_replica = self.db.share_replica_update( context, share_replica['id'], {'availability_zone': self.availability_zone}, with_share_data=True ) _active_replica = ( self.db.share_replicas_get_available_active_replica( context, share_replica['share_id'], with_share_data=True, with_share_server=True)) if not _active_replica: self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_ERROR, 'replica_state': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.CREATE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], detail=message_field.Detail.NO_ACTIVE_REPLICA) msg = _(""An 'active' replica must exist in 'available' "" ""state to create a new replica for share %s."") raise exception.ReplicationException( reason=msg % share_replica['share_id']) # We need the share_network_id in case of # driver_handles_share_server=True share_network_id = share_replica.get('share_network_id', None) if (share_network_id and not self.driver.driver_handles_share_servers): self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_ERROR, 'replica_state': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.CREATE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], detail=message_field.Detail.UNEXPECTED_NETWORK) raise exception.InvalidDriverMode( ""Driver does not expect share-network to be provided "" ""with current configuration."") if share_network_id: try: share_server, share_replica = ( self._provide_share_server_for_share( context, share_network_id, share_replica) ) except Exception: with excutils.save_and_reraise_exception(): LOG.error(""Failed to get share server "" ""for share replica creation."") self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_ERROR, 'replica_state': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.CREATE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], detail=message_field.Detail.NO_SHARE_SERVER) else: share_server = None # Map the existing access rules for the share to # the replica in the DB. share_access_rules = self.db.share_instance_access_copy( context, share_replica['share_id'], share_replica['id']) # Get snapshots for the share. share_snapshots = self.db.share_snapshot_get_all_for_share( context, share_id) # Get the required data for snapshots that have 'aggregate_status' # set to 'available'. available_share_snapshots = [ self._get_replica_snapshots_for_snapshot( context, x['id'], _active_replica['id'], share_replica_id) for x in share_snapshots if x['aggregate_status'] == constants.STATUS_AVAILABLE] replica_list = ( self.db.share_replicas_get_all_by_share( context, share_replica['share_id'], with_share_data=True, with_share_server=True) ) replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] share_replica = self._get_share_replica_dict(context, share_replica) try: replica_ref = self.driver.create_replica( context, replica_list, share_replica, share_access_rules, available_share_snapshots, share_server=share_server) or {} except Exception as excep: with excutils.save_and_reraise_exception(): LOG.error(""Share replica %s failed on creation."", share_replica['id']) self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_ERROR, 'replica_state': constants.STATUS_ERROR}) self._update_share_replica_access_rules_state( context, share_replica['id'], constants.STATUS_ERROR) self.message_api.create( context, message_field.Action.CREATE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], exception=excep) if replica_ref.get('export_locations'): if isinstance(replica_ref.get('export_locations'), list): self.db.share_export_locations_update( context, share_replica['id'], replica_ref.get('export_locations')) else: msg = ('Invalid export locations passed to the share ' 'manager.') LOG.warning(msg) if replica_ref.get('replica_state'): self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_AVAILABLE, 'replica_state': replica_ref.get('replica_state')}) if replica_ref.get('access_rules_status'): self._update_share_replica_access_rules_state( context, share_replica['id'], replica_ref.get('access_rules_status')) else: self._update_share_replica_access_rules_state( context, share_replica['id'], constants.STATUS_ACTIVE) LOG.info(""Share replica %s created successfully."", share_replica['id']) @add_hooks @utils.require_driver_initialized @locked_share_replica_operation def delete_share_replica(self, context, share_replica_id, share_id=None, force=False): """"""Delete a share replica."""""" context = context.elevated() share_replica = self.db.share_replica_get( context, share_replica_id, with_share_data=True, with_share_server=True) # Grab all the snapshot instances that belong to this replica. replica_snapshots = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'share_instance_ids': share_replica_id}, with_share_data=True) ) replica_list = ( self.db.share_replicas_get_all_by_share( context, share_replica['share_id'], with_share_data=True, with_share_server=True) ) replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] replica_snapshots = [self._get_snapshot_instance_dict(context, s) for s in replica_snapshots] share_server = self._get_share_server(context, share_replica) share_replica = self._get_share_replica_dict(context, share_replica) try: self.access_helper.update_access_rules( context, share_replica_id, delete_all_rules=True, share_server=share_server ) except Exception as excep: with excutils.save_and_reraise_exception() as exc_context: # Set status to 'error' from 'deleting' since # access_rules_status has been set to 'error'. self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.DELETE_ACCESS_RULES, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], exception=excep) if force: msg = _(""The driver was unable to delete access rules "" ""for the replica: %s. Will attempt to delete "" ""the replica anyway."") LOG.exception(msg, share_replica['id']) exc_context.reraise = False try: self.driver.delete_replica( context, replica_list, replica_snapshots, share_replica, share_server=share_server) except Exception as excep: with excutils.save_and_reraise_exception() as exc_context: if force: msg = _(""The driver was unable to delete the share "" ""replica: %s on the backend. Since "" ""this operation is forced, the replica will be "" ""deleted from Manila's database. A cleanup on "" ""the backend may be necessary."") LOG.exception(msg, share_replica['id']) exc_context.reraise = False else: self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_ERROR_DELETING, 'replica_state': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.DELETE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], exception=excep) for replica_snapshot in replica_snapshots: self.db.share_snapshot_instance_delete( context, replica_snapshot['id']) self.db.share_replica_delete(context, share_replica['id']) LOG.info(""Share replica %s deleted successfully."", share_replica['id']) @add_hooks @utils.require_driver_initialized @locked_share_replica_operation def promote_share_replica(self, context, share_replica_id, share_id=None): """"""Promote a share replica to active state."""""" context = context.elevated() share_replica = self.db.share_replica_get( context, share_replica_id, with_share_data=True, with_share_server=True) replication_type = share_replica['replication_type'] if replication_type == constants.REPLICATION_TYPE_READABLE: ensure_old_active_replica_to_readonly = True else: ensure_old_active_replica_to_readonly = False share_server = self._get_share_server(context, share_replica) # Get list of all replicas for share replica_list = ( self.db.share_replicas_get_all_by_share( context, share_replica['share_id'], with_share_data=True, with_share_server=True) ) try: old_active_replica = list(filter( lambda r: ( r['replica_state'] == constants.REPLICA_STATE_ACTIVE), replica_list))[0] except IndexError: self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_AVAILABLE}) msg = _(""Share %(share)s has no replica with 'replica_state' "" ""set to %(state)s. Promoting %(replica)s is not "" ""possible."") self.message_api.create( context, message_field.Action.PROMOTE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], detail=message_field.Detail.NO_ACTIVE_REPLICA) raise exception.ReplicationException( reason=msg % {'share': share_replica['share_id'], 'state': constants.REPLICA_STATE_ACTIVE, 'replica': share_replica['id']}) access_rules = self.db.share_access_get_all_for_share( context, share_replica['share_id']) replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] share_replica = self._get_share_replica_dict(context, share_replica) try: updated_replica_list = ( self.driver.promote_replica( context, replica_list, share_replica, access_rules, share_server=share_server) ) except Exception as excep: with excutils.save_and_reraise_exception(): # (NOTE) gouthamr: If the driver throws an exception at # this stage, there is a good chance that the replicas are # somehow altered on the backend. We loop through the # replicas and set their 'status's to 'error' and # leave the 'replica_state' unchanged. This also changes the # 'status' of the replica that failed to promote to 'error' as # before this operation. The backend may choose to update # the actual replica_state during the replica_monitoring # stage. updates = {'status': constants.STATUS_ERROR} for replica_ref in replica_list: self.db.share_replica_update( context, replica_ref['id'], updates) self.message_api.create( context, message_field.Action.PROMOTE, replica_ref['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=replica_ref['id'], exception=excep) # Set any 'creating' snapshots on the currently active replica to # 'error' since we cannot guarantee they will finish 'creating'. active_replica_snapshot_instances = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'share_instance_ids': share_replica['id']}) ) for instance in active_replica_snapshot_instances: if instance['status'] in (constants.STATUS_CREATING, constants.STATUS_DELETING): msg = (""The replica snapshot instance %(instance)s was "" ""in %(state)s. Since it was not in %(available)s "" ""state when the replica was promoted, it will be "" ""set to %(error)s."") payload = { 'instance': instance['id'], 'state': instance['status'], 'available': constants.STATUS_AVAILABLE, 'error': constants.STATUS_ERROR, } LOG.info(msg, payload) self.db.share_snapshot_instance_update( context, instance['id'], {'status': constants.STATUS_ERROR}) if not updated_replica_list: self.db.share_replica_update( context, old_active_replica['id'], {'replica_state': constants.REPLICA_STATE_OUT_OF_SYNC, 'cast_rules_to_readonly': ensure_old_active_replica_to_readonly}) self.db.share_replica_update( context, share_replica['id'], {'status': constants.STATUS_AVAILABLE, 'replica_state': constants.REPLICA_STATE_ACTIVE, 'cast_rules_to_readonly': False}) else: while updated_replica_list: # NOTE(vponomaryov): update 'active' replica last. for updated_replica in updated_replica_list: if (updated_replica['id'] == share_replica['id'] and len(updated_replica_list) > 1): continue updated_replica_list.remove(updated_replica) break updated_export_locs = updated_replica.get( 'export_locations') if(updated_export_locs is not None and isinstance(updated_export_locs, list)): self.db.share_export_locations_update( context, updated_replica['id'], updated_export_locs) updated_replica_state = updated_replica.get( 'replica_state') updates = {} # Change the promoted replica's status from 'available' to # 'replication_change' and unset cast_rules_to_readonly if updated_replica['id'] == share_replica['id']: updates['cast_rules_to_readonly'] = False updates['status'] = constants.STATUS_AVAILABLE elif updated_replica['id'] == old_active_replica['id']: updates['cast_rules_to_readonly'] = ( ensure_old_active_replica_to_readonly) if updated_replica_state == constants.STATUS_ERROR: updates['status'] = constants.STATUS_ERROR if updated_replica_state is not None: updates['replica_state'] = updated_replica_state if updates: self.db.share_replica_update( context, updated_replica['id'], updates) if updated_replica.get('access_rules_status'): self._update_share_replica_access_rules_state( context, share_replica['id'], updated_replica.get('access_rules_status')) LOG.info(""Share replica %s: promoted to active state "" ""successfully."", share_replica['id']) @periodic_task.periodic_task(spacing=CONF.replica_state_update_interval) @utils.require_driver_initialized def periodic_share_replica_update(self, context): LOG.debug(""Updating status of share replica instances."") replicas = self.db.share_replicas_get_all(context, with_share_data=True) # Filter only non-active replicas belonging to this backend def qualified_replica(r): return (share_utils.extract_host(r['host']) == share_utils.extract_host(self.host)) replicas = list(filter(lambda x: qualified_replica(x), replicas)) for replica in replicas: self._share_replica_update( context, replica, share_id=replica['share_id']) @add_hooks @utils.require_driver_initialized def update_share_replica(self, context, share_replica_id, share_id=None): """"""Initiated by the force_update API."""""" share_replica = self.db.share_replica_get( context, share_replica_id, with_share_data=True, with_share_server=True) self._share_replica_update(context, share_replica, share_id=share_id) @locked_share_replica_operation def _share_replica_update(self, context, share_replica, share_id=None): share_server = self._get_share_server(context, share_replica) # Re-grab the replica: try: share_replica = self.db.share_replica_get( context, share_replica['id'], with_share_data=True, with_share_server=True) except exception.ShareReplicaNotFound: # Replica may have been deleted, nothing to do here return # We don't poll for replicas that are busy in some operation, # or if they are the 'active' instance. if (share_replica['status'] in constants.TRANSITIONAL_STATUSES or share_replica['replica_state'] == constants.REPLICA_STATE_ACTIVE): return access_rules = self.db.share_access_get_all_for_share( context, share_replica['share_id']) LOG.debug(""Updating status of share share_replica %s: "", share_replica['id']) replica_list = ( self.db.share_replicas_get_all_by_share( context, share_replica['share_id'], with_share_data=True, with_share_server=True) ) _active_replica = [x for x in replica_list if x['replica_state'] == constants.REPLICA_STATE_ACTIVE][0] # Get snapshots for the share. share_snapshots = self.db.share_snapshot_get_all_for_share( context, share_id) # Get the required data for snapshots that have 'aggregate_status' # set to 'available'. available_share_snapshots = [ self._get_replica_snapshots_for_snapshot( context, x['id'], _active_replica['id'], share_replica['id']) for x in share_snapshots if x['aggregate_status'] == constants.STATUS_AVAILABLE] replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] share_replica = self._get_share_replica_dict(context, share_replica) try: replica_state = self.driver.update_replica_state( context, replica_list, share_replica, access_rules, available_share_snapshots, share_server=share_server) except Exception as excep: msg = (""Driver error when updating replica "" ""state for replica %s."") LOG.exception(msg, share_replica['id']) self.db.share_replica_update( context, share_replica['id'], {'replica_state': constants.STATUS_ERROR, 'status': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.UPDATE, share_replica['project_id'], resource_type=message_field.Resource.SHARE_REPLICA, resource_id=share_replica['id'], exception=excep) return if replica_state in (constants.REPLICA_STATE_IN_SYNC, constants.REPLICA_STATE_OUT_OF_SYNC, constants.STATUS_ERROR): self.db.share_replica_update(context, share_replica['id'], {'replica_state': replica_state}) elif replica_state: msg = ((""Replica %(id)s cannot be set to %(state)s "" ""through update call."") % {'id': share_replica['id'], 'state': replica_state}) LOG.warning(msg) def _validate_share_and_driver_mode(self, share_instance): driver_dhss = self.driver.driver_handles_share_servers share_dhss = share_types.parse_boolean_extra_spec( 'driver_handles_share_servers', share_types.get_share_type_extra_specs( share_instance['share_type_id'], constants.ExtraSpecs.DRIVER_HANDLES_SHARE_SERVERS)) if driver_dhss != share_dhss: msg = _(""Driver mode of share %(share)s being managed is "" ""incompatible with mode DHSS=%(dhss)s configured for"" "" this backend."") % {'share': share_instance['share_id'], 'dhss': driver_dhss} raise exception.InvalidShare(reason=msg) return driver_dhss @add_hooks @utils.require_driver_initialized def manage_share(self, context, share_id, driver_options): context = context.elevated() share_ref = self.db.share_get(context, share_id) share_instance = self._get_share_instance(context, share_ref) project_id = share_ref['project_id'] try: driver_dhss = self._validate_share_and_driver_mode(share_instance) if driver_dhss is True: share_server = self._get_share_server(context, share_instance) share_update = ( self.driver.manage_existing_with_server( share_instance, driver_options, share_server) or {} ) else: share_update = ( self.driver.manage_existing( share_instance, driver_options) or {} ) if not share_update.get('size'): msg = _(""Driver cannot calculate share size."") raise exception.InvalidShare(reason=msg) reservations = QUOTAS.reserve( context, project_id=project_id, user_id=context.user_id, shares=1, gigabytes=share_update['size'], share_type_id=share_instance['share_type_id'], ) QUOTAS.commit( context, reservations, project_id=project_id, share_type_id=share_instance['share_type_id'], ) share_update.update({ 'status': constants.STATUS_AVAILABLE, 'launched_at': timeutils.utcnow(), 'availability_zone': self.availability_zone, }) # If the share was managed with `replication_type` extra-spec, the # instance becomes an `active` replica. if share_ref.get('replication_type'): share_update['replica_state'] = constants.REPLICA_STATE_ACTIVE # NOTE(vponomaryov): we should keep only those export locations # that driver has calculated to avoid incompatibilities with one # provided by user. if 'export_locations' in share_update: self.db.share_export_locations_update( context, share_instance['id'], share_update.pop('export_locations'), delete=True) self.db.share_update(context, share_id, share_update) except Exception: # NOTE(vponomaryov): set size as 1 because design expects size # to be set, it also will allow us to handle delete/unmanage # operations properly with this errored share according to quotas. self.db.share_update( context, share_id, {'status': constants.STATUS_MANAGE_ERROR, 'size': 1}) raise @add_hooks @utils.require_driver_initialized def manage_snapshot(self, context, snapshot_id, driver_options): context = context.elevated() snapshot_ref = self.db.share_snapshot_get(context, snapshot_id) snapshot_instance = self.db.share_snapshot_instance_get( context, snapshot_ref.instance['id'], with_share_data=True ) project_id = snapshot_ref['project_id'] driver_dhss = self.driver.driver_handles_share_servers try: if driver_dhss is True: share_server = self._get_share_server(context, snapshot_ref['share']) snapshot_update = ( self.driver.manage_existing_snapshot_with_server( snapshot_instance, driver_options, share_server) or {} ) else: snapshot_update = ( self.driver.manage_existing_snapshot( snapshot_instance, driver_options) or {} ) if not snapshot_update.get('size'): snapshot_update['size'] = snapshot_ref['share']['size'] LOG.warning(""Cannot get the size of the snapshot "" ""%(snapshot_id)s. Using the size of "" ""the share instead."", {'snapshot_id': snapshot_id}) self._update_quota_usages(context, project_id, { ""snapshots"": 1, ""snapshot_gigabytes"": snapshot_update['size'], }) snapshot_export_locations = snapshot_update.pop( 'export_locations', []) if snapshot_instance['share']['mount_snapshot_support']: for el in snapshot_export_locations: values = { 'share_snapshot_instance_id': snapshot_instance['id'], 'path': el['path'], 'is_admin_only': el['is_admin_only'], } self.db.share_snapshot_instance_export_location_create( context, values) snapshot_update.update({ 'status': constants.STATUS_AVAILABLE, 'progress': '100%', }) snapshot_update.pop('id', None) self.db.share_snapshot_update(context, snapshot_id, snapshot_update) except Exception: # NOTE(vponomaryov): set size as 1 because design expects size # to be set, it also will allow us to handle delete/unmanage # operations properly with this errored snapshot according to # quotas. self.db.share_snapshot_update( context, snapshot_id, {'status': constants.STATUS_MANAGE_ERROR, 'size': 1}) raise def _update_quota_usages(self, context, project_id, usages): user_id = context.user_id for resource, usage in usages.items(): try: current_usage = self.db.quota_usage_get( context, project_id, resource, user_id) self.db.quota_usage_update( context, project_id, user_id, resource, in_use=current_usage['in_use'] + usage) except exception.QuotaUsageNotFound: self.db.quota_usage_create(context, project_id, user_id, resource, usage) @add_hooks @utils.require_driver_initialized def unmanage_share(self, context, share_id): context = context.elevated() share_ref = self.db.share_get(context, share_id) share_instance = self._get_share_instance(context, share_ref) share_server = None project_id = share_ref['project_id'] def share_manage_set_error_status(msg, exception): status = {'status': constants.STATUS_UNMANAGE_ERROR} self.db.share_update(context, share_id, status) LOG.error(msg, exception) dhss = self.driver.driver_handles_share_servers try: if dhss is True: share_server = self._get_share_server(context, share_instance) self.driver.unmanage_with_server(share_instance, share_server) else: self.driver.unmanage(share_instance) except exception.InvalidShare as e: share_manage_set_error_status( (""Share can not be unmanaged: %s.""), e) return try: reservations = QUOTAS.reserve( context, project_id=project_id, shares=-1, gigabytes=-share_ref['size'], share_type_id=share_instance['share_type_id'], ) QUOTAS.commit( context, reservations, project_id=project_id, share_type_id=share_instance['share_type_id'], ) except Exception as e: # Note(imalinovskiy): # Quota reservation errors here are not fatal, because # unmanage is administrator API and he/she could update user # quota usages later if it's required. LOG.warning(""Failed to update quota usages: %s."", e) if self.configuration.safe_get('unmanage_remove_access_rules'): try: self.access_helper.update_access_rules( context, share_instance['id'], delete_all_rules=True, share_server=share_server ) except Exception as e: share_manage_set_error_status( (""Can not remove access rules of share: %s.""), e) return self.db.share_instance_delete(context, share_instance['id']) # NOTE(ganso): Since we are unmanaging a share that is still within a # share server, we need to prevent the share server from being # auto-deleted. if share_server and share_server['is_auto_deletable']: self.db.share_server_update(context, share_server['id'], {'is_auto_deletable': False}) LOG.info(""Share %s: unmanaged successfully."", share_id) @add_hooks @utils.require_driver_initialized def unmanage_snapshot(self, context, snapshot_id): status = {'status': constants.STATUS_UNMANAGE_ERROR} context = context.elevated() snapshot_ref = self.db.share_snapshot_get(context, snapshot_id) share_server = self._get_share_server(context, snapshot_ref['share']) snapshot_instance = self.db.share_snapshot_instance_get( context, snapshot_ref.instance['id'], with_share_data=True ) project_id = snapshot_ref['project_id'] if self.configuration.safe_get('unmanage_remove_access_rules'): try: self.snapshot_access_helper.update_access_rules( context, snapshot_instance['id'], delete_all_rules=True, share_server=share_server) except Exception: LOG.exception( (""Cannot remove access rules of snapshot %s.""), snapshot_id) self.db.share_snapshot_update(context, snapshot_id, status) return dhss = self.driver.driver_handles_share_servers try: if dhss: self.driver.unmanage_snapshot_with_server( snapshot_instance, share_server) else: self.driver.unmanage_snapshot(snapshot_instance) except exception.UnmanageInvalidShareSnapshot as e: self.db.share_snapshot_update(context, snapshot_id, status) LOG.error(""Share snapshot cannot be unmanaged: %s."", e) return try: share_type_id = snapshot_ref['share']['instance']['share_type_id'] reservations = QUOTAS.reserve( context, project_id=project_id, snapshots=-1, snapshot_gigabytes=-snapshot_ref['size'], share_type_id=share_type_id, ) QUOTAS.commit( context, reservations, project_id=project_id, share_type_id=share_type_id, ) except Exception as e: # Note(imalinovskiy): # Quota reservation errors here are not fatal, because # unmanage is administrator API and he/she could update user # quota usages later if it's required. LOG.warning(""Failed to update quota usages: %s."", e) self.db.share_snapshot_instance_delete( context, snapshot_instance['id']) @add_hooks @utils.require_driver_initialized def manage_share_server(self, context, share_server_id, identifier, driver_opts): if self.driver.driver_handles_share_servers is False: msg = _(""Cannot manage share server %s in a "" ""backend configured with driver_handles_share_servers"" "" set to False."") % share_server_id raise exception.ManageShareServerError(reason=msg) server = self.db.share_server_get(context, share_server_id) share_network = self.db.share_network_get( context, server['share_network_id']) try: number_allocations = ( self.driver.get_network_allocations_number()) if self.driver.admin_network_api: number_allocations += ( self.driver.get_admin_network_allocations_number()) if number_allocations > 0: # allocations obtained from the driver that still need to # be validated remaining_allocations = ( self.driver.get_share_server_network_info( context, server, identifier, driver_opts)) if len(remaining_allocations) > 0: if self.driver.admin_network_api: remaining_allocations = ( self.driver.admin_network_api. manage_network_allocations( context, remaining_allocations, server)) # allocations that are managed are removed from # remaining_allocations remaining_allocations = ( self.driver.network_api. manage_network_allocations( context, remaining_allocations, server, share_network)) # We require that all allocations are managed, else we # may have problems deleting this share server if len(remaining_allocations) > 0: msg = (""Failed to manage all allocations. "" ""Allocations %s were not "" ""managed."" % six.text_type( remaining_allocations)) raise exception.ManageShareServerError(reason=msg) else: # if there should be allocations, but the driver # doesn't return any something is wrong msg = (""Driver did not return required network "" ""allocations to be managed. Required number "" ""of allocations is %s."" % number_allocations) raise exception.ManageShareServerError(reason=msg) new_identifier, backend_details = self.driver.manage_server( context, server, identifier, driver_opts) if not new_identifier: new_identifier = server['id'] if backend_details is None or not isinstance( backend_details, dict): backend_details = {} for security_service in share_network['security_services']: ss_type = security_service['type'] data = { 'name': security_service['name'], 'ou': security_service['ou'], 'domain': security_service['domain'], 'server': security_service['server'], 'dns_ip': security_service['dns_ip'], 'user': security_service['user'], 'type': ss_type, 'password': security_service['password'], } backend_details.update({ 'security_service_' + ss_type: jsonutils.dumps(data) }) if backend_details: self.db.share_server_backend_details_set( context, server['id'], backend_details) self.db.share_server_update( context, share_server_id, {'status': constants.STATUS_ACTIVE, 'identifier': new_identifier}) except Exception: msg = ""Error managing share server %s"" LOG.exception(msg, share_server_id) self.db.share_server_update( context, share_server_id, {'status': constants.STATUS_MANAGE_ERROR}) raise LOG.info(""Share server %s managed successfully."", share_server_id) @add_hooks @utils.require_driver_initialized def unmanage_share_server(self, context, share_server_id, force=False): server = self.db.share_server_get( context, share_server_id) server_details = server['backend_details'] security_services = [] for ss_name in constants.SECURITY_SERVICES_ALLOWED_TYPES: ss = server_details.get('security_service_' + ss_name) if ss: security_services.append(jsonutils.loads(ss)) try: self.driver.unmanage_server(server_details, security_services) except NotImplementedError: if not force: LOG.error(""Did not unmanage share server %s since the driver "" ""does not support managing share servers and no "" ""``force`` option was supplied."", share_server_id) self.db.share_server_update( context, share_server_id, {'status': constants.STATUS_UNMANAGE_ERROR}) return try: if self.driver.get_network_allocations_number() > 0: # NOTE(ganso): This will already remove admin allocations. self.driver.network_api.unmanage_network_allocations( context, share_server_id) elif (self.driver.get_admin_network_allocations_number() > 0 and self.driver.admin_network_api): # NOTE(ganso): This is here in case there are only admin # allocations. self.driver.admin_network_api.unmanage_network_allocations( context, share_server_id) self.db.share_server_delete(context, share_server_id) except Exception: msg = ""Error unmanaging share server %s"" LOG.exception(msg, share_server_id) self.db.share_server_update( context, share_server_id, {'status': constants.STATUS_UNMANAGE_ERROR}) raise LOG.info(""Share server %s unmanaged successfully."", share_server_id) @add_hooks @utils.require_driver_initialized def revert_to_snapshot(self, context, snapshot_id, reservations): context = context.elevated() snapshot = self.db.share_snapshot_get(context, snapshot_id) share = snapshot['share'] share_id = share['id'] share_instance_id = snapshot.instance.share_instance_id share_access_rules = ( self.access_helper.get_share_instance_access_rules( context, filters={'state': constants.STATUS_ACTIVE}, share_instance_id=share_instance_id)) snapshot_access_rules = ( self.snapshot_access_helper.get_snapshot_instance_access_rules( context, snapshot.instance['id'])) if share.get('has_replicas'): self._revert_to_replicated_snapshot( context, share, snapshot, reservations, share_access_rules, snapshot_access_rules, share_id=share_id) else: self._revert_to_snapshot(context, share, snapshot, reservations, share_access_rules, snapshot_access_rules) def _revert_to_snapshot(self, context, share, snapshot, reservations, share_access_rules, snapshot_access_rules): share_server = self._get_share_server(context, share) share_id = share['id'] snapshot_id = snapshot['id'] project_id = share['project_id'] user_id = share['user_id'] snapshot_instance = self.db.share_snapshot_instance_get( context, snapshot.instance['id'], with_share_data=True) share_type_id = snapshot_instance[""share_instance""][""share_type_id""] # Make primitive to pass the information to the driver snapshot_instance_dict = self._get_snapshot_instance_dict( context, snapshot_instance, snapshot=snapshot) try: self.driver.revert_to_snapshot(context, snapshot_instance_dict, share_access_rules, snapshot_access_rules, share_server=share_server) except Exception as excep: with excutils.save_and_reraise_exception(): msg = ('Share %(share)s could not be reverted ' 'to snapshot %(snap)s.') msg_args = {'share': share_id, 'snap': snapshot_id} LOG.exception(msg, msg_args) if reservations: QUOTAS.rollback( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_type_id, ) self.db.share_update( context, share_id, {'status': constants.STATUS_REVERTING_ERROR}) self.db.share_snapshot_update( context, snapshot_id, {'status': constants.STATUS_AVAILABLE}) self.message_api.create( context, message_field.Action.REVERT_TO_SNAPSHOT, share['project_id'], resource_type=message_field.Resource.SHARE, resource_id=share_id, exception=excep) if reservations: QUOTAS.commit( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_type_id, ) self.db.share_update( context, share_id, {'status': constants.STATUS_AVAILABLE, 'size': snapshot['size']}) self.db.share_snapshot_update( context, snapshot_id, {'status': constants.STATUS_AVAILABLE}) msg = ('Share %(share)s reverted to snapshot %(snap)s ' 'successfully.') msg_args = {'share': share_id, 'snap': snapshot_id} LOG.info(msg, msg_args) @add_hooks @utils.require_driver_initialized def delete_share_instance(self, context, share_instance_id, force=False): """"""Delete a share instance."""""" context = context.elevated() share_instance = self._get_share_instance(context, share_instance_id) share_id = share_instance.get('share_id') share_server = self._get_share_server(context, share_instance) share = self.db.share_get(context, share_id) self._notify_about_share_usage(context, share, share_instance, ""delete.start"") try: self.access_helper.update_access_rules( context, share_instance_id, delete_all_rules=True, share_server=share_server ) except exception.ShareResourceNotFound: LOG.warning(""Share instance %s does not exist in the "" ""backend."", share_instance_id) except Exception as excep: with excutils.save_and_reraise_exception() as exc_context: if force: msg = (""The driver was unable to delete access rules "" ""for the instance: %s. Will attempt to delete "" ""the instance anyway."") LOG.error(msg, share_instance_id) exc_context.reraise = False else: self.db.share_instance_update( context, share_instance_id, {'status': constants.STATUS_ERROR_DELETING}) self.message_api.create( context, message_field.Action.DELETE_ACCESS_RULES, share_instance['project_id'], resource_type=message_field.Resource.SHARE, resource_id=share_instance_id, exception=excep) try: self.driver.delete_share(context, share_instance, share_server=share_server) except exception.ShareResourceNotFound: LOG.warning(""Share instance %s does not exist in the "" ""backend."", share_instance_id) except Exception as excep: with excutils.save_and_reraise_exception() as exc_context: if force: msg = (""The driver was unable to delete the share "" ""instance: %s on the backend. Since this "" ""operation is forced, the instance will be "" ""deleted from Manila's database. A cleanup on "" ""the backend may be necessary."") LOG.error(msg, share_instance_id) exc_context.reraise = False else: self.db.share_instance_update( context, share_instance_id, {'status': constants.STATUS_ERROR_DELETING}) self.message_api.create( context, message_field.Action.DELETE, share_instance['project_id'], resource_type=message_field.Resource.SHARE, resource_id=share_instance_id, exception=excep) self.db.share_instance_delete( context, share_instance_id, need_to_update_usages=True) LOG.info(""Share instance %s: deleted successfully."", share_instance_id) self._check_delete_share_server(context, share_instance) self._notify_about_share_usage(context, share, share_instance, ""delete.end"") def _check_delete_share_server(self, context, share_instance): if CONF.delete_share_server_with_last_share: share_server = self._get_share_server(context, share_instance) if (share_server and len(share_server.share_instances) == 0 and share_server.is_auto_deletable is True): LOG.debug(""Scheduled deletion of share-server "" ""with id '%s' automatically by "" ""deletion of last share."", share_server['id']) self.delete_share_server(context, share_server) @periodic_task.periodic_task(spacing=600) @utils.require_driver_initialized def delete_free_share_servers(self, ctxt): if not (self.driver.driver_handles_share_servers and self.configuration.automatic_share_server_cleanup): return LOG.info(""Check for unused share servers to delete."") updated_before = timeutils.utcnow() - datetime.timedelta( minutes=self.configuration.unused_share_server_cleanup_interval) servers = self.db.share_server_get_all_unused_deletable(ctxt, self.host, updated_before) for server in servers: self.delete_share_server(ctxt, server) @add_hooks @utils.require_driver_initialized def create_snapshot(self, context, share_id, snapshot_id): """"""Create snapshot for share."""""" snapshot_ref = self.db.share_snapshot_get(context, snapshot_id) share_server = self._get_share_server( context, snapshot_ref['share']['instance']) snapshot_instance = self.db.share_snapshot_instance_get( context, snapshot_ref.instance['id'], with_share_data=True ) snapshot_instance_id = snapshot_instance['id'] snapshot_instance = self._get_snapshot_instance_dict( context, snapshot_instance) try: model_update = self.driver.create_snapshot( context, snapshot_instance, share_server=share_server) or {} except Exception as excep: with excutils.save_and_reraise_exception(): self.db.share_snapshot_instance_update( context, snapshot_instance_id, {'status': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.CREATE, snapshot_ref['project_id'], resource_type=message_field.Resource.SHARE_SNAPSHOT, resource_id=snapshot_instance_id, exception=excep) snapshot_export_locations = model_update.pop('export_locations', []) if snapshot_instance['share']['mount_snapshot_support']: for el in snapshot_export_locations: values = { 'share_snapshot_instance_id': snapshot_instance_id, 'path': el['path'], 'is_admin_only': el['is_admin_only'], } self.db.share_snapshot_instance_export_location_create(context, values) if model_update.get('status') in (None, constants.STATUS_AVAILABLE): model_update['status'] = constants.STATUS_AVAILABLE model_update['progress'] = '100%' self.db.share_snapshot_instance_update( context, snapshot_instance_id, model_update) @add_hooks @utils.require_driver_initialized def delete_snapshot(self, context, snapshot_id, force=False): """"""Delete share snapshot."""""" context = context.elevated() snapshot_ref = self.db.share_snapshot_get(context, snapshot_id) share_server = self._get_share_server( context, snapshot_ref['share']['instance']) snapshot_instance = self.db.share_snapshot_instance_get( context, snapshot_ref.instance['id'], with_share_data=True) snapshot_instance_id = snapshot_instance['id'] if context.project_id != snapshot_ref['project_id']: project_id = snapshot_ref['project_id'] else: project_id = context.project_id snapshot_instance = self._get_snapshot_instance_dict( context, snapshot_instance) share_ref = self.db.share_get(context, snapshot_ref['share_id']) if share_ref['mount_snapshot_support']: try: self.snapshot_access_helper.update_access_rules( context, snapshot_instance['id'], delete_all_rules=True, share_server=share_server) except Exception: LOG.exception( (""Failed to remove access rules for snapshot %s.""), snapshot_instance['id']) LOG.warning(""The driver was unable to remove access rules "" ""for snapshot %s. Moving on."", snapshot_instance['snapshot_id']) try: self.driver.delete_snapshot(context, snapshot_instance, share_server=share_server) except Exception as excep: with excutils.save_and_reraise_exception() as exc: if force: msg = _(""The driver was unable to delete the "" ""snapshot %s on the backend. Since this "" ""operation is forced, the snapshot will "" ""be deleted from Manila's database. A cleanup on "" ""the backend may be necessary."") LOG.exception(msg, snapshot_id) exc.reraise = False else: self.db.share_snapshot_instance_update( context, snapshot_instance_id, {'status': constants.STATUS_ERROR_DELETING}) self.message_api.create( context, message_field.Action.DELETE, snapshot_ref['project_id'], resource_type=message_field.Resource.SHARE_SNAPSHOT, resource_id=snapshot_instance_id, exception=excep) self.db.share_snapshot_instance_delete(context, snapshot_instance_id) share_type_id = snapshot_ref['share']['instance']['share_type_id'] try: reservations = QUOTAS.reserve( context, project_id=project_id, snapshots=-1, snapshot_gigabytes=-snapshot_ref['size'], user_id=snapshot_ref['user_id'], share_type_id=share_type_id, ) except Exception: reservations = None LOG.exception(""Failed to update quota usages while deleting "" ""snapshot %s."", snapshot_id) if reservations: QUOTAS.commit( context, reservations, project_id=project_id, user_id=snapshot_ref['user_id'], share_type_id=share_type_id, ) @add_hooks @utils.require_driver_initialized @locked_share_replica_operation def create_replicated_snapshot(self, context, snapshot_id, share_id=None): """"""Create a snapshot for a replicated share."""""" # Grab the snapshot and replica information from the DB. snapshot = self.db.share_snapshot_get(context, snapshot_id) share_server = self._get_share_server(context, snapshot['share']) replica_snapshots = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'snapshot_ids': snapshot['id']}, with_share_data=True) ) replica_list = ( self.db.share_replicas_get_all_by_share( context, share_id, with_share_data=True, with_share_server=True) ) # Make primitives to pass the information to the driver. replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] replica_snapshots = [self._get_snapshot_instance_dict(context, s) for s in replica_snapshots] updated_instances = [] try: updated_instances = self.driver.create_replicated_snapshot( context, replica_list, replica_snapshots, share_server=share_server) or [] except Exception: with excutils.save_and_reraise_exception(): for instance in replica_snapshots: self.db.share_snapshot_instance_update( context, instance['id'], {'status': constants.STATUS_ERROR}) for instance in updated_instances: if instance['status'] == constants.STATUS_AVAILABLE: instance.update({'progress': '100%'}) self.db.share_snapshot_instance_update( context, instance['id'], instance) def _find_active_replica_on_host(self, replica_list): """"""Find the active replica matching this manager's host."""""" for replica in replica_list: if (replica['replica_state'] == constants.REPLICA_STATE_ACTIVE and share_utils.extract_host(replica['host']) == self.host): return replica @locked_share_replica_operation def _revert_to_replicated_snapshot(self, context, share, snapshot, reservations, share_access_rules, snapshot_access_rules, share_id=None): share_server = self._get_share_server(context, share) snapshot_id = snapshot['id'] project_id = share['project_id'] user_id = share['user_id'] # Get replicas, including an active replica replica_list = self.db.share_replicas_get_all_by_share( context, share_id, with_share_data=True, with_share_server=True) active_replica = self._find_active_replica_on_host(replica_list) # Get snapshot instances, including one on an active replica replica_snapshots = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'snapshot_ids': snapshot_id}, with_share_data=True)) snapshot_instance_filters = { 'share_instance_ids': active_replica['id'], 'snapshot_ids': snapshot_id, } active_replica_snapshot = ( self.db.share_snapshot_instance_get_all_with_filters( context, snapshot_instance_filters))[0] # Make primitives to pass the information to the driver replica_list = [self._get_share_replica_dict(context, replica) for replica in replica_list] active_replica = self._get_share_replica_dict(context, active_replica) replica_snapshots = [self._get_snapshot_instance_dict(context, s) for s in replica_snapshots] active_replica_snapshot = self._get_snapshot_instance_dict( context, active_replica_snapshot, snapshot=snapshot) try: self.driver.revert_to_replicated_snapshot( context, active_replica, replica_list, active_replica_snapshot, replica_snapshots, share_access_rules, snapshot_access_rules, share_server=share_server) except Exception: with excutils.save_and_reraise_exception(): msg = ('Share %(share)s could not be reverted ' 'to snapshot %(snap)s.') msg_args = {'share': share_id, 'snap': snapshot_id} LOG.exception(msg, msg_args) if reservations: QUOTAS.rollback( context, reservations, project_id=project_id, user_id=user_id, share_type_id=active_replica['share_type_id'], ) self.db.share_replica_update( context, active_replica['id'], {'status': constants.STATUS_REVERTING_ERROR}) self.db.share_snapshot_instance_update( context, active_replica_snapshot['id'], {'status': constants.STATUS_AVAILABLE}) if reservations: QUOTAS.commit( context, reservations, project_id=project_id, user_id=user_id, share_type_id=active_replica['share_type_id'], ) self.db.share_update(context, share_id, {'size': snapshot['size']}) self.db.share_replica_update( context, active_replica['id'], {'status': constants.STATUS_AVAILABLE}) self.db.share_snapshot_instance_update( context, active_replica_snapshot['id'], {'status': constants.STATUS_AVAILABLE}) msg = ('Share %(share)s reverted to snapshot %(snap)s ' 'successfully.') msg_args = {'share': share_id, 'snap': snapshot_id} LOG.info(msg, msg_args) @add_hooks @utils.require_driver_initialized @locked_share_replica_operation def delete_replicated_snapshot(self, context, snapshot_id, share_id=None, force=False): """"""Delete a snapshot from a replicated share."""""" # Grab the replica and snapshot information from the DB. snapshot = self.db.share_snapshot_get(context, snapshot_id) share_server = self._get_share_server(context, snapshot['share']) replica_snapshots = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'snapshot_ids': snapshot['id']}, with_share_data=True) ) replica_list = ( self.db.share_replicas_get_all_by_share( context, share_id, with_share_data=True, with_share_server=True) ) replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] replica_snapshots = [self._get_snapshot_instance_dict(context, s) for s in replica_snapshots] deleted_instances = [] updated_instances = [] db_force_delete_msg = _('The driver was unable to delete some or all ' 'of the share replica snapshots on the ' 'backend/s. Since this operation is forced, ' 'the replica snapshots will be deleted from ' 'Manila.') try: updated_instances = self.driver.delete_replicated_snapshot( context, replica_list, replica_snapshots, share_server=share_server) or [] except Exception: with excutils.save_and_reraise_exception() as e: if force: # Can delete all instances if forced. deleted_instances = replica_snapshots LOG.exception(db_force_delete_msg) e.reraise = False else: for instance in replica_snapshots: self.db.share_snapshot_instance_update( context, instance['id'], {'status': constants.STATUS_ERROR_DELETING}) if not deleted_instances: if force: # Ignore model updates on 'force' delete. LOG.warning(db_force_delete_msg) deleted_instances = replica_snapshots else: deleted_instances = list(filter( lambda x: x['status'] == constants.STATUS_DELETED, updated_instances)) updated_instances = list(filter( lambda x: x['status'] != constants.STATUS_DELETED, updated_instances)) for instance in deleted_instances: self.db.share_snapshot_instance_delete(context, instance['id']) for instance in updated_instances: self.db.share_snapshot_instance_update( context, instance['id'], instance) @periodic_task.periodic_task(spacing=CONF.replica_state_update_interval) @utils.require_driver_initialized def periodic_share_replica_snapshot_update(self, context): LOG.debug(""Updating status of share replica snapshots."") transitional_statuses = (constants.STATUS_CREATING, constants.STATUS_DELETING) replicas = self.db.share_replicas_get_all(context, with_share_data=True) def qualified_replica(r): # Filter non-active replicas belonging to this backend return (share_utils.extract_host(r['host']) == share_utils.extract_host(self.host) and r['replica_state'] != constants.REPLICA_STATE_ACTIVE) host_replicas = list(filter( lambda x: qualified_replica(x), replicas)) transitional_replica_snapshots = [] # Get snapshot instances for each replica that are in 'creating' or # 'deleting' states. for replica in host_replicas: filters = { 'share_instance_ids': replica['id'], 'statuses': transitional_statuses, } replica_snapshots = ( self.db.share_snapshot_instance_get_all_with_filters( context, filters, with_share_data=True) ) transitional_replica_snapshots.extend(replica_snapshots) for replica_snapshot in transitional_replica_snapshots: replica_snapshots = ( self.db.share_snapshot_instance_get_all_with_filters( context, {'snapshot_ids': replica_snapshot['snapshot_id']}) ) share_id = replica_snapshot['share']['share_id'] self._update_replica_snapshot( context, replica_snapshot, replica_snapshots=replica_snapshots, share_id=share_id) @locked_share_replica_operation def _update_replica_snapshot(self, context, replica_snapshot, replica_snapshots=None, share_id=None): # Re-grab the replica: try: share_replica = self.db.share_replica_get( context, replica_snapshot['share_instance_id'], with_share_data=True, with_share_server=True) replica_snapshot = self.db.share_snapshot_instance_get( context, replica_snapshot['id'], with_share_data=True) except exception.NotFound: # Replica may have been deleted, try to cleanup the snapshot # instance try: self.db.share_snapshot_instance_delete( context, replica_snapshot['id']) except exception.ShareSnapshotInstanceNotFound: # snapshot instance has been deleted, nothing to do here pass return msg_payload = { 'snapshot_instance': replica_snapshot['id'], 'replica': share_replica['id'], } LOG.debug(""Updating status of replica snapshot %(snapshot_instance)s: "" ""on replica: %(replica)s"", msg_payload) # Grab all the replica and snapshot information. replica_list = ( self.db.share_replicas_get_all_by_share( context, share_replica['share_id'], with_share_data=True, with_share_server=True) ) replica_list = [self._get_share_replica_dict(context, r) for r in replica_list] replica_snapshots = replica_snapshots or [] # Convert data to primitives to send to the driver. replica_snapshots = [self._get_snapshot_instance_dict(context, s) for s in replica_snapshots] replica_snapshot = self._get_snapshot_instance_dict( context, replica_snapshot) share_replica = self._get_share_replica_dict(context, share_replica) share_server = share_replica['share_server'] snapshot_update = None try: snapshot_update = self.driver.update_replicated_snapshot( context, replica_list, share_replica, replica_snapshots, replica_snapshot, share_server=share_server) or {} except exception.SnapshotResourceNotFound: if replica_snapshot['status'] == constants.STATUS_DELETING: LOG.info('Snapshot %(snapshot_instance)s on replica ' '%(replica)s has been deleted.', msg_payload) self.db.share_snapshot_instance_delete( context, replica_snapshot['id']) else: LOG.exception(""Replica snapshot %s was not found on "" ""the backend."", replica_snapshot['id']) self.db.share_snapshot_instance_update( context, replica_snapshot['id'], {'status': constants.STATUS_ERROR}) except Exception: LOG.exception(""Driver error while updating replica snapshot: "" ""%s"", replica_snapshot['id']) self.db.share_snapshot_instance_update( context, replica_snapshot['id'], {'status': constants.STATUS_ERROR}) if snapshot_update: snapshot_status = snapshot_update.get('status') if snapshot_status == constants.STATUS_AVAILABLE: snapshot_update['progress'] = '100%' self.db.share_snapshot_instance_update( context, replica_snapshot['id'], snapshot_update) @add_hooks @utils.require_driver_initialized def update_access(self, context, share_instance_id): """"""Allow/Deny access to some share."""""" share_instance = self._get_share_instance(context, share_instance_id) share_server = self._get_share_server(context, share_instance) LOG.debug(""Received request to update access for share instance"" "" %s."", share_instance_id) self.access_helper.update_access_rules( context, share_instance_id, share_server=share_server) @periodic_task.periodic_task(spacing=CONF.periodic_interval) @utils.require_driver_initialized def _report_driver_status(self, context): LOG.info('Updating share status') share_stats = self.driver.get_share_stats(refresh=True) if not share_stats: return if self.driver.driver_handles_share_servers: share_stats['server_pools_mapping'] = ( self._get_servers_pool_mapping(context) ) self.update_service_capabilities(share_stats) @periodic_task.periodic_task(spacing=CONF.periodic_hooks_interval) @utils.require_driver_initialized def _execute_periodic_hook(self, context): """"""Executes periodic-based hooks."""""" # TODO(vponomaryov): add also access rules and share servers share_instances = ( self.db.share_instances_get_all_by_host( context=context, host=self.host)) periodic_hook_data = self.driver.get_periodic_hook_data( context=context, share_instances=share_instances) for hook in self.hooks: hook.execute_periodic_hook( context=context, periodic_hook_data=periodic_hook_data) def _get_servers_pool_mapping(self, context): """"""Get info about relationships between pools and share_servers."""""" share_servers = self.db.share_server_get_all_by_host(context, self.host) return {server['id']: self.driver.get_share_server_pools(server) for server in share_servers} @add_hooks @utils.require_driver_initialized def publish_service_capabilities(self, context): """"""Collect driver status and then publish it."""""" self._report_driver_status(context) self._publish_service_capabilities(context) def _form_server_setup_info(self, context, share_server, share_network): # Network info is used by driver for setting up share server # and getting server info on share creation. network_allocations = self.db.network_allocations_get_for_share_server( context, share_server['id'], label='user') admin_network_allocations = ( self.db.network_allocations_get_for_share_server( context, share_server['id'], label='admin')) # NOTE(vponomaryov): following network_info fields are deprecated: # 'segmentation_id', 'cidr' and 'network_type'. # And they should be used from network allocations directly. # They should be removed right after no one uses them. network_info = { 'server_id': share_server['id'], 'segmentation_id': share_network['segmentation_id'], 'cidr': share_network['cidr'], 'neutron_net_id': share_network['neutron_net_id'], 'neutron_subnet_id': share_network['neutron_subnet_id'], 'security_services': share_network['security_services'], 'network_allocations': network_allocations, 'admin_network_allocations': admin_network_allocations, 'backend_details': share_server.get('backend_details'), 'network_type': share_network['network_type'], } return network_info def _setup_server(self, context, share_server, metadata=None): try: share_network = self.db.share_network_get( context, share_server['share_network_id']) self.driver.allocate_network(context, share_server, share_network) self.driver.allocate_admin_network(context, share_server) # Get share_network again in case it was updated. share_network = self.db.share_network_get( context, share_server['share_network_id']) network_info = self._form_server_setup_info( context, share_server, share_network) self._validate_segmentation_id(network_info) # NOTE(vponomaryov): Save security services data to share server # details table to remove dependency from share network after # creation operation. It will allow us to delete share server and # share network separately without dependency on each other. for security_service in network_info['security_services']: ss_type = security_service['type'] data = { 'name': security_service['name'], 'ou': security_service['ou'], 'domain': security_service['domain'], 'server': security_service['server'], 'dns_ip': security_service['dns_ip'], 'user': security_service['user'], 'type': ss_type, 'password': security_service['password'], } self.db.share_server_backend_details_set( context, share_server['id'], {'security_service_' + ss_type: jsonutils.dumps(data)}) server_info = self.driver.setup_server( network_info, metadata=metadata) self.driver.update_network_allocation(context, share_server) self.driver.update_admin_network_allocation(context, share_server) if server_info and isinstance(server_info, dict): self.db.share_server_backend_details_set( context, share_server['id'], server_info) return self.db.share_server_update( context, share_server['id'], {'status': constants.STATUS_ACTIVE, 'identifier': server_info.get( 'identifier', share_server['id'])}) except Exception as e: with excutils.save_and_reraise_exception(): details = getattr(e, ""detail_data"", {}) if isinstance(details, dict): server_details = details.get(""server_details"", {}) if not isinstance(server_details, dict): LOG.debug( (""Cannot save non-dict data (%(data)s) "" ""provided as 'server details' of "" ""failed share server '%(server)s'.""), {""server"": share_server[""id""], ""data"": server_details}) else: invalid_details = [] for key, value in server_details.items(): try: self.db.share_server_backend_details_set( context, share_server['id'], {key: value}) except Exception: invalid_details.append(""%(key)s: %(value)s"" % { 'key': six.text_type(key), 'value': six.text_type(value) }) if invalid_details: LOG.debug( (""Following server details "" ""cannot be written to db : %s""), six.text_type(""\n"".join(invalid_details))) else: LOG.debug( (""Cannot save non-dict data (%(data)s) provided as "" ""'detail data' of failed share server '%(server)s'.""), {""server"": share_server[""id""], ""data"": details}) self.db.share_server_update( context, share_server['id'], {'status': constants.STATUS_ERROR}) self.driver.deallocate_network(context, share_server['id']) def _validate_segmentation_id(self, network_info): """"""Raises exception if the segmentation type is incorrect."""""" if (network_info['network_type'] in (None, 'flat') and network_info['segmentation_id']): msg = _('A segmentation ID %(vlan_id)s was specified but can not ' 'be used with a network of type %(seg_type)s; the ' 'segmentation ID option must be omitted or set to 0') raise exception.NetworkBadConfigurationException( reason=msg % {'vlan_id': network_info['segmentation_id'], 'seg_type': network_info['network_type']}) elif (network_info['network_type'] == 'vlan' and (network_info['segmentation_id'] is None or int(network_info['segmentation_id']) > 4094 or int(network_info['segmentation_id']) < 1)): msg = _('A segmentation ID %s was specified but is not valid for ' 'a VLAN network type; the segmentation ID must be an ' 'integer value in the range of [1,4094]') raise exception.NetworkBadConfigurationException( reason=msg % network_info['segmentation_id']) elif (network_info['network_type'] == 'vxlan' and (network_info['segmentation_id'] is None or int(network_info['segmentation_id']) > 16777215 or int(network_info['segmentation_id']) < 1)): msg = _('A segmentation ID %s was specified but is not valid for ' 'a VXLAN network type; the segmentation ID must be an ' 'integer value in the range of [1,16777215]') raise exception.NetworkBadConfigurationException( reason=msg % network_info['segmentation_id']) elif (network_info['network_type'] == 'gre' and (network_info['segmentation_id'] is None or int(network_info['segmentation_id']) > 4294967295 or int(network_info['segmentation_id']) < 1)): msg = _('A segmentation ID %s was specified but is not valid for ' 'a GRE network type; the segmentation ID must be an ' 'integer value in the range of [1, 4294967295]') raise exception.NetworkBadConfigurationException( reason=msg % network_info['segmentation_id']) @add_hooks @utils.require_driver_initialized def delete_share_server(self, context, share_server): @utils.synchronized( ""share_manager_%s"" % share_server['share_network_id']) def _wrapped_delete_share_server(): # NOTE(vponomaryov): Verify that there are no dependent shares. # Without this verification we can get here exception in next case: # share-server-delete API was called after share creation scheduled # and share_server reached ACTIVE status, but before update # of share_server_id field for share. If so, after lock realese # this method starts executing when amount of dependent shares # has been changed. server_id = share_server['id'] shares = self.db.share_instances_get_all_by_share_server( context, server_id) if shares: raise exception.ShareServerInUse(share_server_id=server_id) server_details = share_server['backend_details'] self.db.share_server_update(context, server_id, {'status': constants.STATUS_DELETING}) try: LOG.debug(""Deleting share server '%s'"", server_id) security_services = [] for ss_name in constants.SECURITY_SERVICES_ALLOWED_TYPES: ss = server_details.get('security_service_' + ss_name) if ss: security_services.append(jsonutils.loads(ss)) self.driver.teardown_server( server_details=server_details, security_services=security_services) except Exception: with excutils.save_and_reraise_exception(): LOG.error( ""Share server '%s' failed on deletion."", server_id) self.db.share_server_update( context, server_id, {'status': constants.STATUS_ERROR}) else: self.db.share_server_delete(context, share_server['id']) _wrapped_delete_share_server() LOG.info( ""Share server '%s' has been deleted successfully."", share_server['id']) self.driver.deallocate_network(context, share_server['id']) @add_hooks @utils.require_driver_initialized def extend_share(self, context, share_id, new_size, reservations): context = context.elevated() share = self.db.share_get(context, share_id) share_instance = self._get_share_instance(context, share) share_server = self._get_share_server(context, share_instance) project_id = share['project_id'] user_id = share['user_id'] self._notify_about_share_usage(context, share, share_instance, ""extend.start"") try: self.driver.extend_share( share_instance, new_size, share_server=share_server) except Exception as e: LOG.exception(""Extend share failed."", resource=share) try: self.db.share_update( context, share['id'], {'status': constants.STATUS_EXTENDING_ERROR} ) raise exception.ShareExtendingError( reason=six.text_type(e), share_id=share_id) finally: QUOTAS.rollback( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_instance['share_type_id'], ) # we give the user_id of the share, to update the quota usage # for the user, who created the share, because on share delete # only this quota will be decreased QUOTAS.commit( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_instance['share_type_id'], ) share_update = { 'size': int(new_size), # NOTE(u_glide): translation to lower case should be removed in # a row with usage of upper case of share statuses in all places 'status': constants.STATUS_AVAILABLE.lower() } share = self.db.share_update(context, share['id'], share_update) LOG.info(""Extend share completed successfully."", resource=share) self._notify_about_share_usage(context, share, share_instance, ""extend.end"") @add_hooks @utils.require_driver_initialized def shrink_share(self, context, share_id, new_size): context = context.elevated() share = self.db.share_get(context, share_id) share_instance = self._get_share_instance(context, share) share_server = self._get_share_server(context, share_instance) project_id = share['project_id'] user_id = share['user_id'] new_size = int(new_size) self._notify_about_share_usage(context, share, share_instance, ""shrink.start"") def error_occurred(exc, msg, status=constants.STATUS_SHRINKING_ERROR): LOG.exception(msg, resource=share) self.db.share_update(context, share['id'], {'status': status}) raise exception.ShareShrinkingError( reason=six.text_type(exc), share_id=share_id) reservations = None try: size_decrease = int(share['size']) - new_size # we give the user_id of the share, to update the quota usage # for the user, who created the share, because on share delete # only this quota will be decreased reservations = QUOTAS.reserve( context, project_id=project_id, user_id=user_id, share_type_id=share_instance['share_type_id'], gigabytes=-size_decrease, ) except Exception as e: error_occurred( e, (""Failed to update quota on share shrinking."")) try: self.driver.shrink_share( share_instance, new_size, share_server=share_server) # NOTE(u_glide): Replace following except block by error notification # when Manila has such mechanism. It's possible because drivers # shouldn't shrink share when this validation error occurs. except Exception as e: if isinstance(e, exception.ShareShrinkingPossibleDataLoss): msg = (""Shrink share failed due to possible data loss."") status = constants.STATUS_SHRINKING_POSSIBLE_DATA_LOSS_ERROR error_params = {'msg': msg, 'status': status} else: error_params = {'msg': (""Shrink share failed."")} try: error_occurred(e, **error_params) finally: QUOTAS.rollback( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_instance['share_type_id'], ) QUOTAS.commit( context, reservations, project_id=project_id, user_id=user_id, share_type_id=share_instance['share_type_id'], ) share_update = { 'size': new_size, 'status': constants.STATUS_AVAILABLE } share = self.db.share_update(context, share['id'], share_update) LOG.info(""Shrink share completed successfully."", resource=share) self._notify_about_share_usage(context, share, share_instance, ""shrink.end"") @utils.require_driver_initialized def create_share_group(self, context, share_group_id): context = context.elevated() share_group_ref = self.db.share_group_get(context, share_group_id) share_group_ref['host'] = self.host shares = self.db.share_instances_get_all_by_share_group_id( context, share_group_id) source_share_group_snapshot_id = share_group_ref.get( ""source_share_group_snapshot_id"") snap_ref = None parent_share_server_id = None if source_share_group_snapshot_id: snap_ref = self.db.share_group_snapshot_get( context, source_share_group_snapshot_id) for member in snap_ref['share_group_snapshot_members']: member['share'] = self.db.share_instance_get( context, member['share_instance_id'], with_share_data=True) if 'share_group' in snap_ref: parent_share_server_id = snap_ref['share_group'][ 'share_server_id'] status = constants.STATUS_AVAILABLE share_network_id = share_group_ref.get('share_network_id') share_server = None if parent_share_server_id and self.driver.driver_handles_share_servers: share_server = self.db.share_server_get(context, parent_share_server_id) share_network_id = share_server['share_network_id'] if share_network_id and not self.driver.driver_handles_share_servers: self.db.share_group_update( context, share_group_id, {'status': constants.STATUS_ERROR}) msg = _(""Driver does not expect share-network to be provided "" ""with current configuration."") raise exception.InvalidInput(reason=msg) if not share_server and share_network_id: try: share_server, share_group_ref = ( self._provide_share_server_for_share_group( context, share_network_id, share_group_ref, share_group_snapshot=snap_ref, ) ) except Exception: with excutils.save_and_reraise_exception(): LOG.error(""Failed to get share server"" "" for share group creation."") self.db.share_group_update( context, share_group_id, {'status': constants.STATUS_ERROR}) self.message_api.create( context, message_field.Action.CREATE, share_group_ref['project_id'], resource_type=message_field.Resource.SHARE_GROUP, resource_id=share_group_id, detail=message_field.Detail.NO_SHARE_SERVER) try: # TODO(ameade): Add notification for create.start LOG.info(""Share group %s: creating"", share_group_id) model_update, share_update_list = None, None share_group_ref['shares'] = shares if snap_ref: model_update, share_update_list = ( self.driver.create_share_group_from_share_group_snapshot( context, share_group_ref, snap_ref, share_server=share_server)) else: model_update = self.driver.create_share_group( context, share_group_ref, share_server=share_server) if model_update: share_group_ref = self.db.share_group_update( context, share_group_ref['id'], model_update) if share_update_list: for share in share_update_list: values = copy.deepcopy(share) values.pop('id') export_locations = values.pop('export_locations') self.db.share_instance_update(context, share['id'], values) self.db.share_export_locations_update(context, share['id'], export_locations) except Exception: with excutils.save_and_reraise_exception(): self.db.share_group_update( context, share_group_ref['id'], {'status': constants.STATUS_ERROR, 'availability_zone_id': self._get_az_for_share_group( context, share_group_ref), 'consistent_snapshot_support': self.driver._stats[ 'share_group_stats'].get( 'consistent_snapshot_support')}) for share in shares: self.db.share_instance_update( context, share['id'], {'status': constants.STATUS_ERROR}) LOG.error(""Share group %s: create failed"", share_group_id) now = timeutils.utcnow() for share in shares: self.db.share_instance_update( context, share['id'], {'status': constants.STATUS_AVAILABLE}) self.db.share_group_update( context, share_group_ref['id'], {'status': status, 'created_at': now, 'availability_zone_id': self._get_az_for_share_group( context, share_group_ref), 'consistent_snapshot_support': self.driver._stats[ 'share_group_stats'].get('consistent_snapshot_support')}) LOG.info(""Share group %s: created successfully"", share_group_id) # TODO(ameade): Add notification for create.end return share_group_ref['id'] def _get_az_for_share_group(self, context, share_group_ref): if not share_group_ref['availability_zone_id']: return self.db.availability_zone_get( context, self.availability_zone)['id'] return share_group_ref['availability_zone_id'] @utils.require_driver_initialized def delete_share_group(self, context, share_group_id): context = context.elevated() share_group_ref = self.db.share_group_get(context, share_group_id) share_group_ref['host'] = self.host share_group_ref['shares'] = ( self.db.share_instances_get_all_by_share_group_id( context, share_group_id)) # TODO(ameade): Add notification for delete.start try: LOG.info(""Share group %s: deleting"", share_group_id) share_server = None if share_group_ref.get('share_server_id'): share_server = self.db.share_server_get( context, share_group_ref['share_server_id']) model_update = self.driver.delete_share_group( context, share_group_ref, share_server=share_server) if model_update: share_group_ref = self.db.share_group_update( context, share_group_ref['id'], model_update) except Exception: with excutils.save_and_reraise_exception(): self.db.share_group_update( context, share_group_ref['id'], {'status': constants.STATUS_ERROR}) LOG.error(""Share group %s: delete failed"", share_group_ref['id']) self.db.share_group_destroy(context, share_group_id) LOG.info(""Share group %s: deleted successfully"", share_group_id) # TODO(ameade): Add notification for delete.end @utils.require_driver_initialized def create_share_group_snapshot(self, context, share_group_snapshot_id): context = context.elevated() snap_ref = self.db.share_group_snapshot_get( context, share_group_snapshot_id) for member in snap_ref['share_group_snapshot_members']: member['share'] = self.db.share_instance_get( context, member['share_instance_id'], with_share_data=True) status = constants.STATUS_AVAILABLE now = timeutils.utcnow() updated_members_ids = [] try: LOG.info(""Share group snapshot %s: creating"", share_group_snapshot_id) share_server = None if snap_ref['share_group'].get('share_server_id'): share_server = self.db.share_server_get( context, snap_ref['share_group']['share_server_id']) snapshot_update, member_update_list = ( self.driver.create_share_group_snapshot( context, snap_ref, share_server=share_server)) for update in (member_update_list or []): # NOTE(vponomaryov): we expect that each member is a dict # and has required 'id' key and some optional keys # to be updated such as 'provider_location'. It is planned # to have here also 'export_locations' when it is supported. member_id = update.pop('id', None) if not member_id: LOG.warning( ""One of share group snapshot '%s' members does not "" ""have reference ID. Its update was skipped."", share_group_snapshot_id) continue # TODO(vponomaryov): remove following condition when # sgs members start supporting export locations. if 'export_locations' in update: LOG.debug( ""Removing 'export_locations' data from "" ""share group snapshot member '%s' update because "" ""export locations are not supported."", member_id) update.pop('export_locations') db_update = { 'updated_at': now, 'status': update.pop('status', status) } if 'provider_location' in update: db_update['provider_location'] = ( update.pop('provider_location')) if 'size' in update: db_update['size'] = int(update.pop('size')) updated_members_ids.append(member_id) self.db.share_group_snapshot_member_update( context, member_id, db_update) if update: LOG.debug( ""Share group snapshot ID='%(sgs_id)s', "" ""share group snapshot member ID='%(sgsm_id)s'. "" ""Following keys of sgs member were not updated "" ""as not allowed: %(keys)s."", {'sgs_id': share_group_snapshot_id, 'sgsm_id': member_id, 'keys': ', '.join(update)}) if snapshot_update: snap_ref = self.db.share_group_snapshot_update( context, snap_ref['id'], snapshot_update) except Exception: with excutils.save_and_reraise_exception(): self.db.share_group_snapshot_update( context, snap_ref['id'], {'status': constants.STATUS_ERROR}) LOG.error(""Share group snapshot %s: create failed"", share_group_snapshot_id) for member in (snap_ref.get('share_group_snapshot_members') or []): if member['id'] in updated_members_ids: continue update = {'status': status, 'updated_at': now} self.db.share_group_snapshot_member_update( context, member['id'], update) self.db.share_group_snapshot_update( context, snap_ref['id'], {'status': status, 'updated_at': now}) LOG.info(""Share group snapshot %s: created successfully"", share_group_snapshot_id) return snap_ref['id'] @utils.require_driver_initialized def delete_share_group_snapshot(self, context, share_group_snapshot_id): context = context.elevated() snap_ref = self.db.share_group_snapshot_get( context, share_group_snapshot_id) for member in snap_ref['share_group_snapshot_members']: member['share'] = self.db.share_instance_get( context, member['share_instance_id'], with_share_data=True) snapshot_update = False try: LOG.info(""Share group snapshot %s: deleting"", share_group_snapshot_id) share_server = None if snap_ref['share_group'].get('share_server_id'): share_server = self.db.share_server_get( context, snap_ref['share_group']['share_server_id']) snapshot_update, member_update_list = ( self.driver.delete_share_group_snapshot( context, snap_ref, share_server=share_server)) if member_update_list: snapshot_update = snapshot_update or {} snapshot_update['share_group_snapshot_members'] = [] for update in (member_update_list or []): snapshot_update['share_group_snapshot_members'].append(update) if snapshot_update: snap_ref = self.db.share_group_snapshot_update( context, snap_ref['id'], snapshot_update) except Exception: with excutils.save_and_reraise_exception(): self.db.share_group_snapshot_update( context, snap_ref['id'], {'status': constants.STATUS_ERROR}) LOG.error(""Share group snapshot %s: delete failed"", snap_ref['name']) self.db.share_group_snapshot_destroy(context, share_group_snapshot_id) LOG.info(""Share group snapshot %s: deleted successfully"", share_group_snapshot_id) def _get_share_replica_dict(self, context, share_replica): # TODO(gouthamr): remove method when the db layer returns primitives share_replica_ref = { 'id': share_replica.get('id'), 'name': share_replica.get('name'), 'share_id': share_replica.get('share_id'), 'host': share_replica.get('host'), 'status': share_replica.get('status'), 'replica_state': share_replica.get('replica_state'), 'availability_zone_id': share_replica.get('availability_zone_id'), 'export_locations': share_replica.get('export_locations') or [], 'share_network_id': share_replica.get('share_network_id'), 'share_server_id': share_replica.get('share_server_id'), 'deleted': share_replica.get('deleted'), 'terminated_at': share_replica.get('terminated_at'), 'launched_at': share_replica.get('launched_at'), 'scheduled_at': share_replica.get('scheduled_at'), 'updated_at': share_replica.get('updated_at'), 'deleted_at': share_replica.get('deleted_at'), 'created_at': share_replica.get('created_at'), 'share_server': self._get_share_server(context, share_replica), 'access_rules_status': share_replica.get('access_rules_status'), # Share details 'user_id': share_replica.get('user_id'), 'project_id': share_replica.get('project_id'), 'size': share_replica.get('size'), 'display_name': share_replica.get('display_name'), 'display_description': share_replica.get('display_description'), 'snapshot_id': share_replica.get('snapshot_id'), 'share_proto': share_replica.get('share_proto'), 'share_type_id': share_replica.get('share_type_id'), 'is_public': share_replica.get('is_public'), 'share_group_id': share_replica.get('share_group_id'), 'source_share_group_snapshot_member_id': share_replica.get( 'source_share_group_snapshot_member_id'), 'availability_zone': share_replica.get('availability_zone'), } return share_replica_ref def _get_snapshot_instance_dict(self, context, snapshot_instance, snapshot=None): # TODO(gouthamr): remove method when the db layer returns primitives snapshot_instance_ref = { 'name': snapshot_instance.get('name'), 'share_id': snapshot_instance.get('share_id'), 'share_name': snapshot_instance.get('share_name'), 'status': snapshot_instance.get('status'), 'id': snapshot_instance.get('id'), 'deleted': snapshot_instance.get('deleted') or False, 'created_at': snapshot_instance.get('created_at'), 'share': snapshot_instance.get('share'), 'updated_at': snapshot_instance.get('updated_at'), 'share_instance_id': snapshot_instance.get('share_instance_id'), 'snapshot_id': snapshot_instance.get('snapshot_id'), 'progress': snapshot_instance.get('progress'), 'deleted_at': snapshot_instance.get('deleted_at'), 'provider_location': snapshot_instance.get('provider_location'), } if snapshot: snapshot_instance_ref.update({ 'size': snapshot.get('size'), }) return snapshot_instance_ref def snapshot_update_access(self, context, snapshot_instance_id): snapshot_instance = self.db.share_snapshot_instance_get( context, snapshot_instance_id, with_share_data=True) share_server = self._get_share_server( context, snapshot_instance['share_instance']) self.snapshot_access_helper.update_access_rules( context, snapshot_instance['id'], share_server=share_server) def _notify_about_share_usage(self, context, share, share_instance, event_suffix, extra_usage_info=None): share_utils.notify_about_share_usage( context, share, share_instance, event_suffix, extra_usage_info=extra_usage_info, host=self.host) @periodic_task.periodic_task( spacing=CONF.share_usage_size_update_interval, enabled=CONF.enable_gathering_share_usage_size) @utils.require_driver_initialized def update_share_usage_size(self, context): """"""Invokes driver to gather usage size of shares."""""" updated_share_instances = [] share_instances = self.db.share_instances_get_all_by_host( context, host=self.host, with_share_data=True) if share_instances: try: updated_share_instances = self.driver.update_share_usage_size( context, share_instances) except Exception: LOG.exception(""Gather share usage size failure."") for si in updated_share_instances: share_instance = self._get_share_instance(context, si['id']) share = self.db.share_get(context, share_instance['share_id']) self._notify_about_share_usage( context, share, share_instance, ""consumed.size"", extra_usage_info={'used_size': si['used_size'], 'gathered_at': si['gathered_at']}) ",,4337,0
openstack%2Fnova~master~Id0403f102b7af445bffb7182b748bdb958429256,openstack/nova,master,Id0403f102b7af445bffb7182b748bdb958429256,Move DHCP releasing to privsep.,MERGED,2018-12-10 22:43:19.000000000,2019-03-06 17:20:39.000000000,2019-03-06 05:00:15.000000000,"[{'_account_id': 4690}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-10 22:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/783c03b4aafde1edd520b29e927e86a024edbb6d', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 2, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d09ed08374caa61b0e9d31ad29c769a09e3e3e9', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 3, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bfb81b4dff5eb572ce8cd9e00f2a77134ce2816', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 4, 'created': '2019-02-05 04:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e42e3e6fb05a99710f591878c5bb7a5080324576', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 5, 'created': '2019-02-07 06:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d56a2c275a2c7e6b690e4470d1e3be97048f22a2', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 6, 'created': '2019-02-13 00:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce2a5f3e3060cde3a4337e2ddb534a03ddf46404', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 7, 'created': '2019-02-20 02:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32e8db28434de7ad547e34f2d35b7ab5749a419a', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 8, 'created': '2019-02-26 09:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69212bd089291d2f89fab9c661d2b0adce6337c5', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}, {'number': 9, 'created': '2019-03-05 22:35:50.000000000', 'files': ['nova/network/linux_net.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6b72eb204bc204c5c66b0aa4566a52c047cac963', 'message': 'Move DHCP releasing to privsep.\n\nChange-Id: Id0403f102b7af445bffb7182b748bdb958429256\n'}]",0,624230,6b72eb204bc204c5c66b0aa4566a52c047cac963,103,19,9,2271,,,0,"Move DHCP releasing to privsep.

Change-Id: Id0403f102b7af445bffb7182b748bdb958429256
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/624230/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/linux_net.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py']",3,783c03b4aafde1edd520b29e927e86a024edbb6d,my-own-personal-alternative-universe," mock.patch('nova.privsep.linux_net.dhcp_release', side_effect=processutils.ProcessExecutionError()), ) as (release_dhcp, _vif_get, privsep_dhcp_release): privsep_dhcp_release.assert_called_once_with( networks[1]['bridge'], fix_addr.address, 'DE:AD:BE:EF:00:00')"," mock.patch.object( utils, 'execute', side_effect=processutils.ProcessExecutionError()), ) as (release_dhcp, _vif_get, _execute): _execute.assert_called_once_with('dhcp_release', networks[1]['bridge'], fix_addr.address, 'DE:AD:BE:EF:00:00', run_as_root=True)",12,11
openstack%2Fopenstack-helm~master~I77e5acf3da31e211c444032f26d7625e51d8b0a9,openstack/openstack-helm,master,I77e5acf3da31e211c444032f26d7625e51d8b0a9,Ceilometer chart: update messaging_urls and cache server,MERGED,2019-03-01 16:23:59.000000000,2019-03-06 17:17:17.000000000,2019-03-06 17:17:17.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28435}]","[{'number': 1, 'created': '2019-03-01 16:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/147dac91109fd90d8a2d6fa8bbf66a5de9ab5ea6', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}, {'number': 2, 'created': '2019-03-05 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/92096baecf1fe38dcb16505d4bd2739f2e6c877d', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}, {'number': 3, 'created': '2019-03-06 04:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5efae56fac25d34ce254925bf4ad00005ae5a64d', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}, {'number': 4, 'created': '2019-03-06 06:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/99d732a98b7aedda2b14194232479d957ca4697b', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}, {'number': 5, 'created': '2019-03-06 14:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ac7673a5afc6ba92fb0d8f36a9bb797754315d26', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}, {'number': 6, 'created': '2019-03-06 15:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9e95c28e4aae43bd13378c5253bfd12b75b94d59', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}, {'number': 7, 'created': '2019-03-06 15:54:20.000000000', 'files': ['ceilometer/values.yaml', 'ceilometer/templates/configmap-etc.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/72b0d3c982d93000e011d3f7ffc5cfac5339a16a', 'message': ""Ceilometer chart: update messaging_urls and cache server\n\nCurrently, ceilometer is not listening to the notifications which\nsent from the openstack services as the messaging_urls isn't configured\nproperly. The commit updates the messaging_urls with the correct type\nand the default value.\n\nThe configuration for the cache server is also added. With the cache\nserver configured, ceilometer will not update the resource metadata\nthrough gnocchi client if the resource is not changed.\n\nChange-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9\nStory: 2005019\nTask: 29746\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n""}]",0,640426,72b0d3c982d93000e011d3f7ffc5cfac5339a16a,26,4,7,28435,,,0,"Ceilometer chart: update messaging_urls and cache server

Currently, ceilometer is not listening to the notifications which
sent from the openstack services as the messaging_urls isn't configured
properly. The commit updates the messaging_urls with the correct type
and the default value.

The configuration for the cache server is also added. With the cache
server configured, ceilometer will not update the resource metadata
through gnocchi client if the resource is not changed.

Change-Id: I77e5acf3da31e211c444032f26d7625e51d8b0a9
Story: 2005019
Task: 29746
Signed-off-by: Angie Wang <angie.wang@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/26/640426/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/values.yaml', 'ceilometer/templates/configmap-etc.yaml']",2,147dac91109fd90d8a2d6fa8bbf66a5de9ab5ea6,bp/support-docker-registry-with-authentication-turned-on,"{{- if empty .Values.conf.ceilometer.cache.memcache_servers -}} {{- $_ := tuple ""oslo_cache"" ""internal"" ""memcache"" . | include ""helm-toolkit.endpoints.host_and_port_endpoint_uri_lookup"" | set .Values.conf.ceilometer.cache ""memcache_servers"" -}} {{- end -}} ",,19,2
openstack%2Fkolla-ansible~master~I50c46c674134f9958ee4357f0f4eed5483af2214,openstack/kolla-ansible,master,I50c46c674134f9958ee4357f0f4eed5483af2214,Allow keystone services to use independent hostnames,MERGED,2018-12-18 18:37:44.000000000,2019-03-06 17:06:24.000000000,2019-03-06 17:06:24.000000000,"[{'_account_id': 10343}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 26285}]","[{'number': 1, 'created': '2018-12-18 18:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/89375dcff0ed1040fb07fd67bdd0ea8eb440169f', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 2, 'created': '2018-12-18 19:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5b1977bb69d4968ea5945084ca202f180dccea5e', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 3, 'created': '2018-12-18 19:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6b975e96a48d7b87327efa056975c0739dac4303', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 4, 'created': '2018-12-20 18:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/691271fe65ff05983bf2ce1cbcd45372b8fe11c8', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 5, 'created': '2018-12-26 16:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/81d7d3dc4d2e3145b564003f5131cc8c1db12edf', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 6, 'created': '2018-12-27 17:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/48f1fb933183efd2eeec2e3bb06dcedb4dd1d5ed', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 7, 'created': '2018-12-27 20:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9ba2f6fe044193682ffc3944200795b0861a263f', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}, {'number': 8, 'created': '2019-02-08 15:30:14.000000000', 'files': ['ansible/roles/keystone/templates/wsgi-keystone.conf.j2', 'ansible/group_vars/all.yml', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/keystone/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bece976b919b734d7d23ff169ec7a2df90e2b64a', 'message': 'Allow keystone services to use independent hostnames\n\nThis allows keystone service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* keystone_internal_fqdn\n* keystone_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds the following variables:\n\n* keystone_admin_listen_port\n* keystone_public_listen_port\n\nThese default to keystone_admin_port and keystone_public_port,\nrespectively, for backward compatibility.\n\nThese options allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I50c46c674134f9958ee4357f0f4eed5483af2214\nImplements: blueprint service-hostnames\n'}]",10,625985,bece976b919b734d7d23ff169ec7a2df90e2b64a,30,7,8,10343,,,0,"Allow keystone services to use independent hostnames

This allows keystone service endpoints to use custom hostnames, and adds the
following variables:

* keystone_internal_fqdn
* keystone_external_fqdn

These default to the old values of kolla_internal_fqdn or
kolla_external_fqdn.

This also adds the following variables:

* keystone_admin_listen_port
* keystone_public_listen_port

These default to keystone_admin_port and keystone_public_port,
respectively, for backward compatibility.

These options allow the user to differentiate between the port the
service listens on, and the port the service is reachable on. This is
useful for external load balancers which live on the same host as the
service itself.

Change-Id: I50c46c674134f9958ee4357f0f4eed5483af2214
Implements: blueprint service-hostnames
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/85/625985/8 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all.yml', 'ansible/roles/keystone/templates/wsgi-keystone.conf.j2', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/keystone/tasks/precheck.yml', 'ansible/roles/haproxy/tasks/precheck.yml']",5,89375dcff0ed1040fb07fd67bdd0ea8eb440169f,bp/service-hostnames," port: ""{{ keystone_admin_listen_port }}"" port: ""{{ keystone_public_listen_port }}"" port: ""{{ keystone_public_listen_port }}"""," port: ""{{ keystone_admin_port }}"" port: ""{{ keystone_public_port }}"" port: ""{{ keystone_public_port }}""",19,15
openstack%2Fkolla-ansible~master~I87d7387326b6eaa6adae1600b48d480319d10676,openstack/kolla-ansible,master,I87d7387326b6eaa6adae1600b48d480319d10676,Allow neutron services to use independent hostnames,MERGED,2018-12-18 16:52:58.000000000,2019-03-06 17:06:22.000000000,2019-03-06 17:06:22.000000000,"[{'_account_id': 10343}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2018-12-18 16:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/11caed37f0410d08808b12cd3defcbf989134cf7', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 2, 'created': '2018-12-18 19:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ab2038d43355935f6731deefb85a796442802143', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 3, 'created': '2018-12-18 19:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/749d20715207c5a383652259e8d0816b79d91f9d', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 4, 'created': '2018-12-20 18:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/85c7980ea9da602818a221800001e4b8553a8162', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 5, 'created': '2018-12-26 16:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c2d0abbcbf3782cc1f7c35d42b964f4a2176a617', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 6, 'created': '2018-12-27 17:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/aa21053f19ce91f1809d8532a4accf6aaeb75683', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 7, 'created': '2018-12-27 20:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/85a409c148cec540a17c26ab3a179ee86411b399', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}, {'number': 8, 'created': '2019-02-08 15:30:14.000000000', 'files': ['ansible/roles/neutron/tasks/precheck.yml', 'ansible/roles/nova-hyperv/templates/nova_hyperv.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/neutron/templates/neutron.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/roles/manila/templates/manila-share.conf.j2', 'ansible/roles/neutron/defaults/main.yml', 'ansible/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/255fff02b7de8dd5161f3dbd55ebddd211179246', 'message': 'Allow neutron services to use independent hostnames\n\nThis allows neutron service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* neutron_internal_fqdn\n* neutron_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a neutron_server_listen_port option, which defaults to\nneutron_server_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: I87d7387326b6eaa6adae1600b48d480319d10676\nImplements: blueprint service-hostnames\n'}]",2,625955,255fff02b7de8dd5161f3dbd55ebddd211179246,28,6,8,10343,,,0,"Allow neutron services to use independent hostnames

This allows neutron service endpoints to use custom hostnames, and adds the
following variables:

* neutron_internal_fqdn
* neutron_external_fqdn

These default to the old values of kolla_internal_fqdn or
kolla_external_fqdn.

This also adds a neutron_server_listen_port option, which defaults to
neutron_server_port for backward compatibility.

This option allow the user to differentiate between the port the
service listens on, and the port the service is reachable on. This is
useful for external load balancers which live on the same host as the
service itself.

Change-Id: I87d7387326b6eaa6adae1600b48d480319d10676
Implements: blueprint service-hostnames
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/55/625955/6 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/neutron/tasks/precheck.yml', 'ansible/roles/nova-hyperv/templates/nova_hyperv.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/neutron/templates/neutron.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/group_vars/all.yml', 'ansible/roles/manila/templates/manila-share.conf.j2', 'ansible/roles/neutron/defaults/main.yml']",8,11caed37f0410d08808b12cd3defcbf989134cf7,bp/service-hostnames," port: ""{{ neutron_server_listen_port }}"" port: ""{{ neutron_server_listen_port }}""neutron_internal_fqdn: ""{{ kolla_internal_fqdn }}"" neutron_external_fqdn: ""{{ kolla_external_fqdn }}"" neutron_admin_endpoint: ""{{ admin_protocol }}://{{ neutron_internal_fqdn }}:{{ neutron_server_port }}"" neutron_internal_endpoint: ""{{ internal_protocol }}://{{ neutron_internal_fqdn }}:{{ neutron_server_port }}"" neutron_public_endpoint: ""{{ public_protocol }}://{{ neutron_external_fqdn }}:{{ neutron_server_port }}"""," port: ""{{ neutron_server_port }}"" port: ""{{ neutron_server_port }}""neutron_admin_endpoint: ""{{ admin_protocol }}://{{ kolla_internal_fqdn }}:{{ neutron_server_port }}"" neutron_internal_endpoint: ""{{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ neutron_server_port }}"" neutron_public_endpoint: ""{{ public_protocol }}://{{ kolla_external_fqdn }}:{{ neutron_server_port }}""",15,11
openstack%2Foctavia~master~I9833d8fa403a72ab2eeccaec85af94826282ba4e,openstack/octavia,master,I9833d8fa403a72ab2eeccaec85af94826282ba4e,DNM: Testing bionic on legacy tempest,ABANDONED,2019-03-06 01:18:30.000000000,2019-03-06 17:03:32.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-06 01:18:30.000000000', 'files': ['octavia/opts.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/fa4e03fde405605ea8681b67f8a0f28fef688e08', 'message': 'DNM: Testing bionic on legacy tempest\n\nDepends-On: https://review.openstack.org/#/c/639096/\nChange-Id: I9833d8fa403a72ab2eeccaec85af94826282ba4e\n'}]",0,641182,fa4e03fde405605ea8681b67f8a0f28fef688e08,3,1,1,11628,,,0,"DNM: Testing bionic on legacy tempest

Depends-On: https://review.openstack.org/#/c/639096/
Change-Id: I9833d8fa403a72ab2eeccaec85af94826282ba4e
",git fetch https://review.opendev.org/openstack/octavia refs/changes/82/641182/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/opts.py'],1,fa4e03fde405605ea8681b67f8a0f28fef688e08,, add_auth_opts()," add_auth_opts(),",1,1
openstack%2Fneutron-lbaas~master~I5afafb08e42cc3e2b4eba0e706f1bf5a5d30c9bf,openstack/neutron-lbaas,master,I5afafb08e42cc3e2b4eba0e706f1bf5a5d30c9bf,DNM: Testing legacy tempest on bionic,ABANDONED,2019-03-06 01:19:20.000000000,2019-03-06 17:03:22.000000000,,"[{'_account_id': 9008}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 01:19:20.000000000', 'files': ['neutron_lbaas/opts.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/230840daa6737b085d444b173523ddfc0b29ae60', 'message': 'DNM: Testing legacy tempest on bionic\n\nDepends-On: https://review.openstack.org/#/c/639096/\nChange-Id: I5afafb08e42cc3e2b4eba0e706f1bf5a5d30c9bf\n'}]",0,641183,230840daa6737b085d444b173523ddfc0b29ae60,4,2,1,11628,,,0,"DNM: Testing legacy tempest on bionic

Depends-On: https://review.openstack.org/#/c/639096/
Change-Id: I5afafb08e42cc3e2b4eba0e706f1bf5a5d30c9bf
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/83/641183/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/opts.py'],1,230840daa6737b085d444b173523ddfc0b29ae60,," neutron_lbaas.drivers.haproxy.namespace_driver.OPTS,)", neutron_lbaas.drivers.haproxy.namespace_driver.OPTS),1,1
openstack%2Fopenstack-ansible-tests~master~Id15947401a7e6080f5303ca78067f91ecb2100bf,openstack/openstack-ansible-tests,master,Id15947401a7e6080f5303ca78067f91ecb2100bf,Add Manila logs to the test results,MERGED,2019-03-04 15:33:35.000000000,2019-03-06 17:01:25.000000000,2019-03-06 17:01:25.000000000,"[{'_account_id': 1004}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 15:33:35.000000000', 'files': ['test-log-collect.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/c00e3ec21de1724e6e6036230b07c74debfe12da', 'message': ""Add Manila logs to the test results\n\nAdd manila so it's easier to see what is happening on manila gate check.\n\nChange-Id: Id15947401a7e6080f5303ca78067f91ecb2100bf\n""}]",0,640784,c00e3ec21de1724e6e6036230b07c74debfe12da,7,3,1,13095,,,0,"Add Manila logs to the test results

Add manila so it's easier to see what is happening on manila gate check.

Change-Id: Id15947401a7e6080f5303ca78067f91ecb2100bf
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/84/640784/1 && git format-patch -1 --stdout FETCH_HEAD,['test-log-collect.sh'],1,c00e3ec21de1724e6e6036230b07c74debfe12da,, manila \,,1,0
openstack%2Fplacement~master~I5224776133afa6d9855c535af68f8d73575bad9b,openstack/placement,master,I5224776133afa6d9855c535af68f8d73575bad9b,Stop yelling the 1.11 and 1.25 microversion history at people,MERGED,2019-03-06 14:19:45.000000000,2019-03-06 16:59:49.000000000,2019-03-06 16:59:49.000000000,"[{'_account_id': 6873}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2019-03-06 14:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/adf2249bd07c848fb7aa9549d638345abeb36924', 'message': ""Stop yelling the 1.25 microversion history at people\n\nThe ``GET /allocation_candidates`` formatting in a title\nmakes the title extra yell-y in the docs so just drop that\nformatting.\n\nNote we don't do that same kind of formatting in other\ntitles like 1.20 and 1.31 so I'm not breaking with precedent\nor something we have to get all knifey about.\n\nChange-Id: I5224776133afa6d9855c535af68f8d73575bad9b\n""}, {'number': 2, 'created': '2019-03-06 14:25:51.000000000', 'files': ['placement/rest_api_version_history.rst'], 'web_link': 'https://opendev.org/openstack/placement/commit/9de5da48a314368bb25a370983ece675beef6b60', 'message': ""Stop yelling the 1.11 and 1.25 microversion history at people\n\nThe double back-tick formatting in a title makes the title extra\nloud in the docs so just drop that formatting.\n\nNote we don't do that same kind of formatting in other\ntitles like 1.20 and 1.31 so I'm not breaking with precedent\nor something we have to get all knifey about.\n\nChange-Id: I5224776133afa6d9855c535af68f8d73575bad9b\n""}]",2,641381,9de5da48a314368bb25a370983ece675beef6b60,12,6,2,6873,,,0,"Stop yelling the 1.11 and 1.25 microversion history at people

The double back-tick formatting in a title makes the title extra
loud in the docs so just drop that formatting.

Note we don't do that same kind of formatting in other
titles like 1.20 and 1.31 so I'm not breaking with precedent
or something we have to get all knifey about.

Change-Id: I5224776133afa6d9855c535af68f8d73575bad9b
",git fetch https://review.opendev.org/openstack/placement refs/changes/81/641381/1 && git format-patch -1 --stdout FETCH_HEAD,['placement/rest_api_version_history.rst'],1,adf2249bd07c848fb7aa9549d638345abeb36924,1.25-microversion-history-yelling,1.25 Granular resource requests to GET /allocation_candidates -------------------------------------------------------------,1.25 Granular resource requests to ``GET /allocation_candidates`` -----------------------------------------------------------------,2,2
openstack%2Fkolla-ansible~master~Icb91f728533e2db1908b23dabb0501cf9f8a2b75,openstack/kolla-ansible,master,Icb91f728533e2db1908b23dabb0501cf9f8a2b75,Allow glance services to use independent hostnames,MERGED,2018-12-18 16:52:58.000000000,2019-03-06 16:52:18.000000000,2019-03-06 16:52:18.000000000,"[{'_account_id': 10343}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2018-12-18 16:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/48a3d77617b8efff72174c929e1767342de7d26c', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nAllow glance listening ports to be different than endpoint\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 2, 'created': '2018-12-18 19:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d06b07febea8e761756c6d970725c47865342000', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nAllow glance listening ports to be different than endpoint\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 3, 'created': '2018-12-18 19:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8adb67abc40e091fae4952ef928ebeef95962a5a', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nAllow glance listening ports to be different than endpoint\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 4, 'created': '2018-12-20 18:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1830bb8f828735ea8b51f367697245715b1c693a', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nAllow glance listening ports to be different than endpoint\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 5, 'created': '2018-12-26 16:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6fe118f2340d5ae61f80fa5063c2208b76945e24', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nAllow glance listening ports to be different than endpoint\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 6, 'created': '2018-12-27 17:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0660193a83c9aec81e2947955c018cebc2844f01', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nAllow glance listening ports to be different than endpoint\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 7, 'created': '2018-12-27 20:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7d46cd3c89f585569cf5328982c161af3dbd3036', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}, {'number': 8, 'created': '2019-02-08 15:30:14.000000000', 'files': ['ansible/roles/nova-hyperv/templates/nova_hyperv.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/group_vars/all.yml', 'ansible/roles/cinder/templates/cinder.conf.j2', 'ansible/roles/glance/tasks/precheck.yml', 'ansible/roles/glance/templates/glance-api.conf.j2', 'ansible/roles/glance/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a819ef1215530c741e1baa800e746bde43878380', 'message': 'Allow glance services to use independent hostnames\n\nThis allows glance service endpoints to use custom hostnames, and adds the\nfollowing variables:\n\n* glance_internal_fqdn\n* glance_external_fqdn\n\nThese default to the old values of kolla_internal_fqdn or\nkolla_external_fqdn.\n\nThis also adds a glance_api_listen_port option, which defaults to\nglance_api_port for backward compatibility.\n\nThis option allow the user to differentiate between the port the\nservice listens on, and the port the service is reachable on. This is\nuseful for external load balancers which live on the same host as the\nservice itself.\n\nChange-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75\nImplements: blueprint service-hostnames\n'}]",9,625954,a819ef1215530c741e1baa800e746bde43878380,34,7,8,10343,,,0,"Allow glance services to use independent hostnames

This allows glance service endpoints to use custom hostnames, and adds the
following variables:

* glance_internal_fqdn
* glance_external_fqdn

These default to the old values of kolla_internal_fqdn or
kolla_external_fqdn.

This also adds a glance_api_listen_port option, which defaults to
glance_api_port for backward compatibility.

This option allow the user to differentiate between the port the
service listens on, and the port the service is reachable on. This is
useful for external load balancers which live on the same host as the
service itself.

Change-Id: Icb91f728533e2db1908b23dabb0501cf9f8a2b75
Implements: blueprint service-hostnames
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/54/625954/6 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/group_vars/all.yml', 'ansible/roles/glance/tasks/precheck.yml', 'ansible/roles/glance/templates/glance-api.conf.j2', 'ansible/roles/glance/defaults/main.yml']",5,48a3d77617b8efff72174c929e1767342de7d26c,bp/service-hostnames," port: ""{{ glance_api_listen_port }}"" port: ""{{ glance_api_listen_port }}""haproxy_members: ""{% for host in glance_api_hosts %}server {{ hostvars[host]['ansible_hostname'] }} {{ hostvars[host]['ansible_' + hostvars[host]['api_interface']]['ipv4']['address'] }}:{{ glance_api_listen_port }} check inter 2000 rise 2 fall 5;{% endfor %}""glance_internal_fqdn: ""{{ kolla_internal_fqdn }}"" glance_external_fqdn: ""{{ kolla_external_fqdn }}"" glance_admin_endpoint: ""{{ admin_protocol }}://{{ glance_internal_fqdn }}:{{ glance_api_port }}"" glance_internal_endpoint: ""{{ internal_protocol }}://{{ glance_internal_fqdn }}:{{ glance_api_port }}"" glance_public_endpoint: ""{{ public_protocol }}://{{ glance_external_fqdn }}:{{ glance_api_port }}"""," port: ""{{ glance_api_port }}"" port: ""{{ glance_api_port }}""haproxy_members: ""{% for host in glance_api_hosts %}server {{ hostvars[host]['ansible_hostname'] }} {{ hostvars[host]['ansible_' + hostvars[host]['api_interface']]['ipv4']['address'] }}:{{ glance_api_port }} check inter 2000 rise 2 fall 5;{% endfor %}""glance_admin_endpoint: ""{{ admin_protocol }}://{{ kolla_internal_fqdn }}:{{ glance_api_port }}"" glance_internal_endpoint: ""{{ internal_protocol }}://{{ kolla_internal_fqdn }}:{{ glance_api_port }}"" glance_public_endpoint: ""{{ public_protocol }}://{{ kolla_external_fqdn }}:{{ glance_api_port }}""",14,10
openstack%2Fopenstack-helm-infra~master~I8628ceb246e7c435a2ddd20bf1bcecd94db8ea26,openstack/openstack-helm-infra,master,I8628ceb246e7c435a2ddd20bf1bcecd94db8ea26,Implement Security Context for Memcached,MERGED,2019-02-28 21:58:16.000000000,2019-03-06 16:39:51.000000000,2019-03-06 16:39:51.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 24780}]","[{'number': 1, 'created': '2019-02-28 21:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8bcdfbf5a5c94709278b733b0e2c2555b06d1d93', 'message': 'Implement Security Context for Memcached\n\nImplement a pod security context for the following Memcached resources:\n - Memcached server deployment\n\nChange-Id: I8628ceb246e7c435a2ddd20bf1bcecd94db8ea26\n'}, {'number': 2, 'created': '2019-03-06 03:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b20641411286d930baa6412c8548c3f13d38e788', 'message': 'Implement Security Context for Memcached\n\nImplement a pod security context for the following Memcached resources:\n - Memcached server deployment\n\nChange-Id: I8628ceb246e7c435a2ddd20bf1bcecd94db8ea26\n'}, {'number': 3, 'created': '2019-03-06 06:35:11.000000000', 'files': ['memcached/values.yaml', 'memcached/templates/deployment.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8bbe8452c2525f26313fe0134cbcfe9f183838ab', 'message': 'Implement Security Context for Memcached\n\nImplement a pod security context for the following Memcached resources:\n - Memcached server deployment\n\nChange-Id: I8628ceb246e7c435a2ddd20bf1bcecd94db8ea26\n'}]",0,640201,8bbe8452c2525f26313fe0134cbcfe9f183838ab,18,9,3,22636,,,0,"Implement Security Context for Memcached

Implement a pod security context for the following Memcached resources:
 - Memcached server deployment

Change-Id: I8628ceb246e7c435a2ddd20bf1bcecd94db8ea26
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/01/640201/2 && git format-patch -1 --stdout FETCH_HEAD,"['memcached/values.yaml', 'memcached/templates/deployment.yaml']",2,8bcdfbf5a5c94709278b733b0e2c2555b06d1d93,infra-pod-sec-context,"{{ dict ""envAll"" $envAll ""application"" ""server"" | include ""helm-toolkit.snippets.kubernetes_pod_security_context"" | indent 6 }}", securityContext: readOnlyRootFilesystem: true,6,2
openstack%2Freleases~master~I52c4839475f50a56de6be95e3409f08870b2240d,openstack/releases,master,I52c4839475f50a56de6be95e3409f08870b2240d,Release Searchlight Stein-3,MERGED,2019-03-04 13:19:56.000000000,2019-03-06 16:38:45.000000000,2019-03-06 16:38:45.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27488}, {'_account_id': 29228}]","[{'number': 1, 'created': '2019-03-04 13:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b53d2ac7dd9d5b0547ac496db46e3c8d2f54a4bc', 'message': 'Release Searchlight Stein-3\n\nChange-Id: I52c4839475f50a56de6be95e3409f08870b2240d\nSigned-off-by: Trinh Nguyen <dangtrinhnt@gmail.com>\n'}, {'number': 2, 'created': '2019-03-04 13:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/37ec2ea905588a259370a956e42adcb380e794d3', 'message': 'Release Searchlight Stein-3\n\nSearchlight team releases at Stein-3 milestone:\n\n- searchlight: 6.0.0.0b3\n- searchlight-ui: 6.0.0.0b3\n- python-searchlightclient: 1.5.0\n\nThe major changes in this release are:\n\n- Add python3.7 unit tests\n- Searchlight vision reflection\n- Improve functional tests by tweaking Elasticsearch setup\n\nChange-Id: I52c4839475f50a56de6be95e3409f08870b2240d\nSigned-off-by: Trinh Nguyen <dangtrinhnt@gmail.com>\n'}, {'number': 3, 'created': '2019-03-04 14:59:00.000000000', 'files': ['deliverables/stein/searchlight-ui.yaml', 'deliverables/stein/searchlight.yaml', 'deliverables/stein/python-searchlightclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/9540b917cfa8fade2d08727628483b0cf1deb0e3', 'message': 'Release Searchlight Stein-3\n\nSearchlight team releases at Stein-3 milestone:\n\n- searchlight: 6.0.0.0b3\n- searchlight-ui: 6.0.0.0b3\n- python-searchlightclient: 1.5.0\n\nThe major changes in this release are:\n\n- Add python3.7 unit tests\n- Searchlight vision reflection\n- Improve functional tests by tweaking Elasticsearch setup\n\nChange-Id: I52c4839475f50a56de6be95e3409f08870b2240d\nSigned-off-by: Trinh Nguyen <dangtrinhnt@gmail.com>\n'}]",0,640759,9540b917cfa8fade2d08727628483b0cf1deb0e3,11,6,3,27068,,,0,"Release Searchlight Stein-3

Searchlight team releases at Stein-3 milestone:

- searchlight: 6.0.0.0b3
- searchlight-ui: 6.0.0.0b3
- python-searchlightclient: 1.5.0

The major changes in this release are:

- Add python3.7 unit tests
- Searchlight vision reflection
- Improve functional tests by tweaking Elasticsearch setup

Change-Id: I52c4839475f50a56de6be95e3409f08870b2240d
Signed-off-by: Trinh Nguyen <dangtrinhnt@gmail.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/59/640759/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/stein/searchlight-ui.yaml', 'deliverables/stein/searchlight.yaml', 'deliverables/stein/python-searchlightclient.yaml']",3,b53d2ac7dd9d5b0547ac496db46e3c8d2f54a4bc,, - projects: - hash: Iebf49655274f9869cd53d1f70ef4be474aaaa866 repo: openstack/python-searchlightclient tarball-base: python-searchlightclient version: 1.5.0,,13,0
openstack%2Freleases~master~Ic63f62c97bec94ae5de3848d480a75aefa8e621b,openstack/releases,master,Ic63f62c97bec94ae5de3848d480a75aefa8e621b,Release magnum client 2.12.0,MERGED,2019-03-04 02:07:56.000000000,2019-03-06 16:34:08.000000000,2019-03-06 16:34:08.000000000,"[{'_account_id': 308}, {'_account_id': 6484}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 17068}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 02:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/436df27e8fc06f50bec691dc905084e59edd2051', 'message': 'Release magnum client 2.12.0\n\nChange-Id: Ic63f62c97bec94ae5de3848d480a75aefa8e621b\n'}, {'number': 2, 'created': '2019-03-04 17:12:03.000000000', 'files': ['deliverables/stein/python-magnumclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/723a181b66f6bf142c4fe5aa0b38b617d70fa284', 'message': 'Release magnum client 2.12.0\n\nChange-Id: Ic63f62c97bec94ae5de3848d480a75aefa8e621b\n'}]",0,640660,723a181b66f6bf142c4fe5aa0b38b617d70fa284,16,7,2,6484,,,0,"Release magnum client 2.12.0

Change-Id: Ic63f62c97bec94ae5de3848d480a75aefa8e621b
",git fetch https://review.opendev.org/openstack/releases refs/changes/60/640660/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/python-magnumclient.yaml'],1,436df27e8fc06f50bec691dc905084e59edd2051,magnumclient-2.12, - hash: 37e602d160632a386c2960ec8777bfc65642a9a9 version: 2.12.0, - hash: d41daca59bed255ef7c589fc62cab5afa001eb25 version: 2.11.0,2,2
openstack%2Fopenstack-helm-infra~master~Ib34ea48abf836ae52b909b30fdb8275d80a3c559,openstack/openstack-helm-infra,master,Ib34ea48abf836ae52b909b30fdb8275d80a3c559,(postgresql) Add Helm test,MERGED,2019-02-22 23:00:15.000000000,2019-03-06 16:32:01.000000000,2019-03-06 16:32:01.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-02-22 23:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/886567815129c21a7d432f95d0ca42d234c1b99c', 'message': '(postgresql) Add Helm test\n\n- Add a Helm test for testing DDL and DML for Postgres\n\nChange-Id: Ib34ea48abf836ae52b909b30fdb8275d80a3c559\n'}, {'number': 2, 'created': '2019-03-04 16:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f1927fb0fafce90760994753e8986015bba1f43a', 'message': '(postgresql) Add Helm test\n\n- Add a Helm test for testing DDL and DML for Postgres\n\nChange-Id: Ib34ea48abf836ae52b909b30fdb8275d80a3c559\n'}, {'number': 3, 'created': '2019-03-06 06:36:51.000000000', 'files': ['postgresql/templates/configmap-bin.yaml', 'postgresql/templates/pod-test.yaml', 'postgresql/templates/secret-admin.yaml', 'postgresql/templates/bin/_db_test.sh.tpl', 'postgresql/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/43a93e2cbdb4e829c09fbfe4086ab14cce9f199e', 'message': '(postgresql) Add Helm test\n\n- Add a Helm test for testing DDL and DML for Postgres\n\nChange-Id: Ib34ea48abf836ae52b909b30fdb8275d80a3c559\n'}]",0,638781,43a93e2cbdb4e829c09fbfe4086ab14cce9f199e,16,4,3,26449,,,0,"(postgresql) Add Helm test

- Add a Helm test for testing DDL and DML for Postgres

Change-Id: Ib34ea48abf836ae52b909b30fdb8275d80a3c559
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/81/638781/2 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/templates/configmap-bin.yaml', 'postgresql/templates/pod-test.yaml', 'postgresql/templates/secret-admin.yaml', 'postgresql/templates/bin/_db_test.sh.tpl', 'postgresql/values.yaml']",5,886567815129c21a7d432f95d0ca42d234c1b99c,postgres_pw_rotation," test: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" test: node_selectory_key: openstack-control-plane node_selector_value: enabled tests: services: - endpoint: internal service: postgresql",,175,0
openstack%2Fkolla~master~I160f79cc57f54ec3eac857c5babd1a6e2656d228,openstack/kolla,master,I160f79cc57f54ec3eac857c5babd1a6e2656d228,debian/ubuntu: make use of Python3 based packages,MERGED,2018-12-14 16:23:08.000000000,2019-03-06 16:28:00.000000000,2019-03-06 16:28:00.000000000,"[{'_account_id': 8871}, {'_account_id': 14826}, {'_account_id': 16282}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 26768}]","[{'number': 1, 'created': '2018-12-14 16:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/08c1e3c693f245b5d12a567628e06c5fd5275ea6', 'message': 'ubuntu: Update to Stein UCA\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 2, 'created': '2018-12-18 18:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3ad05bf6a99de506d812cd296117713f42a185a8', 'message': 'WIP: ubuntu: Update to Stein UCA\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 3, 'created': '2018-12-18 19:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/965c2710d33797de77e57c51b44a5dba0cf0f614', 'message': 'WIP: ubuntu: Update to Stein UCA\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 4, 'created': '2018-12-19 21:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/458c4c055be4eb035717745810ac87d4642e686c', 'message': 'WIP: ubuntu: Update to Stein UCA\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 5, 'created': '2018-12-20 08:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cd00d7bb931b28a8e2c7e056077c478354d6ec04', 'message': 'WIP: ubuntu: Update to Stein UCA\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 6, 'created': '2018-12-20 14:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8ace5398fc68a1584250ca785f850bedb820463d', 'message': 'WIP: ubuntu: update to Stein UCA\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nCo-Authored-By: Marcin Juszkiewicz <marcin.juszkiewicz@linaro.org>\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 7, 'created': '2019-01-05 11:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7560381ac65eb1b0f60d0cbb345befabf6ae7b3f', 'message': 'ubuntu: update to Stein UCA\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nCo-Authored-By: Marcin Juszkiewicz <marcin.juszkiewicz@linaro.org>\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n'}, {'number': 8, 'created': '2019-01-09 09:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fb5b31c4589795a2c2acf7fc6b89349b56bf0155', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 9, 'created': '2019-01-24 13:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c01b86143ce8f7668aabdbbd0aed612bcb881c0d', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 10, 'created': '2019-02-22 10:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bd9aaeadb736de4ac09db8ac965278f822e7dc8c', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 11, 'created': '2019-02-22 15:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/786b0aeab6ec57d494109aaf9c245087f5c4e4ea', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 12, 'created': '2019-02-22 15:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cc93d537557cdf881d770c9b1971b4e03d6a7cc2', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 13, 'created': '2019-02-27 13:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cb4345b4ad9384ef404427fd30ee0cad09c5854d', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 14, 'created': '2019-02-28 11:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/31d8396c7a49e8ce75e1a3517f01789b9282eaef', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 15, 'created': '2019-02-28 11:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/85d1257764460ac3e13da55d4d3d123ba9e73c6a', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}, {'number': 16, 'created': '2019-02-28 12:06:52.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2', 'docker/neutron/neutron-metadata-agent-ovn/Dockerfile.j2', 'docker/neutron/neutron-server-opendaylight/Dockerfile.j2', 'docker/macros.j2', 'docker/barbican/barbican-api/Dockerfile.j2', 'docker/base/sources.list.ubuntu.aarch64', 'docker/base/sources.list.ubuntu', 'docker/horizon/Dockerfile.j2', 'docker/placement/placement-api/Dockerfile.j2', 'kolla/image/build.py', 'docker/neutron/neutron-lbaas-agent/Dockerfile.j2', 'docker/aodh/aodh-base/Dockerfile.j2', 'docker/ovn/ovn-base/Dockerfile.j2', 'docker/neutron/neutron-server-ovn/Dockerfile.j2', 'docker/cinder/cinder-api/Dockerfile.j2', 'docker/keystone/keystone-base/Dockerfile.j2', 'docker/neutron/neutron-server/Dockerfile.j2', 'docker/neutron/neutron-base/Dockerfile.j2', 'docker/base/sources.list.ubuntu.ppc64le', 'docker/ceilometer/ceilometer-base/Dockerfile.j2', 'docker/zaqar/zaqar-base/Dockerfile.j2', 'docker/gnocchi/gnocchi-base/Dockerfile.j2', 'docker/ironic/ironic-conductor/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/43b74ccc157c0b50138c3785ed91dab504895571', 'message': ""debian/ubuntu: make use of Python3 based packages\n\nBoth Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack\npackages to Python 3.\n\nNote that Debian 'buster' is not released yet and contains Rocky\npackages. Stein ones will be available later.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228\n""}]",22,625298,43b74ccc157c0b50138c3785ed91dab504895571,61,8,16,10135,,,0,"debian/ubuntu: make use of Python3 based packages

Both Ubuntu Stein UCA and Debian 'buster' migrated their OpenStack
packages to Python 3.

Note that Debian 'buster' is not released yet and contains Rocky
packages. Stein ones will be available later.

Co-Authored-By: Lee Yarwood <lyarwood@redhat.com>
Co-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>

Change-Id: I160f79cc57f54ec3eac857c5babd1a6e2656d228
",git fetch https://review.opendev.org/openstack/kolla refs/changes/98/625298/16 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/sources.list.ubuntu.aarch64', 'docker/base/sources.list.ubuntu.ppc64le', 'docker/base/sources.list.ubuntu']",3,08c1e3c693f245b5d12a567628e06c5fd5275ea6,625298,deb http://ubuntu-cloud.archive.canonical.com/ubuntu bionic-updates/stein main,deb http://ubuntu-cloud.archive.canonical.com/ubuntu bionic-updates/rocky main,3,3
openstack%2Fnova~master~I4a64c212f1e37586db06972e5811a0fab87bab9d,openstack/nova,master,I4a64c212f1e37586db06972e5811a0fab87bab9d,Move set_vf_interface_vlan to be with its only caller.,MERGED,2018-12-10 22:43:19.000000000,2019-03-06 16:26:19.000000000,2019-03-06 04:59:41.000000000,"[{'_account_id': 4690}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-10 22:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd185e2f6165e4b5802bc2ba3ad29530c422493e', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 2, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a28e357e4517676e3b251da6ddefcd4ad29c6c31', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 3, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99e0480eb8a8d1ddb5c838612fd9e0ea3de6cb76', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 4, 'created': '2019-02-05 04:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e84f9af9457c0fb83d48ea2a56f7e37020036127', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 5, 'created': '2019-02-07 06:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/162ff411f4e42f21f62466a7cb51ebbcdc362935', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 6, 'created': '2019-02-13 00:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38661c3c9a575cd403fc321b65905f5249a4f900', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 7, 'created': '2019-02-20 02:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e12c81f20008821511eb323cb48c32391be40c3', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 8, 'created': '2019-02-26 09:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc8eb58834bbead17ab1f2708e8a2e737c63eb43', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}, {'number': 9, 'created': '2019-03-05 22:35:50.000000000', 'files': ['nova/virt/libvirt/vif.py', 'nova/network/linux_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4e26f709340ede9ba3da63b9228c4687856991cf', 'message': 'Move set_vf_interface_vlan to be with its only caller.\n\nAnd then remove the now empty linux_utils module from nova.network.\n\nChange-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d\n'}]",0,624229,4e26f709340ede9ba3da63b9228c4687856991cf,108,18,9,2271,,,0,"Move set_vf_interface_vlan to be with its only caller.

And then remove the now empty linux_utils module from nova.network.

Change-Id: I4a64c212f1e37586db06972e5811a0fab87bab9d
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/624229/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/vif.py', 'nova/network/linux_net.py', 'nova/network/linux_utils.py']",3,dd185e2f6165e4b5802bc2ba3ad29530c422493e,my-own-personal-alternative-universe,,"# Copyright (c) 2011 X.commerce, a business unit of eBay Inc. # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Utility methods for linux networking."""""" from oslo_log import log as logging from nova.pci import utils as pci_utils import nova.privsep.linux_net LOG = logging.getLogger(__name__) def set_vf_interface_vlan(pci_addr, mac_addr, vlan=0): pf_ifname = pci_utils.get_ifname_by_pci_address(pci_addr, pf_interface=True) vf_ifname = pci_utils.get_ifname_by_pci_address(pci_addr) vf_num = pci_utils.get_vf_num_by_pci_address(pci_addr) nova.privsep.linux_net.set_device_macaddr_and_vlan( pf_ifname, vf_num, mac_addr, vlan) # Bring up/down the VF's interface # TODO(edand): The mac is assigned as a workaround for the following issue # https://bugzilla.redhat.com/show_bug.cgi?id=1372944 # once resolved it will be removed port_state = 'up' if vlan > 0 else 'down' nova.privsep.linux_net.set_device_macaddr(vf_ifname, mac_addr, port_state=port_state) ",22,49
openstack%2Fnetworking-ovn~master~I2078b1864e8aa0871d22a7d0ab274b3b549198a0,openstack/networking-ovn,master,I2078b1864e8aa0871d22a7d0ab274b3b549198a0,Trivial: Fix typo in the zuul template name,MERGED,2019-03-06 11:09:56.000000000,2019-03-06 16:16:51.000000000,2019-03-06 16:16:51.000000000,"[{'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-03-06 11:09:56.000000000', 'files': ['zuul.d/networking-ovn-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/92985724dc8e41021ff196413a5cfb81ca8f17cd', 'message': 'Trivial: Fix typo in the zuul template name\n\nThis patch renames the zuul.d/networkin-ovn-jobs.yaml file (it\'s missing a\n""g"" from networking) to zuul.d/networking-ovn-jobs.yaml.\n\nIt\'s trivial but the typo bothers me every time I have to update that\nfile :D\n\nChange-Id: I2078b1864e8aa0871d22a7d0ab274b3b549198a0\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",0,641322,92985724dc8e41021ff196413a5cfb81ca8f17cd,6,2,1,6773,,,0,"Trivial: Fix typo in the zuul template name

This patch renames the zuul.d/networkin-ovn-jobs.yaml file (it's missing a
""g"" from networking) to zuul.d/networking-ovn-jobs.yaml.

It's trivial but the typo bothers me every time I have to update that
file :D

Change-Id: I2078b1864e8aa0871d22a7d0ab274b3b549198a0
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/22/641322/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/networking-ovn-jobs.yaml'],1,92985724dc8e41021ff196413a5cfb81ca8f17cd,typo-zuul-filename,,,0,0
openstack%2Fansible-role-thales-hsm~master~Ib5926776aafbb7615ea8d22386fc33c520e29506,openstack/ansible-role-thales-hsm,master,Ib5926776aafbb7615ea8d22386fc33c520e29506,Add rfs sync to get initial keys,MERGED,2019-03-05 19:26:42.000000000,2019-03-06 16:09:41.000000000,2019-03-06 16:09:41.000000000,"[{'_account_id': 7973}, {'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 19:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-thales-hsm/commit/7a32265b082dcfa57ef9d8c99c332d123bad87bc', 'message': 'Add rfs sync to get initial keys\n\nAfter we set up synchronization with the RFS server, we should\nimmediately do a sync to make sure the local keystore matches\nthe RFS server.\n\nChange-Id: Ib5926776aafbb7615ea8d22386fc33c520e29506\n'}, {'number': 2, 'created': '2019-03-06 15:36:39.000000000', 'files': ['tasks/client.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-role-thales-hsm/commit/08b5efaa7b083c610bb55c4fb64a87455b3bd9eb', 'message': 'Add rfs sync to get initial keys\n\nAfter we set up synchronization with the RFS server, we should\nimmediately do a sync to make sure the local keystore matches\nthe RFS server.\n\nChange-Id: Ib5926776aafbb7615ea8d22386fc33c520e29506\n'}]",0,641106,08b5efaa7b083c610bb55c4fb64a87455b3bd9eb,8,3,2,9914,,,0,"Add rfs sync to get initial keys

After we set up synchronization with the RFS server, we should
immediately do a sync to make sure the local keystore matches
the RFS server.

Change-Id: Ib5926776aafbb7615ea8d22386fc33c520e29506
",git fetch https://review.opendev.org/openstack/ansible-role-thales-hsm refs/changes/06/641106/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/client.yaml'],1,7a32265b082dcfa57ef9d8c99c332d123bad87bc,fix_sync, - name: get keys from rfs server command: /opt/nfast/bin/rfs-sync --update,,3,0
openstack%2Frpm-packaging~stable%2Frocky~Ifa49e5ca21ee279a0569c5e11836113dfd16131e,openstack/rpm-packaging,stable/rocky,Ifa49e5ca21ee279a0569c5e11836113dfd16131e,heat-agents: Add initial spec template,MERGED,2019-03-06 07:44:53.000000000,2019-03-06 15:58:53.000000000,2019-03-06 15:58:53.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 07:44:53.000000000', 'files': ['openstack/heat-agents/heat-agents.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ac5dd704a60c94de11c5805ae68f9735ecbecca5', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nDepends-On: https://review.openstack.org/#/c/640832/\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n(cherry picked from commit 1a4b8beaea471042ed833648eb0fa52e826f6237)\n'}]",0,641265,ac5dd704a60c94de11c5805ae68f9735ecbecca5,12,5,1,7102,,,0,"heat-agents: Add initial spec template

Based on the work from
https://github.com/rdo-packages/heat-agents-distgit with some
adjustments.

Depends-On: https://review.openstack.org/#/c/640832/
Change-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e
(cherry picked from commit 1a4b8beaea471042ed833648eb0fa52e826f6237)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/65/641265/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/heat-agents/heat-agents.spec.j2'],1,ac5dd704a60c94de11c5805ae68f9735ecbecca5,640721-stable/rocky,{% set pypi_name = 'heat-agents' %} {% set upstream_version = upstream_version('1.7.0') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: OpenStack Heat agents License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://git.openstack.org/cgit/openstack/heat-agents Source0: {{ source }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('os-apply-config') }} BuildRequires: {{ py2pkg('os-refresh-config') }} BuildRequires: {{ py2pkg('pbr') }} BuildArch: noarch %description Heat Agents are python hooks for deploying software configurations using heat. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %install # Use os-apply-config to bootstrap /etc/os-collect-config.conf # from heat boot data install -p -D -m 755 heat-config/os-refresh-config/configure.d/20-os-apply-config %{buildroot}%{_libexecdir}/os-refresh-config/configure.d/20-os-apply-config install -p -D -m 600 heat-config/os-apply-config/%{_sysconfdir}/os-collect-config.conf %{buildroot}%{_libexecdir}/os-apply-config/templates/%{_sysconfdir}/os-collect-config.conf # utilities which can be run by deployment scripts install -p -D -m 755 heat-config/bin/heat-config-notify %{buildroot}/%{_bindir}/heat-config-notify install -p -D -m 755 heat-config/bin/heat-config-rebuild-deployed %{buildroot}/%{_bindir}/heat-config-rebuild-deployed # os-refresh-config script to run heat deployment resources install -p -D -m 600 heat-config/os-apply-config/%{_localstatedir}/run/heat-config/heat-config %{buildroot}%{_libexecdir}/os-apply-config/templates/run/heat-config/heat-config install -p -D -m 755 heat-config/os-refresh-config/configure.d/55-heat-config %{buildroot}%{_libexecdir}/os-refresh-config/configure.d/55-heat-config # hook to perform configuration with scripts install -p -D -m 755 heat-config-script/install.d/hook-script.py %{buildroot}%{_libexecdir}/heat-config/hooks/script # hook to perform configuration with puppet install -p -D -m 755 heat-config-puppet/install.d/hook-puppet.py %{buildroot}%{_libexecdir}/heat-config/hooks/puppet # hook to perform configuration with ansible install -p -D -m 755 heat-config-ansible/install.d/hook-ansible.py %{buildroot}%{_libexecdir}/heat-config/hooks/ansible # hook to perform configuration with os-apply-config install -p -D -m 755 heat-config-apply-config/install.d/hook-apply-config.py %{buildroot}%{_libexecdir}/heat-config/hooks/apply-config # hook to perform configuration with hiera install -p -D -m 755 heat-config-hiera/install.d/hook-hiera.py %{buildroot}%{_libexecdir}/heat-config/hooks/hiera # hook to perform configuration with json-file install -p -D -m 755 heat-config-json-file/install.d/hook-json-file.py %{buildroot}%{_libexecdir}/heat-config/hooks/json-file # hook to perform configuration with docker commands install -p -D -m 755 heat-config-docker-cmd/os-refresh-config/configure.d/50-heat-config-docker-cmd %{buildroot}%{_libexecdir}/os-refresh-config/configure.d/50-heat-config-docker-cmd install -p -D -m 755 heat-config-docker-cmd/install.d/hook-docker-cmd.py %{buildroot}%{_libexecdir}/heat-config/hooks/docker-cmd %package -n python-heat-agent Summary: Agent for performing Heat software deployments Requires: {{ py2pkg('dib-utils') }} Requires: {{ py2pkg('heat-cfntools') }} Requires: {{ py2pkg('python-heatclient') }} Requires: {{ py2pkg('os-apply-config') }} Requires: {{ py2pkg('os-collect-config') }} Requires: {{ py2pkg('os-refresh-config') }} Requires: {{ py2pkg('requests') }} Requires: {{ py2pkg('python-zaqarclient') }} %description -n python-heat-agent Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform script based configuration tasks. %package -n python-heat-agent-puppet Summary: Agent for performing Puppet based Heat software deployments Requires: puppet Requires: python-heat-agent %description -n python-heat-agent-puppet Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform puppet based configuration tasks. %package -n python-heat-agent-ansible Summary: Agent for performing Ansible based Heat software deployments Requires: {{ py2pkg('ansible') }} Requires: python-heat-agent %description -n python-heat-agent-ansible Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform ansible based configuration tasks. %package -n python-heat-agent-apply-config Summary: Agent for performing os-apply-config based Heat software deployments Requires: python-heat-agent Requires: {{ py2pkg('os-apply-config') }} %description -n python-heat-agent-apply-config Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform os-apply-config based configuration tasks. %package -n python-heat-agent-hiera Summary: Agent for performing hiera based Heat software deployments Requires: python-heat-agent %description -n python-heat-agent-hiera Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform hiera based configuration tasks. %package -n python-heat-agent-json-file Summary: Agent for performing json-file based Heat software deployments Requires: python-heat-agent %description -n python-heat-agent-json-file Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform json-file based configuration tasks. %package -n python-heat-agent-docker-cmd Summary: Agent for performing Docker based Heat software deployments Requires: python-heat-agent Requires: {{ py2pkg('paunch') }} %description -n python-heat-agent-docker-cmd Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform docker based configuration tasks. %files %license LICENSE %files -n python-heat-agent %license LICENSE %dir %{_libexecdir}/os-refresh-config/configure.d/ %dir %{_libexecdir}/os-apply-config/templates/run/heat-config %{_bindir}/heat-config-notify %{_bindir}/heat-config-rebuild-deployed %dir %{_libexecdir}/os-apply-config/templates/%{_sysconfdir}/ %dir %{_libexecdir}/os-apply-config/templates/run/ %{_libexecdir}/os-apply-config/templates/%{_sysconfdir}/os-collect-config.conf %{_libexecdir}/os-apply-config/templates/run/heat-config/heat-config %{_libexecdir}/os-refresh-config/configure.d/20-os-apply-config %{_libexecdir}/os-refresh-config/configure.d/55-heat-config %dir %{_libexecdir}/heat-config %dir %{_libexecdir}/heat-config/hooks %{_libexecdir}/heat-config/hooks/script %files -n python-heat-agent-puppet %license LICENSE %{_libexecdir}/heat-config/hooks/puppet %files -n python-heat-agent-ansible %{_libexecdir}/heat-config/hooks/ansible %files -n python-heat-agent-apply-config %{_libexecdir}/heat-config/hooks/apply-config %files -n python-heat-agent-hiera %{_libexecdir}/heat-config/hooks/hiera %files -n python-heat-agent-json-file %{_libexecdir}/heat-config/hooks/json-file %files -n python-heat-agent-docker-cmd %{_libexecdir}/heat-config/hooks/docker-cmd %{_libexecdir}/os-refresh-config/configure.d/50-heat-config-docker-cmd %changelog ,,185,0
openstack%2Fhorizon~stable%2Fpike~I750637e3214ad46a8b29e1ad565870cdcb827fe1,openstack/horizon,stable/pike,I750637e3214ad46a8b29e1ad565870cdcb827fe1,"NaNJSONEncoder should be used in api ""cinder/tenantabsolutelimits""",MERGED,2017-11-30 16:09:18.000000000,2019-03-06 15:55:27.000000000,2017-12-14 03:51:25.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 11885}, {'_account_id': 16628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-30 16:09:18.000000000', 'files': ['openstack_dashboard/api/rest/cinder.py', 'openstack_dashboard/test/api_tests/cinder_rest_tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2cda101cf9cea1684fa6be2b1929ac758708d0cb', 'message': 'NaNJSONEncoder should be used in api ""cinder/tenantabsolutelimits""\n\nIn api ""cinder/tenantabsolutelimits"", result maybe contains Infinity values,\nbut Infinity values are not supported by JSON standard, so NaNJSONEncoder is\nneeded here.\n\nChange-Id: I750637e3214ad46a8b29e1ad565870cdcb827fe1\nCloses-bug: #1714417\n(cherry picked from commit de37fc1024a2e02cb9ec0f29a6dbd218474072df)\n'}]",0,524229,2cda101cf9cea1684fa6be2b1929ac758708d0cb,10,5,1,819,,,0,"NaNJSONEncoder should be used in api ""cinder/tenantabsolutelimits""

In api ""cinder/tenantabsolutelimits"", result maybe contains Infinity values,
but Infinity values are not supported by JSON standard, so NaNJSONEncoder is
needed here.

Change-Id: I750637e3214ad46a8b29e1ad565870cdcb827fe1
Closes-bug: #1714417
(cherry picked from commit de37fc1024a2e02cb9ec0f29a6dbd218474072df)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/29/524229/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/rest/cinder.py', 'openstack_dashboard/test/api_tests/cinder_rest_tests.py']",2,2cda101cf9cea1684fa6be2b1929ac758708d0cb,bug/1714417-stable/pike," {'id': 'one', 'val': float('inf')} response_as_json = json.loads(response.content.decode('utf-8')) self.assertEqual(response_as_json['id'], 'one') self.assertEqual(response_as_json['val'], 1e+999)"," {'id': 'one'} self.assertEqual(response.content.decode(""utf-8""), '{""id"": ""one""}')",6,3
openstack%2Fcharm-keystone~master~I20ac87956a7d0cdb49012c12a194e0207eb603b9,openstack/charm-keystone,master,I20ac87956a7d0cdb49012c12a194e0207eb603b9,Configure stestr directly,MERGED,2019-03-06 14:46:49.000000000,2019-03-06 15:50:57.000000000,2019-03-06 15:50:57.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 14:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/fb000f1f6146660956c4a73cd52c6af3ee09186a', 'message': 'Configure stestr directly\n\nChange-Id: I20ac87956a7d0cdb49012c12a194e0207eb603b9\n'}, {'number': 2, 'created': '2019-03-06 14:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/c040dbbc241eb730901d085900240001eb15c9ee', 'message': 'Configure stestr directly\n\nChange-Id: I20ac87956a7d0cdb49012c12a194e0207eb603b9\n'}, {'number': 3, 'created': '2019-03-06 15:06:27.000000000', 'files': ['test-requirements.txt', '.testr.conf', 'tox.ini', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/d1e3a7845dc97a634fc419d15e1692858c04589e', 'message': 'Configure stestr directly\n\nChange-Id: I20ac87956a7d0cdb49012c12a194e0207eb603b9\n'}]",0,641402,d1e3a7845dc97a634fc419d15e1692858c04589e,10,3,3,20634,,,0,"Configure stestr directly

Change-Id: I20ac87956a7d0cdb49012c12a194e0207eb603b9
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/02/641402/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', '.stestr.conf']",2,fb000f1f6146660956c4a73cd52c6af3ee09186a,fix-stestr,[DEFAULT] test_path=./unit_tests top_dir=./ ,,5,2
openstack%2Fcharm-ceph-osd~master~If015f76a839733e1876214c002ec2c9c75f2e12a,openstack/charm-ceph-osd,master,If015f76a839733e1876214c002ec2c9c75f2e12a,Configure stestr directly,MERGED,2019-03-06 12:41:24.000000000,2019-03-06 15:49:57.000000000,2019-03-06 15:49:57.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 12:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/13e6d72cb77e98ba81c2c77ed7fb813852aa1524', 'message': 'Reconfigure tox target\n\nChange-Id: If015f76a839733e1876214c002ec2c9c75f2e12a\n'}, {'number': 2, 'created': '2019-03-06 13:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/ee035526f46ddfdad37ee3609f884fa682fe3c60', 'message': 'Reconfigure tox target\n\nChange-Id: If015f76a839733e1876214c002ec2c9c75f2e12a\n'}, {'number': 3, 'created': '2019-03-06 14:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/0b47ab00959175ab85ddc2ba16f47d00e49ec971', 'message': 'Reconfigure tox target\n\nChange-Id: If015f76a839733e1876214c002ec2c9c75f2e12a\n'}, {'number': 4, 'created': '2019-03-06 15:06:06.000000000', 'files': ['test-requirements.txt', '.testr.conf', 'tox.ini', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/59dcfc4d0658b8566c3ca6040e8912a576a8a35f', 'message': 'Configure stestr directly\n\nChange-Id: If015f76a839733e1876214c002ec2c9c75f2e12a\n'}]",0,641342,59dcfc4d0658b8566c3ca6040e8912a576a8a35f,15,4,4,20634,,,0,"Configure stestr directly

Change-Id: If015f76a839733e1876214c002ec2c9c75f2e12a
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/42/641342/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,13e6d72cb77e98ba81c2c77ed7fb813852aa1524,fix-stestr,commands = stestr run {posargs} stestr run {posargs},commands = ostestr {posargs} ostestr {posargs},2,2
openstack%2Fmagnum~master~I5857fe62f922d27860946fd318296950834a8797,openstack/magnum,master,I5857fe62f922d27860946fd318296950834a8797,Fix prometheus installation script,MERGED,2019-03-01 01:20:58.000000000,2019-03-06 15:44:39.000000000,2019-03-06 15:44:39.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-03-01 01:20:58.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/enable-prometheus-monitoring.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/2cf4df0850931fed8549780d7abebe2592d389e1', 'message': ""Fix prometheus installation script\n\n- Fix the indent in the file.\n- Use 'kubectl apply' instead of 'kubectl create' for more robust\n  service restart.\n- Do not retry infinitely when Prometheus datasource already injected\n  into Grafana\n\nStory: #2005117\nTask: #29765\n\nChange-Id: I5857fe62f922d27860946fd318296950834a8797\n""}]",0,640236,2cf4df0850931fed8549780d7abebe2592d389e1,8,4,1,6732,,,0,"Fix prometheus installation script

- Fix the indent in the file.
- Use 'kubectl apply' instead of 'kubectl create' for more robust
  service restart.
- Do not retry infinitely when Prometheus datasource already injected
  into Grafana

Story: #2005117
Task: #29765

Change-Id: I5857fe62f922d27860946fd318296950834a8797
",git fetch https://review.opendev.org/openstack/magnum refs/changes/36/640236/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/common/templates/kubernetes/fragments/enable-prometheus-monitoring.sh'],1,2cf4df0850931fed8549780d7abebe2592d389e1,fix-prometheus-script,"until [ ""ok"" = ""$(curl --silent http://127.0.0.1:8080/healthz)"" ] do echo ""Waiting for Kubernetes API..."" sleep 5 done # Check if prometheus-monitoring namespace exist already before creating the namespace kubectl get namespace prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/prometheusNamespace.yaml"" ]; then kubectl apply -f '''${PROMETHEUS_MON_BASE_DIR}'''/prometheusNamespace.yaml fi # Check if all resources exist already before creating them # Check if configmap Prometheus exists kubectl get configmap prometheus -n prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/prometheusConfigMap.yaml"" ]; then kubectl apply -f '''${PROMETHEUS_MON_BASE_DIR}'''/prometheusConfigMap.yaml fi # Check if deployment and service Prometheus exist kubectl get service prometheus -n prometheus-monitoring | kubectl get deployment prometheus -n prometheus-monitoring if [ ""${PIPESTATUS[0]}"" != ""0"" ] && [ ""${PIPESTATUS[1]}"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/prometheusService.yaml"" ]; then kubectl apply -f '''${PROMETHEUS_MON_BASE_DIR}'''/prometheusService.yaml fi # Check if node exporter daemonset exist kubectl get daemonset node-exporter -n prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/nodeExporter.yaml"" ]; then kubectl apply -f '''${PROMETHEUS_MON_BASE_DIR}'''/nodeExporter.yaml fi # Check if configmap graf-dash exists kubectl get configmap graf-dash -n prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f '''$GRAFANA_DEF_DASHBOARD_FILE''' ]; then kubectl create configmap graf-dash --from-file='''$GRAFANA_DEF_DASHBOARD_FILE''' -n prometheus-monitoring fi # Check if deployment and service Grafana exist kubectl get service grafana -n prometheus-monitoring | kubectl get deployment grafana -n prometheus-monitoring if [ ""${PIPESTATUS[0]}"" != ""0"" ] && [ ""${PIPESTATUS[1]}"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/grafanaService.yaml"" ]; then kubectl apply -f '''${PROMETHEUS_MON_BASE_DIR}'''/grafanaService.yaml fi # Wait for Grafana pod and then inject data source while true do echo ""Waiting for Grafana pod to be up and Running"" if [ ""$(kubectl get po -n prometheus-monitoring -l name=grafana -o jsonpath={..phase})"" = ""Running"" ]; then break fi sleep 2 done # Which node is running Grafana NODE_IP=`kubectl get po -n prometheus-monitoring -o jsonpath={.items[0].status.hostIP} -l name=grafana` PROM_SERVICE_IP=`kubectl get svc prometheus --namespace prometheus-monitoring -o jsonpath={..clusterIP}` GRAFANA_SERVICE_IP=`kubectl get svc grafana --namespace prometheus-monitoring -o jsonpath={..clusterIP}` # The Grafana pod might be running but the app might still be initiating echo ""Check if Grafana is ready..."" curl -sS --user admin:$ADMIN_PASSWD -X GET http://$GRAFANA_SERVICE_IP:3000/api/datasources/1 until [ $? -eq 0 ] do sleep 2 curl -sS --user admin:$ADMIN_PASSWD -X GET http://$GRAFANA_SERVICE_IP:3000/api/datasources/1 done # Inject Prometheus datasource into Grafana while true do INJECT=`curl -sS --user admin:$ADMIN_PASSWD -X POST \ -H ""Content-Type: application/json;charset=UTF-8"" \ --data-binary '''""'""'''{""name"":""k8sPrometheus"",""isDefault"":true, ""type"":""prometheus"",""url"":""http://'''""'""'''$PROM_SERVICE_IP'''""'""''':9090"",""access"":""proxy""}'''""'""'''\ ""http://$GRAFANA_SERVICE_IP:3000/api/datasources/""` if [[ ""$INJECT"" = *""Datasource added""* ]]; then echo ""Prometheus datasource injected into Grafana"" break elif [[ ""$INJECT"" = *""Data source with same name already exists""* ]]; then echo ""Prometheus datasource already injected into Grafana"" break echo ""Trying to inject Prometheus datasource into Grafana - ""$INJECT done '''Description=Enable Prometheus monitoring stack [Service] Type=oneshot Environment=HOME=/root EnvironmentFile=-/etc/kubernetes/config ExecStart='''${KUBE_MON_BIN}''' [Install] WantedBy=multi-user.target '''"," until [ ""ok"" = ""$(curl --silent http://127.0.0.1:8080/healthz)"" ] do echo ""Waiting for Kubernetes API..."" sleep 5 done # Check if prometheus-monitoring namespace exist already before creating the namespace kubectl get namespace prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/prometheusNamespace.yaml"" ]; then kubectl create -f '''${PROMETHEUS_MON_BASE_DIR}'''/prometheusNamespace.yaml # Check if all resources exist already before creating them # Check if configmap Prometheus exists kubectl get configmap prometheus -n prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/prometheusConfigMap.yaml"" ]; then kubectl create -f '''${PROMETHEUS_MON_BASE_DIR}'''/prometheusConfigMap.yaml fi # Check if deployment and service Prometheus exist kubectl get service prometheus -n prometheus-monitoring | kubectl get deployment prometheus -n prometheus-monitoring if [ ""${PIPESTATUS[0]}"" != ""0"" ] && [ ""${PIPESTATUS[1]}"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/prometheusService.yaml"" ]; then kubectl create -f '''${PROMETHEUS_MON_BASE_DIR}'''/prometheusService.yaml fi # Check if node exporter daemonset exist kubectl get daemonset node-exporter -n prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/nodeExporter.yaml"" ]; then kubectl create -f '''${PROMETHEUS_MON_BASE_DIR}'''/nodeExporter.yaml fi # Check if configmap graf-dash exists kubectl get configmap graf-dash -n prometheus-monitoring if [ ""$?"" != ""0"" ] && \ [ -f '''$GRAFANA_DEF_DASHBOARD_FILE''' ]; then kubectl create configmap graf-dash --from-file='''$GRAFANA_DEF_DASHBOARD_FILE''' -n prometheus-monitoring fi # Check if deployment and service Grafana exist kubectl get service grafana -n prometheus-monitoring | kubectl get deployment grafana -n prometheus-monitoring if [ ""${PIPESTATUS[0]}"" != ""0"" ] && [ ""${PIPESTATUS[1]}"" != ""0"" ] && \ [ -f ""'''${PROMETHEUS_MON_BASE_DIR}'''/grafanaService.yaml"" ]; then kubectl create -f '''${PROMETHEUS_MON_BASE_DIR}'''/grafanaService.yaml fi # Wait for Grafana pod and then inject data source while true do echo ""Waiting for Grafana pod to be up and Running"" if [ ""$(kubectl get po -n prometheus-monitoring -l name=grafana -o jsonpath={..phase})"" = ""Running"" ]; then break fi sleep 2 done # Which node is running Grafana NODE_IP=`kubectl get po -n prometheus-monitoring -o jsonpath={.items[0].status.hostIP} -l name=grafana` PROM_SERVICE_IP=`kubectl get svc prometheus --namespace prometheus-monitoring -o jsonpath={..clusterIP}` GRAFANA_SERVICE_IP=`kubectl get svc grafana --namespace prometheus-monitoring -o jsonpath={..clusterIP}` # The Grafana pod might be running but the app might still be initiating echo ""Check if Grafana is ready..."" curl --user admin:$ADMIN_PASSWD -X GET http://$GRAFANA_SERVICE_IP:3000/api/datasources/1 until [ $? -eq 0 ] do sleep 2 curl --user admin:$ADMIN_PASSWD -X GET http://$GRAFANA_SERVICE_IP:3000/api/datasources/1 done # Inject Prometheus datasource into Grafana while true do INJECT=`curl --user admin:$ADMIN_PASSWD -X POST \ -H ""Content-Type: application/json;charset=UTF-8"" \ --data-binary '''""'""'''{""name"":""k8sPrometheus"",""isDefault"":true, ""type"":""prometheus"",""url"":""http://'''""'""'''$PROM_SERVICE_IP'''""'""''':9090"",""access"":""proxy""}'''""'""'''\ ""http://$GRAFANA_SERVICE_IP:3000/api/datasources/""` if [[ ""$INJECT"" = *""Datasource added""* ]]; then echo ""Prometheus datasource injected into Grafana"" break fi echo ""Trying to inject Prometheus datasource into Grafana - ""$INJECT done ''' Description=Enable Prometheus monitoring stack [Service] Type=oneshot Environment=HOME=/root EnvironmentFile=-/etc/kubernetes/config ExecStart='''${KUBE_MON_BIN}''' [Install] WantedBy=multi-user.target '''",99,95
openstack%2Fnetworking-l2gw~stable%2Fpike~Ia0b69f2e747187d128bd8e7546674a7e5ec8d3d2,openstack/networking-l2gw,stable/pike,Ia0b69f2e747187d128bd8e7546674a7e5ec8d3d2,DNM test commit to trigger gates,ABANDONED,2019-02-26 18:08:48.000000000,2019-03-06 15:42:56.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-26 18:08:48.000000000', 'files': ['networking_l2gw/cmd/eventlet/agent.py'], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/0005e6130dfeefa0854ad1d482d4c2255cdbb449', 'message': 'DNM test commit to trigger gates\n\nChange-Id: Ia0b69f2e747187d128bd8e7546674a7e5ec8d3d2\n'}]",0,639406,0005e6130dfeefa0854ad1d482d4c2255cdbb449,3,1,1,9542,,,0,"DNM test commit to trigger gates

Change-Id: Ia0b69f2e747187d128bd8e7546674a7e5ec8d3d2
",git fetch https://review.opendev.org/openstack/networking-l2gw refs/changes/06/639406/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_l2gw/cmd/eventlet/agent.py'],1,0005e6130dfeefa0854ad1d482d4c2255cdbb449,dnm,# FIXME(pas-ha) dumb comment to trigger gates ,,2,0
openstack%2Fhorizon~stable%2Frocky~I77a6686db5539b8fd7fb75cfe073e4188c960d18,openstack/horizon,stable/rocky,I77a6686db5539b8fd7fb75cfe073e4188c960d18,Imported Translations from Zanata,MERGED,2019-03-01 08:52:04.000000000,2019-03-06 15:36:33.000000000,2019-03-06 15:36:33.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 08:52:04.000000000', 'files': ['openstack_dashboard/locale/ru/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8efab171065bca587822b4ba170e0181c717f80b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I77a6686db5539b8fd7fb75cfe073e4188c960d18\n'}]",0,640273,8efab171065bca587822b4ba170e0181c717f80b,13,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I77a6686db5539b8fd7fb75cfe073e4188c960d18
",git fetch https://review.opendev.org/openstack/horizon refs/changes/73/640273/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/ru/LC_MESSAGES/django.po'],1,8efab171065bca587822b4ba170e0181c717f80b,zanata/translations,"""POT-Creation-Date: 2019-02-05 09:53+0000\n""""PO-Revision-Date: 2019-02-28 01:53+0000\n""""Снимок это образ, который сохраняет состояние диска включенного инстанса.""msgstr ""Подключить диск к включенному инстансу.""msgstr ""Отключить диск от включенного инстанса.""msgstr ""Тип инстанса""""Дополнительно вы можете выбрать тип миграции. Все включенные инстансы узла "" ""могут быть мигрированы \""вживую\"". В случае холодной миграции будет ""msgstr ""Включен""msgstr ""Тип миграции включенных инстансов.""msgstr ""Выключен""msgstr ""Остановлен""","""POT-Creation-Date: 2019-01-14 15:21+0000\n""""PO-Revision-Date: 2019-01-17 05:51+0000\n""""Снимок это образ который сохраняет состояние диска запущенного инстанса.""msgstr ""Подключить диск к запущенному инстансу.""msgstr ""Отключить диск от запущенного инстанса.""msgstr ""Тип инстансов""""Дополнительно вы можете выбрать тип миграции. Все запущенные инстансы узла "" ""могут быть смигрированы \""вживую\"". В случае холодной миграции будет ""msgstr ""Запущенный""msgstr ""Тип миграции запущенных инстансов.""msgstr ""Выключить""msgstr ""Выключается""",12,12
openstack%2Fopenstack-helm-infra~master~I86fd7ec4022067a8bb0d299062761baf819bf92c,openstack/openstack-helm-infra,master,I86fd7ec4022067a8bb0d299062761baf819bf92c,Add init container to load apparmor profile for libvirt,ABANDONED,2019-03-06 11:54:48.000000000,2019-03-06 15:24:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-06 11:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c58fa35f76d615fc050bc2ec0619c52484f9f2c6', 'message': 'Add init container to load apparmor profile\n\nThis patch place in a sample for an init container, generated by\nhelm toolkit, to load an apparmor profile included in the chart.\n\nChange-Id: I309e3b550fd1d683745c319aa39bcfb96b77ea14\nSigned-off-by: Tin Lam <tin@irrational.io>\n\nChange-Id: I86fd7ec4022067a8bb0d299062761baf819bf92c\n'}, {'number': 2, 'created': '2019-03-06 14:25:36.000000000', 'files': ['libvirt/templates/daemonset-libvirt.yaml', 'zuul.d/project.yaml', 'libvirt/templates/configmap-apparmor.yaml', 'tools/deployment/apparmor/050-libvirt.sh', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f82ed76971d15a590023fc80215f56ea7dfac6a9', 'message': 'Add init container to load apparmor profile for libvirt\n\nThis patch place in a sample for an init container, generated by\nhelm toolkit, to load an apparmor profile included in the chart.\n\nChange-Id: I86fd7ec4022067a8bb0d299062761baf819bf92c\n'}]",0,641333,f82ed76971d15a590023fc80215f56ea7dfac6a9,5,1,2,29254,,,0,"Add init container to load apparmor profile for libvirt

This patch place in a sample for an init container, generated by
helm toolkit, to load an apparmor profile included in the chart.

Change-Id: I86fd7ec4022067a8bb0d299062761baf819bf92c
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/33/641333/1 && git format-patch -1 --stdout FETCH_HEAD,"['libvirt/templates/daemonset-libvirt.yaml', 'tools/deployment/apparmor/000-install-packages.sh', 'tools/deployment/common/001-setup-apparmor-profiles.sh', 'tools/deployment/apparmor/040-memcached.sh', 'tools/deployment/apparmor/001-setup-apparmor-profiles.sh', 'helm-toolkit/templates/snippets/_kubernetes_apparmor_volumes.tpl', 'helm-toolkit/templates/snippets/_kubernetes_apparmor_configmap.tpl', 'memcached/templates/deployment.yaml', 'helm-toolkit/templates/snippets/_kubernetes_apparmor_loader_init_container.tpl', 'tools/deployment/apparmor/005-deploy-k8s.sh', 'memcached/templates/configmap-apparmor.yaml', 'zuul.d/project.yaml', 'libvirt/templates/configmap-apparmor.yaml', 'tools/deployment/apparmor/050-libvirt.sh', 'zuul.d/jobs.yaml']",15,c58fa35f76d615fc050bc2ec0619c52484f9f2c6,apparmor-loader, name: openstack-helm-infra-apparmor parent: openstack-helm-infra-functional timeout: 7200 pre-run: playbooks/osh-infra-upgrade-host.yaml run: playbooks/osh-infra-gate-runner.yaml post-run: playbooks/osh-infra-collect-logs.yaml nodeset: openstack-helm-single-node vars: gate_scripts: - ./tools/deployment/apparmor/000-install-packages.sh - ./tools/deployment/apparmor/001-setup-apparmor-profiles.sh - ./tools/deployment/apparmor/005-deploy-k8s.sh - ./tools/deployment/apparmor/040-memcached.sh - job: name: openstack-helm-infra-apparmor-libvirt parent: openstack-helm-infra-functional timeout: 7200 pre-run: playbooks/osh-infra-upgrade-host.yaml run: playbooks/osh-infra-gate-runner.yaml post-run: playbooks/osh-infra-collect-logs.yaml nodeset: openstack-helm-single-node vars: gate_scripts: - ./tools/deployment/apparmor/000-install-packages.sh - ./tools/deployment/apparmor/001-setup-apparmor-profiles.sh - ./tools/deployment/apparmor/005-deploy-k8s.sh - ./tools/deployment/apparmor/050-libvirt.sh - job:,,628,0
openstack%2Fopenstack-helm-infra~master~I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77,openstack/openstack-helm-infra,master,I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77,HTK: Refactor kubernetes security_context macro(s) to allow scoping,MERGED,2019-02-16 02:25:47.000000000,2019-03-06 15:23:01.000000000,2019-03-06 15:23:01.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 17068}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28025}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-02-16 02:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e680f37997c9c40ad38811129adca3a950c00f7f', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 2, 'created': '2019-02-16 02:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0be33d0c08f250304d155940952d2a96f2dca2b3', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 3, 'created': '2019-02-16 03:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ea3d2c25f59f62fa2a3782f3df201f11b404e9bb', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 4, 'created': '2019-02-16 13:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/115f5361ac0f5ae4cfb72c43e2f611051fc5f8b8', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 5, 'created': '2019-02-16 17:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ab45eaad085cdcf93780a4ee5d64f2cee6078c4b', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 6, 'created': '2019-02-16 19:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/715042fd63298fa43d39fe1ef0ab924d3fe63c45', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 7, 'created': '2019-02-16 20:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5d3e547950704b593382d445c8a8ec3d82d9cc54', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 8, 'created': '2019-02-16 21:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ea6370cb01c08a3a4b56848d2e805263132a5cfa', 'message': 'HTK: Update kubernetes_pod_security_context to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 9, 'created': '2019-02-16 21:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2854b3585d39aea19b6d486ec9abb8c8f914e3bd', 'message': 'HTK: Refactor kubernetes security_context macro to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod, in the process renaming\nthe function to kubernetes_security_context to better match the intent.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 10, 'created': '2019-02-21 16:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ee6dd55bffaaeb27d2f428e3bd5c6eaaff131a22', 'message': 'HTK: Refactor kubernetes security_context macro to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod, in the process renaming\nthe function to kubernetes_security_context to better match the intent.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 11, 'created': '2019-02-21 16:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9931a1ec9e742f0ef44d6a4e38ad1a7b1d9c3b0e', 'message': 'HTK: Refactor kubernetes security_context macro to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod, in the process renaming\nthe function to kubernetes_security_context to better match the intent.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 12, 'created': '2019-02-21 17:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/73dc505ae0c191c128a1adbf5d2190cc32c1acc0', 'message': 'HTK: Refactor kubernetes security_context macro to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod, in the process renaming\nthe function to kubernetes_security_context to better match the intent.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 13, 'created': '2019-03-05 14:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b79184b745f7d6f46bfadc81ce63c73f4b568ee8', 'message': 'HTK: Refactor kubernetes security_context macro to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet\nto allow scoping to a container within a pod, in the process renaming\nthe function to kubernetes_security_context to better match the intent.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 14, 'created': '2019-03-05 14:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/621e5851383e5bae29d5a64bc050ba5c2856cd45', 'message': ""HTK: Refactor kubernetes security_context macro(s) to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet, and adds a\nmacro for container securityContexts\n'kubernetes_container_security_context.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n""}, {'number': 15, 'created': '2019-03-05 21:42:35.000000000', 'files': ['helm-toolkit/templates/snippets/_kubernetes_pod_security_context.tpl', 'helm-toolkit/templates/snippets/_kubernetes_container_security_context.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9ec291015172d7777bf1628182e2fa190c9c16e9', 'message': ""HTK: Refactor kubernetes security_context macro(s) to allow scoping\n\nThis PS updates the kubernetes_pod_security_context snippet, and adds a\nmacro for container securityContexts\n'kubernetes_container_security_context.\n\nChange-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77\nSigned-off-by: Pete Birley <pete@port.direct>\n""}]",9,637345,9ec291015172d7777bf1628182e2fa190c9c16e9,51,8,15,23928,,,0,"HTK: Refactor kubernetes security_context macro(s) to allow scoping

This PS updates the kubernetes_pod_security_context snippet, and adds a
macro for container securityContexts
'kubernetes_container_security_context.

Change-Id: I8b9c7b72f836efaf6c9dc3ad20fd8462b0d06d77
Signed-off-by: Pete Birley <pete@port.direct>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/45/637345/5 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/snippets/_kubernetes_pod_security_context.tpl'],1,e680f37997c9c40ad38811129adca3a950c00f7f,readonly-root," global: readOnlyRootFilesystem: true seLinuxOptions: level: ""s0:c123,c456""{{- $container := index . ""container"" | default ""global"" -}}{{- if hasKey ( index $envAll.Values.pod.security_context $application ) $container }} {{ toYaml ( index $envAll.Values.pod.security_context $application $container ) | indent 2 }} {{- end -}}"," readOnlyRootFilesystem: true seLinuxOptions: level: ""s0:c123,c456""{{ toYaml ( index $envAll.Values.pod.security_context $application ) | indent 2 }}",8,4
openstack%2Fopenstack-helm-infra~master~I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542,openstack/openstack-helm-infra,master,I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542,ceph-rgw: Add network policy for ceph-rgw  pods,MERGED,2019-01-22 22:02:41.000000000,2019-03-06 15:21:22.000000000,2019-03-06 15:21:22.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 18236}, {'_account_id': 18250}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 28237}, {'_account_id': 28372}, {'_account_id': 28592}, {'_account_id': 29106}, {'_account_id': 29132}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-01-22 22:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c97bfd57e138e813f6ad36f09021a7931e729b2d', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 2, 'created': '2019-01-22 22:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dbf2ab972cf46287e13680038a76f4216aaf3f6a', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 3, 'created': '2019-01-24 17:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a178e00d58b54e12962c6fd5e81cd563c4bc6ff1', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 4, 'created': '2019-01-24 17:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e061e1c59ddba49fe7e9e51393b8c6805c1dde62', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 5, 'created': '2019-01-24 21:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f16edb91ee72a5073e3e15843af131fd486dd3ba', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 6, 'created': '2019-01-24 21:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ee6e82cba5263da5041d9f6e7c679a4c2a21dca2', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 7, 'created': '2019-01-24 21:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/16f16d0f1aefb0a94f4f5664defe7c2f3129a177', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 8, 'created': '2019-01-24 23:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dc9b24474d69ad0cc62300de9c1adcaf0bc60c01', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 9, 'created': '2019-01-25 03:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5eaa5e857c8c7cb6d51d60f9c3d5979b20eff991', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 10, 'created': '2019-01-25 19:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dd6d80f3a4c466f3642fe9af0235a1fa75f125ff', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 11, 'created': '2019-01-28 15:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/753ff33f87fe626523dedac77e11793a06a907b8', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 12, 'created': '2019-01-29 18:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a0d85415f8f12e5d290d69b2ab4028fff2fe6e75', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 13, 'created': '2019-01-30 17:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cc3fba59c3987e7f270e847d09937b681db9db35', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 14, 'created': '2019-01-31 17:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/11c913098b21601822e290210f1108022e3c2113', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 15, 'created': '2019-02-04 21:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/208eabc3a9652e69ca98ce7810b5e4ad083cdc24', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 16, 'created': '2019-02-07 16:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/07df9d64047420dc35c706f5a61e667effe2da99', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 17, 'created': '2019-02-10 23:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1289d5a25df567aa3cf73ea59553d2d7ccce3708', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 18, 'created': '2019-02-18 19:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f5c1b4e2b867f0b8d04b2abf207c7c711d00bb54', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 19, 'created': '2019-02-25 03:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f73c8148a8820c266d513c374a5b88223bbd4222', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}, {'number': 20, 'created': '2019-03-06 03:08:34.000000000', 'files': ['ceph-rgw/values.yaml', 'ceph-rgw/templates/pod-helm-tests.yaml', 'ceph-rgw/templates/network_policy.yaml', 'tools/deployment/multinode/115-radosgw-osh-infra.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/babe91b75e0853864356164be315d67fa4e6e73c', 'message': 'ceph-rgw: Add network policy for ceph-rgw  pods\n\nThis is to add ingress network policy for ceph-rgw pods\n\nChange-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542\n'}]",10,632567,babe91b75e0853864356164be315d67fa4e6e73c,79,13,20,28372,,,0,"ceph-rgw: Add network policy for ceph-rgw  pods

This is to add ingress network policy for ceph-rgw pods

Change-Id: I32a5d3d9a05b920bc69d5b5bb5a2d27cf6f55542
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/67/632567/14 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-rgw/values.yaml', 'ceph-rgw/templates/network_policy.yaml']",2,c97bfd57e138e813f6ad36f09021a7931e729b2d,netpol-ceph-rgw,"opyright 2017-2018 The Openstack-Helm Authors. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. {{- if .Values.manifests.network_policy -}} {{- $netpol_opts := dict ""envAll"" . ""name"" ""application"" ""label"" ""ceph-rgw`"" -}} {{ $netpol_opts | include ""helm-toolkit.manifests.kubernetes_network_policy"" }} {{- end -}} ",,29,0
openstack%2Fopenstack-helm~master~I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c,openstack/openstack-helm,master,I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c,Add the CentOS system to Ceph related configuration file.,MERGED,2018-12-19 07:19:03.000000000,2019-03-06 15:19:00.000000000,2019-03-06 15:19:00.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 27471}, {'_account_id': 29268}]","[{'number': 1, 'created': '2018-12-19 07:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8c4a6fbc2cbaeac6eb9968675577ece9e5c12a7e', 'message': 'Add the CentOS system to Ceph related configuration file.\n\nTo use RBD devices with CentOS system, multinode deployment script has\nalready been modifed.\n\nChange-Id: I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c\nStory:2004640\nTask:28577\n'}, {'number': 2, 'created': '2019-01-05 04:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c69481cf3021bc62d0dc457248430dd5faf866af', 'message': 'Add the CentOS system to Ceph related configuration file.\n\nTo use RBD devices with CentOS system, multinode deployment script has\nalready been modifed.\n\nChange-Id: I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c\nStory:2004640\nTask:28577\n'}, {'number': 3, 'created': '2019-01-08 06:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/11fbeae3832a82348d493939a08b10e667694a2a', 'message': 'Add the CentOS system to Ceph related configuration file.\n\nTo use RBD devices with CentOS system, multinode deployment script has\nalready been modifed.\n\nChange-Id: I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c\nStory:2004640\nTask:28577\n'}, {'number': 4, 'created': '2019-02-08 08:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ed5e3a1479bd073e645ff5939bc5dd44e18b8cfe', 'message': 'Add the CentOS system to Ceph related configuration file.\n\nTo use RBD devices with CentOS system, multinode deployment script has\nalready been modifed.\n\nChange-Id: I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c\nStory:2004640\nTask:28577\n'}, {'number': 5, 'created': '2019-03-06 03:10:03.000000000', 'files': ['tools/deployment/developer/ceph/040-ceph.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/52aac83b44153c20b50b589c462628817c9d1440', 'message': 'Add the CentOS system to Ceph related configuration file.\n\nTo use RBD devices with CentOS system, multinode deployment script has\nalready been modifed.\n\nChange-Id: I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c\nStory:2004640\nTask:28577\n'}]",0,626105,52aac83b44153c20b50b589c462628817c9d1440,17,6,5,25493,,,0,"Add the CentOS system to Ceph related configuration file.

To use RBD devices with CentOS system, multinode deployment script has
already been modifed.

Change-Id: I8a1ac13b0ec124b14b2bdd06ea3b0a9c081d468c
Story:2004640
Task:28577
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/05/626105/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/developer/ceph/040-ceph.sh'],1,8c4a6fbc2cbaeac6eb9968675577ece9e5c12a7e,add_centos_for_ceph_config,"if [ ""x${ID}"" == ""xcentos"" ] || \ ([ ""x${ID}"" == ""xubuntu"" ] && \ [ ""$(uname -r | awk -F ""."" '{ print $2 }')"" -lt ""5"" ]); then","if [ ""x${ID}"" == ""xubuntu"" ] && \ [ ""$(uname -r | awk -F ""."" '{ print $2 }')"" -lt ""5"" ]; then",3,2
openstack%2Fansible-role-thales-hsm~master~I1585516e8caf5db82cbab6fd34e29c9fc219f85f,openstack/ansible-role-thales-hsm,master,I1585516e8caf5db82cbab6fd34e29c9fc219f85f,Add gate config,MERGED,2019-03-05 17:32:34.000000000,2019-03-06 15:17:10.000000000,2019-03-06 15:17:10.000000000,"[{'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 17:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-thales-hsm/commit/e3a2f2f54e8a7c58148497bf1f480c82f6bf24ab', 'message': 'Add gerrit config\n\nChange-Id: I1585516e8caf5db82cbab6fd34e29c9fc219f85f\n'}, {'number': 2, 'created': '2019-03-06 06:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-thales-hsm/commit/adba336d0ff160c4a53e81cf5557e575e9d6623c', 'message': 'Add gate config\n\nThis patch adds gerrit configuration as well as an\nansible-lint gate job.\n\nChange-Id: I1585516e8caf5db82cbab6fd34e29c9fc219f85f\n'}, {'number': 3, 'created': '2019-03-06 13:26:06.000000000', 'files': ['tasks/rfs.yaml', '.gitignore', '.gitreview', 'test-requirements.txt', 'tasks/client.yaml', 'zuul.d/layout.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-thales-hsm/commit/3076482fda83e5de4f0819aee1390eb031e73dc9', 'message': 'Add gate config\n\nThis patch adds gerrit configuration as well as an\nansible-lint gate job.\n\nChange-Id: I1585516e8caf5db82cbab6fd34e29c9fc219f85f\n'}]",0,641095,3076482fda83e5de4f0819aee1390eb031e73dc9,11,4,3,7973,,,0,"Add gate config

This patch adds gerrit configuration as well as an
ansible-lint gate job.

Change-Id: I1585516e8caf5db82cbab6fd34e29c9fc219f85f
",git fetch https://review.opendev.org/openstack/ansible-role-thales-hsm refs/changes/95/641095/3 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,e3a2f2f54e8a7c58148497bf1f480c82f6bf24ab,,[gerrit] host=review.openstack.org port=29418 project=openstack/ansible-role-thales-hsm.git ,,4,0
openstack%2Fansible-role-atos-hsm~master~I13b5a6505195591f7d6471ebe151cc8ed03eae75,openstack/ansible-role-atos-hsm,master,I13b5a6505195591f7d6471ebe151cc8ed03eae75,Add gate config,MERGED,2019-03-05 17:29:31.000000000,2019-03-06 15:12:44.000000000,2019-03-06 15:12:44.000000000,"[{'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 17:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-atos-hsm/commit/a52398c9d772dee8412ba438c59c3cd1b4f9b5f1', 'message': 'Add gerrit config\n\nChange-Id: I13b5a6505195591f7d6471ebe151cc8ed03eae75\n'}, {'number': 2, 'created': '2019-03-06 05:39:41.000000000', 'files': ['.gitreview', 'test-requirements.txt', 'tasks/main.yaml', 'zuul.d/layout.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-atos-hsm/commit/f6f9c3f3df08c385c6d23f4097c1e2a8b0c18c94', 'message': 'Add gate config\n\nThis patch adds gerrit configuration as well as an\nansible-lint gate job.\n\nChange-Id: I13b5a6505195591f7d6471ebe151cc8ed03eae75\n'}]",0,641092,f6f9c3f3df08c385c6d23f4097c1e2a8b0c18c94,9,3,2,7973,,,0,"Add gate config

This patch adds gerrit configuration as well as an
ansible-lint gate job.

Change-Id: I13b5a6505195591f7d6471ebe151cc8ed03eae75
",git fetch https://review.opendev.org/openstack/ansible-role-atos-hsm refs/changes/92/641092/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,a52398c9d772dee8412ba438c59c3cd1b4f9b5f1,,[gerrit] host=review.openstack.org port=29418 project=openstack/ansible-role-atos-hsm.git ,,4,0
openstack%2Fzaqar~master~I92f10755f1a98239df3b3a1494207299a3681a84,openstack/zaqar,master,I92f10755f1a98239df3b3a1494207299a3681a84,Python 3: Fix parsing of received notification,MERGED,2019-02-28 10:55:00.000000000,2019-03-06 15:09:26.000000000,2019-03-06 04:36:47.000000000,"[{'_account_id': 3153}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 7385}, {'_account_id': 8846}, {'_account_id': 12321}, {'_account_id': 14203}, {'_account_id': 14985}, {'_account_id': 15343}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 28035}]","[{'number': 1, 'created': '2019-02-28 10:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ff58555ebcb656d2250c15006d739c570c5bb2e2', 'message': ""WIP Python 3: Fix parsing of received notification\n\nThe parsing of incoming notifications is performed with a helper\nwhich normally resolves to a mimetools class.\n\nFor Python3, package mimetools doesn't exist anymore, and the helper\nresolves to a class with incompatible signature.\n\nIn order to mimick the original helper behaviour and return a message\nobject as expected, use a different facility from package email.\n\nChange-Id: I92f10755f1a98239df3b3a1494207299a3681a84\nCloses-Bug: #1818046\nCo-Authored-By: Michele Baldessari <michele@acksyn.org>\n""}, {'number': 2, 'created': '2019-03-01 00:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d0f4db1197fa8b5d567fedbf88cb40a7c89af983', 'message': ""Python 3: Fix parsing of received notification\n\nThe parsing of incoming notifications is performed with a helper\nwhich normally resolves to a mimetools class.\n\nFor Python3, package mimetools doesn't exist anymore, and the helper\nresolves to a class with incompatible signature.\n\nIn order to mimick the original helper behaviour and return a message\nobject as expected, use a different facility from package email.\n\nChange-Id: I92f10755f1a98239df3b3a1494207299a3681a84\nCloses-Bug: #1818046\nCo-Authored-By: Michele Baldessari <michele@acksyn.org>\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\n""}, {'number': 3, 'created': '2019-03-04 21:50:37.000000000', 'files': ['zaqar/transport/websocket/protocol.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ff19fdeb5452f19d8420cfb041aa846bdf58c84e', 'message': ""Python 3: Fix parsing of received notification\n\nThe parsing of incoming notifications is performed with a helper\nwhich normally resolves to a mimetools class.\n\nFor Python3, package mimetools doesn't exist anymore, and the helper\nresolves to a class with incompatible signature.\n\nIn order to mimick the original helper behaviour and return a message\nobject as expected, use a different facility from package email.\n\nChange-Id: I92f10755f1a98239df3b3a1494207299a3681a84\nCloses-Bug: #1818046\nCo-Authored-By: Michele Baldessari <michele@acksyn.org>\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\n""}]",7,639983,ff19fdeb5452f19d8420cfb041aa846bdf58c84e,21,16,3,20778,,,0,"Python 3: Fix parsing of received notification

The parsing of incoming notifications is performed with a helper
which normally resolves to a mimetools class.

For Python3, package mimetools doesn't exist anymore, and the helper
resolves to a class with incompatible signature.

In order to mimick the original helper behaviour and return a message
object as expected, use a different facility from package email.

Change-Id: I92f10755f1a98239df3b3a1494207299a3681a84
Closes-Bug: #1818046
Co-Authored-By: Michele Baldessari <michele@acksyn.org>
Co-Authored-By: Alex Schultz <aschultz@redhat.com>
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/83/639983/3 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/transport/websocket/protocol.py'],1,ff58555ebcb656d2250c15006d739c570c5bb2e2,bug/1818046, import email Message = email.message_from_binary_file, from email.mime import message Message = message.MIMEMessage,2,2
openstack%2Fnova~master~Ia6921b5cd9253f65ff6904bdbce942759633de95,openstack/nova,master,Ia6921b5cd9253f65ff6904bdbce942759633de95,Handle missing exception in instance creation code,MERGED,2019-03-05 16:51:51.000000000,2019-03-06 14:46:40.000000000,2019-03-06 00:08:21.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-03-05 16:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d24043d61610ff3bde6913fa907e63e920cbb9b4', 'message': ""Handle missing exception in instance creation code\n\nIn the instance creation code path it's possible for the PciInvalidAlias\nexception to be raised if the flavor extra-specs have an invalid PCI\nalias.  This should be converted to HTTPBadRequest along with the other\nexceptions stemming from invalid extra-specs.\n\nChange-Id: Ia6921b5cd9253f65ff6904bdbce942759633de95\nCloses-Bug: #1818701\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n""}, {'number': 2, 'created': '2019-03-05 17:04:54.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cb5ad6d3c14caccfc2b222dc5d2f1f6c5e05da9c', 'message': ""Handle missing exception in instance creation code\n\nIn the instance creation code path it's possible for the PciInvalidAlias\nexception to be raised if the flavor extra-specs have an invalid PCI\nalias.  This should be converted to HTTPBadRequest along with the other\nexceptions stemming from invalid extra-specs.\n\nWithout this, it gets reported as an HTTP 500 error.\n\nChange-Id: Ia6921b5cd9253f65ff6904bdbce942759633de95\nCloses-Bug: #1818701\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n""}]",1,641082,cb5ad6d3c14caccfc2b222dc5d2f1f6c5e05da9c,19,11,2,8768,,,0,"Handle missing exception in instance creation code

In the instance creation code path it's possible for the PciInvalidAlias
exception to be raised if the flavor extra-specs have an invalid PCI
alias.  This should be converted to HTTPBadRequest along with the other
exceptions stemming from invalid extra-specs.

Without this, it gets reported as an HTTP 500 error.

Change-Id: Ia6921b5cd9253f65ff6904bdbce942759633de95
Closes-Bug: #1818701
Signed-off-by: Chris Friesen <chris.friesen@windriver.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/641082/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/api/openstack/compute/servers.py']",2,d24043d61610ff3bde6913fa907e63e920cbb9b4,bug/1818701," exception.PciInvalidAlias,",,9,0
openstack%2Fopenstack-helm~master~I8aa15c8a8f2d8b3ffb764c3fb2411eb27477d0b6,openstack/openstack-helm,master,I8aa15c8a8f2d8b3ffb764c3fb2411eb27477d0b6,Cleanup specs folder,MERGED,2019-03-04 14:20:38.000000000,2019-03-06 14:43:41.000000000,2019-03-06 14:43:40.000000000,"[{'_account_id': 17068}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-03-04 14:20:38.000000000', 'files': ['doc/source/specs/index.rst', 'doc/source/specs/specifications.rst', 'doc/source/specs/COPYME'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/630ca71e3c3b10695bb5a0803d40a5b4afcd96dd', 'message': ""Cleanup specs folder\n\nSpecs are not ordered currently, and every rst file inside the\nspecs folder is included in the TOC tree, but manually.\n\nThis is a problem as:\n- the current readability of the specs was reduced due to inclusion\n  of non-specs files\n- the process of writing a spec was more tedious, due to the\n  update of the specs/index.rst.\n\nThis fixes it by removing the extra files included by mistake in\nthe middle of the specs (the template for spec writing, and\nthe specs purpose/process), and automatically load all the\nremaining files using a glob.\n\nThe content of the files removed is not lost: The template was\nsimply renamed COPYME to clearly state a spec writer should\ncopy the file (and will understand it needs to be named .rst)\nwith the other files present. The specs process/purpose is\nnow part of the main page of specs, which therefore doesn't need\nextra including.\n\nChange-Id: I8aa15c8a8f2d8b3ffb764c3fb2411eb27477d0b6\n""}]",0,640770,630ca71e3c3b10695bb5a0803d40a5b4afcd96dd,8,4,1,17068,,,0,"Cleanup specs folder

Specs are not ordered currently, and every rst file inside the
specs folder is included in the TOC tree, but manually.

This is a problem as:
- the current readability of the specs was reduced due to inclusion
  of non-specs files
- the process of writing a spec was more tedious, due to the
  update of the specs/index.rst.

This fixes it by removing the extra files included by mistake in
the middle of the specs (the template for spec writing, and
the specs purpose/process), and automatically load all the
remaining files using a glob.

The content of the files removed is not lost: The template was
simply renamed COPYME to clearly state a spec writer should
copy the file (and will understand it needs to be named .rst)
with the other files present. The specs process/purpose is
now part of the main page of specs, which therefore doesn't need
extra including.

Change-Id: I8aa15c8a8f2d8b3ffb764c3fb2411eb27477d0b6
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/70/640770/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/index.rst', 'doc/source/specs/specifications.rst', 'doc/source/specs/COPYME']",3,630ca71e3c3b10695bb5a0803d40a5b4afcd96dd,auto_gen_spec_list,,,35,47
openstack%2Fpython-magnumclient~master~I5977f202fb1f29de731fd802675189815f47814e,openstack/python-magnumclient,master,I5977f202fb1f29de731fd802675189815f47814e,Update hacking version,ABANDONED,2019-03-06 13:59:44.000000000,2019-03-06 14:08:18.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 13:59:44.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/adcf9754c66ef30ece068213144334163da991cc', 'message': 'Update hacking version\n\nChange-Id: I5977f202fb1f29de731fd802675189815f47814e\n'}]",0,641364,adcf9754c66ef30ece068213144334163da991cc,2,1,1,28614,,,0,"Update hacking version

Change-Id: I5977f202fb1f29de731fd802675189815f47814e
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/64/641364/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,adcf9754c66ef30ece068213144334163da991cc,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-zunclient~master~I90423f032092352dd0b9abdf22344f419eed9fa5,openstack/python-zunclient,master,I90423f032092352dd0b9abdf22344f419eed9fa5,Update hacking version,ABANDONED,2019-03-06 13:49:34.000000000,2019-03-06 14:07:56.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 13:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/c846ae019199303c1ee20921d86614148fc34132', 'message': 'Update hacking version\n\nChange-Id: I90423f032092352dd0b9abdf22344f419eed9fa5\n'}, {'number': 2, 'created': '2019-03-06 13:50:44.000000000', 'files': ['zunclient/exceptions.py', 'test-requirements.txt', 'zunclient/shell.py', 'zunclient/common/websocketclient/websocketclient.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/4029d7e3f9b279e458fda8c2d1268610213f6267', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I90423f032092352dd0b9abdf22344f419eed9fa5\n'}]",0,641356,4029d7e3f9b279e458fda8c2d1268610213f6267,3,1,2,28614,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I90423f032092352dd0b9abdf22344f419eed9fa5
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/56/641356/1 && git format-patch -1 --stdout FETCH_HEAD,"['zunclient/exceptions.py', 'test-requirements.txt', 'zunclient/shell.py', 'zunclient/common/websocketclient/websocketclient.py']",4,c846ae019199303c1ee20921d86614148fc34132,, select.POLLIN | select.POLLHUP | select.POLLPRI | select.POLLNVAL), select.POLLIN | select.POLLHUP | select.POLLPRI | select.POLLNVAL),21,23
openstack%2Fos-ken~master~I2edb11e6ae9bb6453bf0eea5bbf4607d4f34f554,openstack/os-ken,master,I2edb11e6ae9bb6453bf0eea5bbf4607d4f34f554,Update hacking version,ABANDONED,2019-03-06 13:54:02.000000000,2019-03-06 14:07:53.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 13:54:02.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-ken/commit/1446e883e80c2cadb1cec05f57ae8b30c25c2d3e', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I2edb11e6ae9bb6453bf0eea5bbf4607d4f34f554\n'}]",0,641360,1446e883e80c2cadb1cec05f57ae8b30c25c2d3e,2,1,1,28614,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I2edb11e6ae9bb6453bf0eea5bbf4607d4f34f554
",git fetch https://review.opendev.org/openstack/os-ken refs/changes/60/641360/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1446e883e80c2cadb1cec05f57ae8b30c25c2d3e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=0.12.0,<0.13 # Apache-2.0",1,1
openstack%2Fpython-cloudkittyclient~master~I1bed9aa23819a3c9c3b598b3d3bcf2148027e695,openstack/python-cloudkittyclient,master,I1bed9aa23819a3c9c3b598b3d3bcf2148027e695,Update hacking version,ABANDONED,2019-03-06 13:55:44.000000000,2019-03-06 14:07:50.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 13:55:44.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/b78b0c3586c75683c4a801eb22130e48481015f0', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I1bed9aa23819a3c9c3b598b3d3bcf2148027e695\n'}]",0,641362,b78b0c3586c75683c4a801eb22130e48481015f0,2,1,1,28614,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I1bed9aa23819a3c9c3b598b3d3bcf2148027e695
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/62/641362/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,b78b0c3586c75683c4a801eb22130e48481015f0,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-performance-tools~master~I80e4ab68233ee37134481b7286fc8c0cd127390e,openstack/os-performance-tools,master,I80e4ab68233ee37134481b7286fc8c0cd127390e,Update hacking version,ABANDONED,2019-03-06 13:58:31.000000000,2019-03-06 14:07:41.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 13:58:31.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-performance-tools/commit/5cf773d9582f38dfb310b426eea326a8496d1b5b', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I80e4ab68233ee37134481b7286fc8c0cd127390e\n'}]",0,641363,5cf773d9582f38dfb310b426eea326a8496d1b5b,2,1,1,28614,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I80e4ab68233ee37134481b7286fc8c0cd127390e
",git fetch https://review.opendev.org/openstack/os-performance-tools refs/changes/63/641363/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,5cf773d9582f38dfb310b426eea326a8496d1b5b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.11,>=0.10.0",1,1
openstack%2Fpython-heatclient~master~I786e01efffb7a4926b062fee761c62f65186b129,openstack/python-heatclient,master,I786e01efffb7a4926b062fee761c62f65186b129,Update hacking version,ABANDONED,2019-03-06 14:01:10.000000000,2019-03-06 14:07:38.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 14:01:10.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/106178a6e9001cc0ece540dd8eec1491b988a29b', 'message': 'Update hacking version\n\nChange-Id: I786e01efffb7a4926b062fee761c62f65186b129\n'}]",0,641365,106178a6e9001cc0ece540dd8eec1491b988a29b,2,1,1,28614,,,0,"Update hacking version

Change-Id: I786e01efffb7a4926b062fee761c62f65186b129
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/65/641365/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,106178a6e9001cc0ece540dd8eec1491b988a29b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-openstackclient~master~Ic10299c81bc233ae9bb4d719313f90407febe1ea,openstack/python-openstackclient,master,Ic10299c81bc233ae9bb4d719313f90407febe1ea,Update hacking version,ABANDONED,2019-03-06 14:04:52.000000000,2019-03-06 14:07:34.000000000,,[{'_account_id': 21691}],"[{'number': 1, 'created': '2019-03-06 14:04:52.000000000', 'files': ['openstackclient/tests/functional/network/v2/test_address_scope.py', 'test-requirements.txt', 'openstackclient/shell.py', 'openstackclient/tests/functional/image/v1/test_image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2ad762920916940d2477a98f307b79bb030c2a15', 'message': 'Update hacking version\n\nChange-Id: Ic10299c81bc233ae9bb4d719313f90407febe1ea\n'}]",0,641367,2ad762920916940d2477a98f307b79bb030c2a15,2,1,1,28614,,,0,"Update hacking version

Change-Id: Ic10299c81bc233ae9bb4d719313f90407febe1ea
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/67/641367/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/functional/network/v2/test_address_scope.py', 'test-requirements.txt', 'openstackclient/shell.py', 'openstackclient/tests/functional/image/v1/test_image.py']",4,2ad762920916940d2477a98f307b79bb030c2a15,, '--os-image-api-version 1 ' + self.openstack('--os-image-api-version 1 ' + 'image delete ' + self.image_id self.openstack('image set ' + '--min-disk 4 ' + '--min-ram 5 ' + '--disk-format qcow2 ' + '--public ' + self.name json_output = json.loads(self.openstack('image show -f json ' + self.name self.openstack('image set ' + '--property a=b ' + '--property c=d ' + '--public ' + self.name json_output = json.loads(self.openstack('image show -f json ' + self.name, '--os-image-api-version 1 ' self.openstack( '--os-image-api-version 1 ' 'image delete ' + self.image_id self.openstack( 'image set ' + '--min-disk 4 ' + '--min-ram 5 ' + '--disk-format qcow2 ' + '--public ' + self.name json_output = json.loads(self.openstack( 'image show -f json ' + self.name self.openstack( 'image set ' + '--property a=b ' + '--property c=d ' + '--public ' + self.name json_output = json.loads(self.openstack( 'image show -f json ' + self.name,41,51
openstack%2Fcookbook-openstack-identity~stable%2Fqueens~I10b31efe1e94fc69cda65e2f7fb7a669afb166ba,openstack/cookbook-openstack-identity,stable/queens,I10b31efe1e94fc69cda65e2f7fb7a669afb166ba,Stop overriding auth methods,MERGED,2019-03-05 11:05:55.000000000,2019-03-06 14:00:03.000000000,2019-03-06 14:00:03.000000000,"[{'_account_id': 11915}, {'_account_id': 19193}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 11:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/c35152c12a87da825d3469b6c0c1bf4290eb0c3d', 'message': ""Stop overriding auth methods\n\nSetting the keystone option [auth]/methods by default blocks additions\nlike application_credential that was newly added to Keystone in Queens.\nLet's stick to Keystone's defaults instead, deployments can override\nthese settings if they need to.\n\nAlso drop some even older version of these attributes that haven't been\nused at all anymore for some time.\n\nChange-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba\n(cherry picked from commit af1d3b1485d041d868537aa2bdccf5c25eba40b8)\n""}, {'number': 2, 'created': '2019-03-05 12:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/b2ed720a421443360b486670263266a0b6f7f0ef', 'message': ""Stop overriding auth methods\n\nSetting the keystone option [auth]/methods by default blocks additions\nlike application_credential that was newly added to Keystone in Queens.\nLet's stick to Keystone's defaults instead, deployments can override\nthese settings if they need to.\n\nAlso drop some even older version of these attributes that haven't been\nused at all anymore for some time.\n\nAdded version bump for stable/queens and pin for fog-openstack gem.\n\nChange-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba\n(cherry picked from commit af1d3b1485d041d868537aa2bdccf5c25eba40b8)\n""}, {'number': 3, 'created': '2019-03-05 12:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/5c1828fddac22f4b124e3eeccef546fefc2aa564', 'message': ""Stop overriding auth methods\n\nSetting the keystone option [auth]/methods by default blocks additions\nlike application_credential that was newly added to Keystone in Queens.\nLet's stick to Keystone's defaults instead, deployments can override\nthese settings if they need to.\n\nAlso drop some even older version of these attributes that haven't been\nused at all anymore for some time.\n\nAdded version bump for stable/queens.\n\nDepends-On: https://review.openstack.org/641002\nChange-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba\n(cherry picked from commit af1d3b1485d041d868537aa2bdccf5c25eba40b8)\n""}, {'number': 4, 'created': '2019-03-05 12:50:19.000000000', 'files': ['attributes/keystone_conf.rb', 'attributes/default.rb', 'metadata.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/b18165407738e9eb8dda9ab9855be692eb37c68d', 'message': ""Stop overriding auth methods\n\nSetting the keystone option [auth]/methods by default blocks additions\nlike application_credential that was newly added to Keystone in Queens.\nLet's stick to Keystone's defaults instead, deployments can override\nthese settings if they need to.\n\nAlso drop some even older version of these attributes that haven't been\nused at all anymore for some time.\n\nAdded version bump for stable/queens and pin for apache2 cookbook.\n\nChange-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba\n(cherry picked from commit af1d3b1485d041d868537aa2bdccf5c25eba40b8)\n""}]",0,640980,b18165407738e9eb8dda9ab9855be692eb37c68d,12,3,4,13252,,,0,"Stop overriding auth methods

Setting the keystone option [auth]/methods by default blocks additions
like application_credential that was newly added to Keystone in Queens.
Let's stick to Keystone's defaults instead, deployments can override
these settings if they need to.

Also drop some even older version of these attributes that haven't been
used at all anymore for some time.

Added version bump for stable/queens and pin for apache2 cookbook.

Change-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba
(cherry picked from commit af1d3b1485d041d868537aa2bdccf5c25eba40b8)
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/80/640980/3 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/keystone_conf.rb', 'attributes/default.rb']",2,c35152c12a87da825d3469b6c0c1bf4290eb0c3d,drop-auth-methods-stable/queens,,"# The external (REMOTE_USER) auth plugin module. (String value) default['openstack']['identity']['auth']['external'] = 'keystone.auth.plugins.external.DefaultDomain' # Default auth methods. (List value) default['openstack']['identity']['auth']['methods'] = 'external, password, token, oauth1' # Default auth_version for now default['openstack']['identity']['auth']['version'] = 'v3' ",0,12
openstack%2Fnetworking-sfc~master~I6e6072ce4d444032af2e65dafcb6719ffd2ec041,openstack/networking-sfc,master,I6e6072ce4d444032af2e65dafcb6719ffd2ec041,Fix unit tests on latest neutron,ABANDONED,2019-03-05 12:31:43.000000000,2019-03-06 13:57:12.000000000,,"[{'_account_id': 13294}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 12:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/eaad83c7dc905ae989595178f8ad223c550baa29', 'message': 'Fix unit tests on latest neutron\n\nSince [1], neutron.plugins.ml2.drivers.openvswitch.agent.\\\novs_agent_extension_api.OVSAgentExtensionAPI.__init_() has 4 params\ninstead of 3, which breaks unit tests.\n\nThis commit adds support for both options, while a permanent fix\nis found.\n\n[1] - https://review.openstack.org/406841\n\nChange-Id: I6e6072ce4d444032af2e65dafcb6719ffd2ec041\nCloses-Bug: #1818653\n'}, {'number': 2, 'created': '2019-03-06 11:37:20.000000000', 'files': ['networking_sfc/tests/unit/services/sfc/agent/extensions/test_sfc.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/f5c7153934fd2c2678e40a7aed0db6835870fbe9', 'message': 'Fix unit tests on latest neutron\n\nSince [1], neutron.plugins.ml2.drivers.openvswitch.agent.\\\novs_agent_extension_api.OVSAgentExtensionAPI.__init_() has 4 params\ninstead of 3, which breaks unit tests.\n\nThis commit adds support for both options, while a permanent fix\nis found.\n\n[1] - https://review.openstack.org/406841\n\nChange-Id: I6e6072ce4d444032af2e65dafcb6719ffd2ec041\nCloses-Bug: #1818653\n'}]",3,640999,f5c7153934fd2c2678e40a7aed0db6835870fbe9,10,4,2,13294,,,0,"Fix unit tests on latest neutron

Since [1], neutron.plugins.ml2.drivers.openvswitch.agent.\
ovs_agent_extension_api.OVSAgentExtensionAPI.__init_() has 4 params
instead of 3, which breaks unit tests.

This commit adds support for both options, while a permanent fix
is found.

[1] - https://review.openstack.org/406841

Change-Id: I6e6072ce4d444032af2e65dafcb6719ffd2ec041
Closes-Bug: #1818653
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/99/640999/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_sfc/tests/unit/services/sfc/agent/extensions/test_sfc.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py']",2,eaad83c7dc905ae989595178f8ad223c550baa29,bug/1818653," try: self.agent_api = ovs_ext_api.OVSAgentExtensionAPI( ovs_bridge.OVSAgentBridge('br-int'), ovs_bridge.OVSAgentBridge('br-tun')) except TypeError: # This method has three parameters after # https://review.openstack.org/406841 self.agent_api = ovs_ext_api.OVSAgentExtensionAPI( ovs_bridge.OVSAgentBridge('br-int'), ovs_bridge.OVSAgentBridge('br-tun'), ovs_bridge.OVSAgentBridge('br-phys'))"," self.agent_api = ovs_ext_api.OVSAgentExtensionAPI( ovs_bridge.OVSAgentBridge('br-int'), ovs_bridge.OVSAgentBridge('br-tun'))",22,6
openstack%2Fpython-monascaclient~master~I895bc58dafa250b1279ffe70f779c5cc1e865db1,openstack/python-monascaclient,master,I895bc58dafa250b1279ffe70f779c5cc1e865db1,Update json module to jsonutils,MERGED,2019-02-24 16:46:23.000000000,2019-03-06 13:55:38.000000000,2019-03-06 13:55:38.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-02-24 16:46:23.000000000', 'files': ['monascaclient/v2_0/shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/dde64fb95046904a8d402ca38f0f715fcba55a82', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and monascaclient  use it in many place[1],\nthis PS to update the remained json moudule to oslo jsonutils for\nconsistency.\n\n[1]: https://github.com/openstack/python-monascaclient/search?utf8=%E2%9C%93&q=jsonutils&type=\n\nChange-Id: I895bc58dafa250b1279ffe70f779c5cc1e865db1\n'}]",0,638987,dde64fb95046904a8d402ca38f0f715fcba55a82,15,4,1,22165,,,0,"Update json module to jsonutils

oslo project provide jsonutils, and monascaclient  use it in many place[1],
this PS to update the remained json moudule to oslo jsonutils for
consistency.

[1]: https://github.com/openstack/python-monascaclient/search?utf8=%E2%9C%93&q=jsonutils&type=

Change-Id: I895bc58dafa250b1279ffe70f779c5cc1e865db1
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/87/638987/1 && git format-patch -1 --stdout FETCH_HEAD,['monascaclient/v2_0/shell.py'],1,dde64fb95046904a8d402ca38f0f715fcba55a82,," type=jsonutils.loads,","import json type=json.loads,",1,2
openstack%2Fpython-zunclient~master~I80423f032092352dd0b9abdf22344f419eed9fa5,openstack/python-zunclient,master,I80423f032092352dd0b9abdf22344f419eed9fa5,Update hacking version,ABANDONED,2018-12-28 15:05:13.000000000,2019-03-06 13:46:25.000000000,,"[{'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/9b8ccc9d599c4d9c33641ca304bc35db7595b16b', 'message': 'Update hacking version\n\nChange-Id: I80423f032092352dd0b9abdf22344f419eed9fa5\n'}, {'number': 2, 'created': '2019-01-02 16:22:54.000000000', 'files': ['zunclient/exceptions.py', 'test-requirements.txt', 'zunclient/shell.py', 'zunclient/common/websocketclient/websocketclient.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/63e27f40b96f2673a6b74a6465a604bfafc03521', 'message': 'Update hacking version\n\nChange-Id: I80423f032092352dd0b9abdf22344f419eed9fa5\n'}]",0,627721,63e27f40b96f2673a6b74a6465a604bfafc03521,7,3,2,21691,,,0,"Update hacking version

Change-Id: I80423f032092352dd0b9abdf22344f419eed9fa5
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/21/627721/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,9b8ccc9d599c4d9c33641ca304bc35db7595b16b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-ken~master~I1edb11e6ae9bb6453bf0eea5bbf4607d4f34f554,openstack/os-ken,master,I1edb11e6ae9bb6453bf0eea5bbf4607d4f34f554,Update hacking version to latest,ABANDONED,2019-01-04 16:42:55.000000000,2019-03-06 13:46:22.000000000,,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2019-01-04 16:42:55.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-ken/commit/f65e55ac93533420ec53730088fb96d447c58d1e', 'message': 'Update hacking version to latest\n\nChange-Id: I1edb11e6ae9bb6453bf0eea5bbf4607d4f34f554\n'}]",0,628591,f65e55ac93533420ec53730088fb96d447c58d1e,4,2,1,21691,,,0,"Update hacking version to latest

Change-Id: I1edb11e6ae9bb6453bf0eea5bbf4607d4f34f554
",git fetch https://review.opendev.org/openstack/os-ken refs/changes/91/628591/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,f65e55ac93533420ec53730088fb96d447c58d1e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=0.12.0,<0.13 # Apache-2.0",1,1
openstack%2Fpython-cloudkittyclient~master~I2bed9aa23819a3c9c3b598b3d3bcf2148027e695,openstack/python-cloudkittyclient,master,I2bed9aa23819a3c9c3b598b3d3bcf2148027e695,Update hacking version,ABANDONED,2018-12-28 15:03:51.000000000,2019-03-06 13:46:18.000000000,,"[{'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 27781}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-12-28 15:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/447a8af895e8c05675656b26fab05cdad1ab4f98', 'message': 'Update hacking version\n\nChange-Id: I2bed9aa23819a3c9c3b598b3d3bcf2148027e695\n'}, {'number': 2, 'created': '2019-02-05 03:58:54.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/57c4213754a5c50b6475c02e2d550bf0d304ed23', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I2bed9aa23819a3c9c3b598b3d3bcf2148027e695\n'}]",0,627674,57c4213754a5c50b6475c02e2d550bf0d304ed23,10,4,2,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I2bed9aa23819a3c9c3b598b3d3bcf2148027e695
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/74/627674/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,447a8af895e8c05675656b26fab05cdad1ab4f98,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fnova~master~I42f530cbf637fc5721482e6f25391c46d42c3000,openstack/nova,master,I42f530cbf637fc5721482e6f25391c46d42c3000,Further de-dupe os-vif VIF tests,MERGED,2019-02-12 16:58:06.000000000,2019-03-06 13:45:20.000000000,2019-03-06 13:45:19.000000000,"[{'_account_id': 7}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-12 16:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cf0f7b150dbbffef84b8d26878bc819aaf0b736', 'message': 'Further de-dupe os-vif VIF tests\n\nThis is effectively part of Icc903834eee59993d89bd20eec39f67134353293\nbut is kept separate to make things _somewhat_ grokable.\n\nChange-Id: I42f530cbf637fc5721482e6f25391c46d42c3000\n'}, {'number': 2, 'created': '2019-02-13 17:19:42.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3d832a043e8e6707865a2207ef8428d318400113', 'message': 'Further de-dupe os-vif VIF tests\n\nThis is effectively part of Icc903834eee59993d89bd20eec39f67134353293\nbut is kept separate to make things _somewhat_ grokable.\n\nChange-Id: I42f530cbf637fc5721482e6f25391c46d42c3000\n'}]",0,636384,3d832a043e8e6707865a2207ef8428d318400113,22,10,2,15334,,,0,"Further de-dupe os-vif VIF tests

This is effectively part of Icc903834eee59993d89bd20eec39f67134353293
but is kept separate to make things _somewhat_ grokable.

Change-Id: I42f530cbf637fc5721482e6f25391c46d42c3000
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/636384/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_vif.py'],1,7cf0f7b150dbbffef84b8d26878bc819aaf0b736,add-noop-plugin," def _test_config_os_vif(self, os_vif_model, vif_model, libvirt_supports_mtu, expected_xml, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = os_vif_model xml = self._get_instance_xml(d, vif_model, has_min_libvirt_version=libvirt_supports_mtu) self._assertXmlEqual(expected_xml, node) def test_config_os_vif_bridge(self): os_vif_type = self.os_vif_bridge vif_type = self.vif_bridge libvirt_supports_mtu = True expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_bridge_no_mtu(self): os_vif_type = self.os_vif_bridge vif_type = self.vif_bridge libvirt_supports_mtu = False expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_bridge_nofw(self): os_vif_type = self.os_vif_bridge vif_type = self.vif_bridge libvirt_supports_mtu = True expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_bridge_nofw_no_mtu(self): os_vif_type = self.os_vif_bridge vif_type = self.vif_bridge libvirt_supports_mtu = False expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_vhostuser(self): os_vif_type = self.os_vif_vhostuser vif_type = self.vif_vhostuser libvirt_supports_mtu = False expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_agilio_ovs_fallthrough(self): os_vif_type = self.os_vif_agilio_ovs vif_type = self.vif_agilio_ovs libvirt_supports_mtu = True expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_agilio_ovs_fallthrough_no_mtu(self): os_vif_type = self.os_vif_agilio_ovs vif_type = self.vif_agilio_ovs libvirt_supports_mtu = False expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_agilio_ovs_forwarder(self): os_vif_type = self.os_vif_agilio_forwarder vif_type = self.vif_agilio_ovs_forwarder libvirt_supports_mtu = None # not supported for direct VIFs expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_agilio_ovs_direct(self): os_vif_type = self.os_vif_agilio_direct vif_type = self.vif_agilio_ovs_direct libvirt_supports_mtu = None # not supported for direct VIFs expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_ovs(self): os_vif_type = self.os_vif_ovs vif_type = self.vif_ovs libvirt_supports_mtu = True expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_ovs_no_mtu(self): os_vif_type = self.os_vif_ovs vif_type = self.vif_ovs libvirt_supports_mtu = False expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_ovs_hybrid(self): os_vif_type = self.os_vif_ovs_hybrid vif_type = self.vif_ovs libvirt_supports_mtu = True expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_ovs_hybrid_no_mtu(self): os_vif_type = self.os_vif_ovs_hybrid vif_type = self.vif_ovs libvirt_supports_mtu = False expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml) def test_config_os_vif_hostdevice_ethernet(self): os_vif_type = self.os_vif_hostdevice_ethernet vif_type = self.vif_bridge libvirt_supports_mtu = None # not supported for hostdev expected_xml = """""" </interface>"""""" self._test_config_os_vif( os_vif_type, vif_type, libvirt_supports_mtu, expected_xml)"," def test_config_os_vif_bridge(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_bridge xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=True) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_bridge_no_mtu(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_bridge mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_bridge_nofw(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_bridge mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=True) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_bridge_nofw_no_mtu(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_bridge mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_vhostuser(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_vhostuser mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_vhostuser) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_agilio_ovs_fallthrough(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_agilio_ovs mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_agilio_ovs, has_min_libvirt_version=True) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_agilio_ovs_fallthrough_no_mtu(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_agilio_ovs mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_agilio_ovs, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_agilio_ovs_forwarder(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_agilio_forwarder mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_agilio_ovs_forwarder) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_agilio_ovs_direct(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_agilio_direct mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_agilio_ovs_direct) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_ovs(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_ovs mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_ovs) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_ovs_no_mtu(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_ovs mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_ovs, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_ovs_hybrid(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_ovs_hybrid mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_ovs) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_ovs_hybrid_no_mtu(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_ovs_hybrid mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_ovs, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node) @mock.patch(""nova.network.os_vif_util.nova_to_osvif_instance"") @mock.patch(""nova.network.os_vif_util.nova_to_osvif_vif"") def test_config_os_vif_hostdevice_ethernet(self, mock_convert_vif, mock_convert_inst): mock_convert_vif.return_value = self.os_vif_hostdevice_ethernet mock_convert_inst.return_value = self.os_vif_inst_info d = vif.LibvirtGenericVIFDriver() xml = self._get_instance_xml(d, self.vif_bridge) node = self._get_node(xml) self._assertXmlEqual("""""" </interface>"""""", node)",124,160
openstack%2Fnova~master~Icc903834eee59993d89bd20eec39f67134353293,openstack/nova,master,Icc903834eee59993d89bd20eec39f67134353293,Validate bandwidth configuration for other VIF types,MERGED,2019-02-12 16:58:06.000000000,2019-03-06 13:45:11.000000000,2019-03-06 13:45:10.000000000,"[{'_account_id': 7}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-12 16:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b65ea88255dc8c01eca5771b75109fb0466274d3', 'message': ""Validate bandwidth configuration for other VIF types\n\nMultiple VIF types support bandwidth configuration but this was not\nbeing tested. Do this, DRY'ing the tests in the process.\n\nChange-Id: Icc903834eee59993d89bd20eec39f67134353293\nRelated-Bug: #1814882\n""}, {'number': 2, 'created': '2019-02-13 17:19:30.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d4f50979fc8ea02ee8e9f8425c2eeedc322791e8', 'message': ""Validate bandwidth configuration for other VIF types\n\nMultiple VIF types support bandwidth configuration but this was not\nbeing tested. Do this, DRY'ing the tests in the process.\n\nChange-Id: Icc903834eee59993d89bd20eec39f67134353293\nRelated-Bug: #1814882\n""}]",0,636383,d4f50979fc8ea02ee8e9f8425c2eeedc322791e8,22,10,2,15334,,,0,"Validate bandwidth configuration for other VIF types

Multiple VIF types support bandwidth configuration but this was not
being tested. Do this, DRY'ing the tests in the process.

Change-Id: Icc903834eee59993d89bd20eec39f67134353293
Related-Bug: #1814882
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/636383/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_vif.py'],1,b65ea88255dc8c01eca5771b75109fb0466274d3,add-noop-plugin," xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=True) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=True) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_bridge, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <target dev=""nicdc065497-3c""/> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_agilio_ovs, has_min_libvirt_version=True) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_agilio_ovs, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_agilio_ovs_forwarder) node = self._get_node(xml) <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source mode=""client"" path=""/var/run/openvswitch/vhudc065497-3c"" type=""unix""/> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_agilio_ovs_direct) node = self._get_node(xml) <mac address=""22:52:25:62:e2:aa""/> <source> <address type=""pci"" domain=""0x0000"" bus=""0x0a"" slot=""0x00"" function=""0x1""/> </source> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_ovs) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_ovs, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_ovs) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_ovs, has_min_libvirt_version=False) node = self._get_node(xml) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> <bandwidth> <inbound average=""100"" peak=""200"" burst=""300""/> <outbound average=""10"" peak=""20"" burst=""30""/> </bandwidth> </interface>"""""", node) xml = self._get_instance_xml(d, self.vif_bridge) node = self._get_node(xml) <mac address=""22:52:25:62:e2:aa""/> <source> <address type=""pci"" domain=""0x0000"" bus=""0x0a"" slot=""0x00"" function=""0x1""/> </source> </interface>"""""", node) self._get_instance_xml, d, self.vif_bridge)"," hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=True): cfg = d.get_config(self.instance, self.vif_bridge, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=False): cfg = d.get_config(self.instance, self.vif_bridge, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=True): cfg = d.get_config(self.instance, self.vif_bridge, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=False): cfg = d.get_config(self.instance, self.vif_bridge, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br100""/> <target dev=""nicdc065497-3c""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=True): cfg = d.get_config(self.instance, self.vif_agilio_ovs, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=False): cfg = d.get_config(self.instance, self.vif_agilio_ovs, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) d = vif.LibvirtGenericVIFDriver() cfg = d.get_config(self.instance, self.vif_agilio_ovs_forwarder, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source mode=""client"" path=""/var/run/openvswitch/vhudc065497-3c"" type=""unix""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) d = vif.LibvirtGenericVIFDriver() cfg = d.get_config(self.instance, self.vif_agilio_ovs_direct, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) <mac address=""22:52:25:62:e2:aa""/> <source> <address type=""pci"" domain=""0x0000"" bus=""0x0a"" slot=""0x00"" function=""0x1""/> </source> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=True): cfg = d.get_config(self.instance, self.vif_ovs, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=False): cfg = d.get_config(self.instance, self.vif_ovs, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <target dev=""nicdc065497-3c""/> <virtualport type=""openvswitch""> <parameters interfaceid=""07bd6cea-fb37-4594-b769-90fc51854ee9""/> </virtualport> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=True): cfg = d.get_config(self.instance, self.vif_ovs, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <mtu size=""9000""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) with mock.patch.object(d, ""_has_min_version_for_mtu"", return_value=False): cfg = d.get_config(self.instance, self.vif_ovs, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) self._assertXmlEqual("""""" <interface type=""bridge""> <mac address=""22:52:25:62:e2:aa""/> <model type=""virtio""/> <source bridge=""br0""/> <target dev=""nicdc065497-3c""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) cfg = d.get_config(self.instance, self.vif_bridge, image_meta, flavor, CONF.libvirt.virt_type, hostimpl) <mac address=""22:52:25:62:e2:aa""/> <source> <address type=""pci"" domain=""0x0000"" bus=""0x0a"" slot=""0x00"" function=""0x1""/> </source> </interface>"""""", cfg.to_xml()) hostimpl = host.Host(""qemu:///system"") flavor = objects.Flavor(name='m1.small') image_meta = objects.ImageMeta.from_dict({}) d.get_config, self.instance, self.vif_bridge, image_meta, flavor, CONF.libvirt.virt_type, hostimpl)",185,235
openstack%2Fos-performance-tools~master~I90e4ab68233ee37134481b7286fc8c0cd127390e,openstack/os-performance-tools,master,I90e4ab68233ee37134481b7286fc8c0cd127390e,Update hacking version to latest,ABANDONED,2019-01-04 16:42:57.000000000,2019-03-06 13:45:08.000000000,,"[{'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-01-04 16:42:57.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-performance-tools/commit/170b68dd8ff411f04c3901d3c8eec8cedd4c5dd6', 'message': 'Update hacking version to latest\n\nChange-Id: I90e4ab68233ee37134481b7286fc8c0cd127390e\n'}]",0,628595,170b68dd8ff411f04c3901d3c8eec8cedd4c5dd6,5,2,1,21691,,,0,"Update hacking version to latest

Change-Id: I90e4ab68233ee37134481b7286fc8c0cd127390e
",git fetch https://review.opendev.org/openstack/os-performance-tools refs/changes/95/628595/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,170b68dd8ff411f04c3901d3c8eec8cedd4c5dd6,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.11,>=0.10.0",1,1
openstack%2Ftempest~master~I5068d96105a22cbfd33f5900f4bdc21b47a65c06,openstack/tempest,master,I5068d96105a22cbfd33f5900f4bdc21b47a65c06,Improved tempest plugin sanity check script,MERGED,2017-11-30 13:26:18.000000000,2019-03-06 13:45:06.000000000,2019-03-06 13:45:06.000000000,"[{'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 5690}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23186}, {'_account_id': 27078}]","[{'number': 1, 'created': '2017-11-30 13:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d88b202e8d7d207c41e81438fe109f796ec8de7a', 'message': 'Fixed binary operator expected shell error\n\n* tempest plugin sanity check script is failing to uninstall\n  the packages from *requirements.txt by giving binary operator\n  expected error. It fixes the issue by checking one file at a\n  time.\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 2, 'created': '2017-11-30 13:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/46a860d788005e0498bd85d7cd3c9beadeb6575d', 'message': ""Fixed binary operator expected shell error\n\n* tempest plugin sanity check script is failing to uninstall\n  the packages from *requirements.txt by giving binary operator\n  expected error. It fixes the issue by checking one file at a\n  time.\n\n* use pip install -e . for installing tempest which will also\n  install packages from tempest's requirements.txt.\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n""}, {'number': 3, 'created': '2017-12-05 06:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5fd26a980948d8bf3c82e593fce7555f46427b03', 'message': 'Fixed tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 4, 'created': '2017-12-06 08:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/00c7ee13138a198c8ce774ae3d84879db77f9fbc', 'message': 'Fixed tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 5, 'created': '2017-12-06 15:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/953b799f862fa74024d06e4076bb42aa4b32a1e1', 'message': 'Fixed tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 6, 'created': '2017-12-06 18:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a1fb64299a267b3250a68a8c450b119b9ec4fefa', 'message': 'Fixed tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 7, 'created': '2018-03-10 15:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c8139d69f0fcd78e48f7488976ef4b99a2fc183a', 'message': 'Improved tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 8, 'created': '2018-07-26 08:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2885f7e92ae80f0aa76100b7fd9fe79ad2c0d0c6', 'message': 'Improved tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 9, 'created': '2018-08-06 06:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1fb62d9d54f79af3bab47075e029e36a6bca3798', 'message': 'Improved tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 10, 'created': '2018-08-06 08:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f591767572a18207cd9b8865917613e665b4643f', 'message': 'Improved tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 11, 'created': '2018-09-14 16:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0f8e6a73f9400fa59e0cbc42fd478e5ae13fbbd8', 'message': 'Improved tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 12, 'created': '2019-01-30 06:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3ff1231747d51dadce4c2e8ce8bdab53b00e2ac8', 'message': 'Improved tempest plugin sanity check script\n\n* Removes the venv and project as the script fails to uninstall\n  the dependencies.\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 13, 'created': '2019-02-01 08:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7cb1a6de07d712765d97926dd87b44b5accab1e9', 'message': 'Improved tempest plugin sanity check script\n\n* To use a fresh venv, use `--clear` option when creating a virtualenv\n* Removes the project as the script fails to uninstall the dependencies.\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 14, 'created': '2019-02-01 09:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/df3f1b6adcdbb5579e610fb4ca36eff8cc2c4641', 'message': 'Improved tempest plugin sanity check script\n\n* To use a fresh venv, use `--clear` option when creating a virtualenv\n* Removes the project as the script fails to uninstall the dependencies.\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 15, 'created': '2019-02-21 06:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/319451b4558f580f5fd9d88794725538f2c637bb', 'message': 'Improved tempest plugin sanity check script\n\n* To use a fresh venv, use `--clear` option when creating a virtualenv\n* Removes the project as the script fails to uninstall the dependencies.\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n* Adds some plugins to BLACKLIST to avoid errors\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}, {'number': 16, 'created': '2019-02-25 04:09:20.000000000', 'files': ['.zuul.yaml', 'tools/tempest-plugin-sanity.sh'], 'web_link': 'https://opendev.org/openstack/tempest/commit/97b1ad78ac96592b379c940e88ea1967757a228c', 'message': 'Improved tempest plugin sanity check script\n\n* To use a fresh venv, use `--clear` option when creating a virtualenv\n* Removes the project as the script fails to uninstall the dependencies.\n* Added missing tempest plugins\n* Log the stdout of each plugin in a file\n* Adds some plugins to BLACKLIST to avoid errors\n\nChange-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06\n'}]",17,524176,97b1ad78ac96592b379c940e88ea1967757a228c,107,13,16,12393,,,0,"Improved tempest plugin sanity check script

* To use a fresh venv, use `--clear` option when creating a virtualenv
* Removes the project as the script fails to uninstall the dependencies.
* Added missing tempest plugins
* Log the stdout of each plugin in a file
* Adds some plugins to BLACKLIST to avoid errors

Change-Id: I5068d96105a22cbfd33f5900f4bdc21b47a65c06
",git fetch https://review.opendev.org/openstack/tempest refs/changes/76/524176/16 && git format-patch -1 --stdout FETCH_HEAD,['tools/tempest-plugin-sanity.sh'],1,d88b202e8d7d207c41e81438fe109f796ec8de7a,tempest-sanity-gate," if [ -e ""$SANITY_DIR""/openstack/""$1""/requirements.txt ]; then ""$TVENV"" pip uninstall -y -r ""$SANITY_DIR""/openstack/""$1""/requirements.txt if [ -e ""$SANITY_DIR""/openstack/""$1""/test-requirements.txt ]; then ""$TVENV"" pip uninstall -y -r ""$SANITY_DIR""/openstack/""$1""/test-requirements.txt fi "," if [ -e ""$SANITY_DIR""/openstack/""$1""/*requirements.txt ]; then ""$TVENV"" pip uninstall -y -r ""$SANITY_DIR""/openstack/""$1""/*requirements.txt",6,2
openstack%2Fpython-brick-cinderclient-ext~master~I0bd8755e9ff4e9b848ef6630892ca1c814010a9b,openstack/python-brick-cinderclient-ext,master,I0bd8755e9ff4e9b848ef6630892ca1c814010a9b,Update hacking version,ABANDONED,2018-12-28 15:03:46.000000000,2019-03-06 13:45:05.000000000,,"[{'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2018-12-28 15:03:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/5e67661ebbb74bcd689d4014e70914928f352ac2', 'message': 'Update hacking version\n\nChange-Id: I0bd8755e9ff4e9b848ef6630892ca1c814010a9b\n'}]",0,627668,5e67661ebbb74bcd689d4014e70914928f352ac2,4,2,1,21691,,,0,"Update hacking version

Change-Id: I0bd8755e9ff4e9b848ef6630892ca1c814010a9b
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/68/627668/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,5e67661ebbb74bcd689d4014e70914928f352ac2,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.11,>=0.10.0",1,1
openstack%2Fpython-magnumclient~master~I5677f202fb1f29de731fd802675189815f47814e,openstack/python-magnumclient,master,I5677f202fb1f29de731fd802675189815f47814e,Update hacking version,ABANDONED,2018-12-28 15:04:15.000000000,2019-03-06 13:44:57.000000000,,"[{'_account_id': 22348}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:04:15.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/03934f9bb70dc26ecfc1ee6f2e20b451741a30dc', 'message': 'Update hacking version\n\nChange-Id: I5677f202fb1f29de731fd802675189815f47814e\n'}]",0,627694,03934f9bb70dc26ecfc1ee6f2e20b451741a30dc,4,2,1,21691,,,0,"Update hacking version

Change-Id: I5677f202fb1f29de731fd802675189815f47814e
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/94/627694/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,03934f9bb70dc26ecfc1ee6f2e20b451741a30dc,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-heatclient~master~I766e01efffb7a4926b062fee761c62f65186b129,openstack/python-heatclient,master,I766e01efffb7a4926b062fee761c62f65186b129,Update hacking version,ABANDONED,2018-12-28 15:04:04.000000000,2019-03-06 13:44:51.000000000,,"[{'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 15:04:04.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/debc1a701b1cdd38fbec391c49556eed3d598254', 'message': 'Update hacking version\n\nChange-Id: I766e01efffb7a4926b062fee761c62f65186b129\n'}]",0,627685,debc1a701b1cdd38fbec391c49556eed3d598254,5,3,1,21691,,,0,"Update hacking version

Change-Id: I766e01efffb7a4926b062fee761c62f65186b129
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/85/627685/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,debc1a701b1cdd38fbec391c49556eed3d598254,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-openstackclient~master~I910199c81bc233ae9bb3d719313f90407febe1ea,openstack/python-openstackclient,master,I910199c81bc233ae9bb3d719313f90407febe1ea,Update hacking version,ABANDONED,2018-12-28 15:04:41.000000000,2019-03-06 13:44:38.000000000,,"[{'_account_id': 841}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2018-12-28 15:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/08b48c9b0545893833f73594c30ef5c6c74cbb5f', 'message': 'Update hacking version\n\nChange-Id: I910199c81bc233ae9bb3d719313f90407febe1ea\n'}, {'number': 2, 'created': '2019-01-02 16:38:51.000000000', 'files': ['openstackclient/tests/functional/network/v2/test_address_scope.py', 'test-requirements.txt', 'openstackclient/shell.py', 'openstackclient/tests/functional/image/v1/test_image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/77db7e3d90de2119858f59900774d27a093987c7', 'message': 'Update hacking version\n\nChange-Id: I910199c81bc233ae9bb3d719313f90407febe1ea\n'}]",0,627705,77db7e3d90de2119858f59900774d27a093987c7,10,4,2,21691,,,0,"Update hacking version

Change-Id: I910199c81bc233ae9bb3d719313f90407febe1ea
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/05/627705/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,08b48c9b0545893833f73594c30ef5c6c74cbb5f,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-acc~master~I6bf148cef47f930e604e323af0766bb98e98c9d9,openstack/os-acc,master,I6bf148cef47f930e604e323af0766bb98e98c9d9,Update hacking version to latest,ABANDONED,2019-01-04 16:42:55.000000000,2019-03-06 13:44:33.000000000,,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2019-01-04 16:42:55.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-acc/commit/71bf1780eea492452cef0a5ad5388a482780c6da', 'message': 'Update hacking version to latest\n\nChange-Id: I6bf148cef47f930e604e323af0766bb98e98c9d9\n'}]",0,628590,71bf1780eea492452cef0a5ad5388a482780c6da,4,2,1,21691,,,0,"Update hacking version to latest

Change-Id: I6bf148cef47f930e604e323af0766bb98e98c9d9
",git fetch https://review.opendev.org/openstack/os-acc refs/changes/90/628590/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,71bf1780eea492452cef0a5ad5388a482780c6da,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.11,>=0.10.2",1,1
openstack%2Fos-collect-config~master~I128cbebb96c07a306b49397bcf2bea76a53c20c9,openstack/os-collect-config,master,I128cbebb96c07a306b49397bcf2bea76a53c20c9,Update hacking version to latest,ABANDONED,2019-01-04 16:42:59.000000000,2019-03-06 13:44:30.000000000,,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2019-01-04 16:42:59.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/e53b8d3bfcbd7b737e17fd9f7e132545f3712071', 'message': 'Update hacking version to latest\n\nChange-Id: I128cbebb96c07a306b49397bcf2bea76a53c20c9\n'}]",0,628598,e53b8d3bfcbd7b737e17fd9f7e132545f3712071,4,2,1,21691,,,0,"Update hacking version to latest

Change-Id: I128cbebb96c07a306b49397bcf2bea76a53c20c9
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/98/628598/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e53b8d3bfcbd7b737e17fd9f7e132545f3712071,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-refresh-config~master~Id843a98c6f9d542c49053c3c954a515aa2aa2a95,openstack/os-refresh-config,master,Id843a98c6f9d542c49053c3c954a515aa2aa2a95,Update hacking version to latest,ABANDONED,2019-01-04 16:43:07.000000000,2019-03-06 13:44:27.000000000,,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2019-01-04 16:43:07.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-refresh-config/commit/ae73e1e595cc7ea4d5852e005fed3ff34b62dfc3', 'message': 'Update hacking version to latest\n\nChange-Id: Id843a98c6f9d542c49053c3c954a515aa2aa2a95\n'}]",0,628607,ae73e1e595cc7ea4d5852e005fed3ff34b62dfc3,4,2,1,21691,,,0,"Update hacking version to latest

Change-Id: Id843a98c6f9d542c49053c3c954a515aa2aa2a95
",git fetch https://review.opendev.org/openstack/os-refresh-config refs/changes/07/628607/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ae73e1e595cc7ea4d5852e005fed3ff34b62dfc3,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Ftripleo-quickstart-extras~master~I42b3f61b734cb8872f52a9e78ed85c8cc861cbe2,openstack/tripleo-quickstart-extras,master,I42b3f61b734cb8872f52a9e78ed85c8cc861cbe2,[DNM] testing os_tempest skip list Added whitelist test: tempest.api.volume.test_volumes_snapshots from master skip list: tempest.api.volume.test_volumes_snapshots.VolumesSnapshotTestJSON https://github.com/openstack/tripleo-quickstart-extras/blob/master /roles/validate-tempest/vars/tempest_skip_master.yml#L20,ABANDONED,2019-03-06 09:36:32.000000000,2019-03-06 13:44:25.000000000,,"[{'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 09:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/239dde9a28c869595cbc204061a02e97612bf17b', 'message': '[DNM] testing os_tempest skip list\nAdded whitelist test:\ntempest.api.volume.test_volumes_snapshots\nfrom master skip list:\ntempest.api.volume.test_volumes_snapshots.VolumesSnapshotTestJSON\nhttps://github.com/openstack/tripleo-quickstart-extras/blob/master\n/roles/validate-tempest/vars/tempest_skip_master.yml#L20\n\nChange-Id: I42b3f61b734cb8872f52a9e78ed85c8cc861cbe2\n'}, {'number': 2, 'created': '2019-03-06 10:46:29.000000000', 'files': ['playbooks/tempest.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/961191861757406ed9ce9e705892fb1ff40b4d06', 'message': '[DNM] testing os_tempest skip list\nAdded whitelist test:\ntempest.api.volume.test_volumes_snapshots\nfrom master skip list:\ntempest.api.volume.test_volumes_snapshots.VolumesSnapshotTestJSON\nhttps://github.com/openstack/tripleo-quickstart-extras/blob/master\n/roles/validate-tempest/vars/tempest_skip_master.yml#L20\n\nDepends-On: https://review.openstack.org/#/c/638272/\n\nChange-Id: I42b3f61b734cb8872f52a9e78ed85c8cc861cbe2\n'}]",0,641287,961191861757406ed9ce9e705892fb1ff40b4d06,8,4,2,12393,,,0,"[DNM] testing os_tempest skip list
Added whitelist test:
tempest.api.volume.test_volumes_snapshots
from master skip list:
tempest.api.volume.test_volumes_snapshots.VolumesSnapshotTestJSON
https://github.com/openstack/tripleo-quickstart-extras/blob/master
/roles/validate-tempest/vars/tempest_skip_master.yml#L20

Depends-On: https://review.openstack.org/#/c/638272/

Change-Id: I42b3f61b734cb8872f52a9e78ed85c8cc861cbe2
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/87/641287/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tempest.yml'],1,239dde9a28c869595cbc204061a02e97612bf17b,testing_skip_list, - 'tempest.api.volume.test_volumes_snapshots',,1,0
openstack%2Fbarbican-tempest-plugin~master~Idcccc4b690060d24e0493e72cf37544f25eaebed,openstack/barbican-tempest-plugin,master,Idcccc4b690060d24e0493e72cf37544f25eaebed,Update the bugs link to storyboard,ABANDONED,2018-12-30 15:48:30.000000000,2019-03-06 13:44:24.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2018-12-30 15:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/9960dcf473c997637077f1e11c3bc7fbc886cecf', 'message': 'Update the bugs link to storyboard\n\nChange-Id: Idcccc4b690060d24e0493e72cf37544f25eaebed\n'}, {'number': 2, 'created': '2018-12-31 12:31:54.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/df956e6d5bea0206fa5dfbb2c32abf3a5432fbe5', 'message': 'Update the bugs link to storyboard\n\nChange-Id: Idcccc4b690060d24e0493e72cf37544f25eaebed\n'}]",2,627827,df956e6d5bea0206fa5dfbb2c32abf3a5432fbe5,11,3,2,21691,,,0,"Update the bugs link to storyboard

Change-Id: Idcccc4b690060d24e0493e72cf37544f25eaebed
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/27/627827/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,9960dcf473c997637077f1e11c3bc7fbc886cecf,, https://storyboard.openstack.org/#!/project/982 , https://bugs.launchpad.net/barbican,1,1
openstack%2Fos-win~master~I0203d537d096008909187c06001410082005359a,openstack/os-win,master,I0203d537d096008909187c06001410082005359a,Update hacking version,ABANDONED,2019-01-04 16:43:29.000000000,2019-03-06 13:44:13.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2019-01-04 16:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/12038177e99a9d22dd83c2e030583c9b8192615e', 'message': 'Update hacking version to latest\n\nChange-Id: I0203d537d096008909187c06001410082005359a\n'}, {'number': 2, 'created': '2019-01-06 11:08:05.000000000', 'files': ['test-requirements.txt', 'os_win/utils/baseutils.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/b2842ad0a15cf3f101b2020910127142e8a37998', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I0203d537d096008909187c06001410082005359a\n'}]",0,628609,b2842ad0a15cf3f101b2020910127142e8a37998,7,3,2,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I0203d537d096008909187c06001410082005359a
",git fetch https://review.opendev.org/openstack/os-win refs/changes/09/628609/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,12038177e99a9d22dd83c2e030583c9b8192615e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-resource-classes~master~I5144fbfc73c2941a5a0f52772d39c111c8307e31,openstack/os-resource-classes,master,I5144fbfc73c2941a5a0f52772d39c111c8307e31,Update hacking version to latest,ABANDONED,2019-01-04 16:43:00.000000000,2019-03-06 13:44:09.000000000,,"[{'_account_id': 7634}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-01-04 16:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/236ebe18d6ecefb271dc2b7f9749a51cef1bb81b', 'message': 'Update hacking version to latest\n\nChange-Id: I5144fbfc73c2941a5a0f52772d39c111c8307e31\n'}, {'number': 2, 'created': '2019-01-07 18:59:47.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-resource-classes/commit/274f6cb9b3c0b414db8a4f3db001cbdad0606abd', 'message': 'Update hacking version to latest\n\nChange-Id: I5144fbfc73c2941a5a0f52772d39c111c8307e31\n'}]",0,628599,274f6cb9b3c0b414db8a4f3db001cbdad0606abd,11,5,2,21691,,,0,"Update hacking version to latest

Change-Id: I5144fbfc73c2941a5a0f52772d39c111c8307e31
",git fetch https://review.opendev.org/openstack/os-resource-classes refs/changes/99/628599/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,236ebe18d6ecefb271dc2b7f9749a51cef1bb81b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=0.12.0,<0.13 # Apache-2.0",1,1
openstack%2Fpython-solumclient~master~Ie34a9e29a73835d2ba74fe4b4561071ae63093af,openstack/python-solumclient,master,Ie34a9e29a73835d2ba74fe4b4561071ae63093af,Update hacking version,ABANDONED,2018-12-28 15:04:44.000000000,2019-03-06 13:44:04.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-12-28 15:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/c82932932367600e9e6060e7471de4915df85353', 'message': 'Update hacking version\n\nChange-Id: Ie34a9e29a73835d2ba74fe4b4561071ae63093af\n'}, {'number': 2, 'created': '2019-02-05 03:53:52.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/051541bc2a8db7d4ab774a8c948e5de6f64c2ffe', 'message': 'Update hacking version\n\nChange-Id: Ie34a9e29a73835d2ba74fe4b4561071ae63093af\n'}]",0,627706,051541bc2a8db7d4ab774a8c948e5de6f64c2ffe,8,4,2,21691,,,0,"Update hacking version

Change-Id: Ie34a9e29a73835d2ba74fe4b4561071ae63093af
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/06/627706/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c82932932367600e9e6060e7471de4915df85353,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-apply-config~master~I262464e2c5a9b400776bca08ddd930cd76df6928,openstack/os-apply-config,master,I262464e2c5a9b400776bca08ddd930cd76df6928,Update hacking version,ABANDONED,2019-01-04 16:43:00.000000000,2019-03-06 13:44:00.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-01-04 16:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/7af73439d7d826c7245256acb516c9adfc95cf37', 'message': 'Update hacking version to latest\n\nChange-Id: I262464e2c5a9b400776bca08ddd930cd76df6928\n'}, {'number': 2, 'created': '2019-01-06 11:11:11.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/d2856395886448140a4827eef2fe4717bbfa581e', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I262464e2c5a9b400776bca08ddd930cd76df6928\n'}]",0,628600,d2856395886448140a4827eef2fe4717bbfa581e,7,3,2,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I262464e2c5a9b400776bca08ddd930cd76df6928
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/00/628600/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7af73439d7d826c7245256acb516c9adfc95cf37,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-karborclient~master~Iaedc66f31b9e604fd9f4686afc6cf4792ca128cf,openstack/python-karborclient,master,Iaedc66f31b9e604fd9f4686afc6cf4792ca128cf,Update hacking version,ABANDONED,2018-12-28 15:04:11.000000000,2019-03-06 13:43:55.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-12-28 15:04:11.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-karborclient/commit/c2ab151fbd7f69692c34f4b883cb2598128b5c6d', 'message': 'Update hacking version\n\nChange-Id: Iaedc66f31b9e604fd9f4686afc6cf4792ca128cf\n'}]",0,627691,c2ab151fbd7f69692c34f4b883cb2598128b5c6d,6,4,1,21691,,,0,"Update hacking version

Change-Id: Iaedc66f31b9e604fd9f4686afc6cf4792ca128cf
",git fetch https://review.opendev.org/openstack/python-karborclient refs/changes/91/627691/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c2ab151fbd7f69692c34f4b883cb2598128b5c6d,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Ftuning-box~master~I15da0d959f365722d8e7caedd8690b955c758570,openstack/tuning-box,master,I15da0d959f365722d8e7caedd8690b955c758570,Update the hacking to latest,ABANDONED,2018-10-16 15:46:00.000000000,2019-03-06 13:42:10.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27781}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-10-16 15:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tuning-box/commit/432bd914a86bb625e70acbe501d07fe570d01b62', 'message': 'Update the hacking to latst\n\nChange-Id: I15da0d959f365722d8e7caedd8690b955c758570\n'}, {'number': 2, 'created': '2018-10-18 07:32:21.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tuning-box/commit/ae7f9e0686cf71d88daa39411a4da27d74294a93', 'message': 'Update the hacking to latest\n\nChange-Id: I15da0d959f365722d8e7caedd8690b955c758570\n'}]",2,611029,ae7f9e0686cf71d88daa39411a4da27d74294a93,11,5,2,21691,,,0,"Update the hacking to latest

Change-Id: I15da0d959f365722d8e7caedd8690b955c758570
",git fetch https://review.opendev.org/openstack/tuning-box refs/changes/29/611029/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,432bd914a86bb625e70acbe501d07fe570d01b62,,============================= Read the OpenStack Style Commandments https://docs.openstack.org/hacking/latest/ ,=============================================== Read the OpenStack Style Commandments http://docs.openstack.org/developer/hacking/,2,2
openstack%2Fopenstack-ansible-os_searchlight~master~Iad5424cc4678ea396c4617acddf3c84ae9d18855,openstack/openstack-ansible-os_searchlight,master,Iad5424cc4678ea396c4617acddf3c84ae9d18855,Completed required variables for README.rst,ABANDONED,2018-07-19 15:05:08.000000000,2019-03-06 13:41:57.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-07-19 15:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_searchlight/commit/6542da2826a3581dacb423b6b064b56c043e4c86', 'message': 'Completed required variables for README.rst\n\nChange-Id: Iad5424cc4678ea396c4617acddf3c84ae9d18855\n'}, {'number': 2, 'created': '2018-07-19 15:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_searchlight/commit/84c8da2a551f92b18894e7bc254e088be0648b2f', 'message': 'Completed required variables for README.rst\n\nChange-Id: Iad5424cc4678ea396c4617acddf3c84ae9d18855\n'}, {'number': 3, 'created': '2018-12-08 17:31:28.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_searchlight/commit/ffb314a7de6b2e4a91c77fb7604ab2c86806e510', 'message': 'Completed required variables for README.rst\n\nChange-Id: Iad5424cc4678ea396c4617acddf3c84ae9d18855\n'}]",0,583983,ffb314a7de6b2e4a91c77fb7604ab2c86806e510,8,2,3,21691,,,0,"Completed required variables for README.rst

Change-Id: Iad5424cc4678ea396c4617acddf3c84ae9d18855
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_searchlight refs/changes/83/583983/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,6542da2826a3581dacb423b6b064b56c043e4c86,," elasticsearch_apt_java_package: ""openjdk-8-jre"" searchlight_rabbitmq_userid: searchlight searchlight_rabbitmq_vhost: /searchlight searchlight_rabbitmq_servers: ""{{ rabbitmq_servers }}"" searchlight_rabbitmq_port: ""{{ rabbitmq_port }}"" searchlight_rabbitmq_use_ssl: ""{{ rabbitmq_use_ssl }}"".. code-block:: yaml - name: Installation and setup of Searchlight hosts: keystone_all user: root roles: - role: elasticsearch - role: ""os_searchlight"" searchlight_venv_tag: ""{{ openstack_release }}"" searchlight_venv_download_url: ""{{ openstack_repo_url }}/venvs/{{ openstack_release }}/{{ ansible_distribution | lower }}/searchlight-{{ openstack_release }}-{{ ansible_architecture | lower }}.tgz"" pip_lock_to_internal_repo: ""{{ (pip_links | length) >= 1 }}"" tags: - ""os-searchlight"" vars: elasticsearch_apt_java_package: ""openjdk-8-jre"" searchlight_rabbitmq_userid: searchlight searchlight_rabbitmq_vhost: /searchlight searchlight_rabbitmq_servers: ""{{ rabbitmq_servers }}"" searchlight_rabbitmq_port: ""{{ rabbitmq_port }}"" searchlight_rabbitmq_use_ssl: ""{{ rabbitmq_use_ssl }}"""," elasticsearch_apt_java_package: ""openjdk-8-jre"" searchlight_rabbitmq_userid: searchlight searchlight_rabbitmq_vhost: /searchlight searchlight_rabbitmq_servers: ""{{ rabbitmq_servers }}"" searchlight_rabbitmq_port: ""{{ rabbitmq_port }}"" searchlight_rabbitmq_use_ssl: ""{{ rabbitmq_use_ssl }}"".. code-block:: yaml - name: Installation and setup of Searchlight hosts: keystone_all user: root roles: - role: elasticsearch - role: ""os_searchlight"" searchlight_venv_tag: ""{{ openstack_release }}"" searchlight_venv_download_url: ""{{ openstack_repo_url }}/venvs/{{ openstack_release }}/{{ ansible_distribution | lower }}/searchlight-{{ openstack_release }}-{{ ansible_architecture | lower }}.tgz"" pip_lock_to_internal_repo: ""{{ (pip_links | length) >= 1 }}"" tags: - ""os-searchlight"" vars: elasticsearch_apt_java_package: ""openjdk-8-jre"" searchlight_rabbitmq_userid: searchlight searchlight_rabbitmq_vhost: /searchlight searchlight_rabbitmq_servers: ""{{ rabbitmq_servers }}"" searchlight_rabbitmq_port: ""{{ rabbitmq_port }}"" searchlight_rabbitmq_use_ssl: ""{{ rabbitmq_use_ssl }}""",25,25
openstack%2Fbarbican-tempest-plugin~master~Iafa82f305c44f34d3f8b820b34957c6486884d50,openstack/barbican-tempest-plugin,master,Iafa82f305c44f34d3f8b820b34957c6486884d50,Update the hacking to latest,ABANDONED,2018-10-16 15:47:52.000000000,2019-03-06 13:40:42.000000000,,"[{'_account_id': 22348}, {'_account_id': 27078}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-10-16 15:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/228816cde5ceab1a24a34766a7d5338e6c2f7e04', 'message': 'Update the hacking to latst\n\nChange-Id: Iafa82f305c44f34d3f8b820b34957c6486884d50\n'}, {'number': 2, 'created': '2018-10-16 16:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/df1aa23461267e4e12e4f76a8f9ac468309675fb', 'message': 'Update the hacking to latst\n\nChange-Id: Iafa82f305c44f34d3f8b820b34957c6486884d50\n'}, {'number': 3, 'created': '2018-10-18 07:59:30.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/17550e8fdb5b097a7e51443634d673dc5af24317', 'message': 'Update the hacking to latest\n\nChange-Id: Iafa82f305c44f34d3f8b820b34957c6486884d50\n'}]",2,611049,17550e8fdb5b097a7e51443634d673dc5af24317,12,5,3,21691,,,0,"Update the hacking to latest

Change-Id: Iafa82f305c44f34d3f8b820b34957c6486884d50
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/49/611049/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,228816cde5ceab1a24a34766a7d5338e6c2f7e04,,========================================== Read the OpenStack Style Commandments https://docs.openstack.org/hacking/latest/ ,=============================================== Read the OpenStack Style Commandments http://docs.openstack.org/developer/hacking/,2,2
openstack%2Fpython-tricircleclient~master~Iedeea626b9b9809d3b4977761ba1b0240c10e305,openstack/python-tricircleclient,master,Iedeea626b9b9809d3b4977761ba1b0240c10e305,Update hacking version,ABANDONED,2018-12-28 15:05:06.000000000,2019-03-06 13:40:38.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-12-28 15:05:06.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/8cafe1fc9593f89b541daae3a4ec2110cf1513fb', 'message': 'Update hacking version\n\nChange-Id: Iedeea626b9b9809d3b4977761ba1b0240c10e305\n'}]",0,627718,8cafe1fc9593f89b541daae3a4ec2110cf1513fb,5,3,1,21691,,,0,"Update hacking version

Change-Id: Iedeea626b9b9809d3b4977761ba1b0240c10e305
",git fetch https://review.opendev.org/openstack/python-tricircleclient refs/changes/18/627718/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,8cafe1fc9593f89b541daae3a4ec2110cf1513fb,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fos-client-config~master~I70f0fb12fba34ef01ccf2b1afedeeada122ae1af,openstack/os-client-config,master,I70f0fb12fba34ef01ccf2b1afedeeada122ae1af,Update hacking version to latest,ABANDONED,2019-01-04 16:42:59.000000000,2019-03-06 13:40:33.000000000,,"[{'_account_id': 2}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-01-04 16:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/cb390015728855ec63d2f32f0f121d4223152055', 'message': 'Update hacking version to latest\n\nChange-Id: I70f0fb12fba34ef01ccf2b1afedeeada122ae1af\n'}, {'number': 2, 'created': '2019-01-22 01:57:26.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/31e19766eae55c8e59143f15bf2866c9b5e8f680', 'message': 'Update hacking version to latest\n\nChange-Id: I70f0fb12fba34ef01ccf2b1afedeeada122ae1af\n'}]",0,628597,31e19766eae55c8e59143f15bf2866c9b5e8f680,19,5,2,21691,,,0,"Update hacking version to latest

Change-Id: I70f0fb12fba34ef01ccf2b1afedeeada122ae1af
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/97/628597/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,cb390015728855ec63d2f32f0f121d4223152055,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-adjutantclient~master~I3e7906b9ac0837c7012c58c650b935cb506b78d4,openstack/python-adjutantclient,master,I3e7906b9ac0837c7012c58c650b935cb506b78d4,Update hacking version,ABANDONED,2018-12-28 15:03:49.000000000,2019-03-06 13:40:24.000000000,,"[{'_account_id': 22348}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:03:49.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-adjutantclient/commit/0b9d75a0b7c175604ffc41c53d2cf1c2ed1d95d1', 'message': 'Update hacking version\n\nChange-Id: I3e7906b9ac0837c7012c58c650b935cb506b78d4\n'}]",0,627672,0b9d75a0b7c175604ffc41c53d2cf1c2ed1d95d1,4,2,1,21691,,,0,"Update hacking version

Change-Id: I3e7906b9ac0837c7012c58c650b935cb506b78d4
",git fetch https://review.opendev.org/openstack/python-adjutantclient refs/changes/72/627672/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0b9d75a0b7c175604ffc41c53d2cf1c2ed1d95d1,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=0.11.0,<0.12 # Apache-2.0",1,1
openstack%2Fpython-ironicclient~master~I681f0f5ec332cdc0bc6ed331db783c528f320549,openstack/python-ironicclient,master,I681f0f5ec332cdc0bc6ed331db783c528f320549,Update hacking version,ABANDONED,2018-12-28 15:04:06.000000000,2019-03-06 13:39:55.000000000,,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 15:04:06.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/7b01f5987aa5495e62262a694b5c4b222f8d7cb0', 'message': 'Update hacking version\n\nChange-Id: I681f0f5ec332cdc0bc6ed331db783c528f320549\n'}]",1,627687,7b01f5987aa5495e62262a694b5c4b222f8d7cb0,5,3,1,21691,,,0,"Update hacking version

Change-Id: I681f0f5ec332cdc0bc6ed331db783c528f320549
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/87/627687/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7b01f5987aa5495e62262a694b5c4b222f8d7cb0,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=1.0.0,<1.1.0 # Apache-2.0",1,1
openstack%2Fpython-masakariclient~master~I89a19b320e83c5e5007a15b0cdac9673dc776362,openstack/python-masakariclient,master,I89a19b320e83c5e5007a15b0cdac9673dc776362,Update hacking version,ABANDONED,2018-12-28 15:04:14.000000000,2019-03-06 13:39:50.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 15:04:14.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-masakariclient/commit/aae378a906f0ffe7e0c989a190d77fc6bddcf14a', 'message': 'Update hacking version\n\nChange-Id: I89a19b320e83c5e5007a15b0cdac9673dc776362\n'}]",0,627692,aae378a906f0ffe7e0c989a190d77fc6bddcf14a,4,2,1,21691,,,0,"Update hacking version

Change-Id: I89a19b320e83c5e5007a15b0cdac9673dc776362
",git fetch https://review.opendev.org/openstack/python-masakariclient refs/changes/92/627692/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,aae378a906f0ffe7e0c989a190d77fc6bddcf14a,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Foslo.log~master~I6a633ff73c7709231734287c7c7478922007b9a3,openstack/oslo.log,master,I6a633ff73c7709231734287c7c7478922007b9a3,Update hacking version,ABANDONED,2018-12-28 14:52:26.000000000,2019-03-06 13:39:39.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27781}, {'_account_id': 27838}]","[{'number': 1, 'created': '2018-12-28 14:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ddfd68b7fb63927a0194e30b07b120a75d712f1d', 'message': 'Update hacking version\n\nChange-Id: I6a633ff73c7709231734287c7c7478922007b9a3\n'}, {'number': 2, 'created': '2019-01-07 15:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/029f3c2e22d0d447e4a1253bb4d8c7f8dd0d57dc', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I6a633ff73c7709231734287c7c7478922007b9a3\n'}, {'number': 3, 'created': '2019-01-08 03:03:35.000000000', 'files': ['oslo_log/_options.py', 'oslo_log/formatters.py', 'test-requirements.txt', 'oslo_log/log.py', 'oslo_log/rate_limit.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/e53b924afae3a30a262173e74c96c060b9ff391d', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I6a633ff73c7709231734287c7c7478922007b9a3\n'}]",0,627657,e53b924afae3a30a262173e74c96c060b9ff391d,14,5,3,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I6a633ff73c7709231734287c7c7478922007b9a3
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/57/627657/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ddfd68b7fb63927a0194e30b07b120a75d712f1d,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fhorizon~stable%2Frocky~If5fc190988cf173387da2b66be23db9134310692,openstack/horizon,stable/rocky,If5fc190988cf173387da2b66be23db9134310692,Use correct cinder API version for tenant_absolute_limits,MERGED,2019-03-06 10:46:07.000000000,2019-03-06 13:39:09.000000000,2019-03-06 13:39:09.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 10:46:07.000000000', 'files': ['openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/microversions.py', 'openstack_dashboard/test/unit/api/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b0eb41f606fdbb8a8407852493da12724e1a979b', 'message': 'Use correct cinder API version for tenant_absolute_limits\n\nTo verify resource usages when updating project quotas,\nproject_id query parameter needs to be supported in\ntenant_absolute_limits in the cinder API.\n\nThis is supported in 3.39 or later in the cinder API.\nAPI vesions shipped with released versions (pike, queens and\nrocky) are selected as verified versions.\n\nChange-Id: If5fc190988cf173387da2b66be23db9134310692\nCloses-Bug: #1810309\n(cherry picked from commit 32bfbbf10074b49b36447abd2e4f47f9f39d0ea7)\n'}]",0,641314,b0eb41f606fdbb8a8407852493da12724e1a979b,7,3,1,29313,,,0,"Use correct cinder API version for tenant_absolute_limits

To verify resource usages when updating project quotas,
project_id query parameter needs to be supported in
tenant_absolute_limits in the cinder API.

This is supported in 3.39 or later in the cinder API.
API vesions shipped with released versions (pike, queens and
rocky) are selected as verified versions.

Change-Id: If5fc190988cf173387da2b66be23db9134310692
Closes-Bug: #1810309
(cherry picked from commit 32bfbbf10074b49b36447abd2e4f47f9f39d0ea7)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/14/641314/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/microversions.py', 'openstack_dashboard/test/unit/api/test_cinder.py']",3,b0eb41f606fdbb8a8407852493da12724e1a979b,bug/1810309-stable/rocky," @mock.patch.object(api.cinder, '_cinderclient_with_limits_project_id_query') mock_cinderclient.assert_called_once_with(self.request)"," @mock.patch.object(api.cinder, 'cinderclient')",20,3
openstack%2Foslo.config~master~I92f8d4ac065b0aab5753f8ae11e1c131437c27c2,openstack/oslo.config,master,I92f8d4ac065b0aab5753f8ae11e1c131437c27c2,Update json module to jsonutils,ABANDONED,2019-02-17 14:24:49.000000000,2019-03-06 13:37:36.000000000,,"[{'_account_id': 2472}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-02-17 14:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/da5aa2ee9fd7f0ca818f1399c9562e81383e1199', 'message': 'Update json module to jsonutils\n\njson is not recommend, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I92f8d4ac065b0aab5753f8ae11e1c131437c27c2\n'}, {'number': 2, 'created': '2019-02-18 02:09:28.000000000', 'files': ['requirements.txt', 'oslo_config/generator.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/621c2040b47e6cdd00e63b934be78f526c4779a9', 'message': 'Update json module to jsonutils\n\njson is not recommend, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I92f8d4ac065b0aab5753f8ae11e1c131437c27c2\n'}]",0,637426,621c2040b47e6cdd00e63b934be78f526c4779a9,9,5,2,21691,,,0,"Update json module to jsonutils

json is not recommend, should use oslo_serialization.jsonutils
instead.

Change-Id: I92f8d4ac065b0aab5753f8ae11e1c131437c27c2
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/26/637426/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo_config/generator.py']",2,da5aa2ee9fd7f0ca818f1399c9562e81383e1199,,"from oslo_serialization import jsonutils output_file.write(jsonutils.dumps(output_data, sort_keys=True))","import json output_file.write(json.dumps(output_data, sort_keys=True))",3,3
openstack%2Foslo.utils~master~I7537f69409ffbba27d54f9e7004792141b803fc4,openstack/oslo.utils,master,I7537f69409ffbba27d54f9e7004792141b803fc4,Update json module to jsonutils,ABANDONED,2019-02-17 14:28:00.000000000,2019-03-06 13:37:32.000000000,,"[{'_account_id': 6928}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27838}]","[{'number': 1, 'created': '2019-02-17 14:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/e52594767261d6754be268357724a2c8ecac6046', 'message': 'Update json module to jsonutils\n\njson is not recommend, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I7537f69409ffbba27d54f9e7004792141b803fc4\n'}, {'number': 2, 'created': '2019-02-18 02:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/7dfd58c5a01334e137050faf9471dc7d32b49941', 'message': 'Update json module to jsonutils\n\njson is not recommend, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I7537f69409ffbba27d54f9e7004792141b803fc4\n'}, {'number': 3, 'created': '2019-02-18 02:42:06.000000000', 'files': ['requirements.txt', 'oslo_utils/imageutils.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/e8747cdd7cfc29009c7268d181d3646e7149b1db', 'message': 'Update json module to jsonutils\n\njson is not recommend, should use oslo_serialization.jsonutils\ninstead.\n\nChange-Id: I7537f69409ffbba27d54f9e7004792141b803fc4\n'}]",0,637427,e8747cdd7cfc29009c7268d181d3646e7149b1db,9,4,3,21691,,,0,"Update json module to jsonutils

json is not recommend, should use oslo_serialization.jsonutils
instead.

Change-Id: I7537f69409ffbba27d54f9e7004792141b803fc4
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/27/637427/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo_utils/imageutils.py']",2,e52594767261d6754be268357724a2c8ecac6046,,from oslo_serialization import jsonutils details = jsonutils.loads(cmd_output or '{}'),import json details = json.loads(cmd_output or '{}'),3,2
openstack%2Foslo.middleware~master~I85cfb916a58d72e517ae7cc33d29ef0913395bcb,openstack/oslo.middleware,master,I85cfb916a58d72e517ae7cc33d29ef0913395bcb,Update hacking version,ABANDONED,2018-12-28 14:52:19.000000000,2019-03-06 13:37:03.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 14:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/062ffc87ff0b6fd23bf1e7aba97b41b230c39537', 'message': 'Update hacking version\n\nChange-Id: I85cfb916a58d72e517ae7cc33d29ef0913395bcb\n'}, {'number': 2, 'created': '2019-02-17 02:24:06.000000000', 'files': ['oslo_middleware/base.py', 'test-requirements.txt', 'oslo_middleware/cors.py', 'oslo_middleware/opts.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/8420e11683b91a73178a82b4285bce3b668dc5be', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I85cfb916a58d72e517ae7cc33d29ef0913395bcb\n'}]",0,627646,8420e11683b91a73178a82b4285bce3b668dc5be,6,2,2,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I85cfb916a58d72e517ae7cc33d29ef0913395bcb
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/46/627646/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,062ffc87ff0b6fd23bf1e7aba97b41b230c39537,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-zaqarclient~master~I1efc18d3d3e370c3a11c18565e4a60092d62ab4b,openstack/python-zaqarclient,master,I1efc18d3d3e370c3a11c18565e4a60092d62ab4b,Update hacking version,ABANDONED,2018-12-28 15:05:31.000000000,2019-03-06 13:36:58.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 15:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/1f015afa1c7c090c5cfc1b14e61069773eb2de72', 'message': 'Update hacking version\n\nChange-Id: I1efc18d3d3e370c3a11c18565e4a60092d62ab4b\n'}, {'number': 2, 'created': '2019-02-17 04:04:56.000000000', 'files': ['test-requirements.txt', 'zaqarclient/_i18n.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/132781600361fd246e82f0343fd395ef87e47a20', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: I1efc18d3d3e370c3a11c18565e4a60092d62ab4b\n'}]",0,627723,132781600361fd246e82f0343fd395ef87e47a20,7,2,2,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: I1efc18d3d3e370c3a11c18565e4a60092d62ab4b
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/23/627723/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1f015afa1c7c090c5cfc1b14e61069773eb2de72,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-cinderclient~master~Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a,openstack/python-cinderclient,master,Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a,Update hacking version,ABANDONED,2018-12-28 15:04:01.000000000,2019-03-06 13:36:49.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-28 15:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/4730a30a180cf17e6df2775cf62277ae088d5892', 'message': 'Update hacking version\n\nChange-Id: Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a\n'}, {'number': 2, 'created': '2019-01-02 16:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/7fea8251ad248061baab435aca95d632da5dcb8b', 'message': 'Update hacking version\n\nChange-Id: Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a\n'}, {'number': 3, 'created': '2019-01-03 11:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/73a8dcf97410731d5f6547ef75d2a518748eaef5', 'message': 'Update hacking version\n\n1. update hacking version to latest[1]\n2. fix pep8 failed\n\n[1]: https://github.com/openstack/python-cinderclient/blob/master/HACKING.rst\n\nChange-Id: Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a\n'}, {'number': 4, 'created': '2019-02-17 03:30:51.000000000', 'files': ['cinderclient/v3/shell.py', 'test-requirements.txt', 'cinderclient/tests/unit/v3/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/35eae3b9ca96fe31a23e449e9f0843fdb41e1ca4', 'message': 'Update hacking version\n\n1. update hacking version to latest[1]\n2. fix pep8 failed\n\n[1]: https://github.com/openstack/python-cinderclient/blob/master/HACKING.rst\n\nChange-Id: Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a\n'}]",0,627681,35eae3b9ca96fe31a23e449e9f0843fdb41e1ca4,11,2,4,21691,,,0,"Update hacking version

1. update hacking version to latest[1]
2. fix pep8 failed

[1]: https://github.com/openstack/python-cinderclient/blob/master/HACKING.rst

Change-Id: Ic4d77868993b7f6c5627ed268a2b7ec22b8dd68a
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/81/627681/3 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,4730a30a180cf17e6df2775cf62277ae088d5892,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Foslo.cache~master~I2b1a592095e75a77d33bde65d4aa7b9785960a30,openstack/oslo.cache,master,I2b1a592095e75a77d33bde65d4aa7b9785960a30,Update hacking version,ABANDONED,2018-12-28 14:43:35.000000000,2019-03-06 13:36:44.000000000,,"[{'_account_id': 15334}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 14:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/06e14b300a5468ed3e0d5af9da099477d2aa6e25', 'message': 'Update hacking version\n\nChange-Id: I2b1a592095e75a77d33bde65d4aa7b9785960a30\n'}, {'number': 2, 'created': '2019-01-04 09:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/6b09d1c086c4cf54307e5eebc7a97719b3920e7e', 'message': 'Update hacking version\n\nChange-Id: I2b1a592095e75a77d33bde65d4aa7b9785960a30\n'}, {'number': 3, 'created': '2019-03-05 15:08:58.000000000', 'files': ['test-requirements.txt', 'oslo_cache/core.py'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/346f99fc8201c8f32947774ce32d85e2430bbca1', 'message': 'Update hacking version\n\nChange-Id: I2b1a592095e75a77d33bde65d4aa7b9785960a30\n'}]",0,627643,346f99fc8201c8f32947774ce32d85e2430bbca1,16,6,3,21691,,,0,"Update hacking version

Change-Id: I2b1a592095e75a77d33bde65d4aa7b9785960a30
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/43/627643/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,06e14b300a5468ed3e0d5af9da099477d2aa6e25,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-designateclient~master~Iee5831259c9463297bbe6423e5bf2efcd66aba81,openstack/python-designateclient,master,Iee5831259c9463297bbe6423e5bf2efcd66aba81,Update hacking version,ABANDONED,2018-12-28 15:03:48.000000000,2019-03-06 13:36:05.000000000,,"[{'_account_id': 8099}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/a1e93198ea200fd7d2f9e1e3d6f0866030db765e', 'message': 'Update hacking version\n\nChange-Id: Iee5831259c9463297bbe6423e5bf2efcd66aba81\n'}, {'number': 2, 'created': '2019-03-01 16:56:41.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/0ec9a4cbe771926844c4c17d7672d8de2dc4d776', 'message': 'Update hacking version\n\nChange-Id: Iee5831259c9463297bbe6423e5bf2efcd66aba81\n'}]",0,627671,0ec9a4cbe771926844c4c17d7672d8de2dc4d776,10,6,2,21691,,,0,"Update hacking version

Change-Id: Iee5831259c9463297bbe6423e5bf2efcd66aba81
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/71/627671/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,a1e93198ea200fd7d2f9e1e3d6f0866030db765e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-muranoclient~master~I7257afebc8c75a1fa981476a287828958e1eb532,openstack/python-muranoclient,master,I7257afebc8c75a1fa981476a287828958e1eb532,Update hacking version,ABANDONED,2018-12-28 15:04:47.000000000,2019-03-06 13:35:47.000000000,,"[{'_account_id': 13962}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:04:47.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/60ed4ab360d8324ae8dee85c01ee92e38d0080cb', 'message': 'Update hacking version\n\nChange-Id: I7257afebc8c75a1fa981476a287828958e1eb532\n'}]",0,627709,60ed4ab360d8324ae8dee85c01ee92e38d0080cb,8,6,1,21691,,,0,"Update hacking version

Change-Id: I7257afebc8c75a1fa981476a287828958e1eb532
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/09/627709/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,60ed4ab360d8324ae8dee85c01ee92e38d0080cb,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fmagnum~master~I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee,openstack/magnum,master,I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee,Update the hacking to latest,ABANDONED,2018-10-16 15:45:42.000000000,2019-03-06 13:35:36.000000000,,"[{'_account_id': 8064}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 26285}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-10-16 15:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3a797da996b74da40adafe215f3c7450dbb7042a', 'message': 'Update the hacking to latst\n\nChange-Id: I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee\n'}, {'number': 2, 'created': '2018-10-18 07:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/df6fd70c206404c1cfbc6591575d1d1dbc30fe17', 'message': 'Update the hacking to latest\n\nChange-Id: I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee\n'}, {'number': 3, 'created': '2018-11-13 16:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3244721c131183dd85795a233424a3471f02cc73', 'message': 'Update the hacking to latest\n\nChange-Id: I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee\n'}, {'number': 4, 'created': '2018-12-06 15:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0f2c400b3a073746c7c81139e3f642751c6fb968', 'message': 'Update the hacking to latest\n\nChange-Id: I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee\n'}, {'number': 5, 'created': '2019-01-02 16:25:40.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/348afb4bf3e3b3b281689ee014bf09dddb17322e', 'message': 'Update the hacking to latest\n\nChange-Id: I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee\n'}]",2,611024,348afb4bf3e3b3b281689ee014bf09dddb17322e,22,8,5,21691,,,0,"Update the hacking to latest

Change-Id: I06c9f674f6c7f4f35d34b52a5a74d7ee9b8bb9ee
",git fetch https://review.opendev.org/openstack/magnum refs/changes/24/611024/2 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,3a797da996b74da40adafe215f3c7450dbb7042a,, https://docs.openstack.org/hacking/latest/ , http://docs.openstack.org/developer/hacking/,1,1
openstack%2Fpython-glanceclient~master~I2d2dde74064b9de62c77f428a7a2fd16f1c091c2,openstack/python-glanceclient,master,I2d2dde74064b9de62c77f428a7a2fd16f1c091c2,Update hacking version,ABANDONED,2018-12-28 15:04:08.000000000,2019-03-06 13:35:31.000000000,,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/0c578a9de171dc9e095586c20cef92f6597313a0', 'message': 'Update hacking version\n\nChange-Id: I2d2dde74064b9de62c77f428a7a2fd16f1c091c2\n'}, {'number': 2, 'created': '2019-01-02 16:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/e1e6eccd5d94b8a4e363a48e4ae70bfa5a0bab0a', 'message': 'Update hacking version\n\nChange-Id: I2d2dde74064b9de62c77f428a7a2fd16f1c091c2\n'}, {'number': 3, 'created': '2019-01-03 02:32:51.000000000', 'files': ['glanceclient/v1/shell.py', 'test-requirements.txt', 'glanceclient/tests/unit/v2/test_shell_v2.py', 'glanceclient/tests/unit/v1/test_shell.py', 'tox.ini', 'glanceclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ca31a79b49b791ffd35dc612c2381cdd6a10ac8e', 'message': 'Update hacking version\n\nChange-Id: I2d2dde74064b9de62c77f428a7a2fd16f1c091c2\n'}]",0,627690,ca31a79b49b791ffd35dc612c2381cdd6a10ac8e,11,5,3,21691,,,0,"Update hacking version

Change-Id: I2d2dde74064b9de62c77f428a7a2fd16f1c091c2
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/90/627690/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0c578a9de171dc9e095586c20cef92f6597313a0,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Foslo.vmware~master~Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2,openstack/oslo.vmware,master,Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2,Update hacking version,ABANDONED,2018-12-28 14:52:27.000000000,2019-03-06 13:35:23.000000000,,"[{'_account_id': 9008}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 14:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/d75978639519244e38215da770607a589d4b913e', 'message': 'Update hacking version\n\nChange-Id: Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2\n'}, {'number': 2, 'created': '2019-02-17 02:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/dd4d4a79b6743389e367619e9fa366044895effa', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2\n'}, {'number': 3, 'created': '2019-02-17 02:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/185fa89a58b68cb454d48cdd797159611c6f5407', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2\n'}, {'number': 4, 'created': '2019-02-20 05:56:03.000000000', 'files': ['test-requirements.txt', 'oslo_vmware/objects/datastore.py', 'README.rst', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/640a1944ed63b8aec9ca64b76c0f315c3f89f000', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2\n'}]",0,627658,640a1944ed63b8aec9ca64b76c0f315c3f89f000,15,5,4,21691,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: Ifa81cef5fe8cbef5eb2d41fdcdf38fd7aff533d2
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/58/627658/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d75978639519244e38215da770607a589d4b913e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Foslo.rootwrap~master~I6358f9d8605ef23338fd07174b074ebf637748ab,openstack/oslo.rootwrap,master,I6358f9d8605ef23338fd07174b074ebf637748ab,Update hacking version,ABANDONED,2018-12-28 14:52:27.000000000,2019-03-06 13:34:47.000000000,,"[{'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 14:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/38f94913d75842b167b168bf669ba7e6171ee453', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}, {'number': 2, 'created': '2019-02-17 03:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/2dda707e8d078258059647d2062ad9696412a33d', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}, {'number': 3, 'created': '2019-02-18 13:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/b9118d3707724c4187d733449ca2d97cdb6b19c5', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}, {'number': 4, 'created': '2019-02-19 02:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/73569cf3e80e82b7d29eb35af395f86237eb408d', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}, {'number': 5, 'created': '2019-02-19 14:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/e855d608e11289555046367f041fc39ecd304925', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}, {'number': 6, 'created': '2019-02-20 15:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/53dc7e9c14d3f739455d840cd4ae5b66f79e604c', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}, {'number': 7, 'created': '2019-02-21 01:41:19.000000000', 'files': ['test-requirements.txt', 'oslo_rootwrap/wrapper.py', 'tox.ini', 'oslo_rootwrap/filters.py'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/9b40bfd8b915f864d2444ba11a59b4049e3728a3', 'message': 'Update hacking version\n\nChange-Id: I6358f9d8605ef23338fd07174b074ebf637748ab\n'}]",3,627659,9b40bfd8b915f864d2444ba11a59b4049e3728a3,25,7,7,21691,,,0,"Update hacking version

Change-Id: I6358f9d8605ef23338fd07174b074ebf637748ab
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/59/627659/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,38f94913d75842b167b168bf669ba7e6171ee453,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fpython-manilaclient~master~I424bfc739c75e0605e878de9d07bd910b48d772a,openstack/python-manilaclient,master,I424bfc739c75e0605e878de9d07bd910b48d772a,Update hacking version,ABANDONED,2018-12-28 15:04:29.000000000,2019-03-06 13:34:38.000000000,,"[{'_account_id': 7102}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 15:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/41e0b727257589d74902115c41b4b107bacfde8b', 'message': 'Update hacking version\n\nChange-Id: I424bfc739c75e0605e878de9d07bd910b48d772a\n'}, {'number': 2, 'created': '2019-01-02 15:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/56f5f5809e45bf2f8c68f66311d7be8e3147ecbb', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: I424bfc739c75e0605e878de9d07bd910b48d772a\n'}, {'number': 3, 'created': '2019-01-02 16:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4f5629f453ee008683c38708a717f964987e13d6', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: I424bfc739c75e0605e878de9d07bd910b48d772a\n'}, {'number': 4, 'created': '2019-01-03 11:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/0a3f950772ad1a6d44006ae8a36bca1b9785cc74', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: I424bfc739c75e0605e878de9d07bd910b48d772a\n'}, {'number': 5, 'created': '2019-02-17 04:31:15.000000000', 'files': ['manilaclient/tests/unit/v2/test_shell.py', 'manilaclient/tests/unit/v2/fakes.py', 'manilaclient/shell.py', 'test-requirements.txt', 'manilaclient/tests/functional/utils.py', 'manilaclient/__init__.py', 'manilaclient/tests/unit/v2/test_shares.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/d8430581c3717288a8a2929df225d10efad821cd', 'message': 'Update hacking version\n\n1. update hacking version to latest\n2. fix pep8 failed\n\nChange-Id: I424bfc739c75e0605e878de9d07bd910b48d772a\n'}]",1,627698,d8430581c3717288a8a2929df225d10efad821cd,15,4,5,21691,,,0,"Update hacking version

1. update hacking version to latest
2. fix pep8 failed

Change-Id: I424bfc739c75e0605e878de9d07bd910b48d772a
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/98/627698/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,41e0b727257589d74902115c41b4b107bacfde8b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fmonasca-agent~master~I57f233578132a3689a2182c53483d8110f15bcea,openstack/monasca-agent,master,I57f233578132a3689a2182c53483d8110f15bcea,Update OVS detection plugin for Keystone v3,MERGED,2019-02-19 13:45:53.000000000,2019-03-06 13:33:31.000000000,2019-03-05 19:23:58.000000000,"[{'_account_id': 10311}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26733}]","[{'number': 1, 'created': '2019-02-19 13:45:53.000000000', 'files': ['tests/detection/test_ovs.py', 'monasca_setup/detection/plugins/ovs.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/5fe2a6d7b9b615a605269e8483be01ea613f0b82', 'message': 'Update OVS detection plugin for Keystone v3\n\nTo properly support Keystone V3, we must also properly convey the\ndomain information to the underlaying Keystone client.\n\nStory: 2005045\nTask: 29542\n\nChange-Id: I57f233578132a3689a2182c53483d8110f15bcea\n'}]",0,637846,5fe2a6d7b9b615a605269e8483be01ea613f0b82,10,4,1,16222,,,0,"Update OVS detection plugin for Keystone v3

To properly support Keystone V3, we must also properly convey the
domain information to the underlaying Keystone client.

Story: 2005045
Task: 29542

Change-Id: I57f233578132a3689a2182c53483d8110f15bcea
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/46/637846/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/detection/test_ovs.py', 'monasca_setup/detection/plugins/ovs.py']",2,5fe2a6d7b9b615a605269e8483be01ea613f0b82,ovs," 'user_domain_name', 'user_domain_id', 'project_domain_name', 'project_domain_id'ignorable_args = ['username', 'password', 'project_name', 'user_domain_name', 'user_domain_id', 'project_domain_name', 'project_domain_id', for_opts = [{'opt': cfg.StrOpt('region', default='RegionOne'), 'group': 'service_auth'}, {'opt': cfg.StrOpt('nova_region_name'), 'group': 'DEFAULT'}, {'opt': cfg.StrOpt('username'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('password'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('project_name'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('user_domain_name'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('user_domain_id'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('project_domain_name'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('project_domain_id'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('auth_url'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('identity_uri'), 'group': 'keystone_authtoken'}] cfg_domain = ['user_domain_name', 'user_domain_id', 'project_domain_name', 'project_domain_id'] for option in cfg_domain: if self.has_option(cfg_section, option): init_config[option] = self.get_option(cfg_section, option) ","ignorable_args = ['username', 'password', 'project_name', for_opts = [{'opt': cfg.StrOpt('region', default='RegionOne'), 'group': 'service_auth'}, {'opt': cfg.StrOpt('nova_region_name'), 'group': 'DEFAULT'}, {'opt': cfg.StrOpt('username'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('password'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('project_name'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('auth_url'), 'group': 'keystone_authtoken'}, {'opt': cfg.StrOpt('identity_uri'), 'group': 'keystone_authtoken'}]",47,20
openstack%2Fsahara-plugin-mapr~master~I93c2eaf1413e40063007ebd8cb31a7b049da5dd3,openstack/sahara-plugin-mapr,master,I93c2eaf1413e40063007ebd8cb31a7b049da5dd3,Adding compatibility to MariaDB,MERGED,2019-02-04 17:59:23.000000000,2019-03-06 13:30:16.000000000,2019-03-06 13:30:16.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 11224}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2019-02-04 17:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-plugin-mapr/commit/bfd1d051d39191bac2d9e547c5b113e13b180cba', 'message': 'Adding compatibility to MariaDB\n\nHue service requires access to libs that is not supported anymore on\nMariaDB. The compatibility rpm fixes that.\n\nChange-Id: I93c2eaf1413e40063007ebd8cb31a7b049da5dd3\n'}, {'number': 2, 'created': '2019-02-04 20:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-plugin-mapr/commit/95f400825f46a1efbedd799c1d866fc42d3158fa', 'message': 'Adding compatibility to MariaDB\n\nHue service requires access to libs that is not supported anymore on\nMariaDB. The compatibility rpm fixes that.\n\nChange-Id: I93c2eaf1413e40063007ebd8cb31a7b049da5dd3\n'}, {'number': 3, 'created': '2019-03-04 11:35:16.000000000', 'files': ['sahara_plugin_mapr/plugins/mapr/resources/images/image.yaml', 'sahara_plugin_mapr/plugins/mapr/resources/images/centos/configure_hue'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-mapr/commit/5de8849622b62697b833ac437ad012ec43cbedfd', 'message': 'Adding compatibility to MariaDB\n\nHue service requires access to libs that is not supported anymore on\nMariaDB. The compatibility rpm fixes that.\n\nChange-Id: I93c2eaf1413e40063007ebd8cb31a7b049da5dd3\n'}]",5,634764,5de8849622b62697b833ac437ad012ec43cbedfd,19,5,3,8932,,,0,"Adding compatibility to MariaDB

Hue service requires access to libs that is not supported anymore on
MariaDB. The compatibility rpm fixes that.

Change-Id: I93c2eaf1413e40063007ebd8cb31a7b049da5dd3
",git fetch https://review.opendev.org/openstack/sahara-plugin-mapr refs/changes/64/634764/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_plugin_mapr/plugins/mapr/resources/images/image.yaml', 'sahara_plugin_mapr/plugins/mapr/resources/images/common/configure_extjs', 'sahara_plugin_mapr/plugins/mapr/resources/images/ubuntu/install_openjdk']",3,bfd1d051d39191bac2d9e547c5b113e13b180cba,, apt-get install -y openjdk-8-jdk, apt-get install -y openjdk-7-jdk,7,9
openstack%2Fneutron-fwaas-dashboard~master~I69d8fbf8f69c2accd92e8cf167e4a4aaff85ecc1,openstack/neutron-fwaas-dashboard,master,I69d8fbf8f69c2accd92e8cf167e4a4aaff85ecc1,Imported Translations from Zanata,MERGED,2019-03-06 06:12:57.000000000,2019-03-06 13:22:43.000000000,2019-03-06 13:22:43.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 06:12:57.000000000', 'files': ['neutron_fwaas_dashboard/locale/id/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/ja/LC_MESSAGES/django.po', 'releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'neutron_fwaas_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'releasenotes/source/locale/es/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'neutron_fwaas_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/de/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/fr/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/zh_CN/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas-dashboard/commit/a6c91325be08c39a80dc87cd46a9518b998552e1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I69d8fbf8f69c2accd92e8cf167e4a4aaff85ecc1\n'}]",0,641206,a6c91325be08c39a80dc87cd46a9518b998552e1,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I69d8fbf8f69c2accd92e8cf167e4a4aaff85ecc1
",git fetch https://review.opendev.org/openstack/neutron-fwaas-dashboard refs/changes/06/641206/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas_dashboard/locale/id/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/ja/LC_MESSAGES/django.po', 'releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'neutron_fwaas_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'releasenotes/source/locale/es/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'neutron_fwaas_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/de/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/fr/LC_MESSAGES/django.po', 'neutron_fwaas_dashboard/locale/zh_CN/LC_MESSAGES/django.po']",11,a6c91325be08c39a80dc87cd46a9518b998552e1,zanata/translations,"""POT-Creation-Date: 2019-02-19 16:16+0000\n""","# Carl <cai.hui@zte.com.cn>, 2016. #zanata# Bin <liubin@glab.cn>, 2017. #zanata""POT-Creation-Date: 2019-01-18 03:31+0000\n""msgctxt ""Action name of a firewall rule"" msgid ""ALLOW"" msgstr ""允许"" msgctxt ""Current status of a firewall"" msgid ""Active"" msgstr ""运行中"" msgid ""Add Firewall"" msgstr ""添加防火墙"" msgid ""Add New Firewall"" msgstr ""添加新的防火墙"" msgid ""Add Router"" msgstr ""添加路由器"" msgid ""Add Router to Firewall"" msgstr ""将路由器添加至防火墙"" msgid ""Add Routers"" msgstr ""添加路由器"" msgid ""Add selected router(s) to the firewall."" msgstr ""将所选路由器添加至防火墙。"" #, python-format msgid ""Added firewall \""%s\""."" msgstr ""防火墙 \""%s\"" 已添加。"" #, python-format msgid ""Added policy \""%s\""."" msgstr ""已添加策略 “%s”。"" #, python-format msgid ""Added rule \""%s\""."" msgstr ""已添加的规则 \""%s\""。"" msgid ""Associated Routers"" msgstr ""已关联路由器"" msgid ""Available Routers"" msgstr ""可用路由"" ""Choose router(s) from Available Routers to Selected Routers by push button "" ""or drag and drop. "" msgstr ""通过按钮或者拖放来从可用路由中选择一个(或多个)到选定路由。"" msgid """"msgid ""Choose the router(s) you want to add."" msgstr ""选择需要添加的路由。"" msgid ""Create Firewall"" msgstr ""创建防火墙"" ""Create a firewall based on a policy.\n"" ""\n"" ""A firewall represents a logical firewall resource that a tenant can "" ""instantiate and manage. A firewall must be associated with one policy, all "" ""other fields are optional."" msgstr """" ""根据策略创建防火墙。\n"" ""\n"" ""防火墙表示租户可以实例化和管理的逻辑防火墙资源。一个防火墙必须与一个策略相关"" ""联，所有其它字段是可选字段。"" msgid """"msgid """" ""Create a firewall rule.\n"" ""\n"" ""A firewall rule is an association of the following attributes:\n"" ""\n"" ""<li>IP Addresses: The addresses from/to which the traffic filtration needs "" ""to be applied.</li><li>IP Version: The type of IP packets (IP V4/V6) that "" ""needs to be filtered.</li><li>Protocol: Type of packets (UDP, ICMP, TCP, "" ""Any) that needs to be checked.</li><li>Action: Action is the type of "" ""filtration required, it can be Reject/Deny/Allow data packets.</li>\n"" ""The protocol and action fields are required, all others are optional."" msgstr """" ""创建防火墙规则。\n"" ""\n"" ""防火墙规则由以下属性关联形成：\n"" ""\n"" ""<li>IP 地址：需要应用流量过滤的来源/目标地址。</li><li>IP版本：需要过滤的 IP "" ""包类型 (IP V4/V6)。</li><li>协议：需要检查的数据包类型（UDP、ICMP、TCP 和 "" ""Any）。</li><li>操作：操作是所需过滤类型，它可为拒绝/放弃/允许数据包。</li>\n"" ""协议字段和操作字段是必填字段，所有其他字段为可选字段。"" msgid ""Create a firewall with selected routers."" msgstr ""创建带有所选路由器的防火墙。"" msgctxt ""Current status of a firewall"" msgid ""Created"" msgstr ""已创建"" msgctxt ""Action name of a firewall rule"" msgid ""DENY"" msgstr ""拒绝"" msgctxt ""Admin state of a firewall"" msgid ""DOWN"" msgstr ""关闭"" msgid ""Delete Firewall"" msgid_plural ""Delete Firewalls"" msgstr[0] ""删除防火墙"" msgctxt ""Current status of a firewall"" msgid ""Down"" msgstr ""关闭"" msgid ""Edit Firewall"" msgstr ""编辑防火墙"" msgid ""Edit Firewall {{ name }}"" msgstr ""编辑防火墙 {{ name }}"" msgid ""Enable Admin State"" msgstr ""启用管理员状态"" msgctxt ""Current status of a firewall"" msgid ""Error"" msgstr ""错误"" #, python-format msgid ""Failed to add router(s) to firewall %(name)s: %(reason)s"" msgstr ""将路由器添加至防火墙 %(name)s 失败：%(reason)s"" msgid ""Failed to remove router(s) from firewall %(name)s: %(reason)s"" msgstr ""未能从防火墙 %(name)s 中移除路由器：%(reason)s"" #, python-formatmsgid ""Failed to retrieve available routers: %s"" msgstr ""无法获取可用的路由器：%s"" #, python-formatmsgid ""Failed to retrieve current routers in firewall %(name)s: %(reason)s"" msgstr ""无法检索防火墙 %(name)s 中的当前路由器：%(reason)s"" #, python-formatmsgid ""Failed to update firewall %(name)s: %(reason)s"" msgstr ""无法更新防火墙 %(name)s：%(reason)s"" #, python-format#, python-format msgid ""Failed to verify extension support %s"" msgstr ""验证扩展支持 %s 失败"" msgid ""Firewall"" msgstr ""防火墙"" #, python-format msgid ""Firewall %s was successfully updated."" msgstr ""已成功更新防火墙 %s。"" msgid ""Firewalls"" msgstr ""防火墙"" msgid ""In Policy"" msgstr ""在策略"" msgctxt ""Current status of a firewall"" msgid ""Inactive"" msgstr ""失效"" msgid """" ""Non admin users are not allowed to set the shared property of the policy."" msgstr ""非管理用户不允许设置策略的共享属性。"" msgid ""Non admin users are not allowed to set the shared property of the rule."" msgstr ""非管理用户不允许设置规则的共享属性。"" msgctxt ""Current status of a firewall"" msgid ""Pending Create"" msgstr ""等待创建"" msgctxt ""Current status of a firewall"" msgid ""Pending Delete"" msgstr ""等待删除"" msgctxt ""Current status of a firewall"" msgid ""Pending Update"" msgstr ""等待更新"" msgid ""Position in Policy"" msgstr ""在策略中的位置"" msgctxt ""Action name of a firewall rule"" msgid ""REJECT"" msgstr ""拒绝"" msgid ""Remove Router"" msgstr ""删除路由器"" msgid ""Remove Router from Firewall"" msgstr ""从防火墙中删除路由器"" #, python-format msgid ""Router(s) was successfully removed from firewall %(firewall)s."" msgstr ""已成功从防火墙 %(firewall)s 中移除路由器。"" #, python-format msgid ""Router(s) was/were successfully added to firewall %(firewall)s."" msgstr ""路由器已经成功添加至以下防火墙：%(firewall)s。"" msgid ""Routers"" msgstr ""路由器"" msgid ""Scheduled deletion of firewall"" msgid_plural ""Scheduled deletion of firewalls"" msgstr[0] ""已调度删除防火墙"" msgid ""Scheduled deletion of policy"" msgid_plural ""Scheduled deletion of policies"" msgstr[0] ""已安排删除策略"" msgid ""Scheduled deletion of rule"" msgid_plural ""Scheduled deletion of rules"" msgstr[0] ""已安排删除规则"" msgid ""Select a policy"" msgstr ""选择一个策略"" msgid ""Select routers for your firewall."" msgstr ""为您的防火墙选择路由器。"" msgid ""Selected Routers"" msgstr ""选择的路由"" msgctxt ""Admin state of a firewall"" msgid ""UP"" msgstr ""启动"" msgid ""Unable to add firewall \""%s\""."" msgstr ""无法添加防火墙 \""%s\""。"" #, python-format msgid ""Unable to add policy \""%s\""."" msgstr ""无法添加策略 “%s”。"" #, python-format msgid ""Unable to add rule \""%s\""."" msgstr ""无法添加规则 \""%s\""。"" #, python-format msgid ""Unable to delete firewall. %s"" msgstr ""无法删除防火墙 %s"" #, python-formatmsgid ""Unable to retrieve firewall details."" msgstr ""无法检索防火墙详情。"" msgid ""Unable to retrieve firewall list."" msgstr ""无法检索防火墙列表。"" msgid ""Unable to retrieve policy list (%(error)s)."" msgstr ""无法检索策略列表 (%(error)s)。"" #, python-format#, python-format msgid ""Unable to retrieve routers (%(error)s)."" msgstr ""无法检索路由器 (%(error)s)。"" msgid ""Unable to retrieve rules (%(error)s)."" msgstr ""无法检索规则 (%(error)s)。"" #, python-formatmsgid ""Unselect the router(s) to be removed from firewall."" msgstr ""取消选中要从防火墙中移除的路由器。"" msgid ""Unselect the routers you want to disassociate from the firewall."" msgstr ""取消选择需要从防火墙中分离的路由。"" msgid ""Used in Policy"" msgstr ""已使用在策略"" msgid ""You may update firewall details here."" msgstr ""您可以在此处更新防火墙详情。"" ""instead to insert or remove a rule"" msgstr """" ""您可以在此处更新策略详情。使用'插入规则'或'移除规则'链接来插入或删除规则。"" msgid """" ""You may update policy details here. Use 'Insert Rule' or 'Remove Rule' links """,50,2431
openstack%2Fmanila~master~I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9,openstack/manila,master,I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9,[pylint] Use filenames in coding-checks,MERGED,2019-02-20 07:11:53.000000000,2019-03-06 13:10:25.000000000,2019-03-05 22:57:21.000000000,"[{'_account_id': 2417}, {'_account_id': 6413}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 26968}]","[{'number': 1, 'created': '2019-02-20 07:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/299234aa078127c5de7e3b56b26ca18cce5923bb', 'message': '[pylint] Use filenames in coding-checks\n\nWhen using the argument ""all"" in our pylint\nscript, we invoke tests against the whole tree.\nThis doesn\'t really work well with module names\nsince it ignores some submodules that are not\ntraversable from the main manila module.\n\nBy using filenames, we allow pylint to cover\nall modules.\n\nChange-Id: I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9\n'}, {'number': 2, 'created': '2019-02-20 07:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/98dfa35ae1e5d84535ff21abb28ecc75cc1fa462', 'message': '[pylint] Use filenames in coding-checks\n\nWhen using the argument ""all"" in our pylint\nscript, we invoke tests against the whole tree.\nThis doesn\'t really work well with module names\nsince it ignores some submodules that are not\ntraversable from the main manila module.\n\nBy using filenames, we allow pylint to cover\nall modules.\n\nChange-Id: I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9\n'}, {'number': 3, 'created': '2019-02-27 20:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6136af02b9259114ccf07811e1ada2d5a23a7d78', 'message': '[pylint] Use filenames in coding-checks\n\nWhen using the argument ""all"" in our pylint\nscript, we invoke tests against the whole tree.\nThis doesn\'t really work well with module names\nsince it ignores some submodules that are not\ntraversable from the main manila module.\n\nBy using filenames, we allow pylint to cover\nall modules.\n\nChange-Id: I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9\n'}, {'number': 4, 'created': '2019-03-05 22:08:53.000000000', 'files': ['tools/coding-checks.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/f2a0410ebd28c53bff0008c8c81b348000d1d251', 'message': '[pylint] Use filenames in coding-checks\n\nWhen using the argument ""all"" in our pylint\nscript, we invoke tests against the whole tree.\nThis doesn\'t really work well with module names\nsince it ignores some submodules that are not\ntraversable from the main manila module.\n\nBy using filenames, we allow pylint to cover\nall modules.\n\nChange-Id: I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9\n'}]",3,638095,f2a0410ebd28c53bff0008c8c81b348000d1d251,45,19,4,16643,,,0,"[pylint] Use filenames in coding-checks

When using the argument ""all"" in our pylint
script, we invoke tests against the whole tree.
This doesn't really work well with module names
since it ignores some submodules that are not
traversable from the main manila module.

By using filenames, we allow pylint to cover
all modules.

Change-Id: I37ea7f72e71ae93f8f654e0aa99744b2ecc1cea9
",git fetch https://review.opendev.org/openstack/manila refs/changes/95/638095/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/coding-checks.sh'],1,299234aa078127c5de7e3b56b26ca18cce5923bb,pylint," files=$(find manila/ -type f -name ""*.py"" -and ! -path ""manila/tests*""|head -n 20) test_files=$(find manila/ -type f -name ""*.py"" -and -path ""manila/tests*""|head -n 20)"," files=""manila"" test_files=""manila.tests""",2,2
openstack%2Ftripleo-common~master~I831ceb84f02b01810f5d2e2c17cc21b7dac6f866,openstack/tripleo-common,master,I831ceb84f02b01810f5d2e2c17cc21b7dac6f866,mistral-executor: handle ansible-playbook-3,MERGED,2019-03-05 16:32:47.000000000,2019-03-06 12:52:02.000000000,2019-03-06 12:52:02.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 16:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d3a054455b3cf64c3cb772b6e87e352a59cc7cee', 'message': 'mistral-executor: handle ansible-playbook-3\n\nansible-playbook-3 is needed where Ansible is run, in the Mistral Executor\ncontainer. This workaround will hopefully be removed soon.\n\nChange-Id: I831ceb84f02b01810f5d2e2c17cc21b7dac6f866\n'}, {'number': 2, 'created': '2019-03-05 17:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/462efe5ad56ae69fdc284294dadec3147e49d851', 'message': 'mistral-executor: handle ansible-playbook-3\n\nansible-playbook-3 is needed where Ansible is run, in the Mistral Executor\ncontainer. This workaround will hopefully be removed soon.\n\nChange-Id: I831ceb84f02b01810f5d2e2c17cc21b7dac6f866\n'}, {'number': 3, 'created': '2019-03-05 23:33:08.000000000', 'files': ['container-images/tripleo_kolla_template_overrides.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/174dcbcf8f501e8d068b8eefd24f2dcb0e80b42d', 'message': 'mistral-executor: handle ansible-playbook-3\n\nansible-playbook-3 is needed where Ansible is run, in the Mistral Executor\ncontainer. This workaround will hopefully be removed soon.\n\nChange-Id: I831ceb84f02b01810f5d2e2c17cc21b7dac6f866\n'}]",3,641076,174dcbcf8f501e8d068b8eefd24f2dcb0e80b42d,17,7,3,3153,,,0,"mistral-executor: handle ansible-playbook-3

ansible-playbook-3 is needed where Ansible is run, in the Mistral Executor
container. This workaround will hopefully be removed soon.

Change-Id: I831ceb84f02b01810f5d2e2c17cc21b7dac6f866
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/76/641076/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_kolla_template_overrides.j2'],1,d3a054455b3cf64c3cb772b6e87e352a59cc7cee,mistral/python3,# TODO(emilien) Remove once proper packaging is released for Ansible {% if distro_python3 %} RUN ln -s /usr/bin/ansible-playbook /usr/bin/ansible-playbook-3 {% endblock %},,4,0
openstack%2Fcharm-deployment-guide~master~I7dff6c3188d1877529e879adea4af9ffb8dee7c8,openstack/charm-deployment-guide,master,I7dff6c3188d1877529e879adea4af9ffb8dee7c8,vault: ensure authorize-charm is run on lead unit,MERGED,2019-03-05 16:11:24.000000000,2019-03-06 12:44:32.000000000,2019-03-06 12:44:32.000000000,"[{'_account_id': 935}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 28899}]","[{'number': 1, 'created': '2019-03-05 16:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/33dfc9376c3a2dd5a9999f11fdf61ca660a974a8', 'message': ""vault: Add note about authorize-charm action\n\nEnsure its clear that the authorize-charm action should be run\non the lead vault unit in a HA deployment.\n\nAdd '--wait' parameter to example to ensure users see any action\nfailures.\n\nChange-Id: I7dff6c3188d1877529e879adea4af9ffb8dee7c8\nCloses-Bug: 1818660\n""}, {'number': 2, 'created': '2019-03-06 09:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/df7ed47a9cbac3ed00722c2b5b1d9f8afd790f81', 'message': ""vault: Add note about authorize-charm action\n\nEnsure its clear that the authorize-charm action should be run\non the lead vault unit in a HA deployment by using the /leader\nsyntax to auto-identify the lead unit.\n\nAdd '--wait' parameter to example to ensure users see any action\nfailures.\n\nChange-Id: I7dff6c3188d1877529e879adea4af9ffb8dee7c8\nCloses-Bug: 1818660\n""}, {'number': 3, 'created': '2019-03-06 09:24:49.000000000', 'files': ['deploy-guide/source/app-vault.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/471734c341635e61ec084b478f7abad8faf6d5de', 'message': ""vault: ensure authorize-charm is run on lead unit\n\nEnsure its clear that the authorize-charm action should be run\non the lead vault unit in a HA deployment by using the /leader\nsyntax to auto-identify the lead unit.\n\nAdd '--wait' parameter to example to ensure users see any action\nfailures.\n\nChange-Id: I7dff6c3188d1877529e879adea4af9ffb8dee7c8\nCloses-Bug: 1818660\n""}]",2,641066,471734c341635e61ec084b478f7abad8faf6d5de,12,4,3,935,,,0,"vault: ensure authorize-charm is run on lead unit

Ensure its clear that the authorize-charm action should be run
on the lead vault unit in a HA deployment by using the /leader
syntax to auto-identify the lead unit.

Add '--wait' parameter to example to ensure users see any action
failures.

Change-Id: I7dff6c3188d1877529e879adea4af9ffb8dee7c8
Closes-Bug: 1818660
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/66/641066/2 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-vault.rst'],1,33dfc9376c3a2dd5a9999f11fdf61ca660a974a8,bug/1818660, juju run-action --wait vault/0 authorize-charm token=03ceadf5-529d-6a64-0cfd-1e341b1dacb1 .. note:: The authorize-charm action must be run on the lead vault unit., juju run-action vault/0 authorize-charm token=03ceadf5-529d-6a64-0cfd-1e341b1dacb1,5,1
openstack%2Fneutron~stable%2Focata~I3cf5c57c7f232deaa190ab6b0129e398fdabe592,openstack/neutron,stable/ocata,I3cf5c57c7f232deaa190ab6b0129e398fdabe592,[OVS] Fix for cleaning after skipped_devices,MERGED,2019-02-07 21:26:47.000000000,2019-03-06 12:38:54.000000000,2019-03-06 12:38:53.000000000,"[{'_account_id': 1131}, {'_account_id': 6593}, {'_account_id': 7016}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-07 21:26:47.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/20fa3f267ebe7e2feb60d930af4a58a77cb9334c', 'message': '[OVS] Fix for cleaning after skipped_devices\n\nWhen Openvswitch agent will get ""port_update"" event\n(e.g. to set port as unbound) and port is already removed\nfrom br-int when agent tries to get vif port in\ntreat_devices_added_updated() method (port is removed\nbecause e.g. nova-compute removes it) then resources set\nfor port by L2 agent extension drivers (like qos) are not\ncleaned properly.\n\nIn such case port is added to skipped_ports and is set\nas DOWN in neutron-db but ext_manager is not called then\nfor such port so it will not clear stuff like bandwidth\nlimit\'s QoS and queue records and also DSCP marking\nopen flow rules for this port.\n\nThis patch fixes this issue by adding call of\next_manager.delete_port() method for all skipped ports.\n\nChange-Id: I3cf5c57c7f232deaa190ab6b0129e398fdabe592\nCloses-Bug: #1737892\n(cherry picked from commit a8271e978a1c540ae9888f568cf14b4c40ea1b6d)\n(cherry picked from commit cdcc704b9e0c6eb3eb8500e5791b007e85653c13)\n'}]",0,635650,20fa3f267ebe7e2feb60d930af4a58a77cb9334c,15,6,1,6593,,,0,"[OVS] Fix for cleaning after skipped_devices

When Openvswitch agent will get ""port_update"" event
(e.g. to set port as unbound) and port is already removed
from br-int when agent tries to get vif port in
treat_devices_added_updated() method (port is removed
because e.g. nova-compute removes it) then resources set
for port by L2 agent extension drivers (like qos) are not
cleaned properly.

In such case port is added to skipped_ports and is set
as DOWN in neutron-db but ext_manager is not called then
for such port so it will not clear stuff like bandwidth
limit's QoS and queue records and also DSCP marking
open flow rules for this port.

This patch fixes this issue by adding call of
ext_manager.delete_port() method for all skipped ports.

Change-Id: I3cf5c57c7f232deaa190ab6b0129e398fdabe592
Closes-Bug: #1737892
(cherry picked from commit a8271e978a1c540ae9888f568cf14b4c40ea1b6d)
(cherry picked from commit cdcc704b9e0c6eb3eb8500e5791b007e85653c13)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/635650/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",2,20fa3f267ebe7e2feb60d930af4a58a77cb9334c,bug/1737892," mock.patch.object(self.agent.ext_manager, ""delete_port"") as ext_mgr_delete_port,\ ext_mgr_delete_port.assert_called_once_with( self.agent.context, {'port_id': 'the_skipped_one'})",,5,0
openstack%2Ftripleo-heat-templates~master~I1a953d386cf8db2ba5e62cf9cbb911f209d49197,openstack/tripleo-heat-templates,master,I1a953d386cf8db2ba5e62cf9cbb911f209d49197,DNM: Testing puppet-certmonger patch,ABANDONED,2019-03-04 14:43:38.000000000,2019-03-06 12:37:58.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 14:43:38.000000000', 'files': ['deployment/nova/novajoin-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5329f452ff3da53c7d864589cedf25013c16af97', 'message': 'DNM: Testing puppet-certmonger patch\n\nChange-Id: I1a953d386cf8db2ba5e62cf9cbb911f209d49197\nDepends-On: https://github.com/saltedsignal/puppet-certmonger/pull/25\n'}]",0,640779,5329f452ff3da53c7d864589cedf25013c16af97,4,2,1,10873,,,0,"DNM: Testing puppet-certmonger patch

Change-Id: I1a953d386cf8db2ba5e62cf9cbb911f209d49197
Depends-On: https://github.com/saltedsignal/puppet-certmonger/pull/25
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/640779/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/novajoin-container-puppet.yaml'],1,5329f452ff3da53c7d864589cedf25013c16af97,test-certmonger-patch, OpenStack containerized novajoin service., OpenStack containerized novajoin service,1,1
openstack%2Fhorizon~master~I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8,openstack/horizon,master,I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8,Add volume group-specs-list support for admin panel,MERGED,2019-02-19 09:12:56.000000000,2019-03-06 12:19:08.000000000,2019-03-06 12:19:08.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-02-19 09:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e997530010db2d934605e85698ca5e941c3a523b', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}, {'number': 2, 'created': '2019-02-19 09:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/62de97016ccd3890ec28b35f82e75899740730bc', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}, {'number': 3, 'created': '2019-02-19 15:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d08009cf1582481e78ab3d6adcd28eb9f32a82d5', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}, {'number': 4, 'created': '2019-02-19 15:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/18032d1443875d4f80b5c0e81500c530e6982278', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}, {'number': 5, 'created': '2019-02-20 07:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5d9ff31caef319f6cfe87b4be9134499535ba6a1', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}, {'number': 6, 'created': '2019-02-28 05:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/05ae35f98f913f8517d35dcbe965e8f7617f131b', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}, {'number': 7, 'created': '2019-03-01 02:21:12.000000000', 'files': ['openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/_edit.html', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/edit.html', 'releasenotes/notes/generic-volume-groups-c0bf175f5d7d3a37.yaml', 'openstack_dashboard/dashboards/admin/group_types/specs/views.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/group_types/specs/forms.py', 'openstack_dashboard/dashboards/admin/group_types/tables.py', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/index.html', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/create.html', 'openstack_dashboard/dashboards/admin/group_types/urls.py', 'openstack_dashboard/dashboards/admin/group_types/specs/urls.py', 'openstack_dashboard/dashboards/admin/group_types/specs/__init__.py', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/_index.html', 'openstack_dashboard/dashboards/admin/group_types/specs/tables.py', 'openstack_dashboard/dashboards/admin/group_types/specs/tests.py', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/_create.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4b523122b0aa122d6ae5f76792fcadac00af89db', 'message': 'Add volume group-specs-list support for admin panel\n\nThis commit allow admin to list/show cinder volume group-spec\nusing horizon dashboard and user can perform the following\ntable action :\n1. group-spec-create\n2. group-spec-edit\n3. group-spec-delete\n\nPartially-Implements blueprint cinder-generic-volume-groups\n\nChange-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8\n'}]",22,637793,4b523122b0aa122d6ae5f76792fcadac00af89db,28,6,7,29313,,,0,"Add volume group-specs-list support for admin panel

This commit allow admin to list/show cinder volume group-spec
using horizon dashboard and user can perform the following
table action :
1. group-spec-create
2. group-spec-edit
3. group-spec-delete

Partially-Implements blueprint cinder-generic-volume-groups

Change-Id: I7a24e21bbf86595bc7e1251d29caed7f7ff5dec8
",git fetch https://review.opendev.org/openstack/horizon refs/changes/93/637793/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/_edit.html', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/edit.html', 'openstack_dashboard/dashboards/admin/group_types/specs/views.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/group_types/specs/forms.py', 'openstack_dashboard/dashboards/admin/group_types/tables.py', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/index.html', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/create.html', 'openstack_dashboard/dashboards/admin/group_types/urls.py', 'openstack_dashboard/dashboards/admin/group_types/specs/urls.py', 'openstack_dashboard/dashboards/admin/group_types/specs/__init__.py', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/_index.html', 'openstack_dashboard/dashboards/admin/group_types/specs/tables.py', 'openstack_dashboard/dashboards/admin/group_types/specs/tests.py', 'openstack_dashboard/dashboards/admin/group_types/templates/group_types/specs/_create.html']",15,e997530010db2d934605e85698ca5e941c3a523b,bp/cinder-generic-volume-groups,"{% extends ""horizon/common/_modal_form.html"" %} {% load i18n %} {% block modal-body-right %} <h3>{% trans ""Description:"" %}</h3> <p>{% trans 'Create a new ""group spec"" key-value pair for a group type.' %}</p> {% endblock %} ",,548,5
openstack%2Fhorizon~master~I8d0e2879a9d2a76cf5173764035f690072a80c82,openstack/horizon,master,I8d0e2879a9d2a76cf5173764035f690072a80c82,Correcting the error messages of Volume Snapshot Table,MERGED,2019-03-06 07:20:17.000000000,2019-03-06 12:16:59.000000000,2019-03-06 12:16:59.000000000,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-03-06 07:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f3ab11471e270a1eee7a8c01976b0226bdb71a57', 'message': 'Correcting the error messages of Volume Snapshot Table\n\nChange-Id: I8d0e2879a9d2a76cf5173764035f690072a80c82\nCloses-Bug: #1818791\n'}, {'number': 2, 'created': '2019-03-06 08:52:44.000000000', 'files': ['openstack_dashboard/dashboards/admin/snapshots/tables.py', 'openstack_dashboard/dashboards/admin/snapshots/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/beedc4e729ae2c819ef3ae4ece87e7b913a9f0da', 'message': 'Correcting the error messages of Volume Snapshot Table\n\nChange-Id: I8d0e2879a9d2a76cf5173764035f690072a80c82\nCloses-Bug: #1818791\n'}]",2,641257,beedc4e729ae2c819ef3ae4ece87e7b913a9f0da,10,3,2,29313,,,0,"Correcting the error messages of Volume Snapshot Table

Change-Id: I8d0e2879a9d2a76cf5173764035f690072a80c82
Closes-Bug: #1818791
",git fetch https://review.opendev.org/openstack/horizon refs/changes/57/641257/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/snapshots/tables.py', 'openstack_dashboard/dashboards/admin/snapshots/views.py']",2,f3ab11471e270a1eee7a8c01976b0226bdb71a57,bug/1818791, msg = _('Unable to retrieve volume ' 'snapshots project information.'), msg = _('Unable to retrieve volume project information.'),3,2
openstack%2Frpm-packaging~master~I82c7fd43d2b50af89b9161dbb560e0c37c7651ea,openstack/rpm-packaging,master,I82c7fd43d2b50af89b9161dbb560e0c37c7651ea,oslo.middleware: Update to 3.37.1,MERGED,2019-03-05 15:20:00.000000000,2019-03-06 12:06:05.000000000,2019-03-06 12:06:05.000000000,"[{'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/109bc0628d5bf8befe6d9a6067e1710753958ac2', 'message': 'oslo.middleware: Update to 3.37.1\n\nChange-Id: I82c7fd43d2b50af89b9161dbb560e0c37c7651ea\n'}, {'number': 2, 'created': '2019-03-06 10:01:05.000000000', 'files': ['openstack/oslo.middleware/oslo.middleware.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4af9240543d5d85fcf7678141505f3ef0963e874', 'message': 'oslo.middleware: Update to 3.37.1\n\nChange-Id: I82c7fd43d2b50af89b9161dbb560e0c37c7651ea\n'}]",0,641032,4af9240543d5d85fcf7678141505f3ef0963e874,12,4,2,7102,,,0,"oslo.middleware: Update to 3.37.1

Change-Id: I82c7fd43d2b50af89b9161dbb560e0c37c7651ea
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/32/641032/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.middleware/oslo.middleware.spec.j2'],1,109bc0628d5bf8befe6d9a6067e1710753958ac2,,{% set upstream_version = upstream_version('3.37.1') %},{% set upstream_version = upstream_version('3.37.0') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~Ie8d8d9b5293a46238f71d40fba034d66f089939e,openstack/rpm-packaging,master,Ie8d8d9b5293a46238f71d40fba034d66f089939e,oslo.cache: Update to 1.33.2,MERGED,2019-03-02 06:06:20.000000000,2019-03-06 12:06:04.000000000,2019-03-06 12:06:04.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-02 06:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3666a8149cf80d54ed49b84c198f68770fb5e93e', 'message': 'oslo.cache: Update to 1.33.2\n\nChange-Id: Ie8d8d9b5293a46238f71d40fba034d66f089939e\n'}, {'number': 2, 'created': '2019-03-05 07:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4a98582ad3bbf89ff1fdf36798942995871720bd', 'message': 'oslo.cache: Update to 1.33.2\n\nChange-Id: Ie8d8d9b5293a46238f71d40fba034d66f089939e\n'}, {'number': 3, 'created': '2019-03-05 13:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3cd872eb5d68606f506f42a17d66f62b3e0b93a9', 'message': 'oslo.cache: Update to 1.33.2\n\nChange-Id: Ie8d8d9b5293a46238f71d40fba034d66f089939e\n'}, {'number': 4, 'created': '2019-03-06 10:01:14.000000000', 'files': ['openstack/oslo.cache/oslo.cache.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bffcdff5af460ea1c5cfa1b23e30ec714d50e249', 'message': 'oslo.cache: Update to 1.33.2\n\nChange-Id: Ie8d8d9b5293a46238f71d40fba034d66f089939e\n'}]",0,640577,bffcdff5af460ea1c5cfa1b23e30ec714d50e249,24,5,4,7102,,,0,"oslo.cache: Update to 1.33.2

Change-Id: Ie8d8d9b5293a46238f71d40fba034d66f089939e
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/77/640577/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.cache/oslo.cache.spec.j2'],1,3666a8149cf80d54ed49b84c198f68770fb5e93e,,{% set upstream_version = upstream_version('1.33.2') %},{% set upstream_version = upstream_version('1.32.0') %},1,1
openstack%2Frpm-packaging~master~Ib199a93dc0bf90c5203301331e36d817cdf238d0,openstack/rpm-packaging,master,Ib199a93dc0bf90c5203301331e36d817cdf238d0,osprofiler: Update to 2.6.0,MERGED,2019-03-02 05:57:46.000000000,2019-03-06 12:06:03.000000000,2019-03-06 12:06:03.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-02 05:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3fda9e8138af5833f58790a44879f4e5dd525b66', 'message': 'osprofiler: Update to 2.6.0\n\nChange-Id: Ib199a93dc0bf90c5203301331e36d817cdf238d0\n'}, {'number': 2, 'created': '2019-03-05 07:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e46dc2d7564ac26d0531b5faa90b442f05b49d98', 'message': 'osprofiler: Update to 2.6.0\n\nChange-Id: Ib199a93dc0bf90c5203301331e36d817cdf238d0\n'}, {'number': 3, 'created': '2019-03-05 13:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6dadbf8161afe70e31c4067f8860f58c9a7d1100', 'message': 'osprofiler: Update to 2.6.0\n\nChange-Id: Ib199a93dc0bf90c5203301331e36d817cdf238d0\n'}, {'number': 4, 'created': '2019-03-06 10:01:21.000000000', 'files': ['openstack/osprofiler/osprofiler.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8e2a3e5cc207619354cdd98a1f02f89822a58c30', 'message': 'osprofiler: Update to 2.6.0\n\nChange-Id: Ib199a93dc0bf90c5203301331e36d817cdf238d0\n'}]",0,640572,8e2a3e5cc207619354cdd98a1f02f89822a58c30,24,5,4,7102,,,0,"osprofiler: Update to 2.6.0

Change-Id: Ib199a93dc0bf90c5203301331e36d817cdf238d0
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/72/640572/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/osprofiler/osprofiler.spec.j2'],1,3fda9e8138af5833f58790a44879f4e5dd525b66,,{% set upstream_version = upstream_version('2.6.0') %},{% set upstream_version = upstream_version('2.4.1') %},1,1
openstack%2Frpm-packaging~master~Ib5570e2d285649dd7d7ab6cb2551f1aeb17d32ba,openstack/rpm-packaging,master,Ib5570e2d285649dd7d7ab6cb2551f1aeb17d32ba,monasca-statsd: Update to 1.11.0,MERGED,2019-03-06 07:34:10.000000000,2019-03-06 12:04:49.000000000,2019-03-06 12:04:49.000000000,"[{'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 07:34:10.000000000', 'files': ['openstack/monasca-statsd/monasca-statsd.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/580dba0903467649df135abce6f20467c68f58b9', 'message': 'monasca-statsd: Update to 1.11.0\n\nChange-Id: Ib5570e2d285649dd7d7ab6cb2551f1aeb17d32ba\n'}]",0,641263,580dba0903467649df135abce6f20467c68f58b9,8,4,1,6593,,,0,"monasca-statsd: Update to 1.11.0

Change-Id: Ib5570e2d285649dd7d7ab6cb2551f1aeb17d32ba
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/63/641263/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-statsd/monasca-statsd.spec.j2'],1,580dba0903467649df135abce6f20467c68f58b9,monasca_statsd,{% set upstream_version = upstream_version('1.11.0') %},{% set upstream_version = upstream_version('1.10.1') %},1,1
openstack%2Frpm-packaging~master~If8e25626b3d4a4185c97ac8bc519f8476a052c1e,openstack/rpm-packaging,master,If8e25626b3d4a4185c97ac8bc519f8476a052c1e,mistral-lib: Update to 1.1.0,MERGED,2019-03-06 07:33:31.000000000,2019-03-06 12:04:48.000000000,2019-03-06 12:04:48.000000000,"[{'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 07:33:31.000000000', 'files': ['openstack/mistral-lib/mistral-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d94b684c711393cf3658f27cf5e9406e39f2d613', 'message': 'mistral-lib: Update to 1.1.0\n\nChange-Id: If8e25626b3d4a4185c97ac8bc519f8476a052c1e\n'}]",0,641262,d94b684c711393cf3658f27cf5e9406e39f2d613,8,4,1,6593,,,0,"mistral-lib: Update to 1.1.0

Change-Id: If8e25626b3d4a4185c97ac8bc519f8476a052c1e
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/62/641262/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/mistral-lib/mistral-lib.spec.j2'],1,d94b684c711393cf3658f27cf5e9406e39f2d613,mistral_lib,Version: 1.1.0,Version: 1.0.0,1,1
openstack%2Fneutron~master~I5f911f4c6a1fc582a9c1006ec5e2880853ff2909,openstack/neutron,master,I5f911f4c6a1fc582a9c1006ec5e2880853ff2909,remove neutron.db.api references,MERGED,2019-01-25 22:02:50.000000000,2019-03-06 11:56:49.000000000,2019-03-06 11:56:49.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-01-25 22:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/722311d4a27e11049a8b5413a30693e7c05cd536', 'message': 'remove neutron.db.api\n\nThe remainder of neutron.db.api was rehomed into neutron lib with [1].\nNow that this functionality is in neutron-lib, consumers do not need\nto import the module as per the bug mentioned in [1].\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/625332/\n\nChange-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909\n'}, {'number': 2, 'created': '2019-02-06 18:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c96ed4b4d043d984d6f96987ad69c6cadfb4b72d', 'message': 'remove neutron.db.api\n\nThe remainder of neutron.db.api was rehomed into neutron lib with [1].\nNow that this functionality is in neutron-lib, consumers do not need\nto import the module as per the bug mentioned in [1].\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/625332/\n\nChange-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909\n'}, {'number': 3, 'created': '2019-02-08 17:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/204fc704775673843682f1044a9433f4557fa339', 'message': 'remove neutron.db.api\n\nThe remainder of neutron.db.api was rehomed into neutron lib with [1].\nNow that this functionality is in neutron-lib, consumers do not need\nto import the module as per the bug mentioned in [1].\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/625332/\n\nChange-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909\n'}, {'number': 4, 'created': '2019-02-11 17:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42227987d97e05a02bc0824044d50f54e94e01a6', 'message': 'remove neutron.db.api\n\nThe remainder of neutron.db.api was rehomed into neutron lib with [1].\nNow that this functionality is in neutron-lib, consumers do not need\nto import the module as per the bug mentioned in [1].\n\nThis patch removes neutron.db.api and updates any references to it\nto use neutron_lib.db.api including doc references.\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/625332/\n\nChange-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909\n'}, {'number': 5, 'created': '2019-02-12 20:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/354f8798baf4a243a5d4d42d8761531f6cf91d59', 'message': 'remove neutron.db.api references\n\nWhile the initial version of this patch removed neutron.db.api, a\ndifferent duplicate patch [1] landed first.\n\nThis patch cleans up the remining references to neutron.db.api\nincluding those in the docs and comments.\n\n[1] https://review.openstack.org/#/c/635978/\n\nChange-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909\n'}, {'number': 6, 'created': '2019-03-05 16:14:59.000000000', 'files': ['neutron/db/db_base_plugin_v2.py', 'doc/source/contributor/internals/quality_of_service.rst', 'neutron/hacking/checks.py', 'doc/source/contributor/internals/retries.rst', 'doc/source/contributor/internals/quota.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f41850ba36fb0715f72ba961d1b019a0e5d9665', 'message': 'remove neutron.db.api references\n\nWhile the initial version of this patch removed neutron.db.api, a\ndifferent duplicate patch [1] landed first.\n\nThis patch cleans up the remining references to neutron.db.api\nincluding those in the docs and comments.\n\n[1] https://review.openstack.org/#/c/635978/\n\nChange-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909\n'}]",0,633283,9f41850ba36fb0715f72ba961d1b019a0e5d9665,51,12,6,5367,,,0,"remove neutron.db.api references

While the initial version of this patch removed neutron.db.api, a
different duplicate patch [1] landed first.

This patch cleans up the remining references to neutron.db.api
including those in the docs and comments.

[1] https://review.openstack.org/#/c/635978/

Change-Id: I5f911f4c6a1fc582a9c1006ec5e2880853ff2909
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/633283/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/utils.py', 'neutron/db/api.py']",2,722311d4a27e11049a8b5413a30693e7c05cd536,bp/neutronlib-decouple-db,,"# Copyright 2011 VMware, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import weakref from neutron_lib.db import model_base import sqlalchemy from sqlalchemy import event # noqa from sqlalchemy import orm # Expire relationships when foreign key changes. # # NOTE(ihrachys) Arguably, it's a sqlalchemy anti-pattern to access child # models directly and through parent relationships in the same session. But # since OVO mechanism is built around synthetic fields that assume this mixed # access is possible, we keep it here until we find a way to migrate OVO # synthetic fields to better mechanism that would update child models via # parents. Even with that, there are multiple places in plugin code where we # mix access when using models directly; those occurrences would need to be # fixed too to be able to remove this hook and explicit expire() calls. # # Adopted from the following recipe: # https://bitbucket.org/zzzeek/sqlalchemy/wiki/UsageRecipes # /ExpireRelationshipOnFKChange # # ...then massively changed to actually work for all neutron backref cases. # # TODO(ihrachys) at some point these event handlers should be extended to also # automatically refresh values for expired attributes def _expire_for_fk_change(target, fk_value, relationship_prop, column_attr): """"""Expire relationship attributes when a many-to-one column changes."""""" sess = orm.object_session(target) # subnets and network's many-to-one relationship is used as example in the # comments in this function if sess is not None: # optional behavior #1 - expire the ""Network.subnets"" # collection on the existing ""network"" object if relationship_prop.back_populates and \ relationship_prop.key in target.__dict__: obj = getattr(target, relationship_prop.key) if obj is not None and sqlalchemy.inspect(obj).persistent: sess.expire(obj, [relationship_prop.back_populates]) # optional behavior #2 - expire the ""Subnet.network"" if sqlalchemy.inspect(target).persistent: sess.expire(target, [relationship_prop.key]) # optional behavior #3 - ""trick"" the ORM by actually # setting the value ahead of time, then emitting a load # for the attribute so that the *new* Subnet.network # is loaded. Then, expire Network.subnets on *that*. # Other techniques here including looking in the identity # map for ""value"", if this is a simple many-to-one get. if relationship_prop.back_populates: target.__dict__[column_attr] = fk_value new = getattr(target, relationship_prop.key) if new is not None: if sqlalchemy.inspect(new).persistent: sess.expire(new, [relationship_prop.back_populates]) else: # no Session yet, do it later. This path is reached from the 'expire' # listener setup by '_expire_prop_on_col' below, when a foreign key # is directly assigned to in the many to one side of a relationship. # i.e. assigning directly to Subnet.network_id before Subnet is added # to the session if target not in _emit_on_pending: _emit_on_pending[target] = [] _emit_on_pending[target].append( (fk_value, relationship_prop, column_attr)) _emit_on_pending = weakref.WeakKeyDictionary() @event.listens_for(orm.session.Session, ""pending_to_persistent"") def _pending_callables(session, obj): """"""Expire relationships when a new object w/ a foreign key becomes persistent """""" if obj is None: return args = _emit_on_pending.pop(obj, []) for a in args: if a is not None: _expire_for_fk_change(obj, *a) @event.listens_for(orm.session.Session, ""persistent_to_deleted"") def _persistent_to_deleted(session, obj): """"""Expire relationships when an object w/ a foreign key becomes deleted"""""" mapper = sqlalchemy.inspect(obj).mapper for prop in mapper.relationships: if prop.direction is orm.interfaces.MANYTOONE: for col in prop.local_columns: colkey = mapper.get_property_by_column(col).key _expire_for_fk_change(obj, None, prop, colkey) @event.listens_for(model_base.BASEV2, ""attribute_instrument"", propagate=True) def _listen_for_changes(cls, key, inst): mapper = sqlalchemy.inspect(cls) if key not in mapper.relationships: return prop = inst.property if prop.direction is orm.interfaces.MANYTOONE: for col in prop.local_columns: colkey = mapper.get_property_by_column(col).key _expire_prop_on_col(cls, prop, colkey) elif prop.direction is orm.interfaces.ONETOMANY: remote_mapper = prop.mapper # the collection *has* to have a MANYTOONE backref so we # can look up the parent. so here we make one if it doesn't # have it already, as is the case in this example if not prop.back_populates: name = ""_%s_backref"" % prop.key backref_prop = orm.relationship( prop.parent, back_populates=prop.key) remote_mapper.add_property(name, backref_prop) prop.back_populates = name def _expire_prop_on_col(cls, prop, colkey): @event.listens_for(getattr(cls, colkey), ""set"") def expire(target, value, oldvalue, initiator): """"""Expire relationships when the foreign key attribute on an object changes """""" _expire_for_fk_change(target, value, prop, colkey) ",1,146
openstack%2Frpm-packaging~master~I369c22e2258621d78b1e7322ad6c74ab42639fe9,openstack/rpm-packaging,master,I369c22e2258621d78b1e7322ad6c74ab42639fe9,Update XStatic dependencies to current stein versions,MERGED,2019-03-06 07:55:06.000000000,2019-03-06 11:52:18.000000000,2019-03-06 11:52:18.000000000,"[{'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 07:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ad91336ca455020a0350b57c7fee8a530e386faf', 'message': 'Update XStatic dependencies to current stein versions\n\nChange-Id: I369c22e2258621d78b1e7322ad6c74ab42639fe9\n'}, {'number': 2, 'created': '2019-03-06 09:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2d9ae25b50f7ed4bd19966e9242b4f4a70a54e19', 'message': 'Update XStatic dependencies to current stein versions\n\nChange-Id: I369c22e2258621d78b1e7322ad6c74ab42639fe9\n'}, {'number': 3, 'created': '2019-03-06 09:58:39.000000000', 'files': ['openstack/XStatic-Angular-lrdragndrop/XStatic-Angular-lrdragndrop.spec.j2', 'openstack/XStatic-Jasmine/XStatic-Jasmine.spec.j2', 'openstack/XStatic-mdi/XStatic-mdi.spec.j2', 'openstack/XStatic-Magic-Search/XStatic-Magic-Search.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b9f7112a3ede24b79d64fb43b1f75bae1dcc3b7a', 'message': 'Update XStatic dependencies to current stein versions\n\nChange-Id: I369c22e2258621d78b1e7322ad6c74ab42639fe9\n'}]",0,641271,b9f7112a3ede24b79d64fb43b1f75bae1dcc3b7a,14,4,3,6593,,,0,"Update XStatic dependencies to current stein versions

Change-Id: I369c22e2258621d78b1e7322ad6c74ab42639fe9
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/71/641271/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/XStatic-Angular-lrdragndrop/XStatic-Angular-lrdragndrop.spec.j2', 'openstack/XStatic-Jasmine/XStatic-Jasmine.spec.j2', 'openstack/XStatic-mdi/XStatic-mdi.spec.j2', 'openstack/XStatic-Magic-Search/XStatic-Magic-Search.spec.j2']",4,ad91336ca455020a0350b57c7fee8a530e386faf,xstatic,Version: 0.2.5.2,Version: 0.2.5.1,5,5
openstack%2Foctavia-dashboard~master~I028fff223db30ab6e465e6d93a102925cbddf74d,openstack/octavia-dashboard,master,I028fff223db30ab6e465e6d93a102925cbddf74d,Imported Translations from Zanata,MERGED,2019-03-06 09:57:04.000000000,2019-03-06 11:47:22.000000000,2019-03-06 11:47:22.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 09:57:04.000000000', 'files': ['octavia_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'octavia_dashboard/locale/zh_TW/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/de/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/fa60abe30d4e3116940f4f236eab1fe298abd838', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I028fff223db30ab6e465e6d93a102925cbddf74d\n'}]",0,641288,fa60abe30d4e3116940f4f236eab1fe298abd838,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I028fff223db30ab6e465e6d93a102925cbddf74d
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/88/641288/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_dashboard/locale/ja/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/zh_CN/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'octavia_dashboard/locale/zh_TW/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'octavia_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'octavia_dashboard/locale/de/LC_MESSAGES/djangojs.po']",9,fa60abe30d4e3116940f4f236eab1fe298abd838,zanata/translations,"""POT-Creation-Date: 2019-02-17 22:34+0000\n""","""POT-Creation-Date: 2018-12-19 10:35+0000\n""msgid ""You have selected \""%s\"". Deleted load balancer is not recoverable."" msgid_plural """" ""You have selected \""%s\"". Deleted load balancers are not recoverable."" msgstr[0] """" ""Sie haben \""%s\"" ausgewählt. Gelöschte Loadbalancer können nicht "" ""wiederhergestellt werden."" msgstr[1] """" ""Sie haben \""%s\"" ausgewählt. Gelöschte Loadbalancer können nicht "" ""wiederhergestellt werden."" #, python-format",55,62
openstack%2Fneutron~master~I31d1a31a935fdcdd12e13e1bc58f7c5f640ca092,openstack/neutron,master,I31d1a31a935fdcdd12e13e1bc58f7c5f640ca092,"Make ""phys_brs"" argument in OVSAgentExtensionAPI optional",MERGED,2019-03-05 16:01:18.000000000,2019-03-06 11:35:17.000000000,2019-03-06 11:35:17.000000000,"[{'_account_id': 1131}, {'_account_id': 5367}, {'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 11975}, {'_account_id': 13294}, {'_account_id': 13995}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-03-05 16:01:18.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_agent_extension_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f08de5cbe9695700e282b9882c661353a2c36d74', 'message': 'Make ""phys_brs"" argument in OVSAgentExtensionAPI optional\n\nIn [1], a new init parameter was introduced in the class\nOVSAgentExtensionAPI. This change in the extension API can break\nbackwards compatibility with other projects (networking_sfc and\nbagpipe are affected).\n\nBecause this parameter is needed only in qos_driver extension when\ncalling OVSAgentExtensionAPI.request_phy_brs() (to retrieve the\nphysical bridges list), we can make this new parameter optional not\nto break other stadium projects. When the OVS it\'s initialized\n(in-tree agent), the extension is called with the three needed\nparameters.\n\n[1] https://review.openstack.org/#/c/406841/22/neutron/plugins/ml2/drivers/openvswitch/agent/ovs_agent_extension_api.py@43\n\nChange-Id: I31d1a31a935fdcdd12e13e1bc58f7c5f640ca092\nCloses-Bug: #1818693\n'}]",0,641064,f08de5cbe9695700e282b9882c661353a2c36d74,12,10,1,16688,,,0,"Make ""phys_brs"" argument in OVSAgentExtensionAPI optional

In [1], a new init parameter was introduced in the class
OVSAgentExtensionAPI. This change in the extension API can break
backwards compatibility with other projects (networking_sfc and
bagpipe are affected).

Because this parameter is needed only in qos_driver extension when
calling OVSAgentExtensionAPI.request_phy_brs() (to retrieve the
physical bridges list), we can make this new parameter optional not
to break other stadium projects. When the OVS it's initialized
(in-tree agent), the extension is called with the three needed
parameters.

[1] https://review.openstack.org/#/c/406841/22/neutron/plugins/ml2/drivers/openvswitch/agent/ovs_agent_extension_api.py@43

Change-Id: I31d1a31a935fdcdd12e13e1bc58f7c5f640ca092
Closes-Bug: #1818693
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/641064/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_agent_extension_api.py'],1,f08de5cbe9695700e282b9882c661353a2c36d74,bug/1818693," def __init__(self, int_br, tun_br, phys_brs=None): self.br_phys = phys_brs or {}"," def __init__(self, int_br, tun_br, phys_brs): self.br_phys = phys_brs",2,2
openstack%2Ftripleo-image-elements~stable%2Fqueens~I6dea32cdee8d0cad83817a6e5ae667b9d15306c5,openstack/tripleo-image-elements,stable/queens,I6dea32cdee8d0cad83817a6e5ae667b9d15306c5,DNM - Test with upper constraints,ABANDONED,2019-03-06 09:27:04.000000000,2019-03-06 11:33:08.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-06 09:27:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/841aa334f93df319e0f901c8837613c91728192b', 'message': 'DNM - Test with upper constraints\n\nChange-Id: I6dea32cdee8d0cad83817a6e5ae667b9d15306c5\n'}]",0,641286,841aa334f93df319e0f901c8837613c91728192b,3,1,1,24245,,,0,"DNM - Test with upper constraints

Change-Id: I6dea32cdee8d0cad83817a6e5ae667b9d15306c5
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/86/641286/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,841aa334f93df319e0f901c8837613c91728192b,DNM-Testing,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/queens} -r{toxinidir}/requirements.txt,deps = -r{toxinidir}/requirements.txt,3,1
openstack%2Fpython-glanceclient~master~I33971a2a16416c8538158299325471c2a69dbb3e,openstack/python-glanceclient,master,I33971a2a16416c8538158299325471c2a69dbb3e,Remove redundant information from error message,MERGED,2017-06-19 11:54:14.000000000,2019-03-06 11:28:50.000000000,2019-03-06 11:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 20146}, {'_account_id': 22348}, {'_account_id': 27248}, {'_account_id': 28543}]","[{'number': 1, 'created': '2017-06-19 11:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/526a56922f28746f48ded222d48030e3a93d0fdb', 'message': 'Remove redundant information from error message\n\nCurrently user get redundant HTTP error code in error message.\nRemoved redundant HTTP error code from the message.\n\nFor Example:\nError message display when user trying to get the non existing image:\n$ glance image-show f433471a-53a8-4d31-bf8f-f0b6b594dfc\nError message:\n404 Not Found\nNo image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc\n    (HTTP 404)\n\nAfter this fix:\nHTTP 404 Not Found No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc\n\nCloses-Bug: #1598714\nChange-Id: I33971a2a16416c8538158299325471c2a69dbb3e\n'}, {'number': 2, 'created': '2017-06-20 12:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/3fae0aba142228a0ef5ff316341b8fb4bd6fd6c9', 'message': 'Remove redundant information from error message\n\nCurrently user get redundant HTTP error code in error message.\nRemoved redundant HTTP error code from the message.\n\nFor Example:\nError message display when user trying to get the non existing image:\n$ glance image-show f433471a-53a8-4d31-bf8f-f0b6b594dfc\nError message:\n404 Not Found\nNo image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc\n    (HTTP 404)\n\nAfter this fix:\nHTTP 404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc\n\nCloses-Bug: #1598714\nChange-Id: I33971a2a16416c8538158299325471c2a69dbb3e\n'}, {'number': 3, 'created': '2017-07-13 06:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cbcf6dc71910791b988ed0473b6cd31e6eee74ec', 'message': 'Remove redundant information from error message\n\nCurrently user get redundant HTTP error code in error message.\nRemoved redundant HTTP error code from the message.\n\nFor Example:\nError message display when user trying to get the non existing image:\n$ glance image-show f433471a-53a8-4d31-bf8f-f0b6b594dfc\nError message:\n404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc (HTTP 404)\n\nAfter this fix:\nHTTP 404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc\n\nCloses-Bug: #1598714\nChange-Id: I33971a2a16416c8538158299325471c2a69dbb3e\n'}, {'number': 4, 'created': '2019-03-06 07:34:01.000000000', 'files': ['glanceclient/exc.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ae4355be01c0b4bcf5b6bdd2c1163b3f6df3e213', 'message': 'Remove redundant information from error message\n\nCurrently user get redundant HTTP error code in error message.\nRemoved redundant HTTP error code from the message.\n\nFor Example:\nError message display when user trying to get the non existing image:\n$ glance image-show f433471a-53a8-4d31-bf8f-f0b6b594dfc\nError message:\n404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc (HTTP 404)\n\nAfter this fix:\nHTTP 404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc\n\nCloses-Bug: #1598714\nChange-Id: I33971a2a16416c8538158299325471c2a69dbb3e\n'}]",3,475351,ae4355be01c0b4bcf5b6bdd2c1163b3f6df3e213,30,9,4,20182,,,0,"Remove redundant information from error message

Currently user get redundant HTTP error code in error message.
Removed redundant HTTP error code from the message.

For Example:
Error message display when user trying to get the non existing image:
$ glance image-show f433471a-53a8-4d31-bf8f-f0b6b594dfc
Error message:
404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc (HTTP 404)

After this fix:
HTTP 404 Not Found: No image found with ID f433471a-53a8-4d31-bf8f-f0b6b594dfc

Closes-Bug: #1598714
Change-Id: I33971a2a16416c8538158299325471c2a69dbb3e
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/51/475351/3 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/exc.py'],1,526a56922f28746f48ded222d48030e3a93d0fdb,bug/1598714," return ""HTTP %s"" % (self.details)"," return ""%s (HTTP %s)"" % (self.details, self.code)",1,1
openstack%2Fcinder~master~I33bd43b2d62b2caec0a579b209dd334e32ac8f04,openstack/cinder,master,I33bd43b2d62b2caec0a579b209dd334e32ac8f04,"Add x_project_id, accepted to transfers",MERGED,2018-11-05 07:28:13.000000000,2019-03-06 11:27:00.000000000,2019-01-13 17:56:23.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 20722}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26458}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29344}]","[{'number': 1, 'created': '2018-11-05 07:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d2cdabdb558c44fab1951d6d90f82852483710e', 'message': 'WIP: Improve transfer records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n'}, {'number': 2, 'created': '2018-11-05 08:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ccc0846563de20e053f8cc07957ef4bf1da57897', 'message': 'WIP: Improve transfer records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n'}, {'number': 3, 'created': '2018-11-06 03:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4713f90c6be34adc16f5e23692e0ce89ef11e26f', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'original_project_id', 'current_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}, {'number': 4, 'created': '2018-11-06 07:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/43561049fb8be2967dc8e8d586bebbc60609406d', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'original_project_id', 'current_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}, {'number': 5, 'created': '2018-12-10 08:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dacac9751d808b4eea03ea10c3ff6226f77a9998', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'source_project_id', 'destination_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}, {'number': 6, 'created': '2018-12-12 03:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f64ee6c2fe431483151f90dce6bd34ae27dee75', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'source_project_id', 'destination_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}, {'number': 7, 'created': '2018-12-12 06:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/62ba0e0701ff63729502fbf3bd7df26986387025', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'source_project_id', 'destination_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}, {'number': 8, 'created': '2018-12-12 07:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2b7c62bb722c4e54e5c0905580c3e489f2981a4', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'source_project_id', 'destination_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}, {'number': 9, 'created': '2018-12-20 08:03:16.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/128_add_project_id_and_accepted_to_transfer.py', 'cinder/db/sqlalchemy/models.py', 'cinder/tests/unit/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/53ec4c8c4d5a14d158f040ad58210f95cdd072da', 'message': ""Add x_project_id, accepted to transfers\n\nThis patch adds the 'source_project_id', 'destination_project_id',\n'accepted' fields to transfers table and model.\n\nPart of blueprint: improve-volume-transfer-records\n\nChange-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04\n""}]",13,615487,53ec4c8c4d5a14d158f040ad58210f95cdd072da,231,50,9,20722,,,0,"Add x_project_id, accepted to transfers

This patch adds the 'source_project_id', 'destination_project_id',
'accepted' fields to transfers table and model.

Part of blueprint: improve-volume-transfer-records

Change-Id: I33bd43b2d62b2caec0a579b209dd334e32ac8f04
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/615487/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/transfer/api.py', 'cinder/db/sqlalchemy/api.py', 'cinder/db/sqlalchemy/migrate_repo/versions/127_add_project_id_and_accept_to_transfer.py', 'cinder/api/microversions.py', 'cinder/api/views/transfers.py', 'cinder/db/sqlalchemy/models.py']",6,0d2cdabdb558c44fab1951d6d90f82852483710e,bp/improve-volume-transfer-records," original_project_id = Column(String(255), nullable=True) current_project_id = Column(String(255), nullable=True) accept = Column(Boolean, default=False)",,60,3
openstack%2Fmanila~master~I388a5d2eca5bf72f24413f4ca636addf0b76d19b,openstack/manila,master,I388a5d2eca5bf72f24413f4ca636addf0b76d19b,DNM - touch all .py files for pylint testing,ABANDONED,2019-02-19 14:23:49.000000000,2019-03-06 11:19:03.000000000,,"[{'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24236}]","[{'number': 1, 'created': '2019-02-19 14:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/19b2899302c737959d3846f7501468606a22c91d', 'message': 'DNM - touch all .py files for pylint testing\n\nChange-Id: I388a5d2eca5bf72f24413f4ca636addf0b76d19b\n'}, {'number': 2, 'created': '2019-02-19 15:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/43339b19f94d4e53c26aa2aafcb841627b206fc8', 'message': 'DNM - touch all .py files for pylint testing\n\nDepends-On: https://review.openstack.org/637634/\nDepends-On: https://review.openstack.org/637644/\nDepends-On: https://review.openstack.org/637659/\nChange-Id: I388a5d2eca5bf72f24413f4ca636addf0b76d19b\n'}, {'number': 3, 'created': '2019-02-19 23:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/168aaa69ab5c900ddfee6f3926cb253a944189ca', 'message': 'DNM - touch all .py files for pylint testing\n\nDepends-On: https://review.openstack.org/636739/\nDepends-On: https://review.openstack.org/637659/\nChange-Id: I388a5d2eca5bf72f24413f4ca636addf0b76d19b\n'}, {'number': 4, 'created': '2019-02-20 10:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/848393648c486d3ed6bef9b9386d96e2d7dd3a35', 'message': 'DNM - touch all .py files for pylint testing\n\nDepends-On: https://review.openstack.org/637659/\nDepends-On: https://review.openstack.org/638127/\nChange-Id: I388a5d2eca5bf72f24413f4ca636addf0b76d19b\n'}, {'number': 5, 'created': '2019-02-20 10:57:17.000000000', 'files': ['manila/tests/message/__init__.py', 'manila/scheduler/weighers/capacity.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/api/v1/share_manage.py', 'manila/policies/quota_class_set.py', 'manila/share/drivers/netapp/__init__.py', 'manila/api/v1/security_service.py', 'manila/tests/api/v2/test_share_group_types.py', 'manila/share/drivers/dell_emc/plugins/vnx/__init__.py', 'manila/tests/runtime_conf.py', 'manila/tests/share/drivers/dell_emc/plugins/vmax/test_object_manager.py', 'manila/db/migrations/alembic/versions/238720805ce1_add_messages_table.py', 'manila/tests/common/__init__.py', 'manila/tests/share/drivers/netapp/__init__.py', 'manila/tests/scheduler/__init__.py', 'manila/tests/share/drivers/netapp/dataontap/client/fakes.py', 'manila/scheduler/utils.py', 'manila/scheduler/weighers/base_host.py', 'manila/scheduler/drivers/chance.py', 'manila/tests/test_coordination.py', 'manila/policies/scheduler_stats.py', 'manila/tests/wsgi/__init__.py', 'manila/api/auth.py', 'manila/tests/share/drivers/infinidat/test_infinidat.py', 'manila/tests/share/test_api.py', 'manila/tests/api/views/test_share_accesses.py', 'manila/tests/api/contrib/stubs.py', 'manila/tests/db/migrations/__init__.py', 'manila/tests/share/drivers/windows/test_service_instance.py', 'manila/share/drivers/generic.py', 'manila/db/migrations/alembic/versions/493eaffd79e1_add_mtu_network_allocations_share_networks.py', 'manila/tests/scheduler/filters/test_base.py', 'manila/policies/__init__.py', 'manila/share/drivers/dell_emc/plugin_manager.py', 'manila/tests/share/drivers/ganesha/test_utils.py', 'manila/tests/share/drivers/container/test_storage_helper.py', 'manila/db/migrations/alembic/versions/fdfb668d19e1_add_gateway_to_network_allocations_table.py', 'manila/network/linux/interface.py', 'manila/db/migrations/alembic/versions/4a482571410f_add_backends_info_table.py', 'manila/policies/share_replica.py', 'manila/scheduler/filters/json.py', 'manila/tests/share/drivers/qnap/test_api.py', 'manila/tests/api/test_versions.py', 'manila/tests/api/v2/test_messages.py', 'manila/share/drivers/dell_emc/plugins/vmax/__init__.py', 'manila/share/drivers/huawei/base.py', 'manila/share/drivers/huawei/huawei_nas.py', 'manila/api/openstack/versioned_method.py', 'manila/api/views/services.py', 'manila/tests/api/v2/test_share_snapshots.py', 'manila/tests/share/drivers/hitachi/hsp/test_driver.py', 'manila/tests/share/drivers/test_glusterfs.py', 'manila/db/sqlalchemy/api.py', 'manila/share/drivers/helpers.py', 'manila/tests/scheduler/filters/test_capabilities.py', 'manila/tests/fake_zfssa.py', 'manila/policies/quota_set.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_cifs_cmode.py', 'manila/share/drivers/windows/service_instance.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_connection.py', 'manila/api/views/scheduler_stats.py', 'manila/share/drivers/dell_emc/plugins/vnx/connection.py', 'manila/share/drivers/netapp/dataontap/__init__.py', 'manila/tests/wsgi/test_common.py', '.zuul.yaml', 'manila/cmd/scheduler.py', 'manila/tests/share/drivers/dummy.py', 'manila/tests/share/drivers/nexenta/ns5/test_nexenta_nas.py', 'manila/api/v1/share_unmanage.py', 'manila/tests/share/drivers/qnap/test_qnap.py', 'manila/tests/share/test_share_types.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/__init__.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/test.py', 'manila/scheduler/weighers/goodness.py', 'manila/db/migrations/alembic/versions/221a83cfd85b_change_user_project_id_length.py', 'manila/db/migrations/alembic/versions/63809d875e32_add_access_key.py', 'manila/share/drivers/zfssa/__init__.py', 'manila/tests/api/test_wsgi.py', 'manila/network/__init__.py', 'manila/api/openstack/__init__.py', 'manila/db/migrations/alembic/versions/11ee96se625f3_add_metadata_for_access.py', 'manila/tests/scheduler/drivers/__init__.py', 'manila/share/drivers/dell_emc/plugins/vmax/object_manager.py', 'manila/api/views/quota_class_sets.py', 'manila/policies/share_type.py', 'manila/share/drivers/huawei/v3/replication.py', 'manila/api/v2/share_snapshots.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/__init__.py', 'manila/tests/share/drivers/dell_emc/__init__.py', 'manila/api/views/share_snapshots.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_data_motion.py', 'manila/share/drivers/netapp/utils.py', 'manila/tests/share/drivers/dell_emc/common/enas/__init__.py', 'manila/tests/share/drivers/glusterfs/test_common.py', 'manila/share/drivers/netapp/dataontap/client/__init__.py', 'manila/tests/scheduler/drivers/test_filter.py', 'manila/share/drivers/dell_emc/common/enas/__init__.py', 'manila/tests/network/linux/test_ip_lib.py', 'manila/coordination.py', 'manila/api/v2/share_export_locations.py', 'manila/api/views/share_networks.py', 'manila/tests/network/neutron/test_neutron_api.py', 'manila/tests/__init__.py', 'manila/wsgi/wsgi.py', 'manila/share/drivers/hpe/__init__.py', 'manila/share/drivers/maprfs/maprfs_native.py', 'manila/tests/test_test_utils.py', 'manila/network/linux/__init__.py', 'manila/scheduler/drivers/filter.py', 'manila/tests/scheduler/weighers/test_goodness.py', 'manila/tests/fake_share.py', 'manila/share/drivers/ibm/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/utils.py', 'manila/db/migrations/alembic/versions/b10fb432c042_squash_share_group_snapshot_members_and_share_snapshot_instance_models.py', 'manila/policies/share_snapshot_export_location.py', 'manila/share/drivers/zfsonlinux/utils.py', 'manila/db/api.py', 'manila/tests/share/test_access.py', 'manila/tests/api/__init__.py', 'manila/tests/test_utils.py', 'manila/share/drivers/dell_emc/plugins/isilon/__init__.py', 'manila/api/v1/share_metadata.py', 'manila/share/snapshot_access.py', 'manila/api/views/share_snapshot_export_locations.py', 'manila/scheduler/rpcapi.py', 'manila/db/migrations/alembic/versions/48a7beae3117_move_share_type_id_to_instances.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_driver.py', 'manila/tests/api/v1/test_security_service.py', 'manila/api/v2/messages.py', 'manila/policies/service.py', 'manila/share/drivers/maprfs/driver_util.py', 'manila/tests/test_rpc.py', 'manila/share/drivers/glusterfs/layout_directory.py', 'manila/scheduler/filters/driver.py', 'manila/tests/api/test_middleware.py', 'manila/share/drivers/windows/windows_smb_helper.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_constants.py', 'manila/cmd/manage.py', 'manila/db/migrations/alembic/versions/17115072e1c3_add_nova_net_id_column_to_share_networks.py', 'manila/share/drivers/huawei/v3/rpcapi.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_single_svm.py', 'manila/scheduler/host_manager.py', 'manila/api/v2/share_instance_export_locations.py', 'manila/db/migrations/alembic/versions/211836bf835c_add_access_level.py', 'manila/share/drivers/zfssa/zfssarest.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_single_svm.py', 'manila/api/v2/share_snapshot_instance_export_locations.py', 'manila/api/views/share_servers.py', 'manila/db/migrations/alembic/versions/5155c7077f99_add_more_network_info_attributes_to_network_allocations_table.py', 'manila/share/manager.py', 'manila/tests/db/test_migration.py', 'manila/share/drivers/netapp/dataontap/protocols/nfs_cmode.py', 'manila/share/drivers/qnap/qnap.py', 'manila/tests/api/test_extensions.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/res_mock.py', 'manila/tests/api/openstack/test_api_version_request.py', 'manila/tests/share/drivers/nexenta/test_utils.py', 'manila/wsgi/eventlet_server.py', 'manila/api/v2/router.py', 'manila/api/views/share_replicas.py', 'manila/db/migrations/alembic/versions/a77e2ad5012d_add_share_snapshot_access.py', 'manila/db/migrations/alembic/versions/3651e16d7c43_add_consistency_groups.py', 'manila/share/drivers/windows/windows_smb_driver.py', 'manila/tests/db/sqlalchemy/test_models.py', 'manila/tests/integrated/integrated_helpers.py', 'manila/tests/fake_driver.py', 'manila/db/migrations/alembic/versions/829a09b0ddd4_fix_project_share_type_quotas_unique_constraint.py', 'manila/tests/volume/test_cinder.py', 'manila/tests/scheduler/test_manager.py', 'manila/tests/api/v2/test_share_instance_export_locations.py', 'manila/share/drivers/lvm.py', 'manila/policies/availability_zone.py', 'manila/db/sqlalchemy/__init__.py', 'manila/share/drivers/nexenta/ns5/nexenta_nas.py', 'manila/tests/share/drivers/container/__init__.py', 'manila/api/v2/share_snapshot_export_locations.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_single_svm.py', 'manila/api/v2/share_group_type_specs.py', 'manila/scheduler/weighers/pool.py', 'manila/tests/share/drivers/hitachi/hsp/fakes.py', 'manila/share/drivers/huawei/v3/smartx.py', 'manila/tests/data/__init__.py', 'manila/tests/scheduler/filters/test_share_replication.py', 'manila/tests/share/drivers/quobyte/test_quobyte.py', 'manila/api/v2/share_replica_export_locations.py', 'manila/share/drivers/glusterfs/common.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/share/drivers/netapp/common.py', 'manila/api/v2/__init__.py', 'manila/db/migrations/alembic/versions/3a482171410f_add_drivers_private_data_table.py', 'manila/network/neutron/api.py', 'manila/policies/share_group_types_spec.py', 'manila/tests/share/__init__.py', 'manila/tests/share/drivers/maprfs/__init__.py', 'manila/api/openstack/api_version_request.py', 'manila/tests/share/drivers/hpe/__init__.py', 'manila/policies/base.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/fake_exceptions.py', 'manila/share/drivers/dell_emc/common/__init__.py', 'manila/tests/share/drivers/nexenta/ns4/test_nexenta_nas.py', 'manila/tests/share/drivers/dell_emc/plugins/vnx/test_connection.py', 'manila/share/drivers/service_instance.py', 'manila/tests/share/drivers/nexenta/ns5/__init__.py', 'manila/policies/share_access.py', 'manila/db/migrations/utils.py', 'manila/tests/api/views/test_quota_class_sets.py', 'manila/tests/scheduler/filters/test_ignore_attempted_hosts.py', 'manila/tests/api/v2/test_share_replica_export_locations.py', 'manila/share/drivers/maprfs/__init__.py', 'manila/scheduler/base_handler.py', 'manila/scheduler/weighers/base.py', 'manila/share/configuration.py', 'manila/api/views/versions.py', 'manila/api/v1/limits.py', 'manila/api/__init__.py', 'manila/db/migrations/alembic/versions/293fac1130ca_add_replication_attrs.py', 'manila/tests/share/drivers/container/test_container_helper.py', 'manila/wsgi/__init__.py', 'manila/share/drivers/container/storage_helper.py', 'manila/share/drivers/infinidat/infinibox.py', 'manila/context.py', 'manila/share/drivers/zfssa/restclient.py', 'manila/db/migrations/alembic/versions/323840a08dc4_add_shares_task_state.py', 'manila/tests/scheduler/test_rpcapi.py', 'manila/scheduler/filters/base.py', 'manila/tests/scheduler/weighers/test_base.py', 'manila/api/views/availability_zones.py', 'manila/share/drivers/cephfs/__init__.py', 'manila/share/drivers/dell_emc/common/enas/utils.py', 'manila/tests/share/drivers/cephfs/__init__.py', 'manila/tests/share/drivers/windows/test_windows_smb_helper.py', 'manila/api/v2/shares.py', 'manila/data/manager.py', 'manila/tests/network/neutron/test_neutron_plugin.py', 'manila/scheduler/filters/share_replication.py', 'manila/tests/fake_network.py', 'manila/scheduler/filters/retry.py', 'manila/tests/data/test_utils.py', 'manila/tests/scheduler/weighers/test_capacity.py', 'manila/tests/share/drivers/container/fakes.py', 'manila/cmd/__init__.py', 'manila/tests/api/v2/test_share_group_snapshots.py', 'manila/api/v1/share_snapshots.py', 'manila/tests/share/drivers/zfssa/__init__.py', 'manila/data/rpcapi.py', 'manila/share/drivers/cephfs/driver.py', 'manila/api/views/share_group_snapshots.py', 'manila/share/drivers/container/protocol_helper.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/share/drivers/quobyte/__init__.py', 'manila/tests/share/drivers/netapp/dataontap/client/__init__.py', 'manila/policies/message.py', 'manila/tests/share/drivers/glusterfs/test_layout.py', 'manila/share/drivers/nexenta/__init__.py', 'manila/tests/scheduler/test_scheduler_options.py', 'manila/scheduler/filters/availability_zone.py', 'manila/tests/api/v1/test_share_snapshots.py', 'manila/tests/fake_service_instance.py', 'manila/db/migrations/alembic/versions/dda6de06349_add_export_locations_metadata.py', 'manila/tests/share/drivers/glusterfs/__init__.py', 'manila/tests/scheduler/weighers/__init__.py', 'manila/tests/api/v2/test_share_access_metadata.py', 'manila/tests/share_group/test_api.py', 'manila/tests/share/drivers/dell_emc/test_driver.py', 'manila/db/base.py', 'manila/tests/xenapi/__init__.py', 'manila/db/migrations/alembic/versions/55761e5f59c5_add_snapshot_support_extra_spec_to_share_types.py', 'manila/policies/share_group_snapshot.py', 'manila/api/v2/share_snapshot_instances.py', 'manila/db/migrations/alembic/versions/162a3e673105_manila_init.py', 'manila/tests/share/drivers/__init__.py', 'manila/api/v2/share_accesses.py', 'manila/share_group/__init__.py', 'manila/tests/api/openstack/test_wsgi.py', 'manila/tests/api/v2/test_share_groups.py', 'manila/tests/share/drivers/nexenta/__init__.py', 'manila/compute/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon.py', 'manila/tests/api/v2/test_quota_sets.py', 'manila/tests/share/drivers/zfssa/test_zfssashare.py', 'manila/share/drivers/huawei/constants.py', 'manila/share/drivers/dell_emc/plugins/vnx/object_manager.py', 'manila/tests/share/drivers/qnap/__init__.py', 'manila/tests/test_policy.py', 'manila/share/access.py', 'manila/tests/cmd/test_share.py', 'manila/share/drivers/nexenta/ns4/nexenta_nfs_helper.py', 'manila/tests/api/v2/test_share_instances.py', 'manila/db/migrations/alembic/versions/5077ffcc5f1c_add_share_instances.py', 'manila/tests/share/drivers/hdfs/__init__.py', 'manila/tests/fake_notifier.py', 'manila/cmd/share.py', 'manila/tests/api/extensions/__init__.py', 'manila/share/drivers/hitachi/hsp/driver.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/data_motion.py', 'manila/tests/scheduler/evaluator/__init__.py', 'manila/policies/share_snapshot_instance.py', 'manila/common/constants.py', 'manila/policies/share_export_location.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_api.py', 'manila/tests/integrated/test_login.py', 'manila/tests/scheduler/fakes.py', 'manila/api/views/share_group_types.py', 'manila/share/drivers/quobyte/jsonrpc.py', 'manila/api/v1/share_servers.py', 'manila/tests/api/v2/test_share_snapshot_instance_export_locations.py', 'manila/db/migrations/alembic/versions/87ce15c59bbe_add_revert_to_snapshot_support.py', 'manila/db/migrations/alembic/versions/3e7d62517afa_add_create_share_from_snapshot_support.py', 'manila/policies/share_network.py', 'manila/tests/scheduler/drivers/test_base.py', 'manila/api/contrib/__init__.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/scheduler/filters/test_extra_specs_ops.py', 'manila/version.py', 'manila/policies/share_server.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/tests/share/drivers/quobyte/__init__.py', 'manila/tests/share/drivers/container/test_protocol_helper.py', 'manila/api/openstack/urlmap.py', 'manila/policies/share_replica_export_location.py', 'manila/tests/api/test_common.py', 'manila/tests/share/test_drivers_private_data.py', 'manila/share/hooks/__init__.py', 'manila/db/migrations/alembic/versions/e8ea58723178_remove_host_from_driver_private_data.py', 'manila/api/extensions.py', 'manila/api/v1/shares.py', 'manila/data/helper.py', 'manila/tests/share/drivers/glusterfs/test_glusterfs_native.py', 'manila/tests/share/test_share_utils.py', 'manila/api/v2/share_access_metadata.py', 'manila/api/v2/share_replicas.py', 'manila/tests/share/drivers/dell_emc/common/enas/utils.py', 'manila/api/v2/share_group_snapshots.py', 'manila/tests/api/v2/test_availability_zones.py', 'manila/api/v2/share_group_types.py', 'manila/tests/api/v2/test_services.py', 'manila/share/drivers/glusterfs/__init__.py', 'manila/tests/share/test_driver.py', 'manila/cmd/status.py', 'manila/scheduler/filters/share_group_filters/consistent_snapshot.py', 'manila/share/drivers/tegile/tegile.py', 'manila/api/views/limits.py', 'manila/network/standalone_network_plugin.py', 'manila/share/drivers/zfsonlinux/driver.py', 'manila/tests/api/views/test_scheduler_stats.py', 'manila/tests/scheduler/evaluator/test_evaluator.py', 'manila/tests/test_test.py', 'manila/tests/api/v2/test_share_networks.py', 'manila/share/drivers/veritas/veritas_isa.py', 'manila/tests/share/drivers/huawei/test_huawei_nas.py', 'manila/tests/scheduler/filters/test_availability_zone.py', 'manila/tests/test_exception.py', 'manila/tests/api/v1/stubs.py', 'manila/network/linux/ovs_lib.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/scheduler/filters/share_group_filters/__init__.py', 'manila/tests/message/test_api.py', 'manila/tests/scheduler/filters/test_json.py', 'manila/api/views/shares.py', 'manila/share/drivers/dell_emc/plugins/unity/client.py', 'manila/share/drivers/hitachi/hsp/__init__.py', 'manila/volume/__init__.py', 'manila/db/migrations/alembic/versions/eb6d5544cbbd_add_provider_location_to_share_snapshot_instances.py', 'manila/db/sqlalchemy/query.py', 'manila/hacking/__init__.py', 'manila/scheduler/drivers/simple.py', 'manila/tests/share/drivers/netapp/fakes.py', 'manila/policies/share_instance_export_location.py', 'manila/tests/share/drivers/zfsonlinux/test_driver.py', 'manila/scheduler/filters/capacity.py', 'manila/tests/api/v1/test_share_unmanage.py', 'manila/tests/share/drivers/netapp/test_common.py', 'manila/scheduler/__init__.py', 'manila/share_group/api.py', 'manila/tests/message/test_message_field.py', 'manila/tests/scheduler/drivers/test_simple.py', 'manila/tests/share/drivers/ganesha/__init__.py', 'manila/tests/share/drivers/veritas/__init__.py', 'manila/api/v1/router.py', 'manila/share/drivers/hpe/hpe_3par_driver.py', 'manila/share/drivers/huawei/huawei_utils.py', 'manila/tests/share/drivers/dell_emc/plugins/vmax/test_connection.py', 'manila/tests/scheduler/filters/test_base_host.py', 'manila/policy.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon.py', 'manila/share/drivers/qnap/api.py', 'manila/tests/share/drivers/dell_emc/common/__init__.py', 'manila/utils.py', 'manila/db/migrations/alembic/versions/4ee2cf4be19a_remove_share_snapshots_export_location.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon_api.py', 'manila/tests/scheduler/test_utils.py', 'manila/api/v1/share_types_extra_specs.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon_api.py', 'manila/tests/share/drivers/windows/test_windows_utils.py', 'manila/data/utils.py', 'manila/share/drivers/huawei/__init__.py', 'manila/share/drivers/dell_emc/driver.py', 'manila/tests/api/openstack/test_versioned_method.py', 'manila/tests/api/v1/test_share_manage.py', 'manila/tests/share/drivers/zfsonlinux/__init__.py', 'manila/db/migrations/alembic/versions/344c1ac4747f_add_share_instance_access_rules_status.py', 'manila/tests/share/drivers/windows/__init__.py', 'manila/tests/share/drivers/huawei/__init__.py', 'manila/tests/share/test_snapshot_access.py', 'manila/policies/share_types_extra_spec.py', 'manila/tests/common/test_config.py', 'manila/tests/db/__init__.py', 'manila/tests/cmd/__init__.py', 'manila/share/drivers/windows/windows_utils.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_driver_interfaces.py', 'manila/api/views/security_service.py', 'manila/share/drivers/hitachi/hnas/driver.py', 'manila/tests/conf_fixture.py', 'manila/share/drivers/dell_emc/plugins/unity/connection.py', 'manila/tests/share/drivers/inspur/as13000/test_as13000_nas.py', 'manila/common/client_auth.py', 'manila/share/drivers/huawei/v3/__init__.py', 'manila/tests/api/extensions/foxinsocks.py', 'manila/db/migration.py', 'manila/share/drivers/inspur/as13000/__init__.py', 'manila/tests/integrated/__init__.py', 'manila/tests/share/test_rpcapi.py', 'manila/api/v2/share_instances.py', 'manila/tests/api/v1/test_share_types_extra_specs.py', 'manila/tests/api/views/test_quota_sets.py', 'manila/tests/share_group/__init__.py', 'manila/api/views/types.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/performance.py', 'manila/tests/api/views/test_versions.py', 'manila/tests/api/v2/test_shares.py', 'manila/volume/cinder.py', 'manila/tests/api/v2/test_security_services.py', 'manila/share/migration.py', 'manila/share/drivers/ganesha/utils.py', 'manila/db/migrations/alembic/versions/54667b9cade7_restore_share_instance_access_map_state.py', 'manila/tests/monkey_patch_example/__init__.py', 'manila/tests/api/contrib/__init__.py', 'manila/tests/share/drivers/qnap/fakes.py', 'manila/tests/share/drivers/hitachi/hnas/__init__.py', 'manila/tests/api/v2/test_share_types.py', 'manila/common/config.py', 'manila/tests/share/drivers/maprfs/test_maprfs.py', 'manila/tests/share/drivers/test_helpers.py', 'manila/tests/fake_compute.py', 'manila/tests/db_utils.py', 'manila/common/__init__.py', 'manila/scheduler/filters/extra_specs_ops.py', 'manila/tests/share/drivers/veritas/test_veritas_isa.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_multi_svm.py', 'manila/tests/fake_utils.py', 'manila/tests/fake_volume.py', 'manila/exception.py', 'manila/message/message_levels.py', 'manila/tests/api/v2/test_share_snapshot_instances.py', 'manila/tests/api/views/test_share_networks.py', 'manila/db/migrations/alembic/versions/e1949a93157a_add_share_group_types_table.py', 'manila/tests/cmd/test_scheduler.py', 'manila/policies/share_group_type.py', 'manila/share/drivers/nexenta/utils.py', 'manila/api/views/share_instance.py', 'manila/tests/common/test_client_auth.py', 'manila/tests/api/openstack/__init__.py', 'manila/compute/nova.py', 'manila/policies/share_access_metadata.py', 'manila/tests/share/drivers/hdfs/test_hdfs_native.py', 'manila/tests/share/drivers/hitachi/hsp/test_rest.py', 'manila/tests/utils.py', 'manila/tests/data/test_rpcapi.py', 'manila/tests/share/drivers/glusterfs/test_layout_directory.py', 'manila/tests/integrated/test_extensions.py', 'manila/share/drivers/windows/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_client.py', 'manila/tests/share/drivers/tegile/__init__.py', 'manila/tests/network/__init__.py', 'manila/tests/network/linux/__init__.py', 'manila/tests/data/test_helper.py', 'manila/db/migrations/alembic/versions/0274d20c560f_add_ou_to_security_service.py', 'manila/tests/db/sqlalchemy/__init__.py', 'manila/network/neutron/constants.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/hitachi/__init__.py', 'manila/tests/share/drivers/nexenta/ns5/test_jsonrpc.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_performance.py', 'manila/tests/api/v1/test_share_servers.py', 'manila/tests/share/test_migration.py', 'manila/share/__init__.py', 'manila/share/drivers/dell_emc/plugins/__init__.py', 'manila/tests/share_group/test_share_group_types.py', 'manila/cmd/data.py', 'manila/db/migrations/alembic/versions/1f0bd302c1a6_add_availability_zones_table.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py', 'manila/tests/test_network.py', 'manila/share/drivers/nexenta/ns4/__init__.py', 'manila/db/migrations/alembic/versions/27cb96d991fa_add_description_for_share_type.py', 'manila/network/linux/ip_lib.py', 'manila/tests/share/drivers/test_lvm.py', 'manila/api/v2/share_groups.py', 'manila/tests/share/drivers/dell_emc/plugins/__init__.py', 'manila/policies/share_instance.py', 'manila/db/migrations/alembic/versions/ef0c02b4366_add_share_type_projects.py', 'manila/tests/db/migrations/alembic/test_migration.py', 'manila/tests/compute/__init__.py', 'manila/tests/db/migrations/alembic/__init__.py', 'manila/tests/declare_conf.py', 'manila/db/migrations/alembic/versions/d5db24264f5c_add_consistent_snapshot_support_attr_to_share_group_model.py', 'manila/api/v1/scheduler_stats.py', 'manila/db/migrations/alembic/versions/95e3cf760840_remove_nova_net_id_column_from_share_.py', 'manila/tests/cmd/test_data.py', 'manila/scheduler/manager.py', 'manila/tests/share/drivers/ibm/__init__.py', 'manila/tests/api/v2/test_share_snapshot_export_locations.py', 'manila/tests/share/drivers/zfssa/test_zfssarest.py', 'manila/scheduler/filters/ignore_attempted_hosts.py', 'manila/tests/share/drivers/quobyte/test_jsonrpc.py', 'manila/scheduler/filters/capabilities.py', 'manila/db/migrations/__init__.py', 'manila/share/drivers/dell_emc/plugins/vmax/connection.py', 'manila/db/migrations/alembic/migration.py', 'manila/share/utils.py', 'manila/tests/test_service.py', 'manila/db/migrations/alembic/versions/30cb96d995fa_add_is_public_column_for_share.py', 'manila/tests/scheduler/filters/test_retry.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_nfs_cmode.py', 'manila/tests/share/test_hook.py', 'manila/api/views/messages.py', 'manila/share/drivers/hitachi/hnas/__init__.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/tests/share/drivers/test_ganesha.py', 'manila/tests/cmd/test_manage.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/share/drivers/tegile/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/vnx/__init__.py', 'manila/api/v2/quota_sets.py', 'manila/share/drivers/netapp/options.py', 'manila/share_group/share_group_types.py', 'manila/share/share_types.py', 'manila/tests/scheduler/filters/__init__.py', 'manila/scheduler/drivers/__init__.py', 'manila/share/driver.py', 'manila/share/drivers/zfsonlinux/__init__.py', 'manila/tests/data/test_manager.py', 'manila/api/middleware/auth.py', 'manila/db/migrations/alembic/versions/927920b37453_add_provider_location_for_share_group_snapshot_members_model.py', 'manila/policies/security_service.py', 'manila/tests/api/v1/test_share_metadata.py', 'manila/share/api.py', 'manila/share/drivers/container/driver.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_base.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_mediator.py', 'manila/quota.py', 'manila/share/drivers/ganesha/manager.py', 'manila/tests/monkey_patch_example/example_a.py', 'manila/tests/share/drivers/glusterfs/test_layout_volume.py', 'manila/share/drivers_private_data.py', 'manila/tests/test_context.py', 'manila/tests/api/views/__init__.py', 'manila/share/drivers/dell_emc/common/enas/connector.py', 'manila/policies/share_snapshot_instance_export_location.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/share/drivers/dell_emc/plugins/unity/__init__.py', 'manila/i18n.py', 'manila/tests/share/drivers/netapp/test_utils.py', 'manila/api/openstack/wsgi.py', 'manila/tests/cmd/test_api.py', 'manila/message/__init__.py', 'manila/share/drivers/hdfs/__init__.py', 'manila/tests/share/drivers/nexenta/ns4/__init__.py', 'manila/api/versions.py', 'manila/api/views/__init__.py', 'manila/share/drivers/nexenta/ns4/jsonrpc.py', 'manila/api/views/share_groups.py', 'manila/policies/share_group.py', 'manila/share/drivers/dell_emc/common/enas/constants.py', 'manila/tests/api/v1/test_limits.py', 'manila/tests/share/drivers/hitachi/__init__.py', 'manila/scheduler/evaluator/evaluator.py', 'manila/db/migrations/alembic/__init__.py', 'manila/api/v1/__init__.py', 'manila/db/migrations/alembic/versions/3db9992c30f3_transform_statuses_to_lowercase.py', 'manila/tests/volume/__init__.py', 'manila/api/common.py', 'manila/scheduler/filters/base_host.py', 'manila/share/drivers/qnap/__init__.py', 'manila/tests/wsgi/test_wsgi.py', 'manila/db/migrations/alembic/versions/56cdbe267881_add_share_export_locations_table.py', 'manila/share/drivers/nexenta/options.py', 'manila/tests/share/drivers/tegile/test_tegile.py', 'manila/api/views/quota_sets.py', 'manila/tests/network/linux/test_ovs_lib.py', 'manila/tests/api/fakes.py', 'manila/scheduler/weighers/__init__.py', 'manila/tests/compute/test_nova.py', 'manila/tests/api/v1/__init__.py', 'manila/share/drivers/nexenta/ns5/jsonrpc.py', 'manila/tests/api/common.py', 'manila/tests/api/v2/__init__.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/message/message_field.py', 'manila/share/drivers/hitachi/hsp/rest.py', 'manila/share/drivers/netapp/dataontap/protocols/base.py', 'manila/share/rpcapi.py', 'manila/tests/scheduler/filters/test_driver.py', 'manila/tests/share/drivers/windows/test_winrm_helper.py', 'manila/service.py', 'manila/tests/test_conf.py', 'manila/api/views/export_locations.py', 'manila/tests/test_manager.py', 'manila/db/migrations/alembic/versions/03da71c0e321_convert_cgs_to_share_groups.py', 'manila/share/drivers/dell_emc/common/enas/xml_api_parser.py', 'manila/scheduler/evaluator/__init__.py', 'manila/scheduler/filters/__init__.py', 'manila/share/drivers/container/container_helper.py', 'manila/tests/monkey_patch_example/example_b.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_multi_svm.py', 'manila/share/drivers/container/__init__.py', 'manila/db/sqlalchemy/models.py', 'manila/share/drivers/nexenta/ns4/nexenta_nas.py', 'manila/tests/share/drivers/hitachi/hnas/test_driver.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'manila/message/api.py', 'manila/tests/network/linux/test_interface.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_base.py', 'manila/tests/network/neutron/__init__.py', 'manila/tests/share/drivers/windows/test_windows_smb_driver.py', 'manila/tests/test_api.py', 'manila/db/migrations/alembic/versions/e9f79621d83f_add_cast_rules_to_readonly_to_share_instances.py', 'manila/tests/api/v2/stubs.py', 'manila/scheduler/drivers/base.py', 'manila/share/drivers/netapp/dataontap/client/client_base.py', 'manila/data/__init__.py', 'manila/tests/share/drivers/dell_emc/common/enas/fakes.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/__init__.py', 'manila/tests/test_hacking.py', 'manila/api/views/share_accesses.py', 'manila/tests/share/drivers/nexenta/ns4/test_jsonrpc.py', 'manila/tests/db/migrations/test_utils.py', 'manila/tests/api/v1/test_shares.py', 'manila/api/v2/share_networks.py', 'manila/tests/test_misc.py', 'manila/tests/test_quota.py', 'manila/share/drivers/dell_emc/plugins/base.py', 'manila/share/drivers/hitachi/hnas/ssh.py', 'manila/share/drivers/veritas/__init__.py', 'manila/share/hook.py', 'manila/db/migrations/alembic/versions/38e632621e5a_change_volume_type_to_share_type.py', 'manila/share/drivers/ganesha/__init__.py', 'manila/scheduler/scheduler_options.py', 'manila/tests/scheduler/weighers/test_pool.py', 'manila/policies/share_snapshot.py', 'manila/opts.py', 'manila/share/drivers/inspur/as13000/as13000_nas.py', 'manila/tests/share/drivers/cephfs/test_driver.py', 'manila/tests/db/test_api.py', 'manila/tests/fake_client_exception_class.py', 'manila/db/__init__.py', 'manila/tests/api/v2/test_share_accesses.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/share/drivers/__init__.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_utils.py', 'manila/wsgi/common.py', 'manila/share/drivers/netapp/dataontap/protocols/cifs_cmode.py', 'manila/api/urlmap.py', 'manila/tests/share/drivers/zfsonlinux/test_utils.py', 'manila/share/drivers/hpe/hpe_3par_mediator.py', 'manila/share/drivers/infinidat/__init__.py', 'manila/share/drivers/quobyte/quobyte.py', 'manila/share/drivers/dell_emc/__init__.py', 'manila/tests/share/drivers/inspur/as13000/__init__.py', 'manila/tests/api/views/test_shares.py', 'manila/api/views/share_migration.py', 'manila/policies/shares.py', 'manila/tests/share/drivers/infinidat/__init__.py', 'manila/tests/integrated/api/__init__.py', 'manila/db/migrations/alembic/versions/533646c7af38_remove_unused_attr_status.py', 'manila/cmd/api.py', 'manila/db/migrations/alembic/versions/579c267fbb4d_add_share_instances_access_map.py', 'manila/tests/network/test_standalone_network_plugin.py', 'manila/tests/scheduler/filters/test_capacity.py', 'manila/tests/share/drivers/dell_emc/plugins/vmax/__init__.py', 'manila/share/drivers/hdfs/hdfs_native.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/__init__.py', 'manila/api/v2/availability_zones.py', 'manila/tests/share/drivers/ganesha/test_manager.py', 'manila/api/v2/services.py', 'manila/api/middleware/fault.py', 'manila/db/migrations/alembic/env.py', 'manila/network/neutron/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/vnx/test_object_manager.py', 'manila/tests/api/v2/test_share_replicas.py', 'manila/share/drivers/glusterfs/layout_volume.py', 'manila/share/drivers/inspur/__init__.py', 'manila/share/drivers/windows/winrm_helper.py', 'manila/api/views/share_snapshot_instances.py', 'manila/tests/api/v2/test_share_group_type_specs.py', 'manila/tests/cmd/test_status.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_utils.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/__init__.py', 'manila/hacking/checks.py', 'manila/tests/api/middleware/__init__.py', 'manila/tests/api/v2/test_quota_class_sets.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/fakes.py', 'manila/rpc.py', 'manila/share/drivers/nexenta/ns5/__init__.py', 'manila/api/middleware/__init__.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/__init__.py', 'manila/share/drivers/netapp/dataontap/protocols/__init__.py', 'manila/tests/db/fakes.py', 'manila/tests/share/drivers/netapp/dataontap/fakes.py', 'manila/db/migrations/alembic/versions/5237b6625330_add_availability_zone_id_field_to_share_groups.py', 'manila/tests/share/drivers/ibm/test_gpfs.py', 'manila/api/v2/quota_class_sets.py', 'manila/tests/share/test_manager.py', 'manila/db/migrations/alembic/versions/b516de97bfee_add_quota_per_share_type_model.py', 'manila/share/drivers/huawei/v3/connection.py', 'manila/tests/api/middleware/test_auth.py', 'manila/db/migrations/alembic/versions/7d142971c4ef_add_reservation_expire_index.py', 'manila/tests/share/drivers/inspur/__init__.py', 'manila/db/migrations/alembic/versions/097fad24d2fc_add_share_instances_share_id_index.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/__init__.py', 'manila/tests/api/middleware/test_faults.py', 'manila/tests/api/v1/test_scheduler_stats.py', 'manila/tests/share/drivers/container/test_driver.py', 'manila/share/drivers/dell_emc/plugins/unity/utils.py', 'manila/tests/integrated/api/client.py', 'manila/manager.py', 'manila/share/drivers/glusterfs/glusterfs_native.py', 'manila/tests/api/v2/test_share_export_locations.py', 'manila/api/v2/share_types.py', 'manila/share/drivers/glusterfs/layout.py', 'manila/db/migrations/alembic/versions/59eb64046740_add_required_extra_spec.py', 'manila/tests/share/drivers/hitachi/hsp/__init__.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/33d30689ea70843aad301af3fa4ce0cfa14e3afb', 'message': 'DNM - touch all .py files for pylint testing\n\nDepends-On: https://review.openstack.org/637659/\nDepends-On: https://review.openstack.org/638127/\nChange-Id: I388a5d2eca5bf72f24413f4ca636addf0b76d19b\n'}]",0,637856,33d30689ea70843aad301af3fa4ce0cfa14e3afb,19,4,5,9003,,,0,"DNM - touch all .py files for pylint testing

Depends-On: https://review.openstack.org/637659/
Depends-On: https://review.openstack.org/638127/
Change-Id: I388a5d2eca5bf72f24413f4ca636addf0b76d19b
",git fetch https://review.opendev.org/openstack/manila refs/changes/56/637856/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/message/__init__.py', 'manila/scheduler/weighers/capacity.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/api/v1/share_manage.py', 'manila/policies/quota_class_set.py', 'manila/share/drivers/netapp/__init__.py', 'manila/api/v1/security_service.py', 'manila/tests/api/v2/test_share_group_types.py', 'manila/share/drivers/dell_emc/plugins/vnx/__init__.py', 'manila/tests/runtime_conf.py', 'manila/tests/share/drivers/dell_emc/plugins/vmax/test_object_manager.py', 'manila/db/migrations/alembic/versions/238720805ce1_add_messages_table.py', 'manila/tests/common/__init__.py', 'manila/tests/share/drivers/netapp/__init__.py', 'manila/tests/scheduler/__init__.py', 'manila/tests/share/drivers/netapp/dataontap/client/fakes.py', 'manila/scheduler/utils.py', 'manila/scheduler/weighers/base_host.py', 'manila/scheduler/drivers/chance.py', 'manila/tests/test_coordination.py', 'manila/policies/scheduler_stats.py', 'manila/tests/wsgi/__init__.py', 'manila/api/auth.py', 'manila/tests/share/drivers/infinidat/test_infinidat.py', 'manila/tests/share/test_api.py', 'manila/tests/api/views/test_share_accesses.py', 'manila/tests/api/contrib/stubs.py', 'manila/tests/db/migrations/__init__.py', 'manila/tests/share/drivers/windows/test_service_instance.py', 'manila/share/drivers/generic.py', 'manila/db/migrations/alembic/versions/493eaffd79e1_add_mtu_network_allocations_share_networks.py', 'manila/tests/scheduler/filters/test_base.py', 'manila/policies/__init__.py', 'manila/share/drivers/dell_emc/plugin_manager.py', 'manila/tests/share/drivers/ganesha/test_utils.py', 'manila/tests/share/drivers/container/test_storage_helper.py', 'manila/db/migrations/alembic/versions/fdfb668d19e1_add_gateway_to_network_allocations_table.py', 'manila/network/linux/interface.py', 'manila/db/migrations/alembic/versions/4a482571410f_add_backends_info_table.py', 'manila/policies/share_replica.py', 'manila/scheduler/filters/json.py', 'manila/tests/share/drivers/qnap/test_api.py', 'manila/tests/api/test_versions.py', 'manila/tests/api/v2/test_messages.py', 'manila/share/drivers/dell_emc/plugins/vmax/__init__.py', 'manila/share/drivers/huawei/base.py', 'manila/share/drivers/huawei/huawei_nas.py', 'manila/api/openstack/versioned_method.py', 'manila/api/views/services.py', 'manila/tests/api/v2/test_share_snapshots.py', 'manila/tests/share/drivers/hitachi/hsp/test_driver.py', 'manila/tests/share/drivers/test_glusterfs.py', 'manila/db/sqlalchemy/api.py', 'manila/share/drivers/helpers.py', 'manila/tests/scheduler/filters/test_capabilities.py', 'manila/tests/fake_zfssa.py', 'manila/policies/quota_set.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_cifs_cmode.py', 'manila/share/drivers/windows/service_instance.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_connection.py', 'manila/api/views/scheduler_stats.py', 'manila/share/drivers/dell_emc/plugins/vnx/connection.py', 'manila/share/drivers/netapp/dataontap/__init__.py', 'manila/tests/wsgi/test_common.py', '.zuul.yaml', 'manila/cmd/scheduler.py', 'manila/tests/share/drivers/dummy.py', 'manila/tests/share/drivers/nexenta/ns5/test_nexenta_nas.py', 'manila/api/v1/share_unmanage.py', 'manila/tests/share/drivers/qnap/test_qnap.py', 'manila/tests/share/test_share_types.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/__init__.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/test.py', 'manila/scheduler/weighers/goodness.py', 'manila/db/migrations/alembic/versions/221a83cfd85b_change_user_project_id_length.py', 'manila/db/migrations/alembic/versions/63809d875e32_add_access_key.py', 'manila/share/drivers/zfssa/__init__.py', 'manila/tests/api/test_wsgi.py', 'manila/network/__init__.py', 'manila/api/openstack/__init__.py', 'manila/db/migrations/alembic/versions/11ee96se625f3_add_metadata_for_access.py', 'manila/tests/scheduler/drivers/__init__.py', 'manila/share/drivers/dell_emc/plugins/vmax/object_manager.py', 'manila/api/views/quota_class_sets.py', 'manila/policies/share_type.py', 'manila/share/drivers/huawei/v3/replication.py', 'manila/api/v2/share_snapshots.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/__init__.py', 'manila/tests/share/drivers/dell_emc/__init__.py', 'manila/api/views/share_snapshots.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_data_motion.py', 'manila/share/drivers/netapp/utils.py', 'manila/tests/share/drivers/dell_emc/common/enas/__init__.py', 'manila/tests/share/drivers/glusterfs/test_common.py', 'manila/share/drivers/netapp/dataontap/client/__init__.py', 'manila/tests/scheduler/drivers/test_filter.py', 'manila/share/drivers/dell_emc/common/enas/__init__.py', 'manila/tests/network/linux/test_ip_lib.py', 'manila/coordination.py', 'manila/api/v2/share_export_locations.py', 'manila/api/views/share_networks.py', 'manila/tests/network/neutron/test_neutron_api.py', 'manila/tests/__init__.py', 'manila/wsgi/wsgi.py', 'manila/share/drivers/hpe/__init__.py', 'manila/share/drivers/maprfs/maprfs_native.py', 'manila/tests/test_test_utils.py', 'manila/network/linux/__init__.py', 'manila/scheduler/drivers/filter.py', 'manila/tests/scheduler/weighers/test_goodness.py', 'manila/tests/fake_share.py', 'manila/share/drivers/ibm/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/utils.py', 'manila/db/migrations/alembic/versions/b10fb432c042_squash_share_group_snapshot_members_and_share_snapshot_instance_models.py', 'manila/policies/share_snapshot_export_location.py', 'manila/share/drivers/zfsonlinux/utils.py', 'manila/db/api.py', 'manila/tests/share/test_access.py', 'manila/tests/api/__init__.py', 'manila/tests/test_utils.py', 'manila/share/drivers/dell_emc/plugins/isilon/__init__.py', 'manila/api/v1/share_metadata.py', 'manila/share/snapshot_access.py', 'manila/api/views/share_snapshot_export_locations.py', 'manila/scheduler/rpcapi.py', 'manila/db/migrations/alembic/versions/48a7beae3117_move_share_type_id_to_instances.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_driver.py', 'manila/tests/api/v1/test_security_service.py', 'manila/api/v2/messages.py', 'manila/policies/service.py', 'manila/share/drivers/maprfs/driver_util.py', 'manila/tests/test_rpc.py', 'manila/share/drivers/glusterfs/layout_directory.py', 'manila/scheduler/filters/driver.py', 'manila/tests/api/test_middleware.py', 'manila/share/drivers/windows/windows_smb_helper.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_constants.py', 'manila/cmd/manage.py', 'manila/db/migrations/alembic/versions/17115072e1c3_add_nova_net_id_column_to_share_networks.py', 'manila/share/drivers/huawei/v3/rpcapi.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_single_svm.py', 'manila/scheduler/host_manager.py', 'manila/api/v2/share_instance_export_locations.py', 'manila/db/migrations/alembic/versions/211836bf835c_add_access_level.py', 'manila/share/drivers/zfssa/zfssarest.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_single_svm.py', 'manila/api/v2/share_snapshot_instance_export_locations.py', 'manila/api/views/share_servers.py', 'manila/db/migrations/alembic/versions/5155c7077f99_add_more_network_info_attributes_to_network_allocations_table.py', 'manila/share/manager.py', 'manila/tests/db/test_migration.py', 'manila/share/drivers/netapp/dataontap/protocols/nfs_cmode.py', 'manila/share/drivers/qnap/qnap.py', 'manila/tests/api/test_extensions.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/res_mock.py', 'manila/tests/api/openstack/test_api_version_request.py', 'manila/tests/share/drivers/nexenta/test_utils.py', 'manila/wsgi/eventlet_server.py', 'manila/api/v2/router.py', 'manila/api/views/share_replicas.py', 'manila/db/migrations/alembic/versions/a77e2ad5012d_add_share_snapshot_access.py', 'manila/db/migrations/alembic/versions/3651e16d7c43_add_consistency_groups.py', 'manila/share/drivers/windows/windows_smb_driver.py', 'manila/tests/db/sqlalchemy/test_models.py', 'manila/tests/integrated/integrated_helpers.py', 'manila/tests/fake_driver.py', 'manila/db/migrations/alembic/versions/829a09b0ddd4_fix_project_share_type_quotas_unique_constraint.py', 'manila/tests/volume/test_cinder.py', 'manila/tests/scheduler/test_manager.py', 'manila/tests/api/v2/test_share_instance_export_locations.py', 'manila/share/drivers/lvm.py', 'manila/policies/availability_zone.py', 'manila/db/sqlalchemy/__init__.py', 'manila/share/drivers/nexenta/ns5/nexenta_nas.py', 'manila/tests/share/drivers/container/__init__.py', 'manila/api/v2/share_snapshot_export_locations.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_single_svm.py', 'manila/api/v2/share_group_type_specs.py', 'manila/scheduler/weighers/pool.py', 'manila/tests/share/drivers/hitachi/hsp/fakes.py', 'manila/share/drivers/huawei/v3/smartx.py', 'manila/tests/data/__init__.py', 'manila/tests/scheduler/filters/test_share_replication.py', 'manila/tests/share/drivers/quobyte/test_quobyte.py', 'manila/api/v2/share_replica_export_locations.py', 'manila/share/drivers/glusterfs/common.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/share/drivers/netapp/common.py', 'manila/api/v2/__init__.py', 'manila/db/migrations/alembic/versions/3a482171410f_add_drivers_private_data_table.py', 'manila/network/neutron/api.py', 'manila/policies/share_group_types_spec.py', 'manila/tests/share/__init__.py', 'manila/tests/share/drivers/maprfs/__init__.py', 'manila/api/openstack/api_version_request.py', 'manila/tests/share/drivers/hpe/__init__.py', 'manila/policies/base.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/fake_exceptions.py', 'manila/share/drivers/dell_emc/common/__init__.py', 'manila/tests/share/drivers/nexenta/ns4/test_nexenta_nas.py', 'manila/tests/share/drivers/dell_emc/plugins/vnx/test_connection.py', 'manila/share/drivers/service_instance.py', 'manila/tests/share/drivers/nexenta/ns5/__init__.py', 'manila/policies/share_access.py', 'manila/db/migrations/utils.py', 'manila/tests/api/views/test_quota_class_sets.py', 'manila/tests/scheduler/filters/test_ignore_attempted_hosts.py', 'manila/tests/api/v2/test_share_replica_export_locations.py', 'manila/share/drivers/maprfs/__init__.py', 'manila/scheduler/base_handler.py', 'manila/scheduler/weighers/base.py', 'manila/share/configuration.py', 'manila/api/views/versions.py', 'manila/api/v1/limits.py', 'manila/api/__init__.py', 'manila/db/migrations/alembic/versions/293fac1130ca_add_replication_attrs.py', 'manila/tests/share/drivers/container/test_container_helper.py', 'manila/wsgi/__init__.py', 'manila/share/drivers/container/storage_helper.py', 'manila/share/drivers/infinidat/infinibox.py', 'manila/context.py', 'manila/share/drivers/zfssa/restclient.py', 'manila/db/migrations/alembic/versions/323840a08dc4_add_shares_task_state.py', 'manila/tests/scheduler/test_rpcapi.py', 'manila/scheduler/filters/base.py', 'manila/tests/scheduler/weighers/test_base.py', 'manila/api/views/availability_zones.py', 'manila/share/drivers/cephfs/__init__.py', 'manila/share/drivers/dell_emc/common/enas/utils.py', 'manila/tests/share/drivers/cephfs/__init__.py', 'manila/tests/share/drivers/windows/test_windows_smb_helper.py', 'manila/api/v2/shares.py', 'manila/data/manager.py', 'manila/tests/network/neutron/test_neutron_plugin.py', 'manila/scheduler/filters/share_replication.py', 'manila/tests/fake_network.py', 'manila/scheduler/filters/retry.py', 'manila/tests/data/test_utils.py', 'manila/tests/scheduler/weighers/test_capacity.py', 'manila/tests/share/drivers/container/fakes.py', 'manila/cmd/__init__.py', 'manila/tests/api/v2/test_share_group_snapshots.py', 'manila/api/v1/share_snapshots.py', 'manila/tests/share/drivers/zfssa/__init__.py', 'manila/data/rpcapi.py', 'manila/share/drivers/cephfs/driver.py', 'manila/api/views/share_group_snapshots.py', 'manila/share/drivers/container/protocol_helper.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/share/drivers/quobyte/__init__.py', 'manila/tests/share/drivers/netapp/dataontap/client/__init__.py', 'manila/policies/message.py', 'manila/tests/share/drivers/glusterfs/test_layout.py', 'manila/share/drivers/nexenta/__init__.py', 'manila/tests/scheduler/test_scheduler_options.py', 'manila/scheduler/filters/availability_zone.py', 'manila/tests/api/v1/test_share_snapshots.py', 'manila/tests/fake_service_instance.py', 'manila/db/migrations/alembic/versions/dda6de06349_add_export_locations_metadata.py', 'manila/tests/share/drivers/glusterfs/__init__.py', 'manila/tests/scheduler/weighers/__init__.py', 'manila/tests/api/v2/test_share_access_metadata.py', 'manila/tests/share_group/test_api.py', 'manila/tests/share/drivers/dell_emc/test_driver.py', 'manila/db/base.py', 'manila/tests/xenapi/__init__.py', 'manila/db/migrations/alembic/versions/55761e5f59c5_add_snapshot_support_extra_spec_to_share_types.py', 'manila/policies/share_group_snapshot.py', 'manila/api/v2/share_snapshot_instances.py', 'manila/db/migrations/alembic/versions/162a3e673105_manila_init.py', 'manila/tests/share/drivers/__init__.py', 'manila/api/v2/share_accesses.py', 'manila/share_group/__init__.py', 'manila/tests/api/openstack/test_wsgi.py', 'manila/tests/api/v2/test_share_groups.py', 'manila/tests/share/drivers/nexenta/__init__.py', 'manila/compute/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon.py', 'manila/tests/api/v2/test_quota_sets.py', 'manila/tests/share/drivers/zfssa/test_zfssashare.py', 'manila/share/drivers/huawei/constants.py', 'manila/share/drivers/dell_emc/plugins/vnx/object_manager.py', 'manila/tests/share/drivers/qnap/__init__.py', 'manila/tests/test_policy.py', 'manila/share/access.py', 'manila/tests/cmd/test_share.py', 'manila/share/drivers/nexenta/ns4/nexenta_nfs_helper.py', 'manila/tests/api/v2/test_share_instances.py', 'manila/db/migrations/alembic/versions/5077ffcc5f1c_add_share_instances.py', 'manila/tests/share/drivers/hdfs/__init__.py', 'manila/tests/fake_notifier.py', 'manila/cmd/share.py', 'manila/tests/api/extensions/__init__.py', 'manila/share/drivers/hitachi/hsp/driver.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/data_motion.py', 'manila/tests/scheduler/evaluator/__init__.py', 'manila/policies/share_snapshot_instance.py', 'manila/common/constants.py', 'manila/policies/share_export_location.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_api.py', 'manila/tests/integrated/test_login.py', 'manila/tests/scheduler/fakes.py', 'manila/api/views/share_group_types.py', 'manila/share/drivers/quobyte/jsonrpc.py', 'manila/api/v1/share_servers.py', 'manila/tests/api/v2/test_share_snapshot_instance_export_locations.py', 'manila/db/migrations/alembic/versions/87ce15c59bbe_add_revert_to_snapshot_support.py', 'manila/db/migrations/alembic/versions/3e7d62517afa_add_create_share_from_snapshot_support.py', 'manila/policies/share_network.py', 'manila/tests/scheduler/drivers/test_base.py', 'manila/api/contrib/__init__.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/scheduler/filters/test_extra_specs_ops.py', 'manila/version.py', 'manila/policies/share_server.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/tests/share/drivers/quobyte/__init__.py', 'manila/tests/share/drivers/container/test_protocol_helper.py', 'manila/api/openstack/urlmap.py', 'manila/policies/share_replica_export_location.py', 'manila/tests/api/test_common.py', 'manila/tests/share/test_drivers_private_data.py', 'manila/share/hooks/__init__.py', 'manila/db/migrations/alembic/versions/e8ea58723178_remove_host_from_driver_private_data.py', 'manila/api/extensions.py', 'manila/api/v1/shares.py', 'manila/data/helper.py', 'manila/tests/share/drivers/glusterfs/test_glusterfs_native.py', 'manila/tests/share/test_share_utils.py', 'manila/api/v2/share_access_metadata.py', 'manila/api/v2/share_replicas.py', 'manila/tests/share/drivers/dell_emc/common/enas/utils.py', 'manila/api/v2/share_group_snapshots.py', 'manila/tests/api/v2/test_availability_zones.py', 'manila/api/v2/share_group_types.py', 'manila/tests/api/v2/test_services.py', 'manila/share/drivers/glusterfs/__init__.py', 'manila/tests/share/test_driver.py', 'manila/cmd/status.py', 'manila/scheduler/filters/share_group_filters/consistent_snapshot.py', 'manila/share/drivers/tegile/tegile.py', 'manila/api/views/limits.py', 'manila/network/standalone_network_plugin.py', 'manila/share/drivers/zfsonlinux/driver.py', 'manila/tests/api/views/test_scheduler_stats.py', 'manila/tests/scheduler/evaluator/test_evaluator.py', 'manila/tests/test_test.py', 'manila/tests/api/v2/test_share_networks.py', 'manila/share/drivers/veritas/veritas_isa.py', 'manila/tests/share/drivers/huawei/test_huawei_nas.py', 'manila/tests/scheduler/filters/test_availability_zone.py', 'manila/tests/test_exception.py', 'manila/tests/api/v1/stubs.py', 'manila/network/linux/ovs_lib.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/scheduler/filters/share_group_filters/__init__.py', 'manila/tests/message/test_api.py', 'manila/tests/scheduler/filters/test_json.py', 'manila/api/views/shares.py', 'manila/share/drivers/dell_emc/plugins/unity/client.py', 'manila/share/drivers/hitachi/hsp/__init__.py', 'manila/volume/__init__.py', 'manila/db/migrations/alembic/versions/eb6d5544cbbd_add_provider_location_to_share_snapshot_instances.py', 'manila/db/sqlalchemy/query.py', 'manila/hacking/__init__.py', 'manila/scheduler/drivers/simple.py', 'manila/tests/share/drivers/netapp/fakes.py', 'manila/policies/share_instance_export_location.py', 'manila/tests/share/drivers/zfsonlinux/test_driver.py', 'manila/scheduler/filters/capacity.py', 'manila/tests/api/v1/test_share_unmanage.py', 'manila/tests/share/drivers/netapp/test_common.py', 'manila/scheduler/__init__.py', 'manila/share_group/api.py', 'manila/tests/message/test_message_field.py', 'manila/tests/scheduler/drivers/test_simple.py', 'manila/tests/share/drivers/ganesha/__init__.py', 'manila/tests/share/drivers/veritas/__init__.py', 'manila/api/v1/router.py', 'manila/share/drivers/hpe/hpe_3par_driver.py', 'manila/share/drivers/huawei/huawei_utils.py', 'manila/tests/share/drivers/dell_emc/plugins/vmax/test_connection.py', 'manila/tests/scheduler/filters/test_base_host.py', 'manila/policy.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon.py', 'manila/share/drivers/qnap/api.py', 'manila/tests/share/drivers/dell_emc/common/__init__.py', 'manila/utils.py', 'manila/db/migrations/alembic/versions/4ee2cf4be19a_remove_share_snapshots_export_location.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon_api.py', 'manila/tests/scheduler/test_utils.py', 'manila/api/v1/share_types_extra_specs.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon_api.py', 'manila/tests/share/drivers/windows/test_windows_utils.py', 'manila/data/utils.py', 'manila/share/drivers/huawei/__init__.py', 'manila/share/drivers/dell_emc/driver.py', 'manila/tests/api/openstack/test_versioned_method.py', 'manila/tests/api/v1/test_share_manage.py', 'manila/tests/share/drivers/zfsonlinux/__init__.py', 'manila/db/migrations/alembic/versions/344c1ac4747f_add_share_instance_access_rules_status.py', 'manila/tests/share/drivers/windows/__init__.py', 'manila/tests/share/drivers/huawei/__init__.py', 'manila/tests/share/test_snapshot_access.py', 'manila/policies/share_types_extra_spec.py', 'manila/tests/common/test_config.py', 'manila/tests/db/__init__.py', 'manila/tests/cmd/__init__.py', 'manila/share/drivers/windows/windows_utils.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_driver_interfaces.py', 'manila/api/views/security_service.py', 'manila/share/drivers/hitachi/hnas/driver.py', 'manila/tests/conf_fixture.py', 'manila/share/drivers/dell_emc/plugins/unity/connection.py', 'manila/tests/share/drivers/inspur/as13000/test_as13000_nas.py', 'manila/common/client_auth.py', 'manila/share/drivers/huawei/v3/__init__.py', 'manila/tests/api/extensions/foxinsocks.py', 'manila/db/migration.py', 'manila/share/drivers/inspur/as13000/__init__.py', 'manila/tests/integrated/__init__.py', 'manila/tests/share/test_rpcapi.py', 'manila/api/v2/share_instances.py', 'manila/tests/api/v1/test_share_types_extra_specs.py', 'manila/tests/api/views/test_quota_sets.py', 'manila/tests/share_group/__init__.py', 'manila/api/views/types.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/performance.py', 'manila/tests/api/views/test_versions.py', 'manila/tests/api/v2/test_shares.py', 'manila/volume/cinder.py', 'manila/tests/api/v2/test_security_services.py', 'manila/share/migration.py', 'manila/share/drivers/ganesha/utils.py', 'manila/db/migrations/alembic/versions/54667b9cade7_restore_share_instance_access_map_state.py', 'manila/tests/monkey_patch_example/__init__.py', 'manila/tests/api/contrib/__init__.py', 'manila/tests/share/drivers/qnap/fakes.py', 'manila/tests/share/drivers/hitachi/hnas/__init__.py', 'manila/tests/api/v2/test_share_types.py', 'manila/common/config.py', 'manila/tests/share/drivers/maprfs/test_maprfs.py', 'manila/tests/share/drivers/test_helpers.py', 'manila/tests/fake_compute.py', 'manila/tests/db_utils.py', 'manila/common/__init__.py', 'manila/scheduler/filters/extra_specs_ops.py', 'manila/tests/share/drivers/veritas/test_veritas_isa.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_multi_svm.py', 'manila/tests/fake_utils.py', 'manila/tests/fake_volume.py', 'manila/exception.py', 'manila/message/message_levels.py', 'manila/tests/api/v2/test_share_snapshot_instances.py', 'manila/tests/api/views/test_share_networks.py', 'manila/db/migrations/alembic/versions/e1949a93157a_add_share_group_types_table.py', 'manila/tests/cmd/test_scheduler.py', 'manila/policies/share_group_type.py', 'manila/share/drivers/nexenta/utils.py', 'manila/api/views/share_instance.py', 'manila/tests/common/test_client_auth.py', 'manila/tests/api/openstack/__init__.py', 'manila/compute/nova.py', 'manila/policies/share_access_metadata.py', 'manila/tests/share/drivers/hdfs/test_hdfs_native.py', 'manila/tests/share/drivers/hitachi/hsp/test_rest.py', 'manila/tests/utils.py', 'manila/tests/data/test_rpcapi.py', 'manila/tests/share/drivers/glusterfs/test_layout_directory.py', 'manila/tests/integrated/test_extensions.py', 'manila/share/drivers/windows/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_client.py', 'manila/tests/share/drivers/tegile/__init__.py', 'manila/tests/network/__init__.py', 'manila/tests/network/linux/__init__.py', 'manila/tests/data/test_helper.py', 'manila/db/migrations/alembic/versions/0274d20c560f_add_ou_to_security_service.py', 'manila/tests/db/sqlalchemy/__init__.py', 'manila/network/neutron/constants.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/hitachi/__init__.py', 'manila/tests/share/drivers/nexenta/ns5/test_jsonrpc.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_performance.py', 'manila/tests/api/v1/test_share_servers.py', 'manila/tests/share/test_migration.py', 'manila/share/__init__.py', 'manila/share/drivers/dell_emc/plugins/__init__.py', 'manila/tests/share_group/test_share_group_types.py', 'manila/cmd/data.py', 'manila/db/migrations/alembic/versions/1f0bd302c1a6_add_availability_zones_table.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py', 'manila/tests/test_network.py', 'manila/share/drivers/nexenta/ns4/__init__.py', 'manila/db/migrations/alembic/versions/27cb96d991fa_add_description_for_share_type.py', 'manila/network/linux/ip_lib.py', 'manila/tests/share/drivers/test_lvm.py', 'manila/api/v2/share_groups.py', 'manila/tests/share/drivers/dell_emc/plugins/__init__.py', 'manila/policies/share_instance.py', 'manila/db/migrations/alembic/versions/ef0c02b4366_add_share_type_projects.py', 'manila/tests/db/migrations/alembic/test_migration.py', 'manila/tests/compute/__init__.py', 'manila/tests/db/migrations/alembic/__init__.py', 'manila/tests/declare_conf.py', 'manila/db/migrations/alembic/versions/d5db24264f5c_add_consistent_snapshot_support_attr_to_share_group_model.py', 'manila/api/v1/scheduler_stats.py', 'manila/db/migrations/alembic/versions/95e3cf760840_remove_nova_net_id_column_from_share_.py', 'manila/tests/cmd/test_data.py', 'manila/scheduler/manager.py', 'manila/tests/share/drivers/ibm/__init__.py', 'manila/tests/api/v2/test_share_snapshot_export_locations.py', 'manila/tests/share/drivers/zfssa/test_zfssarest.py', 'manila/scheduler/filters/ignore_attempted_hosts.py', 'manila/tests/share/drivers/quobyte/test_jsonrpc.py', 'manila/scheduler/filters/capabilities.py', 'manila/db/migrations/__init__.py', 'manila/share/drivers/dell_emc/plugins/vmax/connection.py', 'manila/db/migrations/alembic/migration.py', 'manila/share/utils.py', 'manila/tests/test_service.py', 'manila/db/migrations/alembic/versions/30cb96d995fa_add_is_public_column_for_share.py', 'manila/tests/scheduler/filters/test_retry.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_nfs_cmode.py', 'manila/tests/share/test_hook.py', 'manila/api/views/messages.py', 'manila/share/drivers/hitachi/hnas/__init__.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/tests/share/drivers/test_ganesha.py', 'manila/tests/cmd/test_manage.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/share/drivers/tegile/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/vnx/__init__.py', 'manila/api/v2/quota_sets.py', 'manila/share/drivers/netapp/options.py', 'manila/share_group/share_group_types.py', 'manila/share/share_types.py', 'manila/tests/scheduler/filters/__init__.py', 'manila/scheduler/drivers/__init__.py', 'manila/share/driver.py', 'manila/share/drivers/zfsonlinux/__init__.py', 'manila/tests/data/test_manager.py', 'manila/api/middleware/auth.py', 'manila/db/migrations/alembic/versions/927920b37453_add_provider_location_for_share_group_snapshot_members_model.py', 'manila/policies/security_service.py', 'manila/tests/api/v1/test_share_metadata.py', 'manila/share/api.py', 'manila/share/drivers/container/driver.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_base.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_mediator.py', 'manila/quota.py', 'manila/share/drivers/ganesha/manager.py', 'manila/tests/monkey_patch_example/example_a.py', 'manila/tests/share/drivers/glusterfs/test_layout_volume.py', 'manila/share/drivers_private_data.py', 'manila/tests/test_context.py', 'manila/tests/api/views/__init__.py', 'manila/share/drivers/dell_emc/common/enas/connector.py', 'manila/policies/share_snapshot_instance_export_location.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/share/drivers/dell_emc/plugins/unity/__init__.py', 'manila/i18n.py', 'manila/tests/share/drivers/netapp/test_utils.py', 'manila/api/openstack/wsgi.py', 'manila/tests/cmd/test_api.py', 'manila/message/__init__.py', 'manila/share/drivers/hdfs/__init__.py', 'manila/tests/share/drivers/nexenta/ns4/__init__.py', 'manila/api/versions.py', 'manila/api/views/__init__.py', 'manila/share/drivers/nexenta/ns4/jsonrpc.py', 'manila/api/views/share_groups.py', 'manila/policies/share_group.py', 'manila/share/drivers/dell_emc/common/enas/constants.py', 'manila/tests/api/v1/test_limits.py', 'manila/tests/share/drivers/hitachi/__init__.py', 'manila/scheduler/evaluator/evaluator.py', 'manila/db/migrations/alembic/__init__.py', 'manila/api/v1/__init__.py', 'manila/db/migrations/alembic/versions/3db9992c30f3_transform_statuses_to_lowercase.py', 'manila/tests/volume/__init__.py', 'manila/api/common.py', 'manila/scheduler/filters/base_host.py', 'manila/share/drivers/qnap/__init__.py', 'manila/tests/wsgi/test_wsgi.py', 'manila/db/migrations/alembic/versions/56cdbe267881_add_share_export_locations_table.py', 'manila/share/drivers/nexenta/options.py', 'manila/tests/share/drivers/tegile/test_tegile.py', 'manila/api/views/quota_sets.py', 'manila/tests/network/linux/test_ovs_lib.py', 'manila/tests/api/fakes.py', 'manila/scheduler/weighers/__init__.py', 'manila/tests/compute/test_nova.py', 'manila/tests/api/v1/__init__.py', 'manila/share/drivers/nexenta/ns5/jsonrpc.py', 'manila/tests/api/common.py', 'manila/tests/api/v2/__init__.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/message/message_field.py', 'manila/share/drivers/hitachi/hsp/rest.py', 'manila/share/drivers/netapp/dataontap/protocols/base.py', 'manila/share/rpcapi.py', 'manila/tests/scheduler/filters/test_driver.py', 'manila/tests/share/drivers/windows/test_winrm_helper.py', 'manila/service.py', 'manila/tests/test_conf.py', 'manila/api/views/export_locations.py', 'manila/tests/test_manager.py', 'manila/db/migrations/alembic/versions/03da71c0e321_convert_cgs_to_share_groups.py', 'manila/share/drivers/dell_emc/common/enas/xml_api_parser.py', 'manila/scheduler/evaluator/__init__.py', 'manila/scheduler/filters/__init__.py', 'manila/share/drivers/container/container_helper.py', 'manila/tests/monkey_patch_example/example_b.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_multi_svm.py', 'manila/share/drivers/container/__init__.py', 'manila/db/sqlalchemy/models.py', 'manila/share/drivers/nexenta/ns4/nexenta_nas.py', 'manila/tests/share/drivers/hitachi/hnas/test_driver.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'manila/message/api.py', 'manila/tests/network/linux/test_interface.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_base.py', 'manila/tests/network/neutron/__init__.py', 'manila/tests/share/drivers/windows/test_windows_smb_driver.py', 'manila/tests/test_api.py', 'manila/db/migrations/alembic/versions/e9f79621d83f_add_cast_rules_to_readonly_to_share_instances.py', 'manila/tests/api/v2/stubs.py', 'manila/scheduler/drivers/base.py', 'manila/share/drivers/netapp/dataontap/client/client_base.py', 'manila/data/__init__.py', 'manila/tests/share/drivers/dell_emc/common/enas/fakes.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/__init__.py', 'manila/tests/test_hacking.py', 'manila/api/views/share_accesses.py', 'manila/tests/share/drivers/nexenta/ns4/test_jsonrpc.py', 'manila/tests/db/migrations/test_utils.py', 'manila/tests/api/v1/test_shares.py', 'manila/api/v2/share_networks.py', 'manila/tests/test_misc.py', 'manila/tests/test_quota.py', 'manila/share/drivers/dell_emc/plugins/base.py', 'manila/share/drivers/hitachi/hnas/ssh.py', 'manila/share/drivers/veritas/__init__.py', 'manila/share/hook.py', 'manila/db/migrations/alembic/versions/38e632621e5a_change_volume_type_to_share_type.py', 'manila/share/drivers/ganesha/__init__.py', 'manila/scheduler/scheduler_options.py', 'manila/tests/scheduler/weighers/test_pool.py', 'manila/policies/share_snapshot.py', 'manila/opts.py', 'manila/share/drivers/inspur/as13000/as13000_nas.py', 'manila/tests/share/drivers/cephfs/test_driver.py', 'manila/tests/db/test_api.py', 'manila/tests/fake_client_exception_class.py', 'manila/db/__init__.py', 'manila/tests/api/v2/test_share_accesses.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/share/drivers/__init__.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_utils.py', 'manila/wsgi/common.py', 'manila/share/drivers/netapp/dataontap/protocols/cifs_cmode.py', 'manila/api/urlmap.py', 'manila/tests/share/drivers/zfsonlinux/test_utils.py', 'manila/share/drivers/hpe/hpe_3par_mediator.py', 'manila/share/drivers/infinidat/__init__.py', 'manila/share/drivers/quobyte/quobyte.py', 'manila/share/drivers/dell_emc/__init__.py', 'manila/tests/share/drivers/inspur/as13000/__init__.py', 'manila/tests/api/views/test_shares.py', 'manila/api/views/share_migration.py', 'manila/policies/shares.py', 'manila/tests/share/drivers/infinidat/__init__.py', 'manila/tests/integrated/api/__init__.py', 'manila/db/migrations/alembic/versions/533646c7af38_remove_unused_attr_status.py', 'manila/cmd/api.py', 'manila/db/migrations/alembic/versions/579c267fbb4d_add_share_instances_access_map.py', 'manila/tests/network/test_standalone_network_plugin.py', 'manila/tests/scheduler/filters/test_capacity.py', 'manila/tests/share/drivers/dell_emc/plugins/vmax/__init__.py', 'manila/share/drivers/hdfs/hdfs_native.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/__init__.py', 'manila/api/v2/availability_zones.py', 'manila/tests/share/drivers/ganesha/test_manager.py', 'manila/api/v2/services.py', 'manila/api/middleware/fault.py', 'manila/db/migrations/alembic/env.py', 'manila/network/neutron/__init__.py', 'manila/tests/share/drivers/dell_emc/plugins/vnx/test_object_manager.py', 'manila/tests/api/v2/test_share_replicas.py', 'manila/share/drivers/glusterfs/layout_volume.py', 'manila/share/drivers/inspur/__init__.py', 'manila/share/drivers/windows/winrm_helper.py', 'manila/api/views/share_snapshot_instances.py', 'manila/tests/api/v2/test_share_group_type_specs.py', 'manila/tests/cmd/test_status.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_utils.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/__init__.py', 'manila/hacking/checks.py', 'manila/tests/api/middleware/__init__.py', 'manila/tests/api/v2/test_quota_class_sets.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/fakes.py', 'manila/rpc.py', 'manila/share/drivers/nexenta/ns5/__init__.py', 'manila/api/middleware/__init__.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/__init__.py', 'manila/share/drivers/netapp/dataontap/protocols/__init__.py', 'manila/tests/db/fakes.py', 'manila/tests/share/drivers/netapp/dataontap/fakes.py', 'manila/db/migrations/alembic/versions/5237b6625330_add_availability_zone_id_field_to_share_groups.py', 'manila/tests/share/drivers/ibm/test_gpfs.py', 'manila/api/v2/quota_class_sets.py', 'manila/tests/share/test_manager.py', 'manila/db/migrations/alembic/versions/b516de97bfee_add_quota_per_share_type_model.py', 'manila/share/drivers/huawei/v3/connection.py', 'manila/tests/api/middleware/test_auth.py', 'manila/db/migrations/alembic/versions/7d142971c4ef_add_reservation_expire_index.py', 'manila/tests/share/drivers/inspur/__init__.py', 'manila/db/migrations/alembic/versions/097fad24d2fc_add_share_instances_share_id_index.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/__init__.py', 'manila/tests/api/middleware/test_faults.py', 'manila/tests/api/v1/test_scheduler_stats.py', 'manila/tests/share/drivers/container/test_driver.py', 'manila/share/drivers/dell_emc/plugins/unity/utils.py', 'manila/tests/integrated/api/client.py', 'manila/manager.py', 'manila/share/drivers/glusterfs/glusterfs_native.py', 'manila/tests/api/v2/test_share_export_locations.py', 'manila/api/v2/share_types.py', 'manila/share/drivers/glusterfs/layout.py', 'manila/db/migrations/alembic/versions/59eb64046740_add_required_extra_spec.py', 'manila/tests/share/drivers/hitachi/hsp/__init__.py']",734,19b2899302c737959d3846f7501468606a22c91d,pylint,#Touched ,,734,39
openstack%2Fkolla~master~I0924f6bc11558366d6d49472cdd338e43b744030,openstack/kolla,master,I0924f6bc11558366d6d49472cdd338e43b744030,nova: Remove bridge_utils from base package,MERGED,2019-02-21 12:03:14.000000000,2019-03-06 11:17:37.000000000,2019-03-06 11:17:37.000000000,"[{'_account_id': 10135}, {'_account_id': 13039}, {'_account_id': 14826}, {'_account_id': 16282}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23717}, {'_account_id': 29759}]","[{'number': 1, 'created': '2019-02-21 12:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/297df284f6eb479859178ea766dad2945c2727ed', 'message': 'nova: Do not install bridge_utils on EL >= 8\n\nThe bridge_utils package is being dropped from RHEL 8 and all EL 8 based\ndistributions [1].\n\n[1] https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8-beta/html-single/8.0_beta_release_notes/index#removed_packages\n\nChange-Id: I0924f6bc11558366d6d49472cdd338e43b744030\n'}, {'number': 2, 'created': '2019-02-21 13:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/91a16f24e9e163d52761b0ff5635e53daf8108a6', 'message': 'WIP nova: Remove bridge_utils from base package\n\nThe dependency on bridge_utils has now been removed from os-vif and so\nthe package is no longer required in the base container.\n\nDepends-On: https://review.openstack.org/#/c/636822/\nChange-Id: I0924f6bc11558366d6d49472cdd338e43b744030\n'}, {'number': 3, 'created': '2019-02-27 09:31:37.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4991607b29ef5972953380a582b1778a571cc4ce', 'message': 'nova: Remove bridge_utils from base package\n\nThe dependency on bridge_utils has now been removed from os-vif and so\nthe package is no longer required in the base container.\n\nDepends-On: https://review.openstack.org/#/c/636822/\nChange-Id: I0924f6bc11558366d6d49472cdd338e43b744030\n'}]",0,638403,4991607b29ef5972953380a582b1778a571cc4ce,41,8,3,10135,,,0,"nova: Remove bridge_utils from base package

The dependency on bridge_utils has now been removed from os-vif and so
the package is no longer required in the base container.

Depends-On: https://review.openstack.org/#/c/636822/
Change-Id: I0924f6bc11558366d6d49472cdd338e43b744030
",git fetch https://review.opendev.org/openstack/kolla refs/changes/03/638403/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova/nova-base/Dockerfile.j2'],1,297df284f6eb479859178ea766dad2945c2727ed,," {% if base_distro in ['centos', 'oraclelinux', 'rhel'] and base_distro_tag.startswith('7') %} {% set nova_base_packages = nova_base_packages + [ 'bridge-utils' ] %} {% endif %} {% if base_distro in ['centos', 'oraclelinux', 'rhel'] and base_distro_tag.startswith('7') %} {% set nova_base_packages = nova_base_packages + [ 'bridge-utils' ] %} {% endif %} "," 'bridge-utils', 'bridge-utils',",14,2
openstack%2Fnetworking-ovn~master~I20a17896bc911b59ad85eefa9c76c41c058a0c16,openstack/networking-ovn,master,I20a17896bc911b59ad85eefa9c76c41c058a0c16,Fix downtime bug during migration,MERGED,2019-02-05 22:25:36.000000000,2019-03-06 11:14:53.000000000,2019-02-07 13:52:05.000000000,"[{'_account_id': 10237}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-05 22:25:36.000000000', 'files': ['migration/tripleo_environment/playbooks/roles/migration/templates/clone-br-int.sh.j2'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c6c2c5e4ad09fbc1105a6b36feb0c26e33ccfa3c', 'message': ""Fix downtime bug during migration\n\nWe remove a workaround which was applied because of [1], which\nnow it's fixed in openvswitch. The problem is that the workaround\nintroduced unnecessary downtime.\n\nChange-Id: I20a17896bc911b59ad85eefa9c76c41c058a0c16\nCloses-Bug: 1814831\n""}]",0,635063,c6c2c5e4ad09fbc1105a6b36feb0c26e33ccfa3c,8,3,1,8788,,,0,"Fix downtime bug during migration

We remove a workaround which was applied because of [1], which
now it's fixed in openvswitch. The problem is that the workaround
introduced unnecessary downtime.

Change-Id: I20a17896bc911b59ad85eefa9c76c41c058a0c16
Closes-Bug: 1814831
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/63/635063/1 && git format-patch -1 --stdout FETCH_HEAD,['migration/tripleo_environment/playbooks/roles/migration/templates/clone-br-int.sh.j2'],1,c6c2c5e4ad09fbc1105a6b36feb0c26e33ccfa3c,bug/1814831,, # NOTE(mangelajo): workaround for https://bugzilla.redhat.com/show_bug.cgi?id=1640045 # make sure we don't have any controller configured on br-int at this point: ovs-vsctl set Bridge br-int protocols=[] ovs-vsctl del-controller br-int,0,6
openstack%2Fnetworking-ovn~master~I6064bb207e27928f29d39773b30d98a2345efd43,openstack/networking-ovn,master,I6064bb207e27928f29d39773b30d98a2345efd43,Remove only non-alive agents during migration,MERGED,2019-02-05 19:51:24.000000000,2019-03-06 11:14:13.000000000,2019-02-07 12:17:29.000000000,"[{'_account_id': 6773}, {'_account_id': 10237}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-05 19:51:24.000000000', 'files': ['migration/tripleo_environment/playbooks/roles/migration/tasks/cleanup-dataplane.yml', 'migration/tripleo_environment/playbooks/roles/delete-neutron-resources/templates/delete-neutron-resources.sh.j2'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/20e17d56b55b38341214d37dd5c795148410be91', 'message': 'Remove only non-alive agents during migration\n\nDuring the migration process we were cleaning up all ml2/ovs\nneutron agents, but, in some cases we still rely on the\nneutron-dhcp-agents, and we need to avoid cleaning those up.\n\nChange-Id: I6064bb207e27928f29d39773b30d98a2345efd43\nCloses-bug: 1814812\n'}]",0,635022,20e17d56b55b38341214d37dd5c795148410be91,9,4,1,8788,,,0,"Remove only non-alive agents during migration

During the migration process we were cleaning up all ml2/ovs
neutron agents, but, in some cases we still rely on the
neutron-dhcp-agents, and we need to avoid cleaning those up.

Change-Id: I6064bb207e27928f29d39773b30d98a2345efd43
Closes-bug: 1814812
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/22/635022/1 && git format-patch -1 --stdout FETCH_HEAD,"['migration/tripleo_environment/playbooks/roles/migration/tasks/cleanup-dataplane.yml', 'migration/tripleo_environment/playbooks/roles/delete-neutron-resources/templates/delete-neutron-resources.sh.j2']",2,20e17d56b55b38341214d37dd5c795148410be91,bug/1814812,# Delete non alive neutron agents for i in `openstack network agent list | grep neutron- | grep -v ':-)' | awk {'print $2'}`,# Delete neutron agents for i in `openstack network agent list | grep neutron- | awk {'print $2'}`,7,2
openstack%2Fmasakari~master~Ibdea705f69d139834c9b2294ae11bc9344c259bd,openstack/masakari,master,Ibdea705f69d139834c9b2294ae11bc9344c259bd,Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped,MERGED,2018-07-25 02:24:02.000000000,2019-03-06 10:58:01.000000000,2019-03-06 10:58:01.000000000,"[{'_account_id': 1011}, {'_account_id': 3085}, {'_account_id': 8716}, {'_account_id': 8988}, {'_account_id': 22348}, {'_account_id': 23226}, {'_account_id': 25267}]","[{'number': 1, 'created': '2018-07-25 02:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/6e66466d10fb6a13adf3f98a3277a55448d12eab', 'message': 'Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped\n\nThe instance which is vm_state=resized and power_state=SHUTDOWN\nshould not be recovered with vm_state=error. It should be recovered\nwith vm_state=stopped. The instances such as paused or suspended\n(which are other than vm_state=active,stopped,error) are also the same.\n\nThis patch modified that masakari-engine will recover these instances\nwith vm_state=stopped.\n\nChange-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd\nCloses-Bug: #1782518\n'}, {'number': 2, 'created': '2018-12-07 05:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/cda090d2aa1c94c4b16ed4591e508148897569e4', 'message': 'Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped\n\nThe instance which is vm_state=resized and power_state=SHUTDOWN\nshould not be recovered with vm_state=error. It should be recovered\nwith vm_state=stopped. The instances such as paused or suspended\n(which are other than vm_state=active,stopped,error) are also the same.\n\nThis patch modified that masakari-engine will recover these instances\nwith vm_state=stopped.\n\nChange-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd\nCloses-Bug: #1782518\n'}, {'number': 3, 'created': '2018-12-25 09:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/9b728ff3a9a07b62700760b964fdd650d59a611b', 'message': 'Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped\n\nThe instance which is vm_state=resized and power_state=SHUTDOWN\nshould not be recovered with vm_state=error. It should be recovered\nwith vm_state=stopped. The instances such as paused or suspended\n(which are other than vm_state=active,stopped,error) are also the same.\n\nThis patch modified that masakari-engine will recover these instances\nwith vm_state=stopped.\n\nChange-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd\nCloses-Bug: #1782518\n'}, {'number': 4, 'created': '2018-12-25 10:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/6a1384e613092233c1bd8dc9e9d03d02911d334a', 'message': 'Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped\n\nThe instance which is vm_state=resized and power_state=SHUTDOWN\nshould not be recovered with vm_state=error. It should be recovered\nwith vm_state=stopped. The instances such as paused or suspended\n(which are other than vm_state=active,stopped,error) are also the same.\n\nThis patch modified that masakari-engine will recover these instances\nwith vm_state=stopped.\n\nChange-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd\nCloses-Bug: #1782518\n'}, {'number': 5, 'created': '2019-02-25 05:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/a679d5cd89521e51981247a04bd28f6312df7040', 'message': 'Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped\n\nThe instance which is vm_state=resized and power_state=SHUTDOWN\nshould not be recovered with vm_state=error. It should be recovered\nwith vm_state=stopped. The instances such as paused or suspended\n(which are other than vm_state=active,stopped,error) are also the same.\n\nThis patch modified that masakari-engine will recover these instances\nwith vm_state=stopped.\n\nChange-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd\nCloses-Bug: #1782518\n'}, {'number': 6, 'created': '2019-02-25 05:30:38.000000000', 'files': ['masakari/tests/unit/fakes.py', 'masakari/engine/drivers/taskflow/host_failure.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/c3d12e37b0c5123cb2b2397c12f6f4ba6c45e73f', 'message': 'Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped\n\nThe instance which is vm_state=resized and power_state=SHUTDOWN\nshould not be recovered with vm_state=error. It should be recovered\nwith vm_state=stopped. The instances such as paused or suspended\n(which are other than vm_state=active,stopped,error) are also the same.\n\nThis patch modified that masakari-engine will recover these instances\nwith vm_state=stopped.\n\nChange-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd\nCloses-Bug: #1782518\n'}]",18,585592,c3d12e37b0c5123cb2b2397c12f6f4ba6c45e73f,32,7,6,23226,,,0,"Recover resized instance(power_state=SHUTDOWN) with vm_state=stopped

The instance which is vm_state=resized and power_state=SHUTDOWN
should not be recovered with vm_state=error. It should be recovered
with vm_state=stopped. The instances such as paused or suspended
(which are other than vm_state=active,stopped,error) are also the same.

This patch modified that masakari-engine will recover these instances
with vm_state=stopped.

Change-Id: Ibdea705f69d139834c9b2294ae11bc9344c259bd
Closes-Bug: #1782518
",git fetch https://review.opendev.org/openstack/masakari refs/changes/92/585592/3 && git format-patch -1 --stdout FETCH_HEAD,"['masakari/engine/drivers/taskflow/host_failure.py', 'masakari/tests/unit/fakes.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py']",3,6e66466d10fb6a13adf3f98a3277a55448d12eab,bug/1782518," if getattr(server, 'OS-EXT-STS:vm_state') in \ ['active', 'stopped', 'error']: self.assertEqual(getattr(server, 'OS-EXT-STS:vm_state'), getattr(instance, 'OS-EXT-STS:vm_state')) else: if getattr(server, 'OS-EXT-STS:vm_state') == 'resized' and \ getattr(server, 'OS-EXT-STS:power_state') != 4: self.assertEqual(getattr(instance, 'OS-EXT-STS:vm_state'), 'active') else: self.assertEqual(getattr(instance, 'OS-EXT-STS:vm_state'), 'stopped') self, _mock_novaclient, mock_unlock, mock_lock, mock_enable_disable):"," self.assertIn(getattr(instance, 'OS-EXT-STS:vm_state'), ['active', 'stopped', 'error']) @mock.patch.object(nova.API, 'stop_server') @mock.patch.object(nova.API, 'reset_instance_state') self, _mock_novaclient, mock_reset, mock_stop, mock_unlock, mock_lock, mock_enable_disable): reset_calls = [mock.call(self.ctxt, ""1""), mock.call(self.ctxt, ""2""), mock.call(self.ctxt, ""3""), mock.call(self.ctxt, ""3"")] mock_reset.assert_has_calls(reset_calls) self.assertEqual(4, mock_reset.call_count) stop_calls = [mock.call(self.ctxt, ""2""), mock.call(self.ctxt, ""3"")] mock_stop.assert_has_calls(stop_calls) self.assertEqual(2, mock_stop.call_count)",17,20
openstack%2Fhorizon~master~If5fc190988cf173387da2b66be23db9134310692,openstack/horizon,master,If5fc190988cf173387da2b66be23db9134310692,Use correct cinder API version for tenant_absolute_limits,MERGED,2019-01-14 21:33:53.000000000,2019-03-06 10:46:07.000000000,2019-02-12 21:47:21.000000000,"[{'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-01-14 21:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/554804cf0ce15f0163ee62f713529953212656e7', 'message': 'Use correct cinder API version for tenant_absolute_limits\n\nTo verify resource usages when updating project quotas,\nproject_id query parameter needs to be supported in\ntenant_absolute_limits in the cinder API.\n\nThis is supported in 3.39 or later in the cinder API.\nAPI vesions shipped with released versions (pike, queens and\nrocky) are selected as verified versions.\n\nChange-Id: If5fc190988cf173387da2b66be23db9134310692\nCloses-Bug: #1810309\n'}, {'number': 2, 'created': '2019-01-14 23:32:44.000000000', 'files': ['openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/microversions.py', 'openstack_dashboard/test/unit/api/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/32bfbbf10074b49b36447abd2e4f47f9f39d0ea7', 'message': 'Use correct cinder API version for tenant_absolute_limits\n\nTo verify resource usages when updating project quotas,\nproject_id query parameter needs to be supported in\ntenant_absolute_limits in the cinder API.\n\nThis is supported in 3.39 or later in the cinder API.\nAPI vesions shipped with released versions (pike, queens and\nrocky) are selected as verified versions.\n\nChange-Id: If5fc190988cf173387da2b66be23db9134310692\nCloses-Bug: #1810309\n'}]",0,630774,32bfbbf10074b49b36447abd2e4f47f9f39d0ea7,11,4,2,841,,,0,"Use correct cinder API version for tenant_absolute_limits

To verify resource usages when updating project quotas,
project_id query parameter needs to be supported in
tenant_absolute_limits in the cinder API.

This is supported in 3.39 or later in the cinder API.
API vesions shipped with released versions (pike, queens and
rocky) are selected as verified versions.

Change-Id: If5fc190988cf173387da2b66be23db9134310692
Closes-Bug: #1810309
",git fetch https://review.opendev.org/openstack/horizon refs/changes/74/630774/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/microversions.py', 'openstack_dashboard/test/unit/api/test_cinder.py']",3,554804cf0ce15f0163ee62f713529953212656e7,bug/1810309," @mock.patch.object(api.cinder, '_cinderclient_with_limits_project_id_query') mock_cinderclient.assert_called_once_with(self.request)"," @mock.patch.object(api.cinder, 'cinderclient')",16,3
openstack%2Fnetworking-ovn~master~I9542669c1f7f16c6ce8a7a10afcbf7f563f35919,openstack/networking-ovn,master,I9542669c1f7f16c6ce8a7a10afcbf7f563f35919,Migrate from Octavia to Octavia-Lib,MERGED,2019-02-13 07:56:50.000000000,2019-03-06 10:37:51.000000000,2019-02-15 21:16:50.000000000,"[{'_account_id': 6469}, {'_account_id': 6773}, {'_account_id': 17776}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-13 07:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/cb57a3bcf4bb72bccfef3e671e65d7ba202dbbfe', 'message': 'Migrate from Octavia to Octavia-Lib\n\nThis patch migrates from octavia to octavia-lib\n\nChange-Id: I9542669c1f7f16c6ce8a7a10afcbf7f563f35919\n'}, {'number': 2, 'created': '2019-02-13 07:58:22.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'test-requirements.txt', 'networking_ovn/tests/functional/requirements.txt', 'networking_ovn/tests/functional/octavia/test_ovn_driver.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c9d6820dc4f0b728bbce2ac90ad9d416c451a0c6', 'message': 'Migrate from Octavia to Octavia-Lib\n\nThis patch migrates from octavia to octavia-lib\n\nChange-Id: I9542669c1f7f16c6ce8a7a10afcbf7f563f35919\n'}]",10,636564,c9d6820dc4f0b728bbce2ac90ad9d416c451a0c6,21,5,2,17776,,,0,"Migrate from Octavia to Octavia-Lib

This patch migrates from octavia to octavia-lib

Change-Id: I9542669c1f7f16c6ce8a7a10afcbf7f563f35919
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/64/636564/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/functional/requirements.txt', 'test-requirements.txt', 'networking_ovn/tests/functional/octavia/test_ovn_driver.py', 'lower-constraints.txt', 'tox.ini']",6,cb57a3bcf4bb72bccfef3e671e65d7ba202dbbfe,, coverage erase,,30,19
openstack%2Fpython-glanceclient~master~I4f764b17155bc6cbaf9f03bd9f295de178ed0272,openstack/python-glanceclient,master,I4f764b17155bc6cbaf9f03bd9f295de178ed0272,add python 3.7 unit test job,MERGED,2019-02-15 18:47:54.000000000,2019-03-06 10:37:29.000000000,2019-03-06 10:37:29.000000000,"[{'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-02-15 18:47:54.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/332cc181696e7f7c685a8a5b52df01f089b4715b', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I4f764b17155bc6cbaf9f03bd9f295de178ed0272\nStory: #2004073\nTask: #27415\n'}]",0,637252,332cc181696e7f7c685a8a5b52df01f089b4715b,13,4,1,11805,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I4f764b17155bc6cbaf9f03bd9f295de178ed0272
Story: #2004073
Task: #27415
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/52/637252/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,332cc181696e7f7c685a8a5b52df01f089b4715b,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fcharm-ceph-osd~master~Ie3a0a3c2f03674c9cb9e36096ffc7ebde62a0fce,openstack/charm-ceph-osd,master,Ie3a0a3c2f03674c9cb9e36096ffc7ebde62a0fce,add .stestr.conf,ABANDONED,2019-03-06 10:10:16.000000000,2019-03-06 10:22:46.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-06 10:10:16.000000000', 'files': ['.stestr.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/289350595d98ed803f4cd0f27f8784b9602dd10b', 'message': 'add .stestr.conf\n\nChange-Id: Ie3a0a3c2f03674c9cb9e36096ffc7ebde62a0fce\n'}]",0,641292,289350595d98ed803f4cd0f27f8784b9602dd10b,3,1,1,20634,,,0,"add .stestr.conf

Change-Id: Ie3a0a3c2f03674c9cb9e36096ffc7ebde62a0fce
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/92/641292/1 && git format-patch -1 --stdout FETCH_HEAD,['.stestr.conf'],1,289350595d98ed803f4cd0f27f8784b9602dd10b,add-stestr,[DEFAULT] test_path=./unit_tests top_dir=./ ,,3,0
openstack%2Floci~master~I3e7fe86690a89c5084b79a6e1cc49bbf63002430,openstack/loci,master,I3e7fe86690a89c5084b79a6e1cc49bbf63002430,Add missing curl for suse heat images,MERGED,2019-03-05 16:31:51.000000000,2019-03-06 10:14:02.000000000,2019-03-06 10:14:02.000000000,"[{'_account_id': 2062}, {'_account_id': 7069}, {'_account_id': 7822}, {'_account_id': 9963}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 16:31:51.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/loci/commit/ad1273755911f45e4d261376815e9050b3f79bb5', 'message': 'Add missing curl for suse heat images\n\nheat images use curl in some cases, like glance-bootstrap, to\ndownload artifacts. Suse images do not contain curl by default\nso its missing.\n\nThis adds the curl dependency for suse heat images to the bindep.txt\n\nChange-Id: I3e7fe86690a89c5084b79a6e1cc49bbf63002430\n'}]",0,641075,ad1273755911f45e4d261376815e9050b3f79bb5,10,6,1,12281,,,0,"Add missing curl for suse heat images

heat images use curl in some cases, like glance-bootstrap, to
download artifacts. Suse images do not contain curl by default
so its missing.

This adds the curl dependency for suse heat images to the bindep.txt

Change-Id: I3e7fe86690a89c5084b79a6e1cc49bbf63002430
",git fetch https://review.opendev.org/openstack/loci refs/changes/75/641075/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,ad1273755911f45e4d261376815e9050b3f79bb5,osh_suse_missing_curl,curl [platform:suse heat],,1,0
openstack%2Frpm-packaging~stable%2Fpike~Idc09b204df78eab499f3347e65a439bbf6980346,openstack/rpm-packaging,stable/pike,Idc09b204df78eab499f3347e65a439bbf6980346,python-cinderclient: Update to 3.1.1,MERGED,2019-03-06 07:53:40.000000000,2019-03-06 10:09:18.000000000,2019-03-06 10:09:18.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 07:53:40.000000000', 'files': ['openstack/python-cinderclient/python-cinderclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c82b8cac87a9d29d1b2cdfebcf33359a2a6730c0', 'message': 'python-cinderclient: Update to 3.1.1\n\nChange-Id: Idc09b204df78eab499f3347e65a439bbf6980346\n'}]",0,641269,c82b8cac87a9d29d1b2cdfebcf33359a2a6730c0,9,5,1,7102,,,0,"python-cinderclient: Update to 3.1.1

Change-Id: Idc09b204df78eab499f3347e65a439bbf6980346
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/69/641269/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-cinderclient/python-cinderclient.spec.j2'],1,c82b8cac87a9d29d1b2cdfebcf33359a2a6730c0,stable-pike,Version: 3.1.1,Version: 3.1.0,1,1
openstack%2Fmanila~master~I85d3fe896ee95c52c3da55aedba8f4d72d0c299e,openstack/manila,master,I85d3fe896ee95c52c3da55aedba8f4d72d0c299e,[pylint] Run pylint separately for code and tests,MERGED,2019-02-20 04:30:21.000000000,2019-03-06 10:07:23.000000000,2019-03-05 22:12:38.000000000,"[{'_account_id': 2417}, {'_account_id': 6413}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 26968}]","[{'number': 1, 'created': '2019-02-20 04:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e3199dc4cb0e63e09bc40878e997be46391b680e', 'message': '[pylint] Run pylint separately for code and tests\n\nWe use the mock library in our\nunit tests which assigns mocked objects with\nmembers at run time. This causes pylint to flag\n""no-member"" errors. We also test return values\non methods which return None explicitly, or\nimplicitly, this upsets pylint.\n\npylint is quite inflexible in the way it handles\nignores in code. We can add ignore statements all\nover the test code, but that is quite infeasible.\n\nSo, this change lets us run pylint separately\nfor code and test modules. When running tests,\nit adjusts the disabled pylint checks.\n\nChange-Id: I85d3fe896ee95c52c3da55aedba8f4d72d0c299e\n'}, {'number': 2, 'created': '2019-03-05 21:23:55.000000000', 'files': ['tools/coding-checks.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/10bd807423dfd7e8bb73b114de8c606047846c66', 'message': '[pylint] Run pylint separately for code and tests\n\nWe use the mock library in our\nunit tests which assigns mocked objects with\nmembers at run time. This causes pylint to flag\n""no-member"" errors. We also test return values\non methods which return None explicitly, or\nimplicitly, this upsets pylint.\n\npylint is quite inflexible in the way it handles\nignores in code. We can add ignore statements all\nover the test code, but that is quite infeasible.\n\nSo, this change lets us run pylint separately\nfor code and test modules. When running tests,\nit adjusts the disabled pylint checks.\n\nChange-Id: I85d3fe896ee95c52c3da55aedba8f4d72d0c299e\n'}]",4,638075,10bd807423dfd7e8bb73b114de8c606047846c66,32,17,2,16643,,,0,"[pylint] Run pylint separately for code and tests

We use the mock library in our
unit tests which assigns mocked objects with
members at run time. This causes pylint to flag
""no-member"" errors. We also test return values
on methods which return None explicitly, or
implicitly, this upsets pylint.

pylint is quite inflexible in the way it handles
ignores in code. We can add ignore statements all
over the test code, but that is quite infeasible.

So, this change lets us run pylint separately
for code and test modules. When running tests,
it adjusts the disabled pylint checks.

Change-Id: I85d3fe896ee95c52c3da55aedba8f4d72d0c299e
",git fetch https://review.opendev.org/openstack/manila refs/changes/75/638075/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/coding-checks.sh', 'tox.ini']",2,e3199dc4cb0e63e09bc40878e997be46391b680e,pylint, tools/check_logging.sh \ tools/coding-checks.sh, tools/check_logging.sh,24,10
openstack%2Fkeystone~master~I618c0d263d4c0f497aef59f24215b60169948ea9,openstack/keystone,master,I618c0d263d4c0f497aef59f24215b60169948ea9,Drop py35 jobs,MERGED,2019-02-28 05:00:12.000000000,2019-03-06 09:54:26.000000000,2019-03-06 09:54:26.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-02-28 05:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d5aaf1ed5a9f249b7fac4e62d99bb4e18120decf', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older\nversion.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I618c0d263d4c0f497aef59f24215b60169948ea9\n'}, {'number': 2, 'created': '2019-02-28 05:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fd2695c7298eba39f3fefdc30153699f5c8fc7cf', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older\nversion.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I618c0d263d4c0f497aef59f24215b60169948ea9\n'}, {'number': 3, 'created': '2019-02-28 05:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e2fab06c9c9f20c77d8f8f149b91115f6c2979b1', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older\nversion.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I618c0d263d4c0f497aef59f24215b60169948ea9\n'}, {'number': 4, 'created': '2019-03-05 05:27:33.000000000', 'files': ['.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a022e2730799f3f6c0c48540b647259ce87dd806', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older\nversion.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I618c0d263d4c0f497aef59f24215b60169948ea9\n'}]",1,639909,a022e2730799f3f6c0c48540b647259ce87dd806,22,5,4,27621,,,0,"Drop py35 jobs

Python 3.5 was the target runtime for the Rocky release.
The current target py3 runtime for Stein is Python 3.6,
so there is no reason to keep testing against the older
version.

https://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein

Change-Id: I618c0d263d4c0f497aef59f24215b60169948ea9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/639909/4 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,d5aaf1ed5a9f249b7fac4e62d99bb4e18120decf,drop-py35,"envlist = py37,py36,py27,pep8,api-ref,docs,genconfig,genpolicy,releasenotes","envlist = py37,py36,py35,py27,pep8,api-ref,docs,genconfig,genpolicy,releasenotes",3,4
openstack%2Ftripleo-docs~master~I098ec1cb840ea8ac30c6abccce7625fe0ee6047f,openstack/tripleo-docs,master,I098ec1cb840ea8ac30c6abccce7625fe0ee6047f,Update FFU docs reference to actual docs,MERGED,2019-03-05 10:22:47.000000000,2019-03-06 09:46:53.000000000,2019-03-06 09:46:53.000000000,"[{'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-03-05 10:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/0baf9612d85a6bbac6a9f7e2854fc4596262b430', 'message': 'Update FFU docs reference to actual docs\n\nIt used to point at the patch introducing the docs.\n\nChange-Id: I098ec1cb840ea8ac30c6abccce7625fe0ee6047f\n'}, {'number': 2, 'created': '2019-03-06 08:40:20.000000000', 'files': ['doc/source/upgrade/developer/upgrades/fast_fw_upgrade.rst', 'doc/source/upgrade/fast_forward_upgrade.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/4fe6d68331668a98be030b8b8c65c0a9017eeacb', 'message': 'Update FFU docs reference to actual docs\n\nIt used to point at the patch introducing the docs.\n\nRelated-Bug: #1804642\nChange-Id: I098ec1cb840ea8ac30c6abccce7625fe0ee6047f\n'}]",1,640974,4fe6d68331668a98be030b8b8c65c0a9017eeacb,11,4,2,10873,,,0,"Update FFU docs reference to actual docs

It used to point at the patch introducing the docs.

Related-Bug: #1804642
Change-Id: I098ec1cb840ea8ac30c6abccce7625fe0ee6047f
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/74/640974/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/upgrade/developer/upgrades/fast_fw_upgrade.rst', 'doc/source/upgrade/fast_forward_upgrade.rst']",2,0baf9612d85a6bbac6a9f7e2854fc4596262b430,upgrades-fix,.. _ffu-docs: ,,3,2
openstack%2Fmagnum~master~I2d4cf54631c8ed3a9eb30b3e6c8e1af0007e23d5,openstack/magnum,master,I2d4cf54631c8ed3a9eb30b3e6c8e1af0007e23d5,Do not exit in the enable-helm-tiller script,MERGED,2019-02-28 00:50:30.000000000,2019-03-06 09:46:49.000000000,2019-03-06 09:46:49.000000000,"[{'_account_id': 6484}, {'_account_id': 6732}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 29425}]","[{'number': 1, 'created': '2019-02-28 00:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/278fd886cbf81a63105e81025c851ed48f421cbb', 'message': 'Do not exit in the enable-helm-tiller script\n\nThe scripts included in the Heat kube_cluster_config resource should not exit\nif the particular step is skipped.\n\nChange-Id: I2d4cf54631c8ed3a9eb30b3e6c8e1af0007e23d5\nStory: #2005109\nTask: #29743\n'}, {'number': 2, 'created': '2019-02-28 03:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1a75a498dd8ddfb22e297a3380693c5e6ceafb52', 'message': 'Do not exit in the enable-helm-tiller script\n\nThe scripts included in the Heat kube_cluster_config resource should not exit\nif the particular step is skipped.\n\nChange-Id: I2d4cf54631c8ed3a9eb30b3e6c8e1af0007e23d5\nStory: #2005109\nTask: #29743\n'}, {'number': 3, 'created': '2019-02-28 23:04:08.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/enable-helm-tiller.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/36955360851f62e588cce982278aee3849224f62', 'message': 'Do not exit in the enable-helm-tiller script\n\nThe scripts included in the Heat kube_cluster_config resource should not exit\nif the particular step is skipped.\n\nChange-Id: I2d4cf54631c8ed3a9eb30b3e6c8e1af0007e23d5\nStory: #2005109\nTask: #29743\n'}]",0,639873,36955360851f62e588cce982278aee3849224f62,22,6,3,6732,,,0,"Do not exit in the enable-helm-tiller script

The scripts included in the Heat kube_cluster_config resource should not exit
if the particular step is skipped.

Change-Id: I2d4cf54631c8ed3a9eb30b3e6c8e1af0007e23d5
Story: #2005109
Task: #29743
",git fetch https://review.opendev.org/openstack/magnum refs/changes/73/639873/3 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/common/templates/kubernetes/fragments/enable-helm-tiller.sh'],1,278fd886cbf81a63105e81025c851ed48f421cbb,fix-exit,"step=""enable-helm-tiller"" printf ""Starting to run ${step}\n"" if [ ""$(echo ${TILLER_ENABLED} | tr '[:upper:]' '[:lower:]')"" = ""true"" ]; then CERTS_DIR=""/etc/kubernetes/helm/certs/"" mkdir -p ""${CERTS_DIR}"" # Private CA key openssl genrsa -out ""${CERTS_DIR}/ca.key.pem"" 4096 # CA public cert openssl req -key ""${CERTS_DIR}/ca.key.pem"" -new -x509 -days 7300 -sha256 -out ""${CERTS_DIR}/ca.cert.pem"" -extensions v3_ca -subj ""/C=US/ST=Texas/L=Austin/O=OpenStack/OU=Magnum/CN=tiller"" # Private tiller-server key openssl genrsa -out ""${CERTS_DIR}/tiller.key.pem"" 4096 # Private helm-client key openssl genrsa -out ""${CERTS_DIR}/helm.key.pem"" 4096 # Request for tiller-server cert openssl req -key ""${CERTS_DIR}/tiller.key.pem"" -new -sha256 -out ""${CERTS_DIR}/tiller.csr.pem"" -subj ""/C=US/ST=Texas/L=Austin/O=OpenStack/OU=Magnum/CN=tiller-server"" # Request for helm-client cert openssl req -key ""${CERTS_DIR}/helm.key.pem"" -new -sha256 -out ""${CERTS_DIR}/helm.csr.pem"" -subj ""/C=US/ST=Texas/L=Austin/O=OpenStack/OU=Magnum/CN=helm-client"" # Sign tiller-server cert openssl x509 -req -CA ""${CERTS_DIR}/ca.cert.pem"" -CAkey ""${CERTS_DIR}/ca.key.pem"" -CAcreateserial -in ""${CERTS_DIR}/tiller.csr.pem"" -out ""${CERTS_DIR}/tiller.cert.pem"" -days 365 # Sign helm-client cert openssl x509 -req -CA ""${CERTS_DIR}/ca.cert.pem"" -CAkey ""${CERTS_DIR}/ca.key.pem"" -CAcreateserial -in ""${CERTS_DIR}/helm.csr.pem"" -out ""${CERTS_DIR}/helm.cert.pem"" -days 365 _tiller_prefix=${CONTAINER_INFRA_PREFIX:-gcr.io/kubernetes-helm/} TILLER_RBAC=/srv/magnum/kubernetes/manifests/tiller-rbac.yaml TILLER_DEPLOYER=/srv/magnum/kubernetes/manifests/deploy-tiller.yaml TILLER_IMAGE=""${_tiller_prefix}tiller:${TILLER_TAG}"" [ -f ${TILLER_RBAC} ] || { echo ""Writing File: $TILLER_RBAC"" mkdir -p $(dirname ${TILLER_RBAC}) cat << EOF > ${TILLER_RBAC} } [ -f ${TILLER_DEPLOYER} ] || { echo ""Writing File: $TILLER_DEPLOYER"" mkdir -p $(dirname ${TILLER_DEPLOYER}) cat << EOF > ${TILLER_DEPLOYER} } echo ""Waiting for Kubernetes API..."" until [ ""ok"" = ""$(curl --silent http://127.0.0.1:8080/healthz)"" ] do sleep 5 done kubectl apply -f ${TILLER_RBAC} kubectl apply -f ${TILLER_DEPLOYER} fi printf ""Finished running ${step}\n""","if [ ""$(echo ${TILLER_ENABLED} | tr '[:upper:]' '[:lower:]')"" != ""true"" ]; then exit 0 fi CERTS_DIR=""/etc/kubernetes/helm/certs/"" mkdir -p ""${CERTS_DIR}"" # Private CA key openssl genrsa -out ""${CERTS_DIR}/ca.key.pem"" 4096 # CA public cert openssl req -key ""${CERTS_DIR}/ca.key.pem"" -new -x509 -days 7300 -sha256 -out ""${CERTS_DIR}/ca.cert.pem"" -extensions v3_ca -subj ""/C=US/ST=Texas/L=Austin/O=OpenStack/OU=Magnum/CN=tiller"" # Private tiller-server key openssl genrsa -out ""${CERTS_DIR}/tiller.key.pem"" 4096 # Private helm-client key openssl genrsa -out ""${CERTS_DIR}/helm.key.pem"" 4096 # Request for tiller-server cert openssl req -key ""${CERTS_DIR}/tiller.key.pem"" -new -sha256 -out ""${CERTS_DIR}/tiller.csr.pem"" -subj ""/C=US/ST=Texas/L=Austin/O=OpenStack/OU=Magnum/CN=tiller-server"" # Request for helm-client cert openssl req -key ""${CERTS_DIR}/helm.key.pem"" -new -sha256 -out ""${CERTS_DIR}/helm.csr.pem"" -subj ""/C=US/ST=Texas/L=Austin/O=OpenStack/OU=Magnum/CN=helm-client"" # Sign tiller-server cert openssl x509 -req -CA ""${CERTS_DIR}/ca.cert.pem"" -CAkey ""${CERTS_DIR}/ca.key.pem"" -CAcreateserial -in ""${CERTS_DIR}/tiller.csr.pem"" -out ""${CERTS_DIR}/tiller.cert.pem"" -days 365 # Sign helm-client cert openssl x509 -req -CA ""${CERTS_DIR}/ca.cert.pem"" -CAkey ""${CERTS_DIR}/ca.key.pem"" -CAcreateserial -in ""${CERTS_DIR}/helm.csr.pem"" -out ""${CERTS_DIR}/helm.cert.pem"" -days 365 _tiller_prefix=${CONTAINER_INFRA_PREFIX:-gcr.io/kubernetes-helm/} TILLER_RBAC=/srv/magnum/kubernetes/manifests/tiller-rbac.yaml TILLER_DEPLOYER=/srv/magnum/kubernetes/manifests/deploy-tiller.yaml TILLER_IMAGE=""${_tiller_prefix}tiller:${TILLER_TAG}"" [ -f ${TILLER_RBAC} ] || { echo ""Writing File: $TILLER_RBAC"" mkdir -p $(dirname ${TILLER_RBAC}) cat << EOF > ${TILLER_RBAC}} [ -f ${TILLER_DEPLOYER} ] || { echo ""Writing File: $TILLER_DEPLOYER"" mkdir -p $(dirname ${TILLER_DEPLOYER}) cat << EOF > ${TILLER_DEPLOYER}} echo ""Waiting for Kubernetes API..."" until [ ""ok"" = ""$(curl --silent http://127.0.0.1:8080/healthz)"" ] do sleep 5 done kubectl apply -f ${TILLER_RBAC} kubectl apply -f ${TILLER_DEPLOYER}",46,43
openstack%2Fdesignate~master~Ia9534b2e8615410519cf5f9792c35aa78692ff2c,openstack/designate,master,Ia9534b2e8615410519cf5f9792c35aa78692ff2c,Enable worker by default,ABANDONED,2019-03-01 14:35:48.000000000,2019-03-06 09:35:57.000000000,,"[{'_account_id': 8099}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 14:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c546f960c91953c9678a045d08fa66784f613e9f', 'message': 'Enable worker by default\n\nWe want to remove the [service:worker]enabled option[0], for this we\nneed to make it True by default first. Adapt setting up options in\ndevstack accordingly.\n\nAlso drop some code that has been commented out for years.\n\n[0] I4c0f82b42a4b18ece2e59de8007c527f986ac071\n\nChange-Id: Ia9534b2e8615410519cf5f9792c35aa78692ff2c\n'}, {'number': 2, 'created': '2019-03-05 14:21:12.000000000', 'files': ['designate/worker/__init__.py', 'designate/tests/unit/test_central/test_basic.py', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/5217d39144d48e9048bb01f5076c29de371c6344', 'message': 'Enable worker by default\n\nWe want to remove the [service:worker]enabled option[0], for this we\nneed to make it True by default first. Adapt setting up options in\ndevstack and amend unit tests accordingly.\n\nAlso drop some code that has been commented out for years.\n\n[0] I4c0f82b42a4b18ece2e59de8007c527f986ac071\n\nChange-Id: Ia9534b2e8615410519cf5f9792c35aa78692ff2c\n'}]",0,640383,5217d39144d48e9048bb01f5076c29de371c6344,8,3,2,13252,,,0,"Enable worker by default

We want to remove the [service:worker]enabled option[0], for this we
need to make it True by default first. Adapt setting up options in
devstack and amend unit tests accordingly.

Also drop some code that has been commented out for years.

[0] I4c0f82b42a4b18ece2e59de8007c527f986ac071

Change-Id: Ia9534b2e8615410519cf5f9792c35aa78692ff2c
",git fetch https://review.opendev.org/openstack/designate refs/changes/83/640383/2 && git format-patch -1 --stdout FETCH_HEAD,"['designate/worker/__init__.py', 'devstack/plugin.sh']",2,c546f960c91953c9678a045d08fa66784f613e9f,default-worker, else iniset $DESIGNATE_CONF service:worker enabled False, iniset $DESIGNATE_CONF service:worker enabled True,3,4
openstack%2Fmasakari~master~Iea2769bce4ceaea34d6d52e97c7e29cb8606ca71,openstack/masakari,master,Iea2769bce4ceaea34d6d52e97c7e29cb8606ca71,Functional tests for host APIs,MERGED,2019-03-04 13:07:47.000000000,2019-03-06 09:25:56.000000000,2019-03-06 09:25:56.000000000,"[{'_account_id': 1011}, {'_account_id': 22348}, {'_account_id': 25267}, {'_account_id': 29238}]","[{'number': 1, 'created': '2019-03-04 13:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/94aa842d663623be74d8d3740f329c9f38f0cda4', 'message': 'Functional tests for host APIs\n\nThis patch adds functional tests to check the behaviour\nof host APIs.\n\nChange-Id: Iea2769bce4ceaea34d6d52e97c7e29cb8606ca71\n'}, {'number': 2, 'created': '2019-03-06 05:46:30.000000000', 'files': ['masakari/tests/functional/test_hosts.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/1b047783085579a7ce1ec04ee3728dff6b7a173e', 'message': 'Functional tests for host APIs\n\nThis patch adds functional tests to check the behaviour\nof host APIs.\n\nChange-Id: Iea2769bce4ceaea34d6d52e97c7e29cb8606ca71\n'}]",4,640757,1b047783085579a7ce1ec04ee3728dff6b7a173e,14,4,2,29238,,,0,"Functional tests for host APIs

This patch adds functional tests to check the behaviour
of host APIs.

Change-Id: Iea2769bce4ceaea34d6d52e97c7e29cb8606ca71
",git fetch https://review.opendev.org/openstack/masakari refs/changes/57/640757/2 && git format-patch -1 --stdout FETCH_HEAD,['masakari/tests/functional/test_hosts.py'],1,94aa842d663623be74d8d3740f329c9f38f0cda4,functional_tests_for_host,"# Copyright (C) 2019 NTT DATA # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import ddt from masakari.objects import fields from masakari.tests.functional import base @ddt.ddt class TestHosts(base.BaseFunctionalTest): def setUp(self): super(TestHosts, self).setUp() if not self.hypervisors: self.skipTest(""Skipped as there are no hypervisors "" ""configured in nova"") # Create segment self.segment = self.conn.ha.create_segment( name=self.getUniqueString(), recovery_method=fields.FailoverSegmentRecoveryMethod.AUTO, service_type='COMPUTE') # Delete segment which deletes host/s associated with it self.addCleanup(self.conn.ha.delete_segment, self.segment.uuid) def test_create_get(self): # This test is for testing hosts create/get # Create valid host host_name = self.hypervisors[0]['hypervisor_hostname'] host_data = {'name': host_name, 'type': 'COMPUTE', 'on_maintenance': False, 'reserved': False, 'control_attributes': 'SSH'} host = self.conn.ha.create_host(self.segment.uuid, **host_data) self.assertDictContainsSubset(host_data, host) result = self.conn.ha.get_host(host.uuid, self.segment.uuid) self.assertEqual('COMPUTE', result.type) self.assertEqual(False, result.on_maintenance) self.assertEqual(False, result.reserved) self.assertEqual('SSH', result.control_attributes) def test_list(self): # This test is for testing host/s creation and listing the same. expected_hosts = [] for host in self.hypervisors: host_obj = self.conn.ha.create_host(segment_id=self.segment.uuid, name=host.hypervisor_hostname, type='COMPUTE', on_maintenance=False, reserved=False, control_attributes='SSH') # Deleting 'segment_id' as in GET list call of host 'segment_id' # is not there in response del host_obj['segment_id'] expected_hosts.append(host_obj) hosts = self.conn.ha.hosts(self.segment.uuid) self.assertItemsEqual(expected_hosts, hosts) @ddt.data( {'on_maintenance': False, 'type': 'COMPUTE', 'reserved': False, 'expected_host_data': { ""type"": 'COMPUTE', ""on_maintenance"": False, ""reserved"": False, ""control_attributes"": 'SSH'}}, {'on_maintenance': True, 'type': 'CONTROLLER', 'reserved': True, 'expected_host_data': { ""type"": 'CONTROLLER', ""on_maintenance"": True, ""reserved"": True, ""control_attributes"": 'SSH'}}) @ddt.unpack def test_create_list_with_filter(self, on_maintenance, type, expected_host_data, reserved): # This test is for testing host/s creation and listing # the same based on filters. if len(self.hypervisors) == 1: self.skipTest(""Skipped as there is only one hypervisor "" ""configured in nova"") host_data_1 = {'name': self.hypervisors[0].hypervisor_hostname, ""type"": 'COMPUTE', ""on_maintenance"": False, ""reserved"": False, ""control_attributes"": 'SSH'} host_data_2 = {'name': self.hypervisors[1].hypervisor_hostname, ""type"": 'CONTROLLER', ""on_maintenance"": True, ""reserved"": True, ""control_attributes"": 'SSH'} self.conn.ha.create_host(self.segment.uuid, **host_data_1) self.conn.ha.create_host(self.segment.uuid, **host_data_2) # Returns list of hosts based on filters for host in self.conn.ha.hosts(self.segment.uuid, on_maintenance=on_maintenance, type=type, reserved=reserved): self.assertDictContainsSubset(expected_host_data, host) def test_update_get_delete(self): # This test is for updating created host and deletion of same host_name = self.hypervisors[0]['hypervisor_hostname'] host = self.conn.ha.create_host(segment_id=self.segment.uuid, name=host_name, on_maintenance='False', reserved='False', type='COMPUTE', control_attributes='SSH') self.conn.ha.update_host(host['uuid'], segment_id=self.segment.uuid, on_maintenance='True', control_attributes='TCP', reserved='True') result = self.conn.ha.get_host(host.uuid, host.failover_segment_id) # Confirm host update self.assertEqual(True, result.on_maintenance) self.assertEqual(True, result.reserved) self.assertEqual('TCP', result.control_attributes) def test_update_host_name(self): # This test is for updating host name if len(self.hypervisors) == 1: self.skipTest(""Skipped as there is only one hypervisor "" ""configured in nova"") host = self.conn.ha.create_host(segment_id=self.segment.uuid, name=self.hypervisors[0]['hypervisor_hostname'], type='COMPUTE', control_attributes='SSH') # Update host name updated_host = self.conn.ha.update_host(host['uuid'], segment_id=self.segment.uuid, name=self.hypervisors[1]['hypervisor_hostname']) result = self.conn.ha.get_host(host.uuid, host.failover_segment_id) self.assertEqual(result.name, updated_host.name) ",,169,0
openstack%2Fpuppet-sahara~master~I1571576dc4c1958c5d1ed9cd7cc594d8a0daa005,openstack/puppet-sahara,master,I1571576dc4c1958c5d1ed9cd7cc594d8a0daa005,Add log_file parameter,MERGED,2019-03-06 04:02:30.000000000,2019-03-06 09:18:06.000000000,2019-03-06 09:18:06.000000000,"[{'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 04:02:30.000000000', 'files': ['manifests/logging.pp', 'spec/classes/sahara_logging_spec.rb', 'releasenotes/notes/add-log_file-for-logging-98ab323c1e1528b8.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/312338f9c9390e412d40f580dc7da25972b60060', 'message': 'Add log_file parameter\n\nChange-Id: I1571576dc4c1958c5d1ed9cd7cc594d8a0daa005\n'}]",0,641195,312338f9c9390e412d40f580dc7da25972b60060,7,3,1,26721,,,0,"Add log_file parameter

Change-Id: I1571576dc4c1958c5d1ed9cd7cc594d8a0daa005
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/95/641195/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/logging.pp', 'releasenotes/notes/add-log_file-for-logging-98ab323c1e1528b8.yaml', 'spec/classes/sahara_logging_spec.rb']",3,312338f9c9390e412d40f580dc7da25972b60060,," :log_file => 'sahara.log', :log_file => '<SERVICE DEFAULT>', :log_file => 'sahara.log',",,13,0
openstack%2Fkolla~master~I19000564445254ba4d168f24deef6a901391d2e2,openstack/kolla,master,I19000564445254ba4d168f24deef6a901391d2e2,drop some of the xll related packages,MERGED,2019-03-01 00:12:54.000000000,2019-03-06 09:16:41.000000000,2019-03-06 09:16:40.000000000,"[{'_account_id': 6926}, {'_account_id': 13039}, {'_account_id': 16282}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 23717}]","[{'number': 1, 'created': '2019-03-01 00:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/615a8d97f931616cfe3d30efeefdde4d9d7b8a0b', 'message': 'drop some of the xll related packages\n\nChange-Id: I19000564445254ba4d168f24deef6a901391d2e2\n'}, {'number': 2, 'created': '2019-03-01 00:14:23.000000000', 'files': ['docker/openstack-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5e1ac34c68488ea76cece7fc05370919278c8edf', 'message': 'drop some of the xll related packages\n\nthese are containers, we should not have X11 display libraries\ninstalled in base containers.  If they are being pulled in via\npackages those chains of dependencies should be looked at closely\nand pruned as they have no real use on container images.\n\nChange-Id: I19000564445254ba4d168f24deef6a901391d2e2\n'}]",1,640228,5e1ac34c68488ea76cece7fc05370919278c8edf,16,7,2,16282,,,0,"drop some of the xll related packages

these are containers, we should not have X11 display libraries
installed in base containers.  If they are being pulled in via
packages those chains of dependencies should be looked at closely
and pruned as they have no real use on container images.

Change-Id: I19000564445254ba4d168f24deef6a901391d2e2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/28/640228/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/openstack-base/Dockerfile.j2'],1,615a8d97f931616cfe3d30efeefdde4d9d7b8a0b,x11-library-cleanup,," 'cups-libs', 'fontconfig', 'fontpackages-filesystem', 'freetype', 'libjpeg-turbo', 'libpng', 'libX11', 'libX11-common', 'libXau', 'libxcb', 'libXext', 'libXi',",0,12
openstack%2Fkolla-ansible~master~Ic47f5ad81b8126a51e52a445097f7950dba233cd,openstack/kolla-ansible,master,Ic47f5ad81b8126a51e52a445097f7950dba233cd,Improve standalone ironic support,MERGED,2019-01-28 13:51:15.000000000,2019-03-06 09:03:31.000000000,2019-03-06 09:03:31.000000000,"[{'_account_id': 10343}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2019-01-28 13:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cde2b82bc6fd03e0fdd396637d75a89972957e4e', 'message': 'WIP: Improve standalone ironic support\n\nChange-Id: Ic47f5ad81b8126a51e52a445097f7950dba233cd\nTODO: Documentation, release note.\n'}, {'number': 2, 'created': '2019-02-22 17:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c046abe667feafeba373e5b81a569df59ef57170', 'message': ""Improve standalone ironic support\n\nAdds a new flag, 'enable_openstack_core', which defaults to 'yes'.\nSetting this flag to 'no' will disable the core OpenStack services,\nincluding Glance, Heat, Horizon, Keystone, Neutron, and Nova.\n\nImproves the default configuration of OpenStack Ironic when used in\nstandalone mode. In particular, configures a noauth mode when Keystone\nis disabled, and allows the iPXE server to be used for provisioning as\nwell as inspection if Neutron is disabled.\n\nDocumentation for standalone ironic will be updated separately.\n\nThis patch was developed and tested using Bikolla [1].\n\n[1] https://github.com/markgoddard/bikolla\n\nChange-Id: Ic47f5ad81b8126a51e52a445097f7950dba233cd\nImplements: blueprint standalone-ironic\n""}, {'number': 3, 'created': '2019-02-22 17:22:56.000000000', 'files': ['ansible/roles/ironic/templates/inspector.ipxe.j2', 'ansible/roles/ironic/templates/ironic-inspector.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/group_vars/all.yml', 'releasenotes/notes/ironic-standalone-66dbb02a190c8b5d.yaml', 'ansible/roles/ironic/defaults/main.yml', 'etc/kolla/globals.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/54965c878ba227fbc19d92f4d2676a8b65db51ff', 'message': ""Improve standalone ironic support\n\nAdds a new flag, 'enable_openstack_core', which defaults to 'yes'.\nSetting this flag to 'no' will disable the core OpenStack services,\nincluding Glance, Heat, Horizon, Keystone, Neutron, and Nova.\n\nImproves the default configuration of OpenStack Ironic when used in\nstandalone mode. In particular, configures a noauth mode when Keystone\nis disabled, and allows the iPXE server to be used for provisioning as\nwell as inspection if Neutron is disabled.\n\nDocumentation for standalone ironic will be updated separately.\n\nThis patch was developed and tested using Bikolla [1].\n\n[1] https://github.com/markgoddard/bikolla\n\nChange-Id: Ic47f5ad81b8126a51e52a445097f7950dba233cd\nImplements: blueprint standalone-ironic\n""}]",2,633503,54965c878ba227fbc19d92f4d2676a8b65db51ff,13,6,3,14826,,,0,"Improve standalone ironic support

Adds a new flag, 'enable_openstack_core', which defaults to 'yes'.
Setting this flag to 'no' will disable the core OpenStack services,
including Glance, Heat, Horizon, Keystone, Neutron, and Nova.

Improves the default configuration of OpenStack Ironic when used in
standalone mode. In particular, configures a noauth mode when Keystone
is disabled, and allows the iPXE server to be used for provisioning as
well as inspection if Neutron is disabled.

Documentation for standalone ironic will be updated separately.

This patch was developed and tested using Bikolla [1].

[1] https://github.com/markgoddard/bikolla

Change-Id: Ic47f5ad81b8126a51e52a445097f7950dba233cd
Implements: blueprint standalone-ironic
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/03/633503/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ironic/templates/inspector.ipxe.j2', 'ansible/roles/ironic/templates/ironic-inspector.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/group_vars/all.yml']",4,cde2b82bc6fd03e0fdd396637d75a89972957e4e,bp/standalone-ironic,"# Enable core OpenStack services. This includes: # glance, keystone, neutron, nova, heat, and horizon. enable_openstack_core: ""yes"" enable_glance: ""{{ enable_openstack_core | bool }}""enable_keystone: ""{{ enable_openstack_core | bool }}""enable_neutron: ""{{ enable_openstack_core | bool }}"" enable_nova: ""{{ enable_openstack_core | bool }}""enable_heat: ""{{ enable_openstack_core | bool }}"" enable_horizon: ""{{ enable_openstack_core | bool }}""enable_openvswitch: ""{{ enable_neutron | bool and neutron_plugin_agent != 'linuxbridge' }}""","enable_glance: ""yes""enable_keystone: ""yes""enable_neutron: ""yes"" enable_nova: ""yes""enable_heat: ""yes"" enable_horizon: ""yes""enable_openvswitch: ""{{ neutron_plugin_agent != 'linuxbridge' }}""",44,10
openstack%2Fcinder~master~I6f3d43f819eb0d9aad8a1925ed0b806df198c3fc,openstack/cinder,master,I6f3d43f819eb0d9aad8a1925ed0b806df198c3fc,Remove 'mount.quobyte' and 'umount.quobyte',NEW,2019-01-21 19:35:40.000000000,2019-03-06 09:03:04.000000000,,"[{'_account_id': 24}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-01-21 19:35:40.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters', 'cinder/privsep/quobyte.py', 'cinder/volume/drivers/quobyte.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2d060d092ce3addf6cc375a1c98b5d49a16fa95', 'message': ""Remove 'mount.quobyte' and 'umount.quobyte'\n\nRemove 'mount.quobyte' and 'umount.quobyte'\nfrom rootwrap filters and use oslo.privsep.\n\nChange-Id: I6f3d43f819eb0d9aad8a1925ed0b806df198c3fc\nSigned-off-by: Charles Short <chucks@redhat.com>\n""}]",1,632152,a2d060d092ce3addf6cc375a1c98b5d49a16fa95,63,35,1,24,,,0,"Remove 'mount.quobyte' and 'umount.quobyte'

Remove 'mount.quobyte' and 'umount.quobyte'
from rootwrap filters and use oslo.privsep.

Change-Id: I6f3d43f819eb0d9aad8a1925ed0b806df198c3fc
Signed-off-by: Charles Short <chucks@redhat.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/632152/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/rootwrap.d/volume.filters', 'cinder/privsep/quobyte.py', 'cinder/volume/drivers/quobyte.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py']",4,a2d060d092ce3addf6cc375a1c98b5d49a16fa95,privsep," with mock.patch('cinder.privsep.quobyte.mount') as mock_privsep, \ mock_privsep.assert_called_once_with( self.TEST_QUOBYTE_VOLUME, self.TEST_MNT_POINT, None) with mock.patch('cinder.privsep.quobyte.mount') as mock_privsep, \ mock_privsep.side_effect = [None, putils.ProcessExecutionError( mock_privsep.assert_called_once_with( self.TEST_QUOBYTE_VOLUME, self.TEST_MNT_POINT, None) with mock.patch('cinder.privsep.quobyte.mount') as mock_privsep, \ mock_privsep.side_effect = [ mock_privsep.assert_called_once_with( self.TEST_QUOBYTE_VOLUME, self.TEST_MNT_POINT, None)"," with mock.patch.object(self._driver, '_execute') as mock_execute, \ mount_call = mock.call( 'mount.quobyte', '--disable-xattrs', self.TEST_QUOBYTE_VOLUME, self.TEST_MNT_POINT, run_as_root=False) mock_execute.assert_has_calls( [mount_call], any_order=False) with mock.patch.object(self._driver, '_execute') as mock_execute, \ mock_execute.side_effect = [None, putils.ProcessExecutionError( mount_call = mock.call( 'mount.quobyte', '--disable-xattrs', self.TEST_QUOBYTE_VOLUME, self.TEST_MNT_POINT, run_as_root=False) mock_execute.assert_has_calls([mount_call], any_order=False) with mock.patch.object(self._driver, '_execute') as mock_execute, \ mock_execute.side_effect = [ mount_call = mock.call( 'mount.quobyte', '--disable-xattrs', self.TEST_QUOBYTE_VOLUME, self.TEST_MNT_POINT, run_as_root=False) mock_execute.assert_has_calls([mount_call], any_order=False)",54,33
openstack%2Fmonasca-api~master~Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1,openstack/monasca-api,master,Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1,Remove redundant code,MERGED,2019-01-24 10:23:05.000000000,2019-03-06 08:57:34.000000000,2019-03-06 08:57:34.000000000,"[{'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-01-24 10:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/5d5f52d61c69080014c7d8626974c6df7a8ecb3e', 'message': '[WIP] code cleaning\n\nChange-Id: Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1\n'}, {'number': 2, 'created': '2019-03-04 12:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/cac6399252fca1a26edeaaefc825a29e9b4ce5fd', 'message': 'Remove redundant code\n\nIt is impossible to execute this code because \nold_sub_alarm_defs_by_id value is always empty dict\n\nChange-Id: Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1\n'}, {'number': 3, 'created': '2019-03-04 12:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/723e786bf32625d743fa496f3296b0a269cddc34', 'message': 'Remove redundant code\n\nIt is impossible to execute this code because\nold_sub_alarm_defs_by_id value is always empty dict.\n\nChange-Id: Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1\n'}, {'number': 4, 'created': '2019-03-05 10:19:41.000000000', 'files': ['monasca_api/common/repositories/sqla/alarms_repository.py', 'monasca_api/common/repositories/sqla/alarm_definitions_repository.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/55a172c0725d4d4f517eb3f4e79f54fe42e73b5e', 'message': 'Remove redundant code\n\nIt is impossible to execute this code because\nold_sub_alarm_defs_by_id value is always empty dict.\n\nChange-Id: Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1\n'}]",0,632976,55a172c0725d4d4f517eb3f4e79f54fe42e73b5e,28,3,4,26141,,,0,"Remove redundant code

It is impossible to execute this code because
old_sub_alarm_defs_by_id value is always empty dict.

Change-Id: Id0ae84c4bc96a18185db1e825cd11c7d2e88d2b1
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/76/632976/4 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_api/common/repositories/sqla/alarms_repository.py', 'monasca_api/common/repositories/sqla/alarm_definitions_repository.py']",2,5d5f52d61c69080014c7d8626974c6df7a8ecb3e,632976,," parms = [] for sub_alarm_def_id in old_sub_alarm_defs_by_id.values(): parms.append({'b_id': sub_alarm_def_id.id}) if len(parms) > 0: query = self.update_or_patch_alarm_definition_delete_sad_query conn.execute(query, parms) parms = [] parms_sadd = [] for sub_alarm_def in new_sub_alarm_defs_by_id.values(): adi = sub_alarm_def.alarm_definition_id function = sub_alarm_def.function.encode('utf8') if six.PY2 \ else sub_alarm_def.function metric_name = sub_alarm_def.metric_name.encode('utf8') if six.PY2 \ else sub_alarm_def.metric_name operator = sub_alarm_def.operator.encode('utf8') if six.PY2 \ else sub_alarm_def.operator threshold = sub_alarm_def.threshold period = sub_alarm_def.period periods = sub_alarm_def.periods is_deterministic = sub_alarm_def.is_deterministic parms.append({'b_id': sub_alarm_def.id, 'b_alarm_definition_id': adi, 'b_function': function, 'b_metric_name': metric_name, 'b_operator': operator, 'b_threshold': threshold, 'b_period': period, 'b_periods': periods, 'b_is_deterministic': is_deterministic, 'b_created_at': now, 'b_updated_at': now}) for name, value in sub_alarm_def.dimensions.items(): sadi = sub_alarm_def.id b_dimension_name = name .encode('utf8') if six.PY2 else name b_value = value.encode('utf8') if six.PY2 else value parms_sadd.append({'b_sub_alarm_definition_id': sadi, 'b_dimension_name': b_dimension_name, 'b_value': b_value}) if len(parms) > 0: query = self.update_or_patch_alarm_definition_insert_sad_query conn.execute(query, parms) if len(parms_sadd) > 0: query = self.update_or_patch_alarm_definition_insert_sadd_query conn.execute(query, parms_sadd)",4,55
openstack%2Frpm-packaging~stable%2Frocky~I02439f7632898095f7b5a158606fb680a4941bbe,openstack/rpm-packaging,stable/rocky,I02439f7632898095f7b5a158606fb680a4941bbe,osc-lib: Fix for python3.7,MERGED,2019-03-06 08:04:13.000000000,2019-03-06 08:54:54.000000000,2019-03-06 08:54:54.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-06 08:04:13.000000000', 'files': ['openstack/osc-lib/osc-lib.spec.j2', 'openstack/osc-lib/0001-Fix-formatter-handling-for-python-3.7.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1734a2d7faf11aa5fd4e3e2cde26a8149726047e', 'message': 'osc-lib: Fix for python3.7\n\nAdd patch from https://review.openstack.org/#/c/618137/ to fix\nopenstack client usage with python3.7 .\n\nChange-Id: I02439f7632898095f7b5a158606fb680a4941bbe\n'}]",0,641274,1734a2d7faf11aa5fd4e3e2cde26a8149726047e,11,5,1,7102,,,0,"osc-lib: Fix for python3.7

Add patch from https://review.openstack.org/#/c/618137/ to fix
openstack client usage with python3.7 .

Change-Id: I02439f7632898095f7b5a158606fb680a4941bbe
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/74/641274/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/osc-lib/osc-lib.spec.j2', 'openstack/osc-lib/0001-Fix-formatter-handling-for-python-3.7.patch']",2,1734a2d7faf11aa5fd4e3e2cde26a8149726047e,stable-rocky,"From 72fbf45ed15a1b4c8111cac9f4446289ca187b0d Mon Sep 17 00:00:00 2001 From: Rabi Mishra <ramishra@redhat.com> Date: Thu, 15 Nov 2018 16:57:22 +0530 Subject: [PATCH] Fix formatter handling for python 3.7 Calling issubclass() on a python function fails in Python 3.7. Change-Id: Id2abfaad6ed96532157b9bc7b2124e6f6ad37511 Story: #2003322 Task: 27942 --- osc_lib/utils/__init__.py | 18 ++++++++++++++---- 1 file changed, 14 insertions(+), 4 deletions(-) diff --git a/osc_lib/utils/__init__.py b/osc_lib/utils/__init__.py index d640ca8..f3573c7 100644 --- a/osc_lib/utils/__init__.py +++ b/osc_lib/utils/__init__.py @@ -430,9 +430,10 @@ def get_dict_properties(item, fields, mixed_case_fields=None, formatters=None): data = item[field_name] if field_name in item else '' if field in formatters: formatter = formatters[field] - if issubclass(formatter, cliff_columns.FormattableColumn): + if (isinstance(formatter, type) and issubclass( + formatter, cliff_columns.FormattableColumn)): data = formatter(data) - else: + elif callable(formatter): warnings.warn( 'The usage of formatter functions is now discouraged. ' 'Consider using cliff.columns.FormattableColumn instead. ' @@ -440,6 +441,10 @@ def get_dict_properties(item, fields, mixed_case_fields=None, formatters=None): category=DeprecationWarning) if data is not None: data = formatter(data) + else: + msg = ""Invalid formatter provided."" + raise exceptions.CommandError(msg) + row.append(data) return tuple(row) @@ -492,9 +497,10 @@ def get_item_properties(item, fields, mixed_case_fields=None, formatters=None): data = getattr(item, field_name, '') if field in formatters: formatter = formatters[field] - if issubclass(formatter, cliff_columns.FormattableColumn): + if (isinstance(formatter, type) and issubclass( + formatter, cliff_columns.FormattableColumn)): data = formatter(data) - else: + elif callable(formatter): warnings.warn( 'The usage of formatter functions is now discouraged. ' 'Consider using cliff.columns.FormattableColumn instead. ' @@ -502,6 +508,10 @@ def get_item_properties(item, fields, mixed_case_fields=None, formatters=None): category=DeprecationWarning) if data is not None: data = formatter(data) + else: + msg = ""Invalid formatter provided."" + raise exceptions.CommandError(msg) + row.append(data) return tuple(row) -- 2.21.0 ",,71,0
openstack%2Fdevstack~stable%2Fpike~Ibac950f722ee5bb62f226f636a3e3212049a5ebc,openstack/devstack,stable/pike,Ibac950f722ee5bb62f226f636a3e3212049a5ebc,[DNM/TEST] backporting apache conf from master,ABANDONED,2019-01-10 14:04:53.000000000,2019-03-06 08:50:28.000000000,,"[{'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-10 14:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/84aeb2c64771df65432e7e52573d3c434d9a02b4', 'message': '[DNM/TEST] backporting apache conf from master\n\ntesting apache configuration from master\n\nChange-Id: Ibac950f722ee5bb62f226f636a3e3212049a5ebc\n'}, {'number': 2, 'created': '2019-01-10 15:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a86fdb962e26e4af6eccf0794ace0f7b570b8883', 'message': '[DNM/TEST] backporting apache conf from master\n\ntesting apache configuration from master\n\nChange-Id: Ibac950f722ee5bb62f226f636a3e3212049a5ebc\n'}, {'number': 3, 'created': '2019-01-10 15:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a2b488f9fca3c6789ac2f9853dc8fcb0ba8ddbc7', 'message': '[DNM/TEST] backporting apache conf from master\n\ntesting apache configuration from master\n\nChange-Id: Ibac950f722ee5bb62f226f636a3e3212049a5ebc\n'}, {'number': 4, 'created': '2019-01-11 09:34:15.000000000', 'files': ['lib/apache', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e37755ae987eb68f0aab8b6308a1f1ecb318765d', 'message': '[DNM/TEST] backporting apache conf from master\n\ntesting apache configuration from master\n\nChange-Id: Ibac950f722ee5bb62f226f636a3e3212049a5ebc\n'}]",0,629866,e37755ae987eb68f0aab8b6308a1f1ecb318765d,14,4,4,23851,,,0,"[DNM/TEST] backporting apache conf from master

testing apache configuration from master

Change-Id: Ibac950f722ee5bb62f226f636a3e3212049a5ebc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/66/629866/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/apache'],1,84aeb2c64771df65432e7e52573d3c434d9a02b4,test_apache_conf," # the default is event sudo sed -i '/mod_mpm_event.so/s/^/#/g' /etc/httpd/conf.modules.d/00-mpm.conf iniset ""$file"" uwsgi exit-on-reload false # Set worker-reload-mercy so that worker will not exit till the time # configured after graceful shutdown iniset ""$file"" uwsgi worker-reload-mercy $WORKER_TIMEOUT # Set hook to trigger graceful shutdown on SIGTERM iniset ""$file"" uwsgi hook-master-start ""unix_signal:15 gracefully_kill_them_all"" iniset ""$file"" uwsgi exit-on-reload false # Set hook to trigger graceful shutdown on SIGTERM iniset ""$file"" uwsgi hook-master-start ""unix_signal:15 gracefully_kill_them_all"" # Set worker-reload-mercy so that worker will not exit till the time # configured after graceful shutdown iniset ""$file"" uwsgi worker-reload-mercy $WORKER_TIMEOUT echo ""SetEnv proxy-sendchunked 1"" | sudo tee -a $apache_conf"," # the default is prefork iniset ""$file"" uwsgi exit-on-reload true echo ""SetEnv proxy-sendcl 1"" | sudo tee $apache_conf iniset ""$file"" uwsgi exit-on-reload true",15,4
openstack%2Fironic~stable%2Fqueens~I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b,openstack/ironic,stable/queens,I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b,[DNM/TEST] testing multinode multitenant job,ABANDONED,2018-12-20 11:14:53.000000000,2019-03-06 08:50:19.000000000,,"[{'_account_id': 10118}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 15519}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 28429}]","[{'number': 1, 'created': '2018-12-20 11:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a7f35ed3d62ea2f76cb70ac6668bc437b86c9d00', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 2, 'created': '2018-12-20 11:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/17a1546eb50079b79954f65b0c46eabf3da381f2', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 3, 'created': '2018-12-20 11:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/88eaef82869049bcf9d1406fab756136201ebe1e', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 4, 'created': '2018-12-20 12:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0aa1bbb7be759efb09a95ff662f371dcee671210', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 5, 'created': '2018-12-20 14:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d503d276008bba669224e3d6f8182105db243a8b', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 6, 'created': '2018-12-21 08:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b66a639ada0213de1bef7cab7a1710c2b8fb05ed', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 7, 'created': '2018-12-21 17:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/de066886ee81f4db4954bbd9adbed4a9f5da3f98', 'message': '[TEST/DNM] testing multinode multitenant job\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}, {'number': 8, 'created': '2019-01-10 14:09:40.000000000', 'files': ['playbooks/legacy/grenade-dsvm-ironic-multinode-multitenant/run.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/986867d0ee3637af77d662af1ea74047060c9ae2', 'message': '[DNM/TEST] testing multinode multitenant job\n\nDepends-on: https://review.openstack.org/#/c/629866/\n\nChange-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b\n'}]",0,626549,986867d0ee3637af77d662af1ea74047060c9ae2,59,8,8,23851,,,0,"[DNM/TEST] testing multinode multitenant job

Depends-on: https://review.openstack.org/#/c/629866/

Change-Id: I734650301c8cdf7d5ff4a4d357b8c4e2ddc41e9b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/49/626549/8 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/grenade-dsvm-ironic-multinode-multitenant/run.yaml'],1,a7f35ed3d62ea2f76cb70ac6668bc437b86c9d00,test_fireinthehole," export DEVSTACK_GATE_GRENADE=pullup export DEVSTACK_GATE_OS_TEST_TIMEOUT=2400 export DEVSTACK_GATE_TEMPEST_BAREMETAL_BUILD_TIMEOUT=1200 export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_BUILD_DEPLOY_RAMDISK=False"" export DEVSTACK_GATE_TLSPROXY=0 export BUILD_TIMEOUT # networking-generic-switch requires sudo to execute ovs-vsctl commands export DEVSTACK_GATE_REMOVE_STACK_SUDO=0 export PROJECTS=""openstack/networking-generic-switch $PROJECTS"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin networking-generic-switch git://git.openstack.org/openstack/networking-generic-switch"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_USE_LINK_LOCAL=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""OVS_PHYSICAL_BRIDGE=brbm"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""PHYSICAL_NETWORK=mynetwork"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_PROVISION_NETWORK_NAME=ironic-provision"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_PROVISION_SUBNET_PREFIX=10.0.5.0/24"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_PROVISION_SUBNET_GATEWAY=10.0.5.1"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""Q_PLUGIN=ml2"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""Q_USE_PROVIDERNET_FOR_PUBLIC=False"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""ENABLE_TENANT_VLANS=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""Q_ML2_TENANT_NETWORK_TYPE=vlan"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""TENANT_VLAN_RANGE=100:150"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_ENABLED_NETWORK_INTERFACES=flat,neutron"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_NETWORK_INTERFACE=neutron"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_AUTOMATED_CLEAN_ENABLED=False"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_SPECS_RAM=384"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_RAMDISK_TYPE=tinyipa"" export DEVSTACK_GATE_IRONIC_DRIVER=ipmi export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_DEFAULT_DEPLOY_INTERFACE=direct"" # the direct deploy interface requires Swift temporary URLs export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_TEMPEST_WHOLE_DISK_IMAGE=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_EPHEMERAL_DISK=0"" export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=0 export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_INSPECTOR_BUILD_RAMDISK=False"" "," - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | export DEVSTACK_GATE_GRENADE=pullup export DEVSTACK_GATE_OS_TEST_TIMEOUT=2400 export DEVSTACK_GATE_TEMPEST_BAREMETAL_BUILD_TIMEOUT=1200 export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_BUILD_DEPLOY_RAMDISK=False"" export DEVSTACK_GATE_TLSPROXY=0 export BUILD_TIMEOUT EOF chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | cat << 'EOF' >> ironic-extra-vars EOF chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | cat << 'EOF' >> ironic-extra-vars EOF chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | cat << 'EOF' >> ironic-extra-vars # networking-generic-switch requires sudo to execute ovs-vsctl commands export DEVSTACK_GATE_REMOVE_STACK_SUDO=0 export PROJECTS=""openstack/networking-generic-switch $PROJECTS"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin networking-generic-switch git://git.openstack.org/openstack/networking-generic-switch"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_USE_LINK_LOCAL=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""OVS_PHYSICAL_BRIDGE=brbm"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""PHYSICAL_NETWORK=mynetwork"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_PROVISION_NETWORK_NAME=ironic-provision"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_PROVISION_SUBNET_PREFIX=10.0.5.0/24"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_PROVISION_SUBNET_GATEWAY=10.0.5.1"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""Q_PLUGIN=ml2"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""Q_USE_PROVIDERNET_FOR_PUBLIC=False"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""ENABLE_TENANT_VLANS=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""Q_ML2_TENANT_NETWORK_TYPE=vlan"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""TENANT_VLAN_RANGE=100:150"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_ENABLED_NETWORK_INTERFACES=flat,neutron"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_NETWORK_INTERFACE=neutron"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_AUTOMATED_CLEAN_ENABLED=False"" EOF chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | cat << 'EOF' >> ironic-extra-vars export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_DEPLOY_DRIVER_ISCSI_WITH_IPA=True"" # Standardize VM size for each supported ramdisk case ""tinyipa"" in 'tinyipa') export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_SPECS_RAM=384"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_RAMDISK_TYPE=tinyipa"" ;; 'tinyipa256') export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_SPECS_RAM=256"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_RAMDISK_TYPE=tinyipa"" ;; 'coreos') export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_SPECS_RAM=1280"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_RAMDISK_TYPE=coreos"" ;; # if using a ramdisk without a known good value, use the devstack # default by not exporting any value for IRONIC_VM_SPECS_RAM esac # NOTE(mgoddard): We cannot test node traits when upgrading from # pike, as node traits support was added in queens. export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_DEFAULT_TRAITS=\""\"""" export DEVSTACK_GATE_IRONIC_DRIVER=agent_ipmitool # agent_* drivers require Swift temporary URLs if [ ""wholedisk"" == ""wholedisk"" ] ; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_TEMPEST_WHOLE_DISK_IMAGE=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_EPHEMERAL_DISK=0"" else export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_TEMPEST_WHOLE_DISK_IMAGE=False"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_VM_EPHEMERAL_DISK=1"" fi if [ -n """" ] ; then export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=1 export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_INSPECTOR_BUILD_RAMDISK=True"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""USE_SUBNETPOOL=False"" else export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=0 export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_INSPECTOR_BUILD_RAMDISK=False"" fi if [ ""bios"" == ""uefi"" ] ; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_BOOT_MODE=uefi"" fi export DEVSTACK_PROJECT_FROM_GIT=""""",35,116
openstack%2Fmanila~stable%2Frocky~I398d1ba01a3fd7f1c86ad4065a7984d276f33383,openstack/manila,stable/rocky,I398d1ba01a3fd7f1c86ad4065a7984d276f33383,Simplify running pylint,ABANDONED,2018-10-16 20:19:30.000000000,2019-03-06 08:44:43.000000000,,"[{'_account_id': 24}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24236}]","[{'number': 1, 'created': '2018-10-16 20:19:30.000000000', 'files': ['tools/lintstack.py', '.pylintrc', 'tools/coding-checks.sh', 'tools/lintstack.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/2a8c19ad6caddcc97c12e060a542605b95fc9903', 'message': 'Simplify running pylint\n\nThis commit does several things:\n\n- Setup and run pylint directly rather than running through a script.\n  This allows the user to see what is happening while the user is running\n  through pylint.\n- Allow the user to either run pylint on a particular changeset,\n  or the entire manila tree.\n- Allow the user to run on a particular changeset. Using like HEAD~1,\n  etc.\n- I disabled the tests that were reported by pylint.\n  The thought here would be go through the failures\n  and correct them.\n- Update pylint to 2.1.1.\n\nChange-Id: I398d1ba01a3fd7f1c86ad4065a7984d276f33383\nSigned-off-by: Chuck Short <chucks@redhat.com>\n(cherry picked from commit 4d0abb4a149eea597e51f79c8e76d9d2284d65ee)\n'}]",0,611159,2a8c19ad6caddcc97c12e060a542605b95fc9903,8,6,1,9003,,,0,"Simplify running pylint

This commit does several things:

- Setup and run pylint directly rather than running through a script.
  This allows the user to see what is happening while the user is running
  through pylint.
- Allow the user to either run pylint on a particular changeset,
  or the entire manila tree.
- Allow the user to run on a particular changeset. Using like HEAD~1,
  etc.
- I disabled the tests that were reported by pylint.
  The thought here would be go through the failures
  and correct them.
- Update pylint to 2.1.1.

Change-Id: I398d1ba01a3fd7f1c86ad4065a7984d276f33383
Signed-off-by: Chuck Short <chucks@redhat.com>
(cherry picked from commit 4d0abb4a149eea597e51f79c8e76d9d2284d65ee)
",git fetch https://review.opendev.org/openstack/manila refs/changes/59/611159/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/lintstack.py', '.pylintrc', 'tools/coding-checks.sh', 'tools/lintstack.sh', 'tox.ini']",5,2a8c19ad6caddcc97c12e060a542605b95fc9903,, pylint==2.1.1commands = bash ./tools/coding-checks.sh --pylint {posargs}, pylint==1.9.0commands = bash tools/lintstack.sh,247,293
openstack%2Fmasakari~master~I787b26b29fcd9556bc6b24b75ffe8e70e9f44610,openstack/masakari,master,I787b26b29fcd9556bc6b24b75ffe8e70e9f44610,Add functional CI job and tests for segments,MERGED,2019-01-29 07:17:12.000000000,2019-03-06 08:41:30.000000000,2019-03-06 08:41:30.000000000,"[{'_account_id': 1011}, {'_account_id': 8988}, {'_account_id': 22348}, {'_account_id': 25267}, {'_account_id': 26541}, {'_account_id': 29238}]","[{'number': 1, 'created': '2019-01-29 07:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/36b0aec3b97c3b49c7fc56bda49d958c626dc1b6', 'message': 'Add check CI job for running functional tests\n\nAdded multinode CI job which will run functional tests.\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 2, 'created': '2019-01-29 07:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/45ed323786e50a3c895abd2ffb19b929b9a062ca', 'message': 'Add check CI job for running functional tests\n\nAdded multinode CI job which will run functional tests.\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 3, 'created': '2019-01-29 08:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/f02851ed5a8a8211579126d0db8644944f1c86e6', 'message': 'Add check CI job for running functional tests\n\nAdded multinode CI job which will run functional tests.\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 4, 'created': '2019-02-01 09:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/78ab316660876cd189d56c53d216b2abc6e19f2a', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 5, 'created': '2019-02-07 08:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/93d063b34ba0ac3754ccc104b85892e3ebcccec8', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 6, 'created': '2019-02-22 05:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/72f1e9e391a67062c232b3403fb99213c88e6b72', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 7, 'created': '2019-02-28 06:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/6ece9a2001c2839f5b99e6fdc08edcff8af36f42', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 8, 'created': '2019-03-04 13:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/a800e6647b61ca0cba26aa6bc9610544d92c0e44', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 9, 'created': '2019-03-05 05:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/9ad8b14c264da1cd2587980be0ab85ad3feb873f', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}, {'number': 10, 'created': '2019-03-05 06:55:26.000000000', 'files': ['playbooks/devstack/pre.yaml', 'roles/devstack-config/tasks/main.yml', '.zuul.yaml', 'playbooks/devstack/run.yaml', 'masakari/tests/functional/base.py', 'masakari/tests/functional/__init__.py', 'masakari/tests/functional/test_segments.py', 'tox.ini', 'playbooks/devstack/post.yaml'], 'web_link': 'https://opendev.org/openstack/masakari/commit/0fa59ab7ed28a717d508963e92bf40587c354c7e', 'message': 'Add functional CI job and tests for segments\n\nAdded multi-node CI job to run functional tests.\nThis patch adds functional tests to check the behaviour\nof Segment APIs.\n\nCo-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>\n\nChange-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610\n'}]",9,633663,0fa59ab7ed28a717d508963e92bf40587c354c7e,44,6,10,1011,,,0,"Add functional CI job and tests for segments

Added multi-node CI job to run functional tests.
This patch adds functional tests to check the behaviour
of Segment APIs.

Co-Authored-By: jayashri bidwe <jayashri.bidwe@nttdata.com>

Change-Id: I787b26b29fcd9556bc6b24b75ffe8e70e9f44610
",git fetch https://review.opendev.org/openstack/masakari refs/changes/63/633663/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/devstack/pre.yaml', '.zuul.yaml', 'playbooks/devstack/run.yaml', 'masakari/tests/functional/__init__.py', 'tox.ini', 'playbooks/devstack/post.yaml']",6,36b0aec3b97c3b49c7fc56bda49d958c626dc1b6,add_functional_tests_and_ci_job,- hosts: all roles: - fetch-subunit-output - devstack-config ,,97,0
openstack%2Fnova~master~I4b7be98b5832ca8c580339fcfb7b9203264b5ff8,openstack/nova,master,I4b7be98b5832ca8c580339fcfb7b9203264b5ff8,Improve libvirt image and snapshot handling,MERGED,2018-11-08 21:08:24.000000000,2019-03-06 08:40:48.000000000,2019-03-06 01:44:18.000000000,"[{'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 6962}, {'_account_id': 7634}, {'_account_id': 7730}, {'_account_id': 8768}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12860}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28433}]","[{'number': 1, 'created': '2018-11-08 21:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d341b709078ec35b08643af89d9dad98f159db6f', 'message': ""Add cache=none option for qemu-img convert\n\nThere is limited page cache shared between the host and guest local\ndisks and we don't want image conversion operations to fill\nit. Using cache=none option can also ensure that the data is on\npersistent storage when the command exits.\n\nUse cache=none option only if the filesystem where the instances are\nmounted support O_DIRECT.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\n""}, {'number': 2, 'created': '2018-11-09 15:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51d433812010c886b49762296d47cbba9a1be5fd', 'message': ""Add cache=none option for qemu-img convert\n\nThere is limited page cache shared between the host and guest local\ndisks and we don't want image conversion operations to fill\nit. Using cache=none option can also ensure that the data is on\npersistent storage when the command exits.\n\nUse cache=none option only if the filesystem where the instances are\nmounted support O_DIRECT.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\n""}, {'number': 3, 'created': '2018-11-09 21:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b1322622a7df3ca8931c8e8127d1004e4aacf11', 'message': ""Use virt.images.convert_image for qemu-img convert\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly to deal with cache options.\n\nThere is limited page cache shared between the host and guest local\ndisks and we don't want image conversion operations to fill\nit. Using cache=none option can also ensure that the data is on\npersistent storage when the command exits. Note that cache=none\noption is used only if the filesystem where the instances are\nmounted support O_DIRECT. All these logic is already available in\nvirt.images.convert_image().\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 4, 'created': '2018-11-09 22:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83d25f132670430a7b927104eadf49cba9091a96', 'message': ""Use virt.images.convert_image for qemu-img convert\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly to deal with cache options.\n\nThere is limited page cache shared between the host and guest local\ndisks and we don't want image conversion operations to fill\nit. Using cache=none option can also ensure that the data is on\npersistent storage when the command exits. Note that cache=none\noption is used only if the filesystem where the instances are\nmounted support O_DIRECT. All these logic is already available in\nvirt.images.convert_image().\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 5, 'created': '2018-11-09 22:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08d3f0ca493c31ac7789afb1083456bfc93d95d9', 'message': ""Use virt.images.convert_image for qemu-img convert\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nConditionally enable compression of snapshots when converting to qcow2.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 6, 'created': '2018-11-15 14:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a5da5a3b471bb5592d0a97e93bb69152e6447c0', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nConditionally enable compression of snapshots when converting to qcow2.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 7, 'created': '2018-11-27 17:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57c4523e4e90c7d9e976b34c2143bf6f8d63e1cb', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 8, 'created': '2018-12-04 21:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/913379a42d0438fddafa6bc920bf57f5fb9bd854', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 9, 'created': '2018-12-05 02:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2330386e1f77dbcf161878d8a308a008c884c769', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 10, 'created': '2018-12-11 17:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a8997dd4e35e999c024772eb7346cfb441f259e', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 11, 'created': '2018-12-17 14:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/432f2e15f7396f17886bacc1b484c92021c458b7', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 12, 'created': '2019-01-08 20:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b2021575a618d603685b97b694934c857e6f9c6', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 13, 'created': '2019-01-10 16:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94872b1e8da483b0c06d1ea31b81ed7c69cb9415', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 14, 'created': '2019-01-18 01:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/290bd718db6684c7c21cb464d47522866cc62318', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 15, 'created': '2019-01-29 18:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ef48572192e3a211f54ab9cc9cb8e6973a9742c', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 16, 'created': '2019-01-31 16:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85f679a4308e81ce32f765e7ed7bee49257ad8dc', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 17, 'created': '2019-02-05 17:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/078f197978a861f91c53278f8969d9e633a9b0c9', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 18, 'created': '2019-02-06 15:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bf97bea24dc79a3679ee0310400bb4655445d98', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 19, 'created': '2019-02-07 23:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99a3823f98c593fd7f0a9e3fe3aab4126f9bb383', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that compression option can be\ncontrollered by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\n""}, {'number': 20, 'created': '2019-02-25 23:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f32019b8d010895e39cb03aff2912432a6e0ca6e', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that the compression option can be\ncontrolled by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n""}, {'number': 21, 'created': '2019-02-28 19:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2abf36a6989a597dcdbbe1282e81e51da86f1356', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that the compression option can be\ncontrolled by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n""}, {'number': 22, 'created': '2019-03-01 11:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5318026de6351559b8d3581864062dff364d2075', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nRefactor images.convert_image so that the compression option can be\ncontrolled by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n""}, {'number': 23, 'created': '2019-03-05 18:22:04.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/privsep/qemu.py', 'nova/tests/unit/virt/libvirt/test_imagebackend.py', 'nova/tests/unit/virt/libvirt/test_utils.py', 'nova/virt/libvirt/utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/56541244fd4931c88cc17771c18e2e72ae9356eb', 'message': ""Improve libvirt image and snapshot handling\n\nUse virt.images.convert_image instead of invoking 'qemu-img convert'\ndirectly so that cache option can be set properly. i.e. cache=none\nwhen O_DIRECT is supported by the filesystem.\n\nThe big advantage of this is that it will bypass the host page cache\nso that converting large images won't evict guest data from the cache.\n\nRefactor images.convert_image so that the compression option can be\ncontrolled by the caller.\n\nChange-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8\nSigned-off-by: Jack Ding <jack.ding@windriver.com>\nSigned-off-by: Chris Friesen <chris.friesen@windriver.com>\n""}]",38,616692,56541244fd4931c88cc17771c18e2e72ae9356eb,313,26,23,28433,,,0,"Improve libvirt image and snapshot handling

Use virt.images.convert_image instead of invoking 'qemu-img convert'
directly so that cache option can be set properly. i.e. cache=none
when O_DIRECT is supported by the filesystem.

The big advantage of this is that it will bypass the host page cache
so that converting large images won't evict guest data from the cache.

Refactor images.convert_image so that the compression option can be
controlled by the caller.

Change-Id: I4b7be98b5832ca8c580339fcfb7b9203264b5ff8
Signed-off-by: Jack Ding <jack.ding@windriver.com>
Signed-off-by: Chris Friesen <chris.friesen@windriver.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/616692/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_utils.py', 'nova/virt/libvirt/utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,d341b709078ec35b08643af89d9dad98f159db6f,improve_image_snapshot_handling," mock.call('qemu-img', 'convert', '-f', 'raw', '-t', 'none',"," mock.call('qemu-img', 'convert', '-f', 'raw',",19,4
openstack%2Fpython-cyborgclient~master~I010b3ebb40b27edda846cbc9efe88665844c0489,openstack/python-cyborgclient,master,I010b3ebb40b27edda846cbc9efe88665844c0489,Update hacking version,ABANDONED,2018-12-28 15:04:14.000000000,2019-03-06 08:26:42.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-12-28 15:04:14.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/1c3ddb1cf69dd61c5e7d2469632c30f89d51eec1', 'message': 'Update hacking version\n\nChange-Id: I010b3ebb40b27edda846cbc9efe88665844c0489\n'}]",0,627693,1c3ddb1cf69dd61c5e7d2469632c30f89d51eec1,4,2,1,21691,,,0,"Update hacking version

Change-Id: I010b3ebb40b27edda846cbc9efe88665844c0489
",git fetch https://review.opendev.org/openstack/python-cyborgclient refs/changes/93/627693/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1c3ddb1cf69dd61c5e7d2469632c30f89d51eec1,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking>=0.12.0,<0.13 # Apache-2.0",1,1
openstack%2Fhorizon~master~I4319cf1a54310171baf1dbaf2e10acae8123dac6,openstack/horizon,master,I4319cf1a54310171baf1dbaf2e10acae8123dac6,Add python-memcached library to test-requirements.txt,MERGED,2019-02-28 08:13:28.000000000,2019-03-06 08:24:43.000000000,2019-03-06 08:24:42.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-02-28 08:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e9e0151ea456b87f745e3178b9975e2fdb22782', 'message': 'Add python-memcached library to requirements.txt\n\nHorizon uses python-memcached directly so we need to add it to\nrequirement.txt as well as lower-constraints.txt.\n\nChange-Id: I4319cf1a54310171baf1dbaf2e10acae8123dac6\n'}, {'number': 2, 'created': '2019-03-01 07:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8278211ed386c3d24aa69aea604d37ce46d19a17', 'message': 'Add python-memcached library to test-requirements.txt\n\nHorizon uses python-memcached while running ""tox -e runserver""\nso we need to add it to test-requirement.txt.\n\nChange-Id: I4319cf1a54310171baf1dbaf2e10acae8123dac6\n'}, {'number': 3, 'created': '2019-03-01 08:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d6d7b0f1eae26be662855ff696a36bcfc93cbf34', 'message': 'Add python-memcached library to test-requirements.txt\n\nHorizon uses python-memcached while running ""tox -e runserver""\nso we need to add it to test-requirement.txt as well as\nlower-constraints.txt.\n\nChange-Id: I4319cf1a54310171baf1dbaf2e10acae8123dac6\n'}, {'number': 4, 'created': '2019-03-06 06:02:55.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4e8e907986bccc17b6f92b3f0abd2e326572d86e', 'message': 'Add python-memcached library to test-requirements.txt\n\nHorizon uses python-memcached while running ""tox -e runserver""\nso we need to add it to test-requirement.txt as well as\nlower-constraints.txt.\n\nChange-Id: I4319cf1a54310171baf1dbaf2e10acae8123dac6\n'}]",5,639944,4e8e907986bccc17b6f92b3f0abd2e326572d86e,20,5,4,29313,,,0,"Add python-memcached library to test-requirements.txt

Horizon uses python-memcached while running ""tox -e runserver""
so we need to add it to test-requirement.txt as well as
lower-constraints.txt.

Change-Id: I4319cf1a54310171baf1dbaf2e10acae8123dac6
",git fetch https://review.opendev.org/openstack/horizon refs/changes/44/639944/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,2e9e0151ea456b87f745e3178b9975e2fdb22782,638110,python-memcached==1.59,,2,0
openstack%2Fosc-lib~master~Id2abfaad6ed96532157b9bc7b2124e6f6ad37511,openstack/osc-lib,master,Id2abfaad6ed96532157b9bc7b2124e6f6ad37511,Fix formatter handling for python 3.7,MERGED,2018-11-15 11:56:49.000000000,2019-03-06 08:08:22.000000000,2018-12-03 15:13:35.000000000,"[{'_account_id': 2}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 28649}]","[{'number': 1, 'created': '2018-11-15 11:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/d2686d0bf3625c50bba1bfcc98fd63cad275ae82', 'message': 'Fix issubclass() in python 3.7\n\nCalling issubclass() on a python function fails in Python 3.7.\n\nChange-Id: Id2abfaad6ed96532157b9bc7b2124e6f6ad37511\nStory: #2003322\nTask: 27942\n'}, {'number': 2, 'created': '2018-11-30 06:52:08.000000000', 'files': ['osc_lib/utils/__init__.py'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/72fbf45ed15a1b4c8111cac9f4446289ca187b0d', 'message': 'Fix formatter handling for python 3.7\n\nCalling issubclass() on a python function fails in Python 3.7.\n\nChange-Id: Id2abfaad6ed96532157b9bc7b2124e6f6ad37511\nStory: #2003322\nTask: 27942\n'}]",2,618137,72fbf45ed15a1b4c8111cac9f4446289ca187b0d,16,6,2,8833,,,0,"Fix formatter handling for python 3.7

Calling issubclass() on a python function fails in Python 3.7.

Change-Id: Id2abfaad6ed96532157b9bc7b2124e6f6ad37511
Story: #2003322
Task: 27942
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/37/618137/1 && git format-patch -1 --stdout FETCH_HEAD,['osc_lib/utils/__init__.py'],1,d2686d0bf3625c50bba1bfcc98fd63cad275ae82,story/2003322," if (isinstance(formatter, type) and issubclass( formatter, cliff_columns.FormattableColumn)): if (isinstance(formatter, type) and issubclass( formatter, cliff_columns.FormattableColumn)):"," if issubclass(formatter, cliff_columns.FormattableColumn): if issubclass(formatter, cliff_columns.FormattableColumn):",4,2
openstack%2Fvitrage-tempest-plugin~master~I9cac993067e13b635733008d4ba866271b33cf29,openstack/vitrage-tempest-plugin,master,I9cac993067e13b635733008d4ba866271b33cf29,small refactoring on graph creation and checks,MERGED,2019-03-05 14:07:39.000000000,2019-03-06 08:04:58.000000000,2019-03-06 08:04:58.000000000,"[{'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 14:07:39.000000000', 'files': ['vitrage_tempest_plugin/tests/base.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/e5a4cc630f6681d4455cbd34a9538687ca44bdd6', 'message': 'small refactoring on graph creation and checks\n\n* copy is redundant remove it\n* use enumarate instead of index\n* use for each instead for on range\n\nChange-Id: I9cac993067e13b635733008d4ba866271b33cf29\n'}]",0,641020,e5a4cc630f6681d4455cbd34a9538687ca44bdd6,7,3,1,19134,,,0,"small refactoring on graph creation and checks

* copy is redundant remove it
* use enumarate instead of index
* use for each instead for on range

Change-Id: I9cac993067e13b635733008d4ba866271b33cf29
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/20/641020/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage_tempest_plugin/tests/base.py'],1,e5a4cc630f6681d4455cbd34a9538687ca44bdd6,eyalb/refactor," children = api_graph['children'] for i, node in enumerate(nodes): graph.add_node(str(i), **node) for edge in edges: graph.add_edge(str(edge['source']), str(edge['target']),"," children = api_graph.copy()['children'] for i in range(len(nodes)): graph.add_node(str(i), **nodes[i]) for i in range(len(edges)): graph.add_edge(str(edges[i]['source']), str(edges[i]['target']),",6,6
openstack%2Fnetworking-sfc~stable%2Fpike~Ib7541abb0bee619b87fbcc7fee5d5095255e1ec7,openstack/networking-sfc,stable/pike,Ib7541abb0bee619b87fbcc7fee5d5095255e1ec7,Fix unit tests and test configuration,ABANDONED,2019-02-26 11:21:00.000000000,2019-03-06 07:57:20.000000000,,"[{'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-26 11:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/b331f670d846a90dd963b5932ad8ffc31920d42b', 'message': 'Fix unit tests and test configuration\n\nFix post gate hook to accommodate for new os-testr\nNew versions now use .stestr instead of previous .testrepository\ndirectory\n\nFix ml2 plugin config import\nCommit Ibc5a9ab268578c243ef13f7e0041bacd6c0c410b moved the ml2 plugin\nconfig file, which breaks unit tests\n\nChange-Id: Ib7541abb0bee619b87fbcc7fee5d5095255e1ec7\nCloses-Bug: #1716746\n(cherry picked from commit f9ea384efc86321e90b1bb93f6e1c09ffa868d62)\n'}, {'number': 2, 'created': '2019-02-26 12:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/828b507a1973c406d56445c44d96ffc6710c0cdf', 'message': 'Fix unit tests and test configuration\n\nFix post gate hook to accommodate for new os-testr\nNew versions now use .stestr instead of previous .testrepository\ndirectory\n\nFix ml2 plugin config import\nCommit Ibc5a9ab268578c243ef13f7e0041bacd6c0c410b moved the ml2 plugin\nconfig file, which breaks unit tests\n\nChange-Id: Ib7541abb0bee619b87fbcc7fee5d5095255e1ec7\nCloses-Bug: #1716746\n(cherry picked from commit f9ea384efc86321e90b1bb93f6e1c09ffa868d62)\n'}, {'number': 3, 'created': '2019-02-26 16:40:46.000000000', 'files': ['.gitignore', 'test-requirements.txt', 'networking_sfc/tests/contrib/post_test_hook.sh', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/47a38bf08d5fbbadcb7f1d0da1e31d54b811d313', 'message': 'Fix unit tests and test configuration\n\nFix post gate hook to accommodate for new os-testr\nNew versions now use .stestr instead of previous .testrepository\ndirectory\n\nChange-Id: Ib7541abb0bee619b87fbcc7fee5d5095255e1ec7\nCloses-Bug: #1716746\n(cherry picked from commit f9ea384efc86321e90b1bb93f6e1c09ffa868d62)\n'}]",0,639312,47a38bf08d5fbbadcb7f1d0da1e31d54b811d313,7,2,3,21883,,,0,"Fix unit tests and test configuration

Fix post gate hook to accommodate for new os-testr
New versions now use .stestr instead of previous .testrepository
directory

Change-Id: Ib7541abb0bee619b87fbcc7fee5d5095255e1ec7
Closes-Bug: #1716746
(cherry picked from commit f9ea384efc86321e90b1bb93f6e1c09ffa868d62)
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/12/639312/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'test-requirements.txt', 'networking_sfc/tests/contrib/post_test_hook.sh', 'networking_sfc/tests/base.py', '.stestr.conf']",5,b331f670d846a90dd963b5932ad8ffc31920d42b,bug/1716746,[DEFAULT] test_path=${OS_TEST_PATH:-./networking_sfc/tests/unit} top_dir=./ ,,10,7
openstack%2Fnetworking-sfc~stable%2Fpike~I526a4f2a58dcc21045c5cab2f82c105861d7ac8f,openstack/networking-sfc,stable/pike,I526a4f2a58dcc21045c5cab2f82c105861d7ac8f,Fix py35 and sphinx-docs gates,ABANDONED,2019-02-21 08:24:54.000000000,2019-03-06 07:57:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-21 08:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/e74eb82b91833f19d1af7d1ba137aef97f65b6b9', 'message': '[DNM] - Testing gates\n\nChange-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 2, 'created': '2019-02-22 09:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/2bfe862d3ff025be1d9df672c3320a4dfcb4090e', 'message': '[DNM] - Testing gates\n\nChange-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 3, 'created': '2019-02-22 16:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/c1ea0bce2cf85857dd31be0e2079cc3b2a4cdaea', 'message': '[DNM] - Testing gates\n\nChange-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 4, 'created': '2019-02-26 08:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/48b6051b338a6296ddaed28712e7dd31fbf82a01', 'message': 'Fix py35 gate\n\nFix an issue where toxenv fails when it encounters a non-empty __pycache__\ndirectory. This adjusts the options passed to find so that it is tolerant of\nthis scenario and allows tox runs to proceed.\n\nChange-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 5, 'created': '2019-02-26 10:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/a4b7b8bcb072c79eda240c97fead0e93ca9b6ab4', 'message': 'Fix py35 and sphinx-docs gates\n\nFix an issue where toxenv fails when it encounters a non-empty __pycache__\ndirectory. This adjusts the options passed to find so that it is tolerant of\nthis scenario and allows tox runs to proceed.\n\nMove to python3 to fix sphinx gate\n\nChange-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 6, 'created': '2019-02-26 11:05:04.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/707836f651013d1db3a988aa2b23360ef16ff164', 'message': 'Fix py35 and sphinx-docs gates\n\nFix an issue where toxenv fails when it encounters a non-empty __pycache__\ndirectory. This adjusts the options passed to find so that it is tolerant of\nthis scenario and allows tox runs to proceed.\n\nChange-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}]",0,638362,707836f651013d1db3a988aa2b23360ef16ff164,12,1,6,21883,,,0,"Fix py35 and sphinx-docs gates

Fix an issue where toxenv fails when it encounters a non-empty __pycache__
directory. This adjusts the options passed to find so that it is tolerant of
this scenario and allows tox runs to proceed.

Change-Id: I526a4f2a58dcc21045c5cab2f82c105861d7ac8f
Signed-off-by: Manuel Buil <mbuil@suse.com>
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/62/638362/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_sfc/version.py'],1,e74eb82b91833f19d1af7d1ba137aef97f65b6b9,,,,1,0
openstack%2Fopenstack-helm~master~Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd,openstack/openstack-helm,master,Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd,Ceilometer chart: Add polling process with ipmi functionality,MERGED,2019-03-04 17:39:47.000000000,2019-03-06 07:55:04.000000000,2019-03-06 07:55:04.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-03-04 17:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/826fab772c17040b53394f2ea1d9433af6159864', 'message': 'Ceilometer chart: Add polling process with ipmi functionality\n\nThis commit adds the ability to deploy a polling process with ipmi\nfunctionality to pull ipmi samples.\nStory: 2005019\nTask: 29819\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n\nChange-Id: Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd\n'}, {'number': 2, 'created': '2019-03-05 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/900633e9603df747b44965a6d926b9891268c165', 'message': 'Ceilometer chart: Add polling process with ipmi functionality\n\nThis commit adds the ability to deploy a polling process with ipmi\nfunctionality to pull ipmi samples.\nStory: 2005019\nTask: 29819\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n\nChange-Id: Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd\n'}, {'number': 3, 'created': '2019-03-06 04:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/441bd89ee846a9c816fc9e9570d88f94443ea304', 'message': 'Ceilometer chart: Add polling process with ipmi functionality\n\nThis commit adds the ability to deploy a polling process with ipmi\nfunctionality to pull ipmi samples.\nStory: 2005019\nTask: 29819\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n\nChange-Id: Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd\n'}, {'number': 4, 'created': '2019-03-06 06:34:48.000000000', 'files': ['ceilometer/values.yaml', 'ceilometer/templates/bin/_ceilometer-ipmi.sh.tpl', 'ceilometer/templates/daemonset-ipmi.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ac9c7e1d24e0ecd231ed5749a4dc559b394a9b70', 'message': 'Ceilometer chart: Add polling process with ipmi functionality\n\nThis commit adds the ability to deploy a polling process with ipmi\nfunctionality to pull ipmi samples.\nStory: 2005019\nTask: 29819\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n\nChange-Id: Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd\n'}]",0,640829,ac9c7e1d24e0ecd231ed5749a4dc559b394a9b70,19,4,4,28435,,,0,"Ceilometer chart: Add polling process with ipmi functionality

This commit adds the ability to deploy a polling process with ipmi
functionality to pull ipmi samples.
Story: 2005019
Task: 29819
Signed-off-by: Angie Wang <angie.wang@windriver.com>

Change-Id: Ib61d65f9ab815faa0d750422ffb0e36406dd3ccd
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/29/640829/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/values.yaml', 'ceilometer/templates/bin/_ceilometer-ipmi.sh.tpl', 'ceilometer/templates/daemonset-ipmi.yaml']",3,826fab772c17040b53394f2ea1d9433af6159864,bp/support-docker-registry-with-authentication-turned-on,"{{/* Copyright 2019 The Openstack-Helm Authors. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} {{- if .Values.manifests.daemonset_ipmi }} {{- $envAll := . }} {{- $mounts_ceilometer_ipmi := .Values.pod.mounts.ceilometer_ipmi.ceilometer_ipmi }} {{- $mounts_ceilometer_ipmi_init := .Values.pod.mounts.ceilometer_ipmi.init_container }} {{- $serviceAccountName := ""ceilometer-ipmi"" }} {{ tuple $envAll ""ipmi"" $serviceAccountName | include ""helm-toolkit.snippets.kubernetes_pod_rbac_serviceaccount"" }} --- apiVersion: apps/v1 kind: DaemonSet metadata: name: ceilometer-ipmi annotations: {{ tuple $envAll | include ""helm-toolkit.snippets.release_uuid"" }} labels: {{ tuple $envAll ""ceilometer"" ""ipmi"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 4 }} spec: selector: matchLabels: {{ tuple $envAll ""ceilometer"" ""ipmi"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 6 }} {{ tuple $envAll ""ipmi"" | include ""helm-toolkit.snippets.kubernetes_upgrades_daemonset"" | indent 2 }} template: metadata: labels: {{ tuple $envAll ""ceilometer"" ""ipmi"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 8 }} annotations: {{ tuple $envAll | include ""helm-toolkit.snippets.release_uuid"" | indent 8 }} configmap-bin-hash: {{ tuple ""configmap-bin.yaml"" . | include ""helm-toolkit.utils.hash"" }} configmap-etc-hash: {{ tuple ""configmap-etc.yaml"" . | include ""helm-toolkit.utils.hash"" }} spec: serviceAccountName: {{ $serviceAccountName }} affinity: {{ tuple $envAll ""ceilometer"" ""ipmi"" | include ""helm-toolkit.snippets.kubernetes_pod_anti_affinity"" | indent 8 }} hostNetwork: true hostPID: true dnsPolicy: ClusterFirstWithHostNet nodeSelector: {{ .Values.labels.ipmi.node_selector_key }}: {{ .Values.labels.ipmi.node_selector_value }} initContainers: {{ tuple $envAll ""ipmi"" $mounts_ceilometer_ipmi_init | include ""helm-toolkit.snippets.kubernetes_entrypoint_init_container"" | indent 8 }} containers: - name: ceilometer-ipmi {{ tuple $envAll ""ceilometer_ipmi"" | include ""helm-toolkit.snippets.image"" | indent 10 }} {{ tuple $envAll $envAll.Values.pod.resources.ipmi | include ""helm-toolkit.snippets.kubernetes_resources"" | indent 10 }} securityContext: privileged: true command: - /tmp/ceilometer-ipmi.sh volumeMounts: - name: pod-etc-ceilometer mountPath: /etc/ceilometer - name: ceilometer-etc mountPath: /etc/ceilometer/ceilometer.conf subPath: ceilometer.conf readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/api_paste.ini subPath: api_paste.ini readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/policy.json subPath: policy.json readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/event_definitions.yaml subPath: event_definitions.yaml readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/event_pipeline.yaml subPath: event_pipeline.yaml readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/pipeline.yaml subPath: pipeline.yaml readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/gnocchi_resources.yaml subPath: gnocchi_resources.yaml readOnly: true - name: ceilometer-etc mountPath: /etc/ceilometer/polling.yaml subPath: polling.yaml readOnly: true - name: ceilometer-bin mountPath: /tmp/ceilometer-ipmi.sh subPath: ceilometer-ipmi.sh readOnly: true - name: ipmi-device mountPath: {{ .Values.ipmi_device }} readOnly: true {{ if $mounts_ceilometer_ipmi.volumeMounts }}{{ toYaml $mounts_ceilometer_ipmi.volumeMounts | indent 12 }}{{ end }} volumes: - name: pod-etc-ceilometer emptyDir: {} - name: ceilometer-etc secret: secretName: ceilometer-etc defaultMode: 0444 - name: ceilometer-bin configMap: name: ceilometer-bin defaultMode: 0555 - name: ipmi-device hostPath: path: {{ .Values.ipmi_device }} {{ if $mounts_ceilometer_ipmi.volumes }}{{ toYaml $mounts_ceilometer_ipmi.volumes | indent 8 }}{{ end }} {{- end }} ",,178,0
openstack%2Fnova~master~Ic27195e46502067c87ee9c71a811a3ca3f610b73,openstack/nova,master,Ic27195e46502067c87ee9c71a811a3ca3f610b73,Check hosts have no instances for AZ rename,MERGED,2017-10-03 15:24:53.000000000,2019-03-06 07:49:41.000000000,2019-03-06 04:25:49.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 21813}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26286}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-10-03 15:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ec3b1e0adb7dfa715102711463eaa59a7433090', 'message': ""AZ operations: check host has no instances\n\nThis adds additional check to aggregate API calls: Update Aggregate,\nAdd Host, Remove Host. That check makes sure there are no instances\nin the targeted host for adding and removing host to aggregate. Also\nwith that change, it's not possible to rename AZ it the corresponding\naggregate has instances in any hosts.\n\nThis was done because after making operations described above the\nobsolete value for AZ is left in instance table.  Alternative solution\nwas proposed in Icf58b0fd2e1d77abb817ea46f188f386863578d0.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n""}, {'number': 2, 'created': '2017-10-09 06:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c982c715cbaefc38faecd517d1d788f72c8be066', 'message': ""AZ operations: check host has no instances\n\nThis adds additional check to aggregate API calls: Update Aggregate,\nAdd Host, Remove Host. That check makes sure there are no instances\nin the targeted host for adding and removing host to aggregate. Also\nwith that change, it's not possible to rename AZ it the corresponding\naggregate has instances in any hosts.\n\nThis was done because after making operations described above the\nobsolete value for AZ is left in instance table.  Alternative solution\nwas proposed in Icf58b0fd2e1d77abb817ea46f188f386863578d0.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n""}, {'number': 3, 'created': '2017-10-11 10:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1756db5823d1551771e00e090c5fee13d69018fb', 'message': ""AZ operations: check host has no instances\n\nThis adds additional check to aggregate API calls: Update Aggregate,\nAdd Host, Remove Host. That check makes sure there are no instances\nin the targeted host for adding and removing host to aggregate. Also\nwith that change, it's not possible to rename AZ it the corresponding\naggregate has instances in any hosts.\n\nThis was done because after making operations described above the\nobsolete value for AZ is left in instance table.  Alternative solution\nwas proposed in Icf58b0fd2e1d77abb817ea46f188f386863578d0.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n""}, {'number': 4, 'created': '2019-02-05 16:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/332be69521fe3ecf49782aa68237bb227bb238ea', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate API call has the ability to update availability zone metadata\nfor an aggregate. If the aggregate is not empty (has hosts) it updates\naggregate metadata only that leads to discrepancy for objects\nsaving availability zone as a string but not reference.\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 5, 'created': '2019-02-06 10:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/168caf220281327ab3b56a13de372ec75f96c03f', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 6, 'created': '2019-02-06 19:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3454959b22edc16c6a932bfae872fa2522df07a', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 7, 'created': '2019-02-08 11:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/558d93d8cd9c574d093b5fb45ac746df796df03e', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 8, 'created': '2019-02-15 13:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9efc55d86eeef789b794747fe40f8e603161f0dd', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 9, 'created': '2019-02-15 21:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf9e764e8794c645088423c804028668889c8855', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 10, 'created': '2019-02-15 21:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cf0a9738a19d2b74c7d78459d20866b4460895d', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 11, 'created': '2019-02-20 13:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb07f084f1f3356991bbbb1c59150f4e96139fbf', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nDepends-On: https://review.openstack.org/638028/\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 12, 'created': '2019-02-22 11:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db0a7fad87ac828b48dabead0ee4a65ab296ed16', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nDepends-On: https://review.openstack.org/638028/\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 13, 'created': '2019-02-25 18:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/960c35b1511b6c69e3e8d6085db194726d9ecb4f', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nDepends-On: https://review.openstack.org/638028/\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}, {'number': 14, 'created': '2019-03-01 17:25:46.000000000', 'files': ['releasenotes/notes/bug-1378904-disable-az-rename-b22a558a20b12706.yaml', 'nova/tests/functional/db/test_instance.py', 'nova/objects/instance.py', 'nova/tests/functional/test_aggregates.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8e19ef4173906da0b7c761da4de0728a2fd71e24', 'message': 'Check hosts have no instances for AZ rename\n\nUpdate aggregate and update aggregate metadata API calls have the\nability to update availability zone name for the aggregate. If the\naggregate is not empty (has hosts with instances on it)\nthe update leads to discrepancy for objects saving availability zone as a\nstring but not reference.\n\nFrom devstack DB they are:\n- cinder.backups.availability_zone\n- cinder.consistencygroups.availability_zone\n- cinder.groups.availability_zone\n- cinder.services.availability_zone\n- cinder.volumes.availability_zone\n- neutron.agents.availability_zone\n- neutron.networks.availability_zone_hints\n- neutron.router_extra_attributes.availability_zone_hints\n- nova.dns_domains.availability_zone\n- nova.instances.availability_zone\n- nova.volume_usage_cache.availability_zone\n- nova.shadow_dns_domains.availability_zone\n- nova.shadow_instances.availability_zone\n- nova.shadow_volume_usage_cache.availability_zone\n\nWhy that\'s bad?\nFirst, API and Horizon show different values for host and instance for\nexample. Second, migration for instances with changed availability\nzone fails with ""No valid host found"" for old AZ.\n\nThis change adds an additional check to aggregate an Update Aggregate API call.\nWith the check, it\'s not possible to rename AZ if the corresponding\naggregate has instances in any hosts.\n\nPUT /os-aggregates/{aggregate_id} and\nPOST /os-aggregates/{aggregate_id}/action return HTTP 400 for\navailability zone renaming if the hosts of the aggregate have any instances.\nIt\'s similar to conflicting AZ names error already available.\n\nChange-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73\nCloses-Bug: #1378904\n'}]",68,509206,8e19ef4173906da0b7c761da4de0728a2fd71e24,195,23,14,21813,,,0,"Check hosts have no instances for AZ rename

Update aggregate and update aggregate metadata API calls have the
ability to update availability zone name for the aggregate. If the
aggregate is not empty (has hosts with instances on it)
the update leads to discrepancy for objects saving availability zone as a
string but not reference.

From devstack DB they are:
- cinder.backups.availability_zone
- cinder.consistencygroups.availability_zone
- cinder.groups.availability_zone
- cinder.services.availability_zone
- cinder.volumes.availability_zone
- neutron.agents.availability_zone
- neutron.networks.availability_zone_hints
- neutron.router_extra_attributes.availability_zone_hints
- nova.dns_domains.availability_zone
- nova.instances.availability_zone
- nova.volume_usage_cache.availability_zone
- nova.shadow_dns_domains.availability_zone
- nova.shadow_instances.availability_zone
- nova.shadow_volume_usage_cache.availability_zone

Why that's bad?
First, API and Horizon show different values for host and instance for
example. Second, migration for instances with changed availability
zone fails with ""No valid host found"" for old AZ.

This change adds an additional check to aggregate an Update Aggregate API call.
With the check, it's not possible to rename AZ if the corresponding
aggregate has instances in any hosts.

PUT /os-aggregates/{aggregate_id} and
POST /os-aggregates/{aggregate_id}/action return HTTP 400 for
availability zone renaming if the hosts of the aggregate have any instances.
It's similar to conflicting AZ names error already available.

Change-Id: Ic27195e46502067c87ee9c71a811a3ca3f610b73
Closes-Bug: #1378904
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/509206/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/db/test_instance.py', 'nova/tests/unit/compute/test_compute.py', 'nova/objects/instance.py', 'nova/compute/api.py']",4,0ec3b1e0adb7dfa715102711463eaa59a7433090,bug/1378904," instance_count_by_cell = nova_context.scatter_gather_skip_cell0( context, objects.InstanceList.get_count_by_hosts, _hosts) if any(cnt for cnt in instance_count_by_cell.values()): msg = _(""One or more host has instances"") self._raise_invalid_aggregate_exc(action_name, aggregate.id, msg) self.is_safe_to_update_az(context, aggregate.metadata, hosts=[host_name], aggregate=aggregate, action_name=AGGREGATE_ACTION_DELETE)",,85,0
openstack%2Frpm-packaging~master~Ifa49e5ca21ee279a0569c5e11836113dfd16131e,openstack/rpm-packaging,master,Ifa49e5ca21ee279a0569c5e11836113dfd16131e,heat-agents: Add initial spec template,MERGED,2019-03-04 10:38:17.000000000,2019-03-06 07:44:53.000000000,2019-03-06 06:20:42.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 10:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/57bff9251ad3eddabb02368b4fb907849cd9c5fb', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 2, 'created': '2019-03-04 10:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bb2550db2026f0a43cd886e2acd8e694b9512736', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 3, 'created': '2019-03-04 12:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c5d346f9c66bdd024a640c13310b7dc3b7b052fa', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 4, 'created': '2019-03-05 07:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6889dfe513cdc73e63e3bb9a484a7d23561743ba', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 5, 'created': '2019-03-05 08:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/26f1fcc4fd6ca755afed010c7e0e4b438c679ce5', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nDepends-On: https://review.openstack.org/#/c/640832/\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 6, 'created': '2019-03-05 09:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4d40c171086759f0fbc9aedb38c853931d0f1ba6', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nDepends-On: https://review.openstack.org/#/c/640832/\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 7, 'created': '2019-03-05 09:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0f0b860f426bc534861f97e0e7c3f2aaea0b450d', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nDepends-On: https://review.openstack.org/#/c/640832/\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}, {'number': 8, 'created': '2019-03-05 10:09:48.000000000', 'files': ['openstack/heat-agents/heat-agents.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1a4b8beaea471042ed833648eb0fa52e826f6237', 'message': 'heat-agents: Add initial spec template\n\nBased on the work from\nhttps://github.com/rdo-packages/heat-agents-distgit with some\nadjustments.\n\nDepends-On: https://review.openstack.org/#/c/640832/\nChange-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e\n'}]",2,640721,1a4b8beaea471042ed833648eb0fa52e826f6237,34,5,8,7102,,,0,"heat-agents: Add initial spec template

Based on the work from
https://github.com/rdo-packages/heat-agents-distgit with some
adjustments.

Depends-On: https://review.openstack.org/#/c/640832/
Change-Id: Ifa49e5ca21ee279a0569c5e11836113dfd16131e
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/21/640721/8 && git format-patch -1 --stdout FETCH_HEAD,['openstack/heat-agents/heat-agents.spec.j2'],1,57bff9251ad3eddabb02368b4fb907849cd9c5fb,640721,{% set pypi_name = 'heat-agents' %} {% set upstream_version = upstream_version('1.7.0') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: OpenStack Heat agents License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://git.openstack.org/cgit/openstack/heat-agents Source0: {{ source }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('pbr') }} BuildArch: noarch %description Heat Agents are python hooks for deploying software configurations using heat. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %install # Use os-apply-config to bootstrap /etc/os-collect-config.conf # from heat boot data install -p -D -m 755 heat-config/os-refresh-config/configure.d/20-os-apply-config %{buildroot}%{_libexecdir}/os-refresh-config/configure.d/20-os-apply-config install -p -D -m 600 heat-config/os-apply-config/etc/os-collect-config.conf %{buildroot}%{_libexecdir}/os-apply-config/templates/etc/os-collect-config.conf # utilities which can be run by deployment scripts install -p -D -m 755 heat-config/bin/heat-config-notify %{buildroot}/%{_bindir}/heat-config-notify install -p -D -m 755 heat-config/bin/heat-config-rebuild-deployed %{buildroot}/%{_bindir}/heat-config-rebuild-deployed # os-refresh-config script to run heat deployment resources install -p -D -m 600 heat-config/os-apply-config/var/run/heat-config/heat-config %{buildroot}%{_libexecdir}/os-apply-config/templates/var/run/heat-config/heat-config install -p -D -m 755 heat-config/os-refresh-config/configure.d/55-heat-config %{buildroot}%{_libexecdir}/os-refresh-config/configure.d/55-heat-config # hook to perform configuration with scripts install -p -D -m 755 heat-config-script/install.d/hook-script.py %{buildroot}%{_libexecdir}/heat-config/hooks/script # hook to perform configuration with puppet install -p -D -m 755 heat-config-puppet/install.d/hook-puppet.py %{buildroot}%{_libexecdir}/heat-config/hooks/puppet # hook to perform configuration with ansible install -p -D -m 755 heat-config-ansible/install.d/hook-ansible.py %{buildroot}%{_libexecdir}/heat-config/hooks/ansible # hook to perform configuration with os-apply-config install -p -D -m 755 heat-config-apply-config/install.d/hook-apply-config.py %{buildroot}%{_libexecdir}/heat-config/hooks/apply-config # hook to perform configuration with hiera install -p -D -m 755 heat-config-hiera/install.d/hook-hiera.py %{buildroot}%{_libexecdir}/heat-config/hooks/hiera # hook to perform configuration with json-file install -p -D -m 755 heat-config-json-file/install.d/hook-json-file.py %{buildroot}%{_libexecdir}/heat-config/hooks/json-file # hook to perform configuration with docker commands install -p -D -m 755 heat-config-docker-cmd/os-refresh-config/configure.d/50-heat-config-docker-cmd %{buildroot}%{_libexecdir}/os-refresh-config/configure.d/50-heat-config-docker-cmd install -p -D -m 755 heat-config-docker-cmd/install.d/hook-docker-cmd.py %{buildroot}%{_libexecdir}/heat-config/hooks/docker-cmd %package -n python-heat-agent Summary: Agent for performing Heat software deployments Requires: {{ py2pkg('dib-utils') }} Requires: {{ py2pkg('heat-cfntools') }} Requires: {{ py2pkg('python-heatclient') }} Requires: {{ py2pkg('os-apply-config') }} Requires: {{ py2pkg('os-collect-config') }} Requires: {{ py2pkg('os-refresh-config') }} Requires: {{ py2pkg('requests') }} Requires: {{ py2pkg('python-zaqarclient') }} %description -n python-heat-agent Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform script based configuration tasks. %package -n python-heat-agent-puppet Summary: Agent for performing Puppet based Heat software deployments Requires: python-heat-agent Requires: puppet %description -n python-heat-agent-puppet Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform puppet based configuration tasks. %package -n python-heat-agent-ansible Summary: Agent for performing Ansible based Heat software deployments Requires: python-heat-agent Requires: {{ py2pkg('ansible') }} %description -n python-heat-agent-ansible Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform ansible based configuration tasks. %package -n python-heat-agent-apply-config Summary: Agent for performing os-apply-config based Heat software deployments Requires: python-heat-agent Requires: {{ py2pkg('os-apply-config') }} %description -n python-heat-agent-apply-config Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform os-apply-config based configuration tasks. %package -n python-heat-agent-hiera Summary: Agent for performing hiera based Heat software deployments Requires: python-heat-agent %description -n python-heat-agent-hiera Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform hiera based configuration tasks. %package -n python-heat-agent-json-file Summary: Agent for performing json-file based Heat software deployments Requires: python-heat-agent %description -n python-heat-agent-json-file Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform json-file based configuration tasks. %package -n python-heat-agent-docker-cmd Summary: Agent for performing Docker based Heat software deployments Requires: python-heat-agent Requires: {{ py2pkg('paunch') }} %description -n python-heat-agent-docker-cmd Heat Agents are python hooks for deploying software configurations using heat. This package installs and configures os-collect-config to allow Heat software deployments to perform docker based configuration tasks. %files %license LICENSE %files -n python-heat-agent %license LICENSE %dir %{_libexecdir}/os-refresh-config/configure.d/ %dir %{_libexecdir}/os-apply-config/templates/var/run/heat-config %{_bindir}/heat-config-notify %{_bindir}/heat-config-rebuild-deployed %{_libexecdir}/os-apply-config/templates/etc/os-collect-config.conf %{_libexecdir}/os-apply-config/templates/var/run/heat-config/heat-config %{_libexecdir}/os-refresh-config/configure.d/20-os-apply-config %{_libexecdir}/os-refresh-config/configure.d/55-heat-config %dir %{_libexecdir}/heat-config %dir %{_libexecdir}/heat-config/hooks %{_libexecdir}/heat-config/hooks/script %files -n python-heat-agent-puppet %license LICENSE %{_libexecdir}/heat-config/hooks/puppet %files -n python-heat-agent-ansible %{_libexecdir}/heat-config/hooks/ansible %files -n python-heat-agent-apply-config %{_libexecdir}/heat-config/hooks/apply-config %files -n python-heat-agent-hiera %{_libexecdir}/heat-config/hooks/hiera %files -n python-heat-agent-json-file %{_libexecdir}/heat-config/hooks/json-file %files -n python-heat-agent-docker-cmd %{_libexecdir}/heat-config/hooks/docker-cmd %{_libexecdir}/os-refresh-config/configure.d/50-heat-config-docker-cmd %changelog ,,181,0
openstack%2Frpm-packaging~master~Id830fb9adfa68d17642e3f7239e024a7405e05c5,openstack/rpm-packaging,master,Id830fb9adfa68d17642e3f7239e024a7405e05c5,oslo.serialization: Update to 2.28.2,MERGED,2019-03-05 15:36:00.000000000,2019-03-06 07:42:52.000000000,2019-03-06 07:42:52.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:36:00.000000000', 'files': ['openstack/oslo.serialization/oslo.serialization.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7508ab591477befd729ebd24ce33b322789d3583', 'message': 'oslo.serialization: Update to 2.28.2\n\nChange-Id: Id830fb9adfa68d17642e3f7239e024a7405e05c5\n'}]",0,641047,7508ab591477befd729ebd24ce33b322789d3583,9,5,1,7102,,,0,"oslo.serialization: Update to 2.28.2

Change-Id: Id830fb9adfa68d17642e3f7239e024a7405e05c5
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/47/641047/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.serialization/oslo.serialization.spec.j2'],1,7508ab591477befd729ebd24ce33b322789d3583,,{% set upstream_version = upstream_version('2.28.2') %},{% set upstream_version = upstream_version('2.28.1') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~I5b79c19a01f51ecd9098edf82037e850cb496793,openstack/rpm-packaging,master,I5b79c19a01f51ecd9098edf82037e850cb496793,sphinx-feature-classification: Update to 0.3.2,MERGED,2019-03-05 15:43:51.000000000,2019-03-06 07:42:51.000000000,2019-03-06 07:42:51.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:43:51.000000000', 'files': ['openstack/sphinx-feature-classification/sphinx-feature-classification.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d0516168bea09b33a4c9733667fd15f5e842d454', 'message': 'sphinx-feature-classification: Update to 0.3.2\n\nChange-Id: I5b79c19a01f51ecd9098edf82037e850cb496793\n'}]",0,641053,d0516168bea09b33a4c9733667fd15f5e842d454,9,5,1,7102,,,0,"sphinx-feature-classification: Update to 0.3.2

Change-Id: I5b79c19a01f51ecd9098edf82037e850cb496793
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/53/641053/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/sphinx-feature-classification/sphinx-feature-classification.spec.j2'],1,d0516168bea09b33a4c9733667fd15f5e842d454,,{% set upstream_version = upstream_version('0.3.2') %},{% set upstream_version = upstream_version('0.3.1') %},1,1
openstack%2Frpm-packaging~master~If74bba39b4bffc00e3a3e0f4a251c2c911801114,openstack/rpm-packaging,master,If74bba39b4bffc00e3a3e0f4a251c2c911801114,oslo.privsep: Update to 1.32.1,MERGED,2019-03-05 15:25:51.000000000,2019-03-06 07:41:36.000000000,2019-03-06 07:41:36.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b774889d0b811887f0d056511d7a15443cdea92e', 'message': 'oslo.privsep: Update to 1.32.1\n\nChange-Id: If74bba39b4bffc00e3a3e0f4a251c2c911801114\n'}, {'number': 2, 'created': '2019-03-05 18:47:08.000000000', 'files': ['openstack/oslo.privsep/oslo.privsep.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/162cb6143a2bc55205b854f3b022aac3bacae8e8', 'message': 'oslo.privsep: Update to 1.32.1\n\nChange-Id: If74bba39b4bffc00e3a3e0f4a251c2c911801114\n'}]",0,641040,162cb6143a2bc55205b854f3b022aac3bacae8e8,13,5,2,7102,,,0,"oslo.privsep: Update to 1.32.1

Change-Id: If74bba39b4bffc00e3a3e0f4a251c2c911801114
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/40/641040/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.privsep/oslo.privsep.spec.j2'],1,b774889d0b811887f0d056511d7a15443cdea92e,641040,{% set upstream_version = upstream_version('1.32.1') %}BuildRequires: {{ py2pkg('futures') }} Requires: {{ py2pkg('futures') }},{% set upstream_version = upstream_version('1.30.1') %},3,1
openstack%2Frpm-packaging~master~I7860b860a8e308c67256cb023e991eaef9ce54d7,openstack/rpm-packaging,master,I7860b860a8e308c67256cb023e991eaef9ce54d7,debtcollector: Update to 1.21.0,MERGED,2019-03-02 06:04:29.000000000,2019-03-06 07:41:35.000000000,2019-03-06 07:41:35.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-02 06:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/cac7c8333abaa43a38c446a59f70d7c14a2e4315', 'message': 'debtcollector: Update to 1.21.0\n\nChange-Id: I7860b860a8e308c67256cb023e991eaef9ce54d7\n'}, {'number': 2, 'created': '2019-03-05 07:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a4b70c390c9152b7d8e2cca1b1d5a756f6753f0a', 'message': 'debtcollector: Update to 1.21.0\n\nChange-Id: I7860b860a8e308c67256cb023e991eaef9ce54d7\n'}, {'number': 3, 'created': '2019-03-05 13:10:03.000000000', 'files': ['openstack/debtcollector/debtcollector.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1bb123db5616737db31186bdb79d8acaf1feb79d', 'message': 'debtcollector: Update to 1.21.0\n\nChange-Id: I7860b860a8e308c67256cb023e991eaef9ce54d7\n'}]",0,640576,1bb123db5616737db31186bdb79d8acaf1feb79d,21,5,3,7102,,,0,"debtcollector: Update to 1.21.0

Change-Id: I7860b860a8e308c67256cb023e991eaef9ce54d7
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/76/640576/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/debtcollector/debtcollector.spec.j2'],1,cac7c8333abaa43a38c446a59f70d7c14a2e4315,,Version: 1.21.0,Version: 1.20.0,1,1
openstack%2Frpm-packaging~master~If5d0b38ebc1d61720d3234e7af98d1a44e3fb514,openstack/rpm-packaging,master,If5d0b38ebc1d61720d3234e7af98d1a44e3fb514,oslo.versionedobjects: Update to 1.35.1,MERGED,2019-03-05 15:39:06.000000000,2019-03-06 07:41:34.000000000,2019-03-06 07:41:34.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:39:06.000000000', 'files': ['openstack/oslo.versionedobjects/oslo.versionedobjects.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/631efd0c5f4f9a13bf212d87299ceb5b99b5d480', 'message': 'oslo.versionedobjects: Update to 1.35.1\n\nChange-Id: If5d0b38ebc1d61720d3234e7af98d1a44e3fb514\n'}]",0,641050,631efd0c5f4f9a13bf212d87299ceb5b99b5d480,9,5,1,7102,,,0,"oslo.versionedobjects: Update to 1.35.1

Change-Id: If5d0b38ebc1d61720d3234e7af98d1a44e3fb514
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/50/641050/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.versionedobjects/oslo.versionedobjects.spec.j2'],1,631efd0c5f4f9a13bf212d87299ceb5b99b5d480,,{% set upstream_version = upstream_version('1.35.1') %},"{% set upstream_version = upstream_version('1.34.1') %}BuildRequires: {{ py2pkg('testtools', py_versions=['py2', 'py3']) }}",1,2
openstack%2Frpm-packaging~stable%2Frocky~I772f2bb2e284e94f94dfcfa09a606e5c66fe1c25,openstack/rpm-packaging,stable/rocky,I772f2bb2e284e94f94dfcfa09a606e5c66fe1c25,ovsdbapp: Update to 0.12.3,MERGED,2019-03-05 15:45:09.000000000,2019-03-06 07:36:22.000000000,2019-03-06 07:36:22.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:45:09.000000000', 'files': ['openstack/ovsdbapp/ovsdbapp.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9a3517ec7f003837838030d03dbebd3a1933d9ce', 'message': 'ovsdbapp: Update to 0.12.3\n\nChange-Id: I772f2bb2e284e94f94dfcfa09a606e5c66fe1c25\n'}]",0,641055,9a3517ec7f003837838030d03dbebd3a1933d9ce,9,4,1,7102,,,0,"ovsdbapp: Update to 0.12.3

Change-Id: I772f2bb2e284e94f94dfcfa09a606e5c66fe1c25
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/55/641055/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/ovsdbapp/ovsdbapp.spec.j2'],1,9a3517ec7f003837838030d03dbebd3a1933d9ce,stable-rocky,{% set upstream_version = upstream_version('0.12.3') %},{% set upstream_version = upstream_version('0.12.2') %},1,1
openstack%2Fvitrage-tempest-plugin~master~Ic0acb247e24068d811dc860d272eb166504660de,openstack/vitrage-tempest-plugin,master,Ic0acb247e24068d811dc860d272eb166504660de,Add tempest tests for adding a template by a yaml string,MERGED,2019-03-05 14:03:28.000000000,2019-03-06 07:19:13.000000000,2019-03-06 07:19:13.000000000,"[{'_account_id': 19134}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 14:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/5a4d01cd78ec76adc9ec599a91d07f1359b8682c', 'message': 'Add tempest tests for adding a template by a yaml string\n\nChange-Id: Ic0acb247e24068d811dc860d272eb166504660de\nStory: 2004055\nTask: 29838\n'}, {'number': 2, 'created': '2019-03-05 16:55:56.000000000', 'files': ['vitrage_tempest_plugin/tests/api/templates/test_template_v3.py', 'vitrage_tempest_plugin/tests/api/templates/test_template_v2.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/97668bc3c1162db00b7347d1cbf48048774f3dd6', 'message': 'Add tempest tests for adding a template by a yaml string\n\nChange-Id: Ic0acb247e24068d811dc860d272eb166504660de\nDepends-On: Icf67750226d379c20dbe9d93df18eeabf88aadfa\n\nStory: 2004055\nTask: 29838\n'}]",0,641018,97668bc3c1162db00b7347d1cbf48048774f3dd6,10,3,2,19159,,,0,"Add tempest tests for adding a template by a yaml string

Change-Id: Ic0acb247e24068d811dc860d272eb166504660de
Depends-On: Icf67750226d379c20dbe9d93df18eeabf88aadfa

Story: 2004055
Task: 29838
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/18/641018/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/tests/api/templates/test_template_v3.py', 'vitrage_tempest_plugin/tests/api/templates/test_template_v2.py']",2,5a4d01cd78ec76adc9ec599a91d07f1359b8682c,add_template_string," def _add_by_string(self, template_str): result = self.vitrage_client.template.add(template_str=template_str) self._assert_add_result(result, LOADING_STATUS, TEMPLATE_VALIDATION_OK) TEMPLATE_STRING = """""" metadata: name: host_down_scenarios description: scenarios triggered by Doctor monitor 'compute.host.down' alarm version: 2 type: standard definitions: entities: - entity: category: ALARM name: compute.host.down template_id: host_down_alarm - entity: category: RESOURCE type: nova.host template_id: host relationships: - relationship: source: host_down_alarm relationship_type: on target: host template_id : host_down_alarm_on_host scenarios: - scenario: condition: host_down_alarm_on_host actions: - action: action_type: set_state action_target: target: host properties: state: ERROR """""" def test_template_add_by_string(self): self._add_by_string(TEMPLATE_STRING)",,64,0
openstack%2Fpython-octaviaclient~master~I30b1a7555e1d910e07379bc69e739225a35a1a0c,openstack/python-octaviaclient,master,I30b1a7555e1d910e07379bc69e739225a35a1a0c,Add a new option '--redirect-http-code' into L7Policy CLI,MERGED,2018-12-13 14:16:01.000000000,2019-03-06 07:13:54.000000000,2019-03-06 07:13:54.000000000,"[{'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-13 14:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/f188f11600c4b3e00e65e9357c646f587f129017', 'message': ""Add a new option '--redirect-http-code' into L7Policy CLI\n\nThis patch add a new option '--redirect-http-code' into L7Policy for\nredirection url and prefix action.\n\nChange-Id: I30b1a7555e1d910e07379bc69e739225a35a1a0c\nStory: 2003609\nDepends-On: https://review.openstack.org/#/c/625007\n""}, {'number': 2, 'created': '2018-12-25 02:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/cd908dffb1d6c5f102285672fcb77d07fd9f03e6', 'message': ""Add a new option '--redirect-http-code' into L7Policy CLI\n\nThis patch add a new option '--redirect-http-code' into L7Policy for\nredirection url and prefix action.\n\nChange-Id: I30b1a7555e1d910e07379bc69e739225a35a1a0c\nStory: 2003609\nDepends-On: https://review.openstack.org/#/c/625007\n""}, {'number': 3, 'created': '2019-03-05 00:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/44b91613e1d84c82829e455ee0dc2cd1511d1f3a', 'message': ""Add a new option '--redirect-http-code' into L7Policy CLI\n\nThis patch add a new option '--redirect-http-code' into L7Policy for\nredirection url and prefix action.\n\nChange-Id: I30b1a7555e1d910e07379bc69e739225a35a1a0c\nStory: 2003609\nDepends-On: https://review.openstack.org/#/c/625007\n""}, {'number': 4, 'created': '2019-03-05 00:09:46.000000000', 'files': ['octaviaclient/osc/v2/l7policy.py', 'octaviaclient/osc/v2/constants.py', 'octaviaclient/osc/v2/utils.py'], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/2d1c4f8a85bbc0522f4f02142d8d54270f774187', 'message': ""Add a new option '--redirect-http-code' into L7Policy CLI\n\nThis patch add a new option '--redirect-http-code' into L7Policy for\nredirection url and prefix action.\n\nChange-Id: I30b1a7555e1d910e07379bc69e739225a35a1a0c\nStory: 2003609\nDepends-On: https://review.openstack.org/#/c/625007\n""}]",1,625008,2d1c4f8a85bbc0522f4f02142d8d54270f774187,18,3,4,15309,,,0,"Add a new option '--redirect-http-code' into L7Policy CLI

This patch add a new option '--redirect-http-code' into L7Policy for
redirection url and prefix action.

Change-Id: I30b1a7555e1d910e07379bc69e739225a35a1a0c
Story: 2003609
Depends-On: https://review.openstack.org/#/c/625007
",git fetch https://review.opendev.org/openstack/python-octaviaclient refs/changes/08/625008/4 && git format-patch -1 --stdout FETCH_HEAD,"['octaviaclient/osc/v2/l7policy.py', 'octaviaclient/osc/v2/constants.py', 'octaviaclient/osc/v2/utils.py']",3,f188f11600c4b3e00e65e9357c646f587f129017,redirect_http_code," 'redirect_http_code': ('redirect_http_code', int),",,17,3
openstack%2Fnetworking-sfc~stable%2Fpike~I435f6e6c04d4e73bdad8cac7a7a195be440f9437,openstack/networking-sfc,stable/pike,I435f6e6c04d4e73bdad8cac7a7a195be440f9437,Fix gates,MERGED,2019-02-27 10:46:53.000000000,2019-03-06 06:57:56.000000000,2019-03-06 06:57:56.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 11224}, {'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 18955}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-27 10:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/d5ddd7e2300535ce394c4ccef8c60ee75721dc9f', 'message': 'Fix sfc-tempest-dsvm\n\nInstead of allowing all api extensions, just allow extensions which are\nsupported in Pike\n\nChange-Id: I435f6e6c04d4e73bdad8cac7a7a195be440f9437\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 2, 'created': '2019-03-04 22:40:20.000000000', 'files': ['.gitignore', 'tools/tox_install.sh', 'test-requirements.txt', 'networking_sfc/tests/contrib/post_test_hook.sh', 'networking_sfc/tests/contrib/hooks/api_extensions', 'tox.ini', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/d066e743967e159aa6f6295d18cefa4ca34c31b6', 'message': 'Fix gates\n\npy35: Fix an issue where toxenv fails when it encounters a non-empty\n__pycache__ directory. This adjusts the options passed to find so that it is\ntolerant ofthis scenario and allows tox runs to proceed.\n\nsphinx-docs: Cover the case where no packages must be installed\n\nfunctional-dsvm: Fix post gate hook to accommodate for new os-testr\nNew versions now use .stestr instead of previous .testrepository\ndirectory\n\nsfc-tempest-dsvm: Instead of allowing all api extensions, just allow extensions\nwhich are supported in Pike\n\nChange-Id: I435f6e6c04d4e73bdad8cac7a7a195be440f9437\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}]",0,639625,d066e743967e159aa6f6295d18cefa4ca34c31b6,15,8,2,21883,,,0,"Fix gates

py35: Fix an issue where toxenv fails when it encounters a non-empty
__pycache__ directory. This adjusts the options passed to find so that it is
tolerant ofthis scenario and allows tox runs to proceed.

sphinx-docs: Cover the case where no packages must be installed

functional-dsvm: Fix post gate hook to accommodate for new os-testr
New versions now use .stestr instead of previous .testrepository
directory

sfc-tempest-dsvm: Instead of allowing all api extensions, just allow extensions
which are supported in Pike

Change-Id: I435f6e6c04d4e73bdad8cac7a7a195be440f9437
Signed-off-by: Manuel Buil <mbuil@suse.com>
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/25/639625/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_sfc/tests/contrib/hooks/api_extensions'],1,d5ddd7e2300535ce394c4ccef8c60ee75721dc9f,,"NETWORK_API_EXTENSIONS=agent,binding,dhcp_agent_scheduler,external-net,ext-gw-mode,extra_dhcp_opts,quotas,router,security-group,subnet_allocation,network-ip-availability,auto-allocated-topology,timestamp_core,tag,service-type,rbac-policies,standard-attr-description,pagination,sorting,project-id,sfc,flow_classifier","NETWORK_API_EXTENSIONS=""all,sfc,flow_classifier""",1,1
openstack%2Felection~master~I4fa53076ed9bcdf1545d9c4aa5e80dc5dad95210,openstack/election,master,I4fa53076ed9bcdf1545d9c4aa5e80dc5dad95210,Consistent HTTPS for URLs in non-historical files,MERGED,2019-03-04 16:39:04.000000000,2019-03-06 06:47:47.000000000,2019-03-06 06:47:47.000000000,"[{'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 16:39:04.000000000', 'files': ['doc/source/index.rst', 'doc/source/conf.py', 'openstack_election/utils.py', 'openstack_election/cmds/template_emails.py', 'tools/tc-election-summary.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/election/commit/7c7da155e59a8aee81708810781a3dd8bff13447', 'message': ""Consistent HTTPS for URLs in non-historical files\n\nUpdate the URLs in various templates and generated content to\nconsistently use https:// instead of a mix of that and http://, and\nwhile we're at it set the homepage for the Python package of this\nrepo to the election site rather than the OpenStack Foundation site.\n\nChange-Id: I4fa53076ed9bcdf1545d9c4aa5e80dc5dad95210\n""}]",0,640806,7c7da155e59a8aee81708810781a3dd8bff13447,9,4,1,5263,,,0,"Consistent HTTPS for URLs in non-historical files

Update the URLs in various templates and generated content to
consistently use https:// instead of a mix of that and http://, and
while we're at it set the homepage for the Python package of this
repo to the election site rather than the OpenStack Foundation site.

Change-Id: I4fa53076ed9bcdf1545d9c4aa5e80dc5dad95210
",git fetch https://review.opendev.org/openstack/election refs/changes/06/640806/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/conf.py', 'openstack_election/cmds/template_emails.py', 'openstack_election/utils.py', 'setup.cfg', 'tools/tc-election-summary.py']",6,7c7da155e59a8aee81708810781a3dd8bff13447,,CIVS_BASE = 'https://civs.cs.cornell.edu/cgi-bin/results.pl',CIVS_BASE = 'http://civs.cs.cornell.edu/cgi-bin/results.pl',21,21
openstack%2Fheat~master~I707301c410779df473513803a2efaa62b1a20578,openstack/heat,master,I707301c410779df473513803a2efaa62b1a20578,Move syncpoint from DB to ETCD,ABANDONED,2018-04-03 06:24:42.000000000,2019-03-06 06:41:04.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-04-03 06:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5582107ffd7b9c0e5e342aa3e56258ce39f34b70', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\nTODO: Add unit test and fix current tests\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 2, 'created': '2018-04-04 05:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7ff9950645a11bad2c1578404769db0070d2cea8', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\nTODO: Add unit test and fix current tests\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 3, 'created': '2018-05-17 06:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/884f6bcb550153376b74793472c9e975ef8ff950', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\nTODO: Add unit test and fix current tests\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 4, 'created': '2018-05-17 07:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b79d5250fd80774a4ea4becaa336e569ae9a418', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\nTODO: Add unit test and fix current tests\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 5, 'created': '2018-05-17 08:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5f8c410a31994571718143c80dfb4443b0f0c6f3', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\nTODO: Add unit test and fix current tests\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 6, 'created': '2018-05-17 13:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2249a4a591a15897e9400a2eb555f84e986d6bdb', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\nTODO: Add unit test and fix current tests\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 7, 'created': '2018-05-17 16:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6348583731e117f109968cbe7711c295d76a01a0', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 8, 'created': '2018-05-17 17:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f0222f19338d8d25362ac03168470fe3cea08e8a', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 9, 'created': '2018-05-18 02:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8c19ee15f77e64827da91cb43911f718633027e3', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 10, 'created': '2018-05-19 12:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d4ad0105d27b8d4be90c006e4a4f3ebfb76e2d1a', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 11, 'created': '2018-05-19 14:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/05202a30a232535d1345487c698189eba0e1fff0', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 12, 'created': '2018-05-19 16:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/df0c47840dc0ce1153e1224522c60fd05aabf4a3', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 13, 'created': '2018-05-20 01:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22df8817c1ca776a4f9814798616fb34419cc5c3', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 14, 'created': '2018-05-20 04:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/190554ecec87a8511f5bb22feb3ce5c93ade485c', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nDepends-On: https://review.openstack.org/#/c/569582\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}, {'number': 15, 'created': '2018-05-20 06:53:15.000000000', 'files': ['heat/tests/api/openstack_v1/test_stacks.py', 'heat/rpc/client.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/tests/api/cfn/test_api_cfn_v1.py', 'heat/tests/engine/test_sync_point.py', 'heat/objects/sync_point.py', 'heat/tests/test_convg_stack.py', 'heat/engine/stack.py', 'heat/engine/sync_point.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/adbce36298ded84a676c68b4971e6560617205b2', 'message': 'Move syncpoint from DB to ETCD\n\nSwitch Syncpoint backend from DB to ETCD.\nChange RPC API version to new version, so old and new\nengines will not mix up.\n\nDepends-On: https://review.openstack.org/#/c/569582\n\nChange-Id: I707301c410779df473513803a2efaa62b1a20578\n'}]",0,558395,adbce36298ded84a676c68b4971e6560617205b2,37,2,15,12404,,,0,"Move syncpoint from DB to ETCD

Switch Syncpoint backend from DB to ETCD.
Change RPC API version to new version, so old and new
engines will not mix up.

Depends-On: https://review.openstack.org/#/c/569582

Change-Id: I707301c410779df473513803a2efaa62b1a20578
",git fetch https://review.opendev.org/openstack/heat refs/changes/95/558395/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/rpc/client.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/objects/sync_point.py', 'heat/engine/sync_point.py']",4,5582107ffd7b9c0e5e342aa3e56258ce39f34b70,bp/support-etcd3,"import json """"""Creates a sync point entry in Etcd."""""" return sync_point_object.SyncPoint.create(traversal_id, entity_id, is_update, stack_id, {}) """"""Retrieves a sync point entry from Etcd."""""" sync_point = sync_point_object.SyncPoint.get_by_key(traversal_id, entity_id, """"""Deletes all sync points of with a traversal_id."""""" return sync_point_object.SyncPoint.delete_all_by_traversal(traversal_id) current_traversal, entity_id, is_update, atomic_key,def deserialize_input_data(etcd_input_data): etcd_input_data = json.loads(etcd_input_data) etcd_input_data = etcd_input_data.get('input_data') if not etcd_input_data: return dict(_deserialize(etcd_input_data)) return json.dumps({'input_data': _serialize(input_data)})"," """"""Creates a sync point entry in DB."""""" values = {'entity_id': entity_id, 'traversal_id': traversal_id, 'is_update': is_update, 'atomic_key': 0, 'stack_id': stack_id, 'input_data': {}} return sync_point_object.SyncPoint.create(context, values) """"""Retrieves a sync point entry from DB."""""" sync_point = sync_point_object.SyncPoint.get_by_key(context, entity_id, traversal_id, """"""Deletes all sync points of a stack associated with a traversal_id."""""" return sync_point_object.SyncPoint.delete_all_by_stack_and_traversal( context, stack_id, traversal_id ) context, entity_id, current_traversal, is_update, atomic_key,def deserialize_input_data(db_input_data): db_input_data = db_input_data.get('input_data') if not db_input_data: return dict(_deserialize(db_input_data)) return {'input_data': _serialize(input_data)}",64,69
openstack%2Fheat~master~I956ffcecc1ad1d9588f0c74ada751b06fc9edf09,openstack/heat,master,I956ffcecc1ad1d9588f0c74ada751b06fc9edf09,Add SyncPoint Etcd model,ABANDONED,2018-04-03 06:24:42.000000000,2019-03-06 06:41:01.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-04-03 06:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d71c0203b0e7e85187596844329b6eeea82c8146', 'message': 'Add SyncPoint Etcd model\n\nTODO: Add unit test\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 2, 'created': '2018-04-04 05:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4e49680ea5dc92fdafd8266b8dae8e071331fd74', 'message': 'Add SyncPoint Etcd model\n\nTODO: Add unit test\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 3, 'created': '2018-05-17 06:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e1004605701759879bd8c74a1738a18812e22791', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 4, 'created': '2018-05-17 07:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b13b699b4f6083f846b9572effc326610791074a', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 5, 'created': '2018-05-17 08:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9f24469e3d52f0a0e2c4e50702b8f9934177e64', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 6, 'created': '2018-05-17 13:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f1634f2be26090c1d846f6cdb8faf20deb2ccaad', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 7, 'created': '2018-05-17 16:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7ef5b6df34397cba33b38fe77fad0a91fbb1dbf8', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 8, 'created': '2018-05-17 17:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/efd860f5c989be200655ba3732f816d1d7f39fd3', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 9, 'created': '2018-05-18 02:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/edc53a48893ec6d8d50ab54710f16fae403e6005', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}, {'number': 10, 'created': '2018-05-19 12:30:38.000000000', 'files': ['heat/tests/etcd/test_sync_point.py', 'heat/etcd/sync_point.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/62e88351c1e1173ecc60f11a765eb92646674f5b', 'message': 'Add SyncPoint Etcd model\n\nChange-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09\n'}]",0,558394,62e88351c1e1173ecc60f11a765eb92646674f5b,24,2,10,12404,,,0,"Add SyncPoint Etcd model

Change-Id: I956ffcecc1ad1d9588f0c74ada751b06fc9edf09
",git fetch https://review.opendev.org/openstack/heat refs/changes/94/558394/7 && git format-patch -1 --stdout FETCH_HEAD,['heat/etcd/sync_point.py'],1,d71c0203b0e7e85187596844329b6eeea82c8146,bp/support-etcd3,"# # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from oslo_log import log as logging import six from heat.etcd import base LOG = logging.getLogger(__name__) KEY_SEPERATOR = ':' class SyncPoint(base.Etcd3Worker): """"""""SyncPoint etcd3 backend."""""" def __init__(self, traversal_id, entity_id=None, is_update=None, stack_id=None, input_data={}): super(SyncPoint, self).__init__() self.entity_id = entity_id self.traversal_id = traversal_id self.is_update = is_update self.stack_id = stack_id self.input_data = input_data def create_sync_point(self): key = self.format_sync_point_key() result = self.create(key, self.input_data) if result is False: LOG.debug( ""CONFLICT: conflict when try to create with key %s"" % key) return result def get_sync_point(self): results = self.get(key_prefix=self.format_sync_point_key( [self.traversal_id, self.entity_id, self.is_update]) ) if results and len(results) > 0: return results[0] return None def update_sync_point(self, atomic_key, input_data={}): sp = self.get_sync_point() if sp is None: return None value, metadata = sp # atomic_key is replaced by version information from etcd. if metadata['version'] == atomic_key: return self.update(metadata['key'], input_data) return False def delete_sync_point(self): return self.delete(key_prefix=self.traversal_id) def format_sync_point_key(self, key_list=[]): if not key_list: key_list = [self.traversal_id, self.entity_id, self.is_update, self.stack_id] return KEY_SEPERATOR.join([six.text_type(key) for key in key_list]) @staticmethod def parse_sync_point_key(key): key_list = key.split(KEY_SEPERATOR) key_map = { 'traversal_id': key_list[0], 'entity_id': key_list[1], 'is_update': key_list[2], 'stack_id': key_list[3] } return key_map ",,79,0
openstack%2Fheat~master~If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a,openstack/heat,master,If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a,Move Stack Lock from DB to Etcd,ABANDONED,2018-04-03 06:24:42.000000000,2019-03-06 06:40:59.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-04-03 06:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0c80e2450862a377ca0d4ec6add6a2db31e4f389', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\nTODO: Add unit test and fix current tests\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}, {'number': 2, 'created': '2018-04-04 05:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cf257606cd1cde93c5d4c4557e102f2a336b20bb', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\nTODO: Add unit test and fix current tests\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}, {'number': 3, 'created': '2018-04-04 09:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1b73d571d44ae8e03dfef212e719074430c0f846', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\nTODO: Add unit test and fix current tests\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}, {'number': 4, 'created': '2018-05-17 06:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/803b7764669ec714694c46415dd50af03ab35003', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}, {'number': 5, 'created': '2018-05-17 07:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b8c3c19ac54f6afb5b20ae387b5779e89b9465a6', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}, {'number': 6, 'created': '2018-05-17 08:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ee1e55d87dccd3f4d6a2e340ac6da4cf0c642fc1', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}, {'number': 7, 'created': '2018-05-17 13:02:33.000000000', 'files': ['heat/tests/api/openstack_v1/test_stacks.py', 'heat/tests/engine/service/test_stack_delete.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/stack_resource.py', 'heat/cmd/manage.py', 'heat/objects/stack.py', 'heat/tests/test_stack_resource.py', 'heat/engine/service.py', 'heat/tests/common.py', 'heat/rpc/client.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/tests/api/cfn/test_api_cfn_v1.py', 'heat/tests/test_stack_lock.py', 'heat/tests/db/test_sqlalchemy_api.py', 'heat/objects/stack_lock.py', 'heat/engine/stack_lock.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9b960c7616b980bba26ce13fcf23b8cd436771f6', 'message': ""Move Stack Lock from DB to Etcd\n\nSwitch Stack Lock backend from DB to Etcd\nBump RPC API Version so old engine won't use this feature during\nrolling upgrade.\n\nChange-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a\n""}]",0,558397,9b960c7616b980bba26ce13fcf23b8cd436771f6,20,2,7,12404,,,0,"Move Stack Lock from DB to Etcd

Switch Stack Lock backend from DB to Etcd
Bump RPC API Version so old engine won't use this feature during
rolling upgrade.

Change-Id: If49db14e7d7b9baa6239cb212a5ca0fc4b34be1a
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/558397/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/rpc/client.py', 'heat/tests/engine/service/test_service_engine.py', 'heat/objects/stack_lock.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/stack_resource.py', 'heat/cmd/manage.py', 'heat/engine/stack_lock.py', 'heat/objects/stack.py', 'heat/engine/service.py']",9,0c80e2450862a377ca0d4ec6add6a2db31e4f389,bp/support-etcd3," lock = stack_lock.StackLock(cnxt, current_stack.id, self.engine_id) return stack_lock.StackLock(cnxt, rsrc.stack.id,"," lock = stack_lock.StackLock(cnxt, current_stack.id, self.engine_id) return stack_lock.StackLock(cnxt, rsrc.stack.id,",36,58
openstack%2Fheat~master~I8d7f74460634aaed03890a469c8bff8966602e1d,openstack/heat,master,I8d7f74460634aaed03890a469c8bff8966602e1d,Support Etcd,ABANDONED,2018-04-03 06:24:42.000000000,2019-03-06 06:40:56.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 26240}]","[{'number': 1, 'created': '2018-04-03 06:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/74cc46ca6ab5ca4be2b18a6e97f38b07d41ebe19', 'message': 'Support Etcd\n\nAdd etcd base infrastructure to heat.\nAdd basic etcd module and config options\nAdd config options to devstack.\n\nTODO: Add unit test\n\nChange-Id: I8d7f74460634aaed03890a469c8bff8966602e1d\n'}, {'number': 2, 'created': '2018-04-04 05:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d0e3ffc5279bef3dc75e25e6602d3095f2c8c643', 'message': 'Support Etcd\n\nAdd etcd base infrastructure to heat.\nAdd basic etcd module and config options\nAdd config options to devstack.\n\nTODO: Add unit test\n\nChange-Id: I8d7f74460634aaed03890a469c8bff8966602e1d\n'}, {'number': 3, 'created': '2018-05-17 06:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/335486479e10f32166db565a5e7a61defef67296', 'message': 'Support Etcd\n\nAdd etcd base infrastructure to heat.\nAdd basic etcd module and config options\nAdd config options to devstack.\nAdd fake etcd backend to HeatTestCase\n\nChange-Id: I8d7f74460634aaed03890a469c8bff8966602e1d\n'}, {'number': 4, 'created': '2018-05-17 07:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/23b034fef1de13be34043d676fc4a4243c64a841', 'message': 'Support Etcd\n\nAdd etcd base infrastructure to heat.\nAdd basic etcd module and config options\nAdd config options to devstack.\nAdd fake etcd backend to HeatTestCase\n\nChange-Id: I8d7f74460634aaed03890a469c8bff8966602e1d\n'}, {'number': 5, 'created': '2018-05-17 13:02:33.000000000', 'files': ['heat/tests/etcd/__init__.py', 'heat/tests/etcd/test_base.py', 'devstack/upgrade/upgrade.sh', 'lower-constraints.txt', 'devstack/lib/heat', 'heat/etcd/fake_etcd_client.py', 'heat/tests/common.py', 'requirements.txt', 'playbooks/devstack/functional/run.yaml', 'heat/etcd/base.py', 'heat/common/config.py', 'heat/etcd/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9a1b13645bb9d1ae75aa72880cca66ca1b76e736', 'message': 'Support Etcd\n\nAdd etcd base infrastructure to heat.\nAdd basic etcd module and config options\nAdd config options to devstack.\nAdd fake etcd backend to HeatTestCase\n\nChange-Id: I8d7f74460634aaed03890a469c8bff8966602e1d\n'}]",0,558393,9a1b13645bb9d1ae75aa72880cca66ca1b76e736,14,3,5,12404,,,0,"Support Etcd

Add etcd base infrastructure to heat.
Add basic etcd module and config options
Add config options to devstack.
Add fake etcd backend to HeatTestCase

Change-Id: I8d7f74460634aaed03890a469c8bff8966602e1d
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/558393/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/etcd/base.py', 'devstack/lib/heat', 'heat/common/config.py', 'heat/etcd/__init__.py']",4,74cc46ca6ab5ca4be2b18a6e97f38b07d41ebe19,bp/support-etcd3,,,84,0
openstack%2Fheat~master~I9fcb565ad9a73ff7b04b8bdf18f29053d8417341,openstack/heat,master,I9fcb565ad9a73ff7b04b8bdf18f29053d8417341,Add Etcd Stack Lock,ABANDONED,2018-04-03 06:24:42.000000000,2019-03-06 06:40:53.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 26240}]","[{'number': 1, 'created': '2018-04-03 06:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2c5170440fb25b13d705b3bda77d66507c4a0419', 'message': 'Add Etcd Stack Lock\n\nTODO: Add unit test\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}, {'number': 2, 'created': '2018-04-04 05:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dd2312f74cc45b087b7780624be455c7e9f67415', 'message': 'Add Etcd Stack Lock\n\nTODO: Add unit test\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}, {'number': 3, 'created': '2018-04-04 09:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7f470550503d6fd1a5293fa1a04f5534e897fe95', 'message': 'Add Etcd Stack Lock\n\nTODO: Add unit test\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}, {'number': 4, 'created': '2018-05-17 06:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0c51b0164a38160c404f47f2bb192d52e823d022', 'message': 'Add Etcd Stack Lock\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}, {'number': 5, 'created': '2018-05-17 07:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b3ddcd79a5ab61ef2f91cfe59f84e397b092e14', 'message': 'Add Etcd Stack Lock\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}, {'number': 6, 'created': '2018-05-17 08:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5dcf4f4d529b9aead72ef0d0fd46f145fc06b29f', 'message': 'Add Etcd Stack Lock\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}, {'number': 7, 'created': '2018-05-17 13:02:33.000000000', 'files': ['heat/tests/etcd/test_stack_lock.py', 'heat/etcd/stack_lock.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/53943459359903735d91bc9a9043505b9d0d580e', 'message': 'Add Etcd Stack Lock\n\nChange-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341\n'}]",0,558396,53943459359903735d91bc9a9043505b9d0d580e,20,3,7,12404,,,0,"Add Etcd Stack Lock

Change-Id: I9fcb565ad9a73ff7b04b8bdf18f29053d8417341
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/558396/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/etcd/stack_lock.py'],1,2c5170440fb25b13d705b3bda77d66507c4a0419,bp/support-etcd3,"# # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from oslo_log import log as logging from heat.etcd import base LOG = logging.getLogger(__name__) # TODO(ricolin) Try to integrated with tooz # Current functionality not completly matched with what tooz # provided, but we should try to integrated with tooz KEY_PREFIX = b'/heat/stack_lock/' class StackLock(base.Etcd3Worker): def __init__(self, stack_id, engine_id=None): super(StackLock, self).__init__() self.stack_id = stack_id self.engine_id = engine_id self._key = KEY_PREFIX + self.stack_id def create_stack_lock(self): result = self.create(self._key, self.engine_id) if result is False: LOG.debug( ""CONFLICT: conflict when try to create stack "" ""lock %s"" % self.stack_id) return self.get_engine_id() return None def steal_stack_lock(self): lock = self.get(key=self._key, metadata=False) result = self.put(self._key, self.engine_id) if result is True: return None return lock[0] if len(lock) > 0 else True def release_stack_lock(self): """""" Release Stack Lock Return None if lock released, return True if lock is already released elase return current current engine_id from lock if can't release that lock. """""" result = self.delete(key=self._key) if result is False: lock = self.get(key=self._key, metadata=False) if len(lock) > 0: return lock[0] return True return None def get_engine_id(self): result = self.get(key=self._key, metadata=False) return result[0] if len(result) > 0 else None ",,67,0
openstack%2Fheat-tempest-plugin~master~I5eccc680caebedbec261407d619618d478fc0b28,openstack/heat-tempest-plugin,master,I5eccc680caebedbec261407d619618d478fc0b28,Add external_ref test for update stack,MERGED,2018-04-18 05:28:44.000000000,2019-03-06 06:34:19.000000000,2019-03-06 06:34:19.000000000,"[{'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-04-18 05:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/5bf3d72ab1cdc263121e2d5c79f1124be975c278', 'message': 'Add external_ref test for update stack\n\nAdd test to make sure after we update a stack, external resource will\nstill presented.\n\nDepends-On: https://review.openstack.org/#/c/557175/\nPartial-Bugs: #1756269\n\nChange-Id: I5eccc680caebedbec261407d619618d478fc0b28\n'}, {'number': 2, 'created': '2018-04-18 09:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/7fdee70dfaef020da02a37ed016970e2654e2d90', 'message': 'Add external_ref test for update stack\n\nAdd test to make sure after we update a stack, external resource will\nstill presented.\n\nDepends-On: https://review.openstack.org/#/c/557175/\nPartial-Bugs: #1756269\n\nChange-Id: I5eccc680caebedbec261407d619618d478fc0b28\n'}, {'number': 3, 'created': '2018-05-10 12:03:56.000000000', 'files': ['heat_tempest_plugin/tests/functional/test_external_ref.py'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/261e594dbc5a7a990c0cdecf22a42a47a42a34f7', 'message': 'Add external_ref test for update stack\n\nAdd test to make sure after we update a stack, external resource will\nstill presented.\n\nDepends-On: https://review.openstack.org/#/c/557175/\nStory: #1756269\n\nChange-Id: I5eccc680caebedbec261407d619618d478fc0b28\n'}]",0,562112,261e594dbc5a7a990c0cdecf22a42a47a42a34f7,12,3,3,12404,,,0,"Add external_ref test for update stack

Add test to make sure after we update a stack, external resource will
still presented.

Depends-On: https://review.openstack.org/#/c/557175/
Story: #1756269

Change-Id: I5eccc680caebedbec261407d619618d478fc0b28
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/12/562112/2 && git format-patch -1 --stdout FETCH_HEAD,['heat_tempest_plugin/tests/functional/test_external_ref.py'],1,5bf3d72ab1cdc263121e2d5c79f1124be975c278,story/1756269," def _stack_create(self, template): self.stack_name = self._stack_rand_name() self.stack_identifier = self.stack_create( stack_name=self.stack_name, template=template, self._wait_for_stack_status(self.stack_identifier, 'CREATE_COMPLETE') self.list_resources(self.stack_identifier)) @decorators.idempotent_id('45449bad-18ba-4148-82e6-a6bc1e9a9b04') def test_create_with_external_ref(self): self._stack_create(self.TEMPLATE_WITH_EX_REF) stack = self.client.stacks.get(self.stack_identifier) self._stack_create(self.TEMPLATE) stack = self.client.stacks.get(self.stack_identifier) stack_name = self.stack_identifier.split('/')[0] kwargs = {'stack_id': self.stack_identifier, 'stack_name': stack_name, self._wait_for_stack_status(self.stack_identifier, 'UPDATE_FAILED') @decorators.idempotent_id('0ac301c2-b377-49b8-82e2-2458634bc8cf') def test_update_stack_contain_external_ref(self): self._stack_create(self.TEMPLATE_WITH_EX_REF) stack = self.client.stacks.get(self.stack_identifier) self.assertEqual( [{'description': 'No description given', 'output_key': 'str', 'output_value': 'foobar'}], stack.outputs) # Update Stack without change external_id new_stack_name = self._stack_rand_name() kwargs = {'stack_id': self.stack_identifier, 'stack_name': new_stack_name, 'template': self.TEMPLATE_WITH_EX_REF, 'files': {}, 'disable_rollback': True, 'parameters': {}, 'environment': {} } self.client.stacks.update(**kwargs) self._wait_for_stack_status(self.stack_identifier, 'UPDATE_COMPLETE') expected_resources = {'test1': 'OS::Heat::TestResource'} self.assertEqual(expected_resources, self.list_resources(self.stack_identifier))"," @decorators.idempotent_id('45449bad-18ba-4148-82e6-a6bc1e9a9b04') def test_create_with_external_ref(self): stack_name = self._stack_rand_name() stack_identifier = self.stack_create( stack_name=stack_name, template=self.TEMPLATE_WITH_EX_REF, stack = self.client.stacks.get(stack_identifier) self._wait_for_stack_status(stack_identifier, 'CREATE_COMPLETE') self.list_resources(stack_identifier)) stack = self.client.stacks.get(stack_identifier) stack_name = self._stack_rand_name() stack_identifier = self.stack_create( stack_name=stack_name, template=self.TEMPLATE, files={}, disable_rollback=True, parameters={}, environment={} ) stack = self.client.stacks.get(stack_identifier) self._wait_for_stack_status(stack_identifier, 'CREATE_COMPLETE') expected_resources = {'test1': 'OS::Heat::TestResource'} self.assertEqual(expected_resources, self.list_resources(stack_identifier)) stack = self.client.stacks.get(stack_identifier) stack_name = stack_identifier.split('/')[0] kwargs = {'stack_id': stack_identifier, 'stack_name': stack_name, self._wait_for_stack_status(stack_identifier, 'UPDATE_FAILED')",43,29
openstack%2Fglance~master~I4ddce9c3ed8f393f76a4c81879c68a3cfcf68bbf,openstack/glance,master,I4ddce9c3ed8f393f76a4c81879c68a3cfcf68bbf,Document fileystem drv chunk size option,MERGED,2019-01-21 10:10:37.000000000,2019-03-06 06:23:54.000000000,2019-03-06 06:23:54.000000000,"[{'_account_id': 8543}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-21 10:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c44c58968054cac501dff2b2ec59c8b622532204', 'message': 'Document fileystem drv chunk size option\n\nA new config option has been added to the filesystem driver\nwhich allows specifying the chunk size to be used.\n\nThis change mentions it in the config documentation.\n\nDepends-On: I1559c03308d36ecf9305c7a72ad658ecd1f2dc76\n\nChange-Id: I4ddce9c3ed8f393f76a4c81879c68a3cfcf68bbf\n'}, {'number': 2, 'created': '2019-03-04 10:32:23.000000000', 'files': ['doc/source/configuration/configuring.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/b2b3e53248e5d1ca73a9b873421999831292b3c4', 'message': 'Document fileystem drv chunk size option\n\nA new config option has been added to the filesystem driver\nwhich allows specifying the chunk size to be used.\n\nThis change mentions it in the config documentation.\n\nDepends-On: I1559c03308d36ecf9305c7a72ad658ecd1f2dc76\n\nChange-Id: I4ddce9c3ed8f393f76a4c81879c68a3cfcf68bbf\n'}]",2,632054,b2b3e53248e5d1ca73a9b873421999831292b3c4,13,4,2,8543,,,0,"Document fileystem drv chunk size option

A new config option has been added to the filesystem driver
which allows specifying the chunk size to be used.

This change mentions it in the config documentation.

Depends-On: I1559c03308d36ecf9305c7a72ad658ecd1f2dc76

Change-Id: I4ddce9c3ed8f393f76a4c81879c68a3cfcf68bbf
",git fetch https://review.opendev.org/openstack/glance refs/changes/54/632054/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/configuring.rst'],1,c44c58968054cac501dff2b2ec59c8b622532204,fs_chunk_doc,``filesystem_store_chunk_size=SIZE_IN_BYTES`` Optional. Default: ``65536`` Can only be specified in configuration files. `This option is specific to the filesystem storage backend.` The chunk size used when reading or writing image files. ,,9,0
openstack%2Frpm-packaging~master~If1c42383ac51b7461c6909e2cbde341a9cf3fb97,openstack/rpm-packaging,master,If1c42383ac51b7461c6909e2cbde341a9cf3fb97,Update keystoneauth to 3.13.1,MERGED,2019-03-05 17:06:23.000000000,2019-03-06 06:20:48.000000000,2019-03-06 06:20:48.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 17:06:23.000000000', 'files': ['openstack/keystoneauth1/keystoneauth1.spec.j2', 'openstack/keystoneauth1/0001-Fix-rate-semaphore-for-keystoneclient.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bdfbe9eeb57994d3cf815f39492f62994217660a', 'message': 'Update keystoneauth to 3.13.1\n\nChange-Id: If1c42383ac51b7461c6909e2cbde341a9cf3fb97\n'}]",0,641087,bdfbe9eeb57994d3cf815f39492f62994217660a,10,6,1,8482,,,0,"Update keystoneauth to 3.13.1

Change-Id: If1c42383ac51b7461c6909e2cbde341a9cf3fb97
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/87/641087/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/keystoneauth1/keystoneauth1.spec.j2', 'openstack/keystoneauth1/0001-Fix-rate-semaphore-for-keystoneclient.patch']",2,bdfbe9eeb57994d3cf815f39492f62994217660a,update-ksa,,"From 7b74cc9adb77f025190557e47f6dadae110e6ab5 Mon Sep 17 00:00:00 2001 From: Colleen Murphy <colleen.murphy@suse.de> Date: Tue, 5 Mar 2019 10:00:46 +0100 Subject: [PATCH] Fix rate semaphore for keystoneclient When using keystoneclient sessions, the new parameter is not available and breaks the keystoneclient unit tests[1]. Only use the semaphore kwarg when using keystoneauth sessions. [1] https://review.openstack.org/640953 Change-Id: I0cc7f2514e143ec532d8fb895618f7cf1fea9cc3 --- keystoneauth1/adapter.py | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) diff --git a/keystoneauth1/adapter.py b/keystoneauth1/adapter.py index a15fd54..6bba62f 100644 --- a/keystoneauth1/adapter.py +++ b/keystoneauth1/adapter.py @@ -217,6 +217,8 @@ class Adapter(object): kwargs.setdefault('client_name', self.client_name) if self.client_version: kwargs.setdefault('client_version', self.client_version) + if self._rate_semaphore: + kwargs.setdefault('rate_semaphore', self._rate_semaphore) else: warnings.warn('Using keystoneclient sessions has been deprecated. ' @@ -232,8 +234,6 @@ class Adapter(object): if self.raise_exc is not None: kwargs.setdefault('raise_exc', self.raise_exc) - kwargs.setdefault('rate_semaphore', self._rate_semaphore) - return self.session.request(url, method, **kwargs) def get_token(self, auth=None): -- 2.21.0 ",1,44
openstack%2Frpm-packaging~master~I9177a18eebdc3fb269aa9c1794ee639644ec96b1,openstack/rpm-packaging,master,I9177a18eebdc3fb269aa9c1794ee639644ec96b1,oslo.log: Update to 3.42.3,MERGED,2019-03-05 13:30:40.000000000,2019-03-06 06:20:41.000000000,2019-03-06 06:20:41.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 13:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6d3cc87db4038668915df0e829c747636c027f8d', 'message': 'oslo.log: Update to 3.42.3\n\nChange-Id: I9177a18eebdc3fb269aa9c1794ee639644ec96b1\n'}, {'number': 2, 'created': '2019-03-05 20:55:35.000000000', 'files': ['openstack/oslo.log/oslo.log.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4805b1cd2b87531a6700e8ae77d324eeb3a604c7', 'message': 'oslo.log: Update to 3.42.3\n\nChange-Id: I9177a18eebdc3fb269aa9c1794ee639644ec96b1\n'}]",0,641012,4805b1cd2b87531a6700e8ae77d324eeb3a604c7,14,6,2,7102,,,0,"oslo.log: Update to 3.42.3

Change-Id: I9177a18eebdc3fb269aa9c1794ee639644ec96b1
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/12/641012/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.log/oslo.log.spec.j2'],1,6d3cc87db4038668915df0e829c747636c027f8d,,{% set upstream_version = upstream_version('3.42.3') %},{% set upstream_version = upstream_version('3.42.2') %},1,1
openstack%2Frpm-packaging~master~I6b97711418b7bfdcdcecba1d2bb807a594bdc8ae,openstack/rpm-packaging,master,I6b97711418b7bfdcdcecba1d2bb807a594bdc8ae,oslotest: Update to 3.7.1,MERGED,2019-03-05 15:42:39.000000000,2019-03-06 06:20:40.000000000,2019-03-06 06:20:40.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:42:39.000000000', 'files': ['openstack/oslotest/oslotest.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a2a982cacb8524c56b2a8864dfd7e1b50b92cb14', 'message': 'oslotest: Update to 3.7.1\n\nChange-Id: I6b97711418b7bfdcdcecba1d2bb807a594bdc8ae\n'}]",0,641052,a2a982cacb8524c56b2a8864dfd7e1b50b92cb14,9,5,1,7102,,,0,"oslotest: Update to 3.7.1

Change-Id: I6b97711418b7bfdcdcecba1d2bb807a594bdc8ae
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/52/641052/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslotest/oslotest.spec.j2'],1,a2a982cacb8524c56b2a8864dfd7e1b50b92cb14,,{% set pypi_name = 'oslotest' %} {% set upstream_version = upstream_version('3.7.1') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }}Source0: {{ source }},Name: {{ py2name('oslotest') }} Version: 3.7.0 Release: 0Source0: https://files.pythonhosted.org/packages/source/o/oslotest/oslotest-%{version}.tar.gz,9,4
openstack%2Frpm-packaging~master~If2fe6dd5382c08f60dd767300412e616313f8f49,openstack/rpm-packaging,master,If2fe6dd5382c08f60dd767300412e616313f8f49,oslo.policy: Update to 2.1.1,MERGED,2019-03-05 15:23:23.000000000,2019-03-06 06:20:39.000000000,2019-03-06 06:20:39.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:23:23.000000000', 'files': ['openstack/oslo.policy/oslo.policy.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/db6eaa79f5ee4db09095aef5aca0a1654698e55a', 'message': 'oslo.policy: Update to 2.1.1\n\nChange-Id: If2fe6dd5382c08f60dd767300412e616313f8f49\n'}]",0,641035,db6eaa79f5ee4db09095aef5aca0a1654698e55a,9,5,1,7102,,,0,"oslo.policy: Update to 2.1.1

Change-Id: If2fe6dd5382c08f60dd767300412e616313f8f49
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/35/641035/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.policy/oslo.policy.spec.j2'],1,db6eaa79f5ee4db09095aef5aca0a1654698e55a,,{% set upstream_version = upstream_version('2.1.1') %},{% set upstream_version = upstream_version('2.1.0') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~I3a84e3729b5eb62652bec2b29b487c0a2b7951eb,openstack/rpm-packaging,master,I3a84e3729b5eb62652bec2b29b487c0a2b7951eb,osc-lib: Update to 1.12.1,MERGED,2019-03-05 13:34:06.000000000,2019-03-06 06:20:38.000000000,2019-03-06 06:20:38.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 13:34:06.000000000', 'files': ['openstack/osc-lib/osc-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bd4c26f502c1937d2bfca061f8406a8fdc811665', 'message': 'osc-lib: Update to 1.12.1\n\nChange-Id: I3a84e3729b5eb62652bec2b29b487c0a2b7951eb\n'}]",0,641013,bd4c26f502c1937d2bfca061f8406a8fdc811665,9,5,1,7102,,,0,"osc-lib: Update to 1.12.1

Change-Id: I3a84e3729b5eb62652bec2b29b487c0a2b7951eb
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/13/641013/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/osc-lib/osc-lib.spec.j2'],1,bd4c26f502c1937d2bfca061f8406a8fdc811665,,{% set upstream_version = upstream_version('1.12.1') %},"{% set upstream_version = upstream_version('1.12.0') %}BuildRequires: {{ py2pkg('os-client-config', py_versions=['py2', 'py3']) }}Requires: {{ py2pkg('os-client-config') }}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg",1,4
openstack%2Frpm-packaging~master~Ibca06ce3e150e6401ab9c099eeb8b230a32c09f6,openstack/rpm-packaging,master,Ibca06ce3e150e6401ab9c099eeb8b230a32c09f6,oslo.concurrency: Update to 3.29.1,MERGED,2019-03-05 15:09:39.000000000,2019-03-06 06:16:25.000000000,2019-03-06 06:16:25.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:09:39.000000000', 'files': ['openstack/oslo.concurrency/oslo.concurrency.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/840569a09147652483be0e49ca7a38ed93197549', 'message': 'oslo.concurrency: Update to 3.29.1\n\nChange-Id: Ibca06ce3e150e6401ab9c099eeb8b230a32c09f6\n'}]",0,641028,840569a09147652483be0e49ca7a38ed93197549,9,5,1,7102,,,0,"oslo.concurrency: Update to 3.29.1

Change-Id: Ibca06ce3e150e6401ab9c099eeb8b230a32c09f6
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/28/641028/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.concurrency/oslo.concurrency.spec.j2'],1,840569a09147652483be0e49ca7a38ed93197549,,{% set upstream_version = upstream_version('3.29.1') %},{% set upstream_version = upstream_version('3.29.0') %}Requires: {{ py2pkg('iso8601') }}Requires: {{ py2pkg('retrying') }},1,3
openstack%2Frpm-packaging~master~I2629c7ee2e04f561cef1fc67e102024435fad0f4,openstack/rpm-packaging,master,I2629c7ee2e04f561cef1fc67e102024435fad0f4,oslo.rootwrap: Update to 5.15.2,MERGED,2019-03-05 15:35:04.000000000,2019-03-06 06:16:24.000000000,2019-03-06 06:16:24.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:35:04.000000000', 'files': ['openstack/oslo.rootwrap/oslo.rootwrap.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/70afe485a94329dcc55894f6e7b1a1d2af255aa0', 'message': 'oslo.rootwrap: Update to 5.15.2\n\nChange-Id: I2629c7ee2e04f561cef1fc67e102024435fad0f4\n'}]",0,641046,70afe485a94329dcc55894f6e7b1a1d2af255aa0,9,5,1,7102,,,0,"oslo.rootwrap: Update to 5.15.2

Change-Id: I2629c7ee2e04f561cef1fc67e102024435fad0f4
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/46/641046/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.rootwrap/oslo.rootwrap.spec.j2'],1,70afe485a94329dcc55894f6e7b1a1d2af255aa0,,{% set upstream_version = upstream_version('5.15.2') %},"{% set upstream_version = upstream_version('5.15.1') %}BuildRequires: {{ py2pkg('python-subunit', py_versions=['py2', 'py3']) }}BuildRequires: {{ py2pkg('testrepository', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testscenarios', py_versions=['py2', 'py3']) }}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg",1,5
openstack%2Frpm-packaging~master~I3c6662da23f9f992841380a97acb10d91247e51c,openstack/rpm-packaging,master,I3c6662da23f9f992841380a97acb10d91247e51c,mox3: Update to 0.27.0,MERGED,2019-03-02 06:12:53.000000000,2019-03-06 06:16:23.000000000,2019-03-06 06:16:23.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-02 06:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0e331e0b0d94deb6ab58143995bed281cf7bf76c', 'message': 'mox3: Update to 0.27.0\n\nChange-Id: I3c6662da23f9f992841380a97acb10d91247e51c\n'}, {'number': 2, 'created': '2019-03-05 07:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/efe898dfd120d0c00e67afdec68c0106de878e31', 'message': 'mox3: Update to 0.27.0\n\nChange-Id: I3c6662da23f9f992841380a97acb10d91247e51c\n'}, {'number': 3, 'created': '2019-03-05 15:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3b1bd326041fccf68198bd37a517981c2c79d534', 'message': 'mox3: Update to 0.27.0\n\nChange-Id: I3c6662da23f9f992841380a97acb10d91247e51c\n'}, {'number': 4, 'created': '2019-03-05 21:03:48.000000000', 'files': ['openstack/mox3/mox3.spec.j2', 'openstack/mox3/0001-add-python-3.6-unit-test-job.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7b88bb553c4d1283fbe52d17db7aab84efc99fa4', 'message': 'mox3: Update to 0.27.0\n\nChange-Id: I3c6662da23f9f992841380a97acb10d91247e51c\n'}]",0,640580,7b88bb553c4d1283fbe52d17db7aab84efc99fa4,25,5,4,7102,,,0,"mox3: Update to 0.27.0

Change-Id: I3c6662da23f9f992841380a97acb10d91247e51c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/80/640580/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/mox3/mox3.spec.j2', 'openstack/mox3/0001-add-python-3.6-unit-test-job.patch']",2,0e331e0b0d94deb6ab58143995bed281cf7bf76c,,,"From 31b73b936a97bd57525be82624d328585f6fe91b Mon Sep 17 00:00:00 2001 From: Doug Hellmann <doug@doughellmann.com> Date: Tue, 7 Aug 2018 16:17:31 -0400 Subject: [PATCH] add python 3.6 unit test job See the python3-first goal document for details: https://governance.openstack.org/tc/goals/stein/python3-first.html This also modifies a unit test to not attempt to pass the re.LOCALE flag when the regex is a string, which is prohibited in Python 3.6. It would be possible to use a raw bytes object as the regex instead, but we're testing the repr() here and it has a different representation between Python 2 and Python 3. Just use the re.IGNORECASE flag instead for the purposes of the test. Change-Id: I666d49d0a29963bcaef6ca69be34dc4869f6db6f Co-Authored-By: Zane Bitter <zbitter@redhat.com> Story: #2002586 Task: #24322 --- mox3/tests/test_mox.py | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) diff --git a/mox3/tests/test_mox.py b/mox3/tests/test_mox.py index 1b1883b..a1ddb18 100644 --- a/mox3/tests/test_mox.py +++ b/mox3/tests/test_mox.py @@ -320,8 +320,8 @@ class RegexTest(testtools.TestCase): def testReprWithFlags(self): """"""repr should return the regular expression pattern and flags."""""" - self.assertTrue(repr(mox.Regex(r""a\s+b"", flags=4)) == - ""<regular expression 'a\s+b', flags=4>"") + self.assertTrue(repr(mox.Regex(r""a\s+b"", flags=2)) == + ""<regular expression 'a\s+b', flags=2>"") class IsTest(testtools.TestCase): -- 2.17.1 ",2,45
openstack%2Fkolla~master~Id138f12e10102a6dd2cd8d84f2cc47aa29af3972,openstack/kolla,master,Id138f12e10102a6dd2cd8d84f2cc47aa29af3972,Added elasticsearch exporter image for prometheus,MERGED,2019-02-22 14:59:31.000000000,2019-03-06 06:06:02.000000000,2019-03-06 06:06:01.000000000,"[{'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 23717}, {'_account_id': 26285}, {'_account_id': 27420}]","[{'number': 1, 'created': '2019-02-22 14:59:31.000000000', 'files': ['docker/prometheus/prometheus-elasticsearch-exporter/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/bac8fd3686449209ce2fb6e490e2fb19ba58dad5', 'message': 'Added elasticsearch exporter image for prometheus\n\nChange-Id: Id138f12e10102a6dd2cd8d84f2cc47aa29af3972\n'}]",0,638679,bac8fd3686449209ce2fb6e490e2fb19ba58dad5,15,7,1,27420,,,0,"Added elasticsearch exporter image for prometheus

Change-Id: Id138f12e10102a6dd2cd8d84f2cc47aa29af3972
",git fetch https://review.opendev.org/openstack/kolla refs/changes/79/638679/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/prometheus/prometheus-elasticsearch-exporter/Dockerfile.j2'],1,bac8fd3686449209ce2fb6e490e2fb19ba58dad5,prometheus-elasticsearch,"FROM {{ namespace }}/{{ image_prefix }}prometheus-base:{{ tag }} LABEL maintainer=""{{ maintainer }}"" name=""{{ image_name }}"" build-date=""{{ build_date }}"" {% block prometheus_elasticsearch_exporter_header %}{% endblock %} {% block prometheus_elasticsearch_exporter_repository_version %} ENV elasticsearch_exporter_version=1.0.2 {% endblock %} {% block prometheus_elasticsearch_exporter_install %} RUN curl -sSL -o /tmp/elasticsearch_exporter.tar.gz https://github.com/justwatchcom/elasticsearch_exporter/releases/download/v${elasticsearch_exporter_version}/elasticsearch_exporter-${elasticsearch_exporter_version}.linux-{{debian_arch}}.tar.gz \ && tar xvf /tmp/elasticsearch_exporter.tar.gz -C /opt/ \ && rm -f /tmp/elasticsearch_exporter.tar.gz \ && ln -s /opt/elasticsearch_exporter* /opt/elasticsearch_exporter {% endblock %} {% block prometheus_elasticsearch_exporter_footer %}{% endblock %} {% block footer %}{% endblock %} USER prometheus ",,20,0
openstack%2Fpuppet-tripleo~stable%2Frocky~Ibe91986a3d5ed95d8e9b1b55b34165b728ea1788,openstack/puppet-tripleo,stable/rocky,Ibe91986a3d5ed95d8e9b1b55b34165b728ea1788,Prepare 9.4.0 (Rocky) release,MERGED,2019-03-06 05:47:49.000000000,2019-03-06 05:58:34.000000000,2019-03-06 05:58:34.000000000,"[{'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 05:47:49.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ae1f373f7e2fafec3801905c8ea00b15e2edce02', 'message': 'Prepare 9.4.0 (Rocky) release\n\nChange-Id: Ibe91986a3d5ed95d8e9b1b55b34165b728ea1788\n'}]",0,641201,ae1f373f7e2fafec3801905c8ea00b15e2edce02,6,2,1,10873,,,0,"Prepare 9.4.0 (Rocky) release

Change-Id: Ibe91986a3d5ed95d8e9b1b55b34165b728ea1788
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/01/641201/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,ae1f373f7e2fafec3801905c8ea00b15e2edce02,release-rocky," ""version"": ""9.4.0"","," ""version"": ""9.3.1"",",1,1
openstack%2Fcompute-hyperv~master~Ic4ba9e0c2ed5bcd443fa8eaffac06752a97b0103,openstack/compute-hyperv,master,Ic4ba9e0c2ed5bcd443fa8eaffac06752a97b0103,Refresh extended in-use volumes,MERGED,2017-11-14 16:55:50.000000000,2019-03-06 05:39:47.000000000,2017-11-21 11:21:33.000000000,"[{'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-14 16:55:50.000000000', 'files': ['compute_hyperv/nova/driver.py', 'compute_hyperv/nova/volumeops.py', 'compute_hyperv/tests/unit/test_volumeops.py', 'compute_hyperv/tests/unit/test_driver.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/f615b509a2022025f2465341922a2e11427f8822', 'message': ""Refresh extended in-use volumes\n\nThis change enables the 'supports_extend_volume' driver capability,\nupdating cached information about already extended in-use volumes.\n\nNote that this will only work with passthrough disks (iSCSI/FC) for\nthe moment. Also, this only refreshes host side disk information,\na rescan is required on the guest side as well.\n\nChange-Id: Ic4ba9e0c2ed5bcd443fa8eaffac06752a97b0103\nImplements: blueprint hyperv-extend-volume\n""}]",0,519700,f615b509a2022025f2465341922a2e11427f8822,9,3,1,8543,,,0,"Refresh extended in-use volumes

This change enables the 'supports_extend_volume' driver capability,
updating cached information about already extended in-use volumes.

Note that this will only work with passthrough disks (iSCSI/FC) for
the moment. Also, this only refreshes host side disk information,
a rescan is required on the guest side as well.

Change-Id: Ic4ba9e0c2ed5bcd443fa8eaffac06752a97b0103
Implements: blueprint hyperv-extend-volume
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/00/519700/1 && git format-patch -1 --stdout FETCH_HEAD,"['compute_hyperv/nova/driver.py', 'compute_hyperv/nova/volumeops.py', 'compute_hyperv/tests/unit/test_volumeops.py', 'compute_hyperv/tests/unit/test_driver.py']",4,f615b509a2022025f2465341922a2e11427f8822,bp/hyperv-extend-volume," def test_extend_volume(self): mock_instance = fake_instance.fake_instance_obj(self.context) self.driver.extend_volume( mock.sentinel.connection_info, mock_instance) self.driver._volumeops.extend_volume.assert_called_once_with( mock.sentinel.connection_info) ",,38,0
openstack%2Fopenstack-helm~master~I6b9b7543aa1a77661d6a86166af59fde85085513,openstack/openstack-helm,master,I6b9b7543aa1a77661d6a86166af59fde85085513,Ceilometer chart: Add missing definition files,MERGED,2019-03-04 17:39:47.000000000,2019-03-06 05:33:34.000000000,2019-03-06 05:33:34.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-03-04 17:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c7448174858bd4a73cbb0c68e0ee0b57d914f865', 'message': 'Ceilometer chart: Add missing definition files\n\nThis commit adds two missing definition files which are\nmeters.yaml and polling.yaml.\n\nmeters.yaml is the meter definition file that used for\nceilometer notification agent to convert meters.\npolling.yaml is the polling definition file that used for\nceilometer polling agents to pull meters.\n\nChange-Id: I6b9b7543aa1a77661d6a86166af59fde85085513\nStory: 2005019\nTask: 29811\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 2, 'created': '2019-03-05 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/15e16da0432cef0f95bf8eecf00da732d346c8ed', 'message': 'Ceilometer chart: Add missing definition files\n\nThis commit adds two missing definition files which are\nmeters.yaml and polling.yaml.\n\nmeters.yaml is the meter definition file that used for\nceilometer notification agent to convert meters.\npolling.yaml is the polling definition file that used for\nceilometer polling agents to pull meters.\n\nChange-Id: I6b9b7543aa1a77661d6a86166af59fde85085513\nStory: 2005019\nTask: 29811\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 3, 'created': '2019-03-06 04:00:19.000000000', 'files': ['ceilometer/templates/deployment-notification.yaml', 'ceilometer/values.yaml', 'ceilometer/templates/deployment-central.yaml', 'ceilometer/templates/configmap-etc.yaml', 'ceilometer/templates/daemonset-compute.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f9875953731e68c7051b605f7673de25894af69b', 'message': 'Ceilometer chart: Add missing definition files\n\nThis commit adds two missing definition files which are\nmeters.yaml and polling.yaml.\n\nmeters.yaml is the meter definition file that used for\nceilometer notification agent to convert meters.\npolling.yaml is the polling definition file that used for\nceilometer polling agents to pull meters.\n\nChange-Id: I6b9b7543aa1a77661d6a86166af59fde85085513\nStory: 2005019\nTask: 29811\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}]",0,640828,f9875953731e68c7051b605f7673de25894af69b,15,4,3,28435,,,0,"Ceilometer chart: Add missing definition files

This commit adds two missing definition files which are
meters.yaml and polling.yaml.

meters.yaml is the meter definition file that used for
ceilometer notification agent to convert meters.
polling.yaml is the polling definition file that used for
ceilometer polling agents to pull meters.

Change-Id: I6b9b7543aa1a77661d6a86166af59fde85085513
Story: 2005019
Task: 29811
Signed-off-by: Angie Wang <angie.wang@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/28/640828/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/templates/deployment-notification.yaml', 'ceilometer/values.yaml', 'ceilometer/templates/deployment-central.yaml', 'ceilometer/templates/configmap-etc.yaml', 'ceilometer/templates/daemonset-compute.yaml']",5,c7448174858bd4a73cbb0c68e0ee0b57d914f865,bp/support-docker-registry-with-authentication-turned-on, - name: ceilometer-etc mountPath: /etc/ceilometer/polling.yaml subPath: polling.yaml readOnly: true,,330,0
openstack%2Ftripleo-heat-templates~master~Ib34d2ac3d6cb53cc40ec116953338568d1fbc6cd,openstack/tripleo-heat-templates,master,Ib34d2ac3d6cb53cc40ec116953338568d1fbc6cd,image-serve: only uninstall docker-distribution when it was installed,MERGED,2019-03-05 21:38:03.000000000,2019-03-06 05:30:29.000000000,2019-03-06 05:30:29.000000000,"[{'_account_id': 4571}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 21:38:03.000000000', 'files': ['deployment/image-serve/image-serve-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5d8e8bd860f878e2f48ba27cfb4a8b70771ac471', 'message': 'image-serve: only uninstall docker-distribution when it was installed\n\nChange-Id: Ib34d2ac3d6cb53cc40ec116953338568d1fbc6cd\n'}]",0,641130,5d8e8bd860f878e2f48ba27cfb4a8b70771ac471,8,4,1,3153,,,0,"image-serve: only uninstall docker-distribution when it was installed

Change-Id: Ib34d2ac3d6cb53cc40ec116953338568d1fbc6cd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/641130/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/image-serve/image-serve-baremetal-ansible.yaml'],1,5d8e8bd860f878e2f48ba27cfb4a8b70771ac471,upgr," block: - name: check if docker-distribution is installed command: /usr/bin/rpm -q docker-distribution failed_when: false register: docker_distribution_installed check_mode: no - name: Stop, disable docker-distribution systemd: enabled: false state: stopped name: docker-distribution when: docker_distribution_installed.rc == 0 - name: Uninstall docker-distribution package: name=docker-distribution state=absent when: docker_distribution_installed.rc == 0 # TODO(sbaker) migrate docker-distribution data to image-serve"," - name: Stop, disable docker-distribution when: step|int == 3 systemd: enabled: false state: stopped name: docker-distribution package: name=docker-distribution state=absent # TODO(sbaker) migrate docker-distribution data to image-serve",16,8
openstack%2Fpaunch~master~I43d8f44862591f7b77ee8ab4552dce32428e3701,openstack/paunch,master,I43d8f44862591f7b77ee8ab4552dce32428e3701,Deprecate docker runtime,MERGED,2019-03-04 23:34:08.000000000,2019-03-06 05:30:28.000000000,2019-03-06 05:30:28.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 23:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/7d81f3c680306de6074819540d7afcffe0f1ab13', 'message': 'Deprecate docker runtime\n\nThe plan is to deprecate it in Stein and remove it in Train.\nPodman is now the default.\n\nChange-Id: I43d8f44862591f7b77ee8ab4552dce32428e3701\n'}, {'number': 2, 'created': '2019-03-05 13:27:25.000000000', 'files': ['releasenotes/notes/docker_deprecate-a12eb9c4ab7e6567.yaml', 'paunch/runner.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/a6f17e52dedfa7c229b7b8d8e1148aaa77a30916', 'message': 'Deprecate docker runtime\n\nThe plan is to deprecate it in Stein and remove it in Train.\nPodman is now the default.\n\nChange-Id: I43d8f44862591f7b77ee8ab4552dce32428e3701\n'}]",0,640894,a6f17e52dedfa7c229b7b8d8e1148aaa77a30916,15,5,2,3153,,,0,"Deprecate docker runtime

The plan is to deprecate it in Stein and remove it in Train.
Podman is now the default.

Change-Id: I43d8f44862591f7b77ee8ab4552dce32428e3701
",git fetch https://review.opendev.org/openstack/paunch refs/changes/94/640894/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/docker_deprecate-a12eb9c4ab7e6567.yaml', 'paunch/runner.py']",2,7d81f3c680306de6074819540d7afcffe0f1ab13,docker/deprecate, self.log.warning('docker runtime is deprecated in Stein ' 'and will be removed in Train.'),,6,0
openstack%2Fopenstack-helm~master~Ib0ba502215aa0fe959606f15dacf39e2cdd06fe6,openstack/openstack-helm,master,Ib0ba502215aa0fe959606f15dacf39e2cdd06fe6,Ceilometer chart: upgrade the default to ocata,MERGED,2019-03-01 16:23:59.000000000,2019-03-06 05:23:21.000000000,2019-03-06 05:23:21.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-03-01 16:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/86480b5e561f6e378d65651dc895daa8f8f52661', 'message': 'Ceilometer chart: upgrade the default to ocata\n\nUpgrade the default images from newton to ocata and update\nthe following configuration files to align with ocata.\n\nevent_definitions.yaml\npipeline.yaml\npolicy.json\napi_paste.ini\n\nStory: 2005019\nTask: 29773\nChange-Id: Ib0ba502215aa0fe959606f15dacf39e2cdd06fe6\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 2, 'created': '2019-03-05 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3387d8d8e5b8093afb845976f27c8005964eaeb8', 'message': 'Ceilometer chart: upgrade the default to ocata\n\nUpgrade the default images from newton to ocata and update\nthe following configuration files to align with ocata.\n\nevent_definitions.yaml\npipeline.yaml\npolicy.json\napi_paste.ini\n\nStory: 2005019\nTask: 29773\nChange-Id: Ib0ba502215aa0fe959606f15dacf39e2cdd06fe6\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 3, 'created': '2019-03-06 04:00:03.000000000', 'files': ['ceilometer/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/dbc69e392098fdbd9ae5dd5da7988fa1c147f4fa', 'message': 'Ceilometer chart: upgrade the default to ocata\n\nUpgrade the default images from newton to ocata and update\nthe following configuration files to align with ocata.\n\nevent_definitions.yaml\npipeline.yaml\npolicy.json\napi_paste.ini\n\nStory: 2005019\nTask: 29773\nChange-Id: Ib0ba502215aa0fe959606f15dacf39e2cdd06fe6\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}]",0,640427,dbc69e392098fdbd9ae5dd5da7988fa1c147f4fa,14,3,3,28435,,,0,"Ceilometer chart: upgrade the default to ocata

Upgrade the default images from newton to ocata and update
the following configuration files to align with ocata.

event_definitions.yaml
pipeline.yaml
policy.json
api_paste.ini

Story: 2005019
Task: 29773
Change-Id: Ib0ba502215aa0fe959606f15dacf39e2cdd06fe6
Signed-off-by: Angie Wang <angie.wang@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/27/640427/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/values.yaml'],1,86480b5e561f6e378d65651dc895daa8f8f52661,bp/support-docker-registry-with-authentication-turned-on," db_init: docker.io/kolla/ubuntu-source-ceilometer-api:ocata ceilometer_db_sync: docker.io/kolla/ubuntu-source-ceilometer-api:ocata ks_user: docker.io/openstackhelm/heat:ocata ks_service: docker.io/openstackhelm/heat:ocata ks_endpoints: docker.io/openstackhelm/heat:ocata ceilometer_api: docker.io/kolla/ubuntu-source-ceilometer-api:ocata ceilometer_central: docker.io/kolla/ubuntu-source-ceilometer-central:ocata ceilometer_collector: docker.io/kolla/ubuntu-source-ceilometer-collector:ocata ceilometer_compute: docker.io/kolla/ubuntu-source-ceilometer-compute:ocata ceilometer_notification: docker.io/kolla/ubuntu-source-ceilometer-notification:ocata - event_type: 'compute.instance.*' traits: &instance_traits instance_id: fields: payload.instance_id resource_id: fields: payload.instance_id host: fields: publisher_id.`split(., 1, 1)` service: fields: publisher_id.`split(., 0, -1)` memory_mb: fields: payload.memory_mb disk_gb: type: int fields: payload.disk_gb root_gb: type: int fields: payload.root_gb ephemeral_gb: type: int fields: payload.ephemeral_gb vcpus: type: int fields: payload.vcpus instance_type_id: type: int fields: payload.instance_type_id instance_type: fields: payload.instance_type state: fields: payload.state os_architecture: fields: payload.image_meta.'org.openstack__1__architecture' os_version: fields: payload.image_meta.'org.openstack__1__os_version' os_distro: fields: payload.image_meta.'org.openstack__1__os_distro' launched_at: type: datetime fields: payload.launched_at deleted_at: type: datetime fields: payload.deleted_at - event_type: compute.instance.update traits: <<: *instance_traits old_state: fields: payload.old_state <<: *instance_traits audit_period_beginning: type: datetime audit_period_ending: type: datetime - event_type: ['volume.exists', 'volume.create.*', 'volume.delete.*', 'volume.resize.*', 'volume.attach.*', 'volume.detach.*', 'volume.update.*', 'snapshot.exists', 'snapshot.create.*', 'snapshot.delete.*', 'snapshot.update.*'] traits: &cinder_traits availability_zone: fields: payload.availability_zone display_name: fields: payload.display_name - event_type: ['volume.exists', 'volume.create.*', 'volume.delete.*', 'volume.resize.*', 'volume.attach.*', 'volume.detach.*', 'volume.update.*'] traits: <<: *cinder_traits host: fields: payload.host - event_type: ['snapshot.exists', 'snapshot.create.*', 'snapshot.delete.*', 'snapshot.update.*'] traits: <<: *cinder_traits - event_type: ['image_volume_cache.*'] traits: host: fields: payload.host - event_type: ['image.create', 'image.update', 'image.upload', 'image.delete'] traits: &glance_crud name: fields: payload.name created_at: fields: payload.created_at deleted_at: fields: payload.deleted_at size: fields: payload.size traits: &glance_send image_id: fields: payload.image_id destination_ip: fields: payload.destination_ip bytes_sent: type: int fields: payload.bytes_sent traits: &orchestration_crud user_id: fields: ['_context_trustor_user_id', '_context_user_id'] traits: &sahara_crud resource_id: fields: payload.cluster_id traits: &sahara_health <<: *sahara_crud health_check_status: fields: payload.health_check_status health_check_name: fields: payload.health_check_name health_check_description: fields: payload.health_check_description created_at: type: datetime fields: payload.created_at updated_at: type: datetime fields: payload.updated_at - event_type: ['identity.user.*', 'identity.project.*', 'identity.group.*', 'identity.role.*', 'identity.OS-TRUST:trust.*', 'identity.region.*', 'identity.service.*', 'identity.endpoint.*', 'identity.policy.*'] traits: &identity_crud resource_id: fields: payload.resource_info domain_id: fields: payload.initiator.domain_id traits: &identity_role_assignment group: fields: payload.group domain: fields: payload.domain project: fields: payload.project traits: &identity_authenticate typeURI: fields: payload.typeURI action: fields: payload.action eventType: fields: payload.eventType eventTime: fields: payload.eventTime outcome: fields: payload.outcome initiator_typeURI: fields: payload.initiator.typeURI initiator_host_agent: fields: payload.initiator.host.agent initiator_host_addr: fields: payload.initiator.host.address target_id: fields: payload.target.id observer_typeURI: fields: payload.observer.typeURI observer_id: fields: payload.observer.id - event_type: objectstore.http.request traits: &objectstore_request action: fields: payload.action eventType: fields: payload.eventType eventTime: fields: payload.eventTime outcome: fields: payload.outcome initiator_typeURI: fields: payload.initiator.typeURI target_typeURI: fields: payload.target.typeURI target_action: fields: payload.target.action target_metadata_container: fields: payload.target.metadata.container target_metadata_object: fields: payload.target.metadata.object observer_id: fields: payload.observer.id - event_type: ['network.*', 'subnet.*', 'port.*', 'router.*', 'floatingip.*', 'pool.*', 'vip.*', 'member.*', 'health_monitor.*', 'healthmonitor.*', 'listener.*', 'loadbalancer.*', 'firewall.*', 'firewall_policy.*', 'firewall_rule.*', 'vpnservice.*', 'ipsecpolicy.*', 'ikepolicy.*', 'ipsec_site_connection.*'] traits: &network_traits project_id: fields: _context_tenant_id <<: *network_traits resource_id: fields: ['payload.network.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.subnet.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.port.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.router.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.floatingip.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.pool.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.vip.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.member.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.health_monitor.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.healthmonitor.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.listener.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.loadbalancer.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.firewall.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.firewall_policy.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.firewall_rule.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.vpnservice.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.ipsecpolicy.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.ikepolicy.id', 'payload.id'] <<: *network_traits resource_id: fields: ['payload.ipsec_site_connection.id', 'payload.id'] traits: &http_audit project_id: fields: payload.initiator.project_id user_id: fields: payload.initiator.id typeURI: fields: payload.typeURI action: fields: payload.action outcome: fields: payload.outcome eventTime: fields: payload.eventTime requestPath: fields: payload.requestPath observer_id: fields: payload.observer.id target_id: fields: payload.target.id target_typeURI: fields: payload.target.typeURI target_name: fields: payload.target.name initiator_typeURI: fields: payload.initiator.typeURI initiator_host_address: fields: payload.initiator.host.address <<: *http_audit - event_type: ['dns.domain.create', 'dns.domain.update', 'dns.domain.delete'] traits: &dns_domain_traits retry: fields: payload.retry description: fields: payload.description expire: fields: payload.expire email: fields: payload.email action: fields: payload.action name: fields: payload.name resource_id: fields: payload.id created_at: fields: payload.created_at parent_domain_id: fields: parent_domain_id serial: fields: payload.serial <<: *dns_domain_traits audit_period_beginning: type: datetime audit_period_ending: type: datetime traits: &trove_base_traits state: fields: payload.state_description user_id: fields: payload.user_id resource_id: fields: payload.instance_id fields: payload.launched_at instance_name: fields: payload.instance_name nova_instance_id: fields: payload.nova_instance_id service_id: fields: payload.service_id created_at: type: datetime fields: payload.created_at region: fields: payload.region - event_type: ['trove.instance.create', 'trove.instance.modify_volume', 'trove.instance.modify_flavor', 'trove.instance.delete'] traits: &trove_common_traits name: fields: payload.name fields: payload.instance_size volume_size: type: int fields: payload.volume_size <<: [*trove_base_traits, *trove_common_traits] <<: [*trove_base_traits, *trove_common_traits] old_volume_size: type: int modify_at: type: datetime fields: payload.modify_at <<: [*trove_base_traits, *trove_common_traits] old_instance_size: type: int modify_at: type: datetime fields: payload.modify_at <<: [*trove_base_traits, *trove_common_traits] deleted_at: type: datetime <<: *trove_base_traits audit_period_beginning: fields: payload.audit_period_beginning audit_period_ending: type: datetime fields: payload.audit_period_ending name: fields: payload.name base_id: fields: payload.base_id parent_id: fields: payload.parent_id timestamp: fields: payload.timestamp host: fields: payload.info.host path: fields: payload.info.request.path query: fields: payload.info.request.query method: fields: payload.info.request.method scheme: fields: payload.info.request.scheme db.statement: fields: payload.info.db.statement db.params: fields: payload.info.db.params - event_type: 'magnum.bay.*' traits: &magnum_bay_crud typeURI: fields: payload.typeURI eventType: fields: payload.eventType eventTime: fields: payload.eventTime action: fields: payload.action outcome: fields: payload.outcome initiator_name: fields: payload.initiator.name initiator_host_agent: fields: payload.initiator.host.agent initiator_host_address: fields: payload.initiator.host.address target_id: fields: payload.target.id target_typeURI: fields: payload.target.typeURI - notifier:// host: resource_metadata.(instance_host|host) - memory.bandwidth.total - memory.bandwidth.local - cpu_l3_cache - compute.instance.booting.time - perf.cpu.cycles - perf.instructions - perf.cache.references - perf.cache.misses - network.outgoing.packets.drop - network.incoming.packets.drop - network.outgoing.packets.error - network.incoming.packets.error - event_delete: floatingip.delete.end event_attributes: id: resource_id metrics: volume_type: resource_metadata.volume_type event_delete: volume.delete.start event_attributes: id: resource_id - snapshot.size - volume.snapshot.size - volume.backup.size oslo_config_project: 'ceilometer' 'filter:cors': oslo_config_project: 'ceilometer' oslo_config_project: 'ceilometer' oslo_config_project: 'ceilometer' sources: - name: meter_source meters: - ""*"" - name: cpu_source meters: - ""cpu"" - name: disk_source meters: - ""disk.read.bytes"" - ""disk.read.requests"" - ""disk.write.bytes"" - ""disk.write.requests"" - ""disk.device.read.bytes"" - ""disk.device.read.requests"" - ""disk.device.write.bytes"" - ""disk.device.write.requests"" - name: network_source meters: - ""network.incoming.bytes"" - ""network.incoming.packets"" - ""network.outgoing.bytes"" - ""network.outgoing.packets"" sinks: - name: meter_sink transformers: publishers: - notifier:// - name: cpu_sink transformers: - name: ""rate_of_change"" parameters: target: name: ""cpu_util"" unit: ""%"" type: ""gauge"" max: 100 scale: ""100.0 / (10**9 * (resource_metadata.cpu_number or 1))"" publishers: - notifier:// - name: cpu_delta_sink transformers: - name: ""delta"" parameters: target: name: ""cpu.delta"" growth_only: True publishers: - notifier:// - name: disk_sink transformers: - name: ""rate_of_change"" parameters: source: map_from: name: ""(disk\\.device|disk)\\.(read|write)\\.(bytes|requests)"" unit: ""(B|request)"" target: map_to: name: ""\\1.\\2.\\3.rate"" unit: ""\\1/s"" type: ""gauge"" publishers: - notifier:// - name: network_sink transformers: - name: ""rate_of_change"" parameters: source: map_from: name: ""network\\.(incoming|outgoing)\\.(bytes|packets)"" unit: ""(B|packet)"" target: map_to: name: ""network.\\1.\\2.rate"" unit: ""\\1/s"" type: ""gauge"" publishers: - notifier:// policy: 'context_is_admin': 'role:admin' 'segregation': 'rule:context_is_admin'"," db_init: docker.io/kolla/ubuntu-source-ceilometer-api:3.0.3 ceilometer_db_sync: docker.io/kolla/ubuntu-source-ceilometer-api:3.0.3 ks_user: docker.io/openstackhelm/heat:newton ks_service: docker.io/openstackhelm/heat:newton ks_endpoints: docker.io/openstackhelm/heat:newton ceilometer_api: quay.io/larryrensing/ubuntu-source-ceilometer-api:3.0.3 ceilometer_central: quay.io/larryrensing/ubuntu-source-ceilometer-central:3.0.3 ceilometer_collector: quay.io/larryrensing/ubuntu-source-ceilometer-collector:3.0.3 ceilometer_compute: quay.io/larryrensing/ubuntu-source-ceilometer-compute:3.0.3 ceilometer_notification: quay.io/larryrensing/ubuntu-source-ceilometer-notification:3.0.3 - event_type: compute.instance.* traits: deleted_at: fields: payload.deleted_at type: datetime disk_gb: fields: payload.disk_gb type: int ephemeral_gb: fields: payload.ephemeral_gb type: int host: fields: 'publisher_id.`split(., 1, 1)`' instance_id: fields: payload.instance_id instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id type: int launched_at: fields: payload.launched_at type: datetime memory_mb: fields: payload.memory_mb type: int os_architecture: fields: payload.image_meta.'org.openstack__1__architecture' os_distro: fields: payload.image_meta.'org.openstack__1__os_distro' os_version: fields: payload.image_meta.'org.openstack__1__os_version' root_gb: fields: payload.root_gb type: int service: fields: 'publisher_id.`split(., 0, -1)`' state: fields: payload.state vcpus: fields: payload.vcpus audit_period_beginning: type: datetime audit_period_ending: type: datetime deleted_at: fields: payload.deleted_at type: datetime disk_gb: fields: payload.disk_gb type: int ephemeral_gb: fields: payload.ephemeral_gb type: int host: fields: 'publisher_id.`split(., 1, 1)`' instance_id: fields: payload.instance_id instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id type: int launched_at: fields: payload.launched_at type: datetime memory_mb: fields: payload.memory_mb type: int os_architecture: fields: payload.image_meta.'org.openstack__1__architecture' os_distro: fields: payload.image_meta.'org.openstack__1__os_distro' os_version: fields: payload.image_meta.'org.openstack__1__os_version' root_gb: fields: payload.root_gb type: int service: fields: 'publisher_id.`split(., 0, -1)`' state: fields: payload.state tenant_id: fields: payload.tenant_id vcpus: fields: payload.vcpus type: int - event_type: - volume.exists - volume.create.* - volume.delete.* - volume.resize.* - volume.attach.* - volume.detach.* - volume.update.* - snapshot.exists - snapshot.create.* - snapshot.delete.* - snapshot.update.* traits: availability_zone: fields: payload.availability_zone created_at: fields: payload.created_at display_name: fields: payload.display_name user_id: fields: payload.user_id - event_type: - volume.exists - volume.create.* - volume.delete.* - volume.resize.* - volume.attach.* - volume.detach.* - volume.update.* traits: availability_zone: fields: payload.availability_zone display_name: fields: payload.display_name host: fields: payload.host project_id: fields: payload.tenant_id replication_status: fields: payload.replication_status status: fields: payload.status user_id: fields: payload.user_id - event_type: - snapshot.exists - snapshot.create.* - snapshot.delete.* - snapshot.update.* traits: availability_zone: fields: payload.availability_zone created_at: fields: payload.created_at display_name: fields: payload.display_name project_id: fields: payload.tenant_id status: fields: payload.status user_id: fields: payload.user_id - event_type: - image_volume_cache.* traits: host: fields: payload.host - event_type: - image.create - image.update - image.upload - image.delete traits: created_at: fields: payload.created_at deleted_at: fields: payload.deleted_at name: fields: payload.name size: fields: payload.size traits: bytes_sent: fields: payload.bytes_sent type: int destination_ip: fields: payload.destination_ip image_id: fields: payload.image_id traits: user_id: fields: - _context_trustor_user_id - _context_user_id traits: resource_id: fields: payload.cluster_id traits: created_at: fields: payload.created_at type: datetime health_check_description: fields: payload.health_check_description health_check_name: fields: payload.health_check_name health_check_status: fields: payload.health_check_status project_id: fields: payload.project_id resource_id: fields: payload.cluster_id updated_at: fields: payload.updated_at type: datetime user_id: fields: _context_user_id - event_type: - identity.user.* - identity.project.* - identity.group.* - identity.role.* - 'identity.OS-TRUST:trust.*' - identity.region.* - identity.service.* - identity.endpoint.* - identity.policy.* traits: domain_id: fields: payload.initiator.domain_id resource_id: fields: payload.resource_info traits: domain: fields: payload.domain group: fields: payload.group project: fields: payload.project traits: action: fields: payload.action eventTime: fields: payload.eventTime eventType: fields: payload.eventType initiator_host_addr: fields: payload.initiator.host.address initiator_host_agent: fields: payload.initiator.host.agent initiator_typeURI: fields: payload.initiator.typeURI observer_id: fields: payload.observer.id observer_typeURI: fields: payload.observer.typeURI outcome: fields: payload.outcome target_id: fields: payload.target.id - event_type: objectstore.http.request traits: action: fields: payload.action eventTime: fields: payload.eventTime eventType: fields: payload.eventType initiator_typeURI: fields: payload.initiator.typeURI observer_id: fields: payload.observer.id outcome: fields: payload.outcome target_action: fields: payload.target.action target_metadata_container: fields: payload.target.metadata.container target_metadata_object: fields: payload.target.metadata.object target_typeURI: fields: payload.target.typeURI typeURI: fields: payload.typeURI - event_type: - network.* - subnet.* - port.* - router.* - floatingip.* - pool.* - vip.* - member.* - health_monitor.* - healthmonitor.* - listener.* - loadbalancer.* - firewall.* - firewall_policy.* - firewall_rule.* - vpnservice.* - ipsecpolicy.* - ikepolicy.* - ipsec_site_connection.* traits: project_id: fields: _context_tenant_id project_id: fields: _context_tenant_id resource_id: fields: - payload.network.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.subnet.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.port.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.router.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.floatingip.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.pool.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.vip.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.member.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.health_monitor.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.healthmonitor.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.listener.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.loadbalancer.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.firewall.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.firewall_policy.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.firewall_rule.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.vpnservice.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.ipsecpolicy.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.ikepolicy.id - payload.id user_id: fields: _context_user_id project_id: fields: _context_tenant_id resource_id: fields: - payload.ipsec_site_connection.id - payload.id user_id: fields: _context_user_id traits: action: fields: payload.action eventTime: fields: payload.eventTime initiator_host_address: fields: payload.initiator.host.address initiator_typeURI: fields: payload.initiator.typeURI observer_id: fields: payload.observer.id outcome: fields: payload.outcome project_id: fields: payload.initiator.project_id requestPath: fields: payload.requestPath target_id: fields: payload.target.id target_name: fields: payload.target.name target_typeURI: fields: payload.target.typeURI typeURI: fields: payload.typeURI user_id: fields: payload.initiator.id action: fields: payload.action eventTime: fields: payload.eventTime eventType: fields: payload.eventType id: fields: payload.id initiator_host_address: fields: payload.initiator.host.address initiator_id: fields: payload.initiator.id initiator_name: fields: payload.initiator.name initiator_typeURI: fields: payload.initiator.typeURI observer_id: fields: payload.observer.id outcome: fields: payload.outcome project_id: fields: payload.initiator.project_id requestPath: fields: payload.requestPath target_id: fields: payload.target.id target_name: fields: payload.target.name target_typeURI: fields: payload.target.typeURI typeURI: fields: payload.typeURI user_id: fields: payload.initiator.id - event_type: - dns.domain.create - dns.domain.update - dns.domain.delete traits: action: fields: payload.action created_at: fields: payload.created_at description: fields: payload.description email: fields: payload.email expire: fields: payload.expire name: fields: payload.name parent_domain_id: fields: parent_domain_id resource_id: fields: payload.id retry: fields: payload.retry serial: fields: payload.serial action: fields: payload.action audit_period_beginning: type: datetime audit_period_ending: type: datetime created_at: fields: payload.created_at description: fields: payload.description email: fields: payload.email expire: fields: payload.expire name: fields: payload.name parent_domain_id: fields: parent_domain_id resource_id: fields: payload.id retry: fields: payload.retry serial: fields: payload.serial status: fields: payload.status ttl: fields: payload.ttl updated_at: fields: payload.updated_at version: fields: payload.version traits: created_at: fields: payload.created_at type: datetime instance_name: fields: payload.instance_name fields: payload.launched_at nova_instance_id: fields: payload.nova_instance_id region: fields: payload.region resource_id: fields: payload.instance_id service_id: fields: payload.service_id user_id: fields: payload.user_id - event_type: - trove.instance.create - trove.instance.modify_volume - trove.instance.modify_flavor - trove.instance.delete traits: fields: payload.instance_size name: fields: payload.name volume_size: fields: payload.volume_size type: int availability_zone: fields: payload.availability_zone created_at: fields: payload.created_at type: datetime instance_name: fields: payload.instance_name instance_size: fields: payload.instance_size type: int instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id launched_at: fields: payload.launched_at type: datetime name: fields: payload.name nova_instance_id: fields: payload.nova_instance_id nova_volume_id: fields: payload.nova_volume_id region: fields: payload.region resource_id: fields: payload.instance_id service_id: fields: payload.service_id state: fields: payload.state user_id: fields: payload.user_id volume_size: fields: payload.volume_size type: int availability_zone: fields: payload.availability_zone created_at: fields: payload.created_at type: datetime instance_name: fields: payload.instance_name instance_size: fields: payload.instance_size type: int instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id launched_at: fields: payload.launched_at type: datetime modify_at: fields: payload.modify_at type: datetime name: fields: payload.name nova_instance_id: fields: payload.nova_instance_id nova_volume_id: fields: payload.nova_volume_id old_volume_size: type: int region: fields: payload.region resource_id: fields: payload.instance_id service_id: fields: payload.service_id state: fields: payload.state user_id: fields: payload.user_id volume_size: fields: payload.volume_size type: int availability_zone: fields: payload.availability_zone created_at: fields: payload.created_at type: datetime instance_name: fields: payload.instance_name instance_size: fields: payload.instance_size type: int instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id launched_at: fields: payload.launched_at type: datetime modify_at: fields: payload.modify_at type: datetime name: fields: payload.name nova_instance_id: fields: payload.nova_instance_id nova_volume_id: fields: payload.nova_volume_id old_instance_size: type: int region: fields: payload.region resource_id: fields: payload.instance_id service_id: fields: payload.service_id state: fields: payload.state user_id: fields: payload.user_id volume_size: fields: payload.volume_size type: int availability_zone: fields: payload.availability_zone created_at: fields: payload.created_at type: datetime deleted_at: type: datetime instance_name: fields: payload.instance_name instance_size: fields: payload.instance_size type: int instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id launched_at: fields: payload.launched_at type: datetime name: fields: payload.name nova_instance_id: fields: payload.nova_instance_id nova_volume_id: fields: payload.nova_volume_id region: fields: payload.region resource_id: fields: payload.instance_id service_id: fields: payload.service_id state: fields: payload.state user_id: fields: payload.user_id volume_size: fields: payload.volume_size type: int audit_period_beginning: fields: payload.audit_period_beginning type: datetime audit_period_ending: fields: payload.audit_period_ending type: datetime created_at: fields: payload.created_at type: datetime instance_name: fields: payload.instance_name instance_type: fields: payload.instance_type instance_type_id: fields: payload.instance_type_id launched_at: fields: payload.launched_at nova_instance_id: fields: payload.nova_instance_id region: fields: payload.region resource_id: fields: payload.instance_id service_id: fields: payload.service_id state: fields: payload.state user_id: fields: payload.user_id base_id: fields: payload.base_id db.params: fields: payload.info.db.params db.statement: fields: payload.info.db.statement host: fields: payload.info.host method: fields: payload.info.request.method name: fields: payload.name parent_id: fields: payload.parent_id path: fields: payload.info.request.path query: fields: payload.info.request.query scheme: fields: payload.info.request.scheme timestamp: fields: payload.timestamp - event_type: magnum.bay.* traits: action: fields: payload.action eventTime: fields: payload.eventTime eventType: fields: payload.eventType initiator_host_address: fields: payload.initiator.host.address initiator_host_agent: fields: payload.initiator.host.agent initiator_name: fields: payload.initiator.name outcome: fields: payload.outcome target_id: fields: payload.target.id target_typeURI: fields: payload.target.typeURI typeURI: fields: payload.typeURI - 'notifier://' host: resource_metadata.host - instance - network.incoming.packets - image - metrics: - volume.create - volume.delete - volume.update - volume.resize - volume.attach - volume.detach 'filter:cors': oslo_config_project: ceilometer oslo_config_project: ceilometer sinks: - name: meter_sink publishers: - 'notifier://' transformers: null - name: cpu_sink publishers: - 'notifier://' transformers: - name: rate_of_change parameters: target: name: cpu_util scale: 100.0 / (10**9 * (resource_metadata.cpu_number or 1)) type: gauge unit: '%' - name: cpu_delta_sink publishers: - 'notifier://' transformers: - name: delta parameters: growth_only: true target: name: cpu.delta - name: disk_sink publishers: - 'notifier://' transformers: - name: rate_of_change parameters: source: map_from: name: (disk\.device|disk)\.(read|write)\.(bytes|requests) unit: (B|request) target: map_to: name: \1.\2.\3.rate unit: \1/s type: gauge - name: network_sink publishers: - 'notifier://' transformers: - name: rate_of_change parameters: source: map_from: name: network\.(incoming|outgoing)\.(bytes|packets) unit: (B|packet) target: map_to: name: network.\1.\2.rate unit: \1/s type: gauge sources: - interval: 600 meters: - '*' name: meter_source - interval: 600 meters: - cpu name: cpu_source - interval: 600 meters: - disk.read.bytes - disk.read.requests - disk.write.bytes - disk.write.requests - disk.device.read.bytes - disk.device.read.requests - disk.device.write.bytes - disk.device.write.requests name: disk_source - interval: 600 meters: - network.incoming.bytes - network.incoming.packets - network.outgoing.bytes - network.outgoing.packets name: network_source policy: context_is_admin: 'role:admin' segregation: 'rule:context_is_admin'",465,897
openstack%2Fopenstack-helm~master~I06afb2cc99726991d6941aabb039379dc78c5d66,openstack/openstack-helm,master,I06afb2cc99726991d6941aabb039379dc78c5d66,Ceilometer chart: replace the obsolete ceilometer upgrade command,MERGED,2019-02-27 16:27:16.000000000,2019-03-06 05:20:29.000000000,2019-03-06 05:20:29.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28208}]","[{'number': 1, 'created': '2019-02-27 16:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9d3f28e02109103682492af3d5572c8640e2b2c7', 'message': 'Ceilometer chart: replace the obsolete ceilometer upgrade command\n\nThe current ceilometer upgrade command ""ceilometer-dbsync"" was\ndeprecated since newton and was removed since ocata. The commit\nupdates to use the replaced command.\n\nStory: 2005019\nTask: 29727\nChange-Id: I06afb2cc99726991d6941aabb039379dc78c5d66\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 2, 'created': '2019-03-01 16:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8abebf26dd6f389f1ecda2ee432906e7c3284cd7', 'message': 'Ceilometer chart: replace the obsolete ceilometer upgrade command\n\nThe current ceilometer upgrade command ""ceilometer-dbsync"" was\ndeprecated since newton and was removed since ocata. The commit\nupdates to use the replaced command.\n\nStory: 2005019\nTask: 29727\nChange-Id: I06afb2cc99726991d6941aabb039379dc78c5d66\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 3, 'created': '2019-03-05 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/879ae55b36a056355861bcd30d6fe8e1158f515b', 'message': 'Ceilometer chart: replace the obsolete ceilometer upgrade command\n\nThe current ceilometer upgrade command ""ceilometer-dbsync"" was\ndeprecated since newton and was removed since ocata. The commit\nupdates to use the replaced command.\n\nStory: 2005019\nTask: 29727\nChange-Id: I06afb2cc99726991d6941aabb039379dc78c5d66\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 4, 'created': '2019-03-06 03:57:43.000000000', 'files': ['ceilometer/templates/bin/_db-sync.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d6984c26b3b40636e4b1aa66ad1a79e012706f61', 'message': 'Ceilometer chart: replace the obsolete ceilometer upgrade command\n\nThe current ceilometer upgrade command ""ceilometer-dbsync"" was\ndeprecated since newton and was removed since ocata. The commit\nupdates to use the replaced command.\n\nStory: 2005019\nTask: 29727\nChange-Id: I06afb2cc99726991d6941aabb039379dc78c5d66\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}]",0,639733,d6984c26b3b40636e4b1aa66ad1a79e012706f61,17,5,4,28435,,,0,"Ceilometer chart: replace the obsolete ceilometer upgrade command

The current ceilometer upgrade command ""ceilometer-dbsync"" was
deprecated since newton and was removed since ocata. The commit
updates to use the replaced command.

Story: 2005019
Task: 29727
Change-Id: I06afb2cc99726991d6941aabb039379dc78c5d66
Signed-off-by: Angie Wang <angie.wang@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/33/639733/3 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/templates/bin/_db-sync.sh.tpl'],1,9d3f28e02109103682492af3d5572c8640e2b2c7,bp/support-docker-registry-with-authentication-turned-on,exec ceilometer-upgrade,exec ceilometer-dbsync,1,1
openstack%2Fnetworking-sfc~master~I09420b93b62ac7e4c23372d13882f0812ec6da59,openstack/networking-sfc,master,I09420b93b62ac7e4c23372d13882f0812ec6da59,DNM: ci test,ABANDONED,2019-03-05 15:52:19.000000000,2019-03-06 05:13:29.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-05 15:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/0f1fd1a71de6a016a7aad304973e60b911728783', 'message': 'DNM: ci test\n\nChange-Id: I09420b93b62ac7e4c23372d13882f0812ec6da59\n'}, {'number': 2, 'created': '2019-03-05 16:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/8518e7b6d3ed76384fcab8f055d5fa0846b12ffb', 'message': 'DNM: ci test\n\nChange-Id: I09420b93b62ac7e4c23372d13882f0812ec6da59\n'}, {'number': 3, 'created': '2019-03-05 17:18:35.000000000', 'files': ['do-not-merge', 'requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/91e9045f48c563b1c75d07b0d6b858639f5e37f3', 'message': 'DNM: ci test\n\nChange-Id: I09420b93b62ac7e4c23372d13882f0812ec6da59\n'}]",0,641058,91e9045f48c563b1c75d07b0d6b858639f5e37f3,5,1,3,10980,,,0,"DNM: ci test

Change-Id: I09420b93b62ac7e4c23372d13882f0812ec6da59
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/58/641058/1 && git format-patch -1 --stdout FETCH_HEAD,['do-not-merge'],1,0f1fd1a71de6a016a7aad304973e60b911728783,ci-test,,,0,0
openstack%2Fneutron~master~I915b4e4c6fcb24c06d231f26d56e16ed10cad7bc,openstack/neutron,master,I915b4e4c6fcb24c06d231f26d56e16ed10cad7bc,DNM: test ci,ABANDONED,2019-03-05 02:01:05.000000000,2019-03-06 05:13:23.000000000,,"[{'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-03-05 02:01:05.000000000', 'files': ['do_not_merge'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca45fd7a6663873a6a382d362f949d2d5739c9de', 'message': 'DNM: test ci\n\nChange-Id: I915b4e4c6fcb24c06d231f26d56e16ed10cad7bc\n'}]",0,640920,ca45fd7a6663873a6a382d362f949d2d5739c9de,6,2,1,10980,,,0,"DNM: test ci

Change-Id: I915b4e4c6fcb24c06d231f26d56e16ed10cad7bc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/640920/1 && git format-patch -1 --stdout FETCH_HEAD,['do_not_merge'],1,ca45fd7a6663873a6a382d362f949d2d5739c9de,ci-test,,,0,0
openstack%2Fheat-tempest-plugin~master~I957d5dea00aab5f17778caf0dcbf81e06cfca36a,openstack/heat-tempest-plugin,master,I957d5dea00aab5f17778caf0dcbf81e06cfca36a,Add tests for validate external ref status in remote stack,ABANDONED,2018-04-18 09:40:24.000000000,2019-03-06 05:04:55.000000000,,"[{'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-04-18 09:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/e85dfd6447baa866f09716a1d221d749f238f81b', 'message': 'Add tests for validate external ref status in remote stack\n\nAdd tests for validate external ref status in remote stack.\nAdd config option `external_stack_status` to allow run\ntests for external stack status.\nRelated-Bug: #1756269\n\nChange-Id: I957d5dea00aab5f17778caf0dcbf81e06cfca36a\n'}, {'number': 2, 'created': '2018-05-10 12:03:56.000000000', 'files': ['heat_tempest_plugin/config.py', 'heat_tempest_plugin/tests/functional/test_remote_stack.py'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/7b29f4ea9860bef169f525b50fe569820487609a', 'message': 'Add tests for validate external ref status in remote stack\n\nAdd tests for validate external ref status in remote stack.\nAdd config option `external_stack_status` to allow run\ntests for external stack status.\nStory: #1756269\n\nChange-Id: I957d5dea00aab5f17778caf0dcbf81e06cfca36a\n'}]",1,562172,7b29f4ea9860bef169f525b50fe569820487609a,9,3,2,12404,,,0,"Add tests for validate external ref status in remote stack

Add tests for validate external ref status in remote stack.
Add config option `external_stack_status` to allow run
tests for external stack status.
Story: #1756269

Change-Id: I957d5dea00aab5f17778caf0dcbf81e06cfca36a
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/72/562172/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat_tempest_plugin/config.py', 'heat_tempest_plugin/tests/functional/test_remote_stack.py']",2,e85dfd6447baa866f09716a1d221d749f238f81b,story/1756269,"from heat_tempest_plugin.common import test def _external_rsrc_create(self, stack_id, ref_stack_status): temp_ex_ref_stack = ''' heat_template_version: newton resources: ext_stack: type: OS::Heat::Stack external_id: %s outputs: str: value: {get_resource: ext_stack} ''' % stack_id ex = self.assertRaises( exc.HTTPBadRequest, self.stack_create, template=temp_ex_ref_stack) error_msg = ('ERROR: Invalid external resource: Resource %s ' '(OS::Heat::Stack) is under %s') % ( stack_id, ref_stack_status) self.assertEqual(error_msg, six.text_type(ex)) @test.requires_feature('external_stack_status') @decorators.idempotent_id('2f039409-b8cc-452e-94ed-3472c79a705f') def test_create_external_ref_to_failed_stack(self): template_failed = ''' heat_template_version: newton resources: test1: type: OS::Heat::TestResource properties: fail: True ''' stack_id = self.stack_create(template=template_failed, expected_status='CREATE_FAILED') expected_resources = {'test1': 'OS::Heat::TestResource'} self.assertEqual(expected_resources, self.list_resources(stack_id)) self._external_rsrc_create(stack_id, 'CREATE_FAILED') @test.requires_feature('external_stack_status') @decorators.idempotent_id('cb1798e4-b364-4d64-bf31-ec5caa0e587e') def test_create_external_ref_to_deleted_stack(self): template = ''' heat_template_version: newton resources: test1: type: OS::Heat::TestResource ''' stack_id = self.stack_create(template=template, expected_status='CREATE_COMPLETE') expected_resources = {'test1': 'OS::Heat::TestResource'} self.assertEqual(expected_resources, self.list_resources(stack_id)) self._stack_delete(stack_id) self._external_rsrc_create(stack_id, 'DELETE_COMPLETE') @test.requires_feature('external_stack_status') @decorators.idempotent_id('25dfa87c-7910-4557-84c9-078d85679ba5') def test_create_external_ref_to_in_progress_stack(self): template = ''' heat_template_version: newton resources: test1: type: OS::Heat::TestResource properties: action_wait_secs: create: 15 ''' stack_id = self.stack_create(template=template, expected_status='CREATE_IN_PROGRESS') self._external_rsrc_create(stack_id, 'CREATE_IN_PROGRESS')",,77,1
openstack%2Fkolla~master~Ib7804441fb3608b955c642014620fcab39d911ef,openstack/kolla,master,Ib7804441fb3608b955c642014620fcab39d911ef,Drop py35 jobs,MERGED,2019-02-27 08:30:21.000000000,2019-03-06 05:03:27.000000000,2019-03-06 05:03:27.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 26285}, {'_account_id': 29759}]","[{'number': 1, 'created': '2019-02-27 08:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/24bde830de13728ea5fcc2ddc5f1026e86946b6c', 'message': '[DNM]Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release. The current\ntarget py3 runtime for Stein is Python 3.6, so there is no reason to\nkeep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: Ib7804441fb3608b955c642014620fcab39d911ef\n'}, {'number': 2, 'created': '2019-02-27 08:57:56.000000000', 'files': ['.zuul.d/ubuntu.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f3568a1ba3718fd0cc019b603941cc4898a90ae6', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release. The current\ntarget py3 runtime for Stein is Python 3.6, so there is no reason to\nkeep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: Ib7804441fb3608b955c642014620fcab39d911ef\n'}]",0,639593,f3568a1ba3718fd0cc019b603941cc4898a90ae6,21,6,2,23717,,,0,"Drop py35 jobs

Python 3.5 was the target runtime for the Rocky release. The current
target py3 runtime for Stein is Python 3.6, so there is no reason to
keep testing against the older version.

https://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein

Change-Id: Ib7804441fb3608b955c642014620fcab39d911ef
",git fetch https://review.opendev.org/openstack/kolla refs/changes/93/639593/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.d/ubuntu.yaml', 'tox.ini']",2,24bde830de13728ea5fcc2ddc5f1026e86946b6c,,"envlist = pep8,py37,py36,py27,pypy","envlist = pep8,py37,py36,py35,py27,pypy",1,2
openstack%2Ftempest~master~Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03,openstack/tempest,master,Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03,no force_tenant_isolation in DefaultDomainTestJSON,MERGED,2017-12-04 16:02:24.000000000,2019-03-06 04:25:54.000000000,2019-03-06 04:25:54.000000000,"[{'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20378}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23186}, {'_account_id': 26285}, {'_account_id': 26297}, {'_account_id': 27078}]","[{'number': 1, 'created': '2017-12-04 16:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/82e3cbd69dfe68cd96c243fa0acf431172b00ea4', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 2, 'created': '2018-07-02 23:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dabde99c3a43c1e977fa3294f476cffd0d6843b4', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 3, 'created': '2018-07-03 03:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/49e866c690bb84f979b50a212f6e809ffd8b4f49', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 4, 'created': '2018-07-03 03:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cdc29cc8fc38ab396d4c93e4c2900ca48a24b147', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 5, 'created': '2018-07-03 06:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cd2fa0514550df846f6d67ddcef998d4399f7f0c', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 6, 'created': '2018-07-03 08:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/43385a7f6f07a606dc4a19f913f5e2d83d710e11', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 7, 'created': '2018-07-07 05:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d0bdebaf654b27d78d6eb32ccc3a97f213496dfb', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 8, 'created': '2018-07-18 18:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d0b753adb8cf26fdba3aa95db1eacd155b3c9dce', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 9, 'created': '2018-07-18 19:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c42100718db016862438585f4f6c565a144b98a', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 10, 'created': '2018-07-19 18:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab77b346f1674cc27fe46c6ae62b30007b7ab9c3', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 11, 'created': '2018-08-01 16:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f68a32b32bd0d4ebe8d57fb97596991002d415ba', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 12, 'created': '2018-09-24 19:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f97419bb442937e746f9c898057797f485ec8c79', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 13, 'created': '2018-10-02 13:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e501535f9cd0c4fb2b19f43ab6cdfedf9c70ea37', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nDepends-On: I83a9b8af775580d36a1141be55e9c1cc283a75b6\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 14, 'created': '2018-12-12 17:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/582e0f00a7597f3f9be657421effd84ab59aade9', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nDepends-On: I83a9b8af775580d36a1141be55e9c1cc283a75b6\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 15, 'created': '2019-02-20 00:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ef017827a7ca928cdee0a4dc7c4b35c3fde2030a', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nDepends-On: I83a9b8af775580d36a1141be55e9c1cc283a75b6\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 16, 'created': '2019-02-28 21:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c0970a0f258a9dbdf15090f490c5ba60d3914e9d', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nDepends-On: I83a9b8af775580d36a1141be55e9c1cc283a75b6\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}, {'number': 17, 'created': '2019-03-04 18:34:02.000000000', 'files': ['tempest/api/identity/v3/test_domains.py', 'tempest/api/identity/admin/v3/test_domains.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d94885df02ea0a4826a1f271f011dfefd2c2ca9', 'message': 'no force_tenant_isolation in DefaultDomainTestJSON\n\nNo need for dynamic credentials to test showing the default domain.\n\nBy setting this value to False, consumers with an immutable user source\ncan execute this test.\n\nDepends-On: I83a9b8af775580d36a1141be55e9c1cc283a75b6\nPartial-Bug: #1714277\nChange-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03\n'}]",10,525244,8d94885df02ea0a4826a1f271f011dfefd2c2ca9,97,13,17,20378,,,0,"no force_tenant_isolation in DefaultDomainTestJSON

No need for dynamic credentials to test showing the default domain.

By setting this value to False, consumers with an immutable user source
can execute this test.

Depends-On: I83a9b8af775580d36a1141be55e9c1cc283a75b6
Partial-Bug: #1714277
Change-Id: Ib85691ae3f7b5a4d4a9da620b6ec46c44380ef03
",git fetch https://review.opendev.org/openstack/tempest refs/changes/44/525244/7 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/v3/test_domains.py'],1,82e3cbd69dfe68cd96c243fa0acf431172b00ea4,bug/1714277, # NOTE: force_tenant_isolation is false to allow test execution for # clouds using the pre-provisioned credentials provider force_tenant_isolation = False,,3,0
openstack%2Fpython-tripleoclient~stable%2Fqueens~Ia97a2367770e37bf8c55f2fd04c9a9efde914a67,openstack/python-tripleoclient,stable/queens,Ia97a2367770e37bf8c55f2fd04c9a9efde914a67,Check that the networks are defined on update,MERGED,2019-03-04 15:52:18.000000000,2019-03-06 04:18:19.000000000,2019-03-06 04:18:18.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 15:52:18.000000000', 'files': ['tripleoclient/tests/test_utils.py', 'tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/utils.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6851fc1b4179c5e4119cff5e2c0d6fc43a622569', 'message': ""Check that the networks are defined on update\n\nCheck defined networks in the resource registry of the stack against the\nnetworks defined in the environment files. If the environment provided\ndoesn't have the networks defined, it's likely they were improperly\ndropped which can lead to deployment issues. This is a light check that\nonly checks for the existance of the networks but not the contents of\nthose networks. This handles the case where a user forgets to include\nthe network-isolation configuration on a subsequent update to the cloud.\nThis does not prevent a user from changing the contents of the networks\nto something that breaks their deployment.\n\nConflicts:\n\ttripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py\n\nPartial-Bug: #1817631\nChange-Id: Ia97a2367770e37bf8c55f2fd04c9a9efde914a67\n(cherry picked from commit 1a71c441fa8958896d7f380636075612c67bf7da)\n(cherry picked from commit ab72340021351a82e51920d56ec2247ac265df08)\n""}]",0,640787,6851fc1b4179c5e4119cff5e2c0d6fc43a622569,7,3,1,14985,,,0,"Check that the networks are defined on update

Check defined networks in the resource registry of the stack against the
networks defined in the environment files. If the environment provided
doesn't have the networks defined, it's likely they were improperly
dropped which can lead to deployment issues. This is a light check that
only checks for the existance of the networks but not the contents of
those networks. This handles the case where a user forgets to include
the network-isolation configuration on a subsequent update to the cloud.
This does not prevent a user from changing the contents of the networks
to something that breaks their deployment.

Conflicts:
	tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py

Partial-Bug: #1817631
Change-Id: Ia97a2367770e37bf8c55f2fd04c9a9efde914a67
(cherry picked from commit 1a71c441fa8958896d7f380636075612c67bf7da)
(cherry picked from commit ab72340021351a82e51920d56ec2247ac265df08)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/87/640787/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/test_utils.py', 'tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/utils.py', 'tripleoclient/v1/overcloud_deploy.py']",4,6851fc1b4179c5e4119cff5e2c0d6fc43a622569,bug/1817631," # note(aschultz): network validation goes here before we deploy utils.check_stack_network_matches_env_files(stack, env)",,134,10
openstack%2Ftripleo-ci~master~If58169e838beebb769446fb8b37cf99cee5e6abc,openstack/tripleo-ci,master,If58169e838beebb769446fb8b37cf99cee5e6abc,Collect /var/lib/container-puppet,MERGED,2019-03-01 20:02:30.000000000,2019-03-06 04:18:18.000000000,2019-03-06 04:18:18.000000000,"[{'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-01 20:02:30.000000000', 'files': ['toci-quickstart/config/collect-logs.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1dd2f103958dc6b5cffac6f4fd0202489b89436e', 'message': 'Collect /var/lib/container-puppet\n\nDepends-On: Ie3d05d18e2471d25c0c4ddaba4feece840b34196\nChange-Id: If58169e838beebb769446fb8b37cf99cee5e6abc\n'}]",0,640504,1dd2f103958dc6b5cffac6f4fd0202489b89436e,8,4,1,3153,,,0,"Collect /var/lib/container-puppet

Depends-On: Ie3d05d18e2471d25c0c4ddaba4feece840b34196
Change-Id: If58169e838beebb769446fb8b37cf99cee5e6abc
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/04/640504/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/collect-logs.yml'],1,1dd2f103958dc6b5cffac6f4fd0202489b89436e,docker2/tasks, - /var/lib/container-puppet/,,1,0
openstack%2Fmanila~master~I108961e7436ba13550ef2b8f02079c6e599a6166,openstack/manila,master,I108961e7436ba13550ef2b8f02079c6e599a6166,Add manage/unmanage of shares in DHSS=True,MERGED,2019-02-08 13:03:25.000000000,2019-03-06 04:10:10.000000000,2019-03-06 01:12:31.000000000,"[{'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15439}, {'_account_id': 16643}, {'_account_id': 18058}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-02-08 13:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/eccf67ad42178cde08e9e25fd0acf1b77e6a7253', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 2, 'created': '2019-02-08 13:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/5247e9a675956306bb6799122c1be7ba3b3b9533', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 3, 'created': '2019-02-08 15:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f311e64e378f50e339fb362f75f78979422f73ed', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 4, 'created': '2019-02-08 17:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fda3aeac424f07b93acf82d1ad9479322c0d1bbe', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nImplements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 5, 'created': '2019-02-08 18:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/5d8d54134706f3a25d973edf847de04b8b2aa211', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 6, 'created': '2019-02-12 12:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/974ae35e5a2f176ad77d489e1e78f6842e9eb233', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 7, 'created': '2019-02-13 10:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7c345e23623e72c7672629cb5fe4432e53948658', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 8, 'created': '2019-02-13 13:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/95ac829338b1dc1cec4f978d124f38b97f7d9868', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 9, 'created': '2019-02-19 10:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/847b92dec70ae790c979199e07435a42c5c35fa2', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 10, 'created': '2019-02-19 16:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/49d7d73bc191d607353dfad4d99ff53f08e54ba8', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 11, 'created': '2019-02-21 17:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/810c7248c81e88b5696414daf9c40ffa73ae769b', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 12, 'created': '2019-02-25 16:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/159e774e20c0701cb666b4928d93a082b458d690', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: https://review.openstack.org/635885/\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 13, 'created': '2019-02-26 18:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ef6bc9c7f3ad50d64c918a032dd5e6887fdcb3ab', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 14, 'created': '2019-02-26 18:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f9944011e6e421801156b87944af7f91e5965f47', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 15, 'created': '2019-02-27 01:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a12fe8c999edf61dabaf15beeb078a811cf193d2', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 16, 'created': '2019-02-27 14:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e298218f7b36d7f387c2a642066bfbb885012862', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 17, 'created': '2019-02-27 14:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7bd61526c3b0daef0b9d3fca55503742bda04171', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 18, 'created': '2019-02-27 22:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c6f11617ee9ac40f51386025cc74c154b2c3021c', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 19, 'created': '2019-02-27 23:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/13c13192c00d4dff6b138851101f1a11fc503ac9', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 20, 'created': '2019-02-28 20:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/db4b8c9eb9718ec53068934b5e9542b5f68c61ca', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\neasily allow this feature to be tested in the CI.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 21, 'created': '2019-02-28 22:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/330bb8b6918bc89c57002c93c2923ffd6e43df40', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 22, 'created': '2019-03-01 17:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b95b6657857460e68bedf79e21fc5287dc7cea48', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 23, 'created': '2019-03-03 19:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3e140ce20ac491bf8b62cf3af342357c85b7ee39', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 24, 'created': '2019-03-03 21:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a64f8cc82df3197fe7d29b1782374a23ade575c6', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 25, 'created': '2019-03-03 21:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b2571e10d4f90dc963d96b389832e4c5b2f8f044', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 26, 'created': '2019-03-04 00:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/36dd5659036fec3799364c50d69979cf46307e0f', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 27, 'created': '2019-03-04 01:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2c2ba5142f6adff6609fbb0585a4d3ae89afe07c', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 28, 'created': '2019-03-04 11:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3dde97c0596ee81ed2fe968bc6b3f1f8283e927a', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 29, 'created': '2019-03-04 18:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/976e8c7f034367d3ac9307a8c393b2114153cc4b', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 30, 'created': '2019-03-05 02:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7498f2b3c90ba97e5c65415822b2b3510df8e0c0', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 31, 'created': '2019-03-05 02:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/744a38bd3f8c9f1c41e66128cc98730eb29de838', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 32, 'created': '2019-03-05 16:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/76319dd787b4b1db28cb550f34f24b892cf0323d', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 33, 'created': '2019-03-05 19:05:42.000000000', 'files': ['manila/network/__init__.py', 'manila/tests/network/neutron/test_neutron_plugin.py', 'contrib/ci/post_test_hook.sh', 'manila/db/migrations/alembic/versions/6a3fd2984bc31_add_is_auto_deletable_and_identifier_fields_for_share_servers.py', 'manila/tests/api/v1/test_share_unmanage.py', 'manila/api/v1/share_manage.py', 'manila/api/openstack/api_version_request.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/tests/share/test_rpcapi.py', 'manila/share/rpcapi.py', 'manila/api/v2/share_snapshots.py', 'manila/tests/api/v2/test_share_snapshots.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/api/v2/test_shares.py', 'manila/api/views/share_servers.py', 'manila/share/manager.py', 'manila/tests/api/v2/test_share_servers.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'releasenotes/notes/manage-unmanage-share-servers-cd4a6523d8e9fbdf.yaml', 'manila/network/standalone_network_plugin.py', 'manila/tests/share/test_manager.py', 'manila/api/v2/router.py', 'manila/db/sqlalchemy/models.py', 'manila/api/v1/share_servers.py', 'manila/tests/fake_driver.py', 'manila/tests/api/v1/test_share_servers.py', 'manila/share/driver.py', 'manila/api/v2/share_servers.py', 'manila/tests/share/drivers/dummy.py', 'manila/tests/fake_share.py', 'manila/api/v1/share_unmanage.py', 'manila/tests/network/test_standalone_network_plugin.py', 'manila/tests/test_network.py', 'manila/tests/test_exception.py', 'manila/tests/api/v1/test_share_manage.py', 'manila/db/api.py', 'manila/tests/share/test_api.py', 'manila/share/api.py', 'manila/tests/api/fakes.py', 'manila/policies/share_server.py', 'manila/exception.py', 'manila/api/v2/shares.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/d877b61c5e37ff012341194b8349af6f38155e5d', 'message': 'Add manage/unmanage of shares in DHSS=True\n\nThis patch adds Manage/Unmanage of share servers in\nManila. It also updates the Manage Share API to accept\na ""share_server_id"" parameter, and updates Unmanage\nof Share and Snapshots API to allow unmanaging of\nshares and snapshots in DHSS=True.\n\nManaged share servers are not deleted automatically\nby manila, and if a single share is unmanaged in\nDHSS=True, the respective share server will not be\ndeleted automatically as well.\n\nManaging share servers require that the driver\nimplements 2 functions:\n- get_share_server_network_info: obtain IPs from\n  share server.\n- manage_server: perform required operations to\n  manage and return dict of backend_details.\n\nUnmanaging share servers require that the driver\noverrides unmanage_server function.\n\nThe IPs obtained from the backend are validated\nby the Network plugin, so ports with the exact\nIPs must exist in the subnet and admin subnet\nassociated with the share network specified\nwhen managing the share server (unless\nStandaloneNetworkPlugin is used).\n\nIt is recommended to rename the backend resource\nif possible when managing the share server, to\nprevent issues with re-managing a share server\nthat has already been managed.\n\nThis patch bumps the API microversion to 2.49.\n\nAPIImpact\nDocImpact\n\nDepends-On: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nChange-Id: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}]",256,635831,d877b61c5e37ff012341194b8349af6f38155e5d,291,18,33,14567,,,0,"Add manage/unmanage of shares in DHSS=True

This patch adds Manage/Unmanage of share servers in
Manila. It also updates the Manage Share API to accept
a ""share_server_id"" parameter, and updates Unmanage
of Share and Snapshots API to allow unmanaging of
shares and snapshots in DHSS=True.

Managed share servers are not deleted automatically
by manila, and if a single share is unmanaged in
DHSS=True, the respective share server will not be
deleted automatically as well.

Managing share servers require that the driver
implements 2 functions:
- get_share_server_network_info: obtain IPs from
  share server.
- manage_server: perform required operations to
  manage and return dict of backend_details.

Unmanaging share servers require that the driver
overrides unmanage_server function.

The IPs obtained from the backend are validated
by the Network plugin, so ports with the exact
IPs must exist in the subnet and admin subnet
associated with the share network specified
when managing the share server (unless
StandaloneNetworkPlugin is used).

It is recommended to rename the backend resource
if possible when managing the share server, to
prevent issues with re-managing a share server
that has already been managed.

This patch bumps the API microversion to 2.49.

APIImpact
DocImpact

Depends-On: I17c74b2aa242918188eeff368232c762a4b31093
Partially-implements: bp manage-unmanage-with-share-servers
Change-Id: I108961e7436ba13550ef2b8f02079c6e599a6166
",git fetch https://review.opendev.org/openstack/manila refs/changes/31/635831/33 && git format-patch -1 --stdout FETCH_HEAD,"['manila/network/__init__.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/tests/api/v1/test_share_unmanage.py', 'manila/api/v1/share_manage.py', 'manila/api/openstack/api_version_request.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/db/migrations/alembic/versions/6a3fd2984bc31_add_is_imported_field_for_share_servers.py', 'manila/api/v2/share_snapshots.py', 'manila/share/drivers/hitachi/hsp/driver.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/api/v1/share_servers.py', 'manila/tests/api/v1/test_share_servers.py', 'manila/share/drivers/maprfs/maprfs_native.py', 'manila/tests/fake_share.py', 'manila/tests/network/test_standalone_network_plugin.py', 'manila/tests/test_network.py', 'manila/tests/api/v1/test_share_manage.py', 'manila/db/api.py', 'manila/tests/share/test_api.py', 'manila/tests/api/fakes.py', 'manila/policies/share_server.py', 'manila/share/drivers/generic.py', 'manila/api/v2/shares.py', 'manila/share/drivers/glusterfs/layout_volume.py', 'manila/tests/network/neutron/test_neutron_plugin.py', 'manila/share/drivers/glusterfs/layout_directory.py', 'manila/share/drivers/hitachi/hnas/driver.py', 'manila/share/drivers/huawei/base.py', 'manila/share/drivers/huawei/huawei_nas.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_single_svm.py', 'manila/tests/share/test_rpcapi.py', 'manila/share/rpcapi.py', 'manila/tests/api/v2/test_share_snapshots.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/api/v2/test_shares.py', 'manila/api/views/share_servers.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/share/manager.py', 'manila/tests/api/v2/test_share_servers.py', 'manila/share/drivers/qnap/qnap.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/tests/share/drivers/glusterfs/test_layout.py', 'releasenotes/notes/manage-unmanage-share-servers-cd4a6523d8e9fbdf.yaml', 'manila/network/standalone_network_plugin.py', 'manila/share/drivers/zfsonlinux/driver.py', 'manila/tests/share/test_manager.py', 'manila/api/v2/router.py', 'manila/share/drivers/huawei/v3/connection.py', 'manila/db/sqlalchemy/models.py', 'manila/tests/fake_driver.py', 'manila/share/driver.py', 'manila/api/v2/share_servers.py', 'manila/tests/share/drivers/dummy.py', 'manila/api/v1/share_unmanage.py', 'manila/tests/test_exception.py', 'manila/share/api.py', 'manila/share/drivers/glusterfs/layout.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/drv_multi_svm.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/exception.py']",61,eccf67ad42178cde08e9e25fd0acf1b77e6a7253,manage-unmanage-with-share-servers,"class ManageShareServerError(ManilaException): message = _(""Manage existing share server failed due to: %(reason)s"") ",,2562,313
openstack%2Fopenstack-helm~master~I7344afbf084b79ea07e07bb02cc4037326ad1b30,openstack/openstack-helm,master,I7344afbf084b79ea07e07bb02cc4037326ad1b30,Update irc meeting channel,MERGED,2019-02-27 06:55:47.000000000,2019-03-06 04:10:00.000000000,2019-03-06 04:10:00.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28208}]","[{'number': 1, 'created': '2019-02-27 06:55:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e1a005b0a7b887cad6b8e2effb8c6039e4d07717', 'message': 'Update irc meeting channel\n\nSeems we have moved from #openstack-meeting-5 to #openstack-meeting-4,\nso update README\n\nChange-Id: I7344afbf084b79ea07e07bb02cc4037326ad1b30\n'}]",0,639578,e1a005b0a7b887cad6b8e2effb8c6039e4d07717,8,4,1,29668,,,0,"Update irc meeting channel

Seems we have moved from #openstack-meeting-5 to #openstack-meeting-4,
so update README

Change-Id: I7344afbf084b79ea07e07bb02cc4037326ad1b30
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/78/639578/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e1a005b0a7b887cad6b8e2effb8c6039e4d07717,update_meeting, #openstack-meeting-4 on freenode, #openstack-meeting-5 on freenode,1,1
openstack%2Fopenstack-helm~master~I149ef6827ca10e32492f2b05beb8a13af5a03fc5,openstack/openstack-helm,master,I149ef6827ca10e32492f2b05beb8a13af5a03fc5,Only run bandit when changing python content,MERGED,2019-02-13 16:36:03.000000000,2019-03-06 04:09:59.000000000,2019-03-06 04:09:58.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 16:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/445df26dbd8b416a9b9a158d60ebabd1e29d6265', 'message': 'Only run bandit when changing python content\n\nThis changes the gate check for bandit to only run when either python\nor templated python files are edited. This will cause the check\nto only be ran when those specific file types are edited, and to\nskip the check when not needed.\n\nChange-Id: I149ef6827ca10e32492f2b05beb8a13af5a03fc5\n'}, {'number': 2, 'created': '2019-03-01 19:36:35.000000000', 'files': ['zuul.d/jobs-openstack-helm.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7406014483d6e84608352bbb50b504d379bc72b7', 'message': 'Only run bandit when changing python content\n\nThis changes the gate check for bandit to only run when either python\nor templated python files are edited. This will cause the check\nto only be ran when those specific file types are edited, and to\nskip the check when not needed.\n\nChange-Id: I149ef6827ca10e32492f2b05beb8a13af5a03fc5\n'}]",0,636664,7406014483d6e84608352bbb50b504d379bc72b7,9,3,2,21420,,,0,"Only run bandit when changing python content

This changes the gate check for bandit to only run when either python
or templated python files are edited. This will cause the check
to only be ran when those specific file types are edited, and to
skip the check when not needed.

Change-Id: I149ef6827ca10e32492f2b05beb8a13af5a03fc5
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/64/636664/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs-openstack-helm.yaml'],1,445df26dbd8b416a9b9a158d60ebabd1e29d6265,osh-bandit, files: - ^.*\.py\.tpl$ - ^.*\.py$, # NOTE(gagehugo): Look into only running this for py.tpl file changes # files: # - ^.*\.py\.tpl$ irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^releasenotes/.*$,3,7
openstack%2Fopenstack-helm~master~I16f77f4cc64caf21b21c8519e6da34eaf5d31498,openstack/openstack-helm,master,I16f77f4cc64caf21b21c8519e6da34eaf5d31498,Increase default logging,MERGED,2019-02-27 15:37:06.000000000,2019-03-06 04:09:57.000000000,2019-03-06 04:09:57.000000000,"[{'_account_id': 7069}, {'_account_id': 8898}, {'_account_id': 9963}, {'_account_id': 12281}, {'_account_id': 17068}, {'_account_id': 17966}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-02-27 15:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c891673ebf789c681e65ba8fd21e4dd28f16fc6c', 'message': 'Increase default logging\n\nThe current helm chart defaults drops logs of any warnings\n(and above) for anything logger outside of the namespace\nof the deployed chart.\n\nThis is a problem, as logging could reveal important operator\ninformation. While this could be done with a value override, there\nis no reason to hide warning, errors, or critical information that\nare happening in the cycle of the operation of the software\ndeployed with the helm charts. For example, nothing would get\nlogged in oslo_service, which is a very important part of running\nOpenStack.\n\nThis fixes it by logging to stdout all the warnings (and above)\nfor OpenStack apps.\n\nChange-Id: I16f77f4cc64caf21b21c8519e6da34eaf5d31498\n'}, {'number': 2, 'created': '2019-02-27 16:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/039df8df6158734339470dd4793fff859885087e', 'message': 'Increase default logging\n\nThe current helm chart defaults drops logs of any warnings\n(and above) for any logger outside of the namespace\nof the deployed chart.\n\nThis is a problem, as logging could reveal important information for\noperators. While this could be done with a value override, there\nis no reason to hide warning, errors, or critical information that\nare happening in the cycle of the operation of the software\ndeployed with the helm charts. For example, nothing would get\nlogged in oslo_service, which is a very important part of running\nOpenStack.\n\nThis fixes it by logging to stdout all the warnings (and above)\nfor OpenStack apps.\n\nChange-Id: I16f77f4cc64caf21b21c8519e6da34eaf5d31498\n'}, {'number': 3, 'created': '2019-02-28 09:53:01.000000000', 'files': ['mistral/values.yaml', 'congress/values.yaml', 'barbican/values.yaml', 'heat/values.yaml', 'cinder/values.yaml', 'magnum/values.yaml', 'releasenotes/notes/increase-default-logging-31db0e9d3e51b429.yaml', 'glance/values.yaml', 'nova/values.yaml', 'ironic/values.yaml', 'keystone/values.yaml', 'neutron/values.yaml', 'senlin/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5890ebf4f860a9b10ddb1aee4c558b72163087c0', 'message': 'Increase default logging\n\nThe current helm chart defaults drops logs of any warnings\n(and above) for any logger outside of the namespace\nof the deployed chart.\n\nThis is a problem, as logging could reveal important information for\noperators. While this could be done with a value override, there\nis no reason to hide warning, errors, or critical information that\nare happening in the cycle of the operation of the software\ndeployed with the helm charts. For example, nothing would get\nlogged in oslo_service, which is a very important part of running\nOpenStack.\n\nThis fixes it by logging to stdout all the warnings (and above)\nfor OpenStack apps.\n\nChange-Id: I16f77f4cc64caf21b21c8519e6da34eaf5d31498\n'}]",2,639711,5890ebf4f860a9b10ddb1aee4c558b72163087c0,24,9,3,17068,,,0,"Increase default logging

The current helm chart defaults drops logs of any warnings
(and above) for any logger outside of the namespace
of the deployed chart.

This is a problem, as logging could reveal important information for
operators. While this could be done with a value override, there
is no reason to hide warning, errors, or critical information that
are happening in the cycle of the operation of the software
deployed with the helm charts. For example, nothing would get
logged in oslo_service, which is a very important part of running
OpenStack.

This fixes it by logging to stdout all the warnings (and above)
for OpenStack apps.

Change-Id: I16f77f4cc64caf21b21c8519e6da34eaf5d31498
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/11/639711/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/values.yaml', 'congress/values.yaml', 'barbican/values.yaml', 'heat/values.yaml', 'cinder/values.yaml', 'magnum/values.yaml', 'releasenotes/notes/increase-default-logging-31db0e9d3e51b429.yaml', 'glance/values.yaml', 'nova/values.yaml', 'ironic/values.yaml', 'keystone/values.yaml', 'neutron/values.yaml', 'senlin/values.yaml']",13,c891673ebf789c681e65ba8fd21e4dd28f16fc6c,increase-logging, handlers: stdout, handlers: 'null',18,12
openstack%2Fcongress~master~I548b4d097452b2f001efc054780be29eb3a73398,openstack/congress,master,I548b4d097452b2f001efc054780be29eb3a73398,JSON ingester API execution feature,MERGED,2019-03-01 01:08:57.000000000,2019-03-06 04:05:30.000000000,2019-03-06 04:05:30.000000000,"[{'_account_id': 18591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 01:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2daf360d80f5371c7fac7ee4cb6352b765b050e3', 'message': 'JSON ingester API execution feature\n\nOperator can define an _exec_api view/table in any schema, including\nthe columns: endpoint, path, method, body, parameters, headers\n(body, parameters, headers may be null).\n\nEach time JSON ingester updates state, Congress will make all the\nAPI requests as specified in these _exec_api views/tables.\n\nThe existing action execution semantics is used: execute any new\nactions not present as of the last time the execution tables are\nchecked.\n\nEach JsonIngester instance now keeps a reference to the shared\nExecApiManager instance. Each time a JsonIngester instance updates\nstate, it tells the ExecApiManager instance to check and execute API\nrequests.\n\npartially-implements: bp json-data-model\nChange-Id: I548b4d097452b2f001efc054780be29eb3a73398\n'}, {'number': 2, 'created': '2019-03-01 18:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9adc9cb880065264ea9ed2fa51f8904321f7df33', 'message': 'JSON ingester API execution feature\n\nOperator can define an _exec_api view/table in any schema, including\nthe columns: endpoint, path, method, body, parameters, headers\n(body, parameters, headers may be null).\n\nEach time JSON ingester updates state, Congress will make all the\nAPI requests as specified in these _exec_api views/tables.\n\nThe existing action execution semantics is used: execute any new\nactions not present as of the last time the execution tables are\nchecked.\n\nEach JsonIngester instance now keeps a reference to the shared\nExecApiManager instance. Each time a JsonIngester instance updates\nstate, it tells the ExecApiManager instance to check and execute API\nrequests.\n\npartially-implements: bp json-data-model\nChange-Id: I548b4d097452b2f001efc054780be29eb3a73398\n'}, {'number': 3, 'created': '2019-03-04 18:43:07.000000000', 'files': ['congress/tests/datasources/json_ingester/test_json_ingester.py', 'congress/datasources/json_ingester/exec_api.py', 'congress/datasources/json_ingester/json_ingester.py', 'congress/harness.py', 'congress/tests/fake_datasource.py', 'congress/tests/etc/datasources/nova.yaml', 'congress/tests/datasources/json_ingester/test_exec_api.py', 'congress/tests/datasources/json_ingester/__init__.py', 'congress/datasources/json_ingester/__init__.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/52e5c23485a52ae8ed6988e73431f2d6c266b3fe', 'message': 'JSON ingester API execution feature\n\nOperator can define an _exec_api view/table in any schema, including\nthe columns: endpoint, path, method, body, parameters, headers\n(body, parameters, headers may be null).\n\nEach time JSON ingester updates state, Congress will make all the\nAPI requests as specified in these _exec_api views/tables.\n\nThe existing action execution semantics is used: execute any new\nactions not present as of the last time the execution tables are\nchecked.\n\nEach JsonIngester instance now keeps a reference to the shared\nExecApiManager instance. Each time a JsonIngester instance updates\nstate, it tells the ExecApiManager instance to check and execute API\nrequests.\n\npartially-implements: bp json-data-model\nChange-Id: I548b4d097452b2f001efc054780be29eb3a73398\n'}]",0,640234,52e5c23485a52ae8ed6988e73431f2d6c266b3fe,14,2,3,18591,,,0,"JSON ingester API execution feature

Operator can define an _exec_api view/table in any schema, including
the columns: endpoint, path, method, body, parameters, headers
(body, parameters, headers may be null).

Each time JSON ingester updates state, Congress will make all the
API requests as specified in these _exec_api views/tables.

The existing action execution semantics is used: execute any new
actions not present as of the last time the execution tables are
checked.

Each JsonIngester instance now keeps a reference to the shared
ExecApiManager instance. Each time a JsonIngester instance updates
state, it tells the ExecApiManager instance to check and execute API
requests.

partially-implements: bp json-data-model
Change-Id: I548b4d097452b2f001efc054780be29eb3a73398
",git fetch https://review.opendev.org/openstack/congress refs/changes/34/640234/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/datasources/json_ingester/test_json_ingester.py', 'congress/datasources/json_ingester/exec_api.py', 'congress/datasources/json_ingester/json_ingester.py', 'congress/harness.py', 'congress/tests/fake_datasource.py', 'congress/tests/etc/datasources/nova.yaml', 'congress/tests/datasources/json_ingester/test_exec_api.py', 'congress/datasources/json_ingester/__init__.py', 'congress/tests/datasources/json_ingester/__init__.py']",9,2daf360d80f5371c7fac7ee4cb6352b765b050e3,json-ingester,,,410,18
openstack%2Fnova~master~I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a,openstack/nova,master,I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a,Ensure that bandwidth and VF are from the same PF,MERGED,2018-12-07 16:18:19.000000000,2019-03-06 04:03:59.000000000,2019-03-06 00:08:01.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15554}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28714}]","[{'number': 1, 'created': '2018-12-07 16:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f94564f89029abcec31dd6c059fa76a723ecde03', 'message': ""Ensure that allocated PF matches the used PF\n\nA neutron port can be created with sriov vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bw request, then the\nnova scheduler's PciPassthroughFilter checks if a PCI device is available\nfor such request. This check is only based on the physnet of the neutron\nport and the physnet tag in the pci whitelist config. But it does not\nconsider that which PF provides the bandwidth.\n\nThe currently unsupported case is when a single compute node has more\nthan one PFs that are connected to the same physnet. This two PFs can have\ntotally different bandwidth inventories in placement. (E.g. PF1 has\nplenty of bandwidth available and PF2 has no bandwidth configured at all).\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF2 still has available VFs even if the bandwidtht from the port\nis fulfilled from PF1 which in return might not have available VFs any\nmore.\n\nMoreover the PciClaim has the same logic as the Filter so it will claim\nthe VF from PF2 while the bandwidth was allocated from PF1 in placement.\n\nTODO:\n * RPs are named after the device name, PCI request are identified by\n   PCI address. We need to be able to map between the two to know that\n   what PCI device can be selected based on the RP uuid that provides\n   the bandwidth.\n * Use a more generic base class for the functional test as the current\n   one creates an unnecessary ovs RP tree and we anyhow need to add more\n   sriov device RPs to placement.\n * Make the functional test show the missing mapping logic in\n * PciPassthroughFilter and in PciClaim\n * Add the missing logic :)\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 2, 'created': '2018-12-10 09:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5d2950b9f3b8e5ffbbef503078bc4f4d9782328', 'message': ""Ensure that allocated PF matches the used PF\n\nA neutron port can be created with sriov vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bw request, then the\nnova scheduler's PciPassthroughFilter checks if a PCI device is available\nfor such request. This check is only based on the physnet of the neutron\nport and the physnet tag in the pci whitelist config. But it does not\nconsider that which PF provides the bandwidth.\n\nThe currently unsupported case is when a single compute node has more\nthan one PFs that are connected to the same physnet. This two PFs can have\ntotally different bandwidth inventories in placement. (E.g. PF1 has\nplenty of bandwidth available and PF2 has no bandwidth configured at all).\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF2 still has available VFs even if the bandwidtht from the port\nis fulfilled from PF1 which in return might not have available VFs any\nmore.\n\nMoreover the PciClaim has the same logic as the Filter so it will claim\nthe VF from PF2 while the bandwidth was allocated from PF1 in placement.\n\nTODO:\n * RPs are named after the device name, PCI request are identified by\n   PCI address. We need to be able to map between the two to know that\n   what PCI device can be selected based on the RP uuid that provides\n   the bandwidth.\n * Use a more generic base class for the functional test as the current\n   one creates an unnecessary ovs RP tree and we anyhow need to add more\n   sriov device RPs to placement.\n * Make the functional test show the missing mapping logic in\n * PciPassthroughFilter and in PciClaim\n * Add the missing logic :)\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 3, 'created': '2018-12-10 13:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cd86cdd3d1e12a750e2e3a381e1397291407ae9', 'message': ""Ensure that allocated PF matches the used PF\n\nA neutron port can be created with sriov vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bw request, then the\nnova scheduler's PciPassthroughFilter checks if a PCI device is available\nfor such request. This check is only based on the physnet of the neutron\nport and the physnet tag in the pci whitelist config. But it does not\nconsider that which PF provides the bandwidth.\n\nThe currently unsupported case is when a single compute node has more\nthan one PFs that are connected to the same physnet. This two PFs can have\ntotally different bandwidth inventories in placement. (E.g. PF2 has\nplenty of bandwidth available and PF3 has no bandwidth configured at all).\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PciClaim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch adds a functional test case to that shows the failure in the\nabove use case.\n\nTODO:\n * add the missing logic in PciClaim\n * add the missing logic if PciPassthroughFilter\n * device RPs are named after the device name, PCI request are identified by\n   PCI address. We need to be able to map between the two to know that\n   what PCI device can be selected based on the RP uuid that provides\n   the bandwidth.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 4, 'created': '2018-12-11 16:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/536693c0d8f25bb77d45864e1fb0c1963c078ca1', 'message': ""Ensure that allocated PF matches the used PF\n\nA neutron port can be created with sriov vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bw request, then the\nnova scheduler's PciPassthroughFilter checks if a PCI device is available\nfor such request. This check is only based on the physnet of the neutron\nport and the physnet tag in the pci whitelist config. But it does not\nconsider that which PF provides the bandwidth.\n\nThe currently unsupported case is when a single compute node has more\nthan one PFs that are connected to the same physnet. This two PFs can have\ntotally different bandwidth inventories in placement. (E.g. PF2 has\nplenty of bandwidth available and PF3 has no bandwidth configured at all).\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PciClaim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch adds a functional test case to that shows the failure in the\nabove use case.\n\nTODO:\n  * split up the patch to smaller pieces (object change, conf change,\n    manager change)\n  * refactor manager code to smaller functions\n  * document the new pci whitelist flag\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 5, 'created': '2018-12-12 17:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0106691ba708b0cf48fd0dfebd60b2195968bf4', 'message': ""Ensure that allocated PF matches the used PF\n\nA neutron port can be created with sriov vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bw request, then the\nnova scheduler's PciPassthroughFilter checks if a PCI device is available\nfor such request. This check is only based on the physnet of the neutron\nport and the physnet tag in the pci whitelist config. But it does not\nconsider that which PF provides the bandwidth.\n\nThe currently unsupported case is when a single compute node has more\nthan one PFs that are connected to the same physnet. This two PFs can have\ntotally different bandwidth inventories in placement. (E.g. PF2 has\nplenty of bandwidth available and PF3 has no bandwidth configured at all).\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PciClaim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch adds a functional test case to that shows the failure in the\nabove use case.\n\nTODO:\n  * split up the patch to smaller pieces (object change, conf change,\n    manager change)\n  * refactor manager code to smaller functions\n  * document the new pci whitelist flag\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 6, 'created': '2018-12-14 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba6f4a26c29df2c68a48fca52d74a7b039d4080b', 'message': ""Ensure that allocated PF matches the used PF\n\nA neutron port can be created with sriov vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bw request, then the\nnova scheduler's PciPassthroughFilter checks if a PCI device is available\nfor such request. This check is only based on the physnet of the neutron\nport and the physnet tag in the pci whitelist config. But it does not\nconsider that which PF provides the bandwidth.\n\nThe currently unsupported case is when a single compute node has more\nthan one PFs that are connected to the same physnet. This two PFs can have\ntotally different bandwidth inventories in placement. (E.g. PF2 has\nplenty of bandwidth available and PF3 has no bandwidth configured at all).\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PciClaim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch adds a functional test case to that shows the failure in the\nabove use case.\n\nTODO:\n  * split up the patch to smaller pieces (object change, conf change,\n    manager change)\n  * refactor manager code to smaller functions\n  * document the new pci whitelist flag\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 7, 'created': '2018-12-14 16:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac94c57b62aad27745dc7f8b8f35ae5554b359c8', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 8, 'created': '2018-12-14 17:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c97f01c7acfc6495565ff24c285f9d86e2d27484', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 9, 'created': '2018-12-18 15:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cec90a53344f4ff0d3df2b95d31deb725fbf5b18', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 10, 'created': '2018-12-19 15:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3764d9fb096cb83bd95fb72464682f0c63ac2742', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 11, 'created': '2018-12-20 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0aa904eed078a2a529e50071b13fa35fd6c8a28', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 12, 'created': '2018-12-20 16:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e240ef1ed141f4a2e73b7bd73b65ca447b66619', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 13, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e746f4935ee77fc37345a95f8d75b174e2ada57', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * refactor manager code to smaller functions\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 14, 'created': '2019-01-24 15:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/333759ec9c1d3e9478a4403380c6f79139dd5d67', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 15, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4f2f36330edf823f92ef148cb0db88469e89214', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 16, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/232be3e9b9e67a6b6e4785d6738b87e13ed29958', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 17, 'created': '2019-01-28 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4e4b3c9e2ffccd9cb73196f0a617685cca81955', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 18, 'created': '2019-02-05 10:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b526e0f574f3b4accb03c95ffbe7396f69973bbf', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * add functional test\n    * sriov port without bandwidth works\n    * bandwidth available in one PF but VF available only on the other\n      PF where bandwdith is not available\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 19, 'created': '2019-02-05 15:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf0ea0bd41438aa7819e8ebc3e34d6fbbe46ed1d', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 20, 'created': '2019-02-06 15:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6608f3e345b46be8f46ce43877bdd17ffbcc16af', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 21, 'created': '2019-02-08 01:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/341fbad68981eacac67696a52327a705b9f72555', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 22, 'created': '2019-02-12 09:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/307c7c3f8801486582ae2cbd6e5b9e71d5990db3', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nTODO:\n  * unit test coverage\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 23, 'created': '2019-02-12 13:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77d567b8211e5032bcff415dfbe91ef12d0cb658', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 24, 'created': '2019-02-12 16:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16a4de500f0b504dc2f62a4fd8b883eb7c5c6962', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 25, 'created': '2019-02-13 10:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b2c6fb753aa7b89ea7655ab06d7c1fd477a0aef', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 26, 'created': '2019-02-15 13:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8d4a5d1e11fc2371098eb797d7a2282c1c58b36', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 27, 'created': '2019-02-15 13:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7785ea3ca00eaf8555cb38f19f4c2b5397acf2aa', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 28, 'created': '2019-02-18 13:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0336d4a80075dbfdc9623d93c7be9d95517c563d', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 29, 'created': '2019-02-18 13:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a430071f56026a90a2e3dd0442a1f0dd002c75bf', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 30, 'created': '2019-02-20 08:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a2fe36fd56e1627c46afa4599a9c3d0ea3a5791', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 31, 'created': '2019-02-21 11:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ee18f55d1a2d8abb40d35d378518c05b55d472d', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 32, 'created': '2019-02-27 13:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55bcc241167b9aafdeafd7419d8dcc007dbd0c2a', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 33, 'created': '2019-02-27 13:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b828ec49db7b08065d0e654fe863a9149824e3b', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 34, 'created': '2019-02-27 17:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01f73c6485556fce36c89ccdce7eab6d75d797c9', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 35, 'created': '2019-03-01 13:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8d488ccdef6c0cdbb511cdbae42e17649ade43a', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 36, 'created': '2019-03-01 13:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65e7024f581ba1bc353b5cffbbdaec1d6c1de81d', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 37, 'created': '2019-03-01 15:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0cc0eb17c481e013711b81c4b5427a3bf5cef8d4', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 38, 'created': '2019-03-04 09:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4a7a8b78c9ea7bee8327b32b71f68894162f3d0', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can havee plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe  InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF based on the value of the\n``pf_interface_name`` tag in the pci/passthrough_whitelist config\noption introduced in the previous patch.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 39, 'created': '2019-03-04 15:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7143131c8b1ae0c68060d16df45c6a877422d167', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is only based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. But it does not consider that which PF\nprovides the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PFs which are connected to the same\nphysnet. This two PFs can have totally different bandwidth inventories\nin placement. For example PF2 can have plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter migth accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the pci claim has the same logic as the Filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the pci claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The pci claim code knows about the PF\ninterface name of each available VF from the virt driver reporting the\n'pf_interface_name' key as part of the return value of the\nget_available_resource() driver call.\n\nThe current patch extends the libvirt driver to provider PF interface\nname informaton. Besides the libvirt driver the xenapi driver also\nsupport SRIOV VF handling but this patch does not extend the xenapi\ndriver. So for the xenapi the above described configuration currently\nkept unsupported.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 40, 'created': '2019-03-05 11:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3dc1ac8b25e4ab1daf9216b234ed29b3955d56d', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. It does not consider the actual PF\nproviding the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PF which are connected to the same\nphysnet. These PFs can have totally different bandwidth inventories\nin placement. For example PF2 can have plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter might accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PCI claim has the same logic as the filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the PCI claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The PCI claim code knows about the PF\ninterface name of each available VF from the virt driver reporting the\n'parent_ifname' key as part of the return value of the\nget_available_resource() driver call.\n\nThe PCI claim process is not changed as it already enforces that\nevery fields from the request matches with the fields of the selected\ndevice pool.\n\nThe current patch extends the libvirt driver to provider PF interface\nname information. Besides the libvirt driver the xenapi driver also\nsupport SRIOV VF handling but this patch does not extend the xenapi\ndriver. So for the xenapi the above described configuration currently\nkept unsupported.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 41, 'created': '2019-03-05 14:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecea762eb9f6a15f1006ad574c5ab6c8a9cb24c5', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. It does not consider the actual PF\nproviding the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PF which are connected to the same\nphysnet. These PFs can have totally different bandwidth inventories\nin placement. For example PF2 can have plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter might accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PCI claim has the same logic as the filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the PCI claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The PCI claim code knows about the PF\ninterface name of each available VF from the virt driver reporting the\n'parent_ifname' key as part of the return value of the\nget_available_resource() driver call.\n\nThe PCI claim process is not changed as it already enforces that\nevery fields from the request matches with the fields of the selected\ndevice pool.\n\nThe current patch extends the libvirt driver to provider PF interface\nname information. Besides the libvirt driver the xenapi driver also\nsupport SRIOV VF handling but this patch does not extend the xenapi\ndriver. So for the xenapi the above described configuration currently\nkept unsupported.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}, {'number': 42, 'created': '2019-03-05 16:53:18.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/tests/fixtures.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/scheduler/client/report.py', 'nova/compute/manager.py', 'nova/pci/stats.py', 'nova/tests/functional/test_servers.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c02e213d507c830427a86d6a4bb4f7a2f5158590', 'message': ""Ensure that bandwidth and VF are from the same PF\n\nA neutron port can be created with direct vnic type and also it can have\nbandwidth resource request at the same time. In this case placement will\noffer allocation candidates that could fulfill the bandwidth request, then\nthe nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,\nis available for such request. This check is based on the physnet\nof the neutron port and the physical_network tag in the\npci/passthrough_whitelist config. It does not consider the actual PF\nproviding the bandwidth.\n\nThe currently unsupported case is when a single compute node has\nwhitelisted VFs from more than one PF which are connected to the same\nphysnet. These PFs can have totally different bandwidth inventories\nin placement. For example PF2 can have plenty of bandwidth available\nand PF3 has no bandwidth configured at all.\n\nIn this case the PciPassthroughFilter might accept the host simply\nbecause PF3 still has available VFs even if the bandwidth from the port\nis fulfilled from PF2 which in return might not have available VFs any\nmore.\n\nMoreover the PCI claim has the same logic as the filter so it will claim\nthe VF from PF3 while the bandwidth was allocated from PF2 in placement.\n\nThis patch does not try to solve the issue in the PciPassthroughFilter but\nit does solves the issue in the pci claim. This means that after\nsuccessful scheduling the pci claim can still fail if bandwidth is\nallocated from one PF but a VF is not available from that specific PF\nany more. This will lead to re-schedule.\n\nMaking the PciPassthroughFilter smart enough is complicated because:\n* The filters are not knowing about placement allocation candidates at\n  all\n* The filters are working per compute host not per allocation\n  candidates. If there are two allocation candidates for the same host\n  then nova will only try to filter for the first one. [1][2]\n\nThis patch applies the following logic:\n\nThe compute manager checks the InstancePCIRequest ovos in a given\nboot request and maps each of them to the neutron port that requested\nthe PCI device. Then it maps the neutron port to the physical device\nRP in the placement allocation made for this server. Then the spec in\nthe InstancePCIRequest is extended with the interface name of the PF\nfrom where the bandwidth was allocated from based on the name of the\ndevice RP. Then the PCI claim will enforce that the PF interface\nname in the request matches the interface name of the PF from where\nthe VF is selected from. The PCI claim code knows about the PF\ninterface name of each available VF from the virt driver reporting the\n'parent_ifname' key as part of the return value of the\nget_available_resource() driver call.\n\nThe PCI claim process is not changed as it already enforces that\nevery fields from the request matches with the fields of the selected\ndevice pool.\n\nThe current patch extends the libvirt driver to provider PF interface\nname information. Besides the libvirt driver the xenapi driver also\nsupport SRIOV VF handling but this patch does not extend the xenapi\ndriver. So for the xenapi the above described configuration currently\nkept unsupported.\n\nI know that this feels complicated but it is necessary becase VFs has\nnot been counted as resources in placement yet.\n\n[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239\n[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a\n""}]",91,623543,c02e213d507c830427a86d6a4bb4f7a2f5158590,354,23,42,9708,,,0,"Ensure that bandwidth and VF are from the same PF

A neutron port can be created with direct vnic type and also it can have
bandwidth resource request at the same time. In this case placement will
offer allocation candidates that could fulfill the bandwidth request, then
the nova scheduler's PciPassthroughFilter checks if a PCI device, a VF,
is available for such request. This check is based on the physnet
of the neutron port and the physical_network tag in the
pci/passthrough_whitelist config. It does not consider the actual PF
providing the bandwidth.

The currently unsupported case is when a single compute node has
whitelisted VFs from more than one PF which are connected to the same
physnet. These PFs can have totally different bandwidth inventories
in placement. For example PF2 can have plenty of bandwidth available
and PF3 has no bandwidth configured at all.

In this case the PciPassthroughFilter might accept the host simply
because PF3 still has available VFs even if the bandwidth from the port
is fulfilled from PF2 which in return might not have available VFs any
more.

Moreover the PCI claim has the same logic as the filter so it will claim
the VF from PF3 while the bandwidth was allocated from PF2 in placement.

This patch does not try to solve the issue in the PciPassthroughFilter but
it does solves the issue in the pci claim. This means that after
successful scheduling the pci claim can still fail if bandwidth is
allocated from one PF but a VF is not available from that specific PF
any more. This will lead to re-schedule.

Making the PciPassthroughFilter smart enough is complicated because:
* The filters are not knowing about placement allocation candidates at
  all
* The filters are working per compute host not per allocation
  candidates. If there are two allocation candidates for the same host
  then nova will only try to filter for the first one. [1][2]

This patch applies the following logic:

The compute manager checks the InstancePCIRequest ovos in a given
boot request and maps each of them to the neutron port that requested
the PCI device. Then it maps the neutron port to the physical device
RP in the placement allocation made for this server. Then the spec in
the InstancePCIRequest is extended with the interface name of the PF
from where the bandwidth was allocated from based on the name of the
device RP. Then the PCI claim will enforce that the PF interface
name in the request matches the interface name of the PF from where
the VF is selected from. The PCI claim code knows about the PF
interface name of each available VF from the virt driver reporting the
'parent_ifname' key as part of the return value of the
get_available_resource() driver call.

The PCI claim process is not changed as it already enforces that
every fields from the request matches with the fields of the selected
device pool.

The current patch extends the libvirt driver to provider PF interface
name information. Besides the libvirt driver the xenapi driver also
support SRIOV VF handling but this patch does not extend the xenapi
driver. So for the xenapi the above described configuration currently
kept unsupported.

I know that this feels complicated but it is necessary becase VFs has
not been counted as resources in placement yet.

[1] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L239
[2] https://github.com/openstack/nova/blob/f6996903d2ef0fdb40135b506c83ed6517b28e19/nova/scheduler/filter_scheduler.py#L426

blueprint: bandwidth-resource-provider

Change-Id: I038867c4094d79ae4a20615ab9c9f9e38fcc2e0a
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/623543/14 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/devspec.py', 'nova/pci/utils.py', 'nova/virt/fake.py', 'nova/compute/claims.py', 'nova/pci/manager.py', 'nova/scheduler/filters/pci_passthrough_filter.py', 'nova/network/neutronv2/api.py', 'nova/compute/manager.py', 'nova/pci/stats.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py', 'nova/compute/resource_tracker.py', 'nova/scheduler/host_manager.py']",13,f94564f89029abcec31dd6c059fa76a723ecde03,bp/bandwidth-resource-provider," print('host_manager._locaked_consume_from_request', spec_obj) print('host_manager enabled filters', self.enabled_filters)",,289,2
openstack%2Fopenstack-helm-infra~master~I28b57abf02d2437569c7c7c8d75ec8ba19d84311,openstack/openstack-helm-infra,master,I28b57abf02d2437569c7c7c8d75ec8ba19d84311,Fix wrong command for validation check,MERGED,2019-02-21 01:08:03.000000000,2019-03-06 04:03:32.000000000,2019-03-06 04:03:32.000000000,"[{'_account_id': 1523}, {'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 20469}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-02-21 01:08:03.000000000', 'files': ['tools/deployment/openstack-support/025-ceph-ns-activate.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ff5ce99911ce4bafe9737ca99c9c4369c5c07b99', 'message': 'Fix wrong command for validation check\n\nWe need to change from osh-infra to openstack\nbecause ceph-openstack-config release runs in openstack namespace.\n\nChange-Id: I28b57abf02d2437569c7c7c8d75ec8ba19d84311\n'}]",0,638308,ff5ce99911ce4bafe9737ca99c9c4369c5c07b99,10,7,1,1523,,,0,"Fix wrong command for validation check

We need to change from osh-infra to openstack
because ceph-openstack-config release runs in openstack namespace.

Change-Id: I28b57abf02d2437569c7c7c8d75ec8ba19d84311
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/08/638308/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/openstack-support/025-ceph-ns-activate.sh'],1,ff5ce99911ce4bafe9737ca99c9c4369c5c07b99,fix-wrong-validation-command,kubectl get -n openstack jobs --show-all kubectl get -n openstack secrets kubectl get -n openstack configmaps,kubectl get -n osh-infra jobs --show-all kubectl get -n osh-infra secrets kubectl get -n osh-infra configmaps,3,3
openstack%2Fopenstack-helm-infra~master~I982f6bc08954864afa5ad29923707e1bf64ba9fa,openstack/openstack-helm-infra,master,I982f6bc08954864afa5ad29923707e1bf64ba9fa,[CEPH] RGW tuning for Mimic release,MERGED,2019-02-26 11:54:34.000000000,2019-03-06 04:02:48.000000000,2019-03-06 04:02:48.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 24165}, {'_account_id': 29132}]","[{'number': 1, 'created': '2019-02-26 11:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8df036d12396eb8f88e4613b0ef64d3b3a4b1e5d', 'message': '[CEPH] RGW tuning for Mimic release\n\nRemove overrides that are already set or raised higher in the\nMimic release of Ceph for RGW.\n\nrgw_thread_pool_size is now by default using 512\nobjecter_inflight_ops is now also set to 24576 by default for RGW\n\nChange-Id: I982f6bc08954864afa5ad29923707e1bf64ba9fa\n'}, {'number': 2, 'created': '2019-03-01 06:54:47.000000000', 'files': ['ceph-rgw/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/66cb979bc2e8b838c0cac96c2f6a176b814067e2', 'message': '[CEPH] RGW tuning for Mimic release\n\nRemove overrides that are already set or raised higher in the\nMimic release of Ceph for RGW.\n\nrgw_thread_pool_size is now by default using 512\nobjecter_inflight_ops is now also set to 24576 by default for RGW\n\nChange-Id: I982f6bc08954864afa5ad29923707e1bf64ba9fa\n'}]",0,639317,66cb979bc2e8b838c0cac96c2f6a176b814067e2,14,5,2,29268,,,0,"[CEPH] RGW tuning for Mimic release

Remove overrides that are already set or raised higher in the
Mimic release of Ceph for RGW.

rgw_thread_pool_size is now by default using 512
objecter_inflight_ops is now also set to 24576 by default for RGW

Change-Id: I982f6bc08954864afa5ad29923707e1bf64ba9fa
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/17/639317/2 && git format-patch -1 --stdout FETCH_HEAD,['ceph-rgw/values.yaml'],1,8df036d12396eb8f88e4613b0ef64d3b3a4b1e5d,rgw_tuning,, #NOTE (supamatt): Increase threads and rados handles for better performance rgw_thread_pool_size: 512 objecter_inflight_ops: 10240,0,3
openstack%2Fopenstack-helm~master~I48fec6e7e263d0136e987e744b3a339f8118bfe1,openstack/openstack-helm,master,I48fec6e7e263d0136e987e744b3a339f8118bfe1,Adapt Makefile for releasenotes,MERGED,2019-02-28 09:52:21.000000000,2019-03-06 04:01:01.000000000,2019-03-06 04:01:01.000000000,"[{'_account_id': 7069}, {'_account_id': 8749}, {'_account_id': 8898}, {'_account_id': 9963}, {'_account_id': 12281}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-28 09:52:21.000000000', 'files': ['Makefile'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9b0d62ed595a43ba1125f0fa234987b510a24b48', 'message': 'Adapt Makefile for releasenotes\n\nRelease notes should be excluded from make, as they will cause\nlinting issues.\n\nChange-Id: I48fec6e7e263d0136e987e744b3a339f8118bfe1\n'}]",0,639964,9b0d62ed595a43ba1125f0fa234987b510a24b48,11,7,1,17068,,,0,"Adapt Makefile for releasenotes

Release notes should be excluded from make, as they will cause
linting issues.

Change-Id: I48fec6e7e263d0136e987e744b3a339f8118bfe1
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/64/639964/1 && git format-patch -1 --stdout FETCH_HEAD,['Makefile'],1,9b0d62ed595a43ba1125f0fa234987b510a24b48,remove_release_notes_from_make,EXCLUDES := helm-toolkit doc tests tools logs tmp zuul.d releasenotes,EXCLUDES := helm-toolkit doc tests tools logs tmp zuul.d,1,1
openstack%2Fopenstack-helm-infra~master~I4e610e4acf67d92257f9d254546ec0b5b31609fe,openstack/openstack-helm-infra,master,I4e610e4acf67d92257f9d254546ec0b5b31609fe,Deep copy daemonset_yaml cross loop,MERGED,2019-02-22 11:46:46.000000000,2019-03-06 03:50:09.000000000,2019-03-06 03:50:09.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26686}, {'_account_id': 28208}, {'_account_id': 29668}]","[{'number': 1, 'created': '2019-02-22 11:46:46.000000000', 'files': ['helm-toolkit/templates/utils/_daemonset_overrides.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2df03d3a326d42a9718d273c711cdbeb478bdb1c', 'message': 'Deep copy daemonset_yaml cross loop\n\nIn templates/utils/_daemonset_overrides.tpl,\n$context.Values.__daemonset_yaml is used cross the loop. It is not deep\ncopied in each round of loop. It means that the property set in the\nprevious round of loop will still exist in current loop. This is not\nexpected.\nThis patch is to make a deep copy in each round of loop.\n\nChange-Id: I4e610e4acf67d92257f9d254546ec0b5b31609fe\n'}]",0,638637,2df03d3a326d42a9718d273c711cdbeb478bdb1c,14,6,1,29668,,,0,"Deep copy daemonset_yaml cross loop

In templates/utils/_daemonset_overrides.tpl,
$context.Values.__daemonset_yaml is used cross the loop. It is not deep
copied in each round of loop. It means that the property set in the
previous round of loop will still exist in current loop. This is not
expected.
This patch is to make a deep copy in each round of loop.

Change-Id: I4e610e4acf67d92257f9d254546ec0b5b31609fe
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/37/638637/1 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/utils/_daemonset_overrides.tpl'],1,2df03d3a326d42a9718d273c711cdbeb478bdb1c,," {{/* Deep copy original daemonset_yaml */}} {{- $_ := set $context.Values ""__daemonset_yaml"" ($daemonset_yaml | toYaml | fromYaml) }} {{- if eq $context.Values.__volume.secret.secretName $configmap_name }}"," {{- $_ := set $context.Values ""__daemonset_yaml"" $daemonset_yaml }} {{- $_ := set $context.Values ""__last_configmap_name"" $configmap_name }} {{- if eq $context.Values.__volume.secret.secretName $context.Values.__last_configmap_name }} {{- $_ := set $context.Values ""__last_configmap_name"" $current_dict.dns_1123_name }}",3,4
openstack%2Fopenstack-helm~master~I4a4d6efbbfe073d035bc5c03700fbe998e708d0f,openstack/openstack-helm,master,I4a4d6efbbfe073d035bc5c03700fbe998e708d0f,Support per-host overrides of auto_bridge_add,MERGED,2019-02-25 13:17:39.000000000,2019-03-06 03:42:49.000000000,2019-03-06 03:42:49.000000000,"[{'_account_id': 8898}, {'_account_id': 17068}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28439}, {'_account_id': 28550}, {'_account_id': 28917}, {'_account_id': 29093}, {'_account_id': 29668}]","[{'number': 1, 'created': '2019-02-25 13:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3178a161b4daeee5e4629dbc50e409e9dc2b2842', 'message': 'Support per-host overrides of auto_bridge_add\n\n.Values.network.auto_bridge_add is a global config. So in multi nodes\ndeployment, it requires that all hosts have the same nic names. This is\na strict limit.\nThis patch is to support per-host auto_bridge_add, so that we can define\ndifferent auto_bridge_add for hosts.\n\nChange-Id: I4a4d6efbbfe073d035bc5c03700fbe998e708d0f\nStory: 2005059\nTask: 29601\n'}, {'number': 2, 'created': '2019-02-27 05:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/923566a3e6b7a98bdbdb1bf879ddf4456c1fbaeb', 'message': 'Support per-host overrides of auto_bridge_add\n\n.Values.network.auto_bridge_add is a global config. So in multi nodes\ndeployment, it requires that all hosts have the same nic names. This is\na strict limit.\nThis patch is to support per-host auto_bridge_add, so that we can define\ndifferent auto_bridge_add for hosts.\nAlso, this patch move .network.auto_bridge_add to .conf.auto_bridge_add\n\nChange-Id: I4a4d6efbbfe073d035bc5c03700fbe998e708d0f\nStory: 2005059\nTask: 29601\n'}, {'number': 3, 'created': '2019-02-28 02:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5a88a31bc17208df6221d3aa9acffc2f32feea47', 'message': 'Support per-host overrides of auto_bridge_add\n\n.Values.network.auto_bridge_add is a global config. So in multi nodes\ndeployment, it requires that all hosts have the same nic names. This is\na strict limit.\nThis patch is to support per-host auto_bridge_add, so that we can define\ndifferent auto_bridge_add for hosts.\nAlso, this patch move .network.auto_bridge_add to .conf.auto_bridge_add\n\nChange-Id: I4a4d6efbbfe073d035bc5c03700fbe998e708d0f\nStory: 2005059\nTask: 29601\n'}, {'number': 4, 'created': '2019-02-28 02:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b1df5b1aaaedd0ba5cb684a71e1b175dfd91cad6', 'message': 'Support per-host overrides of auto_bridge_add\n\n.Values.network.auto_bridge_add is a global config. So in multi nodes\ndeployment, it requires that all hosts have the same nic names. This is\na strict limit.\nThis patch is to support per-host auto_bridge_add, so that we can define\ndifferent auto_bridge_add for hosts.\nAlso, this patch move .network.auto_bridge_add to .conf.auto_bridge_add\n\nChange-Id: I4a4d6efbbfe073d035bc5c03700fbe998e708d0f\nStory: 2005059\nTask: 29601\n'}, {'number': 5, 'created': '2019-03-05 08:43:45.000000000', 'files': ['neutron/templates/daemonset-lb-agent.yaml', 'doc/source/devref/networking.rst', 'neutron/templates/bin/_neutron-linuxbridge-agent-init.sh.tpl', 'neutron/templates/daemonset-ovs-agent.yaml', 'neutron/templates/bin/_neutron-openvswitch-agent-init.sh.tpl', 'neutron/values.yaml', 'neutron/templates/configmap-etc.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6e2e4aba8d1053adb6dcfc598c5c3d78c3195c94', 'message': 'Support per-host overrides of auto_bridge_add\n\n.Values.network.auto_bridge_add is a global config. So in multi nodes\ndeployment, it requires that all hosts have the same nic names. This is\na strict limit.\nThis patch is to support per-host auto_bridge_add, so that we can define\ndifferent auto_bridge_add for hosts.\nAlso, this patch move .network.auto_bridge_add to .conf.auto_bridge_add\n\nChange-Id: I4a4d6efbbfe073d035bc5c03700fbe998e708d0f\nStory: 2005059\nTask: 29601\n'}]",4,639087,6e2e4aba8d1053adb6dcfc598c5c3d78c3195c94,29,10,5,29668,,,0,"Support per-host overrides of auto_bridge_add

.Values.network.auto_bridge_add is a global config. So in multi nodes
deployment, it requires that all hosts have the same nic names. This is
a strict limit.
This patch is to support per-host auto_bridge_add, so that we can define
different auto_bridge_add for hosts.
Also, this patch move .network.auto_bridge_add to .conf.auto_bridge_add

Change-Id: I4a4d6efbbfe073d035bc5c03700fbe998e708d0f
Story: 2005059
Task: 29601
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/87/639087/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/templates/daemonset-lb-agent.yaml', 'neutron/templates/bin/_neutron-linuxbridge-agent-init.sh.tpl', 'neutron/templates/daemonset-ovs-agent.yaml', 'neutron/templates/bin/_neutron-openvswitch-agent-init.sh.tpl', 'neutron/templates/configmap-etc.yaml']",5,3178a161b4daeee5e4629dbc50e409e9dc2b2842,auto_bridge_add, auto_bridge_add: {{ toJson $envAll.Values.network.auto_bridge_add | b64enc }},,33,20
openstack%2Fopenstack-helm-infra~master~I7b0ea7a86246b098f38ef4c03dd157731f61e066,openstack/openstack-helm-infra,master,I7b0ea7a86246b098f38ef4c03dd157731f61e066,(postgresql) set db admin password at startup,MERGED,2019-02-05 23:00:37.000000000,2019-03-06 03:42:37.000000000,2019-03-06 03:42:37.000000000,"[{'_account_id': 8898}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26449}, {'_account_id': 28778}]","[{'number': 1, 'created': '2019-02-05 23:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c7a37000561085d87807b4e375ca10c6fb9cb962', 'message': '[WIP] (postgresql) Add job for admin pw rotation\n\n- Add a job that will set the admin password after the service\n  is up even when the database already exists.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 2, 'created': '2019-02-06 17:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0ae4093cc2905786583dc44b970109cdd20c47b6', 'message': '[WIP] (postgresql) Add job for admin pw rotation\n\n- Add a job that will set the admin password after the service\n  is up even when the database already exists.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 3, 'created': '2019-02-07 02:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8d51c962cc1a9be176b0f0aa304be019f066e19a', 'message': '[WIP] (postgresql) Add job for admin pw rotation\n\n- Add a job that will set the admin password after the service\n  is up even when the database already exists.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 4, 'created': '2019-02-07 03:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ae39ac72e933b2d6186046b8f0d11d66298f4c12', 'message': '[WIP] (postgresql) Add job for admin pw rotation\n\n- Add a job that will set the admin password after the service\n  is up even when the database already exists.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 5, 'created': '2019-02-07 21:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/322d3af4cf8256c4ce4065c1a176457fddccc6fe', 'message': '[WIP] (postgresql) Add job for admin pw rotation\n\n- Add a job that will set the admin password after the service\n  is up even when the database already exists.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 6, 'created': '2019-02-07 22:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fc1b705450ab8a05d295cf9326d221babfcdb844', 'message': '[WIP] (postgresql) Add job for admin pw rotation\n\n- Add a job that will set the admin password after the service\n  is up even when the database already exists.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 7, 'created': '2019-02-13 21:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1b9735ab0040e46961b274457209f854b315fbc3', 'message': '[WIP] (postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 8, 'created': '2019-02-13 21:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bea6f9a0c7c99a9ea600295eb3befbc3408dd35b', 'message': '[WIP] (postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 9, 'created': '2019-02-15 18:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8abb3140dbfe8d0cb85bbeb585b3f68edc271a3e', 'message': '[WIP] (postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 10, 'created': '2019-02-15 20:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/30e83a87be5c7b1de269b83e17ef16a9a99cd271', 'message': '(postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 11, 'created': '2019-02-18 15:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dda3a58286376d27a5c52d427996e8ac833462c2', 'message': '(postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\n- Update readiness check to fail until the setpassword utility has\n  finished running.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 12, 'created': '2019-02-22 16:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c71f8c1838e0ba7753a2a02d2a53e18a04f815ee', 'message': '(postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\n- Update readiness check to fail until the setpassword utility has\n  finished running.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 13, 'created': '2019-02-22 21:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf4ecc5bff5cc86c4a6140e9597fdf27483fee20', 'message': '(postgresql) Background process to set password\n\n- When starting up postgres in the pod, first start a background\n  script that will continually attempt to use psql to set the admin\n  users password. This should allow for Postgres to start up and\n  once the password is set, the background script will exit.\n\n- Update readiness check to fail until the setpassword utility has\n  finished running.\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n'}, {'number': 14, 'created': '2019-02-22 23:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/850f7704a39f4ce58e536738a28dafe687915e4e', 'message': ""(postgresql) set db admin password at startup\n\n- Make the default to run the postgres database as the uid 999 which\n  the default image maps to the 'postgres' user\n\n- If the database is already initialized, before starting postgres\n  set the 'postgres' database user password to match the declared\n  intended password\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n""}, {'number': 15, 'created': '2019-03-04 16:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/700e7b670c882cb3a0b9d47dc85f8e3d695474c0', 'message': ""(postgresql) set db admin password at startup\n\n- Make the default to run the postgres database as the uid 999 which\n  the default image maps to the 'postgres' user\n\n- If the database is already initialized, before starting postgres\n  set the 'postgres' database user password to match the declared\n  intended password\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n""}, {'number': 16, 'created': '2019-03-05 18:38:41.000000000', 'files': ['postgresql/templates/bin/_start.sh.tpl', 'postgresql/templates/statefulset.yaml', 'postgresql/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4a505e213c98d5f81138b643d4c710adca9fa082', 'message': ""(postgresql) set db admin password at startup\n\n- Make the default to run the postgres database as the uid 999 which\n  the default image maps to the 'postgres' user\n\n- If the database is already initialized, before starting postgres\n  set the 'postgres' database user password to match the declared\n  intended password\n\nChange-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066\n""}]",11,635070,4a505e213c98d5f81138b643d4c710adca9fa082,52,6,16,26449,,,0,"(postgresql) set db admin password at startup

- Make the default to run the postgres database as the uid 999 which
  the default image maps to the 'postgres' user

- If the database is already initialized, before starting postgres
  set the 'postgres' database user password to match the declared
  intended password

Change-Id: I7b0ea7a86246b098f38ef4c03dd157731f61e066
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/70/635070/6 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/templates/configmap-bin.yaml', 'postgresql/templates/job-rotate-password.yaml', 'postgresql/templates/bin/_rotate-password.sh.tpl', 'postgresql/values.yaml']",4,c7a37000561085d87807b4e375ca10c6fb9cb962,postgres_pw_rotation," rotate_password: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""256Mi"" cpu: ""200m"" rotate_job: ""docker pull lachlanevenson/k8s-kubectl:v1.13.3"" job_rotate_password: services: - endpoint: internal service: postgresql password_rotate: postgres_pod_name: 'postgresql-0' retry_sleep: 60 job_rotate_password: true",,160,0
openstack%2Fopenstack-helm-images~master~Iee93e5a4d542b69bf6ebfbc82920b132a2af7778,openstack/openstack-helm-images,master,Iee93e5a4d542b69bf6ebfbc82920b132a2af7778,[CEPH] Update the Ceph repo and key to be arguements,MERGED,2019-03-01 01:41:06.000000000,2019-03-06 03:29:56.000000000,2019-03-06 03:28:41.000000000,"[{'_account_id': 8898}, {'_account_id': 17068}, {'_account_id': 17119}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 29974}]","[{'number': 1, 'created': '2019-03-01 01:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/164ef0c6cc743646e3511d0b7ec510debabcbd72', 'message': '[CEPH] Add Mirantis Repo and Ceph binaries for Mimic\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}, {'number': 2, 'created': '2019-03-01 04:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/b2655e76456b6fd88b2a1e405b651f508d31aa9e', 'message': '[CEPH] Add Mirantis Repo and Ceph binaries for Mimic\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}, {'number': 3, 'created': '2019-03-01 05:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/495644a937b2af41b6822a248f2fa3b876e2539c', 'message': '[CEPH] Add Mirantis Repo and Ceph binaries for Mimic\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}, {'number': 4, 'created': '2019-03-01 05:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/7d4fc317bf3b2da18e906688b0d21e380cae24b9', 'message': '[CEPH] Add Mirantis Repo and Ceph binaries for Mimic\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}, {'number': 5, 'created': '2019-03-01 18:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8b52b23b11a8407b3b27a80c9430a12205512f5a', 'message': '[CEPH] Update the Ceph repo and key to be arguements\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}, {'number': 6, 'created': '2019-03-01 19:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/704b355ac794a75469a74ec4ccf1b5dae846146e', 'message': '[CEPH] Update the Ceph repo and key to be arguements\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}, {'number': 7, 'created': '2019-03-04 20:05:24.000000000', 'files': ['ceph-config-helper/Dockerfile.ubuntu_xenial', 'ceph-daemon/Dockerfile.ubuntu_xenial', 'libvirt/Dockerfile.ubuntu_xenial', 'ceph-utility/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/bfa78bf03f5cc1b2d6c32461b538eb7cc1e4a1f3', 'message': '[CEPH] Update the Ceph repo and key to be arguements\n\nChange-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778\n'}]",0,640239,bfa78bf03f5cc1b2d6c32461b538eb7cc1e4a1f3,23,7,7,29268,,,0,"[CEPH] Update the Ceph repo and key to be arguements

Change-Id: Iee93e5a4d542b69bf6ebfbc82920b132a2af7778
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/39/640239/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-daemon/Dockerfile.ubuntu_xenial'],1,164ef0c6cc743646e3511d0b7ec510debabcbd72,mirantis,"ADD http://mirror.mirantis.com/nightly/ceph-mimic/xenial/archive-ceph-${CEPH_RELEASE}.key /etc/apt/archive-ceph-${CEPH_RELEASE}.key apt-key add /etc/apt/archive-ceph-${CEPH_RELEASE}.key ;\ rm -f /etc/apt/archive-ceph-${CEPH_RELEASE}.key ;\ echo ""deb http://mirror.mirantis.com/nightly/ceph-${CEPH_RELEASE}/xenial/ xenial main"" | tee /etc/apt/sources.list.d/ceph.list ;\","ADD https://download.ceph.com/keys/release.asc /etc/apt/ceph-release.asc apt-key add /etc/apt/ceph-release.asc ;\ rm -f /etc/apt/ceph-release.asc ;\ echo ""deb http://download.ceph.com/debian-${CEPH_RELEASE}/ xenial main"" | tee /etc/apt/sources.list.d/ceph.list ;\",4,4
openstack%2Fwatcher~master~I94b768c2d3e0471ca619ce43387889ec74769ce2,openstack/watcher,master,I94b768c2d3e0471ca619ce43387889ec74769ce2,improve _collect_aggregates,MERGED,2019-03-04 07:16:13.000000000,2019-03-06 03:29:37.000000000,2019-03-06 03:29:36.000000000,"[{'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 29911}]","[{'number': 1, 'created': '2019-03-04 07:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6e144f92eea9b3d2f31f57c8c18559570deff766', 'message': ""    improve_collect_aggregates\n\n    There are id,name and hosts fields in the response of list aggregates.\n    So don't need invoke get_aggregate_detail again.\n    https://developer.openstack.org/api-ref/compute/?expanded=#list-aggregates\n\nChange-Id: I94b768c2d3e0471ca619ce43387889ec74769ce2\n""}, {'number': 2, 'created': '2019-03-04 07:21:34.000000000', 'files': ['watcher/tests/decision_engine/scope/test_compute.py', 'watcher/decision_engine/scope/compute.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/4cdf6a793089013085f8e29f23c98a19edcaf6e9', 'message': ""    improve _collect_aggregates\n\n    There are id,name and hosts fields in the response of list aggregates.\n    So don't need invoke get_aggregate_detail again.\n    https://developer.openstack.org/api-ref/compute/?expanded=#list-aggregates\n\nChange-Id: I94b768c2d3e0471ca619ce43387889ec74769ce2\n""}]",0,640681,4cdf6a793089013085f8e29f23c98a19edcaf6e9,8,3,2,21692,,,0,"    improve _collect_aggregates

    There are id,name and hosts fields in the response of list aggregates.
    So don't need invoke get_aggregate_detail again.
    https://developer.openstack.org/api-ref/compute/?expanded=#list-aggregates

Change-Id: I94b768c2d3e0471ca619ce43387889ec74769ce2
",git fetch https://review.opendev.org/openstack/watcher refs/changes/81/640681/2 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/decision_engine/scope/test_compute.py', 'watcher/decision_engine/scope/compute.py']",2,6e144f92eea9b3d2f31f57c8c18559570deff766,improve_collect_aggregates, if (aggregate.id in aggregate_ids or aggregate.name in aggregate_names or include_all_nodes): compute_nodes.extend(aggregate.hosts), detailed_aggregate = self.wrapper.get_aggregate_detail( aggregate.id) if (detailed_aggregate.id in aggregate_ids or detailed_aggregate.name in aggregate_names or include_all_nodes): compute_nodes.extend(detailed_aggregate.hosts),11,28
openstack%2Fmagnum~stable%2Frocky~I7f6200a4966fda1cc701749bf1f37ddc492390c5,openstack/magnum,stable/rocky,I7f6200a4966fda1cc701749bf1f37ddc492390c5,Add iptables -P FORWARD ACCEPT unit,MERGED,2019-02-28 08:46:06.000000000,2019-03-06 03:19:05.000000000,2019-03-06 03:19:05.000000000,"[{'_account_id': 1004}, {'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-28 08:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/16884d4badeba281334fbb8970b4e10222b9d279', 'message': ""Add iptables -P FORWARD ACCEPT unit\n\nOn node reboot, kubelet and kube-proxy set\niptables -P FORWARD DROP which doesn't work with\nflannel in the way we use it.\nAdd a systemd unit to set the rule to ACCEPT after\nflannel,docker,kubelet,kube-proxy.\n\nChange-Id: I7f6200a4966fda1cc701749bf1f37ddc492390c5\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n(cherry picked from commit cf5f78e5be5ae5252c065700d581c36760897c3c)\n""}, {'number': 2, 'created': '2019-02-28 09:03:46.000000000', 'files': ['magnum/drivers/common/templates/swarm/fragments/network-service.sh', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-service.sh', 'releasenotes/notes/flannel-reboot-fix-f1382818daed4fa8.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/263d0788a91c171cd696eb26c6a09ef7a680e4e5', 'message': ""Add iptables -P FORWARD ACCEPT unit\n\nOn node reboot, kubelet and kube-proxy set\niptables -P FORWARD DROP which doesn't work with\nflannel in the way we use it.\nAdd a systemd unit to set the rule to ACCEPT after\nflannel,docker,kubelet,kube-proxy.\n\nSquashed in this patch, is the release notes patch [0]\n\n[0] I07771f2c4711b0b86a53610517abdc3dad270574 which is\n(cherry picked from commit e6b3325120a0ff333ebaea2db2d64e07d5011248)\n\nChange-Id: I7f6200a4966fda1cc701749bf1f37ddc492390c5\nCo-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>\n(cherry picked from commit cf5f78e5be5ae5252c065700d581c36760897c3c)\n""}]",0,639948,263d0788a91c171cd696eb26c6a09ef7a680e4e5,9,4,2,20498,,,0,"Add iptables -P FORWARD ACCEPT unit

On node reboot, kubelet and kube-proxy set
iptables -P FORWARD DROP which doesn't work with
flannel in the way we use it.
Add a systemd unit to set the rule to ACCEPT after
flannel,docker,kubelet,kube-proxy.

Squashed in this patch, is the release notes patch [0]

[0] I07771f2c4711b0b86a53610517abdc3dad270574 which is
(cherry picked from commit e6b3325120a0ff333ebaea2db2d64e07d5011248)

Change-Id: I7f6200a4966fda1cc701749bf1f37ddc492390c5
Co-Authored-By: Spyros Trigazis <spyridon.trigazis@cern.ch>
(cherry picked from commit cf5f78e5be5ae5252c065700d581c36760897c3c)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/48/639948/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/swarm/fragments/network-service.sh', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-service.sh']",2,16884d4badeba281334fbb8970b4e10222b9d279,639948,"SYSTEMD_UNITS_DIR=/etc/systemd/system/FLANNEL_IPTABLES_FORWARD_ACCEPT_SERVICE=flannel-iptables-forward-accept.service# Workaround for https://github.com/coreos/flannel/issues/799 # Not solved upstream properly yet. cat >> ""${SYSTEMD_UNITS_DIR}${FLANNEL_IPTABLES_FORWARD_ACCEPT_SERVICE}"" <<EOF [Unit] After=flanneld.service docker.service kubelet.service kube-proxy.service Requires=flanneld.service [Service] Type=oneshot ExecStart=/usr/sbin/iptables -P FORWARD ACCEPT ExecStartPost=/usr/sbin/iptables -S [Install] WantedBy=flanneld.service EOF chown root:root ""${SYSTEMD_UNITS_DIR}${FLANNEL_IPTABLES_FORWARD_ACCEPT_SERVICE}"" chmod 0644 ""${SYSTEMD_UNITS_DIR}${FLANNEL_IPTABLES_FORWARD_ACCEPT_SERVICE}"" systemctl daemon-reload systemctl enable ""${FLANNEL_IPTABLES_FORWARD_ACCEPT_SERVICE}"" ",,46,0
openstack%2Fopenstack-helm-images~master~Ic51fa2ab6898eaa14b45b67ba6708f2d7aea75eb,openstack/openstack-helm-images,master,Ic51fa2ab6898eaa14b45b67ba6708f2d7aea75eb,mini-mirror: Allow per-source Aptly config files,MERGED,2019-03-05 16:31:49.000000000,2019-03-06 03:12:50.000000000,2019-03-06 03:11:40.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 18180}, {'_account_id': 20466}, {'_account_id': 20998}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 22636}, {'_account_id': 23186}, {'_account_id': 23928}, {'_account_id': 26365}, {'_account_id': 26449}, {'_account_id': 26628}, {'_account_id': 26686}, {'_account_id': 27715}, {'_account_id': 28208}, {'_account_id': 28235}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-03-05 16:31:49.000000000', 'files': ['mini-mirror/tools/publish_snapshots.sh', 'mini-mirror/README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/e83bc85d4447d393dfb32b0bf508eeec4c044080', 'message': 'mini-mirror: Allow per-source Aptly config files\n\nCurrent mini-mirror images are build using a single Aptly config file\nprovided at build time. In some cases, it may be desirable to provide an\nAptly configuration file for each source to change the behavior of a\nsingle mirror. This commit introduces support for providing an Aptly\nconfiguration file for each individual source. The config file should be\nnamed aptly.conf and placed in the root source path.\n\nChange-Id: Ic51fa2ab6898eaa14b45b67ba6708f2d7aea75eb\n'}]",3,641074,e83bc85d4447d393dfb32b0bf508eeec4c044080,11,19,1,28618,,,0,"mini-mirror: Allow per-source Aptly config files

Current mini-mirror images are build using a single Aptly config file
provided at build time. In some cases, it may be desirable to provide an
Aptly configuration file for each source to change the behavior of a
single mirror. This commit introduces support for providing an Aptly
configuration file for each individual source. The config file should be
named aptly.conf and placed in the root source path.

Change-Id: Ic51fa2ab6898eaa14b45b67ba6708f2d7aea75eb
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/74/641074/1 && git format-patch -1 --stdout FETCH_HEAD,"['mini-mirror/tools/publish_snapshots.sh', 'mini-mirror/README.rst']",2,e83bc85d4447d393dfb32b0bf508eeec4c044080,,.. NOTE:: Mini-mirror can be configured on a per-repo basis by adding an Aptly config file to the root directory of a source. This overrides the Aptly config file taken from ``APTLY_CONFIG_PATH``. ,,22,8
openstack%2Fopenstack-helm-addons~master~Icf994acf27f5d52b461da17688ca2832139edeb5,openstack/openstack-helm-addons,master,Icf994acf27f5d52b461da17688ca2832139edeb5,Update irc meeting channel,MERGED,2019-02-27 07:08:41.000000000,2019-03-06 03:12:19.000000000,2019-03-06 03:12:19.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-27 07:08:41.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/f9faf4deac92bb9dda7d544653651d7980f2b06e', 'message': 'Update irc meeting channel\n\nupdate irc meeting channel to #openstack-meeting-4\n\nChange-Id: Icf994acf27f5d52b461da17688ca2832139edeb5\n'}]",0,639584,f9faf4deac92bb9dda7d544653651d7980f2b06e,7,3,1,29668,,,0,"Update irc meeting channel

update irc meeting channel to #openstack-meeting-4

Change-Id: Icf994acf27f5d52b461da17688ca2832139edeb5
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/84/639584/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,f9faf4deac92bb9dda7d544653651d7980f2b06e,, #openstack-meeting-4 on freenode, #openstack-meeting-5 on freenode,1,1
openstack%2Foctavia~master~I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2,openstack/octavia,master,I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2,Encrypt certs and keys,MERGED,2018-12-23 10:07:19.000000000,2019-03-06 02:38:21.000000000,2019-03-06 02:38:20.000000000,"[{'_account_id': 6579}, {'_account_id': 8871}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 26970}]","[{'number': 1, 'created': '2018-12-23 10:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3b3223b2b4e31162a372f525e02bcaedf3f8db90', 'message': '[WIP]: Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 2, 'created': '2018-12-24 15:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b1d01cf8291246cabfc0de38fe721de77bcb4b00', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 3, 'created': '2018-12-25 14:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d819d4938f7af419cb967b0e0be1509fa0614e96', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 4, 'created': '2018-12-26 12:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7566eba564d34da787ca7c5013b293d8a11e7b1c', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 5, 'created': '2018-12-26 15:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d37fc284c49ed30e57257bdb04311e9d7a0db9d2', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 6, 'created': '2019-01-01 09:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/06fa8d155a7a750e70e191cf34c7d8a63ab073ab', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 7, 'created': '2019-01-01 09:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/39050a08dc50135e0971efeca567123b63c652a3', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 8, 'created': '2019-01-01 12:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3ecb9f803f6e4240a4680a387fed4a4fea317b76', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 9, 'created': '2019-01-01 22:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c814b0c9742b76c11106bcc24a224f7f24faafa5', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 10, 'created': '2019-01-02 12:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/529f5b3a6ec3388f183c9e400428b2556aa77438', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 11, 'created': '2019-01-03 14:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/008489e0e35b209c5ec9f05ce718ac9c851065c1', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 12, 'created': '2019-01-03 17:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/96688ec788176f3bea7ad28c0a5665df962bd535', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 13, 'created': '2019-01-06 10:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/65001513b2dff094980033c61675c38eefe38c65', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 14, 'created': '2019-02-07 14:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/bf3a5cecafcb871275d264b106b75913af5c082c', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 15, 'created': '2019-02-10 08:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7f628d2b64f9367b66e7997ecaf369def3588fdc', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 16, 'created': '2019-02-11 10:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/29a2fd020297505bd432399a614349460f097cca', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 17, 'created': '2019-02-11 12:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2c210e99e6fe163819a3b915eefee0e96468e63c', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 18, 'created': '2019-02-20 15:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/811d88378fee484f7bebff69933103e6a3b65d8a', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 19, 'created': '2019-02-21 10:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d89c090a5650b15d5913db80311d3737c17231bb', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 20, 'created': '2019-02-21 13:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4cce97239a0dd516d23948999bb877ecf9945072', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nAdditionally, this patch also changes the default key passphrase\nexample to reflect a more secure standard that is used in Fernet.\nThe example passphrase is no longer hardcoded and can now be\nmodified in devstack settings.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 21, 'created': '2019-02-21 14:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8f5393ebca6ecce83c57f7478c678270bf9aba63', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}, {'number': 22, 'created': '2019-02-24 13:41:39.000000000', 'files': ['octavia/common/utils.py', 'octavia/common/config.py', 'octavia/controller/worker/tasks/compute_tasks.py', 'devstack/plugin.sh', 'octavia/controller/worker/tasks/cert_task.py', 'releasenotes/notes/encrypt-certs-and-keys-5175d7704d8df3ce.yaml', 'octavia/tests/unit/controller/worker/tasks/test_amphora_driver_tasks.py', 'octavia/tests/unit/controller/worker/tasks/test_database_tasks.py', 'octavia/tests/unit/controller/worker/tasks/test_cert_task.py', 'octavia/controller/worker/tasks/database_tasks.py', 'octavia/tests/unit/controller/worker/tasks/test_compute_tasks.py', 'octavia/controller/worker/tasks/amphora_driver_tasks.py', 'octavia/controller/worker/controller_worker.py', 'octavia/certificates/common/local.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/ae7c87f54a6c5483a608d5e9fe51ea1966ea1f7e', 'message': 'Encrypt certs and keys\n\nOctavia creates certificates and keys to manage encrypted\ncommunication channel to amphorae.\nWhen debug is enabled, the python taskflow module will log\nall the information we provide to tasks (and sub-flows)\nwhen we create amphorae or handle with anything related to\ncertificates and keys management (rotations, etc).\n\nThere are ways to tell taskflow to exclude specific things\nfrom being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).\nWhile this handles some information in specific flows from being\nlogged, it is susceptive to code changes.\n\nTo avoid an everlasting whack-a-mole game, this patch will merely\nencrypt sensitive information so we can safely log it and decrypts\nit only when we need to use it.\n\nChange-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2\n'}]",38,627064,ae7c87f54a6c5483a608d5e9fe51ea1966ea1f7e,72,6,22,6579,,,0,"Encrypt certs and keys

Octavia creates certificates and keys to manage encrypted
communication channel to amphorae.
When debug is enabled, the python taskflow module will log
all the information we provide to tasks (and sub-flows)
when we create amphorae or handle with anything related to
certificates and keys management (rotations, etc).

There are ways to tell taskflow to exclude specific things
from being logged (e.g., I136081045787c1bbe3ee846d5845a34201c57864).
While this handles some information in specific flows from being
logged, it is susceptive to code changes.

To avoid an everlasting whack-a-mole game, this patch will merely
encrypt sensitive information so we can safely log it and decrypts
it only when we need to use it.

Change-Id: I06d329ca53bc36bd27f7870ae7c7ca0cf18575b2
",git fetch https://review.opendev.org/openstack/octavia refs/changes/64/627064/2 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/controller/worker/tasks/compute_tasks.py', 'octavia/controller/worker/tasks/database_tasks.py', 'octavia/controller/worker/tasks/amphora_driver_tasks.py', 'octavia/controller/worker/tasks/cert_task.py']",4,3b3223b2b4e31162a372f525e02bcaedf3f8db90,encrypt_keys,from cryptography import fernet fer = fernet.Fernet(CONF.certificates.ca_private_key_passphrase) cert.certificate = fer.encrypt(cert.certificate) cert.private_key = fer.encrypt(cert.private_key),,16,5
openstack%2Fpuppet-qdr~master~Ie1348d247a15933ced6b75bbf3d81b7adb793fcb,openstack/puppet-qdr,master,Ie1348d247a15933ced6b75bbf3d81b7adb793fcb,Remove extra spaces,MERGED,2019-03-06 01:11:54.000000000,2019-03-06 02:25:44.000000000,2019-03-06 02:25:44.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 01:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-qdr/commit/ff7f57b817f7d129389b3171c8f2c3c1f2a5a62f', 'message': 'Remove extra spaces\n\nChange-Id: Ie1348d247a15933ced6b75bbf3d81b7adb793fcb\n'}, {'number': 2, 'created': '2019-03-06 01:35:10.000000000', 'files': ['spec/classes/qdr_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-qdr/commit/0dd9804a7d616561f5ca48c913e80d462c5661c4', 'message': 'Remove extra spaces\n\nChange-Id: Ie1348d247a15933ced6b75bbf3d81b7adb793fcb\n'}]",0,641181,0dd9804a7d616561f5ca48c913e80d462c5661c4,8,2,2,9414,,,0,"Remove extra spaces

Change-Id: Ie1348d247a15933ced6b75bbf3d81b7adb793fcb
",git fetch https://review.opendev.org/openstack/puppet-qdr refs/changes/81/641181/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/init_spec.rb'],1,ff7f57b817f7d129389b3171c8f2c3c1f2a5a62f,remove-extra-spaces,, ,1,1
openstack%2Felection~master~Ib21b2f2f33e0b093a570e53999854839d72729d8,openstack/election,master,Ib21b2f2f33e0b093a570e53999854839d72729d8,Adding Andrey Pavlov candidacy for ec2-api,MERGED,2019-02-13 12:40:13.000000000,2019-03-06 02:19:45.000000000,2019-03-06 02:19:45.000000000,"[{'_account_id': 5263}, {'_account_id': 10234}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 12:40:13.000000000', 'files': ['candidates/train/Ec2_Api/andrey.mp@gmail.com'], 'web_link': 'https://opendev.org/openstack/election/commit/c408038c35ae5371f7e185522608c7f1479850c0', 'message': 'Adding Andrey Pavlov candidacy for ec2-api\n\nChange-Id: Ib21b2f2f33e0b093a570e53999854839d72729d8\n'}]",0,636611,c408038c35ae5371f7e185522608c7f1479850c0,10,4,1,10234,,,0,"Adding Andrey Pavlov candidacy for ec2-api

Change-Id: Ib21b2f2f33e0b093a570e53999854839d72729d8
",git fetch https://review.opendev.org/openstack/election refs/changes/11/636611/1 && git format-patch -1 --stdout FETCH_HEAD,['candidates/train/Ec2_Api/andrey.mp@gmail.com'],1,c408038c35ae5371f7e185522608c7f1479850c0,,"Hi all, I would like to continue to run for PTLship. Best regards, Andrey Pavlov. ",,6,0
openstack%2Fnetworking-baremetal~master~Ic0da34ca8281a5634b9e224da4b16984bb76d18c,openstack/networking-baremetal,master,Ic0da34ca8281a5634b9e224da4b16984bb76d18c,Supporting all py3 environments with tox,MERGED,2019-03-04 16:10:40.000000000,2019-03-06 02:18:40.000000000,2019-03-06 02:18:40.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-03-04 16:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/5b353352b45fc607fb1b8bf60ce54e714bb5f8ca', 'message': ""Adding py36 environment to tox\n\nWe're running the python3.6 unit test on CI, we should add py36\nenvironment to tox to explicitely run unit tests offline using\nPython 3.6\n\nAlso reordering list of template jobs.\n\nChange-Id: Ic0da34ca8281a5634b9e224da4b16984bb76d18c\n""}, {'number': 2, 'created': '2019-03-05 13:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/8f2d3ff2e5a5984376aecd6c7bc193f7c2b9d8db', 'message': ""Adding py36 environment to tox\n\nWe're running the python3.6 unit test on CI, we should add py36\nenvironment to tox to explicitely run unit tests offline using\nPython 3.6\n\nAlso reordering list of template jobs.\n\nChange-Id: Ic0da34ca8281a5634b9e224da4b16984bb76d18c\n""}, {'number': 3, 'created': '2019-03-05 13:30:39.000000000', 'files': ['zuul.d/project.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/d594603ab3dad794c59e5b18b762e91f8ed611fb', 'message': 'Supporting all py3 environments with tox\n\nConverting environment py35 to py3 in tox.ini to show support\nfor all Python 3.x versions.\n\nAlso reordering list of template jobs.\n\nChange-Id: Ic0da34ca8281a5634b9e224da4b16984bb76d18c\n'}]",2,640794,d594603ab3dad794c59e5b18b762e91f8ed611fb,15,5,3,23851,,,0,"Supporting all py3 environments with tox

Converting environment py35 to py3 in tox.ini to show support
for all Python 3.x versions.

Also reordering list of template jobs.

Change-Id: Ic0da34ca8281a5634b9e224da4b16984bb76d18c
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/94/640794/3 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'tox.ini']",2,5b353352b45fc607fb1b8bf60ce54e714bb5f8ca,python3-first,"envlist = py35,py36,py27,pep8","envlist = py35,py27,pep8",3,3
openstack%2Foctavia~master~Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586,openstack/octavia,master,Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586,Support L7policy redirect http code,MERGED,2018-12-13 14:13:47.000000000,2019-03-06 02:14:51.000000000,2019-03-06 02:14:51.000000000,"[{'_account_id': 8871}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-13 14:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cada1148227ee5f87fbb0f13d22be1d444d9c058', 'message': ""Support L7policy redirect http code\n\nCurrently, L7Policy already support the redirection by url_prefix.\nThen we can support the redirection with HTTP code.\n\nThis patch adds an new option 'redirect_http_code' to L7Policy API.\n\nStory: 2003609\nTask: 24941\nChange-Id: Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586\n""}, {'number': 2, 'created': '2018-12-20 06:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ec4b3ac2c7c529f81fd8dec1de3fd195c512a930', 'message': ""Support L7policy redirect http code\n\nCurrently, L7Policy already support the redirection by url_prefix.\nThen we can support the redirection with HTTP code.\n\nThis patch adds an new option 'redirect_http_code' to L7Policy API.\n\nStory: 2003609\nTask: 24941\nChange-Id: Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586\n""}, {'number': 3, 'created': '2018-12-21 01:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1c63877e534af309f3f86ee3a3a8cce67f83f3e1', 'message': ""Support L7policy redirect http code\n\nCurrently, L7Policy already support the redirection by url_prefix.\nThen we can support the redirection with HTTP code.\n\nThis patch adds an new option 'redirect_http_code' to L7Policy API.\n\nStory: 2003609\nTask: 24941\nChange-Id: Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586\n""}, {'number': 4, 'created': '2019-03-04 23:04:54.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/v2/examples/l7policy-create-request.json', 'api-ref/source/v2/examples/l7policy-create-response.json', 'octavia/tests/functional/api/test_root_controller.py', 'octavia/common/jinja/haproxy/jinja_cfg.py', 'octavia/common/jinja/haproxy/templates/macros.j2', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/common/validate.py', 'octavia/tests/unit/common/jinja/haproxy/test_jinja_cfg.py', 'octavia/db/migration/alembic_migrations/versions/6742ca1b27c2_add_l7policy_redirect_http_code.py', 'octavia/common/constants.py', 'api-ref/source/v2/examples/l7policy-create-curl', 'api-ref/source/v2/examples/l7policy-show-response.json', 'octavia/db/repositories.py', 'api-ref/source/v2/examples/l7policy-update-curl', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'api-ref/source/v2/examples/l7policies-list-response.json', 'octavia/tests/unit/common/sample_configs/sample_configs.py', 'api-ref/source/v2/l7policy.inc', 'octavia/db/models.py', 'releasenotes/notes/support-redirect-http-code-1c2e87ef7fda12e97.yaml', 'octavia/api/drivers/data_models.py', 'api-ref/source/v2/examples/l7policy-update-response.json', 'octavia/common/data_models.py', 'octavia/api/root_controller.py', 'octavia/api/v2/controllers/l7policy.py', 'octavia/tests/unit/api/drivers/sample_data_models.py', 'api-ref/source/v2/examples/l7policy-update-request.json', 'octavia/api/v2/types/l7policy.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/25fb7e4c3284a8d419cddfc378f41dbb8dbd5ef2', 'message': ""Support L7policy redirect http code\n\nCurrently, L7Policy already support the redirection by url_prefix.\nThen we can support the redirection with HTTP code.\n\nThis patch adds an new option 'redirect_http_code' to L7Policy API.\n\nStory: 2003609\nTask: 24941\nChange-Id: Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586\n""}]",4,625007,25fb7e4c3284a8d419cddfc378f41dbb8dbd5ef2,21,4,4,15309,,,0,"Support L7policy redirect http code

Currently, L7Policy already support the redirection by url_prefix.
Then we can support the redirection with HTTP code.

This patch adds an new option 'redirect_http_code' to L7Policy API.

Story: 2003609
Task: 24941
Change-Id: Id0c9c376ffbc2fb10ddb988537d0ef1a8205e586
",git fetch https://review.opendev.org/openstack/octavia refs/changes/07/625007/3 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/v2/examples/l7policy-create-request.json', 'api-ref/source/v2/examples/l7policy-create-response.json', 'octavia/common/jinja/haproxy/jinja_cfg.py', 'octavia/common/jinja/haproxy/templates/macros.j2', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/common/validate.py', 'octavia/tests/unit/common/jinja/haproxy/test_jinja_cfg.py', 'octavia/db/migration/alembic_migrations/versions/6742ca1b27c2_add_l7policy_redirect_http_code.py', 'octavia/common/constants.py', 'api-ref/source/v2/examples/l7policy-create-curl', 'api-ref/source/v2/examples/l7policy-show-response.json', 'octavia/db/repositories.py', 'api-ref/source/v2/examples/l7policy-update-curl', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'api-ref/source/v2/examples/l7policies-list-response.json', 'octavia/tests/unit/common/sample_configs/sample_configs.py', 'api-ref/source/v2/l7policy.inc', 'octavia/db/models.py', 'releasenotes/notes/support-redirect-http-code-1c2e87ef7fda12e97.yaml', 'octavia/api/drivers/data_models.py', 'api-ref/source/v2/examples/l7policy-update-response.json', 'octavia/common/data_models.py', 'octavia/tests/unit/api/drivers/sample_data_models.py', 'api-ref/source/v2/examples/l7policy-update-request.json', 'octavia/api/v2/types/l7policy.py']",26,cada1148227ee5f87fbb0f13d22be1d444d9c058,redirect_http_code," redirect_http_code = wtypes.wsattr(wtypes.IntegerType()) redirect_http_code = wtypes.wsattr( wtypes.Enum(int, *constants.SUPPORTED_L7POLICY_REDIRECT_HTTP_CODES)) redirect_http_code = wtypes.wsattr( wtypes.Enum(int, *constants.SUPPORTED_L7POLICY_REDIRECT_HTTP_CODES)) redirect_http_code = wtypes.wsattr( wtypes.Enum(int, *constants.SUPPORTED_L7POLICY_REDIRECT_HTTP_CODES))",,279,23
openstack%2Fhorizon~master~I5c3078bdc66e33fe676d431bb28d92b35faaf479,openstack/horizon,master,I5c3078bdc66e33fe676d431bb28d92b35faaf479,Switch integration tests to run with python3,MERGED,2019-02-01 13:27:14.000000000,2019-03-06 02:13:11.000000000,2019-03-06 02:13:11.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-01 13:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/97dbd21e196266bee3ae3e0bf42e05de671b81aa', 'message': 'Switch integration tests to run with python3\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n'}, {'number': 2, 'created': '2019-02-09 09:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6cdb9b7fa38064e3f7c6669e9fa4594eaaaf23a1', 'message': 'Switch integration tests to run with python3\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n'}, {'number': 3, 'created': '2019-02-09 18:58:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5bbf6ea34bb309ccb948db08f5f862d49d404df5', 'message': 'Switch integration tests to run with python3\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n'}, {'number': 4, 'created': '2019-02-09 18:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a59b2ca56abf4c35442e173343769304a155fe4b', 'message': ""Switch integration tests to run with python3\n\ntox env for the integration tests is now renamed to 'integration'\nas it is no longer run under python 2.7.\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n""}, {'number': 5, 'created': '2019-03-01 14:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ef24353b11e0a7e5ac52d028a6c00b223ad589cf', 'message': ""Switch integration tests to run with python3\n\ntox env for the integration tests is now renamed to 'integration'\nas it is no longer run under python 2.7.\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n""}, {'number': 6, 'created': '2019-03-01 15:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2861b3a10101d09ff0736a8bc6657be8b2b4170d', 'message': ""Switch integration tests to run with python3\n\ntox env for the integration tests is now renamed to 'integration'\nas it is no longer run under python 2.7.\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n""}, {'number': 7, 'created': '2019-03-01 19:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3c93c705ca7f51a2fce4d1559be9b4cf84e55bcb', 'message': ""Switch integration tests to run with python3\n\ntox env for the integration tests is now renamed to 'integration'\nas it is no longer run under python 2.7.\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n""}, {'number': 8, 'created': '2019-03-01 20:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b6ef1990635e8a407745f4432277f3abaaf8fb54', 'message': ""Switch integration tests to run with python3\n\ntox env for the integration tests is now renamed to 'integration'\nas it is no longer run under python 2.7.\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n""}, {'number': 9, 'created': '2019-03-05 09:10:07.000000000', 'files': ['openstack_dashboard/test/integration_tests/pages/navigation.py', '.zuul.yaml', 'openstack_dashboard/test/integration_tests/helpers.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/43f8c3b1f5e9bfc7166364262b3ab54536ea04fa', 'message': ""Switch integration tests to run with python3\n\ntox env for the integration tests is now renamed to 'integration'\nas it is no longer run under python 2.7.\n\n__hash__() method is now defined in integration_tests.helpers.BaseTestCase\nto avoid unhashable error during loading django test runner. This is\noriginally caused by the fact that the base testcase class for integration\ntests is implemented on top of testtools and testtools does not define\n__hash__() method. In Python 3, __hash__() method must be defined\nif a class (re)defines __eq__() method to make the class hashable [1].\nIdeally integration base TestCase class can be implemented on top of\nDjango test case, but the current implementation depends on features\nfrom testtools a lot, so it seems better to add __hash__() method\nas a workaround.\n\nUnbound methods don't exist in Python 3[2], so six.create_unbound_method\ndoesn' work as expected. To dynamic method generation we have to use new\ndescriptors interface [3] or just generate new\nfunctools.partialmethod [4] function introduced in Python 3.4 to\ngenerate class methods with pre-defined 'path' argument and pass 'self'\nas a first function argument for class instance.\n\n[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__\n[2] https://six.readthedocs.io/#six.create_unbound_method\n[3] https://docs.python.org/3/howto/descriptor.html\n[4] https://docs.python.org/3/library/functools.html#functools.partialmethod\n\nChange-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479\n""}]",5,634406,43f8c3b1f5e9bfc7166364262b3ab54536ea04fa,36,5,9,1736,,,0,"Switch integration tests to run with python3

tox env for the integration tests is now renamed to 'integration'
as it is no longer run under python 2.7.

__hash__() method is now defined in integration_tests.helpers.BaseTestCase
to avoid unhashable error during loading django test runner. This is
originally caused by the fact that the base testcase class for integration
tests is implemented on top of testtools and testtools does not define
__hash__() method. In Python 3, __hash__() method must be defined
if a class (re)defines __eq__() method to make the class hashable [1].
Ideally integration base TestCase class can be implemented on top of
Django test case, but the current implementation depends on features
from testtools a lot, so it seems better to add __hash__() method
as a workaround.

Unbound methods don't exist in Python 3[2], so six.create_unbound_method
doesn' work as expected. To dynamic method generation we have to use new
descriptors interface [3] or just generate new
functools.partialmethod [4] function introduced in Python 3.4 to
generate class methods with pre-defined 'path' argument and pass 'self'
as a first function argument for class instance.

[1] https://docs.python.org/3.5/reference/datamodel.html#object.__hash__
[2] https://six.readthedocs.io/#six.create_unbound_method
[3] https://docs.python.org/3/howto/descriptor.html
[4] https://docs.python.org/3/library/functools.html#functools.partialmethod

Change-Id: I5c3078bdc66e33fe676d431bb28d92b35faaf479
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/634406/8 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,97dbd21e196266bee3ae3e0bf42e05de671b81aa,py3-integration,envdir = {toxworkdir}/venvbasepython = python3,envdir = {toxworkdir}/py27basepython = python2.7,2,2
openstack%2Fcinder~master~I282efb314b82381feb1d34f84e628f4e9853394f,openstack/cinder,master,I282efb314b82381feb1d34f84e628f4e9853394f,Remove py35 from setup.cfg,MERGED,2019-02-28 05:27:50.000000000,2019-03-06 02:11:58.000000000,2019-02-28 16:52:32.000000000,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 20284}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26458}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-02-28 05:27:50.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/963d71083b147e236a424659c7ecff1b538097aa', 'message': 'Remove py35 from setup.cfg\n\nThis is a followup to Drop py35 jobs from gate and tox env[1].\n\n[1] https://review.openstack.org/#/c/639385/\n\nChange-Id: I282efb314b82381feb1d34f84e628f4e9853394f\n'}]",0,639912,963d71083b147e236a424659c7ecff1b538097aa,37,30,1,27615,,,0,"Remove py35 from setup.cfg

This is a followup to Drop py35 jobs from gate and tox env[1].

[1] https://review.openstack.org/#/c/639385/

Change-Id: I282efb314b82381feb1d34f84e628f4e9853394f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/12/639912/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,963d71083b147e236a424659c7ecff1b538097aa,remove-py35,, Programming Language :: Python :: 3.5,0,1
openstack%2Ftripleo-heat-templates~master~I23c539555fe1f9db96cd9b84fdcb4240473d55df,openstack/tripleo-heat-templates,master,I23c539555fe1f9db96cd9b84fdcb4240473d55df,Rename docker_puppet_tasks to container_puppet_tasks,MERGED,2019-03-01 19:33:35.000000000,2019-03-06 01:45:45.000000000,2019-03-06 01:45:45.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-03-01 19:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7a70d06483b3f17e892c66eaf84aae964501dc3d', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}, {'number': 2, 'created': '2019-03-04 16:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f9a3da7b8cb66423fe6dc09efd874008ffcf4ad', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}, {'number': 3, 'created': '2019-03-04 18:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dcccfe638251a0264231840f08dae85416a9aad4', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}, {'number': 4, 'created': '2019-03-04 20:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a4402997255a80a622e9979a05db0836d9033280', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}, {'number': 5, 'created': '2019-03-04 20:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4f9274bcee1fb7897ad887b8b2c4cf7de76097ff', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}, {'number': 6, 'created': '2019-03-05 17:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1b206de156b71fe42d2727968e6a7bbf9f2095f8', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}, {'number': 7, 'created': '2019-03-05 17:07:15.000000000', 'files': ['deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/database/mysql-container-puppet.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'common/services.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'common/deploy-steps-tasks.yaml', 'docker/services/README.rst', 'tools/yaml-validate.py', 'releasenotes/notes/docker_puppet_tasks-e74637224ee66f66.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e62d483fcc7726421f5980f3f3af59569370e96', 'message': 'Rename docker_puppet_tasks to container_puppet_tasks\n\nChange-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df\n'}]",4,640497,3e62d483fcc7726421f5980f3f3af59569370e96,33,8,7,3153,,,0,"Rename docker_puppet_tasks to container_puppet_tasks

Change-Id: I23c539555fe1f9db96cd9b84fdcb4240473d55df
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/640497/6 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/database/mysql-container-puppet.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'docker/services/octavia-api.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'common/services.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'common/deploy-steps-tasks.yaml', 'docker/services/README.rst', 'tools/yaml-validate.py']",12,7a70d06483b3f17e892c66eaf84aae964501dc3d,docker/tasks,"OPTIONAL_DOCKER_SECTIONS = ['container_puppet_tasks', 'upgrade_tasks',","OPTIONAL_DOCKER_SECTIONS = ['docker_puppet_tasks', 'upgrade_tasks',",21,21
openstack%2Frequirements~master~I116cd3376b48a49ab928c133cbd9d4784ef90ffa,openstack/requirements,master,I116cd3376b48a49ab928c133cbd9d4784ef90ffa,Updated from generate-constraints,MERGED,2019-03-04 06:25:04.000000000,2019-03-06 01:44:29.000000000,2019-03-06 01:44:28.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 06:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3b2665f7cdf51ec7bcfc870e180e1848fcd2191a', 'message': 'Updated from generate-constraints\n\nChange-Id: I116cd3376b48a49ab928c133cbd9d4784ef90ffa\n'}, {'number': 2, 'created': '2019-03-05 06:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/36aa09d69f205d275b4d95039890f1f46f00a16b', 'message': 'Updated from generate-constraints\n\nChange-Id: I116cd3376b48a49ab928c133cbd9d4784ef90ffa\n'}, {'number': 3, 'created': '2019-03-05 14:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/baf8d80b0923b594b7dd9f7eaa49c6699fb9da77', 'message': 'Updated from generate-constraints\n\nChange-Id: I116cd3376b48a49ab928c133cbd9d4784ef90ffa\n'}, {'number': 4, 'created': '2019-03-05 21:18:59.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e832cfd7248ba453300abcc6a0eca555ed478008', 'message': 'Updated from generate-constraints\n\nsqlalchemy held back for neutron issues\n\nChange-Id: I116cd3376b48a49ab928c133cbd9d4784ef90ffa\n'}]",0,640671,e832cfd7248ba453300abcc6a0eca555ed478008,15,2,4,11131,,,0,"Updated from generate-constraints

sqlalchemy held back for neutron issues

Change-Id: I116cd3376b48a49ab928c133cbd9d4784ef90ffa
",git fetch https://review.opendev.org/openstack/requirements refs/changes/71/640671/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,3b2665f7cdf51ec7bcfc870e180e1848fcd2191a,openstack/requirements/constraints/noclob,django-appconf===1.0.3attrs===19.1.0relativetimebuilder===0.2.0pyroute2===0.5.4tornado===5.1.1;python_version=='2.7'amqp===2.4.2stestr===2.3.0opentracing===2.0.0botocore===1.12.106kombu===4.4.0aniso8601===5.1.0scikit-learn===0.20.3,django-appconf===1.0.2attrs===18.2.0pyroute2===0.5.3tornado===4.5.3;python_version=='2.7'amqp===2.4.1stestr===2.2.0opentracing===1.3.0botocore===1.12.105kombu===4.3.0aniso8601===4.1.0scikit-learn===0.20.2,12,11
openstack%2Frequirements~master~I54dfec349c42b9a18c8e007a4dced18d2bf356b0,openstack/requirements,master,I54dfec349c42b9a18c8e007a4dced18d2bf356b0,update constraint for keystoneauth1 to new release 3.13.1,MERGED,2019-03-05 15:23:34.000000000,2019-03-06 01:44:27.000000000,2019-03-06 01:44:26.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 15:23:34.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/290dd327ae29754ff8a4f4aecdeaf83654d48825', 'message': 'update constraint for keystoneauth1 to new release 3.13.1\n\nChange-Id: I54dfec349c42b9a18c8e007a4dced18d2bf356b0\nmeta:version: 3.13.1\nmeta:diff-start: -\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Colleen Murphy <colleen@gazlene.net>\nmeta:release:Commit: Colleen Murphy <colleen@gazlene.net>\nmeta:release:Change-Id: Ib8d8a76c6bbbd7b0028c0c1d6e0b5d750c8d22b1\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+1: Lance Bragstad <lbragstad@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,641036,290dd327ae29754ff8a4f4aecdeaf83654d48825,8,4,1,11131,,,0,"update constraint for keystoneauth1 to new release 3.13.1

Change-Id: I54dfec349c42b9a18c8e007a4dced18d2bf356b0
meta:version: 3.13.1
meta:diff-start: -
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Colleen Murphy <colleen@gazlene.net>
meta:release:Commit: Colleen Murphy <colleen@gazlene.net>
meta:release:Change-Id: Ib8d8a76c6bbbd7b0028c0c1d6e0b5d750c8d22b1
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+1: Lance Bragstad <lbragstad@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/36/641036/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,290dd327ae29754ff8a4f4aecdeaf83654d48825,new-release,keystoneauth1===3.13.1,keystoneauth1===3.13.0,1,1
openstack%2Fneutron~stable%2Fpike~Ice0667df606ae23061acebceea23ab6e49dadbcf,openstack/neutron,stable/pike,Ice0667df606ae23061acebceea23ab6e49dadbcf,ovsfw: Don't create rules if updated port doesn't exist,MERGED,2019-02-21 09:29:50.000000000,2019-03-06 01:44:24.000000000,2019-03-06 01:44:24.000000000,"[{'_account_id': 4694}, {'_account_id': 8655}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-21 09:29:50.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/agent/linux/openvswitch_firewall/exceptions.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d375dcced03c083faa172057fb1966f48a7da7e', 'message': ""ovsfw: Don't create rules if updated port doesn't exist\n\nThe firewall won't attempt on update to initialize port in case\nport hasn't been initialized by sg_agent yet. This fixes a race where update\nrpc call arrives between wiring tap device with integration bridge and\nfirewall initialization.\n\nChange-Id: Ice0667df606ae23061acebceea23ab6e49dadbcf\nCloses-bug: #1740885\n(cherry picked from commit ed57c3de4241f94ead2bc7c7761bab99dd61894e)\n""}]",0,638372,6d375dcced03c083faa172057fb1966f48a7da7e,14,5,1,21107,,,0,"ovsfw: Don't create rules if updated port doesn't exist

The firewall won't attempt on update to initialize port in case
port hasn't been initialized by sg_agent yet. This fixes a race where update
rpc call arrives between wiring tap device with integration bridge and
firewall initialization.

Change-Id: Ice0667df606ae23061acebceea23ab6e49dadbcf
Closes-bug: #1740885
(cherry picked from commit ed57c3de4241f94ead2bc7c7761bab99dd61894e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/638372/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/agent/linux/openvswitch_firewall/exceptions.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py']",3,6d375dcced03c083faa172057fb1966f48a7da7e,bug/1740885-stable/pike, self.assertFalse(prepare_mock.called) def test__remove_egress_no_port_security_non_existing_port(self): with testtools.ExpectedException(exceptions.OVSFWPortNotHandled): self.firewall._remove_egress_no_port_security('foo'), self.assertTrue(prepare_mock.called) def test__remove_egress_no_port_security_no_tag(self): self.mock_bridge.br.db_get_val.return_value = {} self.firewall._remove_egress_no_port_security('port_id') self.assertFalse(self.mock_bridge.br.delete_flows.called),20,10
openstack%2Fpuppet-qdr~master~I183c6486118524b3eedbe2180d42d6bf17bcd8a9,openstack/puppet-qdr,master,I183c6486118524b3eedbe2180d42d6bf17bcd8a9,Fix unit test  for init.pp,MERGED,2019-03-06 00:32:28.000000000,2019-03-06 01:29:36.000000000,2019-03-06 01:29:36.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-06 00:32:28.000000000', 'files': ['spec/classes/qdr_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-qdr/commit/7cd8c71b1bcebe20ce4402eed6930bd604f4a8b3', 'message': 'Fix unit test  for init.pp\n\nChange-Id: I183c6486118524b3eedbe2180d42d6bf17bcd8a9\n'}]",0,641175,7cd8c71b1bcebe20ce4402eed6930bd604f4a8b3,6,2,1,9414,,,0,"Fix unit test  for init.pp

Change-Id: I183c6486118524b3eedbe2180d42d6bf17bcd8a9
",git fetch https://review.opendev.org/openstack/puppet-qdr refs/changes/75/641175/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/qdr_init_spec.rb'],1,7cd8c71b1bcebe20ce4402eed6930bd604f4a8b3,fix-init-test-name,,,0,0
openstack%2Fpython-openstackclient~master~I1d1fe6eb95c0b167265b3664314d764e3c316fe2,openstack/python-openstackclient,master,I1d1fe6eb95c0b167265b3664314d764e3c316fe2,Typo fix,MERGED,2019-02-07 10:15:18.000000000,2019-03-06 01:24:18.000000000,2019-03-06 01:24:18.000000000,"[{'_account_id': 970}, {'_account_id': 7233}, {'_account_id': 8482}, {'_account_id': 10068}, {'_account_id': 22348}, {'_account_id': 23913}, {'_account_id': 29910}]","[{'number': 1, 'created': '2019-02-07 10:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ebe7ff9db652e716fa685437000590df8245e564', 'message': 'Typo fix\n\nJust a typo fix.\n\nChange-Id: I1d1fe6eb95c0b167265b3664314d764e3c316fe2\n'}, {'number': 2, 'created': '2019-02-27 08:07:07.000000000', 'files': ['openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6475882fd8eaae98141d85c40c760cd220aedad1', 'message': 'Typo fix\n\nJust a typo fix.\n\nChange-Id: I1d1fe6eb95c0b167265b3664314d764e3c316fe2\n'}]",0,635471,6475882fd8eaae98141d85c40c760cd220aedad1,19,7,2,29910,,,0,"Typo fix

Just a typo fix.

Change-Id: I1d1fe6eb95c0b167265b3664314d764e3c316fe2
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/71/635471/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/locale/tr_TR/LC_MESSAGES/openstackclient.po', 'openstackclient/compute/v2/server.py']",2,ebe7ff9db652e716fa685437000590df8245e564,FIX_helpmessage_for_createserver_port-parameter," ""This is a wrapper for the '--nic port-id=<port>' """," ""This is a wrapper for the '--nic port-id=<pord>' """,3,3
openstack%2Fkeystone~stable%2Fqueens~I83eae5c390d720da05e91264519ae01e8ca32159,openstack/keystone,stable/queens,I83eae5c390d720da05e91264519ae01e8ca32159,correct the admin_or_target_domain rule,ABANDONED,2019-02-11 21:07:52.000000000,2019-03-06 01:19:22.000000000,,"[{'_account_id': 1916}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 21:07:52.000000000', 'files': ['releasenotes/notes/fix-policy-for-get-domain-api-c48f4a23adc044cd.yaml', 'keystone/tests/unit/test_v3_protection.py', 'etc/policy.v3cloudsample.json', 'keystone/common/policies/base.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a96c06651fa680af4ddc7ba324c54fa09fdf9c6', 'message': ""correct the admin_or_target_domain rule\n\nWith the removal of KeystoneToken from the token model, we longer\nhave the ability to use the token data syntax in the policy rules.\nThis change broke backward compatibility for those is deploying\ncustomized Keystone policies. Unfortunately, we can't go back\nto KeystoneToken model as the change was tightly coupled with\nthe other refactored authorization functionalities.\n\nSince the scope information is now available in the credential\ndictionary, we can just make use of it instead. Those who have\ncustom policies must update their policy files accordingly.\n\nChange-Id: I83eae5c390d720da05e91264519ae01e8ca32159\ncloses-bug: 1810983\n(cherry picked from commit a2e307ed4d526e21cddf7551f160b587b89360e4)\n""}]",0,636222,6a96c06651fa680af4ddc7ba324c54fa09fdf9c6,5,3,1,1916,,,0,"correct the admin_or_target_domain rule

With the removal of KeystoneToken from the token model, we longer
have the ability to use the token data syntax in the policy rules.
This change broke backward compatibility for those is deploying
customized Keystone policies. Unfortunately, we can't go back
to KeystoneToken model as the change was tightly coupled with
the other refactored authorization functionalities.

Since the scope information is now available in the credential
dictionary, we can just make use of it instead. Those who have
custom policies must update their policy files accordingly.

Change-Id: I83eae5c390d720da05e91264519ae01e8ca32159
closes-bug: 1810983
(cherry picked from commit a2e307ed4d526e21cddf7551f160b587b89360e4)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/636222/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-policy-for-get-domain-api-c48f4a23adc044cd.yaml', 'keystone/tests/unit/test_v3_protection.py', 'etc/policy.v3cloudsample.json', 'keystone/common/policies/base.py']",4,6a96c06651fa680af4ddc7ba324c54fa09fdf9c6,bug/1810983-stable/queens, 'project_domain_id:%(target.domain.id)s'), 'token.project.domain.id:%(target.domain.id)s'),33,2
openstack%2Fpython-openstackclient~master~Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b,openstack/python-openstackclient,master,Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b,Add --attached / --detached parameter to volume set,MERGED,2019-02-22 14:22:55.000000000,2019-03-06 00:58:17.000000000,2019-03-06 00:58:17.000000000,"[{'_account_id': 970}, {'_account_id': 22348}, {'_account_id': 23913}]","[{'number': 1, 'created': '2019-02-22 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c260e727bdc9be7edce1639a4fcd54f4ec789826', 'message': ""Add --attach-status parameter to image set\n\nAs to reflect cinder reset-state --attach-status functionality,\nthis patch adds --attach-status parameter to OSC's image set command.\n\nChange-Id: Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b\nCloses-Bug: #1745699\n""}, {'number': 2, 'created': '2019-02-22 16:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/67ca92d8dfaab24c43bcb17249abcf763d7fe409', 'message': ""Add --attach-status parameter to volume set\n\nAs to reflect cinder reset-state --attach-status functionality,\nthis patch adds --attach-status parameter to OSC's volume set command.\n\nChange-Id: Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b\nCloses-Bug: #1745699\n""}, {'number': 3, 'created': '2019-02-22 17:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e77da280956bdb0b513e005ad7d05a2944e3aa33', 'message': ""Add --attach-status parameter to volume set\n\nAs to reflect cinder reset-state --attach-status functionality,\nthis patch adds --attach-status parameter to OSC's volume set command.\n\nChange-Id: Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b\nCloses-Bug: #1745699\n""}, {'number': 4, 'created': '2019-02-28 12:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9ed489df1c0008b44bb259f0729478a42d21c89d', 'message': ""Add --attached / --detached parameter to volume set\n\nAs to reflect cinder reset-state --attach-status functionality,\nthis patch adds --attached / --detached parameter to OSC's volume set\ncommand.\n\nChange-Id: Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b\nCloses-Bug: #1745699\n""}, {'number': 5, 'created': '2019-02-28 15:48:45.000000000', 'files': ['openstackclient/volume/v2/volume.py', 'doc/source/cli/command-objects/volume.rst', 'releasenotes/notes/bug-1745699-afa7318b9dc96696.yaml', 'openstackclient/tests/unit/volume/v2/test_volume.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e776a4f0260af1d2ae66439e647794395d470578', 'message': ""Add --attached / --detached parameter to volume set\n\nAs to reflect cinder reset-state --attach-status functionality,\nthis patch adds --attached / --detached parameter to OSC's volume set\ncommand.\n\nChange-Id: Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b\nCloses-Bug: #1745699\n""}]",2,638671,e776a4f0260af1d2ae66439e647794395d470578,19,3,5,23913,,,0,"Add --attached / --detached parameter to volume set

As to reflect cinder reset-state --attach-status functionality,
this patch adds --attached / --detached parameter to OSC's volume set
command.

Change-Id: Ic8ee928c9ab0e579512cfb7608f63bfcc2993c7b
Closes-Bug: #1745699
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/71/638671/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/volume/v2/volume.py', 'doc/source/cli/command-objects/volume.rst', 'releasenotes/notes/bug-1745699-afa7318b9dc96696.yaml']",3,c260e727bdc9be7edce1639a4fcd54f4ec789826,bug/1745699,--- features: - | [`bug 1745699 <https://bugs.launchpad.net/python-openstackclient/+bug/1745699>`_] Adds a --attach-status parameter to openstack volume set to implement the functionality of cinder reset-state --attach-status. ,,33,0
openstack%2Fos-ken~master~I6d2f463b50551f32bce863aa7dc0c70ad3054cbd,openstack/os-ken,master,I6d2f463b50551f32bce863aa7dc0c70ad3054cbd,Fix pep8 errors in os-ken,MERGED,2019-03-05 20:39:01.000000000,2019-03-06 00:31:50.000000000,2019-03-06 00:31:50.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-03-05 20:39:01.000000000', 'files': ['lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/os-ken/commit/a3b706a774f3839c00b3bbc6e315c197ff99a561', 'message': 'Fix pep8 errors in os-ken\n\nUpdate the lower constraint for appdirs, similarly to how it has been\ndone in other repos.\n\nWhitelist pep8 error E113.  This is the ""unexpected indent"" error.  This\nmodule uses C-style comment blocks pervasively, things like:\n\n    OFPP_IN_PORT = 0xfff8   # Send the packet out the input port. This\n                            # virtual port must be explicitly used\n                            # in order to send back out of the input\n                            # port.\n    OFPP_TABLE = 0xfff9     # Perform actions in flow table.\n                            # NB: This can only be the destination\n                            # port for packet-out messages.\n    OFPP_NORMAL = 0xfffa    # Process with normal L2/L3 switching.\n\nFor the lines above the ones that have an indented comment with no code\nto the left would get E113 with a recent change to a less permissive\npolicy.  It would cause over 260 changes to comment strings, destroying\nthe consistency of comment style, to make that change.  Therefore,\nblacklist that pycodestyle error.\n\nChange-Id: I6d2f463b50551f32bce863aa7dc0c70ad3054cbd\nStory: #2005142\n'}]",0,641122,a3b706a774f3839c00b3bbc6e315c197ff99a561,7,4,1,13995,,,0,"Fix pep8 errors in os-ken

Update the lower constraint for appdirs, similarly to how it has been
done in other repos.

Whitelist pep8 error E113.  This is the ""unexpected indent"" error.  This
module uses C-style comment blocks pervasively, things like:

    OFPP_IN_PORT = 0xfff8   # Send the packet out the input port. This
                            # virtual port must be explicitly used
                            # in order to send back out of the input
                            # port.
    OFPP_TABLE = 0xfff9     # Perform actions in flow table.
                            # NB: This can only be the destination
                            # port for packet-out messages.
    OFPP_NORMAL = 0xfffa    # Process with normal L2/L3 switching.

For the lines above the ones that have an indented comment with no code
to the left would get E113 with a recent change to a less permissive
policy.  It would cause over 260 changes to comment strings, destroying
the consistency of comment style, to make that change.  Therefore,
blacklist that pycodestyle error.

Change-Id: I6d2f463b50551f32bce863aa7dc0c70ad3054cbd
Story: #2005142
",git fetch https://review.opendev.org/openstack/os-ken refs/changes/22/641122/1 && git format-patch -1 --stdout FETCH_HEAD,"['lower-constraints.txt', 'tox.ini']",2,a3b706a774f3839c00b3bbc6e315c197ff99a561,fix_appdirs,"# E113: unexpected whitespace; skipped in os-ken because C-style comment blocks are used pervasivelyignore = E113,E123,E125,W503,E116,E128,E402,E501,E704,E722,E731,E741,F401,F403,F811,F812,F821,F841,H101,H102,H104,H105,H201,H301,H306,H401,H403,H404,H405,H501","ignore = E123,E125,W503,E116,E128,E402,E501,E704,E722,E731,E741,F401,F403,F811,F812,F821,F841,H101,H102,H104,H105,H201,H301,H306,H401,H403,H404,H405,H501",3,2
openstack%2Felection~master~I7efba04adddb2717021853cdf8064c1be60a9014,openstack/election,master,I7efba04adddb2717021853cdf8064c1be60a9014,Train TC Results,MERGED,2019-03-05 23:58:04.000000000,2019-03-06 00:22:41.000000000,2019-03-06 00:22:41.000000000,"[{'_account_id': 5263}, {'_account_id': 6088}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 23:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/5c28e5edf058264f8e58ca057524c580360b888b', 'message': 'Train TC Results\n\nChange-Id: I7efba04adddb2717021853cdf8064c1be60a9014\n'}, {'number': 2, 'created': '2019-03-06 00:03:31.000000000', 'files': ['doc/source/results/train/tc.yaml'], 'web_link': 'https://opendev.org/openstack/election/commit/8dc868bb01dade86f319b98bda8f75e371378231', 'message': 'Train TC Results\n\nChange-Id: I7efba04adddb2717021853cdf8064c1be60a9014\n'}]",0,641164,8dc868bb01dade86f319b98bda8f75e371378231,9,3,2,16708,,,0,"Train TC Results

Change-Id: I7efba04adddb2717021853cdf8064c1be60a9014
",git fetch https://review.opendev.org/openstack/election refs/changes/64/641164/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/results/train/tc.yaml'],1,5c28e5edf058264f8e58ca057524c580360b888b,train_tc_results,candidates: TC: - elected: true email: asettle@suse.com fullname: Alexandra Settle ircname: asettle url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/asettle%40suse.com - elected: false email: flwang@catalyst.net.nz fullname: Feilong Wang ircname: flwang url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/flwang%40catalyst.net.nz - elected: true email: gr@ham.ie fullname: Graham Hayes ircname: mugsie url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/gr%40ham.ie - elected: true email: jim@jimrollenhagen.com fullname: Jim Rollenhagen ircname: jroll url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/jim%40jimrollenhagen.com - elected: true email: mnaser@vexxhost.com fullname: Mohammed Naser ircname: mnaser url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/mnaser%40vexxhost.com - elected: true email: rico.lin.guanyu@gmail.com fullname: Rico Lin ircname: ricolin url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/rico.lin.guanyu%40gmail.com - elected: false email: sbauza@redhat.com fullname: Sylvain Bauza ircname: bauzas url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/sbauza%40redhat.com - elected: true email: thierry@openstack.org fullname: Thierry Carrez ircname: ttx url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/thierry%40openstack.org - elected: true email: zbitter@redhat.com fullname: Zane Bitter ircname: zaneb url: https://git.openstack.org/cgit/openstack/election/plain/candidates/train/TC/zbitter%40redhat.com election: train elections_results: TC: INSERT-RESULT-LINK projects: - TC ,,52,0
openstack%2Felection~master~I2596102a6af02a17899b71e086f402c3d01d3c99,openstack/election,master,I2596102a6af02a17899b71e086f402c3d01d3c99,Setup Train PTL election,MERGED,2019-01-10 02:52:17.000000000,2019-03-06 00:20:59.000000000,2019-03-06 00:20:59.000000000,"[{'_account_id': 5263}, {'_account_id': 12898}, {'_account_id': 14070}, {'_account_id': 16708}, {'_account_id': 21672}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-10 02:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/770d702788d879640b93eb5cb385e369d91228ec', 'message': 'Setup Train PTL election\n\n  Setting PTL Election\n  Release is at: 2019-04-10\n  Latest possible completion is at: 2019-03-20\n  Moving back to Tuesday: 2019-03-19\n  PTL Election from 2019-03-12T23:45 to 2019-03-19T23:45\n  PTL Nominations from 2019-03-05T23:45 to 2019-03-12T23:45\n  Set email_deadline to 2019-02-19T00:00\n  Setting PTL timeframe end to email_deadline\n  Begining of Rocky Cycle @ 2018-02-09 00:00:00+00:00\n  End of Stein cycle @ 2019-03-05 00:00:00+00:00\n  Election timeframe: 389 days, 0:00:00s\n\nNote we do NOT alter the email_deadline so we can leverage the rolls\ngenerated during the TC election.\n\nChange-Id: I2596102a6af02a17899b71e086f402c3d01d3c99\n'}, {'number': 2, 'created': '2019-01-10 04:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/7f7adf292610fa2457fc708fa9423a37b549b3a7', 'message': 'Setup Train PTL election\n\n  Setting PTL Election\n  Release is at: 2019-04-10\n  Latest possible completion is at: 2019-03-20\n  Moving back to Tuesday: 2019-03-19\n  PTL Election from 2019-03-12T23:45 to 2019-03-19T23:45\n  PTL Nominations from 2019-03-05T23:45 to 2019-03-12T23:45\n  Set email_deadline to 2019-02-19T00:00\n  Setting PTL timeframe end to email_deadline\n  Begining of Rocky Cycle @ 2018-02-09 00:00:00+00:00\n  End of Stein cycle @ 2019-03-05 00:00:00+00:00\n  Election timeframe: 389 days, 0:00:00s\n\nNote we do NOT alter the email_deadline so we can leverage the rolls\ngenerated during the TC election.\n\nChange-Id: I2596102a6af02a17899b71e086f402c3d01d3c99\n'}, {'number': 3, 'created': '2019-01-10 04:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/d53392de1bc6f2e9961ea4ae0468f8db5f971a22', 'message': 'Setup Train PTL election\n\n  Setting PTL Election\n  Release is at: 2019-04-10\n  Latest possible completion is at: 2019-03-20\n  Moving back to Tuesday: 2019-03-19\n  PTL Election from 2019-03-12T23:45 to 2019-03-19T23:45\n  PTL Nominations from 2019-03-05T23:45 to 2019-03-12T23:45\n  Set email_deadline to 2019-02-19T00:00\n  Setting PTL timeframe end to email_deadline\n  Begining of Rocky Cycle @ 2018-02-09 00:00:00+00:00\n  End of Stein cycle @ 2019-03-05 00:00:00+00:00\n  Election timeframe: 389 days, 0:00:00s\n\nNote we do NOT alter the email_deadline so we can leverage the rolls\ngenerated during the TC election.\n\nChange-Id: I2596102a6af02a17899b71e086f402c3d01d3c99\n'}, {'number': 4, 'created': '2019-02-22 05:03:29.000000000', 'files': ['candidates/train/Murano/.placeholder', 'candidates/train/Rally/.placeholder', 'candidates/train/Oslo/.placeholder', 'candidates/train/Searchlight/.placeholder', 'candidates/train/Tripleo/.placeholder', 'candidates/train/Swift/.placeholder', 'candidates/train/Quality_Assurance/.placeholder', 'candidates/train/Qinling/.placeholder', 'candidates/train/Keystone/.placeholder', 'candidates/train/Zun/.placeholder', 'candidates/train/Kuryr/.placeholder', 'candidates/train/Barbican/.placeholder', 'candidates/train/Adjutant/.placeholder', 'candidates/train/Infrastructure/.placeholder', 'candidates/train/OpenStack_Charms/.placeholder', 'candidates/train/Storlets/.placeholder', 'candidates/train/Documentation/.placeholder', 'candidates/train/Freezer/.placeholder', 'candidates/train/Trove/.placeholder', 'candidates/train/Masakari/.placeholder', 'candidates/train/Packaging_Rpm/.placeholder', 'candidates/train/Release_Management/.placeholder', 'candidates/train/Tricircle/.placeholder', 'candidates/train/Octavia/.placeholder', 'candidates/train/OpenStackClient/.placeholder', 'candidates/train/Cloudkitty/.placeholder', 'candidates/train/Magnum/.placeholder', 'candidates/train/Blazar/.placeholder', 'candidates/train/Designate/.placeholder', 'candidates/train/I18n/.placeholder', 'candidates/train/PowerVMStackers/.placeholder', 'configuration.yaml', 'candidates/train/Cinder/.placeholder', 'candidates/train/Karbor/.placeholder', 'candidates/train/Kolla/.placeholder', 'candidates/train/Glance/.placeholder', 'candidates/train/Requirements/.placeholder', 'candidates/train/Heat/.placeholder', 'candidates/train/Placement/.placeholder', 'candidates/train/Winstackers/.placeholder', 'candidates/train/Horizon/.placeholder', 'candidates/train/Congress/.placeholder', 'candidates/train/Solum/.placeholder', 'candidates/train/Tacker/.placeholder', 'candidates/train/Mistral/.placeholder', 'candidates/train/Manila/.placeholder', 'candidates/train/Loci/.placeholder', 'candidates/train/OpenStackSDK/.placeholder', 'candidates/train/Telemetry/.placeholder', 'candidates/train/Chef_OpenStack/.placeholder', 'candidates/train/Watcher/.placeholder', 'candidates/train/Neutron/.placeholder', 'candidates/train/Monasca/.placeholder', 'candidates/train/Nova/.placeholder', 'candidates/train/Sahara/.placeholder', 'candidates/train/Puppet_OpenStack/.placeholder', 'candidates/train/OpenStack_Helm/.placeholder', 'candidates/train/Senlin/.placeholder', 'candidates/train/Vitrage/.placeholder', 'candidates/train/Ec2_Api/.placeholder', 'candidates/train/Cyborg/.placeholder', 'candidates/train/OpenStackAnsible/.placeholder', 'candidates/train/Ironic/.placeholder', 'candidates/train/Zaqar/.placeholder'], 'web_link': 'https://opendev.org/openstack/election/commit/c16e33a4a702bf1e2be55bb844096f83cdae703c', 'message': 'Setup Train PTL election\n\n  Setting PTL Election\n  Release is at: 2019-04-10\n  Latest possible completion is at: 2019-03-20\n  Moving back to Tuesday: 2019-03-19\n  PTL Election from 2019-03-12T23:45 to 2019-03-19T23:45\n  PTL Nominations from 2019-03-05T23:45 to 2019-03-12T23:45\n  Set email_deadline to 2019-02-22T00:00\n  Setting PTL timeframe end to email_deadline\n  Begining of Rocky Cycle @ 2018-02-09 00:00:00+00:00\n  End of Stein cycle @ 2019-03-05 00:00:00+00:00\n  Election timeframe: 389 days, 0:00:00s\n\nNote we do NOT alter the email_deadline so we can leverage the rolls\ngenerated during the TC election.\n\nChange-Id: I2596102a6af02a17899b71e086f402c3d01d3c99\n'}]",1,629749,c16e33a4a702bf1e2be55bb844096f83cdae703c,22,6,4,12898,,,0,"Setup Train PTL election

  Setting PTL Election
  Release is at: 2019-04-10
  Latest possible completion is at: 2019-03-20
  Moving back to Tuesday: 2019-03-19
  PTL Election from 2019-03-12T23:45 to 2019-03-19T23:45
  PTL Nominations from 2019-03-05T23:45 to 2019-03-12T23:45
  Set email_deadline to 2019-02-22T00:00
  Setting PTL timeframe end to email_deadline
  Begining of Rocky Cycle @ 2018-02-09 00:00:00+00:00
  End of Stein cycle @ 2019-03-05 00:00:00+00:00
  Election timeframe: 389 days, 0:00:00s

Note we do NOT alter the email_deadline so we can leverage the rolls
generated during the TC election.

Change-Id: I2596102a6af02a17899b71e086f402c3d01d3c99
",git fetch https://review.opendev.org/openstack/election refs/changes/49/629749/4 && git format-patch -1 --stdout FETCH_HEAD,"['candidates/train/Murano/.placeholder', 'candidates/train/Rally/.placeholder', 'candidates/train/Oslo/.placeholder', 'candidates/train/Searchlight/.placeholder', 'candidates/train/Tripleo/.placeholder', 'candidates/train/Swift/.placeholder', 'candidates/train/Quality_Assurance/.placeholder', 'candidates/train/Qinling/.placeholder', 'candidates/train/Keystone/.placeholder', 'candidates/train/Zun/.placeholder', 'candidates/train/Kuryr/.placeholder', 'candidates/train/Barbican/.placeholder', 'candidates/train/Adjutant/.placeholder', 'candidates/train/Infrastructure/.placeholder', 'candidates/train/OpenStack_Charms/.placeholder', 'candidates/train/Storlets/.placeholder', 'candidates/train/Documentation/.placeholder', 'candidates/train/Freezer/.placeholder', 'candidates/train/Trove/.placeholder', 'candidates/train/Masakari/.placeholder', 'candidates/train/Packaging_Rpm/.placeholder', 'candidates/train/Release_Management/.placeholder', 'candidates/train/Tricircle/.placeholder', 'candidates/train/Octavia/.placeholder', 'candidates/train/OpenStackClient/.placeholder', 'candidates/train/Cloudkitty/.placeholder', 'candidates/train/Magnum/.placeholder', 'candidates/train/Blazar/.placeholder', 'candidates/train/Designate/.placeholder', 'candidates/train/I18n/.placeholder', 'candidates/train/PowerVMStackers/.placeholder', 'configuration.yaml', 'candidates/train/Cinder/.placeholder', 'candidates/train/Karbor/.placeholder', 'candidates/train/Kolla/.placeholder', 'candidates/train/Glance/.placeholder', 'candidates/train/Requirements/.placeholder', 'candidates/train/Heat/.placeholder', 'candidates/train/Winstackers/.placeholder', 'candidates/train/Horizon/.placeholder', 'candidates/train/Congress/.placeholder', 'candidates/train/Solum/.placeholder', 'candidates/train/Tacker/.placeholder', 'candidates/train/Mistral/.placeholder', 'candidates/train/Manila/.placeholder', 'candidates/train/Loci/.placeholder', 'candidates/train/OpenStackSDK/.placeholder', 'candidates/train/Telemetry/.placeholder', 'candidates/train/Chef_OpenStack/.placeholder', 'candidates/train/Watcher/.placeholder', 'candidates/train/Neutron/.placeholder', 'candidates/train/Monasca/.placeholder', 'candidates/train/Nova/.placeholder', 'candidates/train/Sahara/.placeholder', 'candidates/train/Puppet_OpenStack/.placeholder', 'candidates/train/OpenStack_Helm/.placeholder', 'candidates/train/Senlin/.placeholder', 'candidates/train/Vitrage/.placeholder', 'candidates/train/Ec2_Api/.placeholder', 'candidates/train/Cyborg/.placeholder', 'candidates/train/OpenStackAnsible/.placeholder', 'candidates/train/Ironic/.placeholder', 'candidates/train/Zaqar/.placeholder']",63,770d702788d879640b93eb5cb385e369d91228ec,setup-train-ptl,,,7,10
openstack%2Fsenlin-tempest-plugin~master~I9ed6724335852e0e1c89191600baa5c71777474c,openstack/senlin-tempest-plugin,master,I9ed6724335852e0e1c89191600baa5c71777474c,Update hacking version to latest,MERGED,2019-01-09 02:20:49.000000000,2019-03-06 00:19:16.000000000,2019-03-06 00:19:16.000000000,"[{'_account_id': 22348}, {'_account_id': 27224}, {'_account_id': 27565}]","[{'number': 1, 'created': '2019-01-09 02:20:49.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/d7dbf0d8eae51aa3a07941f0094ced227e7bb150', 'message': 'Update hacking version to latest\n\nChange-Id: I9ed6724335852e0e1c89191600baa5c71777474c\n'}]",0,629359,d7dbf0d8eae51aa3a07941f0094ced227e7bb150,6,3,1,27565,,,0,"Update hacking version to latest

Change-Id: I9ed6724335852e0e1c89191600baa5c71777474c
",git fetch https://review.opendev.org/openstack/senlin-tempest-plugin refs/changes/59/629359/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d7dbf0d8eae51aa3a07941f0094ced227e7bb150,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fsenlin~master~I8326be379de009b7e94e448254886829a692cbc5,openstack/senlin,master,I8326be379de009b7e94e448254886829a692cbc5,Fix detach LB policy when LB is not in ACTIVE and ONLINE,MERGED,2019-02-26 09:49:26.000000000,2019-03-06 00:11:03.000000000,2019-03-06 00:11:03.000000000,"[{'_account_id': 22348}, {'_account_id': 25674}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-02-26 09:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/0cc40e3206fbe4bacdf5de6f43fe60d69490d9ec', 'message': 'Fix detach LB policy when LB is not in ACTIVE and ONLINE\n\nChange-Id: I8326be379de009b7e94e448254886829a692cbc5\nCloses-Bug: #1817511\n'}, {'number': 2, 'created': '2019-02-27 10:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/13d3bcb85ef83bde165d33331e6b89d93ce7c0fd', 'message': 'Fix detach LB policy when LB is not in ACTIVE and ONLINE\n\nChange-Id: I8326be379de009b7e94e448254886829a692cbc5\nCloses-Bug: #1817511\n'}, {'number': 3, 'created': '2019-03-04 09:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/7dbeaa25b2e6ab19343cd63d4da41e9d3ff7d041', 'message': 'Fix detach LB policy when LB is not in ACTIVE and ONLINE\n\nChange-Id: I8326be379de009b7e94e448254886829a692cbc5\nCloses-Bug: #1817511\n'}, {'number': 4, 'created': '2019-03-05 07:22:38.000000000', 'files': ['senlin/drivers/os/lbaas.py', 'senlin/tests/unit/drivers/test_lbaas.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9a52f4a311e4999da18efb7294cff58f57e70c12', 'message': 'Fix detach LB policy when LB is not in ACTIVE and ONLINE\n\nChange-Id: I8326be379de009b7e94e448254886829a692cbc5\nCloses-Bug: #1817511\n'}]",0,639286,9a52f4a311e4999da18efb7294cff58f57e70c12,18,3,4,29960,,,0,"Fix detach LB policy when LB is not in ACTIVE and ONLINE

Change-Id: I8326be379de009b7e94e448254886829a692cbc5
Closes-Bug: #1817511
",git fetch https://review.opendev.org/openstack/senlin refs/changes/86/639286/4 && git format-patch -1 --stdout FETCH_HEAD,['senlin/drivers/os/lbaas.py'],1,0cc40e3206fbe4bacdf5de6f43fe60d69490d9ec,bug/1817511," res = self._wait_for_lb_ready(lb_id, ignore_not_found=True)", res = self._wait_for_lb_ready(lb_id),1,1
openstack%2Fnova~master~Ie320d7a7eb675bfdba2c907fd44b99c02974d343,openstack/nova,master,Ie320d7a7eb675bfdba2c907fd44b99c02974d343,api-ref: typo service.disable_reason,MERGED,2019-03-05 09:01:55.000000000,2019-03-06 00:08:11.000000000,2019-03-06 00:08:11.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-03-05 09:01:55.000000000', 'files': ['api-ref/source/os-hypervisors.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/14a67676340e865bbec2eea1245f65bc71e48e65', 'message': ""api-ref: typo service.disable_reason\n\n'disable_reason' should be 'disabled_reason'\n\nChange-Id: Ie320d7a7eb675bfdba2c907fd44b99c02974d343\n""}]",0,640956,14a67676340e865bbec2eea1245f65bc71e48e65,15,11,1,21692,,,0,"api-ref: typo service.disable_reason

'disable_reason' should be 'disabled_reason'

Change-Id: Ie320d7a7eb675bfdba2c907fd44b99c02974d343
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/640956/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-hypervisors.inc'],1,14a67676340e865bbec2eea1245f65bc71e48e65,doc_trivial, - service.disabled_reason: service_disable_reason - service.disabled_reason: service_disable_reason, - service.disable_reason: service_disable_reason - service.disable_reason: service_disable_reason,2,2
openstack%2Frequirements~master~If13f8fbad6b6392b138b3ea58f69e4f7e53f69a0,openstack/requirements,master,If13f8fbad6b6392b138b3ea58f69e4f7e53f69a0,Block bad stestr version,MERGED,2019-03-05 14:51:41.000000000,2019-03-06 00:08:07.000000000,2019-03-06 00:08:07.000000000,"[{'_account_id': 6593}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 14:51:41.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c3002c65e06135637876020b5fc37e2bbf6d31d5', 'message': 'Block bad stestr version\n\nhttps://github.com/mtreinish/stestr/issues/231\n\nTony reported the issue (and submitted a potential fix).\n\nChange-Id: If13f8fbad6b6392b138b3ea58f69e4f7e53f69a0\n'}]",0,641026,c3002c65e06135637876020b5fc37e2bbf6d31d5,9,3,1,14288,,,0,"Block bad stestr version

https://github.com/mtreinish/stestr/issues/231

Tony reported the issue (and submitted a potential fix).

Change-Id: If13f8fbad6b6392b138b3ea58f69e4f7e53f69a0
",git fetch https://review.opendev.org/openstack/requirements refs/changes/26/641026/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,c3002c65e06135637876020b5fc37e2bbf6d31d5,block-bad-stestr,stestr!=2.3.0 # Apache-2.0,stestr # Apache-2.0,1,1
openstack%2Fplacement~master~I32240fa6fefd9f431db59a656af000df95f146b6,openstack/placement,master,I32240fa6fefd9f431db59a656af000df95f146b6,Inline Consumer.increment_generation(),MERGED,2019-03-01 16:57:33.000000000,2019-03-05 23:57:42.000000000,2019-03-05 23:57:42.000000000,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 7634}, {'_account_id': 11224}, {'_account_id': 11564}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 16:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/acccd3905aefd59a3bad31b0dfa24a1f5eea01db', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 2, 'created': '2019-03-01 21:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/c592ee5827177202ddaefdacef808e8d61a314f1', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 3, 'created': '2019-03-01 21:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/41824d0ae16c5aacf356927a88ea6fde35c5e9d8', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 4, 'created': '2019-03-01 22:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/2f185c0d185fd3e7be6d7cd3646b11c60aecc5a8', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 5, 'created': '2019-03-01 22:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/db9648a5e23fcd282c01c4eb6f2b427c4914aed9', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 6, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/fbff269ce706e6c8b0ecbb68dfa018aab8c95f28', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 7, 'created': '2019-03-02 00:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/287aa4d8f31638c81297e320befd63d9cfc93174', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 8, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/16f5dcc583f1e6720b11b2df78d8362d3f353f40', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}, {'number': 9, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/objects/consumer.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/995464ab3a8e5d2becac9fb4202a54e939f1077c', 'message': 'Inline Consumer.increment_generation()\n\nConsumer.increment_generation() was previously a thin wrapper around a\nmodule-level _increment_consumer_generation method. With this patch, we\ninline that method. In so doing, we remove a @writer decorator; but the\none place this was being called from was already wrapped in a @writer.\n\nChange-Id: I32240fa6fefd9f431db59a656af000df95f146b6\n'}]",0,640437,995464ab3a8e5d2becac9fb4202a54e939f1077c,25,6,9,14070,,,0,"Inline Consumer.increment_generation()

Consumer.increment_generation() was previously a thin wrapper around a
module-level _increment_consumer_generation method. With this patch, we
inline that method. In so doing, we remove a @writer decorator; but the
one place this was being called from was already wrapped in a @writer.

Change-Id: I32240fa6fefd9f431db59a656af000df95f146b6
",git fetch https://review.opendev.org/openstack/placement refs/changes/37/640437/9 && git format-patch -1 --stdout FETCH_HEAD,['placement/objects/consumer.py'],1,acccd3905aefd59a3bad31b0dfa24a1f5eea01db,scrub-Lists," consumer_gen = self.generation new_generation = consumer_gen + 1 upd_stmt = CONSUMER_TBL.update().where(sa.and_( CONSUMER_TBL.c.id == self.id, CONSUMER_TBL.c.generation == consumer_gen)).values( generation=new_generation) res = self._context.session.execute(upd_stmt) if res.rowcount != 1: raise exception.ConcurrentUpdateDetected self.generation = new_generation","def _increment_consumer_generation(ctx, consumer): """"""Increments the supplied consumer's generation value, supplying the consumer object which contains the currently-known generation. Returns the newly-incremented generation. :param ctx: `placement.context.RequestContext` that contains an oslo_db Session :param consumer: `Consumer` whose generation should be updated. :returns: The newly-incremented generation. :raises placement.exception.ConcurrentUpdateDetected: if another thread updated the same consumer's view of its allocations in between the time when this object was originally read and the call which modified the consumer's state (e.g. replacing allocations for a consumer) """""" consumer_gen = consumer.generation new_generation = consumer_gen + 1 upd_stmt = CONSUMER_TBL.update().where(sa.and_( CONSUMER_TBL.c.id == consumer.id, CONSUMER_TBL.c.generation == consumer_gen)).values( generation=new_generation) res = ctx.session.execute(upd_stmt) if res.rowcount != 1: raise exception.ConcurrentUpdateDetected return new_generation @db_api.placement_context_manager.writer self.generation = _increment_consumer_generation(self._context, self)",11,30
openstack%2Fcinder~master~I082f5f1e00d4bc2c5e42c81620afd1a37f4f5c83,openstack/cinder,master,I082f5f1e00d4bc2c5e42c81620afd1a37f4f5c83,Improve documentation of goodness/filter function,MERGED,2019-02-22 19:05:33.000000000,2019-03-05 23:57:39.000000000,2019-03-05 23:57:39.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29650}]","[{'number': 1, 'created': '2019-02-22 19:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c4fae522efb87c16ae5ff7b8d6ae657462f645bc', 'message': 'Improve documentation of goodness/filter function\n\nBetter explain DriverFilter and GoodnessWeigher usage.\n\nChange-Id: I082f5f1e00d4bc2c5e42c81620afd1a37f4f5c83\n'}, {'number': 2, 'created': '2019-02-25 11:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2dd148ee8c05323ad24ec2d3db24e1fd07b36ab3', 'message': 'Improve documentation of goodness/filter function\n\nBetter explain DriverFilter and GoodnessWeigher usage.\n\nChange-Id: I082f5f1e00d4bc2c5e42c81620afd1a37f4f5c83\n'}, {'number': 3, 'created': '2019-02-25 11:37:59.000000000', 'files': ['doc/source/admin/blockstorage-driver-filter-weighing.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/83b90f78a7bac7dd8071575ed0f8b3a1e9f168fd', 'message': 'Improve documentation of goodness/filter function\n\nBetter explain DriverFilter and GoodnessWeigher usage.\n\nChange-Id: I082f5f1e00d4bc2c5e42c81620afd1a37f4f5c83\n'}]",5,638752,83b90f78a7bac7dd8071575ed0f8b3a1e9f168fd,54,31,3,29650,,,0,"Improve documentation of goodness/filter function

Better explain DriverFilter and GoodnessWeigher usage.

Change-Id: I082f5f1e00d4bc2c5e42c81620afd1a37f4f5c83
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/638752/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/blockstorage-driver-filter-weighing.rst'],1,c4fae522efb87c16ae5ff7b8d6ae657462f645bc,goodness-function-doc,"the ``cinder.conf`` file to ``DriverFilter``. The DriverFilter can also be used along with other filters by adding it to the list if other filters are already present. The GoodnessWeigher can be used along with CapacityWeigher and others, but must be used with caution as it might obfuscate the CapacityWeigher. these. Using them together should be done with caution as depending on the defined logic, one might obfuscate the other. In order to access these properties, use the following format: ``stats.<property>`` free\_capacity\_gb The free capacity in GB may not have any properties available here. Once the capabilities vary too much according to the backend, it is better to check its properties reported on the scheduler log. The scheduler reports these capabilities constantly. In order to access these properties, use the following format: ``capabilities.<property>``In order to access the volume properties, use the following format: ``volume.<property>`` handle volume requests for all volumes with a size less than 5 GB. Both lvm-1 and lvm-2 will have the same priority while lvm-1 contains 3 or less volumes, after that lvm-2 will have priority while it contains 8 or less",the ``cinder.conf`` file to ``DriverFilter`` or add it to the list if other filters are already present. The support for the ``DriverFilter`` and ``GoodnessWeigher`` is optional for back ends. If you are using a back end that does not support the filter and weigher functionality you may not get the full benefit. these.may not have any properties available here.handle volume requests for all volumes with a size less than 5 GB. The lvm-1 host will have priority until it contains three or more volumes. After than lvm-2 will have priority until it contains eight or more,26,11
openstack%2Fswift~master~I2a354e2624c763a68fcea7a6404e9c2fde30d631,openstack/swift,master,I2a354e2624c763a68fcea7a6404e9c2fde30d631,docs: clean up SAIO formatting,MERGED,2019-03-05 01:37:59.000000000,2019-03-05 23:57:37.000000000,2019-03-05 23:57:36.000000000,"[{'_account_id': 9625}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 01:37:59.000000000', 'files': ['swift/common/middleware/s3api/controllers/s3_acl.py', 'doc/source/development_saio.rst', 'swift/common/bufferedhttp.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d185b607bbdda8b47b0bb090f045a6b4ad8ed8b9', 'message': 'docs: clean up SAIO formatting\n\nDrive-by: use six.moves in s3api; fix ""unexpected indent"" warning when building\ndocs on py3\n\nChange-Id: I2a354e2624c763a68fcea7a6404e9c2fde30d631\n'}]",0,640914,d185b607bbdda8b47b0bb090f045a6b4ad8ed8b9,6,2,1,15343,,,0,"docs: clean up SAIO formatting

Drive-by: use six.moves in s3api; fix ""unexpected indent"" warning when building
docs on py3

Change-Id: I2a354e2624c763a68fcea7a6404e9c2fde30d631
",git fetch https://review.opendev.org/openstack/swift refs/changes/14/640914/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/controllers/s3_acl.py', 'doc/source/development_saio.rst', 'swift/common/bufferedhttp.py']",3,d185b607bbdda8b47b0bb090f045a6b4ad8ed8b9,," '''Send a request to the server. :param method: specifies an HTTP request method, e.g. 'GET'. :param url: specifies the object being requested, e.g. '/index.html'. :param skip_host: if True does not add automatically a 'Host:' header :param skip_accept_encoding: if True does not add automatically an 'Accept-Encoding:' header '''",,332,291
openstack%2Fpyeclib~master~I5f81ddd6df1970bef3a2614126bce0eb78f44473,openstack/pyeclib,master,I5f81ddd6df1970bef3a2614126bce0eb78f44473,Use liberasurecode_get_version(),MERGED,2019-02-13 20:27:58.000000000,2019-03-05 23:40:03.000000000,2019-03-05 23:40:03.000000000,"[{'_account_id': 9625}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 20:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/a99d8ca51c167367f279620405fb4e59c52afc78', 'message': 'Use liberasurecode_get_version()\n\n... to determine whether we have a supported version. Note that this\nwas introduced in libec 1.4.0, so increase our minimum supported\nversion, too.\n\nChange-Id: I5f81ddd6df1970bef3a2614126bce0eb78f44473\nCloses-Bug: 1780320\n'}, {'number': 2, 'created': '2019-02-13 22:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/7202ea70176a9aaf26f1fa57f3660151eed56074', 'message': ""Use liberasurecode_get_version()\n\n... to determine whether we have a supported version. If not\navailable, fall back to file name parsing to check the version,\nkeeping in mind that we haven't yet released a v2.\n\nChange-Id: I5f81ddd6df1970bef3a2614126bce0eb78f44473\nCloses-Bug: 1780320\n""}, {'number': 3, 'created': '2019-02-13 22:38:46.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/931c4e4559afeeaf1ea5867b1d44132626f2b575', 'message': ""Use liberasurecode_get_version()\n\n... to determine whether we have a supported version. If not\navailable, fall back to file name parsing to check the version,\nkeeping in mind that we haven't yet released a v2.\n\nChange-Id: I5f81ddd6df1970bef3a2614126bce0eb78f44473\nCloses-Bug: 1780320\n""}]",0,636748,931c4e4559afeeaf1ea5867b1d44132626f2b575,10,2,3,15343,,,0,"Use liberasurecode_get_version()

... to determine whether we have a supported version. If not
available, fall back to file name parsing to check the version,
keeping in mind that we haven't yet released a v2.

Change-Id: I5f81ddd6df1970bef3a2614126bce0eb78f44473
Closes-Bug: 1780320
",git fetch https://review.opendev.org/openstack/pyeclib refs/changes/48/636748/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,a99d8ca51c167367f279620405fb4e59c52afc78,,"import ctypes libec = ctypes.CDLL(found_path) try: packed_version = libec.liberasurecode_get_version() except Exception: pass else: version = ( packed_version >> 16, (packed_version >> 8) & 0xff, packed_version & 0xff) if (1, 4, 0) <= version < (2, 0, 0): return"," if found_path.endswith(library_version) or \ found_path.find(library_version + ""."") > -1: # call 1.x.x the only compatible version for now return",13,4
openstack%2Fpython-senlinclient~master~I5e7859382e7cc988b2c63de74d868caea604669a,openstack/python-senlinclient,master,I5e7859382e7cc988b2c63de74d868caea604669a,add python 3.7 unit test job,MERGED,2019-02-19 09:06:05.000000000,2019-03-05 23:33:05.000000000,2019-03-05 23:33:05.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-02-19 09:06:05.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/56938d3ac1f4c1b6f93a81a65f74d46e1735183e', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I5e7859382e7cc988b2c63de74d868caea604669a\nStory: #2004073\nTask: #27452\n'}]",0,637755,56938d3ac1f4c1b6f93a81a65f74d46e1735183e,7,3,1,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I5e7859382e7cc988b2c63de74d868caea604669a
Story: #2004073
Task: #27452
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/55/637755/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,56938d3ac1f4c1b6f93a81a65f74d46e1735183e,py37-job, - openstack-python37-jobs,,1,0
openstack%2Fpython-senlinclient~master~I157091c5ff09cc01f7e170311c17166bdfd9cab3,openstack/python-senlinclient,master,I157091c5ff09cc01f7e170311c17166bdfd9cab3,Update hacking version,MERGED,2018-12-28 15:04:47.000000000,2019-03-05 23:32:15.000000000,2019-03-05 23:32:14.000000000,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27224}, {'_account_id': 28543}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-12-28 15:04:47.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/c21e57deb007f96298ad20760c111e7a413c1ac5', 'message': 'Update hacking version\n\nChange-Id: I157091c5ff09cc01f7e170311c17166bdfd9cab3\n'}]",0,627710,c21e57deb007f96298ad20760c111e7a413c1ac5,10,5,1,21691,,,0,"Update hacking version

Change-Id: I157091c5ff09cc01f7e170311c17166bdfd9cab3
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/10/627710/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c21e57deb007f96298ad20760c111e7a413c1ac5,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Frpm-packaging~master~I7aa763be06f3a509c97aa80d104b49b59d303088,openstack/rpm-packaging,master,I7aa763be06f3a509c97aa80d104b49b59d303088,oslo.vmware: Update to 2.32.2,MERGED,2019-03-05 15:40:19.000000000,2019-03-05 22:14:33.000000000,2019-03-05 22:14:33.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:40:19.000000000', 'files': ['openstack/oslo.vmware/oslo.vmware.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2934413379db410cc2089e390e3a9268536e3277', 'message': 'oslo.vmware: Update to 2.32.2\n\nChange-Id: I7aa763be06f3a509c97aa80d104b49b59d303088\n'}]",0,641051,2934413379db410cc2089e390e3a9268536e3277,8,4,1,7102,,,0,"oslo.vmware: Update to 2.32.2

Change-Id: I7aa763be06f3a509c97aa80d104b49b59d303088
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/51/641051/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.vmware/oslo.vmware.spec.j2'],1,2934413379db410cc2089e390e3a9268536e3277,,{% set upstream_version = upstream_version('2.32.2') %},{% set upstream_version = upstream_version('2.32.1') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~I8b98a9e020a0fad2729e9709257e6d92572f5793,openstack/rpm-packaging,master,I8b98a9e020a0fad2729e9709257e6d92572f5793,oslo.i18n: Update to 3.32.1,MERGED,2019-03-05 15:17:37.000000000,2019-03-05 22:12:01.000000000,2019-03-05 22:12:01.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:17:37.000000000', 'files': ['openstack/oslo.i18n/oslo.i18n.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/55c35cd080bbc0018fcaea6a530afc9146d3004b', 'message': 'oslo.i18n: Update to 3.32.1\n\nChange-Id: I8b98a9e020a0fad2729e9709257e6d92572f5793\n'}]",0,641031,55c35cd080bbc0018fcaea6a530afc9146d3004b,8,4,1,7102,,,0,"oslo.i18n: Update to 3.32.1

Change-Id: I8b98a9e020a0fad2729e9709257e6d92572f5793
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/31/641031/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.i18n/oslo.i18n.spec.j2'],1,55c35cd080bbc0018fcaea6a530afc9146d3004b,,{% set upstream_version = upstream_version('3.23.1') %},{% set upstream_version = upstream_version('3.23.0') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~If16c733d58e8652cece037aba52253bde62069ec,openstack/rpm-packaging,master,If16c733d58e8652cece037aba52253bde62069ec,oslo.upgradecheck: Update to 0.2.1,MERGED,2019-03-05 15:36:58.000000000,2019-03-05 22:08:38.000000000,2019-03-05 22:08:37.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:36:58.000000000', 'files': ['openstack/oslo.upgradecheck/oslo.upgradecheck.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bf129cec687952e1f04712282ff0e9eca97720b8', 'message': 'oslo.upgradecheck: Update to 0.2.1\n\nChange-Id: If16c733d58e8652cece037aba52253bde62069ec\n'}]",0,641049,bf129cec687952e1f04712282ff0e9eca97720b8,8,4,1,7102,,,0,"oslo.upgradecheck: Update to 0.2.1

Change-Id: If16c733d58e8652cece037aba52253bde62069ec
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/49/641049/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.upgradecheck/oslo.upgradecheck.spec.j2'],1,bf129cec687952e1f04712282ff0e9eca97720b8,,{% set upstream_version = upstream_version('0.2.1') %},{% set upstream_version = upstream_version('0.2.0') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~I6c5b225b481a0a7ae785584d3796b10c40628199,openstack/rpm-packaging,master,I6c5b225b481a0a7ae785584d3796b10c40628199,oslo.reports: Update to 1.29.2,MERGED,2019-03-05 15:32:42.000000000,2019-03-05 22:08:13.000000000,2019-03-05 22:08:12.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:32:42.000000000', 'files': ['openstack/oslo.reports/oslo.reports.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e8610fc51c76facabd34c3b8291d11db4cf3629d', 'message': 'oslo.reports: Update to 1.29.2\n\nChange-Id: I6c5b225b481a0a7ae785584d3796b10c40628199\n'}]",0,641044,e8610fc51c76facabd34c3b8291d11db4cf3629d,9,4,1,7102,,,0,"oslo.reports: Update to 1.29.2

Change-Id: I6c5b225b481a0a7ae785584d3796b10c40628199
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/44/641044/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.reports/oslo.reports.spec.j2'],1,e8610fc51c76facabd34c3b8291d11db4cf3629d,,{% set upstream_version = upstream_version('1.29.2') %},{% set upstream_version = upstream_version('1.29.1') %}sed -i 's/^warning-is-error.*/warning-is-error = 0/g' setup.cfg,1,2
openstack%2Frpm-packaging~master~Ib0cb0704f0e8479893e0c5074c67f40a9e0b7c5d,openstack/rpm-packaging,master,Ib0cb0704f0e8479893e0c5074c67f40a9e0b7c5d,oslo.context: Update to 2.22.1,MERGED,2019-03-05 15:12:36.000000000,2019-03-05 22:08:12.000000000,2019-03-05 22:08:12.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 15:12:36.000000000', 'files': ['openstack/oslo.context/oslo.context.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5293404fea0e37a034fc04c4e0d8f9775404f2c4', 'message': 'oslo.context: Update to 2.22.1\n\nChange-Id: Ib0cb0704f0e8479893e0c5074c67f40a9e0b7c5d\n'}]",0,641029,5293404fea0e37a034fc04c4e0d8f9775404f2c4,8,4,1,7102,,,0,"oslo.context: Update to 2.22.1

Change-Id: Ib0cb0704f0e8479893e0c5074c67f40a9e0b7c5d
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/29/641029/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.context/oslo.context.spec.j2'],1,5293404fea0e37a034fc04c4e0d8f9775404f2c4,,"{% set upstream_version = upstream_version('2.22.1') %}BuildRequires: {{ py2pkg('fixtures', py_versions=['py2', 'py3']) }}BuildRequires: {{ py2pkg('stestr', py_versions=['py2', 'py3']) }}","{% set upstream_version = upstream_version('2.22.0') %}BuildRequires: {{ py2pkg('stestr', py_versions=['py2', 'py3']) }}",3,2
openstack%2Fopenstack-helm-infra~master~Ibee5550db788ea57879837b010e22a24240237bf,openstack/openstack-helm-infra,master,Ibee5550db788ea57879837b010e22a24240237bf,[ceph-osd] resolve name conflicts by appending release name,MERGED,2019-03-04 21:28:40.000000000,2019-03-05 21:48:35.000000000,2019-03-05 21:48:35.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22713}, {'_account_id': 23928}, {'_account_id': 24165}, {'_account_id': 28372}, {'_account_id': 29132}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-03-04 21:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1fdcccdf658eab260f6d2ed02fdc3220a17d4b67', 'message': '[ceph-osd] resolve name conflicts by appending release name\n\nThis is to resolve name conflicts of reources in case of multiple\nreleases required for single deployment of ceph cluster\n\nChange-Id: Ibee5550db788ea57879837b010e22a24240237bf\n'}, {'number': 2, 'created': '2019-03-04 21:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/00fe931ad935d5a0785555f60f4ee134ea2ff384', 'message': '[ceph-osd] resolve name conflicts by appending release name\n\nThis is to resolve name conflicts of reources in case of multiple\nreleases required for single deployment of ceph cluster\n\nChange-Id: Ibee5550db788ea57879837b010e22a24240237bf\n'}, {'number': 3, 'created': '2019-03-04 22:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a9aede83cf08f7c86c890057bb3eb1a7c1c50313', 'message': '[ceph-osd] resolve name conflicts by appending release name\n\nThis is to resolve name conflicts of reources in case of multiple\nreleases required for single deployment of ceph cluster\n\nChange-Id: Ibee5550db788ea57879837b010e22a24240237bf\n'}, {'number': 4, 'created': '2019-03-04 22:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0cdb90ff8917f99048ebe4e549e23ee894c92089', 'message': '[ceph-osd] resolve name conflicts by appending release name\n\nThis is to resolve name conflicts of reources in case of multiple\nreleases required for single deployment of ceph cluster\n\nChange-Id: Ibee5550db788ea57879837b010e22a24240237bf\n'}, {'number': 5, 'created': '2019-03-05 04:39:07.000000000', 'files': ['ceph-osd/templates/daemonset-osd.yaml', 'ceph-osd/templates/configmap-bin.yaml', 'ceph-osd/templates/cronjob-defragosds.yaml', 'ceph-osd/templates/configmap-etc.yaml', 'ceph-osd/templates/pod-helm-tests.yaml', 'ceph-osd/templates/job-bootstrap.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/47d429059cbc3a500a39392ea10569d514d685ca', 'message': '[ceph-osd] resolve name conflicts by appending release name\n\nThis is to resolve name conflicts of reources in case of multiple\nreleases required for single deployment of ceph cluster\n\nChange-Id: Ibee5550db788ea57879837b010e22a24240237bf\n'}]",5,640877,47d429059cbc3a500a39392ea10569d514d685ca,26,9,5,28372,,,0,"[ceph-osd] resolve name conflicts by appending release name

This is to resolve name conflicts of reources in case of multiple
releases required for single deployment of ceph cluster

Change-Id: Ibee5550db788ea57879837b010e22a24240237bf
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/77/640877/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-osd/templates/daemonset-osd.yaml', 'ceph-osd/templates/cronjob-defragosds.yaml', 'ceph-osd/templates/configmap-etc.yaml', 'ceph-osd/templates/pod-helm-tests.yaml', 'ceph-osd/templates/job-bootstrap.yaml']",5,1fdcccdf658eab260f6d2ed02fdc3220a17d4b67,multiple-osd-releases," name: {{ printf ""%s-%s"" $envAll.Release.Name ""ceph-osd-bin"" | quote }}", name: ceph-osd-etc,7,7
openstack%2Fcharm-swift-proxy~master~I567805dd595138acc6147edfda7fa364c8395f81,openstack/charm-swift-proxy,master,I567805dd595138acc6147edfda7fa364c8395f81,upgrade: Fix pike to queens upgrade,MERGED,2019-03-05 11:45:10.000000000,2019-03-05 21:42:34.000000000,2019-03-05 21:42:34.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 11:45:10.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/cli/unitdata.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/525f755281b63ca32be05c957f5e2f660a5d2dd5', 'message': 'upgrade: Fix pike to queens upgrade\n\napt.version_compare changed behaviour to return >= 1 in the event\nthat a newer package version is detected.\n\nResync charmhelpers code to pickup fixes for openstack upgrade\ndetection.\n\nChange-Id: I567805dd595138acc6147edfda7fa364c8395f81\nCloses-Bug: 1817384\n'}]",0,640986,525f755281b63ca32be05c957f5e2f660a5d2dd5,9,3,1,935,,,0,"upgrade: Fix pike to queens upgrade

apt.version_compare changed behaviour to return >= 1 in the event
that a newer package version is detected.

Resync charmhelpers code to pickup fixes for openstack upgrade
detection.

Change-Id: I567805dd595138acc6147edfda7fa364c8395f81
Closes-Bug: 1817384
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/86/640986/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/cli/unitdata.py']",4,525f755281b63ca32be05c957f5e2f660a5d2dd5,bug/1817384," getrange_cmd = nested.add_parser('getrange', help='Retrieve multiple data') getrange_cmd.add_argument('key', metavar='prefix', help='Prefix of the keys to retrieve') getrange_cmd.set_defaults(action='getrange', value=None) elif action == 'getrange': return unitdata.kv().getrange(key)",,18,17
openstack%2Fcharm-swift-storage~master~Iacf8db9bbacca782646584a4982b265937b63b9e,openstack/charm-swift-storage,master,Iacf8db9bbacca782646584a4982b265937b63b9e,upgrade: Fix pike to queens upgrade,MERGED,2019-03-05 11:48:38.000000000,2019-03-05 21:39:22.000000000,2019-03-05 21:39:22.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 11:48:38.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/audits/__init__.py', 'charmhelpers/contrib/openstack/templates/section-oslo-messaging-rabbit', 'charmhelpers/cli/unitdata.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/976391951e6a50011c6db34757b71282f13d502c', 'message': 'upgrade: Fix pike to queens upgrade\n\napt.version_compare changed behaviour to return >= 1 in the event\nthat a newer package version is detected.\n\nResync charmhelpers code to pickup fixes for openstack upgrade\ndetection.\n\nChange-Id: Iacf8db9bbacca782646584a4982b265937b63b9e\nCloses-Bug: 1817384\n'}]",0,640989,976391951e6a50011c6db34757b71282f13d502c,9,3,1,935,,,0,"upgrade: Fix pike to queens upgrade

apt.version_compare changed behaviour to return >= 1 in the event
that a newer package version is detected.

Resync charmhelpers code to pickup fixes for openstack upgrade
detection.

Change-Id: Iacf8db9bbacca782646584a4982b265937b63b9e
Closes-Bug: 1817384
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/89/640989/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/audits/__init__.py', 'charmhelpers/contrib/openstack/templates/section-oslo-messaging-rabbit', 'charmhelpers/cli/unitdata.py']",10,976391951e6a50011c6db34757b71282f13d502c,bug/1817384," getrange_cmd = nested.add_parser('getrange', help='Retrieve multiple data') getrange_cmd.add_argument('key', metavar='prefix', help='Prefix of the keys to retrieve') getrange_cmd.set_defaults(action='getrange', value=None) elif action == 'getrange': return unitdata.kv().getrange(key)",,889,99
openstack%2Fmanila~master~Ie3c609cba8b73640c4cea086bb2400b49209562e,openstack/manila,master,Ie3c609cba8b73640c4cea086bb2400b49209562e,Move grenade job to bionic and run with python 3,MERGED,2019-01-14 16:32:59.000000000,2019-03-05 21:06:59.000000000,2019-03-05 21:06:59.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-01-14 16:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/847abe7388df460a6dd88471084f3eb2b42d41e4', 'message': 'Move grenade job to bionic\n\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}, {'number': 2, 'created': '2019-01-14 18:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3bca5e2fe35a7a0a438ed5c0bdc092017e1578b3', 'message': 'Move grenade job to bionic and run with python 3\n\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}, {'number': 3, 'created': '2019-01-14 20:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0e228911a863a4dea84ae885e66f851e2a43a162', 'message': 'Move grenade job to bionic and run with python 3\n\nDepends-On: https://review.openstack.org/#/c/607379/\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}, {'number': 4, 'created': '2019-01-15 12:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/acbe36d230d89b65afd4d0686abfed62efee3761', 'message': 'Move grenade job to bionic and run with python 3\n\nDepends-On: https://review.openstack.org/630961\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}, {'number': 5, 'created': '2019-02-07 00:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7c83d925ac22fb16fe510e167a9e2013642981bb', 'message': 'Move grenade job to bionic and run with python 3\n\nDepends-On: https://review.openstack.org/630961\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}, {'number': 6, 'created': '2019-02-28 16:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/21662b85839c9dda0b46f2c260ecdfdd641f62f8', 'message': 'Move grenade job to bionic and run with python 3\n\nDepends-On: https://review.openstack.org/630961\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}, {'number': 7, 'created': '2019-03-01 11:10:39.000000000', 'files': ['playbooks/legacy/grenade-dsvm-manila/post.yaml', '.zuul.yaml', 'playbooks/legacy/grenade-dsvm-manila/run.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/86426a3eeb06ebbc34cffd2b886ef0fa1488a166', 'message': 'Move grenade job to bionic and run with python 3\n\nDepends-On: https://review.openstack.org/630961\nChange-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e\n'}]",0,630727,86426a3eeb06ebbc34cffd2b886ef0fa1488a166,90,14,7,9003,,,0,"Move grenade job to bionic and run with python 3

Depends-On: https://review.openstack.org/630961
Change-Id: Ie3c609cba8b73640c4cea086bb2400b49209562e
",git fetch https://review.opendev.org/openstack/manila refs/changes/27/630727/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/grenade-dsvm-manila/post.yaml', '.zuul.yaml']",2,847abe7388df460a6dd88471084f3eb2b42d41e4,zorilla-meets-bionic-beaver, name: manila-grenade parent: manila-tempest-base run: playbooks/legacy/grenade-dsvm-manila/run.yaml post-run: playbooks/legacy/grenade-dsvm-manila/post.yaml timeout: 10800 required-projects: - openstack-dev/grenade - openstack-infra/devstack-gate - openstack/manila - openstack/python-manilaclient - openstack/manila-tempest-plugin - job:, name: manila-grenade parent: legacy-dsvm-base run: playbooks/legacy/grenade-dsvm-manila/run.yaml post-run: playbooks/legacy/grenade-dsvm-manila/post.yaml timeout: 10800 irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^manila/hacking/.*$ - ^manila/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ required-projects: - openstack-dev/grenade - openstack-infra/devstack-gate - openstack/manila - openstack/python-manilaclient - openstack/manila-tempest-plugin - job:,14,25
openstack%2Fnova~master~Iac07fcddd4cc3321c6efe702066eb8af6a875418,openstack/nova,master,Iac07fcddd4cc3321c6efe702066eb8af6a875418,Fix an error when generating a host ID,MERGED,2019-02-28 07:17:58.000000000,2019-03-05 20:42:40.000000000,2019-03-05 20:42:39.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-28 07:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ad3466a277d695c46142fe7e45b91b34b7674dd', 'message': 'Fix an error when generating a host ID\n\nWhen instance action events are created by periodic tasks,\nthe project IDs of them become null (None).\nIt causes an error when \'hostId\' is generated\nin the ""Show Server Action Details""\n(GET /servers/{server_id}/os-instance-actions/{request_id})\nAPI.\n\nFix the issue by using the project ID of the server\nif the project ID of the event is None.\n\nChange-Id: Iac07fcddd4cc3321c6efe702066eb8af6a875418\nCloses-Bug: #1817542\n'}, {'number': 2, 'created': '2019-03-04 05:55:25.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_instance_actions.py', 'nova/api/openstack/compute/instance_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/31fe7c76009e1c6d7859036e44b057d081b059b5', 'message': 'Fix an error when generating a host ID\n\nWhen instance action events are created by periodic tasks,\nthe project IDs of them become null (None).\nIt causes an error when \'hostId\' is generated\nin the ""Show Server Action Details""\n(GET /servers/{server_id}/os-instance-actions/{request_id})\nAPI.\n\nFix the issue by using the project ID of the server\nif the project ID of the event is None.\n\nChange-Id: Iac07fcddd4cc3321c6efe702066eb8af6a875418\nCloses-Bug: #1817542\n'}]",6,639936,31fe7c76009e1c6d7859036e44b057d081b059b5,60,17,2,7634,,,0,"Fix an error when generating a host ID

When instance action events are created by periodic tasks,
the project IDs of them become null (None).
It causes an error when 'hostId' is generated
in the ""Show Server Action Details""
(GET /servers/{server_id}/os-instance-actions/{request_id})
API.

Fix the issue by using the project ID of the server
if the project ID of the event is None.

Change-Id: Iac07fcddd4cc3321c6efe702066eb8af6a875418
Closes-Bug: #1817542
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/639936/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_instance_actions.py', 'nova/api/openstack/compute/instance_actions.py']",2,1ad3466a277d695c46142fe7e45b91b34b7674dd,bug/1817542," evt, action['project_id'] or instance.project_id, show_traceback=show_traceback,"," evt, action['project_id'], show_traceback=show_traceback,",62,2
openstack%2Fpython-senlinclient~master~I2fff7c2cc1bb17c0e32ef5b67294b811aff22192,openstack/python-senlinclient,master,I2fff7c2cc1bb17c0e32ef5b67294b811aff22192,Update client to account for 409 error in cluster actions,MERGED,2018-07-25 21:12:05.000000000,2019-03-05 20:28:49.000000000,2019-03-05 20:28:49.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 23517}, {'_account_id': 25674}, {'_account_id': 27224}]","[{'number': 1, 'created': '2018-07-25 21:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/d113813b241befd0cf8fa4d7981eadf535b86a33', 'message': 'Update client to account for 409 error in cluster actions\n\nThis patch allows the senlin client to properly parse a 409\nerror when a scaling action fails due to a conflict or cooldown\n\nDepends-On: https://review.openstack.org/585573\nChange-Id: I2fff7c2cc1bb17c0e32ef5b67294b811aff22192\n'}, {'number': 2, 'created': '2018-07-25 21:59:21.000000000', 'files': ['senlinclient/v1/cluster.py', '.gitignore'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/87b7b13ea9c74c75e02bfa974f4cdca9340320e2', 'message': 'Update client to account for 409 error in cluster actions\n\nThis patch allows the senlin client to properly parse a 409\nerror when a scaling action fails due to a conflict or cooldown\n\nDepends-On: https://review.openstack.org/585573\nChange-Id: I2fff7c2cc1bb17c0e32ef5b67294b811aff22192\n'}]",2,585888,87b7b13ea9c74c75e02bfa974f4cdca9340320e2,16,5,2,25674,,,0,"Update client to account for 409 error in cluster actions

This patch allows the senlin client to properly parse a 409
error when a scaling action fails due to a conflict or cooldown

Depends-On: https://review.openstack.org/585573
Change-Id: I2fff7c2cc1bb17c0e32ef5b67294b811aff22192
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/88/585888/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/v1/cluster.py', '.gitignore']",2,d113813b241befd0cf8fa4d7981eadf535b86a33,action_cool_down,.coverage.* .idea,,12,0
openstack%2Ftripleo-quickstart~master~I617818478530eafc7b7d922b5373da77c02f96f3,openstack/tripleo-quickstart,master,I617818478530eafc7b7d922b5373da77c02f96f3,Activate validate-services on fs056,MERGED,2019-02-28 06:14:59.000000000,2019-03-05 20:11:34.000000000,2019-03-05 20:11:34.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}, {'_account_id': 28223}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-02-28 06:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/84bda0009e220bb17b0c203dd49a521b0a3d6796', 'message': ""Activate validate-services on fs056\n\nThis will allow to test this new role and ensure we don't get\nfalse-positive.\n\nChange-Id: I617818478530eafc7b7d922b5373da77c02f96f3\n""}, {'number': 2, 'created': '2019-02-28 06:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/12ca8d3983916f0bfe648d4b3050def915493b70', 'message': ""Activate validate-services on fs056\n\nThis will allow to test this new role and ensure we don't get\nfalse-positive.\n\nContext: https://review.openstack.org/637729\n\nChange-Id: I617818478530eafc7b7d922b5373da77c02f96f3\n""}, {'number': 3, 'created': '2019-02-28 08:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b9fe86243346680f7a158d4eb4c8e6d72418d521', 'message': ""Activate validate-services on fs056\n\nThis will allow to test this new role and ensure we don't get\nfalse-positive.\n\nContext: https://review.openstack.org/637729\n\nDepends-On: https://review.openstack.org/639950\nChange-Id: I617818478530eafc7b7d922b5373da77c02f96f3\n""}, {'number': 4, 'created': '2019-02-28 12:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/28affd038d938b0f2ef4c19227b0500f4070e5df', 'message': ""Activate validate-services on fs056\n\nThis will allow to test this new role and ensure we don't get\nfalse-positive.\n\nContext: https://review.openstack.org/637729\n\nDepends-On: https://review.openstack.org/640013\nChange-Id: I617818478530eafc7b7d922b5373da77c02f96f3\n""}, {'number': 5, 'created': '2019-03-01 08:41:32.000000000', 'files': ['config/general_config/featureset056.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/9ad2f999815d546adc5f6214e748fe77f52f7deb', 'message': ""Activate validate-services on fs056\n\nThis will allow to test this new role and ensure we don't get\nfalse-positive.\n\nContext: https://review.openstack.org/637729\n\nDepends-On: https://review.openstack.org/639950\nChange-Id: I617818478530eafc7b7d922b5373da77c02f96f3\n""}]",0,639926,9ad2f999815d546adc5f6214e748fe77f52f7deb,38,15,5,28223,,,0,"Activate validate-services on fs056

This will allow to test this new role and ensure we don't get
false-positive.

Context: https://review.openstack.org/637729

Depends-On: https://review.openstack.org/639950
Change-Id: I617818478530eafc7b7d922b5373da77c02f96f3
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/26/639926/5 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset056.yml'],1,84bda0009e220bb17b0c203dd49a521b0a3d6796,enable-services-validation-fs056, # NOTE(cjeanner) Activate new check only on a non-voting fs validate_services: true,,3,0
openstack%2Fkeystone~master~I7f17a07752432d3e2afd279404362acf04c57a80,openstack/keystone,master,I7f17a07752432d3e2afd279404362acf04c57a80,[api-ref] add domain level limit support,MERGED,2018-12-12 03:46:31.000000000,2019-03-05 20:02:52.000000000,2019-03-05 20:02:52.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-12-12 03:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/176ed09f83a315091654136081533a0ddfa4e1c0', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 2, 'created': '2018-12-17 08:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4ffad2ff3b7c4fe7f3ba4d751ba47824f3d957da', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 3, 'created': '2019-01-09 03:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d4b39341d91fde3defdbe6b259a7d2d4baa74d28', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 4, 'created': '2019-01-09 06:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/25c944304c7a4535c37ecfbffc14c75e10cd0f3e', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 5, 'created': '2019-01-23 07:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d33330d800e34e94160e52f6c0d262ae799d04e', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 6, 'created': '2019-01-24 03:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/00a592ea7fc71d3cf9de7ef5d9b16fd84ad26c6c', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 7, 'created': '2019-02-11 06:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5af15fd765539acfac146e76ea2692ef79e84a76', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 8, 'created': '2019-02-11 07:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/08f77d76694db4a5099f62881614f77e1a81f3ac', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 9, 'created': '2019-02-11 09:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/79c7c4fadab52788d37740d2f4071a50acefaf98', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 10, 'created': '2019-02-12 01:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e5982580cd666ca0a748f023f787a924d5ad00b1', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 11, 'created': '2019-02-12 08:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4f8540f39bb51512a8da4605d0b9cdea3f36212c', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 12, 'created': '2019-02-12 11:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/890e2cb403bab1cca5ccca94c2088ab9261199cc', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}, {'number': 13, 'created': '2019-02-19 03:11:48.000000000', 'files': ['api-ref/source/v3/samples/admin/limit-show-response.json', 'api-ref/source/v3/unified_limits.inc', 'api-ref/source/v3/samples/admin/limits-list-response.json', 'api-ref/source/v3/samples/admin/limits-create-response.json', 'api-ref/source/v3/samples/admin/limits-update-response.json', 'api-ref/source/v3/samples/admin/limits-create-request.json', 'api-ref/source/v3/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3d46e1c97403679cc6a01b67fe2898c719cb1be', 'message': '[api-ref] add domain level limit support\n\nUpdate api-ref to support domain level limit feature.\n\nChange-Id: I7f17a07752432d3e2afd279404362acf04c57a80\nbp: domain-level-limit\n'}]",3,624562,c3d46e1c97403679cc6a01b67fe2898c719cb1be,37,7,13,15054,,,0,"[api-ref] add domain level limit support

Update api-ref to support domain level limit feature.

Change-Id: I7f17a07752432d3e2afd279404362acf04c57a80
bp: domain-level-limit
",git fetch https://review.opendev.org/openstack/keystone refs/changes/62/624562/12 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3/samples/admin/limit-show-response.json', 'api-ref/source/v3/unified_limits.inc', 'api-ref/source/v3/samples/admin/limits-list-response.json', 'api-ref/source/v3/samples/admin/limits-create-response.json', 'api-ref/source/v3/samples/admin/limits-update-response.json', 'api-ref/source/v3/samples/admin/limits-create-request.json', 'api-ref/source/v3/parameters.yaml']",7,176ed09f83a315091654136081533a0ddfa4e1c0,bp/domain-level-limit,domain_id_limit_request_body: description: | The name of the domain. in: body required: false type: stringproject_id_limit_request_body: description: | The ID for the project. in: body required: false type: string,,27,3
openstack%2Fkeystone~master~I60f867ef9ece169afb637336aab460456ff3fedf,openstack/keystone,master,I60f867ef9ece169afb637336aab460456ff3fedf,Release note for domain level limit,MERGED,2018-12-10 08:32:39.000000000,2019-03-05 20:02:50.000000000,2019-03-05 20:02:49.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-12-10 08:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d414b8aa5b7a07f4c73b0fe0418a1af143d9a08a', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 2, 'created': '2018-12-11 02:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a4308c5b9bafab7ef77109e4d89045265d5b0c68', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 3, 'created': '2018-12-17 08:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bd6ac4c319a9d72ab56e9c988472c0522813a2a8', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 4, 'created': '2019-01-09 03:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e541533f78f3d486218b2b59ed83a186b640182c', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 5, 'created': '2019-01-23 07:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9536b78f0d071e91f2a75f4be0cc5f717c572f55', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 6, 'created': '2019-01-24 03:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/58446f6ca6c2884356f05f3bdf2f6b060e834b89', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 7, 'created': '2019-02-11 06:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/710c58ea8e500a2cf96ab34f163114f964ddc1cb', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 8, 'created': '2019-02-11 07:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fc163b02435c333856864ae4fd0dafbe438235e5', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 9, 'created': '2019-02-11 09:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8ac68c49125d17e6a9a2f5fbb11e379d9b0f2830', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 10, 'created': '2019-02-12 01:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/00ed5461607d673634d87114cb55e7e276300f91', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 11, 'created': '2019-02-12 08:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/33477b0f03bb70c8ee4c470a2b3c9736cf01dcd4', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 12, 'created': '2019-02-12 11:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/39de10f05fb9103f554ed5d9dfc60d810db6dc31', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}, {'number': 13, 'created': '2019-02-19 03:11:48.000000000', 'files': ['releasenotes/notes/domain-level-limit-support-60e1e330d06227ed.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/fdd3b9765aac458cb65ca2b4a57482b33b395465', 'message': 'Release note for domain level limit\n\nAdd the release note for domain level limit feature.\n\nThis feature is finished now.\n\nChange-Id: I60f867ef9ece169afb637336aab460456ff3fedf\nbp: domain-level-limit\n'}]",5,624019,fdd3b9765aac458cb65ca2b4a57482b33b395465,38,5,13,15054,,,0,"Release note for domain level limit

Add the release note for domain level limit feature.

This feature is finished now.

Change-Id: I60f867ef9ece169afb637336aab460456ff3fedf
bp: domain-level-limit
",git fetch https://review.opendev.org/openstack/keystone refs/changes/19/624019/3 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/domain-level-limit-support-60e1e330d06227ed.yaml'],1,d414b8aa5b7a07f4c73b0fe0418a1af143d9a08a,bp/domain-level-limit,"--- features: - | [`blueprint domain-level-limit <https://blueprints.launchpad.net/keystone/+spec/domain-level-limit>`_] Keystone now supports domain level unified limit. When creating a limit, users can specify a ``domain_id`` instead of ``project_id` `. For `flat` model, the domain limit is still non-hierarchy. For `strict-two-level` model, the domain limit is considered as the first level, so that the project limit is the second level and the project can not contain any child. ",,10,0
openstack%2Fkeystone~master~I38411001271518b9c2f58d53b2f654c361e952e8,openstack/keystone,master,I38411001271518b9c2f58d53b2f654c361e952e8,Update project depth check,MERGED,2018-12-10 03:56:29.000000000,2019-03-05 20:02:47.000000000,2019-03-05 20:02:47.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-10 03:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e118d5e6a356a355c599c0da577105e589373301', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 2, 'created': '2018-12-17 08:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/356ef9b23f60fad538a8763f2aee58b2bf3e98fe', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 3, 'created': '2019-01-09 03:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7fe201fbb5a60e44aec5b3ba01adae340e0a6ec4', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 4, 'created': '2019-01-23 07:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6d2dc1b4d47a3c8f66b3e4021023154eb67585cf', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 5, 'created': '2019-01-24 03:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bfb6af69c7b92bdf3798dde42877394c38c060f9', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 6, 'created': '2019-02-11 06:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ac9c03f8e90ba097441e1ba00766afb638393c81', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 7, 'created': '2019-02-11 07:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/55e1567207002891a3aa1604da35e58e4d062c2c', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 8, 'created': '2019-02-11 09:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fffb3314943ccf9fcf7217778e1fd211d1af2769', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 9, 'created': '2019-02-12 01:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b1ab9490971591964674466078adec7ed2252811', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 10, 'created': '2019-02-12 08:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c75d2960b818d26539720b38ec9b1ee2d0bf9658', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 11, 'created': '2019-02-12 11:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/415298c82ca52e58a10afb4ecb093a545656de2a', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}, {'number': 12, 'created': '2019-02-19 03:11:48.000000000', 'files': ['keystone/resource/backends/sql.py', 'keystone/tests/unit/test_backend_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8667f42beb861775b2b200988d7a049889416666', 'message': 'Update project depth check\n\nNow `domain` is considered as the first level of project depth.\n\nUpdate the check function to make sure the depth check is correct.\n\nChange-Id: I38411001271518b9c2f58d53b2f654c361e952e8\nbp: domain-level-limit\n'}]",6,623984,8667f42beb861775b2b200988d7a049889416666,34,6,12,15054,,,0,"Update project depth check

Now `domain` is considered as the first level of project depth.

Update the check function to make sure the depth check is correct.

Change-Id: I38411001271518b9c2f58d53b2f654c361e952e8
bp: domain-level-limit
",git fetch https://review.opendev.org/openstack/keystone refs/changes/84/623984/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/resource/backends/sql.py', 'keystone/tests/unit/test_backend_sql.py']",2,e118d5e6a356a355c599c0da577105e589373301,bp/domain-level-limit," # Create a 3 level project tree: # # default_domain # | # project_1 # | # project_2 project_1 = unit.new_project_ref( domain_id=CONF.identity.default_domain_id) PROVIDERS.resource_api.create_project(project_1['id'], project_1) project_2 = unit.new_project_ref( domain_id=CONF.identity.default_domain_id, parent_id=project_1['id']) PROVIDERS.resource_api.create_project(project_2['id'], project_2)"," # create a 3 level project tree ref = unit.new_project_ref(domain_id=CONF.identity.default_domain_id) PROVIDERS.resource_api.create_project(ref['id'], ref) ref_1 = unit.new_project_ref(domain_id=CONF.identity.default_domain_id, parent_id=ref['id']) PROVIDERS.resource_api.create_project(ref_1['id'], ref_1) ref_2 = unit.new_project_ref(domain_id=CONF.identity.default_domain_id, parent_id=ref_1['id']) PROVIDERS.resource_api.create_project(ref_2['id'], ref_2)",49,43
openstack%2Fkeystone~master~Idc9eaac372b66ecd439cdf8001666c0534feaf49,openstack/keystone,master,Idc9eaac372b66ecd439cdf8001666c0534feaf49,Add domain level support for strict-two-level-model,MERGED,2018-12-06 07:53:48.000000000,2019-03-05 20:02:45.000000000,2019-03-05 20:02:45.000000000,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-12-06 07:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d44ca4a88a65eb3001223610698e3b36d6025ca8', 'message': '[WIP] Add domain level support for strict-two-level-model\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 2, 'created': '2018-12-07 06:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7b84b16798e2cd4c3b8e2d95c2428f8a3de80279', 'message': '[WIP] Add domain level support for strict-two-level-model\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 3, 'created': '2018-12-07 08:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/acb5281f1ba7eaa5562e2e8b84634c93c9f2786e', 'message': '[WIP] Add domain level support for strict-two-level-model\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 4, 'created': '2018-12-10 02:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/52266fa66a4d20f90f0cba7df0aea35e1eee148a', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 5, 'created': '2018-12-17 08:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d468774684bbfcd50e2ba421bdc98605e16ecb3d', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 6, 'created': '2019-01-09 03:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8b0291e010f8152da802c0b1a08850697bc13b5b', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 7, 'created': '2019-01-23 07:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7eff18bcaddc5c550d7fad84d7fe98ccdcda46e6', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 8, 'created': '2019-01-24 03:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d30072ad37042d9887854ddf8fb853af50f18537', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 9, 'created': '2019-02-11 06:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/832618eb922607de8873e82fa5d7eed36c32b4cb', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 10, 'created': '2019-02-11 07:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/72d7efeaea4ace3dc9bc74b7e110b2f630f26f54', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 11, 'created': '2019-02-11 09:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c4c439f232df9123ab1b747467026f5ee3eec25e', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 12, 'created': '2019-02-12 01:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d3ac43f8446cf69fceba515ba3d3c30a86e20fb8', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 13, 'created': '2019-02-12 08:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2ac82c17456b69a03881a6b38215140f9f871dfe', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 14, 'created': '2019-02-12 11:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b67d6af6a302430535a4c65f290947bd35df855a', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}, {'number': 15, 'created': '2019-02-19 03:11:48.000000000', 'files': ['keystone/tests/unit/test_limits.py', 'keystone/limit/models/strict_two_level.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7e98d297ae4ba2122056893e571f949015867a27', 'message': 'Add domain level support for strict-two-level-model\n\nRefactor strict-two-level model check function to\nadopt domain level limit.\n\nChange-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49\nbp: domain-level-limit\n'}]",19,623153,7e98d297ae4ba2122056893e571f949015867a27,52,6,15,15054,,,0,"Add domain level support for strict-two-level-model

Refactor strict-two-level model check function to
adopt domain level limit.

Change-Id: Idc9eaac372b66ecd439cdf8001666c0534feaf49
bp: domain-level-limit
",git fetch https://review.opendev.org/openstack/keystone refs/changes/53/623153/15 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_limits.py', 'keystone/limit/models/strict_two_level.py']",2,d44ca4a88a65eb3001223610698e3b36d6025ca8,bp/domain-level-limit," service_id, region_id, parent_id, parent_is_domain): if not parent_is_domain: parent_limit_value = self._get_specified_limit_value( parent_id, resource_name, service_id, region_id) if parent_limit_value and resource_limit > parent_limit_value: raise exception.InvalidLimit( reason=""Limit is bigger than parent."") project_id = limit.get('project_id') domain_id = limit.get('domain_id') parent_list = PROVIDERS.resource_api.list_project_parents( project_id or domain_id) if parent_list: parent_id = parent_list[0]['id'] parent_is_domain = parent_list[0]['is_domain'] parent_is_domain = None parent_limit = list(filter( lambda x: x.get('project_id', x.get('domain_id')) == parent_id, limits)) if parent_limit: if resource_limit > parent_limit[0]['resource_limit']: raise exception.InvalidLimit( reason=""The input hierarchy tree is invalid."") # The limit's parent is in request body, no need to # check the backend any more. continue self._check_limit(project_id or domain_id, resource_name, resource_limit, service_id, region_id, parent_id, parent_is_domain) except exception.InvalidLimit: error = (""The resource limit (%(level)s: %(id)s, "" 'level': 'project_id' if project_id else 'domain_id', 'id': project_id or domain_id, tr_error = _(""The resource limit (%(level)s: %(id)s, "" 'level': 'project_id' if project_id else 'domain_id', 'id': project_id or domain_id,"," service_id, region_id, parent_id): parent_limit_value = self._get_specified_limit_value( parent_id, resource_name, service_id, region_id) if parent_limit_value and resource_limit > parent_limit_value: raise exception.InvalidLimit( reason=""Limit is bigger than parent."") project_id = limit['project_id'] parent_project = PROVIDERS.resource_api.list_project_parents( project_id)[0] if not parent_project['is_domain']: parent_id = parent_project['id'] parent_limit = list(filter( lambda x: x['project_id'] == parent_id, limits)) if parent_limit: if resource_limit > parent_limit[0]['resource_limit']: raise exception.InvalidLimit( reason=""The input hierarchy tree is invalid."") # The limit's parent is in request body, no need to # check the backend any more. continue self._check_limit(project_id, resource_name, resource_limit, service_id, region_id, parent_id) except exception.InvalidLimit: error = (""The resource limit (project_id: %(project_id)s, "" 'project_id': project_id, tr_error = _(""The resource limit (project_id: %(project_id)s, "" 'project_id': project_id,",35,38
openstack%2Fkeystonemiddleware~master~I7304a04870bd5a41ae593d543291a25d73cabe60,openstack/keystonemiddleware,master,I7304a04870bd5a41ae593d543291a25d73cabe60,Drop py35 jobs,MERGED,2019-02-28 05:28:10.000000000,2019-03-05 20:00:46.000000000,2019-03-05 20:00:46.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11224}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-28 05:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/7ca3ce97046234521da3f1481643191c224fcc8d', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I7304a04870bd5a41ae593d543291a25d73cabe60\n'}, {'number': 2, 'created': '2019-03-01 04:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6cfbd156b358dd6eb39bb40e26c39d23b4cfe588', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I7304a04870bd5a41ae593d543291a25d73cabe60\n'}, {'number': 3, 'created': '2019-03-01 10:37:29.000000000', 'files': ['.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c706ceb014fe05da3126c7de23e709b3680a8c34', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older version. Also\ncorrect setup.cfg and tox.ini to reflect the current supported Python\nversions.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: I7304a04870bd5a41ae593d543291a25d73cabe60\n'}]",0,639913,c706ceb014fe05da3126c7de23e709b3680a8c34,13,4,3,27621,,,0,"Drop py35 jobs

Python 3.5 was the target runtime for the Rocky release.
The current target py3 runtime for Stein is Python 3.6,
so there is no reason to keep testing against the older version. Also
correct setup.cfg and tox.ini to reflect the current supported Python
versions.

https://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein

Change-Id: I7304a04870bd5a41ae593d543291a25d73cabe60
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/13/639913/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,7ca3ce97046234521da3f1481643191c224fcc8d,drop-py35,"envlist = py36,py27,pep8,releasenotes","envlist = py36,py35,py27,pep8,releasenotes",1,3
openstack%2Ftripleo-heat-templates~master~Iba2e3643708f4942cbd012c8c8d16d9c25778cdf,openstack/tripleo-heat-templates,master,Iba2e3643708f4942cbd012c8c8d16d9c25778cdf,Use dedicated container tag per skydive service,MERGED,2019-02-22 08:48:49.000000000,2019-03-05 19:54:59.000000000,2019-03-05 19:54:58.000000000,"[{'_account_id': 3153}, {'_account_id': 7141}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26882}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-22 08:48:49.000000000', 'files': ['extraconfig/services/skydive-analyzer.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f48ba5896128b0d0575661271da3d64bb083531e', 'message': 'Use dedicated container tag per skydive service\n\nChange-Id: Iba2e3643708f4942cbd012c8c8d16d9c25778cdf\n'}]",0,638606,f48ba5896128b0d0575661271da3d64bb083531e,14,7,1,7141,,,0,"Use dedicated container tag per skydive service

Change-Id: Iba2e3643708f4942cbd012c8c8d16d9c25778cdf
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/638606/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/services/skydive-analyzer.yaml'],1,f48ba5896128b0d0575661271da3d64bb083531e,dedicated-skydive-container-tag," skydive_analyzer_docker_image_tag: {{skydive_analyzer_docker_image | regex_replace("".*:"")}} skydive_agent_docker_image_tag: {{skydive_agent_docker_image | regex_replace("".*:"")}}"," skydive_docker_image_tag: {{skydive_analyzer_docker_image | regex_replace("".*:"")}}",2,1
openstack%2Ftripleo-heat-templates~master~I20d35affba9da511ed4a9566013868146d3fbf4c,openstack/tripleo-heat-templates,master,I20d35affba9da511ed4a9566013868146d3fbf4c,Add SSHD composable service to Networker role definition,MERGED,2019-02-23 16:57:20.000000000,2019-03-05 19:54:57.000000000,2019-03-05 19:54:57.000000000,"[{'_account_id': 3153}, {'_account_id': 10068}, {'_account_id': 10873}, {'_account_id': 12898}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-02-23 16:57:20.000000000', 'files': ['roles/Networker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/37ea3303700eba9e8d73f45c2e0999c5d39e1132', 'message': 'Add SSHD composable service to Networker role definition\n\nThe composable service OS::TripleO::Services::Sshd is\nenabled by default in the overcloud but it is not included\nin the default Networker.yaml role definition.\n\nChange-Id: I20d35affba9da511ed4a9566013868146d3fbf4c\n'}]",0,638852,37ea3303700eba9e8d73f45c2e0999c5d39e1132,14,10,1,27092,,,0,"Add SSHD composable service to Networker role definition

The composable service OS::TripleO::Services::Sshd is
enabled by default in the overcloud but it is not included
in the default Networker.yaml role definition.

Change-Id: I20d35affba9da511ed4a9566013868146d3fbf4c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/52/638852/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/Networker.yaml'],1,37ea3303700eba9e8d73f45c2e0999c5d39e1132,networker+sshd, - OS::TripleO::Services::Sshd,,1,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~Id08be90d6be89af66d94bc779f311702526eb788,openstack/tripleo-heat-templates,stable/rocky,Id08be90d6be89af66d94bc779f311702526eb788,Rework nova_cell_v2_discover_host.py to use nova.conf and python novaclient,MERGED,2019-02-28 06:18:59.000000000,2019-03-05 19:52:34.000000000,2019-03-05 19:52:33.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-28 06:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b00b5ce526edb1032d29adeacf06bb136de41087', 'message': 'Rework nova_cell_v2_discover_host.py to use nova.conf and python novaclient\n\nPreviously nova_cell_v2_discover_host.py used environment variables passed\nto the script and it got deleted right after usage. This changed to:\n- read auth information from nova.conf\n- read host information from nova.conf\n- use python novaclient to check new services instead of subprocess\ncalls\n\nChange-Id: Id08be90d6be89af66d94bc779f311702526eb788\n(cherry picked from commit df7f43974e4e5bdf6ceee773b0e22be0eb74b36c)\n'}, {'number': 2, 'created': '2019-03-01 10:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/917a34e08024664da7387843a22249adaa3baf4e', 'message': 'Rework nova_cell_v2_discover_host.py to use nova.conf and python novaclient\n\nPreviously nova_cell_v2_discover_host.py used environment variables passed\nto the script and it got deleted right after usage. This changed to:\n- read auth information from nova.conf\n- read host information from nova.conf\n- use python novaclient to check new services instead of subprocess\ncalls\n\nChange-Id: Id08be90d6be89af66d94bc779f311702526eb788\n(cherry picked from commit df7f43974e4e5bdf6ceee773b0e22be0eb74b36c)\n'}, {'number': 3, 'created': '2019-03-01 15:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8a4ddd3a8312cd276dc1f7524c8b5033d707e91d', 'message': 'Rework nova_cell_v2_discover_host.py to use nova.conf and python novaclient\n\nPreviously nova_cell_v2_discover_host.py used environment variables passed\nto the script and it got deleted right after usage. This changed to:\n- read auth information from nova.conf\n- read host information from nova.conf\n- use python novaclient to check new services instead of subprocess\ncalls\n\nChange-Id: Id08be90d6be89af66d94bc779f311702526eb788\n(cherry picked from commit df7f43974e4e5bdf6ceee773b0e22be0eb74b36c)\n'}, {'number': 4, 'created': '2019-03-05 05:33:46.000000000', 'files': ['docker_config_scripts/nova_cell_v2_discover_host.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e02cb626a25f73cb9f497ed2cbd5573cdf0ffaa8', 'message': 'Rework nova_cell_v2_discover_host.py to use nova.conf and python novaclient\n\nPreviously nova_cell_v2_discover_host.py used environment variables passed\nto the script and it got deleted right after usage. This changed to:\n- read auth information from nova.conf\n- read host information from nova.conf\n- use python novaclient to check new services instead of subprocess\ncalls\n\nChange-Id: Id08be90d6be89af66d94bc779f311702526eb788\n(cherry picked from commit df7f43974e4e5bdf6ceee773b0e22be0eb74b36c)\n'}]",0,639929,e02cb626a25f73cb9f497ed2cbd5573cdf0ffaa8,23,10,4,20733,,,0,"Rework nova_cell_v2_discover_host.py to use nova.conf and python novaclient

Previously nova_cell_v2_discover_host.py used environment variables passed
to the script and it got deleted right after usage. This changed to:
- read auth information from nova.conf
- read host information from nova.conf
- use python novaclient to check new services instead of subprocess
calls

Change-Id: Id08be90d6be89af66d94bc779f311702526eb788
(cherry picked from commit df7f43974e4e5bdf6ceee773b0e22be0eb74b36c)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/29/639929/1 && git format-patch -1 --stdout FETCH_HEAD,['docker_config_scripts/nova_cell_v2_discover_host.py'],1,b00b5ce526edb1032d29adeacf06bb136de41087,," import logging from optparse import OptionParser from keystoneauth1 import loading from keystoneauth1 import session from novaclient import client from six.moves.configparser import SafeConfigParser logging.basicConfig(stream=sys.stdout, level=logging.DEBUG) LOG = logging.getLogger('nova_cell_v2_discover_host') nova_cfg = '/etc/nova/nova.conf' if __name__ == '__main__': parser = OptionParser(usage=""usage: %prog [options]"") parser.add_option('-k', '--insecure', action=""store_false"", dest='insecure', default=True, help='Allow insecure connection when using SSL') (options, args) = parser.parse_args() LOG.debug('Running with parameter insecure = %s', options.insecure) if os.path.isfile(nova_cfg): config = SafeConfigParser() config.read(nova_cfg) else: LOG.error('Nova configuration file %s does not exist', nova_cfg) sys.exit(1) my_host = config.get('DEFAULT', 'host') if not my_host: # If host isn't set nova defaults to this my_host = socket.gethostname() loader = loading.get_plugin_loader('password') auth = loader.load_from_options( auth_url=config.get('neutron', 'auth_url'), username=config.get('neutron', 'username'), password=config.get('neutron', 'password'), project_name=config.get('neutron', 'project_name'), project_domain_name=config.get('neutron', 'project_domain_name'), user_domain_name=config.get('neutron', 'user_domain_name')) sess = session.Session(auth=auth, verify=options.insecure) nova = client.Client('2.11', session=sess, endpoint_type='internal') # Wait until this host is listed in the service list then # run cellv2 host discovery retries = 10 for i in range(retries): try: service_list = nova.services.list(binary='nova-compute') for entry in service_list: host = getattr(entry, 'host', '') zone = getattr(entry, 'zone', '') if host == my_host and zone != 'internal': LOG.info('(cellv2) Service registered, running discovery') sys.exit(subprocess.call([ '/usr/bin/nova-manage', 'cell_v2', 'discover_hosts', '--by-service', '--verbose' ])) if len(service_list) == 0: LOG.warning('(cellv2) no nova-compute service registered' + ' after %i checks', i) LOG.info('(cellv2) Waiting for service to register') except subprocess.CalledProcessError: LOG.info('(cellv2) Retrying') except Exception as e: LOG.exception('Error during host discovery:') time.sleep(30) # vim: set et ts=4 sw=4 :","import pwd# Delete this immediataly as it contains auth info os.unlink(__file__) # Only need root to read this script, drop to nova user nova_uid, nova_gid = pwd.getpwnam('nova')[2:4] os.setgid(nova_gid) os.setuid(nova_uid) os.environ.update( OS_PROJECT_DOMAIN_NAME='__OS_PROJECT_DOMAIN_NAME', OS_USER_DOMAIN_NAME='__OS_PROJECT_USER_NAME', OS_PROJECT_NAME='__OS_PROJECT_NAME', OS_USERNAME='__OS_USERNAME', OS_PASSWORD='__OS_PASSWORD', OS_AUTH_URL='__OS_AUTH_URL', OS_AUTH_TYPE='password', OS_IDENTITY_API_VERSION='3' ) try: my_host = subprocess.check_output([ 'crudini', '--get', '/etc/nova/nova.conf', 'DEFAULT', 'host' ], universal_newlines=True).rstrip() except subprocess.CalledProcessError: # If host isn't set nova defaults to this my_host = socket.gethostname() # Wait until this host is listed in the service list then # run cellv2 host discovery retries = 10 for i in range(retries): try: service_output = subprocess.check_output([ 'openstack', '-q', '--os-interface', 'internal', 'compute', 'service', 'list', '-c', 'Host', '-c', 'Zone', '-f', 'value' ], universal_newlines=True) service_list = service_output.split('\n') for entry in service_list: # skip any empty lines if not entry: continue host, zone = entry.split() if host == my_host and zone != 'internal': print('(cellv2) Service registered, running discovery') sys.exit(subprocess.call([ '/usr/bin/nova-manage', 'cell_v2', 'discover_hosts', '--by-service', '--verbose' ])) print('(cellv2) Waiting for service to register') except subprocess.CalledProcessError: print('(cellv2) Retrying') time.sleep(30)",81,67
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487,openstack/tripleo-heat-templates,stable/rocky,Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487,Fix nova_cell_v2_discover_host.py with python3,MERGED,2019-02-28 06:17:30.000000000,2019-03-05 19:52:32.000000000,2019-03-05 19:52:32.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-28 06:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c3fb54eb80016760d527816f30e3915f3c53bfa8', 'message': 'Fix nova_cell_v2_discover_host.py with python3\n\nWhen this script runs via python3 it fails with:\n\n  ""stdout: "",\n  ""stderr: + command -v python3"",\n  ""+ python3 /docker-config-scripts/nova_cell_v2_discover_host.py"",\n  ""Traceback (most recent call last):"",\n  "" File \\""/docker-config-scripts/nova_cell_v2_discover_host.py\\"", line 75, in <module>"",\n  "" TypeError: a bytes-like object is required, not \'str\'""\n\nThis is because in python3 subprocess.check_output() will return bytes\nand trying to split it using a string \'\\n\' will break with the error\nabove. Let\'s just use the universal_newlines=True parameter which we\nhave been using everywhere in tripleo so far.\nAlso skip any empty lines that might show up in the output which would\ngive the error:\n\n  ValueError: not enough values to unpack (expected 2, got 0)\n\nTested with a python3 deployment and got a successful deployment (rhel8\nos + f28 based-containers).\n\nChange-Id: Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\nCloses-Bug: #1813014\n(cherry picked from commit 87a869a408b9732e9ff46e8fecfa1487b3699ffa)\n'}, {'number': 2, 'created': '2019-03-01 10:19:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1a57ea0075238c78dc7d512e91622419f24fa48a', 'message': 'Fix nova_cell_v2_discover_host.py with python3\n\nWhen this script runs via python3 it fails with:\n\n  ""stdout: "",\n  ""stderr: + command -v python3"",\n  ""+ python3 /docker-config-scripts/nova_cell_v2_discover_host.py"",\n  ""Traceback (most recent call last):"",\n  "" File \\""/docker-config-scripts/nova_cell_v2_discover_host.py\\"", line 75, in <module>"",\n  "" TypeError: a bytes-like object is required, not \'str\'""\n\nThis is because in python3 subprocess.check_output() will return bytes\nand trying to split it using a string \'\\n\' will break with the error\nabove. Let\'s just use the universal_newlines=True parameter which we\nhave been using everywhere in tripleo so far.\nAlso skip any empty lines that might show up in the output which would\ngive the error:\n\n  ValueError: not enough values to unpack (expected 2, got 0)\n\nTested with a python3 deployment and got a successful deployment (rhel8\nos + f28 based-containers).\n\nChange-Id: Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\nCloses-Bug: #1813014\n(cherry picked from commit 87a869a408b9732e9ff46e8fecfa1487b3699ffa)\n'}, {'number': 3, 'created': '2019-03-01 15:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5084df849e331e50eed7cf824023a42406ed7bb0', 'message': 'Fix nova_cell_v2_discover_host.py with python3\n\nWhen this script runs via python3 it fails with:\n\n  ""stdout: "",\n  ""stderr: + command -v python3"",\n  ""+ python3 /docker-config-scripts/nova_cell_v2_discover_host.py"",\n  ""Traceback (most recent call last):"",\n  "" File \\""/docker-config-scripts/nova_cell_v2_discover_host.py\\"", line 75, in <module>"",\n  "" TypeError: a bytes-like object is required, not \'str\'""\n\nThis is because in python3 subprocess.check_output() will return bytes\nand trying to split it using a string \'\\n\' will break with the error\nabove. Let\'s just use the universal_newlines=True parameter which we\nhave been using everywhere in tripleo so far.\nAlso skip any empty lines that might show up in the output which would\ngive the error:\n\n  ValueError: not enough values to unpack (expected 2, got 0)\n\nTested with a python3 deployment and got a successful deployment (rhel8\nos + f28 based-containers).\n\nChange-Id: Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\nCloses-Bug: #1813014\n(cherry picked from commit 87a869a408b9732e9ff46e8fecfa1487b3699ffa)\n'}, {'number': 4, 'created': '2019-03-05 05:33:33.000000000', 'files': ['docker_config_scripts/nova_cell_v2_discover_host.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e5d6b52c15349f88788f8fea42071ec9fd5dba5c', 'message': 'Fix nova_cell_v2_discover_host.py with python3\n\nWhen this script runs via python3 it fails with:\n\n  ""stdout: "",\n  ""stderr: + command -v python3"",\n  ""+ python3 /docker-config-scripts/nova_cell_v2_discover_host.py"",\n  ""Traceback (most recent call last):"",\n  "" File \\""/docker-config-scripts/nova_cell_v2_discover_host.py\\"", line 75, in <module>"",\n  "" TypeError: a bytes-like object is required, not \'str\'""\n\nThis is because in python3 subprocess.check_output() will return bytes\nand trying to split it using a string \'\\n\' will break with the error\nabove. Let\'s just use the universal_newlines=True parameter which we\nhave been using everywhere in tripleo so far.\nAlso skip any empty lines that might show up in the output which would\ngive the error:\n\n  ValueError: not enough values to unpack (expected 2, got 0)\n\nTested with a python3 deployment and got a successful deployment (rhel8\nos + f28 based-containers).\n\nChange-Id: Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\nCloses-Bug: #1813014\n(cherry picked from commit 87a869a408b9732e9ff46e8fecfa1487b3699ffa)\n'}]",1,639928,e5d6b52c15349f88788f8fea42071ec9fd5dba5c,25,12,4,20733,,,0,"Fix nova_cell_v2_discover_host.py with python3

When this script runs via python3 it fails with:

  ""stdout: "",
  ""stderr: + command -v python3"",
  ""+ python3 /docker-config-scripts/nova_cell_v2_discover_host.py"",
  ""Traceback (most recent call last):"",
  "" File \""/docker-config-scripts/nova_cell_v2_discover_host.py\"", line 75, in <module>"",
  "" TypeError: a bytes-like object is required, not 'str'""

This is because in python3 subprocess.check_output() will return bytes
and trying to split it using a string '\n' will break with the error
above. Let's just use the universal_newlines=True parameter which we
have been using everywhere in tripleo so far.
Also skip any empty lines that might show up in the output which would
give the error:

  ValueError: not enough values to unpack (expected 2, got 0)

Tested with a python3 deployment and got a successful deployment (rhel8
os + f28 based-containers).

Change-Id: Ic7904c4f3027cc5e7e05d52757e36dbc05f3d487
Co-Authored-By: Damien Ciabrini <dciabrin@redhat.com>
Closes-Bug: #1813014
(cherry picked from commit 87a869a408b9732e9ff46e8fecfa1487b3699ffa)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/28/639928/3 && git format-patch -1 --stdout FETCH_HEAD,['docker_config_scripts/nova_cell_v2_discover_host.py'],1,c3fb54eb80016760d527816f30e3915f3c53bfa8,bug/1813014," ], universal_newlines=True).rstrip() service_output = subprocess.check_output([ ], universal_newlines=True) service_list = service_output.split('\n') for entry in service_list: # skip any empty lines if not entry: continue", ]).rstrip() service_list = subprocess.check_output([ ]).split('\n') for entry in service_list:,7,3
openstack%2Ftripleo-heat-templates~stable%2Frocky~I234db0866fb6f1adefdcf7a2b2a82412e443b7c9,openstack/tripleo-heat-templates,stable/rocky,I234db0866fb6f1adefdcf7a2b2a82412e443b7c9,Service check in nova_cell_v2_discover_host.py to use internal API,MERGED,2019-02-28 05:56:08.000000000,2019-03-05 19:52:30.000000000,2019-03-05 19:52:30.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-28 05:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/51522149a3eefdb3fe831c6c25ae6819b82d1586', 'message': ""Service check in nova_cell_v2_discover_host.py to use internal API\n\ne0e885b8ca3332e0815c537a32c564cac81f7f7e moved the cellv2 discovery from\ncontrol plane to compute services. In case the computes won't have access\nto the external API the service check will fail. This switch the service\ncheck to use the internal endpoint.\n\nChange-Id: I234db0866fb6f1adefdcf7a2b2a82412e443b7c9\nCloses-bug: 1812632\n(cherry picked from commit cde4134d555ba74a1b86f66510069fc2a521286c)\n""}, {'number': 2, 'created': '2019-03-01 10:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a1c741fa0e3c079f00605bf6e18ff2d21242768', 'message': ""Service check in nova_cell_v2_discover_host.py to use internal API\n\ne0e885b8ca3332e0815c537a32c564cac81f7f7e moved the cellv2 discovery from\ncontrol plane to compute services. In case the computes won't have access\nto the external API the service check will fail. This switch the service\ncheck to use the internal endpoint.\n\nChange-Id: I234db0866fb6f1adefdcf7a2b2a82412e443b7c9\nCloses-bug: 1812632\n(cherry picked from commit cde4134d555ba74a1b86f66510069fc2a521286c)\n""}, {'number': 3, 'created': '2019-03-01 15:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/547c410ed5dcebf4e053f9e6c4861d0b0d7dc868', 'message': ""Service check in nova_cell_v2_discover_host.py to use internal API\n\ne0e885b8ca3332e0815c537a32c564cac81f7f7e moved the cellv2 discovery from\ncontrol plane to compute services. In case the computes won't have access\nto the external API the service check will fail. This switch the service\ncheck to use the internal endpoint.\n\nChange-Id: I234db0866fb6f1adefdcf7a2b2a82412e443b7c9\nCloses-bug: 1812632\n(cherry picked from commit cde4134d555ba74a1b86f66510069fc2a521286c)\n""}, {'number': 4, 'created': '2019-03-05 05:33:01.000000000', 'files': ['releasenotes/notes/nova_cell_v2_discover_host_use_internal_api-1bebb3e9c6e69113.yaml', 'docker_config_scripts/nova_cell_v2_discover_host.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eef9d3e49e09b6d68036a2a4f665a8fc80e65e05', 'message': ""Service check in nova_cell_v2_discover_host.py to use internal API\n\ne0e885b8ca3332e0815c537a32c564cac81f7f7e moved the cellv2 discovery from\ncontrol plane to compute services. In case the computes won't have access\nto the external API the service check will fail. This switch the service\ncheck to use the internal endpoint.\n\nChange-Id: I234db0866fb6f1adefdcf7a2b2a82412e443b7c9\nCloses-bug: 1812632\n(cherry picked from commit cde4134d555ba74a1b86f66510069fc2a521286c)\n""}]",0,639922,eef9d3e49e09b6d68036a2a4f665a8fc80e65e05,22,11,4,20733,,,0,"Service check in nova_cell_v2_discover_host.py to use internal API

e0e885b8ca3332e0815c537a32c564cac81f7f7e moved the cellv2 discovery from
control plane to compute services. In case the computes won't have access
to the external API the service check will fail. This switch the service
check to use the internal endpoint.

Change-Id: I234db0866fb6f1adefdcf7a2b2a82412e443b7c9
Closes-bug: 1812632
(cherry picked from commit cde4134d555ba74a1b86f66510069fc2a521286c)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/22/639922/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/nova_cell_v2_discover_host_use_internal_api-1bebb3e9c6e69113.yaml', 'docker_config_scripts/nova_cell_v2_discover_host.py']",2,51522149a3eefdb3fe831c6c25ae6819b82d1586,bug/1812632," '--os-interface', 'internal',",,9,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~I12a02f636f31985bc1b71bff5b744d346286a95f,openstack/tripleo-heat-templates,stable/rocky,I12a02f636f31985bc1b71bff5b744d346286a95f,Move cellv2 discovery from control plane services to compute services,MERGED,2019-02-28 05:52:24.000000000,2019-03-05 19:52:28.000000000,2019-03-05 19:52:28.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-28 05:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f46c7fa6cb95ff3b69b3f26d6842de93fb9d9898', 'message': ""Move cellv2 discovery from control plane services to compute services\n\nIf compute nodes are deployed without deploying/updating the controllers then\nthe computes will not have cellv2 mappings as this is run in the controller\ndeploy steps (nova-api).\nThis can happen if the controller nodes are blacklisted during a compute scale\nout. It's also likely to be an issue going forward if the deployment is staged\n(e.g split control plane).\n\nThis change moves the cell_v2 discovery logic to the nova-compute/nova-ironic\ndeploy step.\n\nConflicts:\n       common/services.yaml\n       docker/services/nova-api.yaml\n\nCloses-bug: 1786961\nChange-Id: I12a02f636f31985bc1b71bff5b744d346286a95f\n""}, {'number': 2, 'created': '2019-03-01 10:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aa8f0ab906e63e7fa3392d42bcd67df3eb286e80', 'message': ""Move cellv2 discovery from control plane services to compute services\n\nIf compute nodes are deployed without deploying/updating the controllers then\nthe computes will not have cellv2 mappings as this is run in the controller\ndeploy steps (nova-api).\nThis can happen if the controller nodes are blacklisted during a compute scale\nout. It's also likely to be an issue going forward if the deployment is staged\n(e.g split control plane).\n\nThis change moves the cell_v2 discovery logic to the nova-compute/nova-ironic\ndeploy step.\n\nConflicts:\n       common/services.yaml\n       docker/services/nova-api.yaml\n\nCloses-bug: 1786961\nChange-Id: I12a02f636f31985bc1b71bff5b744d346286a95f\n""}, {'number': 3, 'created': '2019-03-01 14:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c79998ecf2030ebdd1d2a29a34bfe2a0f12a97ec', 'message': ""Move cellv2 discovery from control plane services to compute services\n\nIf compute nodes are deployed without deploying/updating the controllers then\nthe computes will not have cellv2 mappings as this is run in the controller\ndeploy steps (nova-api).\nThis can happen if the controller nodes are blacklisted during a compute scale\nout. It's also likely to be an issue going forward if the deployment is staged\n(e.g split control plane).\n\nThis change moves the cell_v2 discovery logic to the nova-compute/nova-ironic\ndeploy step.\n\nConflicts:\n       common/services.yaml\n       docker/services/nova-api.yaml\n\nCloses-bug: 1786961\nChange-Id: I12a02f636f31985bc1b71bff5b744d346286a95f\n""}, {'number': 4, 'created': '2019-03-05 05:31:14.000000000', 'files': ['common/services.yaml', 'docker_config_scripts/nova_statedir_ownership.py', 'docker/services/nova-ironic.yaml', 'puppet/all-nodes-config.j2.yaml', 'docker/services/nova-compute-common.yaml', 'overcloud.j2.yaml', 'docker_config_scripts/nova_cell_v2_discover_host.py', 'docker/services/nova-api.yaml', 'docker/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d7704bbf56cc155884e233a816422aa6e721cda3', 'message': ""Move cellv2 discovery from control plane services to compute services\n\nIf compute nodes are deployed without deploying/updating the controllers then\nthe computes will not have cellv2 mappings as this is run in the controller\ndeploy steps (nova-api).\nThis can happen if the controller nodes are blacklisted during a compute scale\nout. It's also likely to be an issue going forward if the deployment is staged\n(e.g split control plane).\n\nThis change moves the cell_v2 discovery logic to the nova-compute/nova-ironic\ndeploy step.\n\nConflicts:\n       common/services.yaml\n       docker/services/nova-api.yaml\n\nCloses-bug: 1786961\nChange-Id: I12a02f636f31985bc1b71bff5b744d346286a95f\n(cherry picked from commit e0e885b8ca3332e0815c537a32c564cac81f7f7e)\n""}]",5,639920,d7704bbf56cc155884e233a816422aa6e721cda3,24,11,4,20733,,,0,"Move cellv2 discovery from control plane services to compute services

If compute nodes are deployed without deploying/updating the controllers then
the computes will not have cellv2 mappings as this is run in the controller
deploy steps (nova-api).
This can happen if the controller nodes are blacklisted during a compute scale
out. It's also likely to be an issue going forward if the deployment is staged
(e.g split control plane).

This change moves the cell_v2 discovery logic to the nova-compute/nova-ironic
deploy step.

Conflicts:
       common/services.yaml
       docker/services/nova-api.yaml

Closes-bug: 1786961
Change-Id: I12a02f636f31985bc1b71bff5b744d346286a95f
(cherry picked from commit e0e885b8ca3332e0815c537a32c564cac81f7f7e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/20/639920/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/services.yaml', 'docker_config_scripts/nova_statedir_ownership.py', 'docker/services/nova-ironic.yaml', 'puppet/all-nodes-config.j2.yaml', 'docker/services/nova-compute-common.yaml', 'overcloud.j2.yaml', 'docker_config_scripts/nova_cell_v2_discover_host.py', 'docker/services/nova-api.yaml', 'docker/services/nova-compute.yaml']",9,f46c7fa6cb95ff3b69b3f26d6842de93fb9d9898,bug/1786961," step_5: nova_cellv2_discover_hosts: start_order: 0 image: *nova_compute_image net: host detach: false volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - - /var/lib/config-data/nova_libvirt/etc/nova/:/etc/nova/:ro - /var/log/containers/nova:/var/log/nova - /var/lib/docker-config-scripts/:/docker-config-scripts/ user: root command: ""/docker-config-scripts/nova_cell_v2_discover_host.py""", cellv2_discovery: true,134,111
openstack%2Ftripleo-quickstart-extras~master~I8e1b39f5e5a9924e3ff4d99119fd58e81e69bf7c,openstack/tripleo-quickstart-extras,master,I8e1b39f5e5a9924e3ff4d99119fd58e81e69bf7c,Use ansible_user_dir instead of hard coded /home/zuul path,MERGED,2019-03-04 12:37:26.000000000,2019-03-05 19:48:05.000000000,2019-03-05 19:48:05.000000000,"[{'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-03-04 12:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f51587a65a3f0ac0faa54261ab8d3cca6928d86e', 'message': ""Use Ansible user home dir instead of hard coded /home/zuul path\n\nIn order to consume os_tempest locally, current playbook has\nhardcoded zuul user which is not present on local system. In order\nto fix that, let's use ansible default user's home to do the same.\n\nChange-Id: I8e1b39f5e5a9924e3ff4d99119fd58e81e69bf7c\n""}, {'number': 2, 'created': '2019-03-05 07:34:22.000000000', 'files': ['playbooks/tempest.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/210c0702bfde487eed0c2d7361c53cfe574e1732', 'message': ""Use ansible_user_dir instead of hard coded /home/zuul path\n\nIn order to consume os_tempest locally, current playbook has\nhardcoded zuul user which is not present on local system. In order\nto fix that, let's use ansible_user_dir to do the same.\n\nChange-Id: I8e1b39f5e5a9924e3ff4d99119fd58e81e69bf7c\n""}]",2,640749,210c0702bfde487eed0c2d7361c53cfe574e1732,16,11,2,12393,,,0,"Use ansible_user_dir instead of hard coded /home/zuul path

In order to consume os_tempest locally, current playbook has
hardcoded zuul user which is not present on local system. In order
to fix that, let's use ansible_user_dir to do the same.

Change-Id: I8e1b39f5e5a9924e3ff4d99119fd58e81e69bf7c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/49/640749/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tempest.yml'],1,f51587a65a3f0ac0faa54261ab8d3cca6928d86e,os_tempest," tempest_workspace: ""{{ lookup('env', 'HOME')/tempest }}"" stackviz_venv_bin: ""{{ lookup('env', 'HOME')/stackviz_venv/bin }}"" tempest_venv_bin: ""{{ lookup('env', 'HOME')/tempest_venv/bin }}"""," tempest_workspace: '/home/zuul/tempest' stackviz_venv_bin: ""/home/zuul/stackviz_venv/bin"" tempest_venv_bin: '/home/zuul/tempest_venv/bin'",3,3
openstack%2Fmanila~master~I64ffff15cc546c67e7e545b1da7ec0efa002bdc5,openstack/manila,master,I64ffff15cc546c67e7e545b1da7ec0efa002bdc5,[pylint] Fix/ignore pylint errors in test modules,MERGED,2019-02-20 03:10:55.000000000,2019-03-05 19:42:59.000000000,2019-03-05 19:42:59.000000000,"[{'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16643}, {'_account_id': 18742}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 26968}]","[{'number': 1, 'created': '2019-02-20 03:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e9079fbed5cea1939d5bb2a283f893710dfdb158', 'message': '[pylint] Fix/ignore pylint errors in test modules\n\n- Add ignores to pylint false positives in the\n  test modules.\n- Remove unnecessary fake data\n- Fix wrong mock methods used in tests\n\nChange-Id: I64ffff15cc546c67e7e545b1da7ec0efa002bdc5\n'}, {'number': 2, 'created': '2019-02-20 03:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1601a96fd83cd155615cf77ef2c050aa77c944a1', 'message': '[pylint] Fix/ignore pylint errors in test modules\n\n- Add ignores to pylint false positives in the\n  test modules.\n- Remove unnecessary fake data\n- Fix wrong mock methods used in tests\n\nChange-Id: I64ffff15cc546c67e7e545b1da7ec0efa002bdc5\n'}, {'number': 3, 'created': '2019-02-20 03:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2de0d44ad87f3c360198d376d3b740f610f3e81a', 'message': '[pylint] Fix/ignore pylint errors in test modules\n\n- Add ignores to pylint false positives in the\n  test modules.\n- Remove unnecessary fake data\n- Fix wrong mock methods used in tests\n\nChange-Id: I64ffff15cc546c67e7e545b1da7ec0efa002bdc5\n'}, {'number': 4, 'created': '2019-02-28 16:36:22.000000000', 'files': ['manila/tests/network/neutron/test_neutron_plugin.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/tests/share/drivers/zfsonlinux/test_driver.py', 'manila/tests/common/test_client_auth.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_utils.py', 'manila/tests/api/test_versions.py', 'manila/tests/scheduler/weighers/test_capacity.py', 'manila/tests/scheduler/test_manager.py', 'manila/tests/share/drivers/maprfs/test_maprfs.py', 'manila/tests/network/linux/test_interface.py', 'manila/tests/fake_share.py', 'manila/tests/share/drivers/netapp/test_utils.py', 'manila/tests/fake_compute.py', 'manila/tests/api/fakes.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/share/test_driver.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/tests/api/v1/test_limits.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/tests/share/drivers/zfsonlinux/test_utils.py', 'manila/tests/scheduler/test_scheduler_options.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/3bd1e5054ae25443d11c3f5e04c9a48f54ede843', 'message': '[pylint] Fix/ignore pylint errors in test modules\n\n- Add ignores to pylint false positives in the\n  test modules.\n- Remove unnecessary fake data\n- Fix wrong mock methods used in tests\n\nChange-Id: I64ffff15cc546c67e7e545b1da7ec0efa002bdc5\n'}]",23,638067,3bd1e5054ae25443d11c3f5e04c9a48f54ede843,39,20,4,16643,,,0,"[pylint] Fix/ignore pylint errors in test modules

- Add ignores to pylint false positives in the
  test modules.
- Remove unnecessary fake data
- Fix wrong mock methods used in tests

Change-Id: I64ffff15cc546c67e7e545b1da7ec0efa002bdc5
",git fetch https://review.opendev.org/openstack/manila refs/changes/67/638067/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/network/neutron/test_neutron_plugin.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/tests/share/drivers/zfsonlinux/test_driver.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_utils.py', 'manila/tests/api/test_versions.py', 'manila/tests/scheduler/weighers/test_capacity.py', 'manila/tests/scheduler/test_manager.py', 'manila/tests/share/drivers/maprfs/test_maprfs.py', 'manila/tests/network/linux/test_interface.py', 'manila/tests/fake_share.py', 'manila/tests/share/drivers/netapp/test_utils.py', 'manila/tests/fake_compute.py', 'manila/tests/api/fakes.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/share/test_driver.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/tests/api/v1/test_limits.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/tests/share/drivers/zfsonlinux/test_utils.py', 'manila/tests/scheduler/test_scheduler_options.py']",20,e9079fbed5cea1939d5bb2a283f893710dfdb158,pylint, # pylint: disable=import-error,,46,61
openstack%2Fmanila-tempest-plugin~master~I17c74b2aa242918188eeff368232c762a4b31093,openstack/manila-tempest-plugin,master,I17c74b2aa242918188eeff368232c762a4b31093,Temporarily disable test_manage_invalid,MERGED,2019-02-08 16:41:41.000000000,2019-03-05 19:42:58.000000000,2019-03-05 19:42:58.000000000,"[{'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 18058}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-02-08 16:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/a5fd942e7bb9fc195fac7b1c414846aa18b79ea6', 'message': 'Temporarily disable test_manage_invalid\n\nThis test stops making sense as-is when running against\nhttps://review.openstack.org/635831. It will be re-enabled by\nthe functional tests of Manage-Unmanage with Share Servers\nfeature.\n\nChange-Id: I17c74b2aa242918188eeff368232c762a4b31093\nImplements: bp manage-unmanage-with-share-servers\nNeeded-By: https://review.openstack.org/635831\n'}, {'number': 2, 'created': '2019-02-11 11:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/58126500ad46769d5e6438b233632566fd305994', 'message': 'Temporarily disable test_manage_invalid\n\nThis test stops making sense as-is when running against\nhttps://review.openstack.org/635831. It will be re-enabled by\nthe functional tests of Manage-Unmanage with Share Servers\nfeature.\n\nChange-Id: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nNeeded-By: https://review.openstack.org/635831\n'}, {'number': 3, 'created': '2019-02-18 19:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/275eb4fff396aa45ba44a8558fb78443441fdcb4', 'message': 'Temporarily disable test_manage_invalid\n\nThis test stops making sense as-is when running against\nhttps://review.openstack.org/635831. The test tries\nto create a share with a share type configured with a\ndriver mode that was unsupported by this API. Since it\nbecomes supported in https://review.openstack.org/635831,\nthe test fails because an error is no longer returned by\nthe API.\n\nThe Manage/Unmanage share test cases are being reworked\nas part of the implementation of the\nManage-Unmanage with Share Servers feature and are to be\nfound in a separate patch dependant on this one.\n\nChange-Id: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nNeeded-By: https://review.openstack.org/635831\n'}, {'number': 4, 'created': '2019-02-20 17:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/a98d9db03ba702de5f8bbf5ffadfa121edcbc840', 'message': 'Temporarily disable test_manage_invalid\n\nThis test stops making sense as-is when running against\nhttps://review.openstack.org/635831. The test tries\nto create a share with a share type configured with a\ndriver mode that was unsupported by this API. Since it\nbecomes supported in https://review.openstack.org/635831,\nthe test fails because an error is no longer returned by\nthe API.\n\nThe Manage/Unmanage share test cases are being reworked\nas part of the implementation of the\nManage-Unmanage with Share Servers feature and are to be\nfound in a separate patch dependant on this one.\n\nChange-Id: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nNeeded-By: https://review.openstack.org/635831\n'}, {'number': 5, 'created': '2019-02-26 18:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/5272b9cbe8fe0eec2328cc6d1dc7a0e5ebb69f45', 'message': 'Temporarily disable test_manage_invalid\n\nThis test stops making sense as-is when running against\nhttps://review.openstack.org/635831. The test tries\nto create a share with a share type configured with a\ndriver mode that was unsupported by this API. Since it\nbecomes supported in https://review.openstack.org/635831,\nthe test fails because an error is no longer returned by\nthe API.\n\nThe Manage/Unmanage share test cases are being reworked\nas part of the implementation of the\nManage-Unmanage with Share Servers feature and are to be\nfound in a separate patch dependant on this one.\n\nChange-Id: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nNeeded-By: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}, {'number': 6, 'created': '2019-03-04 14:14:25.000000000', 'files': ['manila_tempest_tests/tests/api/admin/test_share_manage.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/c60922fb6313dbd8a87d4eafa0e55607e1bda17f', 'message': 'Temporarily disable test_manage_invalid\n\nThis test stops making sense as-is when running against\nhttps://review.openstack.org/635831. The test tries\nto create a share with a share type configured with a\ndriver mode that was unsupported by this API. Since it\nbecomes supported in https://review.openstack.org/635831,\nthe test fails because an error is no longer returned by\nthe API.\n\nThe Manage/Unmanage share test cases are being reworked\nas part of the implementation of the\nManage-Unmanage with Share Servers feature and are to be\nfound in a separate patch dependant on this one.\n\nChange-Id: I17c74b2aa242918188eeff368232c762a4b31093\nPartially-implements: bp manage-unmanage-with-share-servers\nNeeded-By: I108961e7436ba13550ef2b8f02079c6e599a6166\n'}]",6,635885,c60922fb6313dbd8a87d4eafa0e55607e1bda17f,40,6,6,14567,,,0,"Temporarily disable test_manage_invalid

This test stops making sense as-is when running against
https://review.openstack.org/635831. The test tries
to create a share with a share type configured with a
driver mode that was unsupported by this API. Since it
becomes supported in https://review.openstack.org/635831,
the test fails because an error is no longer returned by
the API.

The Manage/Unmanage share test cases are being reworked
as part of the implementation of the
Manage-Unmanage with Share Servers feature and are to be
found in a separate patch dependant on this one.

Change-Id: I17c74b2aa242918188eeff368232c762a4b31093
Partially-implements: bp manage-unmanage-with-share-servers
Needed-By: I108961e7436ba13550ef2b8f02079c6e599a6166
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/85/635885/6 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/admin/test_share_manage.py'],1,a5fd942e7bb9fc195fac7b1c414846aa18b79ea6,manage-unmanage-with-share-servers," @testtools.skipUnless( CONF.share.multitenancy_enabled, ""Will be re-enabled along with the updated tests of Manage-Unmanage "" ""with Share Server patch"")",,4,0
openstack%2Ftripleo-heat-templates~master~I7ca8189432adf64922bd74dc0bceb84a5b297390,openstack/tripleo-heat-templates,master,I7ca8189432adf64922bd74dc0bceb84a5b297390,Remove unused resources of PreNetworkConfig for NFV,MERGED,2019-02-20 05:29:35.000000000,2019-03-05 19:36:18.000000000,2019-03-05 19:36:17.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-20 05:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4fd46db2d666dfe0b404b473cd17631322ef581e', 'message': 'Remove unused resources of PreNetworkConfig for NFV\n\nWith config-download as only supported mechanism, remove\nthe stack based deployments (which are already replaced\nwith ansible base service BootParams).\n\nChange-Id: I7ca8189432adf64922bd74dc0bceb84a5b297390\n'}, {'number': 2, 'created': '2019-02-27 09:45:32.000000000', 'files': ['environments/disable-config-download-environment.yaml', 'extraconfig/pre_network/host_config_and_reboot.yaml', 'overcloud-resource-registry-puppet.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad5dc5ca60b2b0bf72ec5415f330febed013f351', 'message': 'Remove unused resources of PreNetworkConfig for NFV\n\nWith config-download as only supported mechanism, remove\nthe stack based deployments (which are already replaced\nwith ansible base service BootParams).\n\nChange-Id: I7ca8189432adf64922bd74dc0bceb84a5b297390\n'}]",0,638081,ad5dc5ca60b2b0bf72ec5415f330febed013f351,13,7,2,18575,,,0,"Remove unused resources of PreNetworkConfig for NFV

With config-download as only supported mechanism, remove
the stack based deployments (which are already replaced
with ansible base service BootParams).

Change-Id: I7ca8189432adf64922bd74dc0bceb84a5b297390
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/638081/2 && git format-patch -1 --stdout FETCH_HEAD,"['environments/disable-config-download-environment.yaml', 'extraconfig/pre_network/host_config_and_reboot.yaml', 'overcloud-resource-registry-puppet.j2.yaml']",3,4fd46db2d666dfe0b404b473cd17631322ef581e,remove_unused_pre_network,, OS::TripleO::Reboot::SoftwareDeployment: OS::Heat::None ,0,190
openstack%2Fnetworking-ovn~master~I696ec6a40404154bd20d5c36446045755f1206d5,openstack/networking-ovn,master,I696ec6a40404154bd20d5c36446045755f1206d5,Switch default functional tests to Python3,MERGED,2019-03-05 11:45:49.000000000,2019-03-05 19:28:47.000000000,2019-03-05 19:28:46.000000000,"[{'_account_id': 5756}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-03-05 11:45:49.000000000', 'files': ['networking_ovn/tests/contrib/gate_hook.sh', 'playbooks/legacy/networking-ovn-dsvm-functional-py27/post.yaml', 'playbooks/legacy/networking-ovn-dsvm-functional/run.yaml', 'zuul.d/legacy-networking-ovn-jobs.yaml', 'playbooks/legacy/networking-ovn-dsvm-functional-py27/run.yaml', 'zuul.d/project.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6ea0301354858ab02278b2a9ee70187e07e68ec5', 'message': 'Switch default functional tests to Python3\n\nThis patch is switching the default functional tests to Python3 and\nadding a job to Python2.7.\n\nChange-Id: I696ec6a40404154bd20d5c36446045755f1206d5\nCloses-Bug: #1818626\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",0,640988,6ea0301354858ab02278b2a9ee70187e07e68ec5,8,4,1,6773,,,0,"Switch default functional tests to Python3

This patch is switching the default functional tests to Python3 and
adding a job to Python2.7.

Change-Id: I696ec6a40404154bd20d5c36446045755f1206d5
Closes-Bug: #1818626
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/88/640988/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/contrib/gate_hook.sh', 'playbooks/legacy/networking-ovn-dsvm-functional-py27/post.yaml', 'playbooks/legacy/networking-ovn-dsvm-functional/run.yaml', 'zuul.d/legacy-networking-ovn-jobs.yaml', 'playbooks/legacy/networking-ovn-dsvm-functional-py27/run.yaml', 'zuul.d/project.yaml', 'tox.ini']",7,6ea0301354858ab02278b2a9ee70187e07e68ec5,bug/1818626,basepython = python3[testenv:functional-py27] basepython = python2.7basepython = python3[testenv:dsvm-functional-py27] basepython = python2.7,[testenv:functional-py35] basepython = python3.5[testenv:dsvm-functional-py35] basepython = python3.5,22,20
openstack%2Fsenlin~master~Ie5c1fca080c82833941edc130568e76701ce394c,openstack/senlin,master,Ie5c1fca080c82833941edc130568e76701ce394c,Fix Senlin performance issues,MERGED,2019-02-26 19:30:10.000000000,2019-03-05 19:21:59.000000000,2019-03-05 19:21:59.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}, {'_account_id': 27224}, {'_account_id': 28438}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-02-26 19:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a16e902cdf66d04d8cc929d6a37663e239d6f546', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of useing more distinctive join statements.\n\nAdditionally this patch includes a migration to ad a FK constraint\nto the node table for cluster id to get the relationship to work.\n\nThis patch also removes the DB calls that were baked into the\nto_dict() method for the senlin objects and instead retrives that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an apropriate amount of time.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 2, 'created': '2019-02-26 21:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/43e003c6aab43d87fc8457bc8eb71105e6963aea', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of useing more distinctive join statements.\n\nAdditionally this patch includes a migration to ad a FK constraint\nto the node table for cluster id to get the relationship to work.\n\nThis patch also removes the DB calls that were baked into the\nto_dict() method for the senlin objects and instead retrives that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an apropriate amount of time.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 3, 'created': '2019-02-26 21:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a32f7ff1c979c0e2114d6e226800ccdc9fae4099', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of useing more distinctive join statements.\n\nAdditionally this patch includes a migration to ad a FK constraint\nto the node table for cluster id to get the relationship to work.\n\nThis patch also removes the DB calls that were baked into the\nto_dict() method for the senlin objects and instead retrives that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an apropriate amount of time.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 4, 'created': '2019-02-27 01:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/dc57f7c207d6875c82f1dd669827a7a77885968c', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of useing more distinctive join statements.\n\nAdditionally this patch includes a migration to ad a FK constraint\nto the node table for cluster id to get the relationship to work.\n\nThis patch also removes the DB calls that were baked into the\nto_dict() method for the senlin objects and instead retrives that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an apropriate amount of time.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 5, 'created': '2019-02-27 02:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/5dcb3c8e4ec1ba8d610803481b649cb76c0bb56b', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of useing more distinctive join statements.\n\nAdditionally this patch includes a migration to ad a FK constraint\nto the node table for cluster id to get the relationship to work.\n\nThis patch also removes the DB calls that were baked into the\nto_dict() method for the senlin objects and instead retrives that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an apropriate amount of time.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 6, 'created': '2019-02-27 08:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/af87b6095a786a158b67e2dbc1f3d9eda8669400', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of useing more distinctive join statements.\n\nAdditionally this patch includes a migration to ad a FK constraint\nto the node table for cluster id to get the relationship to work.\n\nThis patch also removes the DB calls that were baked into the\nto_dict() method for the senlin objects and instead retrives that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an apropriate amount of time.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 7, 'created': '2019-02-27 09:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/c625fb0fd75e2c81b62eb2c453839594b79af581', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of Senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of using more distinctive join statements.\n\nAdditionally this patch removes the DB calls that were baked into the\nto_dict() method for the Senlin objects and instead retrieves that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an appropriate amount of time.\xa0\n\nThis patch improves performance all around with considerably less CPU\nusage.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 8, 'created': '2019-02-27 22:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/c0ac88f35027f93fa7114f785173bd660f53f455', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of Senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of using more distinctive join statements.\n\nAdditionally this patch removes the DB calls that were baked into the\nto_dict() method for the Senlin objects and instead retrieves that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an appropriate amount of time.\xa0\n\nThis patch improves performance all around with considerably less CPU\nusage.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 9, 'created': '2019-03-01 01:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/03a9831b8dc438d3e2648188efc3a27b77578b08', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of Senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of using more distinctive join statements.\n\nAdditionally this patch removes the DB calls that were baked into the\nto_dict() method for the Senlin objects and instead retrieves that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an appropriate amount of time.\n\nThis patch improves performance all around with considerably less CPU\nusage.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}, {'number': 10, 'created': '2019-03-01 01:30:50.000000000', 'files': ['senlin/tests/unit/db/test_cluster_api.py', 'senlin/tests/unit/engine/test_cluster.py', 'senlin/objects/action.py', 'senlin/objects/cluster.py', 'senlin/tests/unit/engine/test_cluster_policy.py', 'senlin/objects/node.py', 'senlin/db/sqlalchemy/api.py', 'senlin/tests/unit/objects/test_fields.py', 'releasenotes/notes/bug-1817604-41d4b8f6c6f920e4.yaml', 'senlin/db/sqlalchemy/models.py', 'senlin/objects/fields.py', 'senlin/tests/unit/objects/test_cluster.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9f49cfdfb21a51f479fe2d548d67b039ebc217bd', 'message': ""Fix Senlin performance issues\n\nThis patch fixes the interaction of Senlin with the database.\nThe standard model_query (joinload_all('*')) has been removed\nin favor of using more distinctive join statements.\n\nAdditionally this patch removes the DB calls that were baked into the\nto_dict() method for the Senlin objects and instead retrieves that\ndata with joins/single database calls. This allows cluster action\nshow to actually return within an appropriate amount of time.\n\nThis patch improves performance all around with considerably less CPU\nusage.\n\nCloses-Bug: #1817604\nChange-Id: Ie5c1fca080c82833941edc130568e76701ce394c\n""}]",23,639420,9f49cfdfb21a51f479fe2d548d67b039ebc217bd,40,6,10,25674,,,0,"Fix Senlin performance issues

This patch fixes the interaction of Senlin with the database.
The standard model_query (joinload_all('*')) has been removed
in favor of using more distinctive join statements.

Additionally this patch removes the DB calls that were baked into the
to_dict() method for the Senlin objects and instead retrieves that
data with joins/single database calls. This allows cluster action
show to actually return within an appropriate amount of time.

This patch improves performance all around with considerably less CPU
usage.

Closes-Bug: #1817604
Change-Id: Ie5c1fca080c82833941edc130568e76701ce394c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/20/639420/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/db/test_cluster_api.py', 'senlin/tests/unit/engine/test_cluster.py', 'senlin/objects/action.py', 'senlin/db/sqlalchemy/models.py', 'senlin/objects/cluster.py', 'senlin/tests/unit/engine/test_cluster_policy.py', 'senlin/objects/node.py', 'senlin/db/sqlalchemy/migrate_repo/versions/014_node_cluster_id_fk.py', 'senlin/objects/fields.py', 'senlin/db/sqlalchemy/api.py', 'senlin/tests/unit/objects/test_cluster.py']",11,a16e902cdf66d04d8cc929d6a37663e239d6f546,performance_fix,"import six from senlin.objects import cluster_policy as cpo def test_to_dict(self): POLICY1_ID = '2c5139a6-24ba-4a6f-bd53-a268f61536de' POLICY2_ID = '2c5139a6-24ba-4a6f-bd53-a268f61536d3' NODE1_ID = '26f4df4b-889e-4184-ba8d-b5ca122f9566' NODE2_ID = '26f4df4b-889e-4184-ba8d-b5ca122f9567' utils.create_profile(self.ctx, PROFILE_ID) policy_1 = utils.create_policy(self.ctx, POLICY1_ID, 'P1') policy_2 = utils.create_policy(self.ctx, POLICY2_ID, 'P2') p1 = cpo.ClusterPolicy(cluster_id=cluster.id, policy_id=policy_1.id, enabled=True, id=uuidutils.generate_uuid(), last_op=None) p2 = cpo.ClusterPolicy(cluster_id=cluster.id, policy_id=policy_2.id, enabled=True, id=uuidutils.generate_uuid(), last_op=None) values = { 'priority': 12, 'enabled': True, } pb1 = p1.create(self.ctx, cluster.id, POLICY1_ID, values) pb2 = p2.create(self.ctx, cluster.id, POLICY2_ID, values) n1 = utils.create_node(self.ctx, NODE1_ID, PROFILE_ID, cluster.id) n2 = utils.create_node(self.ctx, NODE2_ID, PROFILE_ID, cluster.id) cluster = co.Cluster.get(self.ctx, cluster.id) 'status': six.text_type('INIT'), 'nodes': [six.text_type(n1.id), six.text_type(n2.id)], 'policies': [six.text_type(pb1.id), six.text_type(pb2.id)], 'profile_name': six.text_type('test-profile'),","from senlin.db import api as db_api @mock.patch.object(db_api, 'cluster_policy_ids_by_cluster') @mock.patch.object(db_api, 'node_ids_by_cluster') @mock.patch.object(db_api, 'profile_get') def test_to_dict(self, mock_profile, mock_nodes, mock_bindings): fake_profile = mock.Mock() fake_profile.name = 'PROFILEABC' mock_profile.return_value = fake_profile mock_nodes.return_value = ['N1', 'N2'] mock_bindings.return_value = ['P1', 'P2'] 'status': 'INIT', 'nodes': ['N1', 'N2'], 'policies': ['P1', 'P2'], 'profile_name': 'PROFILEABC',",311,125
openstack%2Fsenlin~master~If9edc253d54d2cf8632979a58ee633932dfd01f7,openstack/senlin,master,If9edc253d54d2cf8632979a58ee633932dfd01f7,Improve Health Manager to avoid duplicate health checks.,MERGED,2019-02-04 21:19:07.000000000,2019-03-05 19:21:58.000000000,2019-03-05 19:21:58.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-02-04 21:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a4781171b0c953781c285f02391ce5bbb25ce5d8', 'message': 'Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster.\n\nThis patch also includes misc QOL improvements to the cluster\naction list command to avoid hitting the database too hard. The\ncluster action list fix is just a bandaid the real fix would to be\nproperly joining the tables instead of doing a db call in the\nto_dict method.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 2, 'created': '2019-02-05 00:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/986be063379182cef9036b4fb92ee6bf3e6368cc', 'message': 'Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster.\n\nThis patch also includes misc QOL improvements to the cluster\naction list command to avoid hitting the database too hard. The\ncluster action list fix is just a bandaid the real fix would to be\nproperly joining the tables instead of doing a db call in the\nto_dict method.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 3, 'created': '2019-02-05 19:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/bc35425ee8baaef28be10ebc1394b976f78b8d0a', 'message': 'Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster.\n\nThis patch also includes misc QOL improvements to the cluster\naction list command to avoid hitting the database too hard. The\ncluster action list fix is just a bandaid the real fix would to be\nproperly joining the tables instead of doing a db call in the\nto_dict method.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 4, 'created': '2019-02-08 02:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2d1a94a1f8991aecfc5fe3582bb6012c106b2773', 'message': '[WIP] Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster. This is\nacomplished by a RuntimeHealthRegistry class that manages the\nruntime/threads for the health manager.\n\nThis patch also includes misc QOL improvements to the cluster\naction list command to avoid hitting the database too hard. The\ncluster action list fix is just a bandaid the real fix would to be\nproperly joining the tables instead of doing a db call in the\nto_dict method.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 5, 'created': '2019-02-09 00:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f2984e6fdccba53e23f69948d5497b77d71bd374', 'message': '[WIP] Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster. This is\nacomplished by a RuntimeHealthRegistry class that manages the\nruntime/threads for the health manager.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 6, 'created': '2019-02-13 02:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/aea6392b744a3ce3b039adff74c0345dd435e4a3', 'message': 'Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster. This is\nacomplished by a RuntimeHealthRegistry class that manages the\nruntime/threads for the health manager.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 7, 'created': '2019-02-13 19:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/50f5cd74b3ef70ef2e8a203a6cbedc70c21d0e93', 'message': 'Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster. This is\nacomplished by a RuntimeHealthRegistry class that manages the\nruntime/threads for the health manager.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}, {'number': 8, 'created': '2019-02-20 19:56:45.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/engine/service.py', 'senlin/common/config.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/drivers/os_test/nova_v2.py', 'senlin/common/consts.py', 'senlin/api/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/39a91603afe152a44855785397b3a269ee83482e', 'message': 'Improve Health Manager to avoid duplicate health checks.\n\nThis patch updates the health manager to avoid getting into a state\nwhere mutiple checks can be running on the same cluster. This is\nacomplished by a RuntimeHealthRegistry class that manages the\nruntime/threads for the health manager.\n\nChange-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7\n'}]",24,634811,39a91603afe152a44855785397b3a269ee83482e,35,4,8,25674,,,0,"Improve Health Manager to avoid duplicate health checks.

This patch updates the health manager to avoid getting into a state
where mutiple checks can be running on the same cluster. This is
acomplished by a RuntimeHealthRegistry class that manages the
runtime/threads for the health manager.

Change-Id: If9edc253d54d2cf8632979a58ee633932dfd01f7
",git fetch https://review.opendev.org/openstack/senlin refs/changes/11/634811/8 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/engine/service.py', 'senlin/objects/action.py', 'senlin/common/config.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/api/common/wsgi.py']",6,a4781171b0c953781c285f02391ce5bbb25ce5d8,hm_misc_fixes," log_exception(err)def log_exception(err): LOG.error(""Unexpected error occurred serving API: %s"", err)"," log_exception(err, sys.exc_info())def log_exception(err, exc_info): args = {'exc_info': exc_info} LOG.error(""Unexpected error occurred serving API: %s"", err, **args)",79,66
openstack%2Fkolla-ansible~stable%2Frocky~I6dfd375c868870f8646ef1a8f02c70812e8f6271,openstack/kolla-ansible,stable/rocky,I6dfd375c868870f8646ef1a8f02c70812e8f6271,Support Docker CE in bootstrap-servers,MERGED,2019-02-22 17:31:14.000000000,2019-03-05 19:11:11.000000000,2019-03-05 19:11:11.000000000,"[{'_account_id': 290}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 24072}]","[{'number': 1, 'created': '2019-02-22 17:31:14.000000000', 'files': ['ansible/roles/baremetal/tasks/install.yml', 'releasenotes/notes/docker-ce-722582da41cf6cd3.yaml', 'ansible/roles/baremetal/tasks/pre-install.yml', 'tests/run.yml', 'ansible/roles/baremetal/templates/docker_yum_repo.j2', 'ansible/kolla-host.yml', 'ansible/roles/baremetal/templates/docker_apt_repo.j2', 'ansible/roles/baremetal/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7de16dbc30f6c1afb62d215af7ba069283ebd79a', 'message': ""Support Docker CE in bootstrap-servers\n\nNOTE: The default of 'docker_legacy_packages' has been changed to 'true'\nin this backport to avoid changing behaviour on a stable branch.\n\nKolla Ansible's bootstrap-servers command provides support for\ninstalling the Docker engine. This is currently done using the packages\nat https://apt.dockerproject.org and https://yum.dockerproject.org.\nThese packages are outdated, with the most recent packages from May 2017\n- docker-engine-17.05.\n\nThe source for up to date docker packages is\nhttps://download.docker.com, which was introduced with the move to\nDocker Community Edition (CE) and Docker Enterprise Edition (EE).\n\nThis change adds support to bootstrap-servers for Docker CE for CentOS\nand Ubuntu.\n\nIt also adds a new variable, 'enable_docker_repo', which controls\nwhether a package repository for Docker will be enabled.\n\nIt also adds a new variable, 'docker_legacy_packages', which controls\nwhether the legacy packages at dockerproject.org will be used or the\nnewer packages at docker.com. The default value for this variable is\n'true', meaning to use the legacy packages.\n\nUpgrading from docker-engine to docker-ce has been tested on CentOS 7.5\nand Ubuntu 16.04, by running 'kolla-ansible bootstrap-servers' with\n'docker_legacy_packages' set to 'false'. The upgrades were successful,\nbut result in all containers being stopped. For this reason, the\nbootstrap-servers command checks running containers prior to upgrading\npackages, and ensures they are running after the package upgrade is\ncomplete.\n\nAs mentioned in the release note, care should be taken when upgrading\nDocker with clustered services, which could lose quorum. To avoid this,\nuse --serial or --limit to apply the change in batches.\n\nChange-Id: I6dfd375c868870f8646ef1a8f02c70812e8f6271\nImplements: blueprint docker-ce\n(cherry picked from commit 48aea5637f3375364cf8330d63389c6785462142)\n""}]",0,638727,7de16dbc30f6c1afb62d215af7ba069283ebd79a,12,5,1,14826,,,0,"Support Docker CE in bootstrap-servers

NOTE: The default of 'docker_legacy_packages' has been changed to 'true'
in this backport to avoid changing behaviour on a stable branch.

Kolla Ansible's bootstrap-servers command provides support for
installing the Docker engine. This is currently done using the packages
at https://apt.dockerproject.org and https://yum.dockerproject.org.
These packages are outdated, with the most recent packages from May 2017
- docker-engine-17.05.

The source for up to date docker packages is
https://download.docker.com, which was introduced with the move to
Docker Community Edition (CE) and Docker Enterprise Edition (EE).

This change adds support to bootstrap-servers for Docker CE for CentOS
and Ubuntu.

It also adds a new variable, 'enable_docker_repo', which controls
whether a package repository for Docker will be enabled.

It also adds a new variable, 'docker_legacy_packages', which controls
whether the legacy packages at dockerproject.org will be used or the
newer packages at docker.com. The default value for this variable is
'true', meaning to use the legacy packages.

Upgrading from docker-engine to docker-ce has been tested on CentOS 7.5
and Ubuntu 16.04, by running 'kolla-ansible bootstrap-servers' with
'docker_legacy_packages' set to 'false'. The upgrades were successful,
but result in all containers being stopped. For this reason, the
bootstrap-servers command checks running containers prior to upgrading
packages, and ensures they are running after the package upgrade is
complete.

As mentioned in the release note, care should be taken when upgrading
Docker with clustered services, which could lose quorum. To avoid this,
use --serial or --limit to apply the change in batches.

Change-Id: I6dfd375c868870f8646ef1a8f02c70812e8f6271
Implements: blueprint docker-ce
(cherry picked from commit 48aea5637f3375364cf8330d63389c6785462142)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/27/638727/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/baremetal/tasks/install.yml', 'releasenotes/notes/docker-ce-722582da41cf6cd3.yaml', 'ansible/roles/baremetal/tasks/pre-install.yml', 'tests/run.yml', 'ansible/roles/baremetal/templates/docker_yum_repo.j2', 'ansible/kolla-host.yml', 'ansible/roles/baremetal/templates/docker_apt_repo.j2', 'ansible/roles/baremetal/defaults/main.yml']",8,7de16dbc30f6c1afb62d215af7ba069283ebd79a,bp/docker-ce,"# Whether to enable a package repository for Docker. enable_docker_repo: true # Whether to use the legacy Docker packages at dockerproject.org instead of the # newer packages at docker.com. docker_legacy_packages: true # Docker APT repository configuration. docker_apt_url: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_apt_url }}{% else %}{{ docker_new_apt_url }}{% endif %}"" docker_apt_repo: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_apt_repo }}{% else %}{{ docker_new_apt_repo }}{% endif %}"" docker_apt_key_file: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_apt_key_file }}{% else %}{{ docker_new_apt_key_file }}{% endif %}"" docker_apt_key_id: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_apt_key_id }}{% else %}{{ docker_new_apt_key_id }}{% endif %}"" docker_apt_package: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_apt_package }}{% else %}{{ docker_new_apt_package }}{% endif %}"" # Docker APT repository configuration when docker_legacy_packages is false. docker_new_apt_url: ""https://download.docker.com/linux/{{ ansible_distribution | lower }}"" docker_new_apt_repo: ""deb {{ docker_new_apt_url }} {{ ansible_lsb.codename }} stable"" docker_new_apt_key_file: ""gpg"" docker_new_apt_key_id: ""0EBFCD88"" docker_new_apt_package: ""docker-ce"" # Docker APT repository configuration when docker_legacy_packages is true. docker_legacy_apt_url: ""{{ 'http://obs.linaro.org/ERP:/17.12/Debian_9' if ansible_architecture == 'aarch64' else 'https://apt.dockerproject.org' }}"" docker_legacy_apt_repo: ""{{ docker_legacy_apt_repo_aarch64 if ansible_architecture == 'aarch64' else docker_legacy_apt_repo_x86_64 }}"" docker_legacy_apt_repo_x86_64: ""deb {{ docker_apt_url }}/repo {{ ansible_distribution | lower }}-{{ ansible_distribution_release | lower }} main"" docker_legacy_apt_repo_aarch64: ""deb {{ docker_apt_url }} ./"" docker_legacy_apt_key_file: ""{{ 'Release.key' if ansible_architecture == 'aarch64' else 'gpg' }}"" docker_legacy_apt_key_id: ""{{ 'C32DA102AD89C2BE' if ansible_architecture == 'aarch64' else 'F76221572C52609D' }}"" docker_legacy_apt_package: ""{{ 'docker-ce' if ansible_architecture == 'aarch64' else 'docker-engine=1.12.*' }}"" # Docker Yum repository configuration. docker_yum_url: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_yum_url }}{% else %}{{ docker_new_yum_url }}{% endif %}"" docker_yum_baseurl: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_yum_baseurl }}{% else %}{{ docker_new_yum_baseurl }}{% endif %}"" docker_yum_gpgkey: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_yum_gpgkey }}{% else %}{{ docker_new_yum_gpgkey }}{% endif %}"" docker_yum_gpgcheck: true docker_yum_package: ""{% if docker_legacy_packages | bool %}{{ docker_legacy_yum_package }}{% else %}{{ docker_new_yum_package }}{% endif %}"" # Docker Yum repository configuration when docker_legacy_packages is false. docker_new_yum_url: ""https://download.docker.com/linux/{{ ansible_distribution | lower }}"" docker_new_yum_baseurl: ""{{ docker_yum_url }}/{{ ansible_distribution_major_version | lower }}/$basearch/stable"" docker_new_yum_gpgkey: ""{{ docker_yum_url }}/gpg"" docker_new_yum_package: ""docker-ce"" # Docker Yum repository configuration when docker_legacy_packages is true. docker_legacy_yum_url: ""https://yum.dockerproject.org"" docker_legacy_yum_baseurl: ""{{ docker_legacy_yum_url }}/repo/main/{{ ansible_distribution | lower }}/{{ ansible_distribution_major_version | lower }}"" docker_legacy_yum_gpgkey: ""{{ docker_legacy_yum_url }}/gpg"" docker_legacy_yum_package: ""docker-engine-1.12.0"" - ""{{ docker_apt_package }}"" - ""{{ docker_yum_package }}""","docker_apt_url: ""{{ 'http://obs.linaro.org/ERP:/17.12/Debian_9' if ansible_architecture == 'aarch64' else 'https://apt.dockerproject.org' }}"" docker_apt_key_file: ""{{ 'Release.key' if ansible_architecture == 'aarch64' else 'gpg' }}"" docker_apt_key_id: ""{{ 'C32DA102AD89C2BE' if ansible_architecture == 'aarch64' else 'F76221572C52609D' }}"" docker_yum_url: ""https://yum.dockerproject.org"" docker_gpg_fingerprint: ""58118E89F3A912897C070ADBF76221572C52609D"" - ""{{ 'docker-ce' if ansible_architecture == 'aarch64' else 'docker-engine=1.12.*' }}"" - docker-engine-1.12.0",178,77
openstack%2Fmanila~master~I44616821c5311d6f14986697efbbe5624de364a5,openstack/manila,master,I44616821c5311d6f14986697efbbe5624de364a5,[pylint] Fix/ignore pylint errors in non-test modules,MERGED,2019-02-19 01:56:14.000000000,2019-03-05 19:05:07.000000000,2019-03-05 19:05:07.000000000,"[{'_account_id': 6413}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 14384}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 26968}]","[{'number': 1, 'created': '2019-02-19 01:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9edefeebb1db57ce63a3314590a21188fd2221ee', 'message': '[pylint] Fix pylint errors in code\n\nPylint does not play very well with\ndynamic object manipulation in python\nThis creates a lot of false-positives in\nthe code-base which affects contributors\nlooking for genuine failures.\n\nSo, this change adds pylint ignore statements\nwhere appropriate to disable testing these\nlines of code and failing.\n\nThis change also replaces all the pylint\nerror codes (they are hard to remember/relate to)\nwith error names which are easier to understand\nwhen reading the code.\n\nThis change also initializes sqlalchemy model\nobjects as dictionaries which is a valid representation\nover None.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 2, 'created': '2019-02-19 02:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/785cd216257eb690f4de1555a18bf82828f2392b', 'message': '[pylint] Fix pylint errors in code\n\nPylint does not play very well with\ndynamic object manipulation in python\nThis creates a lot of false-positives in\nthe code-base which affects contributors\nlooking for genuine failures.\n\nSo, this change adds pylint ignore statements\nwhere appropriate to disable testing these\nlines of code and failing.\n\nThis change also replaces all the pylint\nerror codes (they are hard to remember/relate to)\nwith error names which are easier to understand\nwhen reading the code.\n\nThis change also initializes sqlalchemy model\nobjects as dictionaries which is a valid representation\nover None.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 3, 'created': '2019-02-19 04:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4e880097851d25f5040afe211dc4fa7b0adcbc96', 'message': '[pylint] Fix/ignore pylint errors in code\n\nPylint does not play very well with\ndynamic object manipulation in python\nThis creates a lot of false-positives in\nthe code-base which affects contributors\nlooking for genuine failures.\n\nSo, this change\n- adds pylint ignore statements where appropriate\n  to disable testing these lines of code and failing.\n- replaces all the pylint error codes (they are\n  hard to remember/relate to) with error names\n  which are easier to understand when reading the\n  code.\n- initializes sqlalchemy model objects as dictionaries\n  which is a valid representation over None.\n- removes ignore directives on six.moves which\n  is globally ignored in our pylintrc.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 4, 'created': '2019-02-19 23:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/65613ca5d21a4e5059d451735e0ed05f87969766', 'message': '[pylint] Fix/ignore pylint errors in non-test modules\n\nPylint does not play very well with dynamic object\nmanipulation in python This creates a lot of\nfalse-positives in the code-base which affects\ncontributors looking for genuine failures.\n\nSo, this change\n- adds pylint ignore statements where appropriate\n  to disable testing these lines of code and failing.\n- replaces all the pylint error codes (they are\n  hard to remember/relate to) with error names\n  which are easier to understand when reading the\n  code.\n- initializes sqlalchemy model objects as dictionaries\n  which is a valid representation over None.\n- removes ignore directives on six.moves which\n  is globally ignored in our pylintrc.\n- adds alembic.op to the ignored\n  modules list since they are not supported by\n  pylint and have known issues.\n\nThis patch is the beginning of a series of\ncomments to use pylint in a sane way on manila code.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 5, 'created': '2019-02-19 23:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3a287455ae222a1d9c6500a1a09f660dce0dc27b', 'message': '[pylint] Fix/ignore pylint errors in non-test modules\n\nPylint does not play very well with dynamic object\nmanipulation in python This creates a lot of\nfalse-positives in the code-base which affects\ncontributors looking for genuine failures.\n\nSo, this change\n- adds pylint ignore statements where appropriate\n  to disable testing these lines of code and failing.\n- replaces all the pylint error codes (they are\n  hard to remember/relate to) with error names\n  which are easier to understand when reading the\n  code.\n- initializes sqlalchemy model objects as dictionaries\n  which is a valid representation over None.\n- removes ignore directives on six.moves which\n  is globally ignored in our pylintrc.\n- adds alembic.op to the ignored\n  modules list since they are not supported by\n  pylint and have known issues.\n\nThis patch is the beginning of a series of\ncommits to use pylint in a sane way on manila code.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 6, 'created': '2019-02-20 07:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/eed5f4dfe6ebd49aca22c5df97cf85a302f6bc03', 'message': '[pylint] Fix/ignore pylint errors in non-test modules\n\nPylint does not play very well with dynamic object\nmanipulation in python This creates a lot of\nfalse-positives in the code-base which affects\ncontributors looking for genuine failures.\n\nSo, this change\n- adds pylint ignore statements where appropriate\n  to disable testing these lines of code and failing.\n- replaces all the pylint error codes (they are\n  hard to remember/relate to) with error names\n  which are easier to understand when reading the\n  code.\n- initializes sqlalchemy model objects as dictionaries\n  which is a valid representation over None.\n- removes ignore directives on six.moves which\n  is globally ignored in our pylintrc.\n- adds alembic.op to the ignored\n  modules list since they are not supported by\n  pylint and have known issues.\n\nThis patch is the beginning of a series of\ncommits to use pylint in a sane way on manila code.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 7, 'created': '2019-02-20 10:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fe372e4c78416b07f5819274e9475125a7db3773', 'message': '[pylint] Fix/ignore pylint errors in non-test modules\n\nPylint does not play very well with dynamic object\nmanipulation in python This creates a lot of\nfalse-positives in the code-base which affects\ncontributors looking for genuine failures.\n\nSo, this change\n- adds pylint ignore statements where appropriate\n  to disable testing these lines of code and failing.\n- replaces all the pylint error codes (they are\n  hard to remember/relate to) with error names\n  which are easier to understand when reading the\n  code.\n- initializes sqlalchemy model objects as dictionaries\n  which is a valid representation over None.\n- removes ignore directives on six.moves which\n  is globally ignored in our pylintrc.\n- adds alembic.op to the ignored\n  modules list since they are not supported by\n  pylint and have known issues.\n\nThis patch is the beginning of a series of\ncommits to use pylint in a sane way on manila code.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}, {'number': 8, 'created': '2019-02-25 17:23:39.000000000', 'files': ['manila/share/drivers/dell_emc/common/enas/connector.py', 'manila/api/openstack/__init__.py', '.pylintrc', 'manila/share/drivers/dell_emc/plugins/vmax/object_manager.py', 'manila/share/drivers/dell_emc/plugins/vnx/object_manager.py', 'manila/share_group/api.py', 'manila/db/migrations/alembic/versions/5077ffcc5f1c_add_share_instances.py', 'manila/api/openstack/wsgi.py', 'manila/api/versions.py', 'manila/wsgi/common.py', 'manila/db/migrations/alembic/versions/3db9992c30f3_transform_statuses_to_lowercase.py', 'manila/share/drivers/hpe/hpe_3par_mediator.py', 'manila/utils.py', 'manila/api/v2/share_export_locations.py', 'manila/api/v1/share_types_extra_specs.py', 'manila/db/migrations/alembic/versions/1f0bd302c1a6_add_availability_zones_table.py', 'manila/db/migrations/alembic/versions/56cdbe267881_add_share_export_locations_table.py', 'manila/db/migrations/alembic/versions/579c267fbb4d_add_share_instances_access_map.py', 'manila/share/drivers/zfssa/restclient.py', 'manila/db/migrations/alembic/versions/87ce15c59bbe_add_revert_to_snapshot_support.py', 'manila/db/migrations/alembic/versions/b10fb432c042_squash_share_group_snapshot_members_and_share_snapshot_instance_models.py', 'manila/share/drivers/zfsonlinux/utils.py', 'manila/db/migrations/alembic/versions/3e7d62517afa_add_create_share_from_snapshot_support.py', 'manila/db/migrations/alembic/versions/344c1ac4747f_add_share_instance_access_rules_status.py', 'manila/db/migrations/alembic/env.py', 'manila/db/migrations/alembic/versions/ef0c02b4366_add_share_type_projects.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/db/migrations/alembic/versions/48a7beae3117_move_share_type_id_to_instances.py', 'manila/api/v2/shares.py', 'manila/api/v1/scheduler_stats.py', 'manila/share/drivers/nexenta/ns5/jsonrpc.py', 'manila/tests/api/test_versions.py', 'manila/share/drivers/hitachi/hsp/rest.py', 'manila/api/v2/share_instances.py', 'manila/db/migrations/alembic/migration.py', 'manila/db/sqlalchemy/api.py', 'manila/db/migrations/alembic/versions/03da71c0e321_convert_cgs_to_share_groups.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/db/migrations/alembic/versions/54667b9cade7_restore_share_instance_access_map_state.py', 'manila/db/migrations/alembic/versions/a77e2ad5012d_add_share_snapshot_access.py', 'manila/db/migrations/alembic/versions/dda6de06349_add_export_locations_metadata.py', 'manila/db/sqlalchemy/models.py', 'manila/share/driver.py', 'manila/db/migrations/alembic/versions/55761e5f59c5_add_snapshot_support_extra_spec_to_share_types.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/test.py', 'manila/db/migrations/alembic/versions/e9f79621d83f_add_cast_rules_to_readonly_to_share_instances.py', 'manila/api/v2/share_types.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/3e855d5f60d19dc0ce96fe0e561891e98f75557b', 'message': '[pylint] Fix/ignore pylint errors in non-test modules\n\nPylint does not play very well with dynamic object\nmanipulation in python This creates a lot of\nfalse-positives in the code-base which affects\ncontributors looking for genuine failures.\n\nSo, this change\n- adds pylint ignore statements where appropriate\n  to disable testing these lines of code and failing.\n- replaces all the pylint error codes (they are\n  hard to remember/relate to) with error names\n  which are easier to understand when reading the\n  code.\n- initializes sqlalchemy model objects as dictionaries\n  which is a valid representation over None.\n- removes ignore directives on six.moves which\n  is globally ignored in our pylintrc.\n- adds alembic.op to the ignored\n  modules list since they are not supported by\n  pylint and have known issues.\n\nThis patch is the beginning of a series of\ncommits to use pylint in a sane way on manila code.\n\nChange-Id: I44616821c5311d6f14986697efbbe5624de364a5\n'}]",2,637659,3e855d5f60d19dc0ce96fe0e561891e98f75557b,49,14,8,16643,,,0,"[pylint] Fix/ignore pylint errors in non-test modules

Pylint does not play very well with dynamic object
manipulation in python This creates a lot of
false-positives in the code-base which affects
contributors looking for genuine failures.

So, this change
- adds pylint ignore statements where appropriate
  to disable testing these lines of code and failing.
- replaces all the pylint error codes (they are
  hard to remember/relate to) with error names
  which are easier to understand when reading the
  code.
- initializes sqlalchemy model objects as dictionaries
  which is a valid representation over None.
- removes ignore directives on six.moves which
  is globally ignored in our pylintrc.
- adds alembic.op to the ignored
  modules list since they are not supported by
  pylint and have known issues.

This patch is the beginning of a series of
commits to use pylint in a sane way on manila code.

Change-Id: I44616821c5311d6f14986697efbbe5624de364a5
",git fetch https://review.opendev.org/openstack/manila refs/changes/59/637659/8 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/dell_emc/common/enas/connector.py', 'manila/api/openstack/__init__.py', 'manila/share/drivers/dell_emc/plugins/vmax/object_manager.py', 'manila/api/v1/scheduler_stats.py', 'manila/share/drivers/nexenta/ns5/jsonrpc.py', 'manila/tests/api/test_versions.py', 'manila/share/drivers/dell_emc/plugins/vnx/object_manager.py', 'manila/share_group/api.py', 'manila/share/drivers/hitachi/hsp/rest.py', 'manila/api/openstack/wsgi.py', 'manila/api/v2/share_instances.py', 'manila/db/migrations/alembic/migration.py', 'manila/api/versions.py', 'manila/db/sqlalchemy/api.py', 'manila/wsgi/common.py', 'manila/share/drivers/hpe/hpe_3par_mediator.py', 'manila/utils.py', 'manila/api/v2/share_export_locations.py', 'manila/api/v1/share_types_extra_specs.py', 'manila/db/sqlalchemy/models.py', 'manila/share/driver.py', 'manila/share/drivers/zfssa/restclient.py', 'manila/share/drivers/zfsonlinux/utils.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/test.py', 'manila/api/v2/share_types.py', 'manila/db/migrations/alembic/env.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/api/v2/shares.py']",29,9edefeebb1db57ce63a3314590a21188fd2221ee,pylint," def create(self, req, body): # pylint: disable=function-redefined def create(self, req, body): # pylint: disable=function-redefined def create(self, req, body): # pylint: disable=function-redefined def manage(self, req, body): # pylint: disable=function-redefined"," def create(self, req, body): # pylint: disable=E0102 def create(self, req, body): # pylint: disable=E0102 def create(self, req, body): # pylint: disable=E0102 def manage(self, req, body): # pylint: disable=E0102",59,44
openstack%2Fhorizon~master~I2146b33f46c417c5f1d61a4958336c92f0c03e9c,openstack/horizon,master,I2146b33f46c417c5f1d61a4958336c92f0c03e9c,Updating Note to Setup guide,MERGED,2019-02-20 09:21:51.000000000,2019-03-05 18:55:54.000000000,2019-03-05 18:55:53.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27838}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-02-20 09:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/41ac9412e64259a8f6cc93783918270d97b1f555', 'message': 'Updating Note to Setup guide\n\nDue to [1] patch it\'s better to update note in [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] doc/source/contributor/quickstart.rst\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 2, 'created': '2019-02-21 09:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/82669550c398aa446b07fdfd694d6885701c941a', 'message': 'Updating Note to Setup guide\n\nDue to [1] patch it\'s better to update note in [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] doc/source/contributor/quickstart.rst\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 3, 'created': '2019-02-21 12:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/253ff0fa851486a07ddc9826b35af6661f5e46a4', 'message': 'Updating Note to Setup guide\n\nDue to [1] patch it\'s better to update note in [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] doc/source/contributor/quickstart.rst\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 4, 'created': '2019-02-21 13:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6424a20170d03a8f70349b5e8785475082498185', 'message': 'Updating Setup guide\n\nDue to [1] patch it\'s better to update [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] openstack_dashboard/local/local_settings.py.example\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 5, 'created': '2019-02-21 14:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/83678a70c6c45acf2406023fef2be6499c747d47', 'message': 'Updating Setup guide\n\nDue to [1] patch it\'s better to update [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] openstack_dashboard/local/local_settings.py.example\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 6, 'created': '2019-02-28 08:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/830dc7744f89e1d5ae0f18cf5ebeb4d318ca85af', 'message': 'Updating Note to Setup guide\n\nDue to [1] patch it\'s better to update [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] openstack_dashboard/local/local_settings.py.example\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 7, 'created': '2019-03-05 08:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/57db8563eb80c1ce1148282318ece7c9398253a4', 'message': 'Updating Note to Setup guide\n\nDue to [1] patch it\'s better to update [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] openstack_dashboard/local/local_settings.py.example\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}, {'number': 8, 'created': '2019-03-05 16:32:54.000000000', 'files': ['openstack_dashboard/local/local_settings.py.example', 'doc/source/contributor/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/58211d62845ce1fbd40997b1ffc2524b312f1691', 'message': 'Updating Note to Setup guide\n\nDue to [1] patch it\'s better to update [2] file.\nOtherwise it create confusion to a new devloper if use\n""tox -e runserver"" for developments.\n\n[1] https://review.openstack.org/#/c/630790\n[2] openstack_dashboard/local/local_settings.py.example\n\nChange-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c\n'}]",17,638110,58211d62845ce1fbd40997b1ffc2524b312f1691,37,6,8,29313,,,0,"Updating Note to Setup guide

Due to [1] patch it's better to update [2] file.
Otherwise it create confusion to a new devloper if use
""tox -e runserver"" for developments.

[1] https://review.openstack.org/#/c/630790
[2] openstack_dashboard/local/local_settings.py.example

Change-Id: I2146b33f46c417c5f1d61a4958336c92f0c03e9c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/10/638110/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/quickstart.rst'],1,41ac9412e64259a8f6cc93783918270d97b1f555,638110," ``http://localhost:9000``.If you use ""tox -e runserver"" for developments, then configure SESSION_ENGINE to django.contrib.sessions.backends.signed_cookies in openstack_dashboard/settings.py file.", ``http://localhost:9000``,4,1
openstack%2Fpython-vitrageclient~master~Icf67750226d379c20dbe9d93df18eeabf88aadfa,openstack/python-vitrageclient,master,Icf67750226d379c20dbe9d93df18eeabf88aadfa,Bugfix in add template: the new template_str argument must be last,MERGED,2019-03-05 16:55:13.000000000,2019-03-05 18:51:18.000000000,2019-03-05 18:51:18.000000000,"[{'_account_id': 19134}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 16:55:13.000000000', 'files': ['vitrageclient/v1/template.py'], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/5d6673e343a47fc4cf90e53b2e6e9fa37d7f601c', 'message': 'Bugfix in add template: the new template_str argument must be last\n\nChange-Id: Icf67750226d379c20dbe9d93df18eeabf88aadfa\n'}]",0,641084,5d6673e343a47fc4cf90e53b2e6e9fa37d7f601c,7,3,1,19159,,,0,"Bugfix in add template: the new template_str argument must be last

Change-Id: Icf67750226d379c20dbe9d93df18eeabf88aadfa
",git fetch https://review.opendev.org/openstack/python-vitrageclient refs/changes/84/641084/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrageclient/v1/template.py'],1,5d6673e343a47fc4cf90e53b2e6e9fa37d7f601c,bugfix2," def add(self, path=None, template_type=None, params=None, template_str=None): :param template_type: (optional) The template type, in case it is not written inside the template metadata section :param params: (optional) Actual values for the template parameters def validate(self, path=None, template_type=None, params=None, template_str=None): :param template_type: (optional) The template type, in case it is not written inside the template metadata section :param params: (optional) Actual values for the template parameters"," def add(self, path=None, template_str=None, template_type=None, params=None): :param template_type: (optional) The template type, in case it is not written inside the template metadata section :param params: (optional) Actual values for the template parameters def validate(self, path=None, template_str=None, template_type=None, params=None): :param template_type: (optional) The template type, in case it is not written inside the template metadata section :param params: (optional) Actual values for the template parameters",10,10
openstack%2Floci~master~I64ee9d4eb5b299852c53ee9c6ab8e7d9b862ac73,openstack/loci,master,I64ee9d4eb5b299852c53ee9c6ab8e7d9b862ac73,Make various spelling and usage fixes in Loci,MERGED,2019-01-29 22:04:50.000000000,2019-03-05 18:33:08.000000000,2019-03-05 18:33:08.000000000,"[{'_account_id': 1736}, {'_account_id': 7822}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-29 22:04:50.000000000', 'files': ['scripts/fetch_wheels.py', 'playbooks/vars.yaml', 'playbooks/push.yaml', 'README.md'], 'web_link': 'https://opendev.org/openstack/loci/commit/3f3a672d2589f1c86e11f4b56ff11039ed588c58', 'message': 'Make various spelling and usage fixes in Loci\n\nThis patch is an audit of the Loci documents and code for trivial\nspelling and usage errors.\n\nChange-Id: I64ee9d4eb5b299852c53ee9c6ab8e7d9b862ac73\n'}]",0,633835,3f3a672d2589f1c86e11f4b56ff11039ed588c58,10,4,1,7822,,,0,"Make various spelling and usage fixes in Loci

This patch is an audit of the Loci documents and code for trivial
spelling and usage errors.

Change-Id: I64ee9d4eb5b299852c53ee9c6ab8e7d9b862ac73
",git fetch https://review.opendev.org/openstack/loci refs/changes/35/633835/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/fetch_wheels.py', 'playbooks/push.yaml', 'playbooks/vars.yaml', 'README.md']",4,3f3a672d2589f1c86e11f4b56ff11039ed588c58,spelling, derived from one of those distributions. Dockerfiles to bootstrap the * `PIP_ARGS` Specify additional pip parameters you would like. * `PIP_WHEEL_ARGS` Specify additional pip wheel parameters you would like.To build with the wheels from a private Docker registry rather than Docker Hub run:do this we recommend that you perform any required customization in a child, derived from one of those distributions. Dockerfiles to boostrap the * `PIP_ARGS` Specify additional pip's parameters you would like. * `PIP_WHEEL_ARGS` Specify additional pip's wheel parameters you would like.To build with the wheels from a private Docker registry rather than DockerHub run:do this we recommend that you perform any required customisation in a child,11,11
openstack%2Ftripleo-common~master~I32196c7cef49f59c0d68adf2a585fe7d0f406821,openstack/tripleo-common,master,I32196c7cef49f59c0d68adf2a585fe7d0f406821,Add guard on TestKollaImagBuliderTemplate,ABANDONED,2019-03-05 18:26:32.000000000,2019-03-05 18:29:27.000000000,,[],"[{'number': 1, 'created': '2019-03-05 18:26:32.000000000', 'files': ['tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5b2d39033a144247abb96add2942b67b28bcd999', 'message': 'Add guard on TestKollaImagBuliderTemplate\n\nunittest tweak to not fail if images are not present\n\nChange-Id: I32196c7cef49f59c0d68adf2a585fe7d0f406821\n'}]",0,641102,5b2d39033a144247abb96add2942b67b28bcd999,2,0,1,16282,,,0,"Add guard on TestKollaImagBuliderTemplate

unittest tweak to not fail if images are not present

Change-Id: I32196c7cef49f59c0d68adf2a585fe7d0f406821
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/02/641102/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/tests/image/test_kolla_builder.py'],1,5b2d39033a144247abb96add2942b67b28bcd999,, if image in container_images: container_images.remove(image), container_images.remove(image),2,1
openstack%2Fnova~master~I52247f33faa27a0e0340ea007490302d0fef76ac,openstack/nova,master,I52247f33faa27a0e0340ea007490302d0fef76ac,FUP: docs nit,MERGED,2019-02-27 12:31:17.000000000,2019-03-05 18:28:09.000000000,2019-03-05 18:28:09.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-27 12:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f3ce0b50254143aff9ffe2f1ec0ba83d138773d', 'message': 'FUP: docs nit\n\nFollow-up patch for the reshape series\n\nPart of blueprint reshape-provider-tree\nChange-Id: I52247f33faa27a0e0340ea007490302d0fef76ac\n'}, {'number': 2, 'created': '2019-02-28 09:49:30.000000000', 'files': ['doc/source/admin/virtual-gpu.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/04180e331a73393e33fdf1768e5f3e711f2e2554', 'message': 'FUP: docs nit\n\nFollow-up patch for the reshape series\n\nPart of blueprint reshape-provider-tree\nChange-Id: I52247f33faa27a0e0340ea007490302d0fef76ac\n'}]",0,639647,04180e331a73393e33fdf1768e5f3e711f2e2554,23,11,2,7166,,,0,"FUP: docs nit

Follow-up patch for the reshape series

Part of blueprint reshape-provider-tree
Change-Id: I52247f33faa27a0e0340ea007490302d0fef76ac
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/639647/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/virtual-gpu.rst'],1,3f3ce0b50254143aff9ffe2f1ec0ba83d138773d,bp/reshape-provider-tree," .. warning:: Changing the type is possible but since existing physical GPUs can't address multiple guests having different types, that will make Nova return you a NoValidHost if existing instances with the original type still exist. Accordingly, it's highly recommended to instead deploy the new type to new compute nodes that don't already have workloads and rebuild instances on the nodes that need to change types. ",,11,0
openstack%2Fnova~master~Ide797ebf7790d69042ae275ebec6ced3fa4787b6,openstack/nova,master,Ide797ebf7790d69042ae275ebec6ced3fa4787b6,Add functional test for libvirt vgpu reshape,MERGED,2019-01-17 16:46:10.000000000,2019-03-05 18:28:01.000000000,2019-03-05 18:28:01.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-17 16:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d42ed71333e57ec5a7e48da4785c914e7a3a7799', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 2, 'created': '2019-01-23 23:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ed90d44dc35644b0122c517224e580bb95b93e5', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 3, 'created': '2019-01-23 23:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a433aa1f76e32c4522e48df158e7185bacb8e385', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 4, 'created': '2019-01-25 11:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51b0e825168a2d38d8ec1bdfe63edbb1d7f926d0', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 5, 'created': '2019-02-13 10:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e90f01e81fe9696afcbd96128345a018573cfc05', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 6, 'created': '2019-02-14 13:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22474bddead2f4ce6803b813e0eb0ea5cc5ed1fa', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 7, 'created': '2019-02-14 14:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d0bcfe844aba6d69dccb74e293d5e0d9b5443c2', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 8, 'created': '2019-02-14 17:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98ac81e19608e41b630091e24af21808a9b48b23', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 9, 'created': '2019-02-15 10:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07f165ba35722b3267927c1440af18665a8b32bb', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 10, 'created': '2019-02-19 09:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ce0682e8176ade89999e7a9b90debfd3f3f381c', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 11, 'created': '2019-02-19 16:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35737e27d7e05068fddb0cc4fda3b7d5aeadb307', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot an instance with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocation is reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 12, 'created': '2019-02-27 12:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34f815817cc3b85a6ce6ea5101e2d9b82fb3c46e', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot two instances with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocations are reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}, {'number': 13, 'created': '2019-02-28 09:47:37.000000000', 'files': ['nova/tests/functional/libvirt/base.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/functional/libvirt/test_reshape.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a76eefed62db96fe51ef40e3209c187af3eb9834', 'message': 'Add functional test for libvirt vgpu reshape\n\nThe added functional test covers the reshape code in the libvirt\ndriver for VGPU and all the higher level code interacting with this\nreshape process. It verifies the following sequence:\n\n* boot two instances with VGPU resource request on an old compute where\n  the VGPU resource are provided by the compute RP\n* trigger a reshape and verify that the RP tree and the instance\n  allocations are reshaped properly\n* boot another instance against the new tree and verify its allocation\n\nPart of blueprint reshape-provider-tree\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6\n'}]",50,631559,a76eefed62db96fe51ef40e3209c187af3eb9834,100,13,13,9708,,,0,"Add functional test for libvirt vgpu reshape

The added functional test covers the reshape code in the libvirt
driver for VGPU and all the higher level code interacting with this
reshape process. It verifies the following sequence:

* boot two instances with VGPU resource request on an old compute where
  the VGPU resource are provided by the compute RP
* trigger a reshape and verify that the RP tree and the instance
  allocations are reshaped properly
* boot another instance against the new tree and verify its allocation

Part of blueprint reshape-provider-tree

Co-Authored-By: Sylvain Bauza <sbauza@free.fr>

Change-Id: Ide797ebf7790d69042ae275ebec6ced3fa4787b6
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/631559/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/base.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/functional/libvirt/test_reshape.py']",3,d42ed71333e57ec5a7e48da4785c914e7a3a7799,bp/reshape-provider-tree,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import time import mock from oslo_config import cfg from oslo_log import log as logging from nova.tests.functional.libvirt import base from nova.tests.unit.virt.libvirt import fakelibvirt from nova.virt.libvirt import driver as libvirt_driver CONF = cfg.CONF LOG = logging.getLogger(__name__) class VGPUReshapeTests(base.ServersTestBase): def setUp(self): super(VGPUReshapeTests, self).setUp() def _wait_for_state_change(self, server, expected_status): for i in range(0, 50): server = self.api.get_server(server['id']) if server['status'] == expected_status: return server time.sleep(.1) self.assertEqual(expected_status, server['status']) return server def test_create_server_with_vgpu(self): """""" Verify that vgpu rehape works with libvirt driver 1) create a server with an old tree where ther VGPU resource is on the compute provider 2) trigger a reshape 3) check that the allocation of the server is still valid 4) create another server now against the new tree """""" # NOTE(gibi): We cannot simply ask the virt driver to create an old # RP tree with vgpu on the root RP as that code path does not exists # any more. So we have to hack a ""bit"". We will create a compute # service without vgpu support to have the compute RP ready then we # manually add the VGPU resource to that RP in placement. Also we make # sure that during the instance claim the virt drive does not detect # the old tree as that would be a bad time for reshape. Later when the # compute service is restarted the driver will do the reshape. fake_connection = self._get_connection( host_info=fakelibvirt.HostInfo(), libvirt_version=libvirt_driver.MIN_LIBVIRT_MDEV_SUPPORT, mdev_info=fakelibvirt.HostMdevDevicesInfo()) self.mock_conn.return_value = fake_connection # start a compute with vgpu support disabled so the driver will # ignore the content of the above HostMdevDeviceInfo self.flags(enabled_vgpu_types='', group='devices') self.compute = self.start_service('compute') # create the VGPU resource in placement manually compute_rp_uuid = self.placement_api.get( '/resource_providers?name=compute1').body[ 'resource_providers'][0]['uuid'] inventories = self.placement_api.get( '/resource_providers/%s/inventories' % compute_rp_uuid).body inventories['inventories']['VGPU'] = { 'allocation_ratio': 1.0, 'max_unit': 2, 'min_unit': 1, 'reserved': 0, 'step_size': 1, 'total': 2} self.placement_api.put( '/resource_providers/%s/inventories' % compute_rp_uuid, inventories) # now we boot a server with vgpu extra_spec = {""resources:VGPU"": 1} flavor_id = self._create_flavor(extra_spec=extra_spec) server_req = self._build_server(flavor_id) # NOTE(gibi): during instance_claim() there is a # driver.update_provider_tree() call that would detect the old tree and # would fail as this is not a good time to reshape. To avoid that we # temporarly mock update_provider_tree here. with mock.patch('nova.virt.libvirt.driver.LibvirtDriver.' 'update_provider_tree'): created_server = self.api.post_server({'server': server_req}) server1 = self._wait_for_state_change(created_server, 'ACTIVE') # verify that the inventory, usages and allocation are correct before # the reshape compute_inventory = self.placement_api.get( '/resource_providers/%s/inventories' % compute_rp_uuid).body[ 'inventories'] self.assertEqual(2, compute_inventory['VGPU']['total']) compute_usages = self.placement_api.get( '/resource_providers/%s/usages' % compute_rp_uuid).body[ 'usages'] self.assertEqual(1, compute_usages['VGPU']) allocations = self.placement_api.get( '/allocations/%s' % server1['id']).body[ 'allocations'] self.assertEqual( {'DISK_GB': 20, 'MEMORY_MB': 2048, 'VCPU': 2, 'VGPU': 1}, allocations[compute_rp_uuid]['resources']) self.compute.stop() # enabled vgpu support self.flags(enabled_vgpu_types='nvidia-11', group='devices') # start compute which will trigger a reshape self.compute.start() # verify that the inventory, usages and allocation are correct after # the reshape compute_inventory = self.placement_api.get( '/resource_providers/%s/inventories' % compute_rp_uuid).body[ 'inventories'] self.assertNotIn('VGPU', compute_inventory) gpu_rp_uuid = self.placement_api.get( '/resource_providers?name=compute1_pci_0000_06_00_0').body[ 'resource_providers'][0]['uuid'] gpu_inventory = self.placement_api.get( '/resource_providers/%s/inventories' % gpu_rp_uuid).body[ 'inventories'] self.assertEqual(2, gpu_inventory['VGPU']['total']) gpu_usages = self.placement_api.get( '/resource_providers/%s/usages' % gpu_rp_uuid).body[ 'usages'] self.assertEqual(1, gpu_usages['VGPU']) allocations = self.placement_api.get( '/allocations/%s' % server1['id']).body[ 'allocations'] self.assertEqual( {'DISK_GB': 20, 'MEMORY_MB': 2048, 'VCPU': 2}, allocations[compute_rp_uuid]['resources']) self.assertEqual( {'VGPU': 1}, allocations[gpu_rp_uuid]['resources']) # now create one more instance with vgpu against the reshaped tree created_server = self.api.post_server({'server': server_req}) server2 = self._wait_for_state_change(created_server, 'ACTIVE') gpu_usages = self.placement_api.get( '/resource_providers/%s/usages' % gpu_rp_uuid).body[ 'usages'] self.assertEqual(2, gpu_usages['VGPU']) allocations = self.placement_api.get( '/allocations/%s' % server2['id']).body[ 'allocations'] self.assertEqual( {'DISK_GB': 20, 'MEMORY_MB': 2048, 'VCPU': 2}, allocations[compute_rp_uuid]['resources']) self.assertEqual( {'VGPU': 1}, allocations[gpu_rp_uuid]['resources']) ",,278,17
openstack%2Fnova~master~I511d26dc6487fadfcf22ba747abd385068e975a4,openstack/nova,master,I511d26dc6487fadfcf22ba747abd385068e975a4,libvirt: implement reshaper for vgpu,MERGED,2018-09-02 00:35:08.000000000,2019-03-05 18:27:53.000000000,2019-03-05 18:27:52.000000000,"[{'_account_id': 7}, {'_account_id': 4690}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8864}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25638}, {'_account_id': 26515}, {'_account_id': 27076}]","[{'number': 1, 'created': '2018-09-02 00:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8389c947953f697b5cc74f775b680b379b8f6252', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 2, 'created': '2018-09-02 14:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c27c9bb39d86600de49014ecf1dfccbb185b75c8', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 3, 'created': '2018-09-17 15:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff0c440c5d131f0a27752fd6e5aa4d6ba0d7b464', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 4, 'created': '2018-09-17 16:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef015bb3190c161c9da3909d1aece0ba90c03cd7', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 5, 'created': '2018-09-24 14:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/504262ccc33fa6f8fcb877d15bc784ad90baeb8b', 'message': 'WIP: libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nTODO: - Unit tests refactoring\n\nPart of blueprint reshape-provider-tree\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 6, 'created': '2018-10-02 18:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e2cc89af08e4962a97bfad95bff278224e20606', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 7, 'created': '2018-10-03 17:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c2db8371ecf7999d7f40525acc2397052182c3b', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 8, 'created': '2018-10-05 09:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df6dd72ca237b8a2c7e3701be5befee23f68f5de', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 9, 'created': '2018-11-21 19:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/817cb31092f2379b84f50015bb543e3a7e93eb47', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 10, 'created': '2018-11-22 10:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81d82d1560a04b06f0903b934e915a38d4ae610c', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 11, 'created': '2019-01-23 23:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96bf66f083c11e1229fe83add9022fae3340568a', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 12, 'created': '2019-01-23 23:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3150726396e60a9a9eea5492adc5ee98af92cda5', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 13, 'created': '2019-02-13 10:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b712453b180cdc7f4257d69c494b997351b218d', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nPart of blueprint vgpu-stein\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 14, 'created': '2019-02-14 17:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/520125109a7d65948f0fdbf57709cda0e9acbc7d', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nPart of blueprint vgpu-stein\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 15, 'created': '2019-02-15 10:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8022e4dc6a1df3e14e6fec12d9994df91c987fcd', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nPart of blueprint vgpu-stein\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 16, 'created': '2019-02-19 09:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a151bbab07c6090a46e3131eecf6addec6b27c0b', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nPart of blueprint vgpu-stein\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 17, 'created': '2019-02-19 16:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73c4c87a0f726b1d65e29789638261d8a6d61231', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nPart of blueprint vgpu-stein\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}, {'number': 18, 'created': '2019-02-27 12:31:17.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/libvirt-stein-vgpu-reshape-a1fa23b8ad8aa966.yaml', 'nova/virt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/054eb3a652f340d819f1b04567d0ed5e207ed733', 'message': 'libvirt: implement reshaper for vgpu\n\nThis implements the reshaper routine for the libvirt driver\nto detect and move, if necessary, VGPU inventory and allocations\nfrom the root compute node provider to a child provider of\nVGPU resources. The reshape will be performed on first start\nof nova-compute with this code.\n\nFor a fresh compute node deploy, no reshaping will be necessary\nand the VGPU inventory will start on the child provider.\n\nPart of blueprint reshape-provider-tree\nPart of blueprint vgpu-stein\n\nCo-Authored-By: Sylvain Bauza <sbauza@free.fr>\n\nChange-Id: I511d26dc6487fadfcf22ba747abd385068e975a4\n'}]",176,599208,054eb3a652f340d819f1b04567d0ed5e207ed733,276,27,18,6873,,,0,"libvirt: implement reshaper for vgpu

This implements the reshaper routine for the libvirt driver
to detect and move, if necessary, VGPU inventory and allocations
from the root compute node provider to a child provider of
VGPU resources. The reshape will be performed on first start
of nova-compute with this code.

For a fresh compute node deploy, no reshaping will be necessary
and the VGPU inventory will start on the child provider.

Part of blueprint reshape-provider-tree
Part of blueprint vgpu-stein

Co-Authored-By: Sylvain Bauza <sbauza@free.fr>

Change-Id: I511d26dc6487fadfcf22ba747abd385068e975a4
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/599208/18 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/libvirt-stein-vgpu-reshape-a1fa23b8ad8aa966.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,8389c947953f697b5cc74f775b680b379b8f6252,bp/reshape-provider-tree," # VGPU inventory will be on a child provider in the tree. vgpu_inventory = { rc_fields.ResourceClass.VGPU: { 'step_size': 1, 'min_unit': 1, 'max_unit': 8, 'total': 8 } } # root compute node provider inventory is unchanged # We should have a new VGPU child provider in the tree under the # compute node root provider. compute_node_tree_uuids = self.pt.get_provider_uuids(self.cn_rp.name) self.assertEqual(2, len(compute_node_tree_uuids)) # The VGPU child provider should be the 2nd UUID in that list. vgpu_rp_uuid = compute_node_tree_uuids[1] # The VGPU inventory should be on the VGPU child provider in the tree. vgpu_provider_data = self.pt.data(vgpu_rp_uuid) self.assertEqual('%s_VGPU' % self.cn_rp.name, vgpu_provider_data.name) self.assertEqual(vgpu_inventory, vgpu_provider_data.inventory) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_cpu_traits', new=mock.Mock(return_value=cpu_traits)) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_vgpu_total', return_value=8) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_local_gb_info', return_value={'total': disk_gb}) @mock.patch('nova.virt.libvirt.host.Host.get_memory_mb_total', return_value=memory_mb) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_vcpu_total', return_value=vcpus) def test_update_provider_tree_for_vgpu_reshape( self, mock_vcpu, mock_mem, mock_disk, mock_vgpus): """"""Tests the VGPU reshape scenario."""""" # First create a provider tree with VGPU inventory on the root node # provider. inventory = self._get_inventory() vgpu_inventory = { rc_fields.ResourceClass.VGPU: { 'step_size': 1, 'min_unit': 1, 'max_unit': 8, 'total': 8 } } inventory.update(vgpu_inventory) self.pt.update_inventory(self.cn_rp.uuid, inventory) # Call update_provider_tree which will raise ReshapeNeeded because # there is VGPU inventory on the root node provider. self.assertRaises(exception.ReshapeNeeded, self.driver.update_provider_tree, self.pt, self.cn_rp.name) # Now make up some fake allocations to pass back to the upt method # for the reshape. allocations = { uuids.consumer1: { 'allocations': { # This consumer has ram and vgpu allocations on the root # node provider and should be changed. self.cn_rp.uuid: { 'resources': { rc_fields.ResourceClass.MEMORY_MB: 512, rc_fields.ResourceClass.VGPU: 1 } } } }, uuids.consumer2: { 'allocations': { # This consumer has ram and vcpu allocations on the root # node provider and should not be changed. self.cn_rp.uuid: { 'resources': { rc_fields.ResourceClass.MEMORY_MB: 256, rc_fields.ResourceClass.VCPU: 2 } } } } } original_allocations = copy.deepcopy(allocations) # Initiate the reshape. self.driver.update_provider_tree( self.pt, self.cn_rp.name, allocations=allocations) # We should have a new VGPU child provider in the tree under the # compute node root provider. compute_node_tree_uuids = self.pt.get_provider_uuids(self.cn_rp.name) self.assertEqual(2, len(compute_node_tree_uuids)) # The VGPU child provider should be the 2nd UUID in that list. vgpu_rp_uuid = compute_node_tree_uuids[1] # The VGPU inventory should be on the VGPU child provider in the tree. vgpu_provider_data = self.pt.data(vgpu_rp_uuid) self.assertEqual('%s_VGPU' % self.cn_rp.name, vgpu_provider_data.name) self.assertEqual(vgpu_inventory, vgpu_provider_data.inventory) # The compute node root provider should not have VGPU inventory. del inventory[rc_fields.ResourceClass.VGPU] self.assertEqual(inventory, self.pt.data(self.cn_rp.uuid).inventory) # consumer1 should now have allocations against two providers, # MEMORY_MB on the root compute node provider and VGPU on the child # provider. consumer1_allocs = allocations[uuids.consumer1]['allocations'] self.assertEqual(2, len(consumer1_allocs)) self.assertEqual({rc_fields.ResourceClass.MEMORY_MB: 512}, consumer1_allocs[self.cn_rp.uuid]['resources']) self.assertEqual({rc_fields.ResourceClass.VGPU: 1}, consumer1_allocs[vgpu_rp_uuid]['resources']) # The allocations on consumer2 should be unchanged. self.assertEqual(original_allocations[uuids.consumer2], allocations[uuids.consumer2]) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_cpu_traits', new=mock.Mock(return_value=cpu_traits)) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_vgpu_total', return_value=8) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_local_gb_info', return_value={'total': disk_gb}) @mock.patch('nova.virt.libvirt.host.Host.get_memory_mb_total', return_value=memory_mb) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_vcpu_total', return_value=vcpus) def test_update_provider_tree_for_vgpu_reshape_fails( self, mock_vcpu, mock_mem, mock_disk, mock_vgpus): """"""Tests the VGPU reshape failure scenario where VGPU allocations are not on the root compute node provider as expected. """""" # First create a provider tree with VGPU inventory on the root node # provider. inventory = self._get_inventory() vgpu_inventory = { rc_fields.ResourceClass.VGPU: { 'step_size': 1, 'min_unit': 1, 'max_unit': 8, 'total': 8 } } inventory.update(vgpu_inventory) self.pt.update_inventory(self.cn_rp.uuid, inventory) # Now make up some fake allocations to pass back to the upt method # for the reshape. allocations = { uuids.consumer1: { 'allocations': { # This consumer has invalid VGPU allocations on a non-root # compute node provider. uuids.other_rp: { 'resources': { rc_fields.ResourceClass.MEMORY_MB: 512, rc_fields.ResourceClass.VGPU: 1 } } } } } # Initiate the reshape. ex = self.assertRaises(exception.ReshapeFailed, self.driver.update_provider_tree, self.pt, self.cn_rp.name, allocations=allocations) self.assertIn('Unexpected VGPU resource allocation on provider %s' % uuids.other_rp, six.text_type(ex)) "," # Add VGPU in the expected inventory inventory[rc_fields.ResourceClass.VGPU] = {'step_size': 1, 'min_unit': 1, 'max_unit': 8, 'total': 8}",262,12
openstack%2Foslo.limit~master~Id4cb74fcbb011bd80f82c0cad907b6eea9c47f1a,openstack/oslo.limit,master,Id4cb74fcbb011bd80f82c0cad907b6eea9c47f1a,Drop py35 jobs,MERGED,2019-02-28 05:40:01.000000000,2019-03-05 18:26:27.000000000,2019-03-05 18:26:27.000000000,"[{'_account_id': 5046}, {'_account_id': 6928}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-02-28 05:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/f0ef0a5703c219f811d8401e6c02789b52684c5c', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: Id4cb74fcbb011bd80f82c0cad907b6eea9c47f1a\n'}, {'number': 2, 'created': '2019-03-01 04:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/dc02ee95f363b702790b53f1b98ef2618c15730c', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: Id4cb74fcbb011bd80f82c0cad907b6eea9c47f1a\n'}, {'number': 3, 'created': '2019-03-05 05:43:10.000000000', 'files': ['.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/e089af1370899aa04d107c1cbd40caa50a2f599d', 'message': 'Drop py35 jobs\n\nPython 3.5 was the target runtime for the Rocky release.\nThe current target py3 runtime for Stein is Python 3.6,\nso there is no reason to keep testing against the older version.\n\nhttps://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein\n\nChange-Id: Id4cb74fcbb011bd80f82c0cad907b6eea9c47f1a\n'}]",2,639917,e089af1370899aa04d107c1cbd40caa50a2f599d,14,4,3,27621,,,0,"Drop py35 jobs

Python 3.5 was the target runtime for the Rocky release.
The current target py3 runtime for Stein is Python 3.6,
so there is no reason to keep testing against the older version.

https://governance.openstack.org/tc/reference/runtimes/stein.html#python-runtime-for-stein

Change-Id: Id4cb74fcbb011bd80f82c0cad907b6eea9c47f1a
",git fetch https://review.opendev.org/openstack/oslo.limit refs/changes/17/639917/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,f0ef0a5703c219f811d8401e6c02789b52684c5c,drop-py35,"envlist = py27,pep8,docs","envlist = py35,py27,pep8,docs",1,3
openstack%2Ftraining-labs~stable%2Fqueens~Ic42c13bb024d099d05127fa6e9700898f52df8e9,openstack/training-labs,stable/queens,Ic42c13bb024d099d05127fa6e9700898f52df8e9,Remove commented (obsolete) code,MERGED,2019-03-05 13:59:27.000000000,2019-03-05 18:25:09.000000000,2019-03-05 18:25:09.000000000,"[{'_account_id': 11109}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 13:59:27.000000000', 'files': ['labs/osbash/lib/osbash/lib.ubuntu-16.04-server-amd64.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/e9f894507973d8c2aa7829fb9cb76568ef7dd56d', 'message': 'Remove commented (obsolete) code\n\nChange-Id: Ic42c13bb024d099d05127fa6e9700898f52df8e9\n'}]",0,641017,e9f894507973d8c2aa7829fb9cb76568ef7dd56d,7,3,1,11109,,,0,"Remove commented (obsolete) code

Change-Id: Ic42c13bb024d099d05127fa6e9700898f52df8e9
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/17/641017/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/lib/osbash/lib.ubuntu-16.04-server-amd64.sh'],1,e9f894507973d8c2aa7829fb9cb76568ef7dd56d,cleanup,,#ISO_MD5=23e97cd5d4145d4105fbf29878534049,0,1
openstack%2Fmanila~master~I344b91dca0cfb034751cab9b2c1c9ee0edb4a3cc,openstack/manila,master,I344b91dca0cfb034751cab9b2c1c9ee0edb4a3cc,[pylint] Stop linting usage of 'mock.Mock' module,ABANDONED,2019-02-18 21:54:51.000000000,2019-03-05 18:00:01.000000000,,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 14384}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 26968}]","[{'number': 1, 'created': '2019-02-18 21:54:51.000000000', 'files': ['.pylintrc'], 'web_link': 'https://opendev.org/openstack/manila/commit/220cd3b99d702f5b29a37b74aae6ccfb0f9fbd59', 'message': ""[pylint] Stop linting usage of 'mock.Mock' module\n\npylint does not support (and has no plans to support\n[1][2][3]) the mock.Mock module since it is complicated\nto detect all the monkey patching that mock.Mock does\nto help us unit-test manila code.\n\nSo, ignore the mock.Mock class instead of raising\nall the false positives as warnings, and failing\nthe pylint job.\n\n[1] https://github.com/PyCQA/pylint/issues/1645\n[2] https://github.com/PyCQA/pylint/issues/697\n[3] https://github.com/PyCQA/pylint/issues/323\n\nChange-Id: I344b91dca0cfb034751cab9b2c1c9ee0edb4a3cc\n""}]",1,637634,220cd3b99d702f5b29a37b74aae6ccfb0f9fbd59,12,9,1,16643,,,0,"[pylint] Stop linting usage of 'mock.Mock' module

pylint does not support (and has no plans to support
[1][2][3]) the mock.Mock module since it is complicated
to detect all the monkey patching that mock.Mock does
to help us unit-test manila code.

So, ignore the mock.Mock class instead of raising
all the false positives as warnings, and failing
the pylint job.

[1] https://github.com/PyCQA/pylint/issues/1645
[2] https://github.com/PyCQA/pylint/issues/697
[3] https://github.com/PyCQA/pylint/issues/323

Change-Id: I344b91dca0cfb034751cab9b2c1c9ee0edb4a3cc
",git fetch https://review.opendev.org/openstack/manila refs/changes/34/637634/1 && git format-patch -1 --stdout FETCH_HEAD,['.pylintrc'],1,220cd3b99d702f5b29a37b74aae6ccfb0f9fbd59,pylint,ignored-classes=mock.Mock,,1,1
openstack%2Fpython-novaclient~master~Id324486b5ef32615881085cd46772aa55c245ac6,openstack/python-novaclient,master,Id324486b5ef32615881085cd46772aa55c245ac6,Microversion 2.71 - show server group,MERGED,2019-03-03 22:13:06.000000000,2019-03-05 17:51:11.000000000,2019-03-05 17:51:11.000000000,"[{'_account_id': 679}, {'_account_id': 6873}, {'_account_id': 8313}, {'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-03 22:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/cf526276d1e5f0ded958de2d9b03b7f7f0e7af56', 'message': ""Microversion 2.71 - show server group\n\nAdd support microversion 2.71 which adds server group\ninformation in the output of the following commands.\n\n* nova show\n* nova rebuild\n\nThe 'nova update' command does not output its result\nwhen it is successful.\nSo there is no change for the command.\n\nThe patch for microversion 2.71 in the nova side is\nI4a2a584df56ece7beb8b12c0ce9b0e6b30237120.\n\nChange-Id: Id324486b5ef32615881085cd46772aa55c245ac6\nImplements: blueprint show-server-group\n""}, {'number': 2, 'created': '2019-03-04 17:00:31.000000000', 'files': ['novaclient/tests/unit/v2/fakes.py', 'novaclient/__init__.py', 'releasenotes/notes/microversion-v2_71-a87b4bb4205c46e2.yaml', 'novaclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/b2cd7e12ccb65e67be0a0b01243d6f19f95e70e8', 'message': ""Microversion 2.71 - show server group\n\nAdd support microversion 2.71 which adds server group\ninformation in the output of the following commands.\n\n* nova show\n* nova rebuild\n\nThe 'nova update' command does not output its result\nwhen it is successful.\nSo there is no change for the command.\n\nThe patch for microversion 2.71 in the nova side is\nI4a2a584df56ece7beb8b12c0ce9b0e6b30237120.\n\nChange-Id: Id324486b5ef32615881085cd46772aa55c245ac6\nImplements: blueprint show-server-group\n""}]",10,640657,b2cd7e12ccb65e67be0a0b01243d6f19f95e70e8,13,5,2,7634,,,0,"Microversion 2.71 - show server group

Add support microversion 2.71 which adds server group
information in the output of the following commands.

* nova show
* nova rebuild

The 'nova update' command does not output its result
when it is successful.
So there is no change for the command.

The patch for microversion 2.71 in the nova side is
I4a2a584df56ece7beb8b12c0ce9b0e6b30237120.

Change-Id: Id324486b5ef32615881085cd46772aa55c245ac6
Implements: blueprint show-server-group
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/57/640657/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/unit/v2/fakes.py', 'novaclient/__init__.py', 'releasenotes/notes/microversion-v2_71-a87b4bb4205c46e2.yaml', 'novaclient/tests/unit/v2/test_shell.py']",4,cf526276d1e5f0ded958de2d9b03b7f7f0e7af56,bp/show-server-group," def test_rebuild_server_group(self): out = self.run_command('rebuild sample-server %s' % FAKE_UUID_1, api_version='2.71')[0] self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers/1234', pos=1) self.assert_called('GET', '/v2/images/%s' % FAKE_UUID_1, pos=2) self.assert_called('POST', '/servers/1234/action', {'rebuild': {'imageRef': FAKE_UUID_1, 'description': None, } }, pos=3) self.assert_called('GET', '/v2/images/%s' % FAKE_UUID_2, pos=4) self.assertIn('server_groups', out) self.assertIn('a67359fb-d397-4697-88f1-f55e3ee7c499', out) def test_rebuild_server_group_pre_v271(self): out = self.run_command('rebuild sample-server %s' % FAKE_UUID_1, api_version='2.70')[0] self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers/1234', pos=1) self.assert_called('GET', '/v2/images/%s' % FAKE_UUID_1, pos=2) self.assert_called('POST', '/servers/1234/action', {'rebuild': {'imageRef': FAKE_UUID_1, 'description': None, } }, pos=3) self.assert_called('GET', '/v2/images/%s' % FAKE_UUID_2, pos=4) self.assertNotIn('server_groups', out) self.assertNotIn('a67359fb-d397-4697-88f1-f55e3ee7c499', out) def test_show_including_server_group(self): # Starting microversion 2.71, the 'server_groups' is included # in the output (the response). out = self.run_command('show 1234', api_version='2.71')[0] self.assert_called('GET', '/servers?name=1234', pos=0) self.assert_called('GET', '/servers?name=1234', pos=1) self.assert_called('GET', '/servers/1234', pos=2) self.assert_called('GET', '/v2/images/%s' % FAKE_UUID_2, pos=3) self.assertIn('server_groups', out) self.assertIn('a67359fb-d397-4697-88f1-f55e3ee7c499', out) def test_show_including_server_group_pre_v271(self): out = self.run_command('show 1234', api_version='2.70')[0] self.assert_called('GET', '/servers?name=1234', pos=0) self.assert_called('GET', '/servers?name=1234', pos=1) self.assert_called('GET', '/servers/1234', pos=2) self.assert_called('GET', '/v2/images/%s' % FAKE_UUID_2, pos=3) self.assertNotIn('server_groups', out) self.assertNotIn('a67359fb-d397-4697-88f1-f55e3ee7c499', out) 71, # There are no version-wrapped shell method changes for this.",,67,3
openstack%2Fplacement~master~I85ebc98502e9ca694ff07746e8e23c26e386df3c,openstack/placement,master,I85ebc98502e9ca694ff07746e8e23c26e386df3c,Retry new transaction on failure,MERGED,2019-03-05 05:46:28.000000000,2019-03-05 17:50:20.000000000,2019-03-05 17:50:20.000000000,"[{'_account_id': 7}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 05:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d0bf7c34cc409eb17afada8ebadefcf98cae9bfd', 'message': 'Retry new transaction on failure\n\nAt high concurrency of setting aggregates, _ensure_aggregate() could\nraise a DBDuplicateEntry error. The oslo_db_api wrapper caught it and\nretry the same function, but it couldn\'t find the new entry again\nbecause it tries to find it in the same transaction.\n\nThis blindness of the new record could happen depending on the DB\ntransaction isolation level, but it happens with ""REPEATABLE_READ""\nlevel, to which MySQL defaults.\n\nThis patch moves the retrying wrapper to the upper layer,\n_set_aggregate(), to restart a new transaction when the\nDBDuplicateEntry error happens so that it can find the new entry\nanother transaction has added.\n\nChange-Id: I85ebc98502e9ca694ff07746e8e23c26e386df3c\n'}, {'number': 2, 'created': '2019-03-05 11:39:57.000000000', 'files': ['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/a6f0285778d565595603a08176a7ae2213f2a378', 'message': 'Retry new transaction on failure\n\nAt high concurrency of setting aggregates, _ensure_aggregate() could\nraise a DBDuplicateEntry error. The oslo_db_api wrapper caught it and\nretried the same function, but it couldn\'t find the new entry again\nbecause it tried to find it in the same transaction.\n\nThis blindness of the new record could happen depending on the DB\ntransaction isolation level, but it happens with ""REPEATABLE_READ""\nlevel, to which MySQL defaults.\n\nThis patch moves the retrying wrapper to the upper layer,\n_set_aggregate(), to restart a new transaction when the\nDBDuplicateEntry error happens so that it can find the new entry\nanother transaction has added.\n\nChange-Id: I85ebc98502e9ca694ff07746e8e23c26e386df3c\nCloses-Bug: #1818498\n'}]",4,640939,a6f0285778d565595603a08176a7ae2213f2a378,12,4,2,25625,,,0,"Retry new transaction on failure

At high concurrency of setting aggregates, _ensure_aggregate() could
raise a DBDuplicateEntry error. The oslo_db_api wrapper caught it and
retried the same function, but it couldn't find the new entry again
because it tried to find it in the same transaction.

This blindness of the new record could happen depending on the DB
transaction isolation level, but it happens with ""REPEATABLE_READ""
level, to which MySQL defaults.

This patch moves the retrying wrapper to the upper layer,
_set_aggregate(), to restart a new transaction when the
DBDuplicateEntry error happens so that it can find the new entry
another transaction has added.

Change-Id: I85ebc98502e9ca694ff07746e8e23c26e386df3c
Closes-Bug: #1818498
",git fetch https://review.opendev.org/openstack/placement refs/changes/39/640939/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py']",3,d0bf7c34cc409eb17afada8ebadefcf98cae9bfd,bug/1818498," try: ins_stmt = _AGG_TBL.insert().values(uuid=agg_uuid) res = ctx.session.execute(ins_stmt) agg_id = res.inserted_primary_key[0] LOG.debug(""_ensure_aggregate() created new aggregate %s (id=%d)."", agg_uuid, agg_id) return agg_id except db_exc.DBDuplicateEntry: # Something else added this agg_uuid in between our initial # fetch above and when we tried flushing this session. LOG.debug(""_ensure_provider() failed to create new aggregate %s. "" ""Another thread already created an aggregate record. "", agg_uuid) raise # _ensure_aggregate() can raise DBDuplicateEntry. Then we must start a new # transaction because the new aggregate entry can be found by no means in # the old transaction if the isolation level is set to ""REPEATABLE_READ"" @oslo_db_api.wrap_db_retry( max_retries=10, inc_retry_interval=False, exception_checker=lambda exc: isinstance(exc, db_exc.DBDuplicateEntry))","@oslo_db_api.wrap_db_retry( max_retries=10, jitter=True, exception_checker=lambda exc: isinstance(exc, db_exc.DBDuplicateEntry)) ins_stmt = _AGG_TBL.insert().values(uuid=agg_uuid) res = ctx.session.execute(ins_stmt) agg_id = res.inserted_primary_key[0] LOG.debug(""_ensure_aggregate() created new aggregate %s (id=%d)."", agg_uuid, agg_id) return agg_id ",45,61
openstack%2Fplacement~master~Ia863977a154300ccf8da321c1828f83c951c9a19,openstack/placement,master,Ia863977a154300ccf8da321c1828f83c951c9a19,FUPs for improve-debug-log series,MERGED,2019-03-05 01:05:39.000000000,2019-03-05 17:50:19.000000000,2019-03-05 17:50:19.000000000,"[{'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2019-03-05 01:05:39.000000000', 'files': ['placement/objects/resource_provider.py', 'placement/tests/unit/objects/test_rp_candidates.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/0d0c47945713663a59e53a3b02b1d73f77c9a273', 'message': 'FUPs for improve-debug-log series\n\nThe following issues are addressed:\n\n - https://review.openstack.org/#/c/639888/3/placement/tests/unit/objects/test_rp_candidates.py@24\n - https://review.openstack.org/#/c/639888/3/placement/objects/resource_provider.py@3697\n\nChange-Id: Ia863977a154300ccf8da321c1828f83c951c9a19\n'}]",0,640909,0d0c47945713663a59e53a3b02b1d73f77c9a273,8,4,1,25625,,,0,"FUPs for improve-debug-log series

The following issues are addressed:

 - https://review.openstack.org/#/c/639888/3/placement/tests/unit/objects/test_rp_candidates.py@24
 - https://review.openstack.org/#/c/639888/3/placement/objects/resource_provider.py@3697

Change-Id: Ia863977a154300ccf8da321c1828f83c951c9a19
",git fetch https://review.opendev.org/openstack/placement refs/changes/09/640909/1 && git format-patch -1 --stdout FETCH_HEAD,"['placement/objects/resource_provider.py', 'placement/tests/unit/objects/test_rp_candidates.py']",2,0d0c47945713663a59e53a3b02b1d73f77c9a273,trivial," ('rp1', 'root1'), ('rp2', 'root1'), ('ss1', 'root1'), ('rp3', 'root'), ('ss1', 'root')]) ('ss1', 'root1', 'rc_1'), ('rp3', 'root', 'rc_1'), ('ss1', 'root', 'rc_1')]) expected_rps = set(['rp1', 'rp2', 'rp3', 'ss1']) ('ss1', 'root1', 'rc_1')]) self.rp_candidates.filter_by_rp(set([('ss1', 'root1')])) expected_rpsinfo = set([('ss1', 'root1', 'rc_1')]) self.rp_candidates.filter_by_rp_or_tree(set(['ss1', 'root1'])) # we get 'ss1' and rps under 'root1' expected_rpsinfo = set([('ss1', 'root', 'rc_1'), ('ss1', 'root1', 'rc_1'), ('rp1', 'root1', 'rc_1'), ('rp2', 'root1', 'rc_1')]) rps_rc2 = set([('rp1', 'root2'), ('rp4', 'root2'), ('ss1', 'root2'), ('rp5', 'root'), ('ss1', 'root')]) expected_rpsinfo = set([('rp3', 'root', 'rc_1'), ('rp5', 'root', 'rc_2'), ('ss1', 'root', 'rc_1'), ('ss1', 'root', 'rc_2')])"," ('rp1', 'root1'), ('rp2', 'root1'), ('rp3', 'root1'), ('rp1', 'root'), ('rp4', 'root')]) ('rp3', 'root1', 'rc_1'), ('rp1', 'root', 'rc_1'), ('rp4', 'root', 'rc_1')]) expected_rps = set(['rp1', 'rp2', 'rp3', 'rp4']) ('rp3', 'root1', 'rc_1')]) self.rp_candidates.filter_by_rp(set([('rp1', 'root1')])) expected_rpsinfo = set([('rp1', 'root1', 'rc_1')]) self.rp_candidates.filter_by_rp_or_tree(set(['rp1', 'root1'])) # we get 'rp1' and rps under 'root1' expected_rpsinfo = set([('rp1', 'root1', 'rc_1'), ('rp2', 'root1', 'rc_1'), ('rp3', 'root1', 'rc_1'), ('rp1', 'root', 'rc_1')]) rps_rc2 = set([('rp1', 'root2'), ('rp2', 'root2'), ('rp5', 'root2'), ('rp1', 'root'), ('rp6', 'root')]) expected_rpsinfo = set([('rp1', 'root', 'rc_1'), ('rp4', 'root', 'rc_1'), ('rp1', 'root', 'rc_2'), ('rp6', 'root', 'rc_2')])",22,22
openstack%2Fkeystone~master~I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad,openstack/keystone,master,I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad,Project Tags SQL Refactor,ABANDONED,2018-03-19 19:24:04.000000000,2019-03-05 17:49:24.000000000,,"[{'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23140}]","[{'number': 1, 'created': '2018-03-19 19:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/08a6a12b4d30c16d5a774a80d14171e95a94651a', 'message': 'Project Tags SQL Refactor\n\nSQl refactor to allow tags search a more\nuniform and expected result.\n\nCloses-Bug: #1756190\nPartially Implements: bp project-tags\n\nChange-Id: I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad\n'}, {'number': 2, 'created': '2018-03-19 19:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ff8737ffa062d096cd891ecf2615fbfb4f93080b', 'message': 'Project Tags SQL Refactor\n\nSQl refactor to allow tags search a more\nuniform and expected result.\n\nCloses-Bug: #1756190\nPartially Implements: bp project-tags\n\nChange-Id: I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad\n'}, {'number': 3, 'created': '2018-03-19 20:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/20bd3f1ccd348bed0dfe83ac673af6986d757286', 'message': 'Project Tags SQL Refactor\n\nSQl refactor to allow tags search a more\nuniform and expected result.\n\nCloses-Bug: #1756190\nPartially Implements: bp project-tags\n\nChange-Id: I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad\n'}, {'number': 4, 'created': '2018-03-31 00:12:24.000000000', 'files': ['keystone/resource/backends/sql.py', 'keystone/resource/core.py', 'keystone/resource/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f014d8f7995b052471d62a50d9136e32e80d4d00', 'message': 'Project Tags SQL Refactor\n\nSQl refactor to allow tags search a more\nuniform and expected result.\n\nCloses-Bug: #1756190\nPartially Implements: bp project-tags\n\nChange-Id: I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad\n'}]",9,554327,f014d8f7995b052471d62a50d9136e32e80d4d00,14,8,4,23625,,,0,"Project Tags SQL Refactor

SQl refactor to allow tags search a more
uniform and expected result.

Closes-Bug: #1756190
Partially Implements: bp project-tags

Change-Id: I766cc7a8a7ce2ca3c68d6b910445062675f3d7ad
",git fetch https://review.opendev.org/openstack/keystone refs/changes/27/554327/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_resource.py', 'keystone/resource/backends/sql.py']",2,08a6a12b4d30c16d5a774a80d14171e95a94651a,bug/1756190,"from sqlalchemy.orm import aliased def list_projects_by_tags(self, hints): pid_list = [] for tag_filter in hints.filters: if 'equals' not in tag_filter['comparator']: pass else: query = self._exact_filter(query, tag_filter) for pid in query: if pid.project_id not in pid_list: pid_list.append(pid.project_id) if pid_list == []: pquery = session.query(Project) pquery = pquery.filter(Project.id.in_(pid_list)) return [project_ref.to_dict() for project_ref in pquery.all() def _exact_filter(self, query, filters): tags = filters['value'].split(',') tag_alias = aliased(ProjectTag) subq = query.join(tag_alias, ProjectTag.project_id == tag_alias.project_id) if 'any' in filters['method']: subq = subq.filter(tag_alias.name.in_(tags)) else: # We build a JOIN ladder expression for each tag, JOIN'ing # the first tag to the instances table, and each subsequent # tag to the last JOIN'd tags table for tag in tags: tag_alias = aliased(ProjectTag) subq = subq.join(tag_alias, ProjectTag.project_id == tag_alias.project_id) subq = subq.filter(tag_alias.name == tag) if 'not' in filters['method']: not_list = [] for pid in subq: if pid['project_id'] not in not_list: not_list.append(pid['project_id']) if not_list == []: subq = query else: subq = query.filter(~ProjectTag.project_id.in_(not_list)) return subq"," def list_projects_by_tags(self, filters): filtered_ids = [] if 'tags' in filters.keys(): filtered_ids += self._filter_ids_by_sorted_tags( query, filters['tags'].split(',')) if 'tags-any' in filters.keys(): any_tags = filters['tags-any'].split(',') subq = query.filter(ProjectTag.name.in_(any_tags)) filtered_ids += [ptag['project_id'] for ptag in subq] if 'not-tags' in filters.keys(): blacklist_ids = self._filter_ids_by_sorted_tags( query, filters['not-tags'].split(',')) filtered_ids = self._filter_not_tags(session, filtered_ids, blacklist_ids) if 'not-tags-any' in filters.keys(): any_tags = filters['not-tags-any'].split(',') subq = query.filter(ProjectTag.name.in_(any_tags)) blacklist_ids = [ptag['project_id'] for ptag in subq] if 'not-tags' in filters.keys(): filtered_ids += blacklist_ids else: filtered_ids = self._filter_not_tags(session, filtered_ids, blacklist_ids) if not filtered_ids: query = session.query(Project) query = query.filter(Project.id.in_(filtered_ids)) return [project_ref.to_dict() for project_ref in query.all() def _filter_ids_by_sorted_tags(self, query, tags): filtered_ids = [] sorted_tags = sorted(tags) subq = query.filter(ProjectTag.name.in_(sorted_tags)) for ptag in subq: subq_tags = query.filter(ProjectTag.project_id == ptag['project_id']) result = map(lambda x: x['name'], subq_tags.all()) if sorted(result) == sorted_tags: filtered_ids.append(ptag['project_id']) return filtered_ids def _filter_not_tags(self, session, filtered_ids, blacklist_ids): subq = session.query(Project) valid_ids = [q['id'] for q in subq if q['id'] not in blacklist_ids] if filtered_ids: valid_ids = list(set(valid_ids) & set(filtered_ids)) return valid_ids",77,78
openstack%2Fkeystone~master~I89148194b7f51be429cb77580872dc4b5d779b5e,openstack/keystone,master,I89148194b7f51be429cb77580872dc4b5d779b5e,Added versions to keystone headers,ABANDONED,2017-05-25 22:40:08.000000000,2019-03-05 17:49:11.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 10608}, {'_account_id': 16465}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 23625}, {'_account_id': 23659}, {'_account_id': 23674}]","[{'number': 1, 'created': '2017-05-25 22:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1852ca69cee2f9ad4a9b461448470e7d6376908e', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 2, 'created': '2017-06-02 20:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7922975cbf96400c01555c2cadd11b0413d8ce71', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 3, 'created': '2017-06-05 18:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/90c24003d870cfa83a31991c6b764f6b1d04e544', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 4, 'created': '2017-06-06 21:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/16fc024ed982301cc69052a0eb21689e0f5067d9', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 5, 'created': '2017-06-07 23:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ed11b378caf7d3dad57d86403139cd7775c57a75', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 6, 'created': '2017-06-09 15:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c0f80f78744155d72d1b804ed8adcea9d00b18b', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 7, 'created': '2017-06-09 17:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/048fe942d36f2419d1ecc581527e372b6db0d820', 'message': 'Added versions to keyston headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 8, 'created': '2017-06-13 20:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c864bcc1ce405147604eccc6332e31044c3e80cf', 'message': 'WIP - Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\n'}, {'number': 9, 'created': '2017-06-20 21:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/44d128005b757af831c0675156052a7788fcd462', 'message': 'WIP - Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored By: Rohan Arora <ra271w@att.com>\n'}, {'number': 10, 'created': '2017-06-21 13:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dffa28e2aed4bbb50682a240241e06e4024e5462', 'message': 'WIP - Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored-By: Rohan Arora <ra271w@att.com>\n'}, {'number': 11, 'created': '2017-06-21 16:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23723c83254ab2238fde7ae7afc83919fc10e1c5', 'message': 'WIP - Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored-By: Rohan Arora <ra271w@att.com>\n'}, {'number': 12, 'created': '2017-06-30 20:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/04135d62299013146c324e064c4dbf0948291874', 'message': 'WIP - Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored-By: Rohan Arora <ra271w@att.com>\n'}, {'number': 13, 'created': '2017-07-03 12:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5c56dd7f05accb7862ff0ea0e1f41f9d3420f409', 'message': 'WIP - Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored-By: Rohan Arora <ra271w@att.com>\n'}, {'number': 14, 'created': '2017-08-02 14:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e4342171921be823d9aa7d01819d3a1ff447fedd', 'message': 'Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored-By: Rohan Arora <ra271w@att.com>\n'}, {'number': 15, 'created': '2017-08-04 15:10:14.000000000', 'files': ['keystone/version/controllers.py', 'keystone/conf/__init__.py', 'keystone/common/api_version_request.py', 'keystone/tests/unit/test_wsgi.py', 'keystone/tests/unit/test_versions.py', 'keystone/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0bf941bc293e77c3f08f8f228e18ffeaf6785264', 'message': 'Added versions to keystone headers\n\nThis adds the version of some endpoints into the header\nof keystone api requests\n\nChange-Id: I89148194b7f51be429cb77580872dc4b5d779b5e\nPartial-Bug: #1689644\nCo-Authored-By: Rohan Arora <ra271w@att.com>\n'}]",52,468189,0bf941bc293e77c3f08f8f228e18ffeaf6785264,59,11,15,23625,,,0,"Added versions to keystone headers

This adds the version of some endpoints into the header
of keystone api requests

Change-Id: I89148194b7f51be429cb77580872dc4b5d779b5e
Partial-Bug: #1689644
Co-Authored-By: Rohan Arora <ra271w@att.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/89/468189/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/api_version_request.py', 'keystone/common/wsgi.py']",2,1852ca69cee2f9ad4a9b461448470e7d6376908e,bug/1689644,"from keystone.common import api_version_request req_uri = req.context_dict['environment']['REQUEST_URI'] version = set_api_version_request(self, req_uri) user_locale=best_match_language(req), ex_version=version) user_locale=best_match_language(req), ex_version=version) user_locale=best_match_language(req), ex_version=version) user_locale=best_match_language(req), ex_version=version) http_client.responses[http_client.NO_CONTENT]), version=version) method=req.method, version=version)def set_api_version_request(self, url): """"""Find api request version. Return with current or depricated status. """""" version = None if 'v3' in url: url_string_list = url.split(""/"") for route in url_string_list: if 'v3' in route: version = api_version_request. \ APIVersionRequest().get_version(route) else: if 'v2' in url: version = api_version_request.APIVersionRequest().get_version('v2') elif 'v1' in url: version = api_version_request.APIVersionRequest().get_version('v1') else: version = None return version def render_response(body=None, status=None, headers=None, method=None, version=None): if version: headers.append(('API_VERSION_REQUEST_HEADER', version)) def render_exception(error, context=None, request=None, user_locale=None, ex_version=None): headers=headers, version=ex_version)"," user_locale=best_match_language(req)) user_locale=best_match_language(req)) user_locale=best_match_language(req)) user_locale=best_match_language(req)) http_client.responses[http_client.NO_CONTENT])) method=req.method)def render_response(body=None, status=None, headers=None, method=None):def render_exception(error, context=None, request=None, user_locale=None): headers=headers)",115,9
openstack%2Frequirements~master~I80a3f4cab1e841592aee2d7f4a30a5b978132054,openstack/requirements,master,I80a3f4cab1e841592aee2d7f4a30a5b978132054,update constraint for python-swiftclient to new release 3.7.0,MERGED,2019-03-05 13:15:53.000000000,2019-03-05 17:35:45.000000000,2019-03-05 17:35:45.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 13:15:53.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/deb35373952318e2f87501d107b5279148788f74', 'message': 'update constraint for python-swiftclient to new release 3.7.0\n\nChange-Id: I80a3f4cab1e841592aee2d7f4a30a5b978132054\nmeta:version: 3.7.0\nmeta:diff-start: -\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: John Dickinson <me@not.mn>\nmeta:release:Commit: John Dickinson <me@not.mn>\nmeta:release:Change-Id: If72394636fec238cc597386a067b83be9f81b9f2\nmeta:release:Code-Review+2: Jean-Philippe Evrard <jean-philippe@evrard.me>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,641010,deb35373952318e2f87501d107b5279148788f74,6,2,1,11131,,,0,"update constraint for python-swiftclient to new release 3.7.0

Change-Id: I80a3f4cab1e841592aee2d7f4a30a5b978132054
meta:version: 3.7.0
meta:diff-start: -
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: yes
meta:release:Author: John Dickinson <me@not.mn>
meta:release:Commit: John Dickinson <me@not.mn>
meta:release:Change-Id: If72394636fec238cc597386a067b83be9f81b9f2
meta:release:Code-Review+2: Jean-Philippe Evrard <jean-philippe@evrard.me>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/10/641010/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,deb35373952318e2f87501d107b5279148788f74,new-release,python-swiftclient===3.7.0,python-swiftclient===3.6.0,1,1
openstack%2Ftripleo-validations~master~I586e5a2db334b61f6ecd99b08070db7a235c1e9e,openstack/tripleo-validations,master,I586e5a2db334b61f6ecd99b08070db7a235c1e9e,Add lookup_plugins into validation-lib-utils role,ABANDONED,2019-03-04 12:40:13.000000000,2019-03-05 17:25:57.000000000,,"[{'_account_id': 17888}, {'_account_id': 22348}, {'_account_id': 26343}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-03-04 12:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/15c0437093bae759facb7d6a8addc14e26d13346', 'message': 'Add lookup_plugins into validation-lib-utils role\n\nChange-Id: I586e5a2db334b61f6ecd99b08070db7a235c1e9e\nImplements: blueprint validation-framework\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2019-03-05 15:06:33.000000000', 'files': ['roles/validation-lib-utils/lookup_plugins/nova_flavors.py', 'roles/validation-lib-utils/lookup_plugins/tht.py', 'roles/validation-lib-utils/lookup_plugins/nova_hypervisor_statistics.py', 'roles/validation-lib-utils/lookup_plugins/glance_images.py', 'roles/validation-lib-utils/lookup_plugins/introspection_data.py', 'roles/validation-lib-utils/lookup_plugins/nova_servers.py', 'roles/validation-lib-utils/lookup_plugins/roles_info.py', 'roles/validation-lib-utils/lookup_plugins/ironic_nodes.py', 'roles/validation-lib-utils/lookup_plugins/stack_resources.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/e42d75c7f003dfe9b4e563eaeeb865b8b660fc54', 'message': 'Add lookup_plugins into validation-lib-utils role\n\nChange-Id: I586e5a2db334b61f6ecd99b08070db7a235c1e9e\nImplements: blueprint validation-framework\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}]",0,640752,e42d75c7f003dfe9b4e563eaeeb865b8b660fc54,6,4,2,11491,,,0,"Add lookup_plugins into validation-lib-utils role

Change-Id: I586e5a2db334b61f6ecd99b08070db7a235c1e9e
Implements: blueprint validation-framework
Signed-off-by: Gael Chamoulaud <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/52/640752/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/validation-lib-utils/lookup_plugins/nova_flavors.py', 'roles/validation-lib-utils/lookup_plugins/tht.py', 'roles/validation-lib-utils/lookup_plugins/glance_images.py', 'roles/validation-lib-utils/lookup_plugins/introspection_data.py', 'roles/validation-lib-utils/lookup_plugins/nova_hypervisor_statistics.py', 'roles/validation-lib-utils/lookup_plugins/nova_servers.py', 'roles/validation-lib-utils/lookup_plugins/roles_info.py', 'roles/validation-lib-utils/lookup_plugins/ironic_nodes.py', 'roles/validation-lib-utils/lookup_plugins/stack_resources.py']",9,15c0437093bae759facb7d6a8addc14e26d13346,bp/validation-framework,"#!/usr/bin/env python # Copyright 2017 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from ansible.plugins.lookup import LookupBase from tripleo_validations import utils class LookupModule(LookupBase): def run(self, terms, variables=None, **kwargs): """"""Returns the current plan's stack resources. :return: A list of dicts """""" ret = [] heat = utils.get_heat_client(variables) resource_list = heat.resources.list(variables['plan']) for resource in resource_list: ret.append(dict( resource_name=resource.resource_name, resource_status=resource.resource_status, logical_resource_id=resource.logical_resource_id, links=resource.links, creation_time=resource.creation_time, resource_status_reason=resource.resource_status_reason, updated_time=resource.updated_time, required_by=resource.required_by, physical_resource_id=resource.physical_resource_id, resource_type=resource.resource_type )) return ret ",,609,0
openstack%2Fkeystone-specs~master~I0bd99d24517b90f16557aadc3d721ecee9cd8eb5,openstack/keystone-specs,master,I0bd99d24517b90f16557aadc3d721ecee9cd8eb5,Update app cred capabilities spec,MERGED,2019-02-25 19:30:28.000000000,2019-03-05 16:57:29.000000000,2019-03-05 16:57:29.000000000,"[{'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 19:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f57ad7e7dcb6fbc8b9ad55a1cf875c3bbfb011dc', 'message': 'Update app cred capabilities spec\n\nThis change brings the spec which was agreed upon nearly a year ago,\ninto alignment with the current proposed implementation.\n\nChange-Id: I0bd99d24517b90f16557aadc3d721ecee9cd8eb5\n'}, {'number': 2, 'created': '2019-02-25 19:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/b8691c10eadac3ce0df3fe167e8e6783259adf7d', 'message': 'Update app cred capabilities spec\n\nThis change brings the spec, which was agreed upon nearly a year ago,\ninto alignment with the current proposed implementation. It also cleans\nup some formatting and style issues.\n\nChange-Id: I0bd99d24517b90f16557aadc3d721ecee9cd8eb5\n'}, {'number': 3, 'created': '2019-02-26 09:00:00.000000000', 'files': ['specs/keystone/stein/capabilities-app-creds.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/c83ae97852002a6f91b5bb18e0b85a4c47e81578', 'message': 'Update app cred capabilities spec\n\nThis change brings the spec, which was agreed upon nearly a year ago,\ninto alignment with the current proposed implementation. It also cleans\nup some formatting and style issues.\n\nChange-Id: I0bd99d24517b90f16557aadc3d721ecee9cd8eb5\n'}]",9,639182,c83ae97852002a6f91b5bb18e0b85a4c47e81578,17,5,3,8482,,,0,"Update app cred capabilities spec

This change brings the spec, which was agreed upon nearly a year ago,
into alignment with the current proposed implementation. It also cleans
up some formatting and style issues.

Change-Id: I0bd99d24517b90f16557aadc3d721ecee9cd8eb5
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/82/639182/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/keystone/stein/capabilities-app-creds.rst'],1,f57ad7e7dcb6fbc8b9ad55a1cf875c3bbfb011dc,bp/whitelist-extension-for-app-creds,"style list of access rules for an application credential which other OpenStack already. from inside a cluster's instances where the container orchestration engine requires it (e.g. Glance as backend for docker-registry or cinder as backend for docker-volume)1) Alongside an application credential, a list of access rules with zero or more access rules can be stored. An entry in this list consists of: (a) A URL path (e.g. `/v2.1/servers`, `/v2.1/servers/*` or `/v2.1/servers/{server_id}`). This URL path must be explicitly permitted according to an operator-configured list of access rules (see `Access Rules Config`_ below). (b) A request method (e.g. `GET`) (c) A service type (ideally matching the `published Service Types Authority`_) from the Keystone service catalog. This list is a whitelist, i.e. any request not explicitly allowed by an access rule is rejected. Keystone itself does not validate the content of access rules because that would require domain knowledge of each service in the catalog. Every access rule must match a permitted access rule as described in the `Access Rules Config`_ section below. If one or more access rule entries fail this test, application credential creation will fail. 2) A future iteration of this feature will create a toggle to control whether a service can use one of these token to make background requests on behalf of the user, for example to allow the compute service to make requests to the block storage service even though the block storage API wasn't explicitly whitelisted in the application credential access rules. For the time being, chained service requests like this will be unrestricted and will rely on operator-configured policies to prevent abuse. 3) `keystonemiddleware` on the service's side receives the access rule list during token validation. It then checks (a) The service type (e.g. `compute`) (b) The URL path (e.g. `/v2.1/servers/*` or or `/v2.1/servers/{server_id}` or `/v2.1/servers/b2088298-50e5-4c81-8a50-66bfd1d8943b`) (c) The request method (e.g. `GET`) Against every entry in the access rule list retrieved from the token. If an access rule matches the request, checking stops and the request is handed over to `oslo.policy` for the regular role based checking. If no access rules match, the request is rejected right away. There are three special cases to access rule list processing: (a) If no list is provided (i.e. if the `access_rules` attribute is `None`), no access rule checking is performed and the request is passed to `oslo.policy` right away. (b) If an empty list is provided (i.e. `[]`), all requests are rejected (even if the request would otherwise pass the test in (c). (c) If there is a valid service token in the request, `keystonemiddleware` passes the request to `oslo.policy` right away, though a future iteration of this feature will enable a toggle to control this behavior. .. _published Service Types Authority: https://service-types.openstack.org/ Access Rules Config ------------------- Every access rule must be validated against an operator-configured list upon application credential upon creation, unless the operator has explicitly configured a permissive mode that does no validation. This section describes how an operator defines a list and how they are used by Keystone. The allowed access rules are operator configured as a JSON config file on disk, with the idea that perhaps such a catalog might be exposed on service endpoints someday. Keystone will document a curated list of URL templates for those APIs where such a thing can be generated automatically. The operator can then use this list as-is in the simplest case, or modify it for their local setup as they chose. For every access rule the following information is stored: 1) A service type that matches one of the services in the Keystone catalog. 2) A URL path pattern, such as `/v2.1/servers/{server_id}`. The combination of this string and the service type from (1) must be unique. It is anchored at the beginning of a path, i.e. access rules' path attributes must fully match * `{named_variable}`: allows arbitrary strings (excluding the `/` character). Named placeholders in the access rule path pattern are there for readability and direct comparison to API references and policy files, they do not correlate to string formatting substitutions. * `*`: allows arbitrary strings (excluding the `/` character) * `**`: allows arbitrary strings (including the `/` character) A user using a path pattern containing wild cards for validating one of their access rules may substitute the wild card by any string fulfilling the permissive in their URL templates (to the point of only having one ""**"" wild card template in their access rules.Keystone would provide the access rule list upon token validation, the othercredentials with access rules (i.e. a `access_rules` attribute that is not application that supports access rule enforcement) sets an `Openstack-Identity-Access-Rules` header with a version string as its value. Token validation for an application credential with a access rule list will2) If there is no `Openstack-Identity-Access-Rules` header in the tokenThis way we ensure that nobody erroneously assumes access rules are beingany application credentials that do not have access rules, validation proceeds as it would have before the introduction of access rules (regardless of whether there is an `Openstack-Identity-Access-Rules` or not). Discoverability for Access Rules Config --------------------------------------- Any user with a valid auth token can list the operator maintained access rules through the Keystone API:: GET /v3/access_rules_config .. code-block:: json { ""compute"": [ ""path"": ""/v2.1/servers"", ""method"": ""GET"" ] } This allows them to discover the URL path templates they can use for creating access rules in application credentials. Access Rules and Roles ---------------------- Configured access rules will have an optional ROLE_ID value. If this value is set, it indicates the role that the user needs to provide in the applicationis set, the user will only be able to use the access rule if the user has that role assigned, either directly, or as a result of an implied role.One thing the access rules make rather tough is chained API calls: if an API call is permitted by an access rule, but the service uses the same access rulebe possible to circumvent this problem with additional access rules to coverA future optimization of this feature will implement a toggle for access rules to give services blanket permission to perform chained API calls with the token resulting from the Application credential. This is implemented as follows: application credential with this toggle set, it requests a service token and adds it to the request's object's headers. with this toggle plus a valid service token it will ignore any non-empty access rulelists and pass the request to the service as-is. ""access_rules"": [ ""method"": ""POST"" ""method"": ""POST"" (a) Application credential access rules do not require a `Cambrian (b) Application credential access rules does not require any changes to create new ones"". Application credential access rules on the other (d) Application credential access rules do not require keystone to be the (e) Unlike a policy based check, an access rule based check will also work rather than URL paths in the access rules, which would have been easier in easily change over time, thus breaking existing access rules.* URLs in access rules are user-supplied strings. Care must be taken to* It might be a good idea to limit the length/number of acces rules per of non-matching access rules, which can be used to slow down a particularmitigated by limiting the number of access rules allowed per applicationbackwards compatible, since specifying access rules when creating an application credential is optional: if none are specified, the `access_rules` attribute will be `None`, leading to no access rule checks being performed. * Colleen Murphy <colleen@gazlene.net> cmurphy * Johannes Grassler <jgr-launchpad@btw23.de> jgr-launchpad allow for receiving and storing access rule lists. 2. Implement handling for access rules in python-keystoneclient and3. Extend the Keystone token validation API to access rule lists upon* The access rule related settings for application credentials need to be* Documentation on access rules needs to be added to the *Application having access rules in application credentials) * Related concept for Istio: https://istio.io/docs/reference/config/authorization/istio.rbac.v1alpha1/#AccessRule","style list of capabilities for an application credential which other OpenStack already. from inside a cluster's instances where the container orchestration engine requires it (e.g. Glance as backend for docker-registry or cinder as backend for docker-volume)1) Alongside an application credential, a capability list with zero or more capabilities can be stored. An entry in this list consists of: (a) A URL path (e.g. `/v2.1/servers` or `/v2.1/servers/{server_id}`). This URL path must be permissible according to a URL path template which must exist in the table of URL path templates (see `Permissible Path Templates`_ below). (b) A dictionary whose keys need to exactly match the placeholders in the URL path. Both extraneous and missing keys for one or more capabilities will cause application credential creation to fail. (c) A request type (e.g. `GET`) (d) A service UUID from the Keystone service catalog. This UUID is not user provided. Instead, it is filled in from the URL template this capability is validated against. This list is a whitelist, e.g. any request not explicitly allowed by a capability is rejected. Keystone itself does not validate the content of capabilities because that would require domain knowledge of each service on Keystone's path. Every capability must reference an row in the table described in the `Permissible Path Templates`_ section below. If one or more capabilities entries fail this test, API Credential creation will fail. 2) A boolean `allow_chained` attribute of the application credential (`False` by default) controls whether chained API calls, i.e. follow-up calls issued by a service as a result of an API call permitted by a capability. This may only be set to `True` if all capabilities listed in the template were validated against an URL template with its own `allow_chained` attribute set to `True`. 3) `keystonemiddleware` on the service's side receives the capability list during token validation. It then performs templating on all entries and checks (a) The service's own service ID (e.g. `ae8a69ae-3bc2-4189-88be-c0b9ea6ef06f`) (b) The URL path (e.g. `/v2.1/servers/{*}` or `/v2.1/servers/b2088298-50e5-4c81-8a50-66bfd1d8943b`) (c) The request's type (e.g. `GET`) Against every entry in the templated URL list computed from the capability information in the token (See `URL Path Templating`_ for how it is computed). If a capability matches the request, checking stops and the request is handed over to `oslo.policy` for the regular role based checking. If no capabilities match, the request is rejected right away. There are three special cases to capability list processing: (a) If no list is provided (i.e. if the `capabilities` attribute is `None`), no capability checking is performed and the request is passed to `oslo.policy` right away. (b) If an empty list is provided (i.e. `[]`), all requests are rejected (even if the request would otherwise pass the test in (c). (c) If the application credential's `allow_chained` attribute is `True` and there is a valid service token in the request, `keystonemiddleware` passes the request to `oslo.policy` right away. Permissible Path Templates -------------------------- Every capability must be validated against a URL Path Template referenced by UUID upon application credential upon creation. This section describes how an operator defines such URL path templates and how they are used by Keystone. The permissible URL path templates are operator configured through the Keystone API and stored in a dedicated table in the Keystone database. Keystone will document a curated list of URL templates for those APIs where such a thing can be generated automatically. The operator can then use this list as-is in the simplest case, or modify it for their local setup as they chose. For every URL template the following information is stored: 1) A service UUID that matches one of the services in the Keystone catalog. This is copied to the capability verbatim. The service UUID is validated upon URL template creation: it must match an existing service's UUID. This UUID should not have a foreign key constraint so as not to create dependencies from the catalog on URL templates or the capabilities validated against them. If a service is deleted later, and a non-existent UUID is thus being referenced, keystonemiddleware will reject any capabilities referencing it since there is no service whose service UUID will match it at that point. 2) A UUID that serves as a unique resource identifier. This is used to reference the path template to use for evaluation when creating a capability. This reference is only used for validation upon application credential creation and not recorded as part of the application credential. 3) A URL template string, such as `/v2.1/servers/{server_id}`. The combination of this string and the service ID from (1) must be unique. It is anchored at the beginning of a path, i.e. capabilities' path attributes must fully match * `{*}`: allows arbitrary strings (excluding the `/` character) in capability enforcement. * `{**}`: allows arbitrary strings (including the `/` character) in capability enforcement. A user using a URL template containing wild cards for validating one of their capabilities may substitute the wild card by any string fulfilling the permissive in their URL templates (to the point of only having one ""{**}"" wild card template in their capabilities. 4) A boolean `allow_chained` attribute (`False` by default). If this is `True` for all URL templates referenced when creating an application credential, that application credential's own `allow_chained` attribute may be set to `True`. 5) A list of template keys to be provided by the user (henceforth referred to as ""user template keys""). 6) A list of template keys to be provided from token context. (henceforth referred to as ""context template keys""). The following are available: * `domain_id` UUID of the domain the Application Credential is scoped to (where applicable) * `project_id` UUID of the project the Application Credential is scoped to (where applicable) * `user_id` UUID of the user who created the Application Credential Between (4) and (5) all template keys in the URL template string must be covered. If this condition is not met, creation of the path template fails. URL Path Templating ------------------- `keystonemiddleware` receives the capability list information upon token validation. It then processes each capability as follows: 1) All placeholders from the user template keys list are replaced by the corresponding values in the user provided dictionary of values in the capability. 2) All placeholders from the context template keys list are replaced by the corresponding values from token context. 3) Wild card placeholders (`{*}`) are left in place. These will be used during capability enforcement to match any string in the respective path component.Keystone would provide the capability list upon token validation, the othercredentials with capabilities (i.e. a `capabilities` attribute that is not application that supports capability enforcement) sets an `Openstack-Identity-Capabilities` header with a version string as its value. Token validation for an application credential with a capability list will2) If there is no `Openstack-Identity-Capabilities` header in the tokenThis way we ensure that nobody erroneously assumes capabilities are beingany application credentials that do not have capabilities, validation proceeds as it would have before the introduction of capabilities (regardless of whether there is an `Openstack-Identity-Capabilities` or not). Discoverability for URL Path Templates -------------------------------------- Any user with a valid auth token can list the operator maintained URL path templates through the Keystone API. This allows them to discover the URL path templates they can use for creating capability enabled application credentials. URL Templates and Roles ----------------------- URL path templates will have an optional ROLE_ID value. If this value is set, it indicates the role that the user needs to provide in the applicationis set, the user will only be able to use the URL value in a capability if the user has that role assigned, either directly, or as a result of an implied role.One thing the capabilities make rather tough is chained API calls: if an API call is permitted by a capability, but the service uses the same capabilitybe possible to circumvent this problem with additional capabilities to coverTo make it easier on users and services, the `allow_chained` attribute gives services blanket permission to perform chained API calls with the token resulting from the Application credential. This is implemented as follows: application credential with the `allow_chained` attribute set, it requests a service token and adds it to the request's object's headers. Keystone only allows setting this `allow_chained` attribute for an application credential all capabilities' underlying URL templates have the `allow_chained` attribute set to `True`. with `allow_chained` plus a valid service token it will ignore any non-empty capability lists and pass the request to the service as-is. ""allow_chained"": false, ""capabilities"": [ ""substitutions"": {}, ""type"": ""POST"", ""url_template"": ""376a83c4-c6e9-4cdf-b413-ba4880bfda4d"" ""substitutions"": {}, ""type"": ""POST"", ""url_template"": ""c73beef3-c982-4ed8-86d5-dd362af48614""An example creation request (issued by an operator) for a URL template might look as follows: :: POST /v3/capability-templates .. code-block:: json { ""capability_template"": { ""allow_chained"": true, ""role_id"": ""0dbbcb80-9d70-4c86-b38a-ae826e501885"", ""path"": ""/v2.1/servers/**"", ""substitutions"": {}, ""service"": ""67764758-3bdb-462e-babf-537c8fbe7bcd"", ""type"": ""GET"" } } Any user may discover the current list of URL through a :: GET /v3/capability-templates In response they will get a list of URL templates: .. code-block:: json [ { ""capability_template"": { ""id"": ""5631dd39-1451-4101-a961-bbc949624b2f"", ""allow_chained"": true, ""role_id"": ""0dbbcb80-9d70-4c86-b38a-ae826e501885"", ""path"": ""/v2.1/servers/**"", ""substitutions"": {}, ""service"": ""67764758-3bdb-462e-babf-537c8fbe7bcd"", ""type"": ""GET"" } }, { ""capability_template"": { ""id"": ""cdfeecfb-752a-4370-9aaf-03751d3645b3"", ""allow_chained"": false, ""role_id"": null, ""path"": ""/v2.1/servers/a13b634a-dde3-4e5d-bbcb-3c1482bcf6c8"", ""substitutions"": {}, ""service"": ""67764758-3bdb-462e-babf-537c8fbe7bcd"", ""type"": ""POST"" } }, { ""capability_template"": { ""id"": ""e86584c8-1a1a-4f5d-9da9-da5e265a0423"", ""allow_chained"": false, ""role_id"": null, ""path"": ""/v2.0/metrics"", ""substitutions"": {}, ""service"": ""1a5e983d-7ac2-4b27-a7a1-caa62a46d82a"", ""type"": ""POST"" } }, { ""capability_template"": { ""id"": ""8458c208-6a91-4f54-af89-4598b972cd52"", ""allow_chained"": false, ""role_id"": null, ""path"": ""/v3.0/logs"", ""substitutions"": {}, ""service"": ""f6bd818d-861f-450b-a523-2e1546a06a18"", ""type"": ""POST"" } } ] (a) Application credential capabilities do not require a `Cambrian (b) Application credential capabilities does not require any changes to create new ones"". Application credential capabilities on the other (d) Application credential capabilities do not require keystone to be the (e) Unlike a policy based check, a capability based check will also work rather than URL paths in the capabilities, which would have been easier in easily change over time, thus breaking existing capabilities.* URLs in capabilities are user-supplied strings. Care must be taken to* It might be a good idea to limit the length/number of capability rules per of non-matching capabilities, which can be used to slow down a particularmitigated by limiting the number of capabilities allowed per applicationOther Deployer Impact --------------------- This change will introduce the following settings for Keystone: * `[application_credential]/soft_capability_quota` [Default: `5`] This setting determines the number of entries allowed in newly created capability lists globally. `-1` denotes an unlimited number of entries. Any existing application credentials with more capabilities will continue to work. * `[application_credential]/hard_capability_quota` [Default: `-1`] This setting determines the number of entries allowed in capability lists globally. `-1` denotes an unlimited number of entries. Any existing application credentials with more capabilities will fail token validation. backwards compatible, since specifying capabilities when creating an application credential is optional: if none are specified, the `capabilities` attribute will be `None`, leading to no capability checks being performed. * Johannes Grassler <jgr-launchpad@btw23.de> jgr-launchpad * Colleen Murphy <colleen@gazlene.net> cmurphy allow for receiving and storing capability lists. 2. Implement handling for capabilities in python-keystoneclient and3. Extend the Keystone token validation API to capability lists upon* The capability related settings for application credentials need to be* The URL template ""language"" outlined in the `Permissible Path Templates`_ section needs to be documented in the Keystone admin guide. * Documentation on capabilities needs to be added to the *Application having capabilities in application credentials)",152,280
openstack%2Fcinder~master~I94f14ffafb086a1d637bfcbb08e3ea7200e17121,openstack/cinder,master,I94f14ffafb086a1d637bfcbb08e3ea7200e17121,Add policy test for volume create policy,MERGED,2018-11-13 09:38:23.000000000,2019-03-05 16:45:43.000000000,2019-01-09 02:34:33.000000000,"[{'_account_id': 1736}, {'_account_id': 5046}, {'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15054}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 20722}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29716}]","[{'number': 1, 'created': '2018-11-13 09:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30776017f6542b149a6a046e31c457802fe7113b', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the serious patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 2, 'created': '2018-11-14 06:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d05e6d422987e3e6937b121e3ff67923b2d78e34', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 3, 'created': '2018-12-05 08:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6107adf6257b5a3b3ae7b788c39eaa267d64113e', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 4, 'created': '2018-12-06 01:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/601c5fe109b5e820acd6b062ccd61b26eb14acbe', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 5, 'created': '2018-12-10 01:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a720acc281a8e3273e10776a63e386fbed016f7', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 6, 'created': '2018-12-13 12:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/394c1364f3422a012c7398f9a633e4e3444aaebe', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 7, 'created': '2018-12-13 12:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/284e92ea3b870a972fb306cfaddb4cdad6377bb6', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 8, 'created': '2018-12-14 01:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e304da64186c7b5bd0767d8d8bed74a8eb049f8a', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 9, 'created': '2018-12-14 02:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1dba8634c7c7fcfd4df841df6951a3a63f342e07', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 10, 'created': '2018-12-14 02:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22d02af9ebfd2126a7e31638ee3614b3aedb5ab2', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}, {'number': 11, 'created': '2018-12-20 03:12:49.000000000', 'files': ['cinder/tests/unit/policy.json', 'cinder/tests/unit/api/v3/test_volume_protection.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8dfec08fd106419ba7ab08c73c45ddb505df1397', 'message': 'Add policy test for volume create policy\n\nAdd policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and\nremove them from test policy file.\n\nThis is one of the series patches of policy-in-code test, see\nmore information on [1] and [2].\n\n[1] 530fb9319ce21b7ff99e55f095c04f13f0785842\n[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e\n\nChange-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121\n'}]",21,617542,8dfec08fd106419ba7ab08c73c45ddb505df1397,292,43,11,20722,,,0,"Add policy test for volume create policy

Add policy test for CREATE_POLICY, CREATE_FROM_IMAGE_POLICY, and
remove them from test policy file.

This is one of the series patches of policy-in-code test, see
more information on [1] and [2].

[1] 530fb9319ce21b7ff99e55f095c04f13f0785842
[2] f207bac80924ffaf6d4c2a500c295d0e2e71966e

Change-Id: I94f14ffafb086a1d637bfcbb08e3ea7200e17121
",git fetch https://review.opendev.org/openstack/cinder refs/changes/42/617542/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/policy.json', 'cinder/tests/unit/api/v3/test_volume_protection.py']",2,30776017f6542b149a6a046e31c457802fe7113b,policy_in_code_test,"from cinder.tests.unit.image import fake as fake_image fake_image.mock_image_service(self) def test_everyone_can_create_volume(self): # Make sure normal user is authorized to force delete volumes user_context = self.user_context path = '/v3/%(project_id)s/volumes' % { 'project_id': user_context.project_id } body = {""volume"": {""size"": 1}} response = self._get_request_response(user_context, path, 'POST', body=body) self.assertEqual(http_client.ACCEPTED, response.status_int) def test_everyone_can_create_volume_from_image(self): # Make sure normal user is authorized to force delete volumes user_context = self.user_context path = '/v3/%(project_id)s/volumes' % { 'project_id': user_context.project_id } body = {""volume"": {""size"": 1, ""image_id"": fake_constants.IMAGE_ID}} response = self._get_request_response(user_context, path, 'POST', body=body) self.assertEqual(http_client.ACCEPTED, response.status_int)",,28,2
openstack%2Fpython-tripleoclient~master~Ib86005596e046587a4608a755a15ce8620105f8b,openstack/python-tripleoclient,master,Ib86005596e046587a4608a755a15ce8620105f8b,Add new CLI option openstack tripleo validate run,MERGED,2019-02-14 11:36:34.000000000,2019-03-05 16:45:21.000000000,2019-03-05 16:45:21.000000000,"[{'_account_id': 3153}, {'_account_id': 7509}, {'_account_id': 10112}, {'_account_id': 11082}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 17888}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-02-14 11:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/13e2437106b3edd0d2321eaaacb8cacbbac0498f', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 2, 'created': '2019-02-15 09:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/eeedef70e09eb80d534cff44ce12d7145877f17b', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 3, 'created': '2019-02-19 09:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/326521ffa86354922aed10b2c8cb1effa20c563a', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 4, 'created': '2019-02-19 10:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/03445990ececb57eb8757ff86e0818cadecca1b1', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 5, 'created': '2019-02-21 14:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0c092df92a1ae67ad262a525edd64a947f02cb68', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 6, 'created': '2019-02-22 14:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f277d2ee0e4d3e686f078df88f0d089a5625278f', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 7, 'created': '2019-02-27 08:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9f703d175a6e1589c816c2ff85d9467d7f72aac9', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 8, 'created': '2019-03-05 08:28:36.000000000', 'files': ['tripleoclient/workflows/validations.py', 'tripleoclient/v1/tripleo_validator.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b3af96f74e871765de5cd20437ea464c1ce0ce7f', 'message': 'Add new CLI option openstack tripleo validate run\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the running of all current installed validations\nbased on group validations or single validations.\n\nChange-Id: Ib86005596e046587a4608a755a15ce8620105f8b\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}]",8,636930,b3af96f74e871765de5cd20437ea464c1ce0ce7f,51,12,8,20775,,,0,"Add new CLI option openstack tripleo validate run

This submission starts with the integration of the current supported
Mistral workflows for running the validations.

This submission integrates the running of all current installed validations
based on group validations or single validations.

Change-Id: Ib86005596e046587a4608a755a15ce8620105f8b
Implements: blueprint validation-framework
Depends-On: I294ab0016fda9587b405ef08dba3212b8e46a816
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/30/636930/8 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/validations.py', 'tripleoclient/v1/tripleo_validator.py', 'setup.cfg']",3,13e2437106b3edd0d2321eaaacb8cacbbac0498f,bp/validation-framework, tripleo_validator_run = tripleoclient.v1.tripleo_validator:TripleOValidatorRun,,109,0
openstack%2Fpython-tripleoclient~master~Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6,openstack/python-tripleoclient,master,Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6,Add new CLI option openstack tripleo validate list,MERGED,2019-02-13 10:01:28.000000000,2019-03-05 16:45:20.000000000,2019-03-05 16:45:20.000000000,"[{'_account_id': 3153}, {'_account_id': 7509}, {'_account_id': 10873}, {'_account_id': 11082}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 28223}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-02-13 10:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ed53ce16796b8d74cb914a37c6b4cea99cb86356', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validations-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 2, 'created': '2019-02-13 10:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/99ab81b1c88d14f1d72e49620b9dcec084b19464', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 3, 'created': '2019-02-13 10:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f592bc2f61f3f909c688121f8903ee304105f087', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 4, 'created': '2019-02-13 14:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/84e3aed4a689c825fcb7c54e19581ada3977c23e', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 5, 'created': '2019-02-14 08:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4d9fbd8416c2d4ae5f296f02d9bf8b7a560f6e86', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 6, 'created': '2019-02-14 10:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3f9a523b8c8b1c884fb6f3a3633273ed8faeb17e', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 7, 'created': '2019-02-15 09:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ffc99b8de129c57c8f9884ba982357f622396ca8', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 8, 'created': '2019-02-21 13:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/47d72eb8930ab507ab6e83272b9dbc38cec7e3c0', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 9, 'created': '2019-02-22 14:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/edd2aeb74945f5475322a6f0bca7b3f5047fa81c', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 10, 'created': '2019-02-27 08:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b693e3286ba154dc9c06d9dbece7a73c5ef76c0d', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}, {'number': 11, 'created': '2019-03-05 08:28:36.000000000', 'files': ['tripleoclient/constants.py', 'tripleoclient/workflows/validations.py', 'tripleoclient/utils.py', 'tripleoclient/v1/tripleo_validator.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6f6d6332bbab82cea120cee933676f7d406dc448', 'message': 'Add new CLI option openstack tripleo validate list\n\nThis submission starts with the integration of the current supported\nMistral workflows for running the validations.\n\nThis submission integrates the listing of all current installed validations.\n\nChange-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6\nImplements: blueprint validation-framework\nDepends-On: I294ab0016fda9587b405ef08dba3212b8e46a816\n'}]",4,636581,6f6d6332bbab82cea120cee933676f7d406dc448,79,12,11,20775,,,0,"Add new CLI option openstack tripleo validate list

This submission starts with the integration of the current supported
Mistral workflows for running the validations.

This submission integrates the listing of all current installed validations.

Change-Id: Ic4a396598dcfdb55a0858bea95e9a2fcfc7b46e6
Implements: blueprint validation-framework
Depends-On: I294ab0016fda9587b405ef08dba3212b8e46a816
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/81/636581/3 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/validations.py', 'tripleoclient/utils.py', 'tripleoclient/v1/tripleo_validator.py', 'setup.cfg']",4,ed53ce16796b8d74cb914a37c6b4cea99cb86356,bp/validation-framework, tripleo_validator_run = tripleoclient.v1.tripleo_validator:TripleOValidatorRun tripleo_validator_list = tripleoclient.v1.tripleo_validator:TripleOValidatorList,,149,0
openstack%2Fplacement~master~I2b59156e6f376df630bb0b574682964428c65c04,openstack/placement,master,I2b59156e6f376df630bb0b574682964428c65c04,Use native list for lists of Allocation,MERGED,2019-03-01 17:20:51.000000000,2019-03-05 16:34:16.000000000,2019-03-05 16:34:16.000000000,"[{'_account_id': 7}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 17:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/a1172d93c4856e965e9d485fb5f53e7d18e68a3b', 'message': ""WIP: Use native list of list of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nThis is still a WIP because:\n\n* There are problems in the patch before this one which mean\n  it has bad formatting and can't pass py27 tests.\n\n* This patch also has formatting problems.\n\nHowever, the general principles are there and it seems to work\n(for python 3), so conceptual review is welcome.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n""}, {'number': 2, 'created': '2019-03-01 22:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/7bfb24caab15057325ece89ac61125aec619baaa', 'message': ""WIP: Use native list of list of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nThis is still a WIP because:\n\n* There are problems in the patch before this one which mean\n  it has bad formatting and can't pass py27 tests.\n\n* This patch also has formatting problems.\n\nHowever, the general principles are there and it seems to work\n(for python 3), so conceptual review is welcome.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n""}, {'number': 3, 'created': '2019-03-01 22:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/c1d965fbe03e4af2a211f5bcf38b0ca98cd92773', 'message': ""WIP: Use native list of list of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nThis is still a WIP because:\n\n* There are problems in the patch before this one which mean\n  it has bad formatting and can't pass py27 tests.\n\n* This patch also has formatting problems.\n\nHowever, the general principles are there and it seems to work\n(for python 3), so conceptual review is welcome.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n""}, {'number': 4, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/b87dfde08bfb362e4b8975799d1f1538422d46cc', 'message': ""WIP: Use native list of list of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nThis is still a WIP because:\n\n* There are problems in the patch before this one which mean\n  it has bad formatting and can't pass py27 tests.\n\n* This patch also has formatting problems.\n\nHowever, the general principles are there and it seems to work\n(for python 3), so conceptual review is welcome.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n""}, {'number': 5, 'created': '2019-03-02 00:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/b026b2cf5afcfa8211399a41e645ddd45dbb6851', 'message': ""WIP: Use native list of list of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nThis is still a WIP because:\n\n* There are problems in the patch before this one which mean\n  it has bad formatting and can't pass py27 tests.\n\n* This patch also has formatting problems.\n\nHowever, the general principles are there and it seems to work\n(for python 3), so conceptual review is welcome.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n""}, {'number': 6, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/5b1fad2a6c0fdfe14a0062f8924fa86ceb494334', 'message': 'Use native list for lists of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n'}, {'number': 7, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_consumer.py', 'placement/handlers/allocation.py', 'placement/tests/functional/db/test_allocation.py', 'placement/objects/allocation.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/tests/unit/objects/test_allocation.py', 'placement/objects/reshaper.py', 'placement/tests/functional/db/test_reshape.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/2808f5627624bc2b636a30f6f0c0fa121c479a3c', 'message': 'Use native list for lists of Allocation\n\nRemove the AllocationList class and make the retrieval and\nreplace methods on it module level in placement.objects.allocation.\n\nThe methods that perform write operations on a list of allocations\ntake the list as an argument.\n\nAdapting to this change requires a lot of changes in tests and\nthe allocation handler.\n\nChange-Id: I2b59156e6f376df630bb0b574682964428c65c04\n'}]",9,640450,2808f5627624bc2b636a30f6f0c0fa121c479a3c,21,4,7,11564,,,0,"Use native list for lists of Allocation

Remove the AllocationList class and make the retrieval and
replace methods on it module level in placement.objects.allocation.

The methods that perform write operations on a list of allocations
take the list as an argument.

Adapting to this change requires a lot of changes in tests and
the allocation handler.

Change-Id: I2b59156e6f376df630bb0b574682964428c65c04
",git fetch https://review.opendev.org/openstack/placement refs/changes/50/640450/6 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_consumer.py', 'placement/handlers/allocation.py', 'placement/tests/functional/db/test_allocation.py', 'placement/objects/allocation.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/tests/unit/objects/test_allocation.py', 'placement/tests/functional/db/test_reshape.py']",9,a1172d93c4856e965e9d485fb5f53e7d18e68a3b,scrub-Lists," alloc_obj.replace_all(self.ctx, allocs) before_allocs_i1 = alloc_obj.get_all_by_consumer_id(self.ctx, i1_uuid) before_allocs_i2 = alloc_obj.get_all_by_consumer_id(self.ctx, i2_uuid) after_allocs = [ ] after_allocs_i1 = alloc_obj.get_all_by_consumer_id(self.ctx, i1_uuid) after_allocs_i2 = alloc_obj.get_all_by_consumer_id(self.ctx, i2_uuid) alloc_obj.replace_all(self.ctx, allocs) after_allocs = [ ]"," alloc_list = alloc_obj.AllocationList(objects=allocs) alloc_list.replace_all(self.ctx) before_allocs_i1 = alloc_obj.AllocationList.get_all_by_consumer_id( self.ctx, i1_uuid) before_allocs_i2 = alloc_obj.AllocationList.get_all_by_consumer_id( self.ctx, i2_uuid) after_allocs = alloc_obj.AllocationList(objects=[ ]) after_allocs_i1 = alloc_obj.AllocationList.get_all_by_consumer_id( self.ctx, i1_uuid) after_allocs_i2 = alloc_obj.AllocationList.get_all_by_consumer_id( self.ctx, i2_uuid) alloc_list = alloc_obj.AllocationList(objects=allocs) alloc_list.replace_all(self.ctx) after_allocs = alloc_obj.AllocationList(objects=[ ])",328,379
openstack%2Fplacement~master~I7a4e2526f43f5f0c679f8350261e5ed0343d899a,openstack/placement,master,I7a4e2526f43f5f0c679f8350261e5ed0343d899a,ResourceProvider.increment_generation(),MERGED,2019-03-01 16:43:31.000000000,2019-03-05 16:34:15.000000000,2019-03-05 16:34:15.000000000,"[{'_account_id': 7}, {'_account_id': 11224}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 16:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/fb4dbe80e92a461b78035485b2c2697e9df8c3e6', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}, {'number': 2, 'created': '2019-03-01 21:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/7199dea562f124eebfe409d5da59dd6c01f58a86', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}, {'number': 3, 'created': '2019-03-01 21:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/f70adaeaac63ce17fc3f94b5d7d8c7fa8883cee5', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}, {'number': 4, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/296af01ec623d5166f714f650ca9ac66ba970ec1', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}, {'number': 5, 'created': '2019-03-02 00:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/3d0fdab84d8d94e1a1db5a53ef16085029f70e2e', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}, {'number': 6, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/4288b3a60ad11be4f249e4da7f0b59ba9f8a280f', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}, {'number': 7, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/c4b0d8446a9dbfc61a077c5751074c78fe3ed0f3', 'message': 'ResourceProvider.increment_generation()\n\nMove the _increment_provider_generation method into the ResourceProvider\nclass as an instance method.\n\nChange-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a\n'}]",0,640433,c4b0d8446a9dbfc61a077c5751074c78fe3ed0f3,19,5,7,14070,,,0,"ResourceProvider.increment_generation()

Move the _increment_provider_generation method into the ResourceProvider
class as an instance method.

Change-Id: I7a4e2526f43f5f0c679f8350261e5ed0343d899a
",git fetch https://review.opendev.org/openstack/placement refs/changes/33/640433/6 && git format-patch -1 --stdout FETCH_HEAD,"['placement/objects/allocation.py', 'placement/objects/resource_provider.py']",2,fb4dbe80e92a461b78035485b2c2697e9df8c3e6,scrub-Lists," rp.increment_generation() rp.increment_generation() rp.increment_generation() rp.increment_generation() resource_provider.increment_generation() rp.increment_generation() def increment_generation(self): """"""Increments this provider's generation value, supplying the currently-known generation. :raises placement.exception.ConcurrentUpdateDetected: if another thread updated the resource provider's view of its inventory or allocations in between the time when this object was originally read and the call to set the inventory. """""" rp_gen = self.generation new_generation = rp_gen + 1 upd_stmt = _RP_TBL.update().where(sa.and_( _RP_TBL.c.id == self.id, _RP_TBL.c.generation == rp_gen)).values( generation=new_generation) res = self._context.session.execute(upd_stmt) if res.rowcount != 1: raise exception.ResourceProviderConcurrentUpdateDetected() self.generation = new_generation ","def _increment_provider_generation(ctx, rp): """"""Increments the supplied provider's generation value, supplying the currently-known generation. Returns whether the increment succeeded. :param ctx: `placement.context.RequestContext` that contains an oslo_db Session :param rp: `ResourceProvider` whose generation should be updated. :returns: The new resource provider generation value if successful. :raises placement.exception.ConcurrentUpdateDetected: if another thread updated the same resource provider's view of its inventory or allocations in between the time when this object was originally read and the call to set the inventory. """""" rp_gen = rp.generation new_generation = rp_gen + 1 upd_stmt = _RP_TBL.update().where(sa.and_( _RP_TBL.c.id == rp.id, _RP_TBL.c.generation == rp_gen)).values( generation=(new_generation)) res = ctx.session.execute(upd_stmt) if res.rowcount != 1: raise exception.ResourceProviderConcurrentUpdateDetected() return new_generation rp.generation = _increment_provider_generation(context, rp) rp.generation = _increment_provider_generation(context, rp) rp.generation = _increment_provider_generation(context, rp) rp.generation = _increment_provider_generation(context, rp) resource_provider.generation = _increment_provider_generation( context, resource_provider) rp.generation = _increment_provider_generation(context, rp)",28,35
openstack%2Fplacement~master~I9a22963759aa17e2d97f0d305c5160d508c8a79f,openstack/placement,master,I9a22963759aa17e2d97f0d305c5160d508c8a79f,Move reshape() into placement.objects.reshaper,MERGED,2019-03-01 21:50:51.000000000,2019-03-05 16:34:14.000000000,2019-03-05 16:34:14.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 21:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/b7f01770ab8a3063dc8cd4a4e5b793f3c4466941', 'message': 'Move reshape() into placement.tasks.reshaper\n\nIntroduce a new module, placement.tasks.reshaper, to house the reshape()\nmethod.\n\nChange-Id: I9a22963759aa17e2d97f0d305c5160d508c8a79f\n'}, {'number': 2, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/a9137d686b61855fce6fe46530b9e4971cd841ce', 'message': 'Move reshape() into placement.tasks.reshaper\n\nIntroduce a new module, placement.tasks.reshaper, to house the reshape()\nmethod.\n\nChange-Id: I9a22963759aa17e2d97f0d305c5160d508c8a79f\n'}, {'number': 3, 'created': '2019-03-02 00:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/3d4dafae5392108dddb094187599382644dcb177', 'message': ""Move reshape() into placement.objects.reshaper\n\nIntroduce a new module, placement.objects.reshaper, to house the\nreshape() method.\n\nNB: reshaper isn't an object, but there's a feeling that the\n'placement.objects' package should soon be renamed to something less\nobject-y, and we don't want to create a package like 'placement.tasks'\nor similar.\n\nChange-Id: I9a22963759aa17e2d97f0d305c5160d508c8a79f\n""}, {'number': 4, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/0f40ef363e5507ea22aafac69d19ea0bb4e3279a', 'message': ""Move reshape() into placement.objects.reshaper\n\nIntroduce a new module, placement.objects.reshaper, to house the\nreshape() method.\n\nNB: reshaper isn't an object, but there's a feeling that the\n'placement.objects' package should soon be renamed to something less\nobject-y, and we don't want to create a package like 'placement.tasks'\nor similar.\n\nChange-Id: I9a22963759aa17e2d97f0d305c5160d508c8a79f\n""}, {'number': 5, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/handlers/reshaper.py', 'placement/objects/resource_provider.py', 'placement/objects/reshaper.py', 'placement/tests/functional/db/test_reshape.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/664d9348e3ad84ea07686bb80afb6e3bbefe9e4c', 'message': ""Move reshape() into placement.objects.reshaper\n\nIntroduce a new module, placement.objects.reshaper, to house the\nreshape() method.\n\nNB: reshaper isn't an object, but there's a feeling that the\n'placement.objects' package should soon be renamed to something less\nobject-y, and we don't want to create a package like 'placement.tasks'\nor similar.\n\nChange-Id: I9a22963759aa17e2d97f0d305c5160d508c8a79f\n""}]",0,640540,664d9348e3ad84ea07686bb80afb6e3bbefe9e4c,18,5,5,14070,,,0,"Move reshape() into placement.objects.reshaper

Introduce a new module, placement.objects.reshaper, to house the
reshape() method.

NB: reshaper isn't an object, but there's a feeling that the
'placement.objects' package should soon be renamed to something less
object-y, and we don't want to create a package like 'placement.tasks'
or similar.

Change-Id: I9a22963759aa17e2d97f0d305c5160d508c8a79f
",git fetch https://review.opendev.org/openstack/placement refs/changes/40/640540/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/handlers/reshaper.py', 'placement/tasks/reshaper.py', 'placement/objects/resource_provider.py', 'placement/tasks/__init__.py', 'placement/tests/functional/db/test_reshape.py']",5,b7f01770ab8a3063dc8cd4a4e5b793f3c4466941,scrub-Lists,"from placement.tasks import reshaper reshaper.reshape(self.ctx, after_inventories, after_allocs) reshaper.reshape, self.ctx, after_inventories, after_allocs)"," rp_obj.reshape(self.ctx, after_inventories, after_allocs) rp_obj.reshape, self.ctx, after_inventories, after_allocs)",118,96
openstack%2Ftripleo-heat-templates~master~I1181ba4ecbf2381ad8fc6580ef03d54f2a4f6a9c,openstack/tripleo-heat-templates,master,I1181ba4ecbf2381ad8fc6580ef03d54f2a4f6a9c,mistral-executor: handle ansible-playbook-3 situation,ABANDONED,2019-03-05 16:26:39.000000000,2019-03-05 16:32:54.000000000,,[],"[{'number': 1, 'created': '2019-03-05 16:26:39.000000000', 'files': ['deployment/mistral/mistral-executor-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8b2759e82cc2863f7eee410a22649a8b646ba4a1', 'message': ""mistral-executor: handle ansible-playbook-3 situation\n\nansible-playbook-3 is needed where Ansible is run, in the Mistral\nExecutor container.\nThis workaround will hopefully be removed soon.\n\nNote: we use the config_files interface in kolla_config, which doesn't\nallow to create a symlink, but it should be fine.\n\nChange-Id: I1181ba4ecbf2381ad8fc6580ef03d54f2a4f6a9c\n""}]",0,641072,8b2759e82cc2863f7eee410a22649a8b646ba4a1,3,0,1,3153,,,0,"mistral-executor: handle ansible-playbook-3 situation

ansible-playbook-3 is needed where Ansible is run, in the Mistral
Executor container.
This workaround will hopefully be removed soon.

Note: we use the config_files interface in kolla_config, which doesn't
allow to create a symlink, but it should be fine.

Change-Id: I1181ba4ecbf2381ad8fc6580ef03d54f2a4f6a9c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/641072/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/mistral/mistral-executor-container-puppet.yaml'],1,8b2759e82cc2863f7eee410a22649a8b646ba4a1,mistral/python3," - - source: ""/usr/bin/ansible-playbook"" dest: ""/usr/bin/ansible-playbook-3"" preserve_properties: true",,3,0
openstack%2Fplacement~master~I0066fc8fa9b61196ea99e35e780a7d123612023f,openstack/placement,master,I0066fc8fa9b61196ea99e35e780a7d123612023f,Use native list for lists of Usage,MERGED,2019-02-26 17:13:18.000000000,2019-03-05 16:24:34.000000000,2019-03-05 16:24:33.000000000,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 5754}, {'_account_id': 7634}, {'_account_id': 11224}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-26 17:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/e1172be52fab9f72e57a708ba7f90f4ac5a9b6ee', 'message': 'WIP: Use native list for lists of Usage\n\nThe refactoring to remove oslo versioned objects and then to\nDRY out the ListObjects into common code makes it pretty\nclear that the ListObjects, at least in some cases, are not\nreally doing all that much and using simple Python lists\nworks just fine.\n\nThis change move UsageList and Usage into their own file\nand makes the query methods on UsageList module level, and\nremoves the the UsageList class.\n\nThere remain some warts, but as a first pass it looks\npretty workable. The warts:\n\n* _RC_CACHE needs its own home that is a clear global for\n  everyone.\n* The tests for UsageList need to be in their own file.\n\nChange-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f\n'}, {'number': 2, 'created': '2019-02-28 17:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/bef49b7fcf93fb5770ee1b82083aeb798dfde376', 'message': 'Use native list for lists of Usage\n\nThe refactoring to remove oslo versioned objects and then to\nDRY out the ListObjects into common code makes it pretty\nclear that the ListObjects, at least in some cases, are not\nreally doing all that much and using simple Python lists\nworks just fine.\n\nThis change moves Usage into its own own file, deletes UsageList,\nand makes the get_all* query methods on UsageList module level\n\nThe unit and functional tests related to Usage* are moved into\ntheir own files. Since both test_resource_provider and test_usage\nuse the DISK_INVENTORY and DISK_ALLOCATION globals, they are\nmoved to db/test_base.\n\nChange-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f\n'}, {'number': 3, 'created': '2019-03-01 15:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/e7988d63a422ee08f3205f629043d46cb5720c8f', 'message': 'Use native list for lists of Usage\n\nThe refactoring to remove oslo versioned objects and then to\nDRY out the ListObjects into common code makes it pretty\nclear that the ListObjects, at least in some cases, are not\nreally doing all that much and using simple Python lists\nworks just fine.\n\nThis change moves Usage into its own own file, deletes UsageList,\nand makes the get_all* query methods on UsageList module level\n\nThe unit and functional tests related to Usage* are moved into\ntheir own files. Since both test_resource_provider and test_usage\nuse the DISK_INVENTORY and DISK_ALLOCATION globals, they are\nmoved to db/test_base.\n\nChange-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f\n'}, {'number': 4, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/37d4c90b5475c746633ade9289949a6540eeff6e', 'message': 'Use native list for lists of Usage\n\nThe refactoring to remove oslo versioned objects and then to\nDRY out the ListObjects into common code makes it pretty\nclear that the ListObjects, at least in some cases, are not\nreally doing all that much and using simple Python lists\nworks just fine.\n\nThis change moves Usage into its own own file, deletes UsageList,\nand makes the get_all* query methods on UsageList module level\n\nThe unit and functional tests related to Usage* are moved into\ntheir own files. Since both test_resource_provider and test_usage\nuse the DISK_INVENTORY and DISK_ALLOCATION globals, they are\nmoved to db/test_base.\n\nChange-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f\n'}, {'number': 5, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/bf5a1d7995e9d356d2e1e2d7a490cfcd7a9d0654', 'message': 'Use native list for lists of Usage\n\nThe refactoring to remove oslo versioned objects and then to\nDRY out the ListObjects into common code makes it pretty\nclear that the ListObjects, at least in some cases, are not\nreally doing all that much and using simple Python lists\nworks just fine.\n\nThis change moves Usage into its own own file, deletes UsageList,\nand makes the get_all* query methods on UsageList module level\n\nThe unit and functional tests related to Usage* are moved into\ntheir own files. Since both test_resource_provider and test_usage\nuse the DISK_INVENTORY and DISK_ALLOCATION globals, they are\nmoved to db/test_base.\n\nChange-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f\n'}, {'number': 6, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/tests/functional/db/test_base.py', 'placement/tests/unit/objects/test_resource_provider.py', 'placement/handlers/usage.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/tests/functional/db/test_usage.py', 'placement/tests/unit/objects/test_usage.py', 'placement/objects/usage.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/e608e4154a3b6f55be5b64c121c0c09f8c30d81e', 'message': 'Use native list for lists of Usage\n\nThe refactoring to remove oslo versioned objects and then to\nDRY out the ListObjects into common code makes it pretty\nclear that the ListObjects, at least in some cases, are not\nreally doing all that much and using simple Python lists\nworks just fine.\n\nThis change moves Usage into its own own file, deletes UsageList,\nand makes the get_all* query methods on UsageList module level\n\nThe unit and functional tests related to Usage* are moved into\ntheir own files. Since both test_resource_provider and test_usage\nuse the DISK_INVENTORY and DISK_ALLOCATION globals, they are\nmoved to db/test_base.\n\nChange-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f\n'}]",37,639391,e608e4154a3b6f55be5b64c121c0c09f8c30d81e,29,8,6,11564,,,0,"Use native list for lists of Usage

The refactoring to remove oslo versioned objects and then to
DRY out the ListObjects into common code makes it pretty
clear that the ListObjects, at least in some cases, are not
really doing all that much and using simple Python lists
works just fine.

This change moves Usage into its own own file, deletes UsageList,
and makes the get_all* query methods on UsageList module level

The unit and functional tests related to Usage* are moved into
their own files. Since both test_resource_provider and test_usage
use the DISK_INVENTORY and DISK_ALLOCATION globals, they are
moved to db/test_base.

Change-Id: I0066fc8fa9b61196ea99e35e780a7d123612023f
",git fetch https://review.opendev.org/openstack/placement refs/changes/91/639391/4 && git format-patch -1 --stdout FETCH_HEAD,"['placement/handlers/usage.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/objects/usage.py']",4,e1172be52fab9f72e57a708ba7f90f4ac5a9b6ee,scrub-Lists,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import func from sqlalchemy import sql from placement.db.sqlalchemy import models from placement import db_api from placement.objects import resource_provider @db_api.placement_context_manager.reader def _get_all_by_resource_provider_uuid(context, rp_uuid): query = (context.session.query(models.Inventory.resource_class_id, func.coalesce(func.sum(models.Allocation.used), 0)) .join(models.ResourceProvider, models.Inventory.resource_provider_id == models.ResourceProvider.id) .outerjoin(models.Allocation, sql.and_(models.Inventory.resource_provider_id == models.Allocation.resource_provider_id, models.Inventory.resource_class_id == models.Allocation.resource_class_id)) .filter(models.ResourceProvider.uuid == rp_uuid) .group_by(models.Inventory.resource_class_id)) result = [dict(resource_class_id=item[0], usage=item[1]) for item in query.all()] return result @db_api.placement_context_manager.reader def _get_all_by_project_user(context, project_id, user_id=None): query = (context.session.query(models.Allocation.resource_class_id, func.coalesce(func.sum(models.Allocation.used), 0)) .join(models.Consumer, models.Allocation.consumer_id == models.Consumer.uuid) .join(models.Project, models.Consumer.project_id == models.Project.id) .filter(models.Project.external_id == project_id)) if user_id: query = query.join(models.User, models.Consumer.user_id == models.User.id) query = query.filter(models.User.external_id == user_id) query = query.group_by(models.Allocation.resource_class_id) result = [dict(resource_class_id=item[0], usage=item[1]) for item in query.all()] return result def get_all_by_resource_provider_uuid(context, rp_uuid): usage_list = _get_all_by_resource_provider_uuid(context, rp_uuid) return [Usage(**db_item) for db_item in usage_list] def get_all_by_project_user(context, project_id, user_id=None): usage_list = _get_all_by_project_user(context, project_id, user_id=user_id) return [Usage(**db_item) for db_item in usage_list] class Usage(object): def __init__(self, resource_class=None, resource_class_id=None, usage=0): self.resource_class = resource_class if resource_class_id is not None: # FIXME(cdent): Make _RC_CACHE non-private indepenent module. self.resource_class = resource_provider._RC_CACHE.string_from_id( resource_class_id) self.usage = usage @staticmethod def _from_db_object(context, target, source): for field in target.fields: if field not in ('resource_class'): setattr(target, field, source[field]) if 'resource_class' not in target: # FIXME(cdent): Make _RC_CACHE non-private indepenent module. rc_str = resource_provider._RC_CACHE.string_from_id( source['resource_class_id']) target.resource_class = rc_str target._context = context target.obj_reset_changes() return target ",,119,101
openstack%2Fplacement~master~I76039ef9f3c62713577c58b45399efdd79953762,openstack/placement,master,I76039ef9f3c62713577c58b45399efdd79953762,Clean up ObjectList._set_objects signature,MERGED,2019-02-16 00:12:35.000000000,2019-03-05 16:24:32.000000000,2019-03-05 16:24:31.000000000,"[{'_account_id': 7}, {'_account_id': 11224}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-16 00:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/803bc173864bc189f55837f931dfafc18edaad8a', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 2, 'created': '2019-02-26 15:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/a8f201c74d19e0be73edeb4c71267960f34fa801', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 3, 'created': '2019-02-26 16:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/1ff61305ccb23384dbf03abd07c3457e949e86af', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 4, 'created': '2019-02-28 17:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/1cc16ebee6ca860e446003cdbea91e23689cc03a', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 5, 'created': '2019-03-01 15:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/14fdb1644ffc9ee8a22178c5cb298ccceb68b54c', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 6, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/7d35e8f6be8f37059df01ad2833e394b2d14c139', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 7, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/fff5d2a9d6af7d1f31ded6ebae168661ee98a72c', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}, {'number': 8, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/objects/resource_provider.py', 'placement/objects/common.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/f5a1a6d9e63073945837d4647cb724cb967d0796', 'message': ""Clean up ObjectList._set_objects signature\n\nDefining ITEM_CLS on *List classes allows us to be explicit (more than\njust the naming convention) about what kind of thing is being List'd. It\nalso lets us do away with the argument that was that class.\n\n_set_objects was also taking an instance of the *List class itself,\nwhich we can do away with by making _set_objects a @classmethod\ninstead of a @staticmethod.\n\nChange-Id: I76039ef9f3c62713577c58b45399efdd79953762\n""}]",1,637335,f5a1a6d9e63073945837d4647cb724cb967d0796,24,5,8,14070,,,0,"Clean up ObjectList._set_objects signature

Defining ITEM_CLS on *List classes allows us to be explicit (more than
just the naming convention) about what kind of thing is being List'd. It
also lets us do away with the argument that was that class.

_set_objects was also taking an instance of the *List class itself,
which we can do away with by making _set_objects a @classmethod
instead of a @staticmethod.

Change-Id: I76039ef9f3c62713577c58b45399efdd79953762
",git fetch https://review.opendev.org/openstack/placement refs/changes/35/637335/8 && git format-patch -1 --stdout FETCH_HEAD,"['placement/objects/resource_provider.py', 'placement/objects/common.py']",2,803bc173864bc189f55837f931dfafc18edaad8a,scrub-Lists," # For FooList, ITEM_CLS = Foo ITEM_CLS = None @classmethod def _set_objects(cls, context, db_list): list_obj = cls() for db_item in db_list: list_obj.objects.append(cls.ITEM_CLS(context, **db_item))"," @staticmethod def _set_objects(context, list_obj, item_cls, db_list): for db_item in db_list: list_obj.objects.append(item_cls(context, **db_item))",23,14
openstack%2Fplacement~master~Ia35403c5fe2afefd9b8d077b36561963abe16b34,openstack/placement,master,Ia35403c5fe2afefd9b8d077b36561963abe16b34,Move *List.__repr__ into ObjectList,MERGED,2019-02-15 23:45:51.000000000,2019-03-05 16:24:31.000000000,2019-03-05 16:24:31.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 23:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/8442420d35cbb4378cd766f047c1c8c16fa28c93', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 2, 'created': '2019-02-26 15:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/ee59d091e51eb3d365e2c645243de92ff3f1a888', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 3, 'created': '2019-02-26 16:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d863cb79b9b38f940a254c7b1fa846359c494abf', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nAlso note: For lists of objects that are especially long this could\nresult in very long log messages, which can cause issues with some\nlogging tools. We will want to watch this and explore other options.\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 4, 'created': '2019-02-28 17:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/2aa6e50e809f8760a64171bb6c867ac0d7cec15b', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nAlso note: For lists of objects that are especially long this could\nresult in very long log messages, which can cause issues with some\nlogging tools. We will want to watch this and explore other options.\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 5, 'created': '2019-03-01 15:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d4cde6c2b32eab8693a63dd6b65862877ba13e9c', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nAlso note: For lists of objects that are especially long this could\nresult in very long log messages, which can cause issues with some\nlogging tools. We will want to watch this and explore other options.\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 6, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/2642be44fd027c8d3a491e13ca3d0f6997bae9f2', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nAlso note: For lists of objects that are especially long this could\nresult in very long log messages, which can cause issues with some\nlogging tools. We will want to watch this and explore other options.\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 7, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/592b7d7c9d710d38576d589d4f600beeb32f6eb5', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nAlso note: For lists of objects that are especially long this could\nresult in very long log messages, which can cause issues with some\nlogging tools. We will want to watch this and explore other options.\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}, {'number': 8, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/objects/resource_provider.py', 'placement/objects/common.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/22a3dd290dc0398cd836e1b67b77cbd603e8aca3', 'message': ""Move *List.__repr__ into ObjectList\n\nContinue to DRY listy classes by moving the __repr__ method into the\nObjectList base class.\n\nNote: unlike previous refactors, this is not a no-op change, as it will\naffect the repr() of some *List classes that didn't previously override\n__repr__. Since the repr is just used to make pretty logs/errors, this\nshould be copacetic. (Besides, I'm pretty sure we wildly changed the\ndefault __repr__ when we de-OVO-ified.)\n\nAlso note: For lists of objects that are especially long this could\nresult in very long log messages, which can cause issues with some\nlogging tools. We will want to watch this and explore other options.\n\nChange-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34\n""}]",4,637332,22a3dd290dc0398cd836e1b67b77cbd603e8aca3,28,5,8,14070,,,0,"Move *List.__repr__ into ObjectList

Continue to DRY listy classes by moving the __repr__ method into the
ObjectList base class.

Note: unlike previous refactors, this is not a no-op change, as it will
affect the repr() of some *List classes that didn't previously override
__repr__. Since the repr is just used to make pretty logs/errors, this
should be copacetic. (Besides, I'm pretty sure we wildly changed the
default __repr__ when we de-OVO-ified.)

Also note: For lists of objects that are especially long this could
result in very long log messages, which can cause issues with some
logging tools. We will want to watch this and explore other options.

Change-Id: Ia35403c5fe2afefd9b8d077b36561963abe16b34
",git fetch https://review.opendev.org/openstack/placement refs/changes/32/637332/3 && git format-patch -1 --stdout FETCH_HEAD,"['placement/objects/resource_provider.py', 'placement/objects/common.py']",2,8442420d35cbb4378cd766f047c1c8c16fa28c93,scrub-Lists," def __repr__(self): strings = [repr(x) for x in self.objects] return ""%s[%s]"" % (self.__class__.__name__, "", "".join(strings)) ",,4,12
openstack%2Fplacement~master~Iefa45c52bff98c2b1e81be94bce825e84572e92e,openstack/placement,master,Iefa45c52bff98c2b1e81be94bce825e84572e92e,Move _set_objects into ObjectList,MERGED,2019-02-15 23:37:14.000000000,2019-03-05 16:24:30.000000000,2019-03-05 16:24:30.000000000,"[{'_account_id': 7}, {'_account_id': 5754}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 23:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/9728110528d8378df2e48cf7bc0213e0237d3529', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass. Only the context-needing version of\n_set_objects is moved; one subclass overrides the method with a\ndifferent signature (lacking context).\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 2, 'created': '2019-02-26 15:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/b34490d6d61af0e6629ae33b5588ee175c5e6df3', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass. Only the context-needing version of\n_set_objects is moved; one subclass overrides the method with a\ndifferent signature (lacking context).\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 3, 'created': '2019-02-26 16:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/41620c91bb83f07916b072fbeb145eaf8ea626bd', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass.\n\nUsageList had a version of _set_objects which created a Usage\nwithout a context. Instead of maintaining that, Usage now\ntakes an unused context as its first arg. Since within\nUsageList is the only way a Usage gets created, this is a\nlow impact change.\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 4, 'created': '2019-02-28 17:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/5373f7a976ca95bed045072c341a93248869feb2', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass.\n\nUsageList had a version of _set_objects which created a Usage\nwithout a context. Instead of maintaining that, Usage now\ntakes an unused context as its first arg. Since within\nUsageList is the only way a Usage gets created, this is a\nlow impact change.\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 5, 'created': '2019-03-01 15:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/93c7ee88a334e1736f50bc42cf9ca95e8b3c3d69', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass.\n\nUsageList had a version of _set_objects which created a Usage\nwithout a context. Instead of maintaining that, Usage now\ntakes an unused context as its first arg. Since within\nUsageList is the only way a Usage gets created, this is a\nlow impact change.\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 6, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d82ae34e33ed67aba5d921c25ca345c46a5abe27', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass.\n\nUsageList had a version of _set_objects which created a Usage\nwithout a context. Instead of maintaining that, Usage now\ntakes an unused context as its first arg. Since within\nUsageList is the only way a Usage gets created, this is a\nlow impact change.\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 7, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/98c393dee00a97124d69cb368fd166f7139d2d30', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass.\n\nUsageList had a version of _set_objects which created a Usage\nwithout a context. Instead of maintaining that, Usage now\ntakes an unused context as its first arg. Since within\nUsageList is the only way a Usage gets created, this is a\nlow impact change.\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}, {'number': 8, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/tests/unit/objects/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/objects/common.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/8a68c978345689680fd260573a732114a5f1097e', 'message': 'Move _set_objects into ObjectList\n\nContinue factoring out common *List methods by moving _set_objects into\nthe ObjectList superclass.\n\nUsageList had a version of _set_objects which created a Usage\nwithout a context. Instead of maintaining that, Usage now\ntakes an unused context as its first arg. Since within\nUsageList is the only way a Usage gets created, this is a\nlow impact change.\n\nChange-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e\n'}]",3,637328,8a68c978345689680fd260573a732114a5f1097e,25,5,8,14070,,,0,"Move _set_objects into ObjectList

Continue factoring out common *List methods by moving _set_objects into
the ObjectList superclass.

UsageList had a version of _set_objects which created a Usage
without a context. Instead of maintaining that, Usage now
takes an unused context as its first arg. Since within
UsageList is the only way a Usage gets created, this is a
low impact change.

Change-Id: Iefa45c52bff98c2b1e81be94bce825e84572e92e
",git fetch https://review.opendev.org/openstack/placement refs/changes/28/637328/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/objects/resource_provider.py', 'placement/objects/common.py']",2,9728110528d8378df2e48cf7bc0213e0237d3529,scrub-Lists," @staticmethod def _set_objects(context, list_obj, item_cls, db_list): for db_item in db_list: list_obj.objects.append(item_cls(context, **db_item)) return list_obj",,7,25
openstack%2Fplacement~master~Ice41cbdcec62d0e7d0f058bcae677e416189b1ae,openstack/placement,master,Ice41cbdcec62d0e7d0f058bcae677e416189b1ae,Factor listiness into an ObjectList base class,MERGED,2019-02-15 23:24:19.000000000,2019-03-05 16:19:08.000000000,2019-03-05 16:14:04.000000000,"[{'_account_id': 7}, {'_account_id': 5754}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 23:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/4d97a11d56e5e937d2fa0957cf20aceb5d3399dd', 'message': 'Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n'}, {'number': 2, 'created': '2019-02-15 23:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/549a04e2c2433978d1bcb89ad9f5c91b66d19ba0', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 3, 'created': '2019-02-26 15:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/5db1e8efeac98fb15cfab1d2110f8a84484a8a1f', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 4, 'created': '2019-02-26 16:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d3e38ab528ad117aba562c150f1af71d294bac5e', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nAllocationList was previously saving a context arg as an instance\nvariable and using it in replace_all and delete_all. All calling paths\nof those methods had a context in scope that was the same as the one\nused to init the AllocationList object itself. This change adds a\ncontext arg to replace_all and delete_all, allowing us to remove the\ninstance variable. This allows us to remove the __init__ method from\nAllocationList, since it can now simply use the one from the ObjectList\nsuperclass.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 5, 'created': '2019-02-28 17:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/d4af1ef087d793c30df65f121f12605855680001', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nAllocationList was previously saving a context arg as an instance\nvariable and using it in replace_all and delete_all. All calling paths\nof those methods had a context in scope that was the same as the one\nused to init the AllocationList object itself. This change adds a\ncontext arg to replace_all and delete_all, allowing us to remove the\ninstance variable. This allows us to remove the __init__ method from\nAllocationList, since it can now simply use the one from the ObjectList\nsuperclass.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 6, 'created': '2019-03-01 15:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/cb00540528649280faa41e912427e59b5a0a5ae1', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nAllocationList was previously saving a context arg as an instance\nvariable and using it in replace_all and delete_all. All calling paths\nof those methods had a context in scope that was the same as the one\nused to init the AllocationList object itself. This change adds a\ncontext arg to replace_all and delete_all, allowing us to remove the\ninstance variable. This allows us to remove the __init__ method from\nAllocationList, since it can now simply use the one from the ObjectList\nsuperclass.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 7, 'created': '2019-03-01 23:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/172d5005dac42ac9b1512450f558a9d788f03cd2', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nAllocationList was previously saving a context arg as an instance\nvariable and using it in replace_all and delete_all. All calling paths\nof those methods had a context in scope that was the same as the one\nused to init the AllocationList object itself. This change adds a\ncontext arg to replace_all and delete_all, allowing us to remove the\ninstance variable. This allows us to remove the __init__ method from\nAllocationList, since it can now simply use the one from the ObjectList\nsuperclass.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 8, 'created': '2019-03-04 10:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/0a510209beffae160319df990150e4e34bc4eff9', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nAllocationList was previously saving a context arg as an instance\nvariable and using it in replace_all and delete_all. All calling paths\nof those methods had a context in scope that was the same as the one\nused to init the AllocationList object itself. This change adds a\ncontext arg to replace_all and delete_all, allowing us to remove the\ninstance variable. This allows us to remove the __init__ method from\nAllocationList, since it can now simply use the one from the ObjectList\nsuperclass.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}, {'number': 9, 'created': '2019-03-04 15:38:04.000000000', 'files': ['placement/tests/functional/db/test_base.py', 'placement/tests/functional/db/test_consumer.py', 'placement/handlers/allocation.py', 'placement/tests/functional/db/test_resource_provider.py', 'placement/objects/resource_provider.py', 'placement/objects/common.py', 'placement/tests/functional/db/test_reshape.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/617d1f0733564a15eea43a3cc5ae2876c92071cd', 'message': ""Factor listiness into an ObjectList base class\n\nWhile de-OVO-ifying objects, all the *List classes ended up with a\ncommon pattern of __init__, __len__, and __getitem__ methods to make\nthem behave listily. Here we factor these out into a base ObjectList\nclass in a new placement.objects.common module.\n\nNote that there's still commonality among the *List classes that could\nbe factored into ObjectList - e.g. the _set_objects method. That is left\nfor a future change.\n\nAllocationList was previously saving a context arg as an instance\nvariable and using it in replace_all and delete_all. All calling paths\nof those methods had a context in scope that was the same as the one\nused to init the AllocationList object itself. This change adds a\ncontext arg to replace_all and delete_all, allowing us to remove the\ninstance variable. This allows us to remove the __init__ method from\nAllocationList, since it can now simply use the one from the ObjectList\nsuperclass.\n\nChange-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae\n""}]",2,637325,617d1f0733564a15eea43a3cc5ae2876c92071cd,33,5,9,14070,,,0,"Factor listiness into an ObjectList base class

While de-OVO-ifying objects, all the *List classes ended up with a
common pattern of __init__, __len__, and __getitem__ methods to make
them behave listily. Here we factor these out into a base ObjectList
class in a new placement.objects.common module.

Note that there's still commonality among the *List classes that could
be factored into ObjectList - e.g. the _set_objects method. That is left
for a future change.

AllocationList was previously saving a context arg as an instance
variable and using it in replace_all and delete_all. All calling paths
of those methods had a context in scope that was the same as the one
used to init the AllocationList object itself. This change adds a
context arg to replace_all and delete_all, allowing us to remove the
instance variable. This allows us to remove the __init__ method from
AllocationList, since it can now simply use the one from the ObjectList
superclass.

Change-Id: Ice41cbdcec62d0e7d0f058bcae677e416189b1ae
",git fetch https://review.opendev.org/openstack/placement refs/changes/25/637325/3 && git format-patch -1 --stdout FETCH_HEAD,"['placement/objects/resource_provider.py', 'placement/objects/common.py']",2,4d97a11d56e5e937d2fa0957cf20aceb5d3399dd,scrub-Lists,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class ObjectList(object): """"""Provide listiness for objects which are a list of other objects."""""" def __init__(self, objects=None): self.objects = objects or [] def __len__(self): """"""List length is a proxy for truthiness."""""" return len(self.objects) def __getitem__(self, index): return self.objects[index] ",,35,64
openstack%2Fcinder~master~I869bc0c9b18887da1ea83f855d255557f0f3cba0,openstack/cinder,master,I869bc0c9b18887da1ea83f855d255557f0f3cba0,Fix multiattach set to false after retype,MERGED,2018-09-27 11:17:35.000000000,2019-03-05 16:18:56.000000000,2018-10-23 13:46:02.000000000,"[{'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12670}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18058}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-27 11:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c7de9334745f4920c8204640348a80ef866b3a6', 'message': 'Fix multiattach set to false after retype\n\nThe return value of get_by_name_or_id in the volume_types module\nreturns a dictionary.\nDuring the function call to _is_multiattach, the getattr() returns\n{}(default value) because a dictionary is passed instead of an object.\nAfter importing the cinder.objects.volume_type module,\nthe current function call to get_by_name_or_id() returns an object\nhence getattr() will return the appropriate extra_specs instead of\nthe default value({}).\n\nChange-Id: I869bc0c9b18887da1ea83f855d255557f0f3cba0\n'}, {'number': 2, 'created': '2018-09-27 18:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ad010792ff0dd97f6c7bbff7011a29327de6db6', 'message': 'Fix multiattach set to false after retype\n\nThe return value of get_by_name_or_id in the volume_types module\nreturns a dictionary.\nDuring the function call to _is_multiattach, the getattr() returns\n{}(default value) because a dictionary is passed instead of an object.\nAfter importing the cinder.objects.volume_type module,\nthe current function call to get_by_name_or_id() returns an object\nhence getattr() will return the appropriate extra_specs instead of\nthe default value({}).\n\nCloses-Bug: 1790840\nChange-Id: I869bc0c9b18887da1ea83f855d255557f0f3cba0\n'}, {'number': 3, 'created': '2018-09-28 10:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2bea482510c4e18c530c0eddece4eb1374b9c82d', 'message': 'Fix multiattach set to false after retype\n\nThe return value of get_by_name_or_id in the volume_types module\nreturns a dictionary.\nDuring the function call to _is_multiattach, the getattr() returns\n{}(default value) because a dictionary is passed instead of an object.\nAfter importing the cinder.objects.volume_type module,\nthe current function call to get_by_name_or_id() returns an object\nhence getattr() will return the appropriate extra_specs instead of\nthe default value({}).\n\nCloses-Bug: 1790840\nChange-Id: I869bc0c9b18887da1ea83f855d255557f0f3cba0\n'}, {'number': 4, 'created': '2018-09-28 18:10:57.000000000', 'files': ['cinder/tests/unit/volume/test_volume_retype.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f85be418669286392c833479dfdc7c2a33f86d1', 'message': 'Fix multiattach set to false after retype\n\nThe return value of get_by_name_or_id in the volume_types module\nreturns a dictionary.\nDuring the function call to _is_multiattach, the getattr() returns\n{}(default value) because a dictionary is passed instead of an object.\nAfter importing the cinder.objects.volume_type module,\nthe current function call to get_by_name_or_id() returns an object\nhence getattr() will return the appropriate extra_specs instead of\nthe default value({}).\n\nCloses-Bug: 1790840\nChange-Id: I869bc0c9b18887da1ea83f855d255557f0f3cba0\n'}]",28,605650,7f85be418669286392c833479dfdc7c2a33f86d1,136,39,4,27615,,,0,"Fix multiattach set to false after retype

The return value of get_by_name_or_id in the volume_types module
returns a dictionary.
During the function call to _is_multiattach, the getattr() returns
{}(default value) because a dictionary is passed instead of an object.
After importing the cinder.objects.volume_type module,
the current function call to get_by_name_or_id() returns an object
hence getattr() will return the appropriate extra_specs instead of
the default value({}).

Closes-Bug: 1790840
Change-Id: I869bc0c9b18887da1ea83f855d255557f0f3cba0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/605650/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/api.py'],1,7c7de9334745f4920c8204640348a80ef866b3a6,bug/1790840,"from cinder.objects import volume_type volume_type.VolumeType.get_by_name_or_id(context.elevated(), new_type))"," volume_types.get_by_name_or_id(context.elevated(), new_type))",3,1
openstack%2Fgovernance~master~Ib17202f6bc698cedca87133570aed7b7fb6c50d8,openstack/governance,master,Ib17202f6bc698cedca87133570aed7b7fb6c50d8,mention goal selection owners as a chair duty,MERGED,2019-03-05 13:14:09.000000000,2019-03-05 16:18:27.000000000,2019-03-05 16:18:27.000000000,"[{'_account_id': 2472}, {'_account_id': 8099}, {'_account_id': 8556}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 13:14:09.000000000', 'files': ['CHAIR.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/2e290f445764c69a42b67d3ee5cfab7d1bbbf43a', 'message': 'mention goal selection owners as a chair duty\n\nChange-Id: Ib17202f6bc698cedca87133570aed7b7fb6c50d8\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,641009,2e290f445764c69a42b67d3ee5cfab7d1bbbf43a,9,5,1,2472,,,0,"mention goal selection owners as a chair duty

Change-Id: Ib17202f6bc698cedca87133570aed7b7fb6c50d8
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/09/641009/1 && git format-patch -1 --stdout FETCH_HEAD,['CHAIR.rst'],1,2e290f445764c69a42b67d3ee5cfab7d1bbbf43a,documentation-change,* Ensure that 2 TC members are signed up to manage the goal selection process for the next cycle.,,2,0
openstack%2Fpaunch~master~I7faaf0b120cc58c5f643da1c4ce186ad340b4710,openstack/paunch,master,I7faaf0b120cc58c5f643da1c4ce186ad340b4710,Switch to Podman by default,MERGED,2019-03-04 23:20:42.000000000,2019-03-05 16:07:54.000000000,2019-03-05 16:07:54.000000000,"[{'_account_id': 4571}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 23:20:42.000000000', 'files': ['README.rst', 'paunch/cmd.py', 'releasenotes/notes/podman_default-be591a4b208cfd6a.yaml', 'paunch/tests/test_paunch.py', 'paunch/__init__.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/e42b4690e6ad9af04f76d1ef416df25d80c31136', 'message': 'Switch to Podman by default\n\nDocker will be deprecated in Stein and removed in Train.\n\nChange-Id: I7faaf0b120cc58c5f643da1c4ce186ad340b4710\n'}]",0,640893,e42b4690e6ad9af04f76d1ef416df25d80c31136,8,5,1,3153,,,0,"Switch to Podman by default

Docker will be deprecated in Stein and removed in Train.

Change-Id: I7faaf0b120cc58c5f643da1c4ce186ad340b4710
",git fetch https://review.opendev.org/openstack/paunch refs/changes/93/640893/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'paunch/cmd.py', 'releasenotes/notes/podman_default-be591a4b208cfd6a.yaml', 'paunch/tests/test_paunch.py', 'paunch/__init__.py']",5,e42b4690e6ad9af04f76d1ef416df25d80c31136,podman/default,"def apply(config_id, config, managed_by, labels=None, cont_cmd='podman',def cleanup(config_ids, managed_by, cont_cmd='podman', default_runtime=None,def list(managed_by, cont_cmd='podman', default_runtime=None, 'podman inspect' dicts for each container. cont_cmd='podman', default_runtime=None, log_level=None,def delete(config_ids, managed_by, cont_cmd='podman', default_runtime=None,","def apply(config_id, config, managed_by, labels=None, cont_cmd='docker',def cleanup(config_ids, managed_by, cont_cmd='docker', default_runtime=None,def list(managed_by, cont_cmd='docker', default_runtime=None, 'docker inspect' dicts for each container. cont_cmd='docker', default_runtime=None, log_level=None,def delete(config_ids, managed_by, cont_cmd='docker', default_runtime=None,",25,21
openstack%2Fopenstack-helm-infra~master~I1b8f8af9e3822f00352621426199548f72df6756,openstack/openstack-helm-infra,master,I1b8f8af9e3822f00352621426199548f72df6756,[WIP]: Updated the logic to calculate PGs,ABANDONED,2019-02-23 00:50:22.000000000,2019-03-05 16:06:39.000000000,,"[{'_account_id': 22348}, {'_account_id': 22713}, {'_account_id': 23928}, {'_account_id': 29268}]","[{'number': 1, 'created': '2019-02-23 00:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/49cf228cd4c5116e149763df4068937382f7191c', 'message': '[WIP]: Updated the logic to calculate PGs\n\nChange-Id: I1b8f8af9e3822f00352621426199548f72df6756\n'}, {'number': 2, 'created': '2019-02-23 00:56:51.000000000', 'files': ['ceph-client/templates/bin/pool/_calc.py.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f0cc38715eb2cdcd617d79f8066abb17a0dfe61b', 'message': '[WIP]: Updated the logic to calculate PGs\n\nChange-Id: I1b8f8af9e3822f00352621426199548f72df6756\n'}]",0,638795,f0cc38715eb2cdcd617d79f8066abb17a0dfe61b,6,4,2,29132,,,0,"[WIP]: Updated the logic to calculate PGs

Change-Id: I1b8f8af9e3822f00352621426199548f72df6756
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/95/638795/2 && git format-patch -1 --stdout FETCH_HEAD,['ceph-client/templates/bin/pool/_calc.py.tpl'],1,49cf228cd4c5116e149763df4068937382f7191c,,"# NOTE(portdirect): this is a simple approximation of https://ceph.com/pgcalc/pow2belowThreshold = 0.25 minValue = nearestPow2(math.floor(number_of_osds/replication)+1) if minValue < number_of_osds: minValue *= 2 calcValue = nearestPow2(((target_pgs_per_osd*number_of_osds*percentage_data)/(100*replication))) if minValue > calcValue: print minValue else: print calcValue def nearestPow2(aSize): tmp = int(math.pow(2, round(math.log(aSize, 2)))) if tmp < (aSize*(1-pow2belowThreshold)): tmp *= 2 return tmp","#NOTE(portdirect): this is a simple approximation of https://ceph.com/pgcalc/ raw_pg_num_opt = target_pgs_per_osd * number_of_osds \ * (math.ceil(percentage_data) / 100.0) / replication raw_pg_num_min = number_of_osds / replication if raw_pg_num_min >= raw_pg_num_opt: raw_pg_num = raw_pg_num_min else: raw_pg_num = raw_pg_num_opt max_pg_num = int(math.pow(2, math.ceil(math.log(raw_pg_num, 2)))) min_pg_num = int(math.pow(2, math.floor(math.log(raw_pg_num, 2)))) if min_pg_num >= (raw_pg_num * 0.75): print min_pg_num else: print max_pg_num",14,15
openstack%2Ftripleo-heat-templates~master~Icf2856fd261b49a4da1f197c7190c9a18d21e30f,openstack/tripleo-heat-templates,master,Icf2856fd261b49a4da1f197c7190c9a18d21e30f,flatten the octavia service configurations,MERGED,2019-02-22 20:18:14.000000000,2019-03-05 15:51:58.000000000,2019-03-05 15:51:58.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-22 20:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b31f164f18b1d4e832699ab6277fac7d364e773', 'message': 'flatten the octavia service configurations\n\nThis change combines the previous puppet and docker files into a single\nfile that performs the containerized service installation and configuration\nfor the octavia services.\n\nWith this patch the baremetal version of each respective octavia service\nhas been removed.\n\nRelated-Blueprint: services-yaml-flattening\n\nChange-Id: Icf2856fd261b49a4da1f197c7190c9a18d21e30f\n'}, {'number': 2, 'created': '2019-03-04 20:28:26.000000000', 'files': ['ci/environments/scenario010-multinode-containers.yaml', 'puppet/services/octavia-worker.yaml', 'deployment/octavia/octavia-worker-container-puppet.yaml', 'environments/services/octavia.yaml', 'deployment/octavia/octavia-base.yaml', 'puppet/services/octavia-controller.yaml', 'puppet/services/octavia-health-manager.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'deployment/octavia/octavia-deployment-config.j2.yaml', 'environments/services-baremetal/octavia.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml', 'puppet/services/octavia-base.yaml', 'puppet/services/octavia-api.yaml', 'puppet/services/octavia-housekeeping.yaml', 'tools/yaml-validate.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ebc9dd98e0b12df90c5d9ffbb23fc9c73f26f0cd', 'message': 'flatten the octavia service configurations\n\nThis change combines the previous puppet and docker files into a single\nfile that performs the containerized service installation and configuration\nfor the octavia services.\n\nWith this patch the baremetal version of each respective octavia service\nhas been removed.\n\nRelated-Blueprint: services-yaml-flattening\n\nChange-Id: Icf2856fd261b49a4da1f197c7190c9a18d21e30f\n'}]",1,638762,ebc9dd98e0b12df90c5d9ffbb23fc9c73f26f0cd,16,6,2,360,,,0,"flatten the octavia service configurations

This change combines the previous puppet and docker files into a single
file that performs the containerized service installation and configuration
for the octavia services.

With this patch the baremetal version of each respective octavia service
has been removed.

Related-Blueprint: services-yaml-flattening

Change-Id: Icf2856fd261b49a4da1f197c7190c9a18d21e30f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/638762/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario010-multinode-containers.yaml', 'puppet/services/octavia-worker.yaml', 'deployment/octavia/octavia-worker-container-puppet.yaml', 'environments/services/octavia.yaml', 'deployment/octavia/octavia-base.yaml', 'puppet/services/octavia-controller.yaml', 'puppet/services/octavia-health-manager.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'deployment/octavia/octavia-deployment-config.j2.yaml', 'environments/services-baremetal/octavia.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml', 'puppet/services/octavia-base.yaml', 'puppet/services/octavia-api.yaml', 'puppet/services/octavia-housekeeping.yaml', 'tools/yaml-validate.py']",16,3b31f164f18b1d4e832699ab6277fac7d364e773,bp/services-yaml-flattening," './deployment/octavia/octavia-deployment-config.yaml',"," './docker/services/octavia/octavia-deployment-config.yaml',",469,854
openstack%2Fpython-glanceclient~master~I4d64cc983cf1dc550227a48488275ac4aac7f888,openstack/python-glanceclient,master,I4d64cc983cf1dc550227a48488275ac4aac7f888,DNM: lower-constraints job py36 test,ABANDONED,2018-12-17 16:27:33.000000000,2019-03-05 15:49:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-17 16:27:33.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/dc1288552988f8db6ccf02e544748e57b1b0a099', 'message': 'DNM: lower-constraints job py36 test\n\nSee http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001026.html\n\nDepends-on: https://review.openstack.org/#/c/623229/\nChange-Id: I4d64cc983cf1dc550227a48488275ac4aac7f888\n'}]",0,625650,dc1288552988f8db6ccf02e544748e57b1b0a099,3,1,1,5314,,,0,"DNM: lower-constraints job py36 test

See http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001026.html

Depends-on: https://review.openstack.org/#/c/623229/
Change-Id: I4d64cc983cf1dc550227a48488275ac4aac7f888
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/50/625650/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,dc1288552988f8db6ccf02e544748e57b1b0a099,py36-lc,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fglance_store~master~I19407f7d4489747cb045293ae08590fa02fd5fb3,openstack/glance_store,master,I19407f7d4489747cb045293ae08590fa02fd5fb3,DNM: lower-constraints job py36 test,ABANDONED,2018-12-17 16:27:16.000000000,2019-03-05 15:48:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-17 16:27:16.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/4feaae98972ca826e736084455d9134c6c4924ed', 'message': 'DNM: lower-constraints job py36 test\n\nSee http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001026.html\n\nDepends-on: https://review.openstack.org/#/c/623229/\nChange-Id: I19407f7d4489747cb045293ae08590fa02fd5fb3\n'}]",0,625649,4feaae98972ca826e736084455d9134c6c4924ed,3,1,1,5314,,,0,"DNM: lower-constraints job py36 test

See http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001026.html

Depends-on: https://review.openstack.org/#/c/623229/
Change-Id: I19407f7d4489747cb045293ae08590fa02fd5fb3
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/49/625649/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,4feaae98972ca826e736084455d9134c6c4924ed,py36-lc,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fglance~master~I51bd91fd1f7b767e95c69dfd4daca825e39040f1,openstack/glance,master,I51bd91fd1f7b767e95c69dfd4daca825e39040f1,DNM: lower-constraints job py36 test,ABANDONED,2018-12-17 16:22:45.000000000,2019-03-05 15:48:34.000000000,,"[{'_account_id': 9008}, {'_account_id': 11564}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-17 16:22:45.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/glance/commit/3450c9d31d6df0b97bbb64c991d1f27b4f45648d', 'message': 'DNM: lower-constraints job py36 test\n\nSee http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001026.html\n\nDepends-on: https://review.openstack.org/#/c/623229/\nChange-Id: I51bd91fd1f7b767e95c69dfd4daca825e39040f1\n'}]",0,625646,3450c9d31d6df0b97bbb64c991d1f27b4f45648d,5,3,1,5314,,,0,"DNM: lower-constraints job py36 test

See http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001026.html

Depends-on: https://review.openstack.org/#/c/623229/
Change-Id: I51bd91fd1f7b767e95c69dfd4daca825e39040f1
",git fetch https://review.opendev.org/openstack/glance refs/changes/46/625646/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,3450c9d31d6df0b97bbb64c991d1f27b4f45648d,py36-lc,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fnetworking-ovn~master~Ia40364b807b64fb99724adfc27dd5569bf7b45d1,openstack/networking-ovn,master,Ia40364b807b64fb99724adfc27dd5569bf7b45d1,Run TripleO scenario003 in gate pipeline,MERGED,2019-02-21 14:05:24.000000000,2019-03-05 15:47:26.000000000,2019-03-05 15:47:26.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-21 14:05:24.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8721ca9af138e745586bb1f8d66af519d6bf031a', 'message': ""Run TripleO scenario003 in gate pipeline\n\nFor some reason, the previous definition didn't trigger the job\nto run scenario 003 in the gate pipeline. Changing it now to\nmatch the one in the check pipeline.\n\nChange-Id: Ia40364b807b64fb99724adfc27dd5569bf7b45d1\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n""}]",0,638422,8721ca9af138e745586bb1f8d66af519d6bf031a,17,3,1,23804,,,0,"Run TripleO scenario003 in gate pipeline

For some reason, the previous definition didn't trigger the job
to run scenario 003 in the gate pipeline. Changing it now to
match the one in the check pipeline.

Change-Id: Ia40364b807b64fb99724adfc27dd5569bf7b45d1
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/22/638422/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,8721ca9af138e745586bb1f8d66af519d6bf031a,, - networking-ovn-tripleo-c7-s003-oooq-containers:, - tripleo-ci-centos-7-scenario003-multinode-oooq-container:,1,1
openstack%2Fironic-tempest-plugin~master~I09d9a21e1ea5512c0140e818b0ca3de501870c12,openstack/ironic-tempest-plugin,master,I09d9a21e1ea5512c0140e818b0ca3de501870c12,Deploy templates: add API tests,MERGED,2019-02-15 13:56:36.000000000,2019-03-05 15:44:36.000000000,2019-03-05 15:44:36.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 13:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/c763b4bd5618450f3bc5d73935c668a81202f04d', 'message': 'WIP: Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.54.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 2, 'created': '2019-02-15 17:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/c387e9c77548d072d8a0d1c32e913329378b818e', 'message': 'WIP: Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.54.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 3, 'created': '2019-02-22 19:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/af6e4cf042be4fc3f30e9cf64d3b33df4f477db4', 'message': 'WIP: Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 4, 'created': '2019-02-25 14:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/bba943e1bf89a59c70b95348aa00f85d487a2aa5', 'message': 'WIP: Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 5, 'created': '2019-02-25 14:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/06f6ce01baab90b10f4e0e253097ac56202a545f', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 6, 'created': '2019-02-25 14:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/0739e85b1201e696c187da82b409f66c31500a9f', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 7, 'created': '2019-02-26 18:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/c9107736858b83e51d9faec0f5ba1134dd602f8b', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 8, 'created': '2019-02-28 13:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/ce4ff3c1cce5bccd0e0de2d0c7b74af106e45597', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nAlso fixes an issue where the microversion fixture was not used in the resource\ncleanup, so new resources would see a 404 and not be deleted. Fixing this\nuncovered an issue in the volume tests where volume connectors and targets\ncould not be deleted due to being associated with a powered on node. The\nsimplest fix was to move node deletion before the volume connector and target\nin resource cleanup.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 9, 'created': '2019-03-01 14:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/df761b3c3a7cc92d2d60d988e596663a9679fa66', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nAlso fixes an issue where the microversion fixture was not used in the resource\ncleanup, so new resources would see a 404 and not be deleted. Fixing this\nuncovered an issue in the volume tests where volume connectors and targets\ncould not be deleted due to being associated with a powered on node. The\nsimplest fix was to move node deletion before the volume connector and target\nin resource cleanup.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 10, 'created': '2019-03-01 15:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/05301dd89f7f083365c8dc7aa7a79e7f564c70be', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nAlso fixes an issue where the microversion fixture was not used in the resource\ncleanup, so new resources would see a 404 and not be deleted. Fixing this\nuncovered an issue in the volume tests where volume connectors and targets\ncould not be deleted due to being associated with a powered on node. The\nsimplest fix was to move node deletion before the volume connector and target\nin resource cleanup.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 11, 'created': '2019-03-04 10:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/3967aee2b27166ca4031b1dde22417d761172fcb', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nAlso fixes an issue where the microversion fixture was not used in the resource\ncleanup, so new resources would see a 404 and not be deleted. Fixing this\nuncovered an issue in the volume tests where volume connectors and targets\ncould not be deleted due to being associated with a powered on node. The\nsimplest fix was to move node deletion before the volume connector and target\nin resource cleanup.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 12, 'created': '2019-03-05 09:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/f2770fd2b09b06d7f2e532629c8ce7c806688920', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nAlso fixes an issue where the microversion fixture was not used in the resource\ncleanup, so new resources would see a 404 and not be deleted. Fixing this\nuncovered an issue in the volume tests where volume connectors and targets\ncould not be deleted due to being associated with a powered on node. The\nsimplest fix was to move node deletion before the volume connector and target\nin resource cleanup.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}, {'number': 13, 'created': '2019-03-05 11:05:53.000000000', 'files': ['ironic_tempest_plugin/services/baremetal/v1/json/baremetal_client.py', 'ironic_tempest_plugin/tests/api/admin/test_deploy_templates.py', 'ironic_tempest_plugin/tests/api/admin/base.py'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/6f2e72c455a9f138a018f66473402720a6fc285a', 'message': 'Deploy templates: add API tests\n\nAdds tests for the deploy templates API added in 1.55.\n\nAlso fixes an issue where the microversion fixture was not used in the resource\ncleanup, so new resources would see a 404 and not be deleted. Fixing this\nuncovered an issue in the volume tests where volume connectors and targets\ncould not be deleted due to being associated with a powered on node. The\nsimplest fix was to move node deletion before the volume connector and target\nin resource cleanup.\n\nChange-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28679\n'}]",28,637187,6f2e72c455a9f138a018f66473402720a6fc285a,45,4,13,14826,,,0,"Deploy templates: add API tests

Adds tests for the deploy templates API added in 1.55.

Also fixes an issue where the microversion fixture was not used in the resource
cleanup, so new resources would see a 404 and not be deleted. Fixing this
uncovered an issue in the volume tests where volume connectors and targets
could not be deleted due to being associated with a powered on node. The
simplest fix was to move node deletion before the volume connector and target
in resource cleanup.

Change-Id: I09d9a21e1ea5512c0140e818b0ca3de501870c12
Depends-On: https://review.openstack.org/631845
Story: 1722275
Task: 28679
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/87/637187/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_tempest_plugin/services/baremetal/v1/json/baremetal_client.py', 'ironic_tempest_plugin/tests/api/admin/test_deploy_templates.py', 'ironic_tempest_plugin/tests/api/admin/base.py']",3,c763b4bd5618450f3bc5d73935c668a81202f04d,story/1722275," 'node', 'chassis', 'deploy_template']"," 'node', 'chassis']",351,1
openstack%2Fneutron~master~Idd55f7d24a2062c08ac8a0dc2243625632d962a5,openstack/neutron,master,Idd55f7d24a2062c08ac8a0dc2243625632d962a5,Delete port binding level for deleted bindings,MERGED,2019-01-31 16:59:16.000000000,2019-03-05 15:41:45.000000000,2019-03-05 15:41:45.000000000,"[{'_account_id': 841}, {'_account_id': 4187}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 11975}, {'_account_id': 12171}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 28714}]","[{'number': 1, 'created': '2019-01-31 16:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd56db2dd55c36eea7f2564e7cc838378dbd42ae', 'message': ""Delete port binding level for deleted bindings\n\nToday if live migration has failed after the inactive\nbinding was created on the destination node but before\nthe activation of the binding. the port's binding level\nfor the destination host is not cleared during nova's API call to neutron\nto delete the port binding.\nThis causes future attempts to perform live migration of the instance\nto the same host to fail.\n\nThis change removes port binding level object during port binding deletion.\n\n**missing unit tests\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}, {'number': 2, 'created': '2019-02-10 14:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d287e4951cd76b0bcb2f95de1b528bf29b83b94c', 'message': ""Delete port binding level for deleted bindings\n\nToday, if live migration has failed after an inactive\nbinding was created on the destination node but before\nthe activation of the created binding, the port's binding level\nfor the destination host is not cleared during nova's API call\nto neutron to delete the port binding.\n\nThis causes future attempts to perform live migration\nof the instance to the same host to fail.\n\nThis change removes port binding level object during port binding\ndeletion.\n\n**missing unit tests\n\nCloses-Bug: #1815345\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}, {'number': 3, 'created': '2019-02-11 13:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b2a1aec62ebe80890d7547713552cfc65b27d591', 'message': ""Delete port binding level for deleted bindings\n\nToday, if live migration has failed after an inactive\nbinding was created on the destination node but before\nthe activation of the created binding, the port's binding level\nfor the destination host is not cleared during nova's API call\nto neutron to delete the port binding.\n\nThis causes future attempts to perform live migration\nof the instance to the same host to fail.\n\nThis change removes port binding level object during port binding\ndeletion.\n\n**missing unit tests\n\nCloses-Bug: #1815345\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}, {'number': 4, 'created': '2019-02-13 12:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7486c53f23d7b83215951be6ecb393b4c93c9a4', 'message': ""Delete port binding level for deleted bindings\n\nToday, if live migration has failed after an inactive\nbinding was created on the destination node but before\nthe activation of the created binding, the port's binding level\nfor the destination host is not cleared during nova's API call\nto neutron to delete the port binding.\n\nThis causes future attempts to perform live migration\nof the instance to the same host to fail.\n\nThis change removes port binding level object during port binding\ndeletion.\n\n**missing unit tests\n\nCloses-Bug: #1815345\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}, {'number': 5, 'created': '2019-02-13 13:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/465767b3e1f77dbb5d2d7cd201a40b1229b2bf20', 'message': ""Delete port binding level for deleted bindings\n\nToday, if live migration has failed after an inactive\nbinding was created on the destination node but before\nthe activation of the created binding, the port's binding level\nfor the destination host is not cleared during nova's API call\nto neutron to delete the port binding.\n\nThis causes future attempts to perform live migration\nof the instance to the same host to fail.\n\nThis change removes port binding level object during port binding\ndeletion.\n\n**missing unit tests\n\nCloses-Bug: #1815345\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}, {'number': 6, 'created': '2019-02-13 14:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8743897ee378b426b2e1fce808d47966c09b808', 'message': ""Delete port binding level for deleted bindings\n\nToday, if live migration has failed after an inactive\nbinding was created on the destination node but before\nthe activation of the created binding, the port's binding level\nfor the destination host is not cleared during nova's API call\nto neutron to delete the port binding.\n\nThis causes future attempts to perform live migration\nof the instance to the same host to fail.\n\nThis change removes port binding level object during port binding\ndeletion.\n\nCloses-Bug: #1815345\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}, {'number': 7, 'created': '2019-03-03 10:30:43.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b197f7c1c4b9c0dd4c58f5c5a4b654dde5596b85', 'message': ""Delete port binding level for deleted bindings\n\nToday, if live migration has failed after an inactive\nbinding was created on the destination node but before\nthe activation of the created binding, the port's binding level\nfor the destination host is not cleared during nova's API call\nto neutron to delete the port binding.\n\nThis causes future attempts to perform live migration\nof the instance to the same host to fail.\n\nThis change removes port binding level object during port binding\ndeletion.\n\nCloses-Bug: #1815345\n\nChange-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5\n""}]",12,634276,b197f7c1c4b9c0dd4c58f5c5a4b654dde5596b85,55,13,7,28714,,,0,"Delete port binding level for deleted bindings

Today, if live migration has failed after an inactive
binding was created on the destination node but before
the activation of the created binding, the port's binding level
for the destination host is not cleared during nova's API call
to neutron to delete the port binding.

This causes future attempts to perform live migration
of the instance to the same host to fail.

This change removes port binding level object during port binding
deletion.

Closes-Bug: #1815345

Change-Id: Idd55f7d24a2062c08ac8a0dc2243625632d962a5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/634276/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,dd56db2dd55c36eea7f2564e7cc838378dbd42ae,bug/1815345," ports_obj.PortBinding.delete_objects(context, host=host, ports_obj.PortBindingLevel.delete_objects(context, host=host, port_id=port_id) # TODO(adrianc): need to perform checks before # deleting port binding levels ?"," ports_obj.PortBinding.delete_objects(context, host=host,",7,1
openstack%2Fneutron~master~I0a2ef52b13151a39e678e9a3e6f75babb47298d0,openstack/neutron,master,I0a2ef52b13151a39e678e9a3e6f75babb47298d0,Add QoS minimum egress bandwidth rule into ovs-agent,MERGED,2016-12-05 09:33:22.000000000,2019-03-05 15:35:18.000000000,2019-03-04 12:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8313}, {'_account_id': 8976}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 18051}, {'_account_id': 20330}, {'_account_id': 22348}, {'_account_id': 23266}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2016-12-05 09:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5fec50e2d645983779b4d2df2d198e3a43514c3', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n* The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n* Uses patch ports between bridges.\n* Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  * br-phy[] --> limited to physical bridges\n  * no tunneled traffic\n\nTODO:\n* Write devref\n* Add unit and functional test\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\nPartial-Bug: #1560963\n'}, {'number': 2, 'created': '2016-12-26 16:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8697cc47e3c8bb6c6c2de3d9af03e5989cebe636', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n* The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n* Uses patch ports between bridges.\n* Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  * br-phy[] --> limited to physical bridges\n  * no tunneled traffic\n\nTODO:\n* Write devref\n* Add unit and functional test\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\nPartial-Bug: #1560963\n'}, {'number': 3, 'created': '2018-11-08 17:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e239169b68b0d5753a98c426d44cfaf48f0bcf36', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n- The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n- Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  - phy-brs: limited to physical bridges\n  - no tunneled traffic\n\nTODO:\n* Write devref\n* Add unit and functional test\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\nPartial-Bug: #1560963\n'}, {'number': 4, 'created': '2018-11-08 19:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3a44a152e16f32539d0dd1c6c0d36d5c1c19b7d', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n- The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n- Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  - phy-brs: limited to physical bridges\n  - no tunneled traffic\n\nTODO:\n* Write devref\n* Add unit and functional test\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\nPartial-Bug: #1560963\n'}, {'number': 5, 'created': '2018-11-09 16:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fcfe64a065c9d79a609aa59ed726773ee0439caf', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n- The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n- Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  - phy-brs: limited to physical bridges\n  - no tunneled traffic\n\nTODO:\n* Write devref\n* Add unit and functional test\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\nPartial-Bug: #1560963\n'}, {'number': 6, 'created': '2018-11-27 11:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4639d2bba830b8945cc9faeccf5213029e99df6', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n- The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n- Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  - phy-brs: limited to physical bridges\n  - no tunneled traffic\n\nTODO:\n* Write devref\n* Add unit and functional test\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\nPartial-Bug: #1560963\n'}, {'number': 7, 'created': '2018-11-28 18:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/740988d3f9377c9db14b77712d37431dd266564f', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n- The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n- Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  - phy-brs: limited to physical bridges\n  - no tunneled traffic\n\nTODO:\n* Write devref\n* Add fullstack tests\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 8, 'created': '2018-11-29 10:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/446597ace73a9594c1d98349123285c59766041a', 'message': '[WIP] Add QoS minimum egress bandwidth rule into ovs-agent\n\nThis is POC for minimum egress bandwidth of ovs-agent.\n- The scope of this implementation is reduced to N/S\n  traffic. There is no QoS applied on traffic between\n  VMs.\n- Applies QoS policies (and rules) to exit ports\n  in bridges other than br-int:\n  - phy-brs: limited to physical bridges\n  - no tunneled traffic\n\nTODO:\n* Add fullstack tests\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 9, 'created': '2018-11-29 17:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca0f7e63e93c86c7c08ab40237b581dabf3d9c63', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 10, 'created': '2018-11-29 19:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01a0573f157b8fbe63686f3c253c2ca8895d011c', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 11, 'created': '2018-11-30 10:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b0b4b5836be5939677756971e304f6c398abf660', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 12, 'created': '2018-12-01 23:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c88fe59cd41d8ceecd5eae5c5989960fdde206b3', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 13, 'created': '2018-12-03 08:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/575b3ea3061f361fed53df0a1b48b6303d065618', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nDepends-On: https://review.openstack.org/#/c/620377/\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 14, 'created': '2018-12-21 16:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf363c05a5d0fab7305e60868f52b247bebcf5e6', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 15, 'created': '2018-12-24 17:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/509d81245777dce152c07203d7b4fd290486bcd0', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\n\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 16, 'created': '2018-12-25 15:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e71a222d3842c1ba7e0515300eae505a89ad892e', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 17, 'created': '2018-12-25 18:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1c3d0cd00a48d4253d5f65317fef6ac324b2aaa', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 18, 'created': '2018-12-25 20:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1809423462b12092a713499250b8eb19bc841f84', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 19, 'created': '2019-01-26 20:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a220e2f14bca8b99ed8872b8751f19229e115682', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 20, 'created': '2019-01-28 12:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58c44a80ee7a9455430ac281cdf6e1bcc563d51b', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 21, 'created': '2019-01-28 14:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/220c54e485509849b0db8b8adc97a66273b1059f', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}, {'number': 22, 'created': '2019-02-26 11:05:04.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/fullstack/resources/client.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_agent_extension_api.py', 'doc/source/admin/config-qos.rst', 'neutron/tests/functional/services/logapi/test_logging.py', 'neutron/tests/unit/agent/l2/extensions/test_qos.py', 'neutron/agent/common/ovs_lib.py', 'neutron/tests/unit/services/logapi/agent/test_log_extension.py', 'neutron/tests/fullstack/test_qos.py', 'neutron/tests/functional/agent/common/test_ovs_lib.py', 'neutron/tests/functional/agent/common/__init__.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_agent_extension_api.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/extension_drivers/test_qos_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc8808d539e9b40fe8c7b9b9001f146edc663203', 'message': 'Add QoS minimum egress bandwidth rule into ovs-agent\n\nAdd minimum egress bandwidth support for Open vSwitch.\n\nThe scope of this implementation is reduced to N/S traffic.\nThere is no QoS applied on traffic between VMs.\n\nThe QoS rules are aplied to exit ports in bridges other than\nbr-int; that means all physical bridges. No tunneled traffic\nwill be shaped. This feature will be implemented in a following\npatch.\n\nPartial-Bug: #1560963\nChange-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0\n'}]",22,406841,cc8808d539e9b40fe8c7b9b9001f146edc663203,138,23,22,16688,,,0,"Add QoS minimum egress bandwidth rule into ovs-agent

Add minimum egress bandwidth support for Open vSwitch.

The scope of this implementation is reduced to N/S traffic.
There is no QoS applied on traffic between VMs.

The QoS rules are aplied to exit ports in bridges other than
br-int; that means all physical bridges. No tunneled traffic
will be shaped. This feature will be implemented in a following
patch.

Partial-Bug: #1560963
Change-Id: I0a2ef52b13151a39e678e9a3e6f75babb47298d0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/406841/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/common/ovs_lib.py', 'releasenotes/notes/qos-min-egress-bw-rule-b1c80f5675a4c1c3.yaml', 'doc/source/devref/quality_of_service.rst', 'neutron/plugins/ml2/drivers/openvswitch/agent/extension_drivers/qos_driver.py', 'neutron/plugins/ml2/drivers/openvswitch/mech_driver/mech_openvswitch.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_agent_extension_api.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/extension_drivers/test_qos_driver.py']",8,c5fec50e2d645983779b4d2df2d198e3a43514c3,bug/1560963," self.qos_driver._minimum_bandwidth_initialize = mock.Mock() self._create_dscp_marking_rule_obj(), self._create_minimum_bandwidth_rule_obj()] def _create_minimum_bandwidth_rule_obj(self): rule_obj = rule.QosMinimumBandwidthRule() rule_obj.id = uuidutils.generate_uuid() rule_obj.min_kbps = 10000 rule_obj.obj_reset_changes() return rule_obj ofport = 1 self._assert_minimum_bandwidth_rule_create_updated() self._assert_minimum_bandwidth_rule_create_updated() self._assert_minimum_bandwidth_rule_create_updated() self._assert_minimum_bandwidth_rule_deleted() self._assert_minimum_bandwidth_rule_deleted() self.qos_driver.br_int.method_calls[-2][0]) def _assert_minimum_bandwidth_rule_create_updated(self): (self.qos_driver.br_int.update_minimum_bandwidth_queue. assert_called_once_with(self.port['port_id'], self.rules[2].min_kbps, self.port['vif_port'].ofport)) def _assert_minimum_bandwidth_rule_deleted(self): (self.qos_driver.br_int.delete_minimum_bandwidth_queue. assert_called_once_with(self.port['port_id']))", self._create_dscp_marking_rule_obj()] self.qos_driver.br_int.method_calls[-1][0]),274,22
openstack%2Fironic-python-agent~master~I6fe33b2f17c742d57d19985169cd9800007b5768,openstack/ironic-python-agent,master,I6fe33b2f17c742d57d19985169cd9800007b5768,Replace ZUUL_REFNAME for zuul.branch,MERGED,2019-03-05 13:05:39.000000000,2019-03-05 15:33:20.000000000,2019-03-05 15:33:20.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 13:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f23d038d87186742b24368554b1a8d319099381e', 'message': 'Replace ZUUL_REFNAME for zuul.branch\n\nReplace `ZUUL_REFNAME` in favor of `zuul.brach` to get the correct\nbranch name when building images.\n\nChange-Id: I6fe33b2f17c742d57d19985169cd9800007b5768\n'}, {'number': 2, 'created': '2019-03-05 13:13:21.000000000', 'files': ['playbooks/ironic-python-agent-buildimage/run.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/37fce96531b64d920290ce7eb2dcb512c7544c7f', 'message': 'Replace ZUUL_REFNAME for zuul.branch\n\nReplace `ZUUL_REFNAME` in favor of `zuul.branch` to get the correct\nbranch name when building images.\n\nChange-Id: I6fe33b2f17c742d57d19985169cd9800007b5768\n'}]",4,641007,37fce96531b64d920290ce7eb2dcb512c7544c7f,12,3,2,15519,,,0,"Replace ZUUL_REFNAME for zuul.branch

Replace `ZUUL_REFNAME` in favor of `zuul.branch` to get the correct
branch name when building images.

Change-Id: I6fe33b2f17c742d57d19985169cd9800007b5768
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/07/641007/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/ironic-python-agent-buildimage/run.yaml'],1,f23d038d87186742b24368554b1a8d319099381e,ZUUL_REFNAME, BRANCH={{ zuul.branch }}, BRANCH=$ZUUL_REFNAME,1,1
openstack%2Fmasakari~master~Ica030c540970474cd2511ffe0ba653d7bb057849,openstack/masakari,master,Ica030c540970474cd2511ffe0ba653d7bb057849,Py3: Ensure wsgi headers are not bytes type,MERGED,2019-02-13 20:28:23.000000000,2019-03-05 15:25:21.000000000,2019-03-05 00:08:04.000000000,"[{'_account_id': 1011}, {'_account_id': 8716}, {'_account_id': 22348}, {'_account_id': 25267}, {'_account_id': 27302}]","[{'number': 1, 'created': '2019-02-13 20:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/8b5bc112c8ad6640df328c08eab9ebc72cef5223', 'message': 'Py3: Ensure wsgi headers are not bytes type\n\nIn Python 3, running the Masakari API as a wsgi application was\nresulting in ""TypeError: expected unicode object, value of type\nbytes found"". It looks like headerlist should not include bytes\ntype objects so let\'s ensure they are str objects for Python 3.\n\nChange-Id: Ica030c540970474cd2511ffe0ba653d7bb057849\nPartial-Bug: #1815657\n'}, {'number': 2, 'created': '2019-03-04 15:58:11.000000000', 'files': ['masakari/tests/unit/api/openstack/test_wsgi.py', 'masakari/api/openstack/wsgi.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/041af276d725456cdf6e45d09a013e38188d803d', 'message': 'Py3: Ensure wsgi headers are not bytes type\n\nIn Python 3, running the Masakari API as a wsgi application was\nresulting in ""TypeError: expected unicode object, value of type\nbytes found"". It looks like headerlist should not include bytes\ntype objects so let\'s ensure they are str objects for Python 3.\n\nChange-Id: Ica030c540970474cd2511ffe0ba653d7bb057849\nPartial-Bug: #1815657\n'}]",0,636749,041af276d725456cdf6e45d09a013e38188d803d,29,5,2,11805,,,0,"Py3: Ensure wsgi headers are not bytes type

In Python 3, running the Masakari API as a wsgi application was
resulting in ""TypeError: expected unicode object, value of type
bytes found"". It looks like headerlist should not include bytes
type objects so let's ensure they are str objects for Python 3.

Change-Id: Ica030c540970474cd2511ffe0ba653d7bb057849
Partial-Bug: #1815657
",git fetch https://review.opendev.org/openstack/masakari refs/changes/49/636749/1 && git format-patch -1 --stdout FETCH_HEAD,"['masakari/tests/unit/api/openstack/test_wsgi.py', 'masakari/api/openstack/wsgi.py']",2,8b5bc112c8ad6640df328c08eab9ebc72cef5223,bug/1815657," if six.PY3: response.headers['Content-Length'] = (str( response.headers['Content-Length'])) else: # NOTE: we need to encode 'Content-Length' header, since # webob.Response auto sets it if ""body"" attr is presented. # github.com/Pylons/webob/blob/1.5.0b0/webob/response.py#L147 response.headers['Content-Length'] = utils.utf8( response.headers['Content-Length']) if six.PY3: response.headers[hdr] = str(value) else: response.headers[hdr] = utils.utf8(value) if six.PY3: response.headers['Content-Type'] = str(content_type) else: response.headers['Content-Type'] = utils.utf8(content_type) if six.PY3: response.headers[hdr] = str(val) else: # Headers must be utf-8 strings response.headers[hdr] = utils.utf8(val)"," # NOTE: we need to encode 'Content-Length' header, # since webob.Response auto sets it if ""body"" attr is presented. # https://github.com/Pylons/webob/blob/1.5.0b0/webob/response.py#L147 response.headers['Content-Length'] = utils.utf8( response.headers['Content-Length']) response.headers[hdr] = utils.utf8(value) response.headers['Content-Type'] = utils.utf8(content_type) # Headers must be utf-8 strings response.headers[hdr] = utils.utf8(val)",36,16
openstack%2Fnova~master~Id68aa27a8ab08d9c00655e5ed6b48d194aa8e6f6,openstack/nova,master,Id68aa27a8ab08d9c00655e5ed6b48d194aa8e6f6,Fixes race condition with privsep utime,MERGED,2018-12-18 00:47:58.000000000,2019-03-05 15:24:46.000000000,2019-03-04 14:00:27.000000000,"[{'_account_id': 2271}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 13734}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16771}, {'_account_id': 17216}, {'_account_id': 17280}, {'_account_id': 19684}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-18 00:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a901e147e0eef5b052d3f3357d223184ad53ce9', 'message': '[WIP] Fixes race condition with privsep utime\n\nThere is a race condition that occurs over NFS when multiple instances\nare beling created where utime fails, due to some other process\nmodifying the file path. This patch locks the file to ensure it can\nmodify the times.\n\nChange-Id: Id68aa27a8ab08d9c00655e5ed6b48d194aa8e6f6\nSigned-off-by: Tim Rozet <trozet@redhat.com>\n'}, {'number': 2, 'created': '2018-12-19 18:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07ed1c3292b46ecddd32ba22386795df732f77a0', 'message': 'Fixes race condition with privsep utime\n\nThere is a race condition that occurs over NFS when multiple instances\nare being created where utime fails, due to some other process\nmodifying the file path. This patch locks the file to ensure it can\nmodify the times.\n\nCloses-Bug: 1809123\n\nChange-Id: Id68aa27a8ab08d9c00655e5ed6b48d194aa8e6f6\nSigned-off-by: Tim Rozet <trozet@redhat.com>\n'}, {'number': 3, 'created': '2019-03-01 21:44:43.000000000', 'files': ['releasenotes/notes/fix-image-utime-race-condition-3c404e272ea91b34.yaml', 'nova/privsep/path.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/525631d8dc058910728e55def616358b0e7f2f69', 'message': 'Fixes race condition with privsep utime\n\nThere is a race condition that occurs over NFS when multiple instances\nare being created where utime fails, due to some other process\nmodifying the file path. This patch ensures the path is created and\nis readable before attempting to modify with utime.\n\nCloses-Bug: 1809123\n\nChange-Id: Id68aa27a8ab08d9c00655e5ed6b48d194aa8e6f6\nSigned-off-by: Tim Rozet <trozet@redhat.com>\n'}]",11,625741,525631d8dc058910728e55def616358b0e7f2f69,58,21,3,17280,,,0,"Fixes race condition with privsep utime

There is a race condition that occurs over NFS when multiple instances
are being created where utime fails, due to some other process
modifying the file path. This patch ensures the path is created and
is readable before attempting to modify with utime.

Closes-Bug: 1809123

Change-Id: Id68aa27a8ab08d9c00655e5ed6b48d194aa8e6f6
Signed-off-by: Tim Rozet <trozet@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/625741/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/privsep/path.py'],1,1a901e147e0eef5b052d3f3357d223184ad53ce9,bug/1809123," with open(path, 'a'): os.utime(path, None)"," # NOTE(mikal): the old version of this used execute(touch, ...), which # would apparently fail on shared storage when multiple instances were # being launched at the same time. If we see failures here, we might need # to wrap this in a try / except. os.utime(path, None)",2,6
openstack%2Frpm-packaging~master~I8d286fb556221ed3de59e5d6f69e7e44283c7582,openstack/rpm-packaging,master,I8d286fb556221ed3de59e5d6f69e7e44283c7582,stevedore: Update to 1.30.1,MERGED,2019-03-05 05:25:35.000000000,2019-03-05 15:14:54.000000000,2019-03-05 15:14:54.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 05:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fdcd987ce8a68fb073e91411b88098a25e7a41da', 'message': 'stevedore: Update to 1.30.1\n\nChange-Id: I8d286fb556221ed3de59e5d6f69e7e44283c7582\n'}, {'number': 2, 'created': '2019-03-05 07:49:28.000000000', 'files': ['openstack/stevedore/stevedore.spec.j2', 'openstack/stevedore/0001-Make-openstackdocstheme-an-optional-doc-dependency.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5258773c237e7f83d9b8979c3f8519641ad00d7a', 'message': 'stevedore: Update to 1.30.1\n\nChange-Id: I8d286fb556221ed3de59e5d6f69e7e44283c7582\n'}]",0,640938,5258773c237e7f83d9b8979c3f8519641ad00d7a,13,5,2,7102,,,0,"stevedore: Update to 1.30.1

Change-Id: I8d286fb556221ed3de59e5d6f69e7e44283c7582
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/38/640938/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/stevedore/stevedore.spec.j2', 'openstack/stevedore/0001-Make-openstackdocstheme-an-optional-doc-dependency.patch']",2,fdcd987ce8a68fb073e91411b88098a25e7a41da,,,"From f9503f1a3069c4a151c8f35f942f892f09451263 Mon Sep 17 00:00:00 2001 From: Thomas Bechtold <tbechtold@suse.com> Date: Wed, 23 Aug 2017 08:30:23 +0200 Subject: [PATCH 1/2] Make openstackdocstheme an optional doc dependency stevedore is a library that is used outside of OpenStack, too. Having a build requirement that needs something OpenStack specific makes life in cases (eg. for downstream packagers) more difficult. So let's make openstackdocstheme an optional requirement. Change-Id: Ic8cc577e617e5da699f9dc43830183005bd2ee66 --- doc/source/conf.py | 16 ++++++++++++++-- setup.cfg | 8 ++++++++ test-requirements.txt | 1 - tox.ini | 1 + 4 files changed, 23 insertions(+), 3 deletions(-) Index: stevedore-1.25.0/doc/source/conf.py =================================================================== --- stevedore-1.25.0.orig/doc/source/conf.py +++ stevedore-1.25.0/doc/source/conf.py @@ -14,6 +14,16 @@ import datetime import subprocess +# make openstackdocstheme an optional dependency. stevedore is a low level lib +# that is used outside of OpenStack. Not having something OpenStack specific +# as build requirement is a good thing. +try: + import openstackdocstheme +except ImportError: + has_openstackdocstheme = False +else: + has_openstackdocstheme = True + # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. @@ -31,9 +41,10 @@ extensions = [ 'sphinx.ext.todo', 'sphinx.ext.graphviz', 'sphinx.ext.extlinks', - 'openstackdocstheme', 'stevedore.sphinxext', ] +if has_openstackdocstheme: + extensions.append('openstackdocstheme') # openstackdocstheme options repository_name = 'openstack/stevedore' @@ -108,7 +119,8 @@ pygments_style = 'sphinx' # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. #html_theme = 'default' -html_theme = 'openstackdocs' +if has_openstackdocstheme: + html_theme = 'openstackdocs' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the Index: stevedore-1.25.0/setup.cfg =================================================================== --- stevedore-1.25.0.orig/setup.cfg +++ stevedore-1.25.0/setup.cfg @@ -16,6 +16,14 @@ classifier = Intended Audience :: Developers Environment :: Console +[extras] +docs = + # make openstackdocstheme an optional dependency. stevedore is a low level + # lib that is used outside of OpenStack. Not having something OpenStack + # specific as build requirement is a good thing. + openstackdocstheme>=1.16.0 # Apache-2.0 + + [global] setup-hooks = pbr.hooks.setup_hook Index: stevedore-1.25.0/test-requirements.txt =================================================================== --- stevedore-1.25.0.orig/test-requirements.txt +++ stevedore-1.25.0/test-requirements.txt @@ -7,5 +7,4 @@ sphinx>=1.6.2 # BSD mock>=2.0 # BSD coverage!=4.4,>=4.0 # Apache-2.0 testrepository>=0.0.18 # Apache-2.0/BSD -openstackdocstheme>=1.11.0 # Apache-2.0 reno!=2.3.1,>=1.8.0 # Apache-2.0 Index: stevedore-1.25.0/tox.ini =================================================================== --- stevedore-1.25.0.orig/tox.ini +++ stevedore-1.25.0/tox.ini @@ -10,6 +10,7 @@ setenv = install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} deps = -r{toxinidir}/test-requirements.txt + .[docs] distribute = False commands = python setup.py testr --testr-args='{posargs}' ",1,103
openstack%2Fcharm-nova-cloud-controller~stable%2F18.11~I4d4367ef20e2a20aee1e26d4a0ec69cad2ac69d6,openstack/charm-nova-cloud-controller,stable/18.11,I4d4367ef20e2a20aee1e26d4a0ec69cad2ac69d6,Disable BuildFailureWeigher,MERGED,2019-03-05 09:26:58.000000000,2019-03-05 15:09:03.000000000,2019-03-05 15:09:03.000000000,"[{'_account_id': 935}, {'_account_id': 6737}, {'_account_id': 11805}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 09:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/e6abaae33e21d228b7dee8128cba2bdc63af8190', 'message': ""Disable BuildFailureWeigher\n\nDisable the BuildFailureWeigher used when weighting hosts during\ninstance scheduling. A single build failure will result in a\n-1000000 weighting which effectively excludes the hypervisor\nfrom the scheduling decision.\n\nA bad image can result in build failures resulting in a heavy\nload on hypervisors which have not had a build failure with\nthose that have effectively being ignored; the build failure\ncount will be reset on a successful build but due to the high\nweighting this won't happen until all resources on known good\nhypervisors have been completely consumed.\n\nChange-Id: I4d4367ef20e2a20aee1e26d4a0ec69cad2ac69d6\nCloses-Bug: 1818239\n(cherry picked from commit c5029e9831ab5063485877213987d6827c4d86f1)\n""}, {'number': 2, 'created': '2019-03-05 12:42:52.000000000', 'files': ['templates/pike/nova.conf', 'templates/rocky/nova.conf'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/56de84a81be00bf9ddffca4426d28c17d5d9798e', 'message': ""Disable BuildFailureWeigher\n\nDisable the BuildFailureWeigher used when weighting hosts during\ninstance scheduling. A single build failure will result in a\n-1000000 weighting which effectively excludes the hypervisor\nfrom the scheduling decision.\n\nA bad image can result in build failures resulting in a heavy\nload on hypervisors which have not had a build failure with\nthose that have effectively being ignored; the build failure\ncount will be reset on a successful build but due to the high\nweighting this won't happen until all resources on known good\nhypervisors have been completely consumed.\n\nChange-Id: I4d4367ef20e2a20aee1e26d4a0ec69cad2ac69d6\nCloses-Bug: 1818239\n(cherry picked from commit c5029e9831ab5063485877213987d6827c4d86f1)\n""}]",0,640961,56de84a81be00bf9ddffca4426d28c17d5d9798e,14,6,2,935,,,0,"Disable BuildFailureWeigher

Disable the BuildFailureWeigher used when weighting hosts during
instance scheduling. A single build failure will result in a
-1000000 weighting which effectively excludes the hypervisor
from the scheduling decision.

A bad image can result in build failures resulting in a heavy
load on hypervisors which have not had a build failure with
those that have effectively being ignored; the build failure
count will be reset on a successful build but due to the high
weighting this won't happen until all resources on known good
hypervisors have been completely consumed.

Change-Id: I4d4367ef20e2a20aee1e26d4a0ec69cad2ac69d6
Closes-Bug: 1818239
(cherry picked from commit c5029e9831ab5063485877213987d6827c4d86f1)
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/61/640961/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/pike/nova.conf', 'templates/rocky/nova.conf']",2,e6abaae33e21d228b7dee8128cba2bdc63af8190,bug/1818239,"# Disable BuildFailureWeigher as any failed build will result # in a very low weighting for the hypervisor, resulting in # instances all being scheduled to hypervisors with no build # failures. # https://bugs.launchpad.net/charm-nova-cloud-controller/+bug/1818239 build_failure_weight_multiplier = 0.0 ",,14,0
openstack%2Freleases~master~Ib8d8a76c6bbbd7b0028c0c1d6e0b5d750c8d22b1,openstack/releases,master,Ib8d8a76c6bbbd7b0028c0c1d6e0b5d750c8d22b1,Critical release of keystoneauth 3.13.1,MERGED,2019-03-05 14:42:15.000000000,2019-03-05 15:05:35.000000000,2019-03-05 15:05:34.000000000,"[{'_account_id': 5046}, {'_account_id': 11904}, {'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 14:42:15.000000000', 'files': ['deliverables/stein/keystoneauth.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/2761f722123ca622ace10ffa0ddae79bd7c1dc4b', 'message': 'Critical release of keystoneauth 3.13.1\n\nWithout this release, unit tests for python-keystoneclient fail.\n\nChange-Id: Ib8d8a76c6bbbd7b0028c0c1d6e0b5d750c8d22b1\n'}]",0,641024,2761f722123ca622ace10ffa0ddae79bd7c1dc4b,8,4,1,8482,,,0,"Critical release of keystoneauth 3.13.1

Without this release, unit tests for python-keystoneclient fail.

Change-Id: Ib8d8a76c6bbbd7b0028c0c1d6e0b5d750c8d22b1
",git fetch https://review.opendev.org/openstack/releases refs/changes/24/641024/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/keystoneauth.yaml'],1,2761f722123ca622ace10ffa0ddae79bd7c1dc4b,release-ksa-3.13.1, - projects: - hash: bde07bc95b5b5d16b829f72be7aaa62fab9d716a repo: openstack/keystoneauth tarball-base: keystoneauth1 version: 3.13.1,,5,0
openstack%2Fsearchlight~master~I2144d6925ecb13762707120213f50f36a26d9c59,openstack/searchlight,master,I2144d6925ecb13762707120213f50f36a26d9c59,Add Dockerfile and docker-compose.yml to run searchlight      in docker containers,MERGED,2019-02-13 10:41:25.000000000,2019-03-05 14:58:30.000000000,2019-03-05 14:58:30.000000000,"[{'_account_id': 22348}, {'_account_id': 27068}, {'_account_id': 27488}, {'_account_id': 29228}]","[{'number': 1, 'created': '2019-02-13 10:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/2f35be6cf11d5e26094b4ad1c12abdcfaa363af1', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 2, 'created': '2019-03-04 13:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/6b0c8319af2adc6084a3617427f0b0d377ad3d33', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 3, 'created': '2019-03-04 14:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/3ea6c0273d0022177402fdafa44f7ecac32b3976', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 4, 'created': '2019-03-04 14:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/df02b981c7cbdb58da623bcb3720f13b773a4c55', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 5, 'created': '2019-03-04 15:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/d2d8a5e2633b45be1a7a11f65515b8a62fa18c54', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 6, 'created': '2019-03-04 23:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/25eae483d2bfa9f975cdc919b5b788acd6db1621', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 7, 'created': '2019-03-05 08:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/ed4e4357305eca7314d6c0284c67fa74c19ee49a', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 8, 'created': '2019-03-05 13:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/c1550522f7007a10f535415013acb77cd28b6a42', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}, {'number': 9, 'created': '2019-03-05 13:57:58.000000000', 'files': ['contrib/docker/docker-compose.example.yml', 'contrib/docker/Dockerfile', 'contrib/docker/README.rst', 'contrib/docker/entrypoint.sh', 'contrib/docker/searchlight.conf'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/7038886a8bdb0d3a263cfc25e1bd24f5efa196ad', 'message': 'Add Dockerfile and docker-compose.yml to run searchlight\n     in docker containers\n\nChange-Id: I2144d6925ecb13762707120213f50f36a26d9c59\n'}]",33,636587,7038886a8bdb0d3a263cfc25e1bd24f5efa196ad,30,4,9,27488,,,0,"Add Dockerfile and docker-compose.yml to run searchlight
     in docker containers

Change-Id: I2144d6925ecb13762707120213f50f36a26d9c59
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/87/636587/6 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/docker/Dockerfile', 'contrib/docker/entrypoint.sh', 'contrib/docker/searchlight.conf', 'contrib/docker/README.md']",4,2f35be6cf11d5e26094b4ad1c12abdcfaa363af1,,,,106,0
openstack%2Ftempest-lib~master~Iac7cad253e92ff19b7ad47ed0419688a53f7f83b,openstack/tempest-lib,master,Iac7cad253e92ff19b7ad47ed0419688a53f7f83b,Update json module to jsonutils,ABANDONED,2019-02-24 14:23:52.000000000,2019-03-05 14:58:07.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-24 14:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/0a1aca6f00b81fc09b875b481a51e8d3d70cb83a', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and tempest-lib use it in many place[1],\nthis PS to update the remained json moudule to oslo jsonutils for\nconsistency.\n\n[1]: https://github.com/openstack/tempest-lib/search?utf8=%E2%9C%93&q=jsonutils&type=\n\nChange-Id: Iac7cad253e92ff19b7ad47ed0419688a53f7f83b\n'}, {'number': 2, 'created': '2019-02-24 14:29:38.000000000', 'files': ['tempest_lib/tests/fake_identity.py', 'tempest_lib/tests/services/identity/v3/test_token_client.py', 'tempest_lib/tests/test_rest_client.py', 'tempest_lib/tests/services/identity/v2/test_token_client.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/efd56914a29de8ea4a0f5c17ca2135abe7ed7794', 'message': 'Update json module to jsonutils\n\noslo project provide jsonutils, and tempest-lib use it in many place[1],\nthis PS to update the remained json moudule to oslo jsonutils for\nconsistency.\n\n[1]: https://github.com/openstack/tempest-lib/search?utf8=%E2%9C%93&q=jsonutils&type=\n\nChange-Id: Iac7cad253e92ff19b7ad47ed0419688a53f7f83b\n'}]",0,638958,efd56914a29de8ea4a0f5c17ca2135abe7ed7794,6,2,2,22165,,,0,"Update json module to jsonutils

oslo project provide jsonutils, and tempest-lib use it in many place[1],
this PS to update the remained json moudule to oslo jsonutils for
consistency.

[1]: https://github.com/openstack/tempest-lib/search?utf8=%E2%9C%93&q=jsonutils&type=

Change-Id: Iac7cad253e92ff19b7ad47ed0419688a53f7f83b
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/58/638958/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/tests/fake_identity.py', 'tempest_lib/tests/services/identity/v3/test_token_client.py', 'tempest_lib/tests/test_rest_client.py', 'tempest_lib/tests/services/identity/v2/test_token_client.py']",4,0a1aca6f00b81fc09b875b481a51e8d3d70cb83a,,from oslo_serialization import jsonutils as json,import json ,4,6
openstack%2Fopenstack-helm-images~master~I340f25bb19896b691dccfca6a4e14e223c031174,openstack/openstack-helm-images,master,I340f25bb19896b691dccfca6a4e14e223c031174,Zuul: Update dockerhub credentials and remove newline from secret,MERGED,2019-03-04 15:24:49.000000000,2019-03-05 14:55:26.000000000,2019-03-05 14:55:26.000000000,"[{'_account_id': 17068}, {'_account_id': 17591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 15:24:49.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d276d54d05f51e63c1e747b4cbeda57bbfe0bef7', 'message': 'Zuul: Update dockerhub credentials and remove newline from secret\n\nThis PS updates the credentials used for dockerhub pushes and also\nremoves any newlines from them.\n\nChange-Id: I340f25bb19896b691dccfca6a4e14e223c031174\nSigned-off-by: Pete Birley <pete@port.direct>\n'}]",0,640782,d276d54d05f51e63c1e747b4cbeda57bbfe0bef7,8,3,1,23928,,,0,"Zuul: Update dockerhub credentials and remove newline from secret

This PS updates the credentials used for dockerhub pushes and also
removes any newlines from them.

Change-Id: I340f25bb19896b691dccfca6a4e14e223c031174
Signed-off-by: Pete Birley <pete@port.direct>
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/82/640782/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,d276d54d05f51e63c1e747b4cbeda57bbfe0bef7,update-creds, - RToLVrVSLl4ih5OcfL/AnemDTVLsg+TLijXniZ+MPK8h332v813CRMH2vVFf7zZxVw+fA rjVjonkSaNkseXlGd9+psv8gRvxV5qg63emxFtpARSJiS7HgyOdBUy4ZhsrweF7F1KfH1 LNKXoaYdDCn7UcP/YaqYBkr2UQ/F0t7Yu6ACjdQYUr3FKh8XfAhrUtcc+uAv7broiIxKq LRi7UTXa1NEpA0rH0dLep5eNKQBpiXo/7cF3fCIMJ8oCGTZToaUkJfoqax96g/oncpf+a wQvlML5WN7YrB5Fi9RkylOVkCOUJcO5HUeFWpfcnPsvwELulpIKnxLlLxR94ZM0ZmCNcI of8yyEAoxCOHOLYZcKNSKjWl6rMmKElTEeedqiJniBSWRwxz7/pj27fQKHDJPfPSXgfqU GNkOLBHdK03idEL39G3rvPKt+lR5xV29iX5EH03VoJoKUBoeggxkC9/3/DcjZ2M8hUD7Q IM5UjMV1Lgo5apodGZu5tUfaoCMPN4xHCzI2vZZ08ZP5952opp9A4c/OLKOUDHV63qei5 e2SA8BBtvz/eiUWhLhwMHZK18XqsB8vLZNeO8BUDS5oOfw8YYaEfm3t3hqXNn7khWNlT6 MAn3KrFsslsP7ENNFHIxIy4eVXDoDtG90CZWReM2cLdGnbQa2YLdwjjPWN6tlc= - GPDRxEQwaaFK7427kQByOYoEzcAXvNkGJKcBhoiwXPZ2V2taDH3vZWMDByfWLPDp7HTNp MHIJqeGE446EtO+eGmDNFuXHDCbwEwBIGd27QNNKGdmYAXlrU5dxKaoChra+8gcxsXYxJ FlNlfdMqz3Dt+ZTA7f68db9T/hBm2PDAuJml2dHsHCQg5yFljZADcNvbRV4PPf/9SylMa wJPI6XAbzo/bTBnMmsn5u6ovlrIBkO+OMdYQ2Bd22GZkOoUo04M7mz10kPTeSCaGI10b2 LR1eN7thS+1ViB+VqoecZ3yOf3KgU9KmVsLkmEGfJUjBXV7dfWZsCvzSM/72WE6yjybQ3 iwhpiKVr8EmZAePgiEvjfI/eFcDp+BCfn7fjA5vpJ1qhYXx6WX+IebC8bQ/SfDBXz2kgI kgeCOCqszqR6z/lF//j6ttIIKMGM/OV8AVN8mSwqbx9x6W9y0wFX+Qr4awDcHV0eVJelA aYZxpgceCShEZp54yIVNjDoe01m8UpDDSSj7qtaehX+5U8vKd6lWOf13YEVIfaYUCoNaK Zp1xo0hJ2T2/8FGY/+sgZtjXJ4SETyTTw0kzQy/Ias8h63YIsDi7cQ2Yx48rGtugxArTD Kkrob2q6wFLBIutk8NgfXUy0oLClufRmHidne4XB0VLHeykuxKjiujGm+O9AcQ=, - ElBadZeuRFwbxgDHz+TOCdpaqHMAAA0E2WYnplrREC3ndO25CB0zmoBUaYMHObnykM1Yv K/bcfWtlcj8Ucz/U8KIDPBVED7T4OqhhUeIIc+8cw5QuQ9now0ltk8S0/fdJ0qHmNypz9 lnbhE0Ir7NPWCSHRIE61BasVcem5QPMre9rNy91rCby8r0+onHlyArRAIoxF3V5Y6DazC DeUDw8fIYZsIfMa5/uuGLf1PW4xCyLhiOiZ0Sr0e454l68tjGGniPpYGIxnjAMKy+hwSb dTX+wc+GP7/7XJnQJ3JcGKt5fYrGgkdzljUeMndfMuKq5WBXkH1EaT6YWJ6V7qAzQk3WN 0QHNO80Wa4Uu8Yyyeh9HFXut5VCKLQGOObG8t7Rw75Yf4TXKdFCQKRZ/ecV7KSGFNWh5i 4zvgxCwIcv06TX14PcqUJAC8WAWbtUXWhmVgVSPA1B8DU9o8sBVH5CqwgMg32gzQwrDdN 8hf3ErWSPVIqtpLZ3SgsnvgUl3W43wwafxp5pMcFEvZS2iG6Ty89BukzEu/xYNEwaS/ys nvpe+El8VBXuB2ZlgwOXyEzgSdzInibTQsLdCyHGWJ1jy+m0R48GjllCCggjAUzqL9o7e jPPb8mfq+jHs9LJVJLYI5tRVYEd4GxoK/1c1LO5v9ixeyKj3PWWBHv54gJ6F74= - OWlZwPHSDB5+E0dDwR9cfRpeoODFtOm6L1VztzvQYShQNce6i0iLHpJ6dUyk1HXSFG53t hOQ++q5DHpqV8SCZIYgmcDGrw+EhIlYBINxNL94MlkPNz6YYaemAATdP1kzFmCjlQBRB5 z2CyrTs0gTdOjAKdP1GEBQPKdllt0iw0px3il2ux5fNM2WZuc5Vs0mOXa4+OFioUMCUn7 KBlSzuVkhYCynvZb/cKDUqsNAuu6RINv/J/OmYbSw0aUxmDHtJ//U8lFHA8YBNUVInQZV HidTyJxBEVLrqqwQPESV1ZB1K0ydeq2rYq5ebrfnl4TyYAOH/Tegg36Tlc8dPebddPaOk 38+9KJ25xWpVvFs/83MYxxEdLiUztv3FyxE51yd6gDZ4146l8Vc89VLdi35ce4TVsys0A 80yfr/mi6U0xIEzhoxqaDPpAE65lQ1zFdz7/10JiZiwlgEKrzjiAKy7gYbdfnWhBz0YaA U+qKRpWX2r+mOrsyBC6TR3fkCofai11VuL3wwJm37wNteUN9WXTWB61CoDKmuMISKwCxf zP68/8zIekxwRuqKM9aQrqmPg7TEX/GEj7hpUTW/OO6wPktkHX+I6e+FtNTtL33TNRAbh /MlQspgCDU2QL/2JvfkXxOwxEe143a8vEn6NMyRuQM7gpIB6yeK29bCgXcH3x8=,20,20
openstack%2Fopenstack-chef~stable%2Fqueens~I1aa9411099c8d019c6f50863eeb5ba3503d0e9a6,openstack/openstack-chef,stable/queens,I1aa9411099c8d019c6f50863eeb5ba3503d0e9a6,Pin apache2 cookbook,ABANDONED,2019-03-05 12:36:34.000000000,2019-03-05 14:44:36.000000000,,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 12:36:34.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/2d63749bd6001ae2f5de17dd7a20598fecd336c9', 'message': 'Pin apache2 cookbook\n\nThere is a new version 6.0.0 released that breaks things.\n\nChange-Id: I1aa9411099c8d019c6f50863eeb5ba3503d0e9a6\n'}]",0,641002,2d63749bd6001ae2f5de17dd7a20598fecd336c9,4,2,1,13252,,,0,"Pin apache2 cookbook

There is a new version 6.0.0 released that breaks things.

Change-Id: I1aa9411099c8d019c6f50863eeb5ba3503d0e9a6
",git fetch https://review.opendev.org/openstack/openstack-chef refs/changes/02/641002/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,2d63749bd6001ae2f5de17dd7a20598fecd336c9,pin-apache2-queens," cookbook 'apache2', '< 6'",,2,0
openstack%2Ftripleo-common~master~Iab6218fb263cdc2a9b707166e904ff26bd113c6c,openstack/tripleo-common,master,Iab6218fb263cdc2a9b707166e904ff26bd113c6c,Warning cleanup in TestConfig,MERGED,2019-02-27 19:06:49.000000000,2019-03-05 14:43:25.000000000,2019-03-05 14:43:24.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 13039}, {'_account_id': 14985}, {'_account_id': 16282}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-27 19:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/628f66f238a892b68b3eff2cdbaf6d68d45d25d2', 'message': ""Warning cleanup in TestConfig\n\nwhen running tox for the unittests\n\nTestConfig was generating 95 ResourceWarnings\n\n$ tox -e py36 tripleo_common.tests.utils.test_config.TestConfig | grep ResourceWarning | wc -l\n95\n\nAfter this patch\n\n$ tox -e py36 tripleo_common.tests.utils.test_config.TestConfig | grep ResourceWarning | wc -l\n18\n\nExample Warning:\ntripleo_common/tests/utils/test_config.py:667: ResourceWarning: unclosed file\n<_io.TextIOWrapper name='/tmp/tmpyzh4ejn6/tmpvxwydwti/group_vars/Controller' mode='r' encoding='UTF-8'>\n  open(os.path.join(config_dir, 'group_vars', f)).read()),\n\nChange-Id: Iab6218fb263cdc2a9b707166e904ff26bd113c6c\n""}, {'number': 2, 'created': '2019-02-28 10:31:50.000000000', 'files': ['tripleo_common/tests/utils/test_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/948a5f0c48fc003188e7b45ea792f6568eebdadf', 'message': ""Warning cleanup in TestConfig\n\nwhen running tox for the unittests\n\nTestConfig was generating 95 ResourceWarnings\n\n$ tox -e py36 tripleo_common.tests.utils.test_config.TestConfig | grep ResourceWarning | wc -l\n95\n\nAfter this patch\n\n$ tox -e py36 tripleo_common.tests.utils.test_config.TestConfig | grep ResourceWarning | wc -l\n18\n\nExample Warning:\ntripleo_common/tests/utils/test_config.py:667: ResourceWarning: unclosed file\n<_io.TextIOWrapper name='/tmp/tmpyzh4ejn6/tmpvxwydwti/group_vars/Controller' mode='r' encoding='UTF-8'>\n  open(os.path.join(config_dir, 'group_vars', f)).read()),\n\nChange-Id: Iab6218fb263cdc2a9b707166e904ff26bd113c6c\n""}]",0,639776,948a5f0c48fc003188e7b45ea792f6568eebdadf,22,10,2,16282,,,0,"Warning cleanup in TestConfig

when running tox for the unittests

TestConfig was generating 95 ResourceWarnings

$ tox -e py36 tripleo_common.tests.utils.test_config.TestConfig | grep ResourceWarning | wc -l
95

After this patch

$ tox -e py36 tripleo_common.tests.utils.test_config.TestConfig | grep ResourceWarning | wc -l
18

Example Warning:
tripleo_common/tests/utils/test_config.py:667: ResourceWarning: unclosed file
<_io.TextIOWrapper name='/tmp/tmpyzh4ejn6/tmpvxwydwti/group_vars/Controller' mode='r' encoding='UTF-8'>
  open(os.path.join(config_dir, 'group_vars', f)).read()),

Change-Id: Iab6218fb263cdc2a9b707166e904ff26bd113c6c
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/76/639776/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/tests/utils/test_config.py'],1,628f66f238a892b68b3eff2cdbaf6d68d45d25d2,fixup_test_leaks," with open(config_data_path) as fin: config_data = yaml.safe_load(fin.read()) with open(file_path) as fin: return yaml.safe_load(fin.read()) with open(os.path.join(tmp_path, 'group_vars', f)) as fin: self.assertEqual( self._get_yaml_file(f), yaml.safe_load(fin.read())) with open(os.path.join(tmp_path, 'host_vars', f)) as fin: self.assertEqual( self._get_yaml_file(os.path.join('host_vars', f)), yaml.safe_load(fin.read())) with open(os.path.join(tmp_path, 'Controller', 'overcloud-controller-0', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-controller-0', d))) with open(os.path.join(tmp_path, 'Compute', 'overcloud-novacompute-0', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-0', d))) with open(os.path.join(tmp_path, 'Compute', 'overcloud-novacompute-1', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-1', d))) with open(os.path.join(tmp_path, 'Compute', 'overcloud-novacompute-2', d)) as fin: self.assertEqual( yaml.safe_load( fin.read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-2', d))) with open(os.path.join(config_dir, 'group_vars', f)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(f)) with open(os.path.join(config_dir, 'Controller', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-controller-0', d))) with open(os.path.join(config_dir, 'Compute', 'overcloud-novacompute-0', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-0', d))) with open(os.path.join(config_dir, 'Compute', 'overcloud-novacompute-1', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-1', d))) with open(os.path.join(config_dir, 'Compute', d)) as fin: self.assertEqual( yaml.safe_load(fin.read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-2', d)))"," config_data = yaml.safe_load(open(config_data_path).read()) return yaml.safe_load(open(file_path).read()) self.assertEqual( self._get_yaml_file(f), yaml.safe_load( open(os.path.join(tmp_path, 'group_vars', f)).read())) self.assertEqual( self._get_yaml_file(os.path.join('host_vars', f)), yaml.safe_load( open(os.path.join(tmp_path, 'host_vars', f)).read())) self.assertEqual( yaml.safe_load( open(os.path.join(tmp_path, 'Controller', 'overcloud-controller-0', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-controller-0', d))) self.assertEqual( yaml.safe_load( open(os.path.join(tmp_path, 'Compute', 'overcloud-novacompute-0', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-0', d))) self.assertEqual( yaml.safe_load( open(os.path.join(tmp_path, 'Compute', 'overcloud-novacompute-1', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-1', d))) self.assertEqual( yaml.safe_load( open(os.path.join(tmp_path, 'Compute', 'overcloud-novacompute-2', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-2', d))) self.assertEqual( yaml.safe_load( open(os.path.join(config_dir, 'group_vars', f)).read()), self._get_yaml_file(f)) self.assertEqual( yaml.safe_load( open(os.path.join(config_dir, 'Controller', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-controller-0', d))) self.assertEqual( yaml.safe_load( open(os.path.join(config_dir, 'Compute', 'overcloud-novacompute-0', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-0', d))) self.assertEqual( yaml.safe_load( open(os.path.join(config_dir, 'Compute', 'overcloud-novacompute-1', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-1', d))) self.assertEqual( yaml.safe_load( open(os.path.join(config_dir, 'Compute', d)).read()), self._get_yaml_file(os.path.join( 'overcloud-novacompute-2', d)))",79,77
openstack%2Fdesignate~master~I96a345ba5fc0cd6461265d162e10a6f4e8b7f2e4,openstack/designate,master,I96a345ba5fc0cd6461265d162e10a6f4e8b7f2e4,Fix html_last_updated_fmt for Python3.,ABANDONED,2017-06-09 05:53:47.000000000,2019-03-05 14:34:21.000000000,,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 17130}, {'_account_id': 19741}, {'_account_id': 25254}]","[{'number': 1, 'created': '2017-06-09 05:53:47.000000000', 'files': ['api-ref/source/conf.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/5d24e175717d9d42cc75e655aa7144ad62b1adf2', 'message': 'Fix html_last_updated_fmt for Python3.\n\nhtml_last_updated_fmt option is interpreted as a\nbyte string in python3, causing Sphinx build to break.\nThis patch makes it utf-8 string.\n\nChange-Id: I96a345ba5fc0cd6461265d162e10a6f4e8b7f2e4\nCloses-Bug:#1693670\n'}]",0,472531,5d24e175717d9d42cc75e655aa7144ad62b1adf2,7,5,1,20184,,,0,"Fix html_last_updated_fmt for Python3.

html_last_updated_fmt option is interpreted as a
byte string in python3, causing Sphinx build to break.
This patch makes it utf-8 string.

Change-Id: I96a345ba5fc0cd6461265d162e10a6f4e8b7f2e4
Closes-Bug:#1693670
",git fetch https://review.opendev.org/openstack/designate refs/changes/31/472531/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/conf.py'],1,5d24e175717d9d42cc75e655aa7144ad62b1adf2,bug/1693670,html_last_updated_fmt = subprocess.check_output(git_cmd).decode('utf-8'),"html_last_updated_fmt = subprocess.Popen( git_cmd, stdout=subprocess.PIPE).communicate()[0]",1,2
openstack%2Fmagnum~master~If1dcab0a1b5ba03963afa09beb5ce22f6d0ed5de,openstack/magnum,master,If1dcab0a1b5ba03963afa09beb5ce22f6d0ed5de,DNM: Disable cluster health check,ABANDONED,2019-02-25 10:02:00.000000000,2019-03-05 14:33:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-25 10:02:00.000000000', 'files': ['magnum/drivers/common/k8s_monitor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e50e13e9f7c9f4324cf773cbca8446d41ef4a0e1', 'message': 'DNM: Disable cluster health check\n\nDisable until story 2005057 is fixed.\n\nChange-Id: If1dcab0a1b5ba03963afa09beb5ce22f6d0ed5de\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",0,639044,e50e13e9f7c9f4324cf773cbca8446d41ef4a0e1,3,1,1,20498,,,0,"DNM: Disable cluster health check

Disable until story 2005057 is fixed.

Change-Id: If1dcab0a1b5ba03963afa09beb5ce22f6d0ed5de
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/44/639044/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/common/k8s_monitor.py'],1,e50e13e9f7c9f4324cf773cbca8446d41ef4a0e1,cluster-upgrades, return,,1,0
openstack%2Fnova~master~Ic50c6b8c3b1f1b260d2b7caab369e77e4870686f,openstack/nova,master,Ic50c6b8c3b1f1b260d2b7caab369e77e4870686f,libvirt: Omit needless check on 'CONF.serial_console',MERGED,2019-02-18 16:27:20.000000000,2019-03-05 14:30:56.000000000,2019-03-05 14:30:56.000000000,"[{'_account_id': 6962}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28454}]","[{'number': 1, 'created': '2019-02-18 16:27:20.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c0fd216780cfa9c17da385af63fa743d40434fa0', 'message': 'libvirt: Omit needless check on \'CONF.serial_console\'\n\nAll calls to _create_pty_device() check for\n\'CONF.serial_console.enabled\' themselves; so remove the redundant check\nin the function _create_pty_device().\n\nAnd Georg Hoesch pointed out in a review, this also creates\n""functionally symmetric code"", as in: the functions\n_create_serial_consoles() and _create_pty_device() create the serial\nconsole devices, and the function _create_consoles_qemu_kvm() tells us\nwhat type of console we need.\n\nNo tests are added to show nothing functional has changed.\n\nChange-Id: Ic50c6b8c3b1f1b260d2b7caab369e77e4870686f\nSuggested-by: Georg Hoesch <georg_hoesch@genua.de>\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",12,637578,c0fd216780cfa9c17da385af63fa743d40434fa0,58,15,1,6962,,,0,"libvirt: Omit needless check on 'CONF.serial_console'

All calls to _create_pty_device() check for
'CONF.serial_console.enabled' themselves; so remove the redundant check
in the function _create_pty_device().

And Georg Hoesch pointed out in a review, this also creates
""functionally symmetric code"", as in: the functions
_create_serial_consoles() and _create_pty_device() create the serial
console devices, and the function _create_consoles_qemu_kvm() tells us
what type of console we need.

No tests are added to show nothing functional has changed.

Change-Id: Ic50c6b8c3b1f1b260d2b7caab369e77e4870686f
Suggested-by: Georg Hoesch <georg_hoesch@genua.de>
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/637578/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,c0fd216780cfa9c17da385af63fa743d40434fa0,Bump_min_libvirt_and_QEMU_for_Stein,, if CONF.serial_console.enabled: return ,0,3
openstack%2Fironic~master~I08d31b5ddbad626811c971389e634a450aeaf066,openstack/ironic,master,I08d31b5ddbad626811c971389e634a450aeaf066,Add option to protect available nodes from accidental deletion,MERGED,2019-02-26 08:03:40.000000000,2019-03-05 14:21:26.000000000,2019-03-05 14:21:08.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11292}, {'_account_id': 14629}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 25547}, {'_account_id': 26340}, {'_account_id': 28429}, {'_account_id': 29209}]","[{'number': 1, 'created': '2019-02-26 08:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b3eec40c693e66e3e6d513b98958bde538d81243', 'message': ""Add option to protect available nodes from accidental deletion\n\nIronic allows to delete nodes which are in state 'available'.\nAs bringing nodes into 'available' is typically not instantaneous\n(e.g. due to inspection and cleanup), this patch proposes a new\noption 'allow_deleting_available_nodes' to support the protection\nof available nodes against accidental removal.\n\nChange-Id: I08d31b5ddbad626811c971389e634a450aeaf066\nStory: #2005060\nTask: #29604\n""}, {'number': 2, 'created': '2019-02-26 11:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fce4e5b0a9e84cbb937e5f6228e7a5edea08cb15', 'message': ""Add option to protect available nodes from accidental deletion\n\nIronic allows to delete nodes which are in state 'available'.\nAs bringing nodes into 'available' is typically not instantaneous\n(e.g. due to inspection and cleanup), this patch proposes a new\noption 'allow_deleting_available_nodes' to support the protection\nof available nodes against accidental removal.\n\nChange-Id: I08d31b5ddbad626811c971389e634a450aeaf066\nStory: #2005060\nTask: #29604\n""}, {'number': 3, 'created': '2019-02-27 20:59:46.000000000', 'files': ['ironic/conf/conductor.py', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/common/states.py', 'ironic/releasenotes/notes/add-protection-for-available-nodes-25f163d69782ef63.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/885ddb4362c347e4963fe36521e59dcfd9dad708', 'message': ""Add option to protect available nodes from accidental deletion\n\nIronic allows to delete nodes which are in state 'available'.\nAs bringing nodes into 'available' comes at an operational cost\n(i.e. enroll, inspect, clean, ...), this patch proposes a new\noption 'allow_deleting_available_nodes' to support the protection\nof available nodes against accidental removal.\n\nChange-Id: I08d31b5ddbad626811c971389e634a450aeaf066\nStory: #2005060\nTask: #29604\n""}]",12,639264,885ddb4362c347e4963fe36521e59dcfd9dad708,48,14,3,11292,,,0,"Add option to protect available nodes from accidental deletion

Ironic allows to delete nodes which are in state 'available'.
As bringing nodes into 'available' comes at an operational cost
(i.e. enroll, inspect, clean, ...), this patch proposes a new
option 'allow_deleting_available_nodes' to support the protection
of available nodes against accidental removal.

Change-Id: I08d31b5ddbad626811c971389e634a450aeaf066
Story: #2005060
Task: #29604
",git fetch https://review.opendev.org/openstack/ironic refs/changes/64/639264/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conf/conductor.py', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/common/states.py', 'ironic/releasenotes/notes/add-protection-for-available-nodes-25f163d69782ef63.yaml']",5,b3eec40c693e66e3e6d513b98958bde538d81243,protect_available_nodes,"--- features: - Adds option 'allow_deleting_available_nodes' to control whether nodes in state 'available' should be deletable. Setting this option to False provides protection against accidental removal of nodes which are ready for allocation. For backwards compatibility reasons, the default value for this option is True. ",,30,1
openstack%2Fkeystoneauth~master~I0cc7f2514e143ec532d8fb895618f7cf1fea9cc3,openstack/keystoneauth,master,I0cc7f2514e143ec532d8fb895618f7cf1fea9cc3,Fix rate semaphore for keystoneclient,MERGED,2019-03-05 09:02:29.000000000,2019-03-05 14:19:58.000000000,2019-03-05 14:19:58.000000000,"[{'_account_id': 2}, {'_account_id': 2903}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-03-05 09:02:29.000000000', 'files': ['keystoneauth1/adapter.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/7b74cc9adb77f025190557e47f6dadae110e6ab5', 'message': 'Fix rate semaphore for keystoneclient\n\nWhen using keystoneclient sessions, the new parameter is not available\nand breaks the keystoneclient unit tests[1]. Only use the semaphore\nkwarg when using keystoneauth sessions.\n\n[1] https://review.openstack.org/640953\n\nChange-Id: I0cc7f2514e143ec532d8fb895618f7cf1fea9cc3\n'}]",0,640957,7b74cc9adb77f025190557e47f6dadae110e6ab5,8,4,1,8482,,,0,"Fix rate semaphore for keystoneclient

When using keystoneclient sessions, the new parameter is not available
and breaks the keystoneclient unit tests[1]. Only use the semaphore
kwarg when using keystoneauth sessions.

[1] https://review.openstack.org/640953

Change-Id: I0cc7f2514e143ec532d8fb895618f7cf1fea9cc3
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/57/640957/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth1/adapter.py'],1,7b74cc9adb77f025190557e47f6dadae110e6ab5,fix-semaphore," if self._rate_semaphore: kwargs.setdefault('rate_semaphore', self._rate_semaphore)"," kwargs.setdefault('rate_semaphore', self._rate_semaphore) ",2,2
openstack%2Fnova~master~Idbea99a690d960a27b19e156268912fb7c30d8e9,openstack/nova,master,Idbea99a690d960a27b19e156268912fb7c30d8e9,WIP context: Ensure templated connection URLs are rendered before use,ABANDONED,2019-02-27 09:20:32.000000000,2019-03-05 14:17:41.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-27 09:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/293fdf02b4d5058d001e09c7feadee0bf613d186', 'message': 'WIP status: Ensure templated connection URLs are rendered before use\n\nChange-Id: Idbea99a690d960a27b19e156268912fb7c30d8e9\n'}, {'number': 2, 'created': '2019-02-27 16:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5eb18ab5e86fbe67ef9e906426d525a1f7d1a6fb', 'message': 'WIP status: Ensure templated connection URLs are rendered before use\n\nChange-Id: Idbea99a690d960a27b19e156268912fb7c30d8e9\n'}, {'number': 3, 'created': '2019-02-28 11:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bef899be9928f7aecc30a136debbef6f4c9a24ae', 'message': 'WIP context: Ensure templated connection URLs are rendered before use\n\nChange-Id: Idbea99a690d960a27b19e156268912fb7c30d8e9\n'}, {'number': 4, 'created': '2019-02-28 13:31:57.000000000', 'files': ['nova/context.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f365e81aba7bc611b54f7749873bb67ac03a9e69', 'message': 'WIP context: Ensure templated connection URLs are rendered before use\n\nThis change ensures that the db and mq connection URLs are rendered\nbefore being stashed in the CELL_CACHE.\n\nCloses-Bug: #\nChange-Id: Idbea99a690d960a27b19e156268912fb7c30d8e9\n'}]",0,639607,f365e81aba7bc611b54f7749873bb67ac03a9e69,27,8,4,10135,,,0,"WIP context: Ensure templated connection URLs are rendered before use

This change ensures that the db and mq connection URLs are rendered
before being stashed in the CELL_CACHE.

Closes-Bug: #
Change-Id: Idbea99a690d960a27b19e156268912fb7c30d8e9
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/639607/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/cmd/status.py'],1,293fdf02b4d5058d001e09c7feadee0bf613d186,tripleo_upgradechecks, # As we are pulling these records directly from the database we # need to ensure that any templated URLs are rendered correctly. cell_mapping.db_connection = cell_mapping_obj.format_db_url( cell_mapping.db_connection) cell_mapping.mq_connection = cell_mapping_obj.format_mq_url( cell_mapping.mq_connection),,6,0
openstack%2Fvitrage-tempest-plugin~master~I67765c1eda8c506fea920485e2abec6ddd728445,openstack/vitrage-tempest-plugin,master,I67765c1eda8c506fea920485e2abec6ddd728445,Removing dependency of vitrage,MERGED,2019-03-04 16:58:44.000000000,2019-03-05 14:03:56.000000000,2019-03-05 14:03:56.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 16:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/c3e468cdedb186771c7c3730204190a4b6258cd5', 'message': 'WIP: removing dependency of vitrage\n\nuse the networkx graph instead of vitrage graph\n\nChange-Id: I67765c1eda8c506fea920485e2abec6ddd728445\n'}, {'number': 2, 'created': '2019-03-05 07:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/56ca67c894923e734cb36968426d0766491ea0be', 'message': 'WIP: removing dependency of vitrage\n\nuse the networkx graph instead of vitrage graph\n\nChange-Id: I67765c1eda8c506fea920485e2abec6ddd728445\n'}, {'number': 3, 'created': '2019-03-05 12:13:24.000000000', 'files': ['devstack/post_test_hook.sh', 'vitrage_tempest_plugin/tests/base.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/d424a7cb1c5913aedaa4c906de994fe19f9601df', 'message': 'Removing dependency of vitrage\n\nuse the networkx graph instead of vitrage graph\n\nChange-Id: I67765c1eda8c506fea920485e2abec6ddd728445\n'}]",2,640817,d424a7cb1c5913aedaa4c906de994fe19f9601df,13,5,3,19134,,,0,"Removing dependency of vitrage

use the networkx graph instead of vitrage graph

Change-Id: I67765c1eda8c506fea920485e2abec6ddd728445
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/17/640817/3 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/tests/base.py', 'vitrage_tempest_plugin/tests/datasources/test_nova.py']",2,c3e468cdedb186771c7c3730204190a4b6258cd5,eyalb/graph," graph = self._create_graph_from_graph_dictionary2(api_graph) self._validate_graph_correctness2(graph, num_entities, num_edges, entities)"," graph = self._create_graph_from_graph_dictionary(api_graph) self._validate_graph_correctness(graph, num_entities, num_edges, entities)",120,7
openstack%2Fmonasca-events-api~master~If630fc2e13ed4a81bb7b74c4238d1e28c78490d7,openstack/monasca-events-api,master,If630fc2e13ed4a81bb7b74c4238d1e28c78490d7,Reconfigure tempest configuration,MERGED,2018-12-05 11:57:08.000000000,2019-03-05 14:02:28.000000000,2019-03-05 14:02:28.000000000,"[{'_account_id': 7102}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 28062}]","[{'number': 1, 'created': '2018-12-05 11:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/ee0360ba6e0b95cd3883eeeaa2f56f9944083825', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 2, 'created': '2018-12-05 11:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/ee5d0ea4b279fc125646b0e3c1b5506d859a0453', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 3, 'created': '2018-12-05 12:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/0c1b73361c94c65986572e86f6f8bfca23d6ac0d', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 4, 'created': '2018-12-05 13:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/fd86b5556b8e80275b48a7545e40d31da1fb8108', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 5, 'created': '2018-12-06 08:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/90905c5d28d1c64f9a94b42c01064f13b2743b50', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 6, 'created': '2018-12-06 08:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/6a789cb85ac7c5d7b7b0cb26700acba2df1c8f47', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 7, 'created': '2018-12-06 09:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/5a624701217c644bb326abbc6c08676cf39fef26', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 8, 'created': '2018-12-06 09:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/5a04a8fa9d5b73fc377bbeb2054a6133d2149881', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 9, 'created': '2018-12-06 09:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/496a3baad7789d2085681fdb49165f3ace72d1e4', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 10, 'created': '2018-12-06 10:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/d5a1746b461d13eb9d58fc413b3d14f9730cc747', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 11, 'created': '2018-12-06 12:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/25ae0c9d3ff5ef83c22a8ae0237e461e588b2808', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 12, 'created': '2018-12-06 12:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/2f0c0f7dd7eae54373ee6e1cc84767e346eb4e41', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 13, 'created': '2018-12-11 07:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/39ac518b4a52d364b8726002fc1d64c94fe09d7d', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 14, 'created': '2018-12-19 12:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/6afdc5eeed210d417ac716c98dd9e9bf08464371', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 15, 'created': '2018-12-19 13:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/e133c5590c0eb729a4b33628b8e69868c6287d58', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 16, 'created': '2019-01-22 09:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/4503806850c5524248f5c98bec3ea233b992cb4f', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 17, 'created': '2019-01-22 11:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/c3bc1f53c845879b8282183df06fb060cb8bf574', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 18, 'created': '2019-02-05 14:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/14e5feda820129a77f0444ed6102855111a99fd3', 'message': 'Reconfigure tempest configuration\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 19, 'created': '2019-03-04 12:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/86f47e80652522c0d3cb0a3d8fadce5079aae8e7', 'message': 'Reconfigure tempest configuration\n\nSwitch tempest test to zuul3 native, and add proper configuration  \nfor events tempest test.\n\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 20, 'created': '2019-03-04 12:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/b0c86b9754ad91bd55c72d66c774518e465c5815', 'message': 'Reconfigure tempest configuration\n\nSwitch tempest test to zuul3 native, and add proper configuration  \nfor events tempest test.\n\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 21, 'created': '2019-03-05 10:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/06801222de11d20b8c0b547262c1465087e7b9ba', 'message': 'Reconfigure tempest configuration\n\nSwitch tempest test to zuul3 native, and add proper configuration  \nfor events tempest test.\n\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}, {'number': 22, 'created': '2019-03-05 10:46:37.000000000', 'files': ['.zuul.yaml', 'devstack/lib/elasticsearch.sh', 'playbooks/legacy/monasca-tempest-events-base/run.yaml', 'playbooks/legacy/monasca-tempest-events-base/post.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-events-api/commit/e86c6fbc6518d50342d92b6044deb76a64296ac1', 'message': 'Reconfigure tempest configuration\n\nSwitch tempest test to zuul3 native, and add proper configuration  \nfor events tempest test.\n\n\nStory: 2004549\nTask: 28303\nDepends-On: https://review.openstack.org/599575\n\nChange-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7\n'}]",24,622940,e86c6fbc6518d50342d92b6044deb76a64296ac1,59,5,22,26141,,,0,"Reconfigure tempest configuration

Switch tempest test to zuul3 native, and add proper configuration  
for events tempest test.


Story: 2004549
Task: 28303
Depends-On: https://review.openstack.org/599575

Change-Id: If630fc2e13ed4a81bb7b74c4238d1e28c78490d7
",git fetch https://review.opendev.org/openstack/monasca-events-api refs/changes/40/622940/14 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'playbooks/legacy/monasca-tempest-events-base/run.yaml', 'playbooks/legacy/monasca-tempest-events-base/post.yaml']",3,ee0360ba6e0b95cd3883eeeaa2f56f9944083825,zuul-test,,- hosts: primary tasks: - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/logs/** - --include=*/ - --exclude=* - --prune-empty-dirs ,23,92
openstack%2Fpython-vitrageclient~master~Ieaa372e92d201b46124163b164cc868ae35c86b2,openstack/python-vitrageclient,master,Ieaa372e92d201b46124163b164cc868ae35c86b2,Allow calling template validate and template add with a string,MERGED,2019-03-05 12:21:58.000000000,2019-03-05 13:44:35.000000000,2019-03-05 13:44:35.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 12:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/93ee72f549ea50385c3f7b14748962d6a16ab203', 'message': 'Allow calling template validate and template add with a string\n\nVitrage template add and template validate can now be called with either\na path or a string that holds the template yaml.\n\nChange-Id: Ieaa372e92d201b46124163b164cc868ae35c86b2\nStory: 2004055\nTask: 27061\n'}, {'number': 2, 'created': '2019-03-05 12:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/6d7b9c6a6a249a9e720b3914c2b958eed0937ef3', 'message': 'Allow calling template validate and template add with a string\n\nVitrage template add and template validate can now be called with either\na path or a string that holds the template yaml.\n\nChange-Id: Ieaa372e92d201b46124163b164cc868ae35c86b2\nStory: 2004055\nTask: 27061\n'}, {'number': 3, 'created': '2019-03-05 13:10:21.000000000', 'files': ['vitrageclient/tests/test_template.py', 'releasenotes/notes/add-template-by-string-ab6aff3badc279cd.yaml', 'vitrageclient/tests/resources/template1.yaml', 'vitrageclient/tests/utils.py', 'vitrageclient/v1/template.py'], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/ecd027535d8f62e88df2bde58097159204a31a94', 'message': 'Allow calling template validate and template add with a string\n\nVitrage template add and template validate can now be called with either\na path or a string that holds the template yaml.\n\nChange-Id: Ieaa372e92d201b46124163b164cc868ae35c86b2\nStory: 2004055\nTask: 27061\n'}]",2,640996,ecd027535d8f62e88df2bde58097159204a31a94,14,4,3,19159,,,0,"Allow calling template validate and template add with a string

Vitrage template add and template validate can now be called with either
a path or a string that holds the template yaml.

Change-Id: Ieaa372e92d201b46124163b164cc868ae35c86b2
Story: 2004055
Task: 27061
",git fetch https://review.opendev.org/openstack/python-vitrageclient refs/changes/96/640996/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrageclient/tests/test_template.py', 'vitrageclient/tests/resources/template1.yaml', 'vitrageclient/tests/utils.py', 'vitrageclient/v1/template.py']",4,93ee72f549ea50385c3f7b14748962d6a16ab203,add_template_string,"import json def add(self, path=None, template_str=None, template_type=None, params=None): """"""Add a new template :param path: (optional) The template file path or templates dir path :param template_str: (optional) A string representation of the template yaml Either path or template_str must exist (but not both) :param template_type: (optional) The template type, in case it is not written inside the template metadata section :param params: (optional) Actual values for the template parameters :return: """""" files_content = \ self._load_template(path=path, template_str=template_str) def validate(self, path=None, template_str=None, template_type=None, params=None): :param path: (optional) The template file path or templates dir path :param template_str: (optional) A string representation of the template yaml Either path or template_str must exist (but not both) :param template_type: (optional) The template type, in case it is not written inside the template metadata section :param params: (optional) Actual values for the template parameters :return: """""" files_content = \ self._load_template(path=path, template_str=template_str) @classmethod def _load_yaml_files(cls, path): template = cls._load_yaml_file(file_path) files_content = [(path, cls._load_yaml_file(path))] @classmethod def _load_yaml_file(cls, path): @classmethod def _load_yaml_string(cls, yaml_str): try: return yaml_utils.load(yaml_str) except ValueError as e: message = 'Could not load template: %s. Reason: %s' \ % (yaml_str, e.message) raise exc.CommandError(message) @classmethod def _load_template(cls, path, template_str): if path: files_content = cls._load_yaml_files(path) elif template_str: template_str = json.loads(template_str) files_content = [(None, cls._load_yaml_string(template_str))] else: raise exc.CommandError( 'Add template API must be called with either \'path\' or ' '\'template_json\'') return files_content"," def add(self, path, template_type=None, params=None): """"""Add a new template"""""" files_content = self._load_yaml_files(path) def validate(self, path, template_type=None, params=None): :param path: the template file path or templates dir path :param template_type: type of templates ('standard','definition',...) :param params: (optional) actual values for the template parameters """""" files_content = self._load_yaml_files(path) def _load_yaml_files(self, path): template = self._load_yaml_file(file_path) files_content = [(path, self._load_yaml_file(path))] @staticmethod def _load_yaml_file(path):",174,14
openstack%2Ftripleo-docs~master~Ice6a2c24a6fc27f40e4971efd6f64bc6b77118d0,openstack/tripleo-docs,master,Ice6a2c24a6fc27f40e4971efd6f64bc6b77118d0,Add --default-runtime to paunch manual,MERGED,2019-03-04 21:33:35.000000000,2019-03-05 13:18:53.000000000,2019-03-05 13:18:53.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 21:33:35.000000000', 'files': ['doc/source/install/containers_deployment/tips_tricks.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/0ec1e466ca4ed6fc702b6d5d9680d84ad5365f2a', 'message': 'Add --default-runtime to paunch manual\n\nChange-Id: Ice6a2c24a6fc27f40e4971efd6f64bc6b77118d0\n'}]",0,640881,0ec1e466ca4ed6fc702b6d5d9680d84ad5365f2a,7,4,1,3153,,,0,"Add --default-runtime to paunch manual

Change-Id: Ice6a2c24a6fc27f40e4971efd6f64bc6b77118d0
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/81/640881/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/containers_deployment/tips_tricks.rst'],1,0ec1e466ca4ed6fc702b6d5d9680d84ad5365f2a,podman, --default-runtime Default runtime for containers. Can be docker or podman.,,2,0
openstack%2Fgovernance~master~I027ba8b86ada15f67be823a4955b165853a21d12,openstack/governance,master,I027ba8b86ada15f67be823a4955b165853a21d12,Add ``ceph-rbd-mirror`` charm and dependencies,MERGED,2019-02-25 11:21:42.000000000,2019-03-05 13:17:48.000000000,2019-03-05 13:17:48.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 8099}, {'_account_id': 11564}, {'_account_id': 11655}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-25 11:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/70366ed1cc9aa1003697f5d2340727e94d55de7d', 'message': 'Add ``ceph-rbd-mirror`` charm and dependencies\n\nChange-Id: I027ba8b86ada15f67be823a4955b165853a21d12\nDepends-On: Ica61a89c9b6a7fa7ccc1f38f5c7f614f692552d7\n'}, {'number': 2, 'created': '2019-02-25 13:55:52.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/b3a181bf5bfa579596dcbd45ee626259620f00bf', 'message': 'Add ``ceph-rbd-mirror`` charm and dependencies\n\nChange-Id: I027ba8b86ada15f67be823a4955b165853a21d12\nDepends-On: Ica61a89c9b6a7fa7ccc1f38f5c7f614f692552d7\n'}]",0,639068,b3a181bf5bfa579596dcbd45ee626259620f00bf,16,8,2,13686,,,0,"Add ``ceph-rbd-mirror`` charm and dependencies

Change-Id: I027ba8b86ada15f67be823a4955b165853a21d12
Depends-On: Ica61a89c9b6a7fa7ccc1f38f5c7f614f692552d7
",git fetch https://review.opendev.org/openstack/governance refs/changes/68/639068/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,70366ed1cc9aa1003697f5d2340727e94d55de7d,new-project, charm-ceph-rbd-mirror: release-management: external repos: - openstack/charm-ceph-rbd-mirror charm-interface-ceph-rbd-mirror: release-management: external repos: - openstack/charm-interface-ceph-rbd-mirror charm-layer-ceph: release-management: external repos: - charm-layer-ceph,,12,0
openstack%2Fgovernance~master~I4c566ff4f9d7fa20eb755061af5dae01ac6e8edb,openstack/governance,master,I4c566ff4f9d7fa20eb755061af5dae01ac6e8edb,Get rid of popularity discussion in PTI,MERGED,2019-02-19 23:35:31.000000000,2019-03-05 13:17:21.000000000,2019-03-05 13:17:21.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 8099}, {'_account_id': 8556}, {'_account_id': 11564}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 23:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/65ae6f11a1e41da46aeb17812a0682d52bd9baf1', 'message': ""Get rid of popularity discussion in PTI\n\nNow that we no longer use 'popularity' as a criteria for including\ndistros in the PTI, there's no need to include a boring disclaimer about\nthe relative popularity of RHEL vs. CentOS.\n\nChange-Id: I4c566ff4f9d7fa20eb755061af5dae01ac6e8edb\n""}, {'number': 2, 'created': '2019-02-25 21:24:58.000000000', 'files': ['reference/project-testing-interface.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/f06b84b3ec86f6df6d7c2b68df9777a5e81a7442', 'message': ""Get rid of popularity discussion in PTI\n\nNow that we no longer use 'popularity' as a criteria for including\ndistros in the PTI, there's no need to include a boring disclaimer about\nthe relative popularity of RHEL vs. CentOS.\n\nChange-Id: I4c566ff4f9d7fa20eb755061af5dae01ac6e8edb\n""}]",3,638045,f06b84b3ec86f6df6d7c2b68df9777a5e81a7442,19,9,2,4257,,,0,"Get rid of popularity discussion in PTI

Now that we no longer use 'popularity' as a criteria for including
distros in the PTI, there's no need to include a boring disclaimer about
the relative popularity of RHEL vs. CentOS.

Change-Id: I4c566ff4f9d7fa20eb755061af5dae01ac6e8edb
",git fetch https://review.opendev.org/openstack/governance refs/changes/45/638045/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/project-testing-interface.rst'],1,65ae6f11a1e41da46aeb17812a0682d52bd9baf1,formal-vote,The following free operating systems are representative of platforms regularly used to deploying OpenStack on:,"The following operating systems are regularly used when deploying OpenStack: .. note:: The CentOS distribution is derived from the sources of Red Hat Enterprise Linux (RHEL). In reality, RHEL is more popular than CentOS but we can't use this platform on upstream gates, so we rely on CentOS. ",2,7
openstack%2Frpm-packaging~stable%2Frocky~Ic986b0e6d09b4a2512ce65da1f044634f7f32de9,openstack/rpm-packaging,stable/rocky,Ic986b0e6d09b4a2512ce65da1f044634f7f32de9,os-apply-config: Install the templates dir,MERGED,2019-03-05 12:34:18.000000000,2019-03-05 13:16:50.000000000,2019-03-05 13:16:50.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 12:34:18.000000000', 'files': ['openstack/os-apply-config/os-apply-config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5492eeaf8c88c9e9e8ba8fa21320145fffd947d2', 'message': 'os-apply-config: Install the templates dir\n\nThis is needed for heat-agents which installs files into the\ntemplates/ directory.\n\nChange-Id: Ic986b0e6d09b4a2512ce65da1f044634f7f32de9\n(cherry picked from commit d5afb096e072d9461652d809489024d9891e3adf)\n'}]",0,641000,5492eeaf8c88c9e9e8ba8fa21320145fffd947d2,8,4,1,7102,,,0,"os-apply-config: Install the templates dir

This is needed for heat-agents which installs files into the
templates/ directory.

Change-Id: Ic986b0e6d09b4a2512ce65da1f044634f7f32de9
(cherry picked from commit d5afb096e072d9461652d809489024d9891e3adf)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/00/641000/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-apply-config/os-apply-config.spec.j2'],1,5492eeaf8c88c9e9e8ba8fa21320145fffd947d2,,install -d -m 755 %{buildroot}%{_libexecdir}/os-apply-config/templates%dir %{_libexecdir}/os-apply-config %dir %{_libexecdir}/os-apply-config/templates,,3,0
openstack%2Fopenstacksdk~master~I5d7bd12606785365d2f5b5b52ec7a2316459b68f,openstack/openstacksdk,master,I5d7bd12606785365d2f5b5b52ec7a2316459b68f,Replace TaskManager with a keystoneauth concurrency,MERGED,2018-09-24 22:25:16.000000000,2019-03-05 13:13:43.000000000,2019-03-05 13:13:43.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 2903}, {'_account_id': 3099}, {'_account_id': 5046}, {'_account_id': 10239}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2018-09-24 22:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0cd2b5f8a40f0341e143d64882b44c23c91676f2', 'message': ""WIP Replace TaskManager with a semaphore and lock\n\nDon't look at this\n\nSeriously. You'll put your eye out\n\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 2, 'created': '2018-09-25 00:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/87db9f2604d0a3dbffefe43022371077dc3b1539', 'message': ""WIP Replace TaskManager with a semaphore and lock\n\nDon't look at this\n\nSeriously. You'll put your eye out\n\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 3, 'created': '2018-09-25 10:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/286bcf8206fd493dcdd539d0f79348a49a7efdb5', 'message': ""WIP Replace TaskManager with a semaphore and lock\n\nDon't look at this\n\nSeriously. You'll put your eye out\n\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 4, 'created': '2018-09-25 14:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9e5a7b183b672fe3941a3385d64cdb46ad7818f3', 'message': 'Replace TaskManager with a semaphore and lock\n\nThe work done by TaskManager can be accomplished much more simply by\nusing a Fair Semaphore and a lock and letting concurrency come not from\nan additional executor pool but from the concurrency of the calling\napplication itself.\n\nDepends-On: https://review.openstack.org/605052\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n'}, {'number': 5, 'created': '2018-09-25 14:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8070ae8bb8a3a10d5b638a40e026849cf74f44b1', 'message': 'Replace TaskManager with a semaphore and lock\n\nThe work done by TaskManager can be accomplished much more simply by\nusing a Fair Semaphore and a lock and letting concurrency come not from\nan additional executor pool but from the concurrency of the calling\napplication itself.\n\nDepends-On: https://review.openstack.org/605052\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n'}, {'number': 6, 'created': '2018-09-26 19:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6465879437ef1e5f1a733c3daf23dc54a1731e4b', 'message': 'Replace TaskManager with a semaphore and lock\n\nThe work done by TaskManager can be accomplished much more simply by\nusing a Fair Semaphore and a lock and letting concurrency come not from\nan additional executor pool but from the concurrency of the calling\napplication itself.\n\nDepends-On: https://review.openstack.org/605052\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n'}, {'number': 7, 'created': '2018-10-06 14:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3ff8ad3fb0503f20022e9990f0ee2faa13d78997', 'message': 'Replace TaskManager with a semaphore and lock\n\nThe work done by TaskManager can be accomplished much more simply by\nusing a Fair Semaphore and a lock and letting concurrency come not from\nan additional executor pool but from the concurrency of the calling\napplication itself.\n\nDepends-On: https://review.openstack.org/605052\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n'}, {'number': 8, 'created': '2018-10-06 14:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0b66c99080b58f308e37473e8c072cd418ca1587', 'message': 'Replace TaskManager with a semaphore and lock\n\nThe work done by TaskManager can be accomplished much more simply by\nusing a Fair Semaphore and a lock and letting concurrency come not from\nan additional executor pool but from the concurrency of the calling\napplication itself.\n\nDepends-On: https://review.openstack.org/605052\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n'}, {'number': 9, 'created': '2018-10-21 15:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/147f7187d89e05b0ddedc8fd0282a1c9298e33d4', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 10, 'created': '2018-10-21 15:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/431ea084d16f6544144f0000cb24881d272ec546', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 11, 'created': '2018-10-21 15:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a768d58ec807d496a9f4092fe57e08b7fb528395', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 12, 'created': '2018-10-22 13:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/430eee881b767d97e59211984da4174d57f8325d', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 13, 'created': '2018-10-29 16:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/915b974d4b7db3a5fde1157b1176528317cd1b47', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 14, 'created': '2018-10-29 16:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2dbbeb782513a79055e1fa04613ebf43f3b79efc', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 15, 'created': '2018-11-01 18:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ed835e339efbf0bf614f60749fc477ae9a8d9bca', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 16, 'created': '2018-11-01 18:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/bf10535ad1c094f40d8a7dc229026933f830da27', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 17, 'created': '2018-11-01 21:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d50bbf5927eee1c2331e457e75a65c4bb8fe95f5', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 18, 'created': '2018-11-01 23:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a95b1b26c97874be1ea49d291e894bf2904cc236', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 19, 'created': '2018-11-04 14:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e3cfa0abc66c32f157f654e1f98fe02b18ff2db4', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 20, 'created': '2018-11-09 00:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d1a71894e59812ce7aa1a3f870ed613aad6aaeb1', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 21, 'created': '2018-11-09 14:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/70e4d9ef679513ce1d8e2dff952988152c329112', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 22, 'created': '2018-11-09 16:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/456a869009bf4f0a1fd99b3fbe7763d7ca315eaf', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 23, 'created': '2018-11-23 09:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e9ae8629a18a503d0e01a0e26698fd5aa9eee7ea', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 24, 'created': '2019-02-28 18:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3f5f76181b57699df4d8a81ec2c9b837b6de54b6', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 25, 'created': '2019-03-01 16:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/385dfdee239d602f7f9feb4f2353da524baed5c3', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/605043\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 26, 'created': '2019-03-01 19:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e4a88394009ab7a541f13fa1a3a1a13d92ef62ff', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/#/c/640389/\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 27, 'created': '2019-03-01 22:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/306e17a4e5c755a920faa3192bb42fcb362dad8d', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/#/c/640389/\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 28, 'created': '2019-03-02 02:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/18f31629c99dcfb0308ca555bb3c43205f44de02', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/#/c/640389/\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 29, 'created': '2019-03-02 08:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8ceaa1f2c9560e5e95ea13a9cf3c5118a709d905', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/#/c/640389/\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}, {'number': 30, 'created': '2019-03-02 15:26:28.000000000', 'files': ['openstack/config/cloud_region.py', 'openstack/tests/unit/test_connection.py', 'openstack/cloud/openstackcloud.py', 'requirements.txt', 'doc/source/user/guides/logging.rst', 'openstack/service_description.py', 'openstack/tests/unit/cloud/test_task_manager.py', 'lower-constraints.txt', 'openstack/tests/unit/base.py', 'openstack/connection.py', 'openstack/_adapter.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c9b60f2b8634c7f8c4254e158cc921202538db04', 'message': ""Replace TaskManager with a keystoneauth concurrency\n\nWe've added concurrency and rate-limiting controls to keystoneauth. That\nmeans we don't need to do them in openstacksdk.\n\nDepends-On: https://review.openstack.org/#/c/640389/\nChange-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f\n""}]",21,604926,c9b60f2b8634c7f8c4254e158cc921202538db04,78,9,30,2,,,0,"Replace TaskManager with a keystoneauth concurrency

We've added concurrency and rate-limiting controls to keystoneauth. That
means we don't need to do them in openstacksdk.

Depends-On: https://review.openstack.org/#/c/640389/
Change-Id: I5d7bd12606785365d2f5b5b52ec7a2316459b68f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/26/604926/27 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/test_connection.py', 'openstack/cloud/openstackcloud.py', 'doc/source/user/guides/logging.rst', 'openstack/service_description.py', 'openstack/task_manager.py', 'openstack/tests/unit/cloud/test_task_manager.py', 'openstack/cloud/_tasks.py', 'openstack/_adapter.py', 'openstack/connection.py']",9,0cd2b5f8a40f0341e143d64882b44c23c91676f2,task-manager,,"from openstack import task_manager as _task_manager task_manager=None, :param task_manager: Task Manager to handle the execution of remote REST calls. Defaults to None which causes a direct-action Task Manager to be used. :type manager: :class:`~openstack.task_manager.TaskManager` self.task_manager = task_manager or _task_manager.TaskManager( self.config.full_name, rate=rate) self.task_manager.start() ",74,649
openstack%2Fstorlets~master~I30969c6443e204ca748f328aab948469d0d97955,openstack/storlets,master,I30969c6443e204ca748f328aab948469d0d97955,DNM: test commit to run functional tests,ABANDONED,2019-03-05 11:45:42.000000000,2019-03-05 13:13:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-05 11:45:42.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/storlets/commit/3ae9992e7e8cf74e0d055e382b76177d60199da2', 'message': 'DNM: test commit to run functional tests\n\nChange-Id: I30969c6443e204ca748f328aab948469d0d97955\n'}]",0,640987,3ae9992e7e8cf74e0d055e382b76177d60199da2,3,1,1,4608,,,0,"DNM: test commit to run functional tests

Change-Id: I30969c6443e204ca748f328aab948469d0d97955
",git fetch https://review.opendev.org/openstack/storlets refs/changes/87/640987/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3ae9992e7e8cf74e0d055e382b76177d60199da2,testing,,,1,0
openstack%2Fnetworking-generic-switch~master~I2c5238bdc923e8214142dd25c22195787b747035,openstack/networking-generic-switch,master,I2c5238bdc923e8214142dd25c22195787b747035,Adding python 3.6 unit test,MERGED,2019-03-04 16:14:41.000000000,2019-03-05 13:12:32.000000000,2019-03-05 13:12:32.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 16:14:41.000000000', 'files': ['zuul.d/project.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/0027c049002ece9f84f187c7fa6bcb4ceed642e3', 'message': 'Adding python 3.6 unit test\n\nThis patch adds python 3.6 unit test to CI and py36 environment\nto tox configuration.\n\nAlso reordering templates jobs.\n\nChange-Id: I2c5238bdc923e8214142dd25c22195787b747035\n'}]",0,640796,0027c049002ece9f84f187c7fa6bcb4ceed642e3,7,3,1,23851,,,0,"Adding python 3.6 unit test

This patch adds python 3.6 unit test to CI and py36 environment
to tox configuration.

Also reordering templates jobs.

Change-Id: I2c5238bdc923e8214142dd25c22195787b747035
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/96/640796/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'tox.ini']",2,0027c049002ece9f84f187c7fa6bcb4ceed642e3,python3-first,"envlist = py35,py36,py27,pep8","envlist = py35,py27,pep8",3,2
openstack%2Frpm-packaging~stable%2Frocky~I76be2f90709adeda19e1f8d6882737644de9251f,openstack/rpm-packaging,stable/rocky,I76be2f90709adeda19e1f8d6882737644de9251f,os-refresh-config: Fix dirs,MERGED,2019-03-05 12:34:46.000000000,2019-03-05 13:10:50.000000000,2019-03-05 13:10:50.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 12:34:46.000000000', 'files': ['openstack/os-refresh-config/os-refresh-config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7e7a7f82fb7768724b5ae3c2b6fe3547ace1f980', 'message': 'os-refresh-config: Fix dirs\n\nWhen py2name translates to python-os-refresh-config, the\npre-configure.d/, configure.d/, migration.d/ and post-configure.d/\ndirectories are installed into the wrong place. Fix this by not using\n%{name} which would be wrong in the given example.\n\nChange-Id: I76be2f90709adeda19e1f8d6882737644de9251f\n(cherry picked from commit 9373efe3a195bd4bdbb1d58cb2f083b89db140a5)\n'}]",0,641001,7e7a7f82fb7768724b5ae3c2b6fe3547ace1f980,8,4,1,7102,,,0,"os-refresh-config: Fix dirs

When py2name translates to python-os-refresh-config, the
pre-configure.d/, configure.d/, migration.d/ and post-configure.d/
directories are installed into the wrong place. Fix this by not using
%{name} which would be wrong in the given example.

Change-Id: I76be2f90709adeda19e1f8d6882737644de9251f
(cherry picked from commit 9373efe3a195bd4bdbb1d58cb2f083b89db140a5)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/01/641001/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-refresh-config/os-refresh-config.spec.j2'],1,7e7a7f82fb7768724b5ae3c2b6fe3547ace1f980,,install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/pre-configure.d install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/configure.d install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/migration.d install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/post-configure.d%{_libexecdir}/os-refresh-config,install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/pre-configure.d install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/configure.d install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/migration.d install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/post-configure.d%{_libexecdir}/%{name},5,5
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I31b38eaf66bb899e72b1bfeca8795e5d1007eee5,openstack/tripleo-heat-templates,stable/queens,I31b38eaf66bb899e72b1bfeca8795e5d1007eee5,[FFU] Ensure compatibility with ansible 2.6.,MERGED,2019-02-26 10:57:39.000000000,2019-03-05 13:10:14.000000000,2019-02-28 19:21:32.000000000,"[{'_account_id': 3153}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27141}]","[{'number': 1, 'created': '2019-02-26 10:57:39.000000000', 'files': ['docker/services/database/mysql.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'common/deploy-steps.j2', 'puppet/services/database/mysql.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6297c1b2d812b504f3a037af5d358a8eb22ef0eb', 'message': ""[FFU] Ensure compatibility with ansible 2.6.\n\nAnsible 2.6 fix didn't properly selct bootstrap node. Also\nnew ansible changed mysql backend library making it unable\nto read misformated my.cnf. This library also needs to have\nsocket specified if it's going to connect to local server.\n\nChange-Id: I31b38eaf66bb899e72b1bfeca8795e5d1007eee5\nResolves: rhbz#1678235\nCloses-bug: #1816422\n(cherry picked from commit d8c368e09f375136efc94cc2b2512bbad8a7ad67)\n""}]",0,639305,6297c1b2d812b504f3a037af5d358a8eb22ef0eb,9,5,1,11166,,,0,"[FFU] Ensure compatibility with ansible 2.6.

Ansible 2.6 fix didn't properly selct bootstrap node. Also
new ansible changed mysql backend library making it unable
to read misformated my.cnf. This library also needs to have
socket specified if it's going to connect to local server.

Change-Id: I31b38eaf66bb899e72b1bfeca8795e5d1007eee5
Resolves: rhbz#1678235
Closes-bug: #1816422
(cherry picked from commit d8c368e09f375136efc94cc2b2512bbad8a7ad67)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/05/639305/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/database/mysql.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'common/deploy-steps.j2', 'puppet/services/database/mysql.yaml']",4,6297c1b2d812b504f3a037af5d358a8eb22ef0eb,bug/1816422, login_unix_socket: '/var/lib/mysql/mysql.sock' login_unix_socket: '/var/lib/mysql/mysql.sock',,19,1
openstack%2Ftraining-labs~stable%2Fqueens~I91ad3c42b1e588d70b4e215e61bc9517ea8dd7a4,openstack/training-labs,stable/queens,I91ad3c42b1e588d70b4e215e61bc9517ea8dd7a4,Update Ubuntu LTS ISO to 16.04.6,MERGED,2019-03-01 15:17:44.000000000,2019-03-05 13:07:48.000000000,2019-03-05 13:07:48.000000000,"[{'_account_id': 6547}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 15:17:44.000000000', 'files': ['labs/osbash/lib/osbash/lib.ubuntu-16.04-server-i386.sh', 'labs/stacktrain/distros/ubuntu_16_04_server_amd64.py', 'labs/osbash/lib/osbash/lib.ubuntu-16.04-server-amd64.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/dec0ade22667ac9033815ebb8e95d7dd2f1c26da', 'message': 'Update Ubuntu LTS ISO to 16.04.6\n\nChange-Id: I91ad3c42b1e588d70b4e215e61bc9517ea8dd7a4\n'}]",1,640399,dec0ade22667ac9033815ebb8e95d7dd2f1c26da,7,3,1,11109,,,0,"Update Ubuntu LTS ISO to 16.04.6

Change-Id: I91ad3c42b1e588d70b4e215e61bc9517ea8dd7a4
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/99/640399/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/osbash/lib/osbash/lib.ubuntu-16.04-server-i386.sh', 'labs/stacktrain/distros/ubuntu_16_04_server_amd64.py', 'labs/osbash/lib/osbash/lib.ubuntu-16.04-server-amd64.sh']",3,dec0ade22667ac9033815ebb8e95d7dd2f1c26da,update_xenial,ISO_URL=$ISO_URL_BASE/ubuntu-16.04.6-server-amd64.isoISO_MD5=ac8a79a86a905ebdc3ef3f5dd16b7360,ISO_URL=$ISO_URL_BASE/ubuntu-16.04.5-server-amd64.isoISO_MD5=24636fd103a2a43c95659f1c3c63718e,8,8
openstack%2Freleases~master~If72394636fec238cc597386a067b83be9f81b9f2,openstack/releases,master,If72394636fec238cc597386a067b83be9f81b9f2,swiftclient 3.7.0 release,MERGED,2019-03-01 22:39:38.000000000,2019-03-05 13:03:46.000000000,2019-03-05 13:03:46.000000000,"[{'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 22:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/33cb11dc033df2b5b11cd2c026bbdfb1c1b2e451', 'message': 'swiftclient 3.6.1 release\n\nChange-Id: If72394636fec238cc597386a067b83be9f81b9f2\n'}, {'number': 2, 'created': '2019-03-05 04:58:26.000000000', 'files': ['deliverables/stein/python-swiftclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/128274a67ea35910303d06e78b0de14d3b9b5c68', 'message': 'swiftclient 3.7.0 release\n\nChange-Id: If72394636fec238cc597386a067b83be9f81b9f2\n'}]",0,640549,128274a67ea35910303d06e78b0de14d3b9b5c68,11,3,2,330,,,0,"swiftclient 3.7.0 release

Change-Id: If72394636fec238cc597386a067b83be9f81b9f2
",git fetch https://review.opendev.org/openstack/releases refs/changes/49/640549/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/python-swiftclient.yaml'],1,33cb11dc033df2b5b11cd2c026bbdfb1c1b2e451,swiftclient_release,releases: - version: 3.6.1 projects: - repo: openstack/python-swiftclient hash: eabed44f82ea447a76f4bbe9effd20ff919f64ab,,5,0
openstack%2Fmanila~master~I36b1757acbacfeb48264946ff7a5299ddd3307e8,openstack/manila,master,I36b1757acbacfeb48264946ff7a5299ddd3307e8,Refactor Container Driver,MERGED,2019-02-19 16:27:00.000000000,2019-03-05 12:53:07.000000000,2019-03-05 12:53:06.000000000,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-02-19 16:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7ee79df733d3c35428a48d053afd9f92161b0a33', 'message': ""Refactor Container Driver\n\nThe container driver code needs a refactor to facilitate\nthe development of new functionality. This patch improves:\n\n- Error handling: don't swallow every exception.\n- Method modularization: move common code to private methods.\n- Move methods to more appropriate classes: methods should live\n  in classes that encapsulate their responsibility. E.g: the\n  protocol helper should not access the container to obtain its\n  IP address, it should invoke a method from the container helper.\n- Don't use share_id everywhere: even though the code\n  currently does not use the instance_id, deriving the\n  share name from the export location makes it easier to\n  support instance_id or manage/unmanage future implementations.\n\nChange-Id: I36b1757acbacfeb48264946ff7a5299ddd3307e8\n""}, {'number': 2, 'created': '2019-02-26 12:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/445db46976b43884648856839acaf69836925847', 'message': ""Refactor Container Driver\n\nThe container driver code needs a refactor to facilitate\nthe development of new functionality. This patch improves:\n\n- Error handling: don't swallow every exception.\n- Method modularization: move common code to private methods.\n- Move methods to more appropriate classes: methods should live\n  in classes that encapsulate their responsibility. E.g: the\n  protocol helper should not access the container to obtain its\n  IP address, it should invoke a method from the container helper.\n- Don't use share_id everywhere: even though the code\n  currently does not use the instance_id, deriving the\n  share name from the export location makes it easier to\n  support instance_id or manage/unmanage future implementations.\n\nChange-Id: I36b1757acbacfeb48264946ff7a5299ddd3307e8\n""}, {'number': 3, 'created': '2019-03-04 11:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7853d659a1fdf45a4cb37861e2b859d56a23a8aa', 'message': ""Refactor Container Driver\n\nThe container driver code needs a refactor to facilitate\nthe development of new functionality. This patch improves:\n\n- Error handling: don't swallow every exception.\n- Method modularization: move common code to private methods.\n- Move methods to more appropriate classes: methods should live\n  in classes that encapsulate their responsibility. E.g: the\n  protocol helper should not access the container to obtain its\n  IP address, it should invoke a method from the container helper.\n- Don't use share_id everywhere: even though the code\n  currently does not use the instance_id, deriving the\n  share name from the export location makes it easier to\n  support instance_id or manage/unmanage future implementations.\n\nChange-Id: I36b1757acbacfeb48264946ff7a5299ddd3307e8\n""}, {'number': 4, 'created': '2019-03-04 17:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/032ddf27db22780180903d1a0ffbb9540e4c6e3c', 'message': ""Refactor Container Driver\n\nThe container driver code needs a refactor to facilitate\nthe development of new functionality. This patch improves:\n\n- Error handling: don't swallow every exception.\n- Method modularization: move common code to private methods.\n- Move methods to more appropriate classes: methods should live\n  in classes that encapsulate their responsibility. E.g: the\n  protocol helper should not access the container to obtain its\n  IP address, it should invoke a method from the container helper.\n- Don't use share_id everywhere: even though the code\n  currently does not use the instance_id, deriving the\n  share name from the export location makes it easier to\n  support instance_id or manage/unmanage future implementations.\n\nChange-Id: I36b1757acbacfeb48264946ff7a5299ddd3307e8\n""}, {'number': 5, 'created': '2019-03-04 18:34:20.000000000', 'files': ['manila/tests/share/drivers/container/test_storage_helper.py', 'manila/share/drivers/container/protocol_helper.py', 'manila/tests/share/drivers/container/test_driver.py', 'manila/tests/share/drivers/container/fakes.py', 'manila/share/drivers/container/driver.py', 'manila/tests/share/drivers/container/test_container_helper.py', 'manila/share/drivers/container/storage_helper.py', 'manila/share/drivers/container/container_helper.py', 'manila/tests/share/drivers/container/test_protocol_helper.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/28df9d22683c5336c9cb10be80805473e739035c', 'message': ""Refactor Container Driver\n\nThe container driver code needs a refactor to facilitate\nthe development of new functionality. This patch improves:\n\n- Error handling: don't swallow every exception.\n- Method modularization: move common code to private methods.\n- Move methods to more appropriate classes: methods should live\n  in classes that encapsulate their responsibility. E.g: the\n  protocol helper should not access the container to obtain its\n  IP address, it should invoke a method from the container helper.\n- Don't use share_id everywhere: even though the code\n  currently does not use the instance_id, deriving the\n  share name from the export location makes it easier to\n  support instance_id or manage/unmanage future implementations.\n\nChange-Id: I36b1757acbacfeb48264946ff7a5299ddd3307e8\n""}]",52,637926,28df9d22683c5336c9cb10be80805473e739035c,55,14,5,14567,,,0,"Refactor Container Driver

The container driver code needs a refactor to facilitate
the development of new functionality. This patch improves:

- Error handling: don't swallow every exception.
- Method modularization: move common code to private methods.
- Move methods to more appropriate classes: methods should live
  in classes that encapsulate their responsibility. E.g: the
  protocol helper should not access the container to obtain its
  IP address, it should invoke a method from the container helper.
- Don't use share_id everywhere: even though the code
  currently does not use the instance_id, deriving the
  share name from the export location makes it easier to
  support instance_id or manage/unmanage future implementations.

Change-Id: I36b1757acbacfeb48264946ff7a5299ddd3307e8
",git fetch https://review.opendev.org/openstack/manila refs/changes/26/637926/5 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/drivers/container/test_storage_helper.py', 'manila/share/drivers/container/protocol_helper.py', 'manila/tests/share/drivers/container/test_driver.py', 'manila/share/drivers/container/driver.py', 'manila/tests/share/drivers/container/fakes.py', 'manila/tests/share/drivers/container/test_container_helper.py', 'manila/share/drivers/container/container_helper.py', 'manila/share/drivers/container/storage_helper.py', 'manila/tests/share/drivers/container/test_protocol_helper.py']",9,7ee79df733d3c35428a48d053afd9f92161b0a33,manage-unmanage-with-share-servers," self.DockerCIFSHelper.delete_share(""fakeserver"", ""fakeshareid"") [""net"", ""conf"", ""delshare"", ""fakeshareid""], False) [""net"", ""conf"", ""getparm"", ""fake_share"", ""fake_access""], swallow_exception=True) ""fakeserver"", ""fakeshareid"", allow_rules, [], []) self.DockerCIFSHelper.update_access(""fakeserver"", ""fakeshareid"", self.DockerCIFSHelper.update_access(""fakeserver"", ""fakeshareid"", [], self.DockerCIFSHelper.update_access(""fakeserver"", ""fakeshareid"", [], [], delete_rules)"," self.DockerCIFSHelper.delete_share(""fakeserver"") [""net"", ""conf"", ""delshare"", ""fakeshareid""]) [""net"", ""conf"", ""getparm"", ""fake_share"", ""fake_access""]) ""fakeserver"", allow_rules, [], []) self.DockerCIFSHelper.update_access(""fakeserver"", self.DockerCIFSHelper.update_access(""fakeserver"", [], self.DockerCIFSHelper.update_access(""fakeserver"", [], [], delete_rules) @ddt.data(('inet', ""192.168.0.254"", [""5: br0 inet 192.168.0.254/24 brd 192.168.0.255 "" ""scope global br0 valid_lft forever preferred_lft forever""]), (""inet6"", ""2001:470:8:c82:6600:6aff:fe84:8dda"", [""5: br0 inet6 2001:470:8:c82:6600:6aff:fe84:8dda/64 "" ""scope global valid_lft forever preferred_lft forever""]), ) @ddt.unpack def test__fetch_container_address(self, address_family, expected_address, return_value): self.DockerCIFSHelper.container.execute = mock.Mock( return_value=return_value) address = self.DockerCIFSHelper._fetch_container_address( ""fakeserver"", address_family) self.assertEqual(expected_address, address)",559,276
openstack%2Fdevstack~stable%2Fnewton~Ie810b22eacd81c3f648f351933106b3397c69773,openstack/devstack,stable/newton,Ie810b22eacd81c3f648f351933106b3397c69773,Use split instead of strip,ABANDONED,2019-03-05 11:33:31.000000000,2019-03-05 12:51:38.000000000,,"[{'_account_id': 970}, {'_account_id': 4146}, {'_account_id': 13252}, {'_account_id': 17685}, {'_account_id': 25618}]","[{'number': 1, 'created': '2019-03-05 11:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/edc2f4e4d4ac4c7c35957fa5045f2aa5a63d11d4', 'message': 'Use split instead of strip\n\nIf pip major version is greater than 9 stack.sh fails due\nto issue with incorrect version. strip return 1, split\nwill return 10 or higher.\n\nTrivialFix\n\nChange-Id: Ie810b22eacd81c3f648f351933106b3397c69773\n'}, {'number': 2, 'created': '2019-03-05 11:41:07.000000000', 'files': ['inc/python'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8be6dbc71e9d4ce5485ec3222970d1297ebd324b', 'message': ""Use split instead of strip\n\nIf pip major version is greater than 9 stack.sh fails due\nto issue with incorrect version. strip return 1, split\nwill return 10 or higher\n\nIt was in past in review:\n\nProperly get pip version\n\nThe old code was strip()ing the version string instead of split()ing the\nversion string so we always got the first character of the version\nstring. This worked fine as long as the pip version was single digit but\nas soon as it rolls over to '10.stuff' we will compare:\n\n  pip version 1 (instead of 10) > 6\n\nWhich fails bceause 1 is less than six. Instaed we really do want to\ncompare 10 > 6 so use split on '.' instead.\n\nCloses-Bug: #1764046\nChange-Id: Ic7d0c04d7fa77774ab2d70fb9d11f182becec553\n(cherry picked from commit 0657795)i\n\nChange-Id: Ie810b22eacd81c3f648f351933106b3397c69773\n""}]",0,640985,8be6dbc71e9d4ce5485ec3222970d1297ebd324b,5,5,2,25618,,,0,"Use split instead of strip

If pip major version is greater than 9 stack.sh fails due
to issue with incorrect version. strip return 1, split
will return 10 or higher

It was in past in review:

Properly get pip version

The old code was strip()ing the version string instead of split()ing the
version string so we always got the first character of the version
string. This worked fine as long as the pip version was single digit but
as soon as it rolls over to '10.stuff' we will compare:

  pip version 1 (instead of 10) > 6

Which fails bceause 1 is less than six. Instaed we really do want to
compare 10 > 6 so use split on '.' instead.

Closes-Bug: #1764046
Change-Id: Ic7d0c04d7fa77774ab2d70fb9d11f182becec553
(cherry picked from commit 0657795)i

Change-Id: Ie810b22eacd81c3f648f351933106b3397c69773
",git fetch https://review.opendev.org/openstack/devstack refs/changes/85/640985/2 && git format-patch -1 --stdout FETCH_HEAD,['inc/python'],1,edc2f4e4d4ac4c7c35957fa5045f2aa5a63d11d4,bug/1764046," print(pip.__version__.split('.')[0])"")"," print(pip.__version__.strip('.')[0])"")",1,1
openstack%2Fkuryr-tempest-plugin~master~I0faa3272e0920604da79f52d51f200335891f605,openstack/kuryr-tempest-plugin,master,I0faa3272e0920604da79f52d51f200335891f605,Test CRD podSelector update,MERGED,2019-02-19 13:01:32.000000000,2019-03-05 12:44:30.000000000,2019-03-05 12:44:30.000000000,"[{'_account_id': 4727}, {'_account_id': 6598}, {'_account_id': 11600}, {'_account_id': 21302}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-02-19 13:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/45c22e2b7ea0f6f1e29683f06487762bfe682934', 'message': 'Test CRD podSelector update\n\nWhen the podSelector of a NP is updated,\nthe podSelector on the respective CRD must also be\nupdated with the same values.\n\nChange-Id: I0faa3272e0920604da79f52d51f200335891f605\n'}, {'number': 2, 'created': '2019-02-19 15:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/38215e8e0ffeb2a94b8ecf6956d22c23fe41abf6', 'message': 'Test CRD podSelector update\n\nWhen the podSelector of a NP is updated,\nthe podSelector on the respective CRD must also be\nupdated with the same values.\n\nChange-Id: I0faa3272e0920604da79f52d51f200335891f605\n'}, {'number': 3, 'created': '2019-02-20 10:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/0b48067bab4002037732707c8a27e034d6247d64', 'message': 'Test CRD podSelector update\n\nWhen the podSelector of a NP is updated,\nthe podSelector on the respective CRD must also be\nupdated with the same values.\n\nDepends-On: https://review.openstack.org/#/c/636590/\n\nChange-Id: I0faa3272e0920604da79f52d51f200335891f605\n'}, {'number': 4, 'created': '2019-02-26 13:12:17.000000000', 'files': ['kuryr_tempest_plugin/tests/scenario/test_network_policy.py', 'kuryr_tempest_plugin/tests/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/0d51e9905bf9d9af62d6f536b7c2156956c59699', 'message': 'Test CRD podSelector update\n\nWhen the podSelector of a NP is updated,\nthe podSelector on the respective CRD must also be\nupdated with the same values.\n\nDepends-On: https://review.openstack.org/#/c/636590/\n\nChange-Id: I0faa3272e0920604da79f52d51f200335891f605\n'}]",11,637836,0d51e9905bf9d9af62d6f536b7c2156956c59699,26,7,4,27032,,,0,"Test CRD podSelector update

When the podSelector of a NP is updated,
the podSelector on the respective CRD must also be
updated with the same values.

Depends-On: https://review.openstack.org/#/c/636590/

Change-Id: I0faa3272e0920604da79f52d51f200335891f605
",git fetch https://review.opendev.org/openstack/kuryr-tempest-plugin refs/changes/36/637836/4 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_tempest_plugin/tests/scenario/test_network_policy.py', 'kuryr_tempest_plugin/tests/scenario/base.py']",2,45c22e2b7ea0f6f1e29683f06487762bfe682934,test-crd-pod-selector-update," def create_network_policy(cls, name=None, namespace='default', match_labels=None): match_labels=match_labels), def update_network_policy(cls, np): np_name = np.metadata.name np_namespace = np.metadata.namespace np_updated = cls.k8s_client.NetworkingV1Api( ).replace_namespaced_network_policy( name=np_name, namespace=np_namespace, body=np) return np_updated @classmethod def read_network_policy(cls, np): np_name = np.metadata.name np_namespace = np.metadata.namespace return cls.k8s_client.NetworkingV1Api( ).read_namespaced_network_policy( name=np_name, namespace=np_namespace) @classmethod"," def create_network_policy(cls, name=None, namespace='default'): match_labels=None),",57,2
openstack%2Fkuryr-kubernetes~master~Id60457fc86e2bcf836cf854b12b2872fd68a35f5,openstack/kuryr-kubernetes,master,Id60457fc86e2bcf836cf854b12b2872fd68a35f5,Switch except statements order,MERGED,2019-02-20 16:11:37.000000000,2019-03-05 12:42:28.000000000,2019-03-05 12:42:28.000000000,"[{'_account_id': 6598}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2019-02-20 16:11:37.000000000', 'files': ['kuryr_kubernetes/controller/drivers/lbaasv2.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/8eaeb88d1e89aabdb5010531b9e1c82e7102c2f6', 'message': 'Switch except statements order\n\nneutronclient.common.exceptions.NotFound is subclass of\nneutronclient.common.exceptions.NeutronClientexception, so statements\ncatching the latter should be last of except clauses. This commit\nswitches order of except statements in LBaaSv2Driver to fix that.\n\nChange-Id: Id60457fc86e2bcf836cf854b12b2872fd68a35f5\n'}]",0,638192,8eaeb88d1e89aabdb5010531b9e1c82e7102c2f6,7,3,1,11600,,,0,"Switch except statements order

neutronclient.common.exceptions.NotFound is subclass of
neutronclient.common.exceptions.NeutronClientexception, so statements
catching the latter should be last of except clauses. This commit
switches order of except statements in LBaaSv2Driver to fix that.

Change-Id: Id60457fc86e2bcf836cf854b12b2872fd68a35f5
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/92/638192/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/drivers/lbaasv2.py'],1,8eaeb88d1e89aabdb5010531b9e1c82e7102c2f6,switch-statement," except n_exc.NotFound: LOG.debug('Security group %s already deleted', sg_id)"," except n_exc.NotFound: LOG.debug('Security group %s already deleted', sg_id)",2,2
openstack%2Ftripleo-ci~master~I89f7e4af20188203e77bae3bcac82a474403f607,openstack/tripleo-ci,master,I89f7e4af20188203e77bae3bcac82a474403f607,Unskip neutron tempest plugin,ABANDONED,2019-01-17 07:38:27.000000000,2019-03-05 12:35:47.000000000,,"[{'_account_id': 8367}, {'_account_id': 10022}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-17 07:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/54d5a2b6b44ba038e3e1d109f8c3ad4ceb71ff8c', 'message': 'Unskip neutron tempest plugin\n\nDepends-On: https://review.openstack.org/#/c/606937/\nChange-Id: I89f7e4af20188203e77bae3bcac82a474403f607\n'}, {'number': 2, 'created': '2019-01-17 12:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/616c4701cb0b79fe8f613ac4a794ceace131f5d0', 'message': 'Unskip neutron tempest plugin\n\nDepends-On: https://review.openstack.org/#/c/606937/\nChange-Id: I89f7e4af20188203e77bae3bcac82a474403f607\n'}, {'number': 3, 'created': '2019-01-21 05:32:49.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2250d9979a9f7f75932c5380149e79c40e3e876b', 'message': 'Unskip neutron tempest plugin\n\nDepends-On: https://review.openstack.org/#/c/606937/\nChange-Id: I89f7e4af20188203e77bae3bcac82a474403f607\n'}]",0,631441,2250d9979a9f7f75932c5380149e79c40e3e876b,13,5,3,12393,,,0,"Unskip neutron tempest plugin

Depends-On: https://review.openstack.org/#/c/606937/
Change-Id: I89f7e4af20188203e77bae3bcac82a474403f607
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/41/631441/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,54d5a2b6b44ba038e3e1d109f8c3ad4ceb71ff8c,unskip_neutorn, - 'neutron_tempest_plugin' - 'neutron_tempest_plugin' - 'neutron_tempest_plugin' - 'neutron_tempest_plugin',,4,0
openstack%2Frpm-packaging~master~I76be2f90709adeda19e1f8d6882737644de9251f,openstack/rpm-packaging,master,I76be2f90709adeda19e1f8d6882737644de9251f,os-refresh-config: Fix dirs,MERGED,2019-03-04 10:34:18.000000000,2019-03-05 12:34:46.000000000,2019-03-04 12:35:45.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 10:34:18.000000000', 'files': ['openstack/os-refresh-config/os-refresh-config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9373efe3a195bd4bdbb1d58cb2f083b89db140a5', 'message': 'os-refresh-config: Fix dirs\n\nWhen py2name translates to python-os-refresh-config, the\npre-configure.d/, configure.d/, migration.d/ and post-configure.d/\ndirectories are installed into the wrong place. Fix this by not using\n%{name} which would be wrong in the given example.\n\nChange-Id: I76be2f90709adeda19e1f8d6882737644de9251f\n'}]",0,640719,9373efe3a195bd4bdbb1d58cb2f083b89db140a5,10,5,1,7102,,,0,"os-refresh-config: Fix dirs

When py2name translates to python-os-refresh-config, the
pre-configure.d/, configure.d/, migration.d/ and post-configure.d/
directories are installed into the wrong place. Fix this by not using
%{name} which would be wrong in the given example.

Change-Id: I76be2f90709adeda19e1f8d6882737644de9251f
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/19/640719/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-refresh-config/os-refresh-config.spec.j2'],1,9373efe3a195bd4bdbb1d58cb2f083b89db140a5,,install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/pre-configure.d install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/configure.d install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/migration.d install -d -m 755 %{buildroot}%{_libexecdir}/os-refresh-config/post-configure.d%{_libexecdir}/os-refresh-config,install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/pre-configure.d install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/configure.d install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/migration.d install -d -m 755 %{buildroot}%{_libexecdir}/%{name}/post-configure.d%{_libexecdir}/%{name},5,5
openstack%2Frpm-packaging~master~Ic986b0e6d09b4a2512ce65da1f044634f7f32de9,openstack/rpm-packaging,master,Ic986b0e6d09b4a2512ce65da1f044634f7f32de9,os-apply-config: Install the templates dir,MERGED,2019-03-04 10:30:43.000000000,2019-03-05 12:34:18.000000000,2019-03-04 11:25:27.000000000,"[{'_account_id': 6593}, {'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-04 10:30:43.000000000', 'files': ['openstack/os-apply-config/os-apply-config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d5afb096e072d9461652d809489024d9891e3adf', 'message': 'os-apply-config: Install the templates dir\n\nThis is needed for heat-agents which installs files into the\ntemplates/ directory.\n\nChange-Id: Ic986b0e6d09b4a2512ce65da1f044634f7f32de9\n'}]",0,640718,d5afb096e072d9461652d809489024d9891e3adf,9,4,1,7102,,,0,"os-apply-config: Install the templates dir

This is needed for heat-agents which installs files into the
templates/ directory.

Change-Id: Ic986b0e6d09b4a2512ce65da1f044634f7f32de9
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/18/640718/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-apply-config/os-apply-config.spec.j2'],1,d5afb096e072d9461652d809489024d9891e3adf,,install -d -m 755 %{buildroot}%{_libexecdir}/os-apply-config/templates%dir %{_libexecdir}/os-apply-config %dir %{_libexecdir}/os-apply-config/templates,,3,0
openstack%2Fblazar~master~I725774e3006f52087bb9bc442c40a8ddcccbdbc3,openstack/blazar,master,I725774e3006f52087bb9bc442c40a8ddcccbdbc3,Update placement client unit tests,MERGED,2019-03-03 07:35:17.000000000,2019-03-05 12:33:37.000000000,2019-03-05 12:33:37.000000000,"[{'_account_id': 8878}, {'_account_id': 13192}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-03 07:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/6b4398310b666e33fd1599a1e5b9abd09c304f85', 'message': 'Update unit tests of placement client\n\nIn commit 09934718f7d34d61abcb63b07d6e5c1d783d4150, kestoneauth1\nsupports client-side rate limiting, and a new parameter,\n`rate_semaphore` is added.\n\nDue to this change, the unit tests of the placment client in blazar\nstarted to fail, so this patch updates the unit tests accordingly.\n\nChange-Id: I725774e3006f52087bb9bc442c40a8ddcccbdbc3\n'}, {'number': 2, 'created': '2019-03-05 09:28:12.000000000', 'files': ['blazar/tests/utils/openstack/test_placement.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/9160ada28aa447875af51686568132f4e30216cc', 'message': 'Update placement client unit tests\n\nIn commit 09934718f7d34d61abcb63b07d6e5c1d783d4150, keystoneauth1 got\nsupport for client-side rate limiting. A new parameter `rate_semaphore`\nwas added.\n\nDue to this change, the unit tests of the placment client in blazar\nstarted to fail. This patch updates the unit tests accordingly.\n\nChange-Id: I725774e3006f52087bb9bc442c40a8ddcccbdbc3\n'}]",0,640623,9160ada28aa447875af51686568132f4e30216cc,9,4,2,25625,,,0,"Update placement client unit tests

In commit 09934718f7d34d61abcb63b07d6e5c1d783d4150, keystoneauth1 got
support for client-side rate limiting. A new parameter `rate_semaphore`
was added.

Due to this change, the unit tests of the placment client in blazar
started to fail. This patch updates the unit tests accordingly.

Change-Id: I725774e3006f52087bb9bc442c40a8ddcccbdbc3
",git fetch https://review.opendev.org/openstack/blazar refs/changes/23/640623/1 && git format-patch -1 --stdout FETCH_HEAD,['blazar/tests/utils/openstack/test_placement.py'],1,6b4398310b666e33fd1599a1e5b9abd09c304f85,gate-fix," def _add_default_kwargs(self, kwargs): kwargs['endpoint_filter'] = {'service_type': 'placement', 'interface': 'public'} kwargs['headers'] = {'accept': 'application/json'} kwargs['microversion'] = PLACEMENT_MICROVERSION kwargs['raise_exc'] = False kwargs['rate_semaphore'] = mock.ANY def _assert_keystone_called_once(self, kss_req, url, method, **kwargs): self._add_default_kwargs(kwargs) kss_req.assert_called_once_with(url, method, **kwargs) def _assert_keystone_called_any(self, kss_req, url, method, **kwargs): self._add_default_kwargs(kwargs) kss_req.assert_any_call(url, method, **kwargs) self._assert_keystone_called_once(kss_req, url, 'GET') self._assert_keystone_called_once(kss_req, url, 'POST', json=data) self._assert_keystone_called_once(kss_req, url, 'PUT', json=data) self._assert_keystone_called_once(kss_req, url, 'DELETE') self._assert_keystone_called_once(kss_req, expected_url, 'GET') self._assert_keystone_called_once(kss_req, expected_url, 'GET') expected_data = {'uuid': rp_uuid, 'name': rp_name, 'parent_provider_uuid': parent_uuid} self._assert_keystone_called_once(kss_req, expected_url, 'POST', json=expected_data) self._assert_keystone_called_once(kss_req, expected_url, 'DELETE') self._assert_keystone_called_any(kss_req, expected_url_get, 'GET') expected_data = {'name': 'blazar_compute-1', 'parent_provider_uuid': host_uuid} self._assert_keystone_called_any(kss_req, expected_url_post, 'POST', json=expected_data) self._assert_keystone_called_any(kss_req, expected_url_get, 'GET') self._assert_keystone_called_any(kss_req, expected_url_post, 'DELETE') self._assert_keystone_called_any(kss_req, expected_url_get, 'GET') expected_data = {'name': 'CUSTOM_RESERVATION_ABC_DEF'} self._assert_keystone_called_once(kss_req, expected_url, 'POST', json=expected_data) self._assert_keystone_called_once(kss_req, expected_url, 'DELETE') self._assert_keystone_called_once(kss_req, expected_url, 'PUT', json=expected_data) self._assert_keystone_called_once(kss_req, expected_url, 'PUT', json=expected_data) self._assert_keystone_called_once(kss_req, expected_url, 'DELETE')"," kss_req.assert_called_once_with( url, 'GET', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( url, 'POST', json=data, endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( url, 'PUT', json=data, endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( url, 'DELETE', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'GET', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'GET', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'POST', json={'uuid': rp_uuid, 'name': rp_name, 'parent_provider_uuid': parent_uuid}, endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'DELETE', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_any_call( expected_url_get, 'GET', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_any_call( expected_url_post, 'POST', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, json={'name': 'blazar_compute-1', 'parent_provider_uuid': host_uuid}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_any_call( expected_url_get, 'GET', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_any_call( expected_url_post, 'DELETE', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_any_call( expected_url_get, 'GET', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'POST', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, json={'name': 'CUSTOM_RESERVATION_ABC_DEF'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'DELETE', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'PUT', json=expected_data, endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'PUT', json=expected_data, endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False) kss_req.assert_called_once_with( expected_url, 'DELETE', endpoint_filter={'service_type': 'placement', 'interface': 'public'}, headers={'accept': 'application/json'}, microversion=PLACEMENT_MICROVERSION, raise_exc=False)",45,114
openstack%2Fmonasca-common~master~I504919a13a6c9380a8b41e29c21d9171239f0d27,openstack/monasca-common,master,I504919a13a6c9380a8b41e29c21d9171239f0d27,Use proper naming for docker base image zuul jobs,MERGED,2019-03-04 12:29:51.000000000,2019-03-05 12:31:25.000000000,2019-03-05 12:31:25.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-03-04 12:29:51.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/5cfcbda66c6d3285c0be08a2e1f5f3ecc9032b43', 'message': 'Use proper naming for docker base image zuul jobs\n\nhttps://docs.openstack.org/infra/manual/drivers.html#consistent-naming-for-jobs-with-zuul-v3\n\nChange-Id: I504919a13a6c9380a8b41e29c21d9171239f0d27\n'}]",0,640747,5cfcbda66c6d3285c0be08a2e1f5f3ecc9032b43,11,3,1,21922,,,0,"Use proper naming for docker base image zuul jobs

https://docs.openstack.org/infra/manual/drivers.html#consistent-naming-for-jobs-with-zuul-v3

Change-Id: I504919a13a6c9380a8b41e29c21d9171239f0d27
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/47/640747/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5cfcbda66c6d3285c0be08a2e1f5f3ecc9032b43,zuul, - build-monasca-common-docker-base-image - publish-monasca-common-docker-base-image - publish-monasca-common-docker-base-image - publish-monasca-common-docker-base-image name: build-monasca-common-docker-base-image name: publish-monasca-common-docker-base-image parent: build-monasca-common-docker-base-image, - docker-build-monasca-base - docker-publish-monasca-base - docker-publish-monasca-base - docker-publish-monasca-base name: docker-build-monasca-base name: docker-publish-monasca-base parent: docker-build-monasca-base,7,7
openstack%2Frpm-packaging~master~Ibbee30fcd39ebf96eca093a6b8f4d09c5afea596,openstack/rpm-packaging,master,Ibbee30fcd39ebf96eca093a6b8f4d09c5afea596,Fix keystoneclient unit tests,MERGED,2019-03-05 09:06:00.000000000,2019-03-05 12:27:08.000000000,2019-03-05 12:27:08.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 09:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/aa6e46fa3d3ca7fcdfa9f8faca3607504dfffcc5', 'message': 'Fix keystoneclient unit tests\n\nThe latest keystoneauth release included a feature that is incompatible\nwith keystoneclient and breaks the unit tests. Add a temporary patch to\nfix the issue.\n\nChange-Id: Ibbee30fcd39ebf96eca093a6b8f4d09c5afea596\n'}, {'number': 2, 'created': '2019-03-05 09:37:22.000000000', 'files': ['openstack/keystoneauth1/keystoneauth1.spec.j2', 'openstack/keystoneauth1/0001-Fix-rate-semaphore-for-keystoneclient.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7b6246a057381db1fcd7be7ab952b6e514c79b07', 'message': 'Fix keystoneclient unit tests\n\nThe latest keystoneauth release included a feature that is incompatible\nwith keystoneclient and breaks the unit tests. Add a temporary patch to\nfix the issue.\n\nChange-Id: Ibbee30fcd39ebf96eca093a6b8f4d09c5afea596\n'}]",0,640958,7b6246a057381db1fcd7be7ab952b6e514c79b07,15,7,2,8482,,,0,"Fix keystoneclient unit tests

The latest keystoneauth release included a feature that is incompatible
with keystoneclient and breaks the unit tests. Add a temporary patch to
fix the issue.

Change-Id: Ibbee30fcd39ebf96eca093a6b8f4d09c5afea596
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/58/640958/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/keystoneauth1/keystoneauth1.spec.j2', 'openstack/keystoneauth1/0001-Fix-rate-semaphore-for-keystoneclient.patch']",2,aa6e46fa3d3ca7fcdfa9f8faca3607504dfffcc5,fix-ksa,"From 7b74cc9adb77f025190557e47f6dadae110e6ab5 Mon Sep 17 00:00:00 2001 From: Colleen Murphy <colleen.murphy@suse.de> Date: Tue, 5 Mar 2019 10:00:46 +0100 Subject: [PATCH] Fix rate semaphore for keystoneclient When using keystoneclient sessions, the new parameter is not available and breaks the keystoneclient unit tests[1]. Only use the semaphore kwarg when using keystoneauth sessions. [1] https://review.openstack.org/640953 Change-Id: I0cc7f2514e143ec532d8fb895618f7cf1fea9cc3 --- keystoneauth1/adapter.py | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) diff --git a/keystoneauth1/adapter.py b/keystoneauth1/adapter.py index a15fd54..6bba62f 100644 --- a/keystoneauth1/adapter.py +++ b/keystoneauth1/adapter.py @@ -217,6 +217,8 @@ class Adapter(object): kwargs.setdefault('client_name', self.client_name) if self.client_version: kwargs.setdefault('client_version', self.client_version) + if self._rate_semaphore: + kwargs.setdefault('rate_semaphore', self._rate_semaphore) else: warnings.warn('Using keystoneclient sessions has been deprecated. ' @@ -232,8 +234,6 @@ class Adapter(object): if self.raise_exc is not None: kwargs.setdefault('raise_exc', self.raise_exc) - kwargs.setdefault('rate_semaphore', self._rate_semaphore) - return self.session.request(url, method, **kwargs) def get_token(self, auth=None): -- 2.21.0 ",,43,0
openstack%2Fvitrage~master~I4b55fda0b6e90f295896070384e82f0c3b67ba40,openstack/vitrage,master,I4b55fda0b6e90f295896070384e82f0c3b67ba40,improve logging of events enqueued,MERGED,2019-03-03 11:54:03.000000000,2019-03-05 12:15:12.000000000,2019-03-05 12:15:12.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}, {'_account_id': 26339}, {'_account_id': 29383}]","[{'number': 1, 'created': '2019-03-03 11:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/69f0c4b9a7e67a49f6f0d88ae9e6a39eea30dfc8', 'message': 'improve logging of events enqueued\n\nChange-Id: I4b55fda0b6e90f295896070384e82f0c3b67ba40\n'}, {'number': 2, 'created': '2019-03-03 13:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/b196381398eab6c6159c6dcdf570a5e0375c6ecd', 'message': 'improve logging of events enqueued\n\nChange-Id: I4b55fda0b6e90f295896070384e82f0c3b67ba40\n'}, {'number': 3, 'created': '2019-03-03 14:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/42f7dbfb5d80b0ec1a1d9f11b327619a80111ab7', 'message': 'improve logging of events enqueued\n\nChange-Id: I4b55fda0b6e90f295896070384e82f0c3b67ba40\n'}, {'number': 4, 'created': '2019-03-04 08:45:53.000000000', 'files': ['vitrage/entity_graph/driver_exec.py', 'vitrage/datasources/neutron/port/driver.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/b4a441bc090d7e3aa6c32fae6b4529b7d5eeb5fa', 'message': 'improve logging of events enqueued\n\nChange-Id: I4b55fda0b6e90f295896070384e82f0c3b67ba40\n'}]",2,640631,b4a441bc090d7e3aa6c32fae6b4529b7d5eeb5fa,37,6,4,19134,,,0,"improve logging of events enqueued

Change-Id: I4b55fda0b6e90f295896070384e82f0c3b67ba40
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/31/640631/4 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/entity_graph/driver_exec.py'],1,69f0c4b9a7e67a49f6f0d88ae9e6a39eea30dfc8,eyalb/log," LOG.info('EVENTS ENQUEUED:[%s] [%s] \n%s' % (publisher_id, event_type, events))", LOG.info('EVENTS ENQUEUED: \n' + str(events)),2,1
openstack%2Fcharm-nova-compute~stable%2F18.11~I1bb3cee4ac532d0867b4297c742707668566a527,openstack/charm-nova-compute,stable/18.11,I1bb3cee4ac532d0867b4297c742707668566a527,Enable support for auto-converge and post-copy,MERGED,2019-02-28 15:25:48.000000000,2019-03-05 11:57:09.000000000,2019-03-05 11:57:09.000000000,"[{'_account_id': 935}, {'_account_id': 6737}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 29356}]","[{'number': 1, 'created': '2019-02-28 15:25:48.000000000', 'files': ['hooks/nova_compute_context.py', 'templates/ocata/nova.conf', 'templates/pike/nova.conf', 'config.yaml', 'templates/newton/nova.conf', 'unit_tests/test_nova_compute_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/0043d38223dfec0a86abdf0a8968598751511a1e', 'message': 'Enable support for auto-converge and post-copy\n\nImplement missing configuration options and context to support\nconfiguration of:\n\n  live_migration_permit_auto_converge\n  live_migration_permit_post_copy\n\nin nova.conf. The configuration parameters are only added to the\nnova.conf template when live-migration is actually enabled, since they\nhave no purpose without live-migration enabled. The options are added to\nversion Newton and upwards as that is the Nova version since they were\nfirst supported.\n\nChange-Id: I1bb3cee4ac532d0867b4297c742707668566a527\nCloses-Bug: #1799916\n(cherry picked from commit 1fa2a8023cd4b1acee891a09311f4fd1b803e85d)\n'}]",0,640060,0043d38223dfec0a86abdf0a8968598751511a1e,9,5,1,6737,,,0,"Enable support for auto-converge and post-copy

Implement missing configuration options and context to support
configuration of:

  live_migration_permit_auto_converge
  live_migration_permit_post_copy

in nova.conf. The configuration parameters are only added to the
nova.conf template when live-migration is actually enabled, since they
have no purpose without live-migration enabled. The options are added to
version Newton and upwards as that is the Nova version since they were
first supported.

Change-Id: I1bb3cee4ac532d0867b4297c742707668566a527
Closes-Bug: #1799916
(cherry picked from commit 1fa2a8023cd4b1acee891a09311f4fd1b803e85d)
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/60/640060/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/nova_compute_context.py', 'templates/ocata/nova.conf', 'templates/pike/nova.conf', 'config.yaml', 'templates/newton/nova.conf', 'unit_tests/test_nova_compute_contexts.py']",6,0043d38223dfec0a86abdf0a8968598751511a1e,bug/1799916," 'live_migration_permit_auto_converge': False, 'live_migration_permit_post_copy': False, 'force_raw_images': True, 'reserved_host_memory': 512}, libvirt()) def test_libvirt_bin_context_migration_tcp_listen_with_auto_converge(self): self.kv.return_value = FakeUnitdata(**{'host_uuid': self.host_uuid}) self.lsb_release.return_value = {'DISTRIB_CODENAME': 'lucid'} self.test_config.set('enable-live-migration', True) self.test_config.set('live-migration-permit-auto-converge', True) libvirt = context.NovaComputeLibvirtContext() self.assertEqual( {'libvirtd_opts': '-d -l', 'libvirt_user': 'libvirtd', 'arch': platform.machine(), 'ksm': 'AUTO', 'kvm_hugepages': 0, 'listen_tls': 0, 'host_uuid': self.host_uuid, 'live_migration_uri': 'qemu+ssh://%s/system', 'live_migration_permit_auto_converge': True, 'live_migration_permit_post_copy': False, 'force_raw_images': True, 'reserved_host_memory': 512}, libvirt()) def test_libvirt_bin_context_migration_tcp_listen_with_post_copy(self): self.kv.return_value = FakeUnitdata(**{'host_uuid': self.host_uuid}) self.lsb_release.return_value = {'DISTRIB_CODENAME': 'lucid'} self.test_config.set('enable-live-migration', True) self.test_config.set('live-migration-permit-post-copy', True) libvirt = context.NovaComputeLibvirtContext() self.assertEqual( {'libvirtd_opts': '-d -l', 'libvirt_user': 'libvirtd', 'arch': platform.machine(), 'ksm': 'AUTO', 'kvm_hugepages': 0, 'listen_tls': 0, 'host_uuid': self.host_uuid, 'live_migration_uri': 'qemu+ssh://%s/system', 'live_migration_permit_auto_converge': False, 'live_migration_permit_post_copy': True,",,80,0
openstack%2Ftacker~master~Ia09240875bd5c0ceb70602d73a0a5c94a4dde060,openstack/tacker,master,Ia09240875bd5c0ceb70602d73a0a5c94a4dde060,Add functional test for reservation support,MERGED,2019-02-27 10:19:14.000000000,2019-03-05 11:49:29.000000000,2019-03-05 11:49:28.000000000,"[{'_account_id': 1011}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26588}]","[{'number': 1, 'created': '2019-02-27 10:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/422d41823fe5d3f3da3166f6b1d557420d5acf01', 'message': 'WIP:Add functional test for reservation support\n\nAdded functional test for reservation support.\n\nImplements: blueprint reservation-vnfm\nChange-Id: Ia09240875bd5c0ceb70602d73a0a5c94a4dde060\n'}, {'number': 2, 'created': '2019-02-28 06:26:44.000000000', 'files': ['tacker/tests/functional/base.py', 'tacker/tests/functional/vnfm/test_tosca_vnf_reservation.py', 'test-requirements.txt', 'tacker/tests/etc/samples/sample-tosca-vnfd-instance-reservation.yaml', 'tacker/tests/constants.py', 'lower-constraints.txt', 'tacker/tests/functional/vnfm/test_tosca_vnf_alarm.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/1d7cd6f6041ad5924bf522b959559bdf38bb7b13', 'message': 'Add functional test for reservation support\n\nAdded functional test for reservation support.\n\nImplements: blueprint reservation-vnfm\nChange-Id: Ia09240875bd5c0ceb70602d73a0a5c94a4dde060\n'}]",0,639621,1d7cd6f6041ad5924bf522b959559bdf38bb7b13,13,4,2,26463,,,0,"Add functional test for reservation support

Added functional test for reservation support.

Implements: blueprint reservation-vnfm
Change-Id: Ia09240875bd5c0ceb70602d73a0a5c94a4dde060
",git fetch https://review.opendev.org/openstack/tacker refs/changes/21/639621/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/functional/base.py', 'tacker/tests/functional/vnfm/test_tosca_vnf_reservation.py', 'test-requirements.txt', 'tacker/tests/constants.py', 'tacker/tests/etc/samples/sample-tosca-vnfd-instance-reservation.yaml', 'lower-constraints.txt', 'tacker/tests/functional/vnfm/test_tosca_vnf_alarm.py']",7,422d41823fe5d3f3da3166f6b1d557420d5acf01,bp/reservation-vnfm," self.trigger_vnf(vnf_id, mon_policy_name, mon_policy_action) self.trigger_vnf( vnf_id, mon_policy_name, scaling_out_action) self.trigger_vnf( vnf_id, scaling_in_name, scaling_in_action)"," vnf_trigger_path = '/vnfs/%s/triggers' def trigger_vnf(vnf, policy_name, policy_action): credential = 'g0jtsxu9' body = {""trigger"": {'policy_name': policy_name, 'action_name': policy_action, 'params': { 'data': {'alarm_id': '35a80852-e24f-46ed-bd34-e2f831d00172', 'current': 'alarm'}, # noqa 'credential': credential} } } self.client.post(vnf_trigger_path % vnf, body) trigger_vnf(vnf_id, mon_policy_name, mon_policy_action) trigger_vnf(vnf_id, mon_policy_name, scaling_out_action) trigger_vnf(vnf_id, scaling_in_name, scaling_in_action)",375,15
openstack%2Fpython-ironicclient~master~I0f2f37e840449ee41f747e2a43ed6f53c927094e,openstack/python-ironicclient,master,I0f2f37e840449ee41f747e2a43ed6f53c927094e,Deploy templates: client support,MERGED,2019-02-14 11:40:18.000000000,2019-03-05 11:49:23.000000000,2019-03-05 11:49:23.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-14 11:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/bf794a13618430377d5b07db08a36bd3c118df39', 'message': 'WIP: Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nStory: 1722275\nTask: 28678\n'}, {'number': 2, 'created': '2019-02-14 12:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/db878c8838425b6408074d9b01e1e15a4561cb6e', 'message': 'WIP: Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 3, 'created': '2019-02-14 13:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/47689f1bc06da1f6b06ec5b71671941c2b2dd77d', 'message': 'WIP: Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 4, 'created': '2019-02-15 17:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/bdbf5dd90a8f51f94003a6c9f7e6848a59a4c132', 'message': 'WIP: Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 5, 'created': '2019-02-15 19:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/3aaefc479b9ebd5aa4b8c122889af8bd36251d1f', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 6, 'created': '2019-02-22 18:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/395bbed9425bd4ca72a8c1bc6bc2f3d2d2f04cbb', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 7, 'created': '2019-02-25 11:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c31bce1016852524c7aae8223c1d7ef99210030e', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 8, 'created': '2019-02-25 12:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/38cb0a1ef80c7bf9fc10828bcab8384d426f38a3', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 9, 'created': '2019-02-26 17:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5722afb11d4b9b79cb274d3ee9dfe036b48e7cf9', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 10, 'created': '2019-02-26 18:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f04736c84be27a36e80085694de6ad586785e53b', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 11, 'created': '2019-02-26 19:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/ffb7621742d1681c4a955dbcfe5c6b277d590b14', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 12, 'created': '2019-02-28 13:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/25a975a71d623d16b28e7a5800cc8cbbfced2387', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 13, 'created': '2019-03-01 12:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5d4543d3aca6f82063527e908ed602d34bd1f28b', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}, {'number': 14, 'created': '2019-03-01 14:24:35.000000000', 'files': ['ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/common/http.py', 'ironicclient/osc/v1/baremetal_port.py', 'ironicclient/v1/deploy_template.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_deploy_template.py', 'ironicclient/v1/resource_fields.py', 'ironicclient/osc/v1/baremetal_deploy_template.py', 'ironicclient/tests/unit/v1/test_deploy_template.py', 'ironicclient/tests/functional/osc/v1/base.py', 'ironicclient/v1/client.py', 'releasenotes/notes/deploy-templates-df354ce825b00430.yaml', 'setup.cfg', 'ironicclient/common/utils.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_deploy_template_basic.py', 'ironicclient/osc/v1/baremetal_node.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/cc3725342820862724a86e27d63190d276231141', 'message': 'Deploy templates: client support\n\nAdds OSC support for the deploy templates API.\n\nChange-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e\nDepends-On: https://review.openstack.org/631845\nStory: 1722275\nTask: 28678\n'}]",30,636931,cc3725342820862724a86e27d63190d276231141,39,5,14,14826,,,0,"Deploy templates: client support

Adds OSC support for the deploy templates API.

Change-Id: I0f2f37e840449ee41f747e2a43ed6f53c927094e
Depends-On: https://review.openstack.org/631845
Story: 1722275
Task: 28678
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/31/636931/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/common/http.py', 'ironicclient/v1/deploy_template.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_deploy_template.py', 'ironicclient/v1/resource_fields.py', 'ironicclient/osc/v1/baremetal_deploy_template.py', 'ironicclient/tests/unit/v1/test_deploy_template.py', 'ironicclient/tests/functional/osc/v1/base.py', 'ironicclient/v1/client.py', 'setup.cfg', 'ironicclient/common/utils.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_deploy_template_basic.py', 'ironicclient/osc/v1/baremetal_node.py']",13,bf794a13618430377d5b07db08a36bd3c118df39,story/1722275," clean_steps = utils.handle_json_arg(clean_steps, 'clean steps') raid_config = utils.handle_json_arg(raid_config, 'target_raid_config')", if clean_steps == '-': clean_steps = utils.get_from_stdin('clean steps') if clean_steps: clean_steps = utils.handle_json_or_file_arg(clean_steps) if raid_config == '-': raid_config = utils.get_from_stdin('target_raid_config') raid_config = utils.handle_json_or_file_arg(raid_config),1348,8
openstack%2Ftacker~master~Ia6a87894ba219c045140e8e65e03f87509bbdb6d,openstack/tacker,master,Ia6a87894ba219c045140e8e65e03f87509bbdb6d,Add reservation support,MERGED,2018-12-05 08:27:42.000000000,2019-03-05 11:48:08.000000000,2019-03-05 11:48:07.000000000,"[{'_account_id': 1011}, {'_account_id': 18955}, {'_account_id': 19316}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26463}, {'_account_id': 26588}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-12-05 08:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/231c49d6f966b52712460914391fc95bf1ce0203', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 2, 'created': '2018-12-05 11:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/be2afa1eca0eb64f4ac19819de444923cb4b54b9', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 3, 'created': '2018-12-10 10:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3273b33c103767ffbd4cb10b84cac2f779bfeffb', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 4, 'created': '2018-12-27 11:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/7701f96e50f3e3993fcb42307466053cb7cf0d36', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 5, 'created': '2019-01-09 06:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b5e9d72c7e7dfa61cfd9a93e03f08980d1758cab', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 6, 'created': '2019-01-11 10:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/8e216e9ec6fc86e7eb094dbb531e7627f74caaae', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 7, 'created': '2019-01-11 13:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/6d833c05974245fd69b4908c544a79bd32fd4065', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 8, 'created': '2019-01-15 04:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/912fbfb612717a50e89f422b3c50fdeb7147f466', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 9, 'created': '2019-01-15 06:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/85750fa7d908dc31d16b426ea3d42e96bd3a0496', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 10, 'created': '2019-01-15 10:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ffc691b1b05e2f6bffae77e1ad7aab9f5fab2a5b', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 11, 'created': '2019-01-16 08:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/99c4214b92e0bfbd4a2274810ceabee222d60e24', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 12, 'created': '2019-01-17 07:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1798d44591f4feb1ce793240c82e6846c59f7fe6', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 13, 'created': '2019-01-23 04:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/f0eda35327937d5109642058d9ff2e054d6b8bdd', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 14, 'created': '2019-01-28 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b058eec0ac5ecd9aaa445e0ae885f838bd0d088b', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 15, 'created': '2019-01-29 08:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ac97aa7278b289843e946385bbc8d7dcb27526f3', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 16, 'created': '2019-02-05 04:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/6e12dd6cecbccf877fa002832bc8d67cb0317f6d', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 17, 'created': '2019-02-08 09:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/5576281ab6937a95d864c8809947b0e03f18b680', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 18, 'created': '2019-02-15 12:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/d63480f32918442e2df6de19f58e76caabf2bb2e', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 19, 'created': '2019-02-18 06:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/5d52085d3a013b16b7161815bb14ecd1b66cfba6', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 20, 'created': '2019-02-19 05:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/158c62ee7b3a5eb84333fbac5dc281a1e4e40787', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 21, 'created': '2019-02-22 13:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/38e2e4b4fb04110d9504ddcd51392e4f9475cd44', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 22, 'created': '2019-02-27 10:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/d320493b576979c2fdcb1d0e7f0384cc1a7df030', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}, {'number': 23, 'created': '2019-02-28 06:26:44.000000000', 'files': ['tacker/tosca/lib/tacker_nfv_defs.yaml', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/test_tosca-vnfd-instance-reservation.yaml', 'tacker/tosca/lib/tacker_defs.yaml', 'tacker/tosca/utils.py', 'requirements.txt', 'tacker/vnfm/plugin.py', 'samples/tosca-templates/vnfd/tosca-vnfd-host-reservation.yaml', 'tacker/tests/constants.py', 'tacker/tests/unit/db/utils.py', 'doc/source/reference/reservation_policy_usage_guide.rst', 'tacker/vnfm/monitor.py', 'tacker/tests/unit/vnfm/test_plugin.py', 'doc/source/reference/index.rst', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/test_tosca_post_process_template.yaml', '.zuul.yaml', 'tacker/vnfm/infra_drivers/openstack/translate_template.py', 'lower-constraints.txt', 'tacker/tests/unit/vnfm/test_monitor.py', 'tacker/tests/unit/vnfm/tosca/test_utils.py', 'releasenotes/notes/add-reservation-policy-support-0a197cfc7659cddf.yaml', 'samples/tosca-templates/vnfd/tosca-vnfd-host-reservation-param-values.yaml', 'samples/tosca-templates/vnfd/tosca-vnfd-instance-reservation-param-values.yaml', 'samples/tosca-templates/vnfd/tosca-vnfd-instance-reservation.yaml', 'tacker/plugins/common/constants.py', 'doc/source/install/devstack.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/2595cc112f82483365fc9bc71d861662dd622b11', 'message': 'Add reservation support\n\nAdded reservation policy support.\nWith reservation policy user can use the reserved resources\nby blazar to create VNF.\n\nDepends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73\nImplements: blueprint reservation-vnfm\nChange-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d\n'}]",65,622888,2595cc112f82483365fc9bc71d861662dd622b11,76,9,23,26463,,,0,"Add reservation support

Added reservation policy support.
With reservation policy user can use the reserved resources
by blazar to create VNF.

Depends-On:I2b989a49ac3447995a82ddb7193bf478bb847b73
Implements: blueprint reservation-vnfm
Change-Id: Ia6a87894ba219c045140e8e65e03f87509bbdb6d
",git fetch https://review.opendev.org/openstack/tacker refs/changes/88/622888/17 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/functional/base.py', 'tacker/common/exceptions.py', 'test-requirements.txt', 'tacker/vnfm/infra_drivers/openstack/translate_template.py', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/test_tosca-vnfd-reservation-id.yaml', 'tacker/tosca/lib/tacker_defs.yaml', 'tacker/tosca/utils.py', 'tacker/tests/unit/vnfm/test_monitor.py', 'tacker/vnfm/plugin.py', 'samples/tosca-templates/vnfd/tosca-vnfd-reservation-id.yaml', 'tacker/tests/constants.py', 'tacker/tests/etc/samples/sample-tosca-vnfd-reservation-id.yaml', 'samples/tosca-templates/vnfd/tosca-vnfd-reservation-id-param-values.yaml', 'tacker/tests/unit/db/utils.py', 'tacker/plugins/common/constants.py', 'tacker/tests/functional/vnfm/test_tosca_vnf_alarm.py', 'tacker/vnfm/monitor.py', 'tacker/tests/unit/vnfm/test_plugin.py']",18,231c49d6f966b52712460914391fc95bf1ce0203,bp/reservation-vnfm," self._mock_vnf_reservation_monitor() def _mock_vnf_reservation_monitor(self): self._vnf_reservation_mon = mock.Mock(wraps=FakeVNFMonitor()) fake_vnf_reservation_monitor = mock.Mock() fake_vnf_reservation_monitor.return_value = self._vnf_reservation_mon self._mock( 'tacker.vnfm.monitor.VNFReservationAlarmMonitor', fake_vnf_reservation_monitor) @patch('tacker.db.vnfm.vnfm_db.VNFMPluginDb.get_vnf') def test_create_vnf_trigger_scale_with_reservation(self, mock_get_vnf): dummy_vnf = self._get_dummy_active_vnf( utils.vnfd_reservation_alarm_scale_tosca_template) mock_get_vnf.return_value = dummy_vnf self._test_create_vnf_trigger(policy_name=""start_actions"", action_value=""SP_RSV-out"")",,651,14
openstack%2Frpm-packaging~master~I9520ace1096810045a1475396b4a8378c5679dd8,openstack/rpm-packaging,master,I9520ace1096810045a1475396b4a8378c5679dd8,os-api-ref: Drop oslosphinx BuildRequires and fix build,MERGED,2019-03-05 10:35:31.000000000,2019-03-05 11:44:45.000000000,2019-03-05 11:44:45.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 10:35:31.000000000', 'files': ['openstack/os-api-ref/os-api-ref.spec.j2', 'openstack/os-api-ref/0001-Fix-microversion-test-handle-different-HTML-renderin.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9b2f4c7b0727a2389114340f136801b688da0f71', 'message': 'os-api-ref: Drop oslosphinx BuildRequires and fix build\n\n- oslosphinx is not needed\n- Add a patch which handles different beautifulsoup4 render results\n- for different versions. The patch is already merged upstream.\n\nChange-Id: I9520ace1096810045a1475396b4a8378c5679dd8\n'}]",0,640977,9b2f4c7b0727a2389114340f136801b688da0f71,10,6,1,7102,,,0,"os-api-ref: Drop oslosphinx BuildRequires and fix build

- oslosphinx is not needed
- Add a patch which handles different beautifulsoup4 render results
- for different versions. The patch is already merged upstream.

Change-Id: I9520ace1096810045a1475396b4a8378c5679dd8
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/77/640977/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/os-api-ref/os-api-ref.spec.j2', 'openstack/os-api-ref/0001-Fix-microversion-test-handle-different-HTML-renderin.patch']",2,9b2f4c7b0727a2389114340f136801b688da0f71,,"From 4e56d09dafaa7e2b2dc9fd2cd1864ffe6c39e219 Mon Sep 17 00:00:00 2001 From: Luigi Toscano <ltoscano@redhat.com> Date: Fri, 11 Jan 2019 11:58:11 +0100 Subject: [PATCH] Fix microversion test: handle different HTML renderings The rendered HTML changes a bit between beautifulsoup4 4.6.3 and 4.7.1. A regular expression can handle both cases. Change-Id: I64d4c56b480d54b50e58141999636b91b5fb4f94 --- os_api_ref/tests/test_microversions.py | 12 ++++++------ 1 file changed, 6 insertions(+), 6 deletions(-) diff --git a/os_api_ref/tests/test_microversions.py b/os_api_ref/tests/test_microversions.py index b58f6a6..d58f673 100644 --- a/os_api_ref/tests/test_microversions.py +++ b/os_api_ref/tests/test_microversions.py @@ -45,13 +45,13 @@ class TestMicroversions(base.TestCase): def test_rest_method(self): """"""Test that min / max mv css class attributes are set"""""" content = self.soup.find_all(class_='rp_min_ver_2_17') - self.assertIn( - '<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 "">', - str(content[0])) + self.assertRegexpMatches( + str(content[0]), + '^<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 ?""') content = self.soup.find_all(class_='rp_max_ver_2_19') - self.assertIn( - '<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 "">', - str(content[0])) + self.assertRegexpMatches( + str(content[0]), + '^<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 ?""') def test_parameters_table(self): """"""Test that min / max mv css class attributes are set in params"""""" -- 2.21.0 ",,42,1
openstack%2Ftripleo-quickstart-extras~master~I90641ae636287ae1b6c5c225f7812431e28a39d5,openstack/tripleo-quickstart-extras,master,I90641ae636287ae1b6c5c225f7812431e28a39d5,Reuse the validate-tempest skip list in os_tempest,MERGED,2019-02-01 08:45:36.000000000,2019-03-05 11:35:01.000000000,2019-03-05 11:35:01.000000000,"[{'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-01 08:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/706d14f66e164ca94be19ba78198ce486fc908c2', 'message': 'Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 2, 'created': '2019-02-01 12:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3026313032313763c67dad275221dda3512c2211', 'message': 'Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 3, 'created': '2019-02-04 09:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/892dd257379a26f5e4f454b3961fc7c64abae5f7', 'message': 'Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 4, 'created': '2019-02-04 15:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2985cb7b0218157ffa3be0ad2a646317384e4bc6', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 5, 'created': '2019-02-05 10:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/94bcc3d7e6e701fc54f707296c05b5a7c4b503a2', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 6, 'created': '2019-02-05 14:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/b21e3862a6f37ffd8c830de00028808019df5bb9', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 7, 'created': '2019-02-05 16:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/63ac44766c4e52e729d39bf77076fcbd693d50f4', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 8, 'created': '2019-02-06 10:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6f6993ecfe7994eebd5b06115bfbe0d897704824', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 9, 'created': '2019-02-06 13:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e3d94c847d9b386b545703a7415a57654ee02272', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 10, 'created': '2019-02-07 08:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4d648b6648ecdaa7f53901af9311db3a5ce017b9', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 11, 'created': '2019-02-07 13:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/843c4f1ef65bf85e3e9fb580dbca6abbebac77de', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 12, 'created': '2019-02-22 13:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d8352dfd892f460a609a855695a8b9b626fd3873', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 13, 'created': '2019-02-27 10:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1506dfce7445d26278b924a74cf230fc84f39da3', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 14, 'created': '2019-02-27 10:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0bca98817524c40112b225d5230f321c71ac0c13', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 15, 'created': '2019-02-27 11:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/cb44bb08081d433a1039894276b49475e17b4e19', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 16, 'created': '2019-02-27 13:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/027c2f51194ffdfa87c18ebf98378d14ff060d0d', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 17, 'created': '2019-02-27 14:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c4edc801c066303e198cc789b9a79db0bf5ba6c6', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 18, 'created': '2019-02-27 16:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9571ee14a300c685562a7fe8209d65b6be566d68', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 19, 'created': '2019-02-28 10:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/00777ea6df2758e74f71841910328152886d76fe', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 20, 'created': '2019-02-28 13:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1e0e62538cdc777d348a60755644e467de8e55cc', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 21, 'created': '2019-02-28 14:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f06725e28f98cc33af0a6a8c6f41de89731c426f', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 22, 'created': '2019-02-28 22:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/248a6da04786ff6abc4f2b58401c943974fd91f6', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 23, 'created': '2019-02-28 22:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/802acd8062e2253358f0e4ce7ac75c86602c7beb', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 24, 'created': '2019-03-01 09:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9b1aadeda43d75cb7d4570ff9369c0da8deb7e7b', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 25, 'created': '2019-03-01 12:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/351c78bbe1e82bfb536e8b7d2e17107bade26d9c', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 26, 'created': '2019-03-01 13:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/41bb5f5dc0cf6eda048ab6c3b1d1a9cfffcbcabd', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 27, 'created': '2019-03-02 08:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8a4179e98fa02f84a84e0bed6dc1daa7ee920dd4', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 28, 'created': '2019-03-02 10:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/72a5f7676fee71656e367df045625ed9cde55e69', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 29, 'created': '2019-03-02 12:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/828f8fdaee272e414e9e0ae4f8090c698210c23f', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 30, 'created': '2019-03-02 13:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e02606ab3ad3aa93637092a1899c124353955efb', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 31, 'created': '2019-03-02 15:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4f9923cdb19581566626fb305f855e235909066b', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 32, 'created': '2019-03-02 22:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f9cf97b16797c4761b1551fc16cd67e004d60f93', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 33, 'created': '2019-03-03 09:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1b0cb0ae1afa06a825ac9f39aec58813562821d1', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 34, 'created': '2019-03-03 10:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/869826fded890758d7acf718192681edb917e7a0', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 35, 'created': '2019-03-03 12:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e790815bc7d0f9b2bbe119beae4d03e2b9f1c41c', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 36, 'created': '2019-03-03 15:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fc3fdd89bb606a9ee3a0bb273feb440b61ee0236', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 37, 'created': '2019-03-03 17:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/216f264f1b1a5af057c2a05f621e931e50e19eb7', 'message': '[WIP] Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 38, 'created': '2019-03-04 09:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ed3ac4b6c56d8c2a6038f5e6252ca0e63eb7274f', 'message': 'Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 39, 'created': '2019-03-04 11:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4e892ba9bfec3e3cef4caff33b023848ba0148ed', 'message': 'Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nDepends-On: https://review.openstack.org/640358\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}, {'number': 40, 'created': '2019-03-04 12:37:08.000000000', 'files': ['playbooks/tempest.yml', 'vars', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/316ca33d2dc95ff04873b062a466f91da39a35c6', 'message': 'Reuse the validate-tempest skip list in os_tempest\n\nBefore porting all the jobs to os_tempest from validate-tempest\nwe need to make sure that we are using the existing master skip\nlist otherwise it will leads to lots of failures.\n\nChange-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5\n'}]",9,634380,316ca33d2dc95ff04873b062a466f91da39a35c6,152,11,40,12393,,,0,"Reuse the validate-tempest skip list in os_tempest

Before porting all the jobs to os_tempest from validate-tempest
we need to make sure that we are using the existing master skip
list otherwise it will leads to lots of failures.

Change-Id: I90641ae636287ae1b6c5c225f7812431e28a39d5
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/80/634380/40 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/multinode-standalone.yml'],1,706d14f66e164ca94be19ba78198ce486fc908c2,os_tempest_skip," vars_files: - ""{{ playbook_dir }}/../roles/validate-tempest/vars/tempest_skip_master.yml"" tempest_test_blacklist: ""{{ known_failures }}""",,3,0
openstack%2Fswift~feature%2Flosf~I517f0b2ca6594d2819eb49cedf86f05dc625b51c,openstack/swift,feature/losf,I517f0b2ca6594d2819eb49cedf86f05dc625b51c,Merge remote-tracking branch 'remotes/origin/master' into merge-master,MERGED,2019-03-05 08:52:40.000000000,2019-03-05 11:34:24.000000000,2019-03-05 11:34:23.000000000,"[{'_account_id': 13852}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-05 08:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d90ab533ba421602429c89f63e306f4e62ac9c78', 'message': ""Merge remote-tracking branch 'remotes/origin/master' into merge-master\n\nChange-Id: I517f0b2ca6594d2819eb49cedf86f05dc625b51c\n""}]",0,640955,d90ab533ba421602429c89f63e306f4e62ac9c78,8,2,1,13852,,,0,"Merge remote-tracking branch 'remotes/origin/master' into merge-master

Change-Id: I517f0b2ca6594d2819eb49cedf86f05dc625b51c
",git fetch https://review.opendev.org/openstack/swift refs/changes/55/640955/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,d90ab533ba421602429c89f63e306f4e62ac9c78,bug/1810567,,,0,0
openstack%2Fgrenade~master~I0349de2026c49279ba7f262d5e86d37018d66326,openstack/grenade,master,I0349de2026c49279ba7f262d5e86d37018d66326,Determine PYTHON3_VERSION when necessary,MERGED,2019-01-15 12:48:17.000000000,2019-03-05 11:34:22.000000000,2019-03-05 11:34:22.000000000,"[{'_account_id': 970}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 9003}, {'_account_id': 10459}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-15 12:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/fa48615dff9fcd82ae354bce78c0f26e94392b29', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change determines the version of python 3\nwithin grenade if it was not set by its caller.\n\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 2, 'created': '2019-01-15 13:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/6d752f8dcb8a7d643616918c4060188d73a71a47', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change determines the version of python 3\nwithin grenade if it was not set by its caller.\n\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 3, 'created': '2019-01-15 14:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/a42f804c43fb024f445b79f52402e3ee7706901f', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change determines the version of python 3\nwithin grenade if it was not set by its caller.\n\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 4, 'created': '2019-01-15 15:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/02788d14cb47969ee1c410ba3da05c0d7de9f06a', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change determines the version of python 3\nwithin grenade if it was not set by its caller.\n\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 5, 'created': '2019-01-17 12:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/b820a2e95f2b8fb5ec3bd06a852e38cd127cf4d4', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change determines the version of python 3\nwithin grenade if it was not set by its caller.\n\nCloses-bug: #1812208\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 6, 'created': '2019-02-06 22:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/c117edac03a613218c8c8715c69cabcf9e0d4ccc', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change determines the version of python 3\nwithin grenade if it was not set by its caller.\n\nCloses-bug: #1812208\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 7, 'created': '2019-02-07 10:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/5aaf18eafe9633994cc1caf5ba9b255dbe5f133c', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change uses a bit of code borrowed from\nstackrc in devstack to determine the version of python\nwithin grenade if it was not set by the caller.\n\nCloses-bug: #1812208\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}, {'number': 8, 'created': '2019-03-03 17:49:19.000000000', 'files': ['grenaderc', 'inc/bootstrap'], 'web_link': 'https://opendev.org/openstack/grenade/commit/d5dc033a2e6df988b0576fc0417be46cc8d157ed', 'message': 'Determine PYTHON3_VERSION when necessary\n\nWhen grenade.sh is invoked by devstack-gate, PYTHON3_VERSION\nis not set so grenadrc defaults it to 3.5, which breaks grenade\non nodes where python 3.5 does not exist, such as ubuntu bionic.\n\nOne solution is to set PYTHON3_VERSION in devstack-gate [1].\nAlternatively, this change uses a bit of code borrowed from\nstackrc in devstack to determine the version of python\nwithin grenade if it was not set by the caller.\n\nCloses-bug: #1812208\n[1] https://review.openstack.org/#/c/607379/\n\nChange-Id: I0349de2026c49279ba7f262d5e86d37018d66326\n'}]",10,630961,d5dc033a2e6df988b0576fc0417be46cc8d157ed,49,11,8,9003,,,0,"Determine PYTHON3_VERSION when necessary

When grenade.sh is invoked by devstack-gate, PYTHON3_VERSION
is not set so grenadrc defaults it to 3.5, which breaks grenade
on nodes where python 3.5 does not exist, such as ubuntu bionic.

One solution is to set PYTHON3_VERSION in devstack-gate [1].
Alternatively, this change uses a bit of code borrowed from
stackrc in devstack to determine the version of python
within grenade if it was not set by the caller.

Closes-bug: #1812208
[1] https://review.openstack.org/#/c/607379/

Change-Id: I0349de2026c49279ba7f262d5e86d37018d66326
",git fetch https://review.opendev.org/openstack/grenade refs/changes/61/630961/2 && git format-patch -1 --stdout FETCH_HEAD,"['grenaderc', 'inc/bootstrap']",2,fa48615dff9fcd82ae354bce78c0f26e94392b29,bug/1812208, if [ -z $PYTHON3_VERSION ]; then USE_PYTHON3_VERSION=get_python3_version export PYTHON3_VERSION=${USE_PYTHON3_VERSION:-3.5} fi,,4,5
openstack%2Fnova~master~I1dea4472b232d6c054879ebda2536658d9769053,openstack/nova,master,I1dea4472b232d6c054879ebda2536658d9769053,Fix wrong consumer type in logging,MERGED,2019-03-04 10:39:48.000000000,2019-03-05 11:34:18.000000000,2019-03-05 11:34:18.000000000,"[{'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-03-04 10:39:48.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/scheduler/client/report.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/704880468b2cc495bb00266ff00bbea4fb0f28e6', 'message': ""Fix wrong consumer type in logging\n\nIn the 'delete_allocation_for_instance' method,\na consumer UUID is output in the log.\n\nThe consumer UUID is UUID of a server or UUID of a migration.\nHowever the consumer UUID is described as UUID of a server\nin the log.\nFix the description in the log.\n\nChange-Id: I1dea4472b232d6c054879ebda2536658d9769053\nCloses-Bug: #1818252\n""}]",0,640723,704880468b2cc495bb00266ff00bbea4fb0f28e6,36,16,1,7634,,,0,"Fix wrong consumer type in logging

In the 'delete_allocation_for_instance' method,
a consumer UUID is output in the log.

The consumer UUID is UUID of a server or UUID of a migration.
However the consumer UUID is described as UUID of a server
in the log.
Fix the description in the log.

Change-Id: I1dea4472b232d6c054879ebda2536658d9769053
Closes-Bug: #1818252
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/640723/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/scheduler/client/report.py', 'nova/compute/manager.py']",3,704880468b2cc495bb00266ff00bbea4fb0f28e6,bug/1818252," context, migration.uuid, consumer_type='migration')"," context, migration.uuid)",17,10
openstack%2Frpm-packaging~master~I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf,openstack/rpm-packaging,master,I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf,Update openstackclients to current version,MERGED,2019-02-04 17:47:13.000000000,2019-03-05 11:10:24.000000000,2019-03-05 11:10:24.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-04 17:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bbb366c6b6eb12b12dbdfd15003a442cb4794d0b', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}, {'number': 2, 'created': '2019-02-04 20:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/450d2699a24d7faba986c8d121a6d45204966f97', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}, {'number': 3, 'created': '2019-02-06 13:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9e3fa95b1f5da05603de356fb77af63f44c3a355', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}, {'number': 4, 'created': '2019-02-08 10:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/71bbb1cb239960ad530b9961b72582a642ddd174', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}, {'number': 5, 'created': '2019-02-08 12:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1eb6de620bd7c7bd6ef4682f1e8340201db99765', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}, {'number': 6, 'created': '2019-03-04 09:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5f4fe8e153fb23ee8ee4dcfc6490e67e83dc02e1', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}, {'number': 7, 'created': '2019-03-05 09:29:10.000000000', 'files': ['openstack/python-heatclient/python-heatclient.spec.j2', 'openstack/python-freezerclient/python-freezerclient.spec.j2', 'openstack/python-barbicanclient/python-barbicanclient.spec.j2', 'openstack/python-glanceclient/python-glanceclient.spec.j2', 'openstack/python-octaviaclient/python-octaviaclient.spec.j2', 'openstack/python-manilaclient/python-manilaclient.spec.j2', 'openstack/python-zaqarclient/python-zaqarclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3e519b4a5b4d47e723691ba6c732c04724c76c9e', 'message': 'Update openstackclients to current version\n\nChange-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf\n'}]",0,634761,3e519b4a5b4d47e723691ba6c732c04724c76c9e,38,6,7,6593,,,0,"Update openstackclients to current version

Change-Id: I4049ba7c0aa22c32ba7b61b2558aa674a910d2bf
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/61/634761/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/python-heatclient/python-heatclient.spec.j2', 'openstack/python-freezerclient/python-freezerclient.spec.j2', 'openstack/python-keystoneclient/python-keystoneclient.spec.j2', 'openstack/python-ironic-inspector-client/python-ironic-inspector-client.spec.j2', 'openstack/python-barbicanclient/python-barbicanclient.spec.j2', 'openstack/python-watcherclient/python-watcherclient.spec.j2', 'openstack/python-octaviaclient/python-octaviaclient.spec.j2', 'openstack/python-vitrageclient/python-vitrageclient.spec.j2', 'openstack/python-magnumclient/python-magnumclient.spec.j2', 'openstack/python-manilaclient/python-manilaclient.spec.j2', 'openstack/python-zaqarclient/python-zaqarclient.spec.j2', 'openstack/os-apply-config/os-apply-config.spec.j2', 'openstack/os-collect-config/os-collect-config.spec.j2', 'openstack/python-karborclient/python-karborclient.spec.j2', 'openstack/python-glanceclient/python-glanceclient.spec.j2', 'openstack/castellan/castellan.spec.j2', 'openstack/keystonemiddleware/keystonemiddleware.spec.j2', 'openstack/oslo.config/oslo.config.spec.j2', 'openstack/python-ironicclient/python-ironicclient.spec.j2']",19,bbb366c6b6eb12b12dbdfd15003a442cb4794d0b,634761,{% set upstream_version = upstream_version('2.6.0') %},{% set upstream_version = upstream_version('2.5.0') %},19,19
openstack%2Frpm-packaging~master~Ie6bf58fb24676e464e6ca471538718675b098ca6,openstack/rpm-packaging,master,Ie6bf58fb24676e464e6ca471538718675b098ca6,Update futurist to 1.8.1,MERGED,2019-03-01 09:09:11.000000000,2019-03-05 11:08:31.000000000,2019-03-05 11:08:31.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-01 09:09:11.000000000', 'files': ['openstack/futurist/futurist.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2eb41a285e71491d573f5b7c9bdfc9b1a21e44a4', 'message': 'Update futurist to 1.8.1\n\nChange-Id: Ie6bf58fb24676e464e6ca471538718675b098ca6\n'}]",0,640279,2eb41a285e71491d573f5b7c9bdfc9b1a21e44a4,16,6,1,8482,,,0,"Update futurist to 1.8.1

Change-Id: Ie6bf58fb24676e464e6ca471538718675b098ca6
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/79/640279/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/futurist/futurist.spec.j2'],1,2eb41a285e71491d573f5b7c9bdfc9b1a21e44a4,futurist,{% set upstream_version = upstream_version('1.8.1') %},{% set upstream_version = upstream_version('1.8.0') %},1,1
openstack%2Fcookbook-openstack-identity~master~I10b31efe1e94fc69cda65e2f7fb7a669afb166ba,openstack/cookbook-openstack-identity,master,I10b31efe1e94fc69cda65e2f7fb7a669afb166ba,Stop overriding auth methods,MERGED,2019-03-01 09:17:53.000000000,2019-03-05 11:05:55.000000000,2019-03-05 11:04:38.000000000,"[{'_account_id': 11915}, {'_account_id': 19193}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-01 09:17:53.000000000', 'files': ['attributes/keystone_conf.rb', 'attributes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/af1d3b1485d041d868537aa2bdccf5c25eba40b8', 'message': ""Stop overriding auth methods\n\nSetting the keystone option [auth]/methods by default blocks additions\nlike application_credential that was newly added to Keystone in Queens.\nLet's stick to Keystone's defaults instead, deployments can override\nthese settings if they need to.\n\nAlso drop some even older version of these attributes that haven't been\nused at all anymore for some time.\n\nChange-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba\n""}]",0,640284,af1d3b1485d041d868537aa2bdccf5c25eba40b8,8,3,1,13252,,,0,"Stop overriding auth methods

Setting the keystone option [auth]/methods by default blocks additions
like application_credential that was newly added to Keystone in Queens.
Let's stick to Keystone's defaults instead, deployments can override
these settings if they need to.

Also drop some even older version of these attributes that haven't been
used at all anymore for some time.

Change-Id: I10b31efe1e94fc69cda65e2f7fb7a669afb166ba
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/84/640284/1 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/keystone_conf.rb', 'attributes/default.rb']",2,af1d3b1485d041d868537aa2bdccf5c25eba40b8,drop-auth-methods,,"# The external (REMOTE_USER) auth plugin module. (String value) default['openstack']['identity']['auth']['external'] = 'keystone.auth.plugins.external.DefaultDomain' # Default auth methods. (List value) default['openstack']['identity']['auth']['methods'] = 'external, password, token, oauth1' # Default auth_version for now default['openstack']['identity']['auth']['version'] = 'v3' ",0,12
openstack%2Ftripleo-specs~master~I352b0fbad444f8f340e53da0b758287f55e1c752,openstack/tripleo-specs,master,I352b0fbad444f8f340e53da0b758287f55e1c752,Add spec safe-side-containers,MERGED,2018-11-26 13:58:49.000000000,2019-03-05 10:54:43.000000000,2019-03-05 10:54:43.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-11-26 13:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4d34f9a3d53232317354d495a96005a36bdd05e0', 'message': 'Add spec safe-side-containers\n\nThis is an alternative pattern which can be used to launch\nside containers in a safe manner within our current architecture.\n\nChange-Id: I352b0fbad444f8f340e53da0b758287f55e1c752\n'}, {'number': 2, 'created': '2019-03-04 14:02:52.000000000', 'files': ['specs/stein/safe-side-containers.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/827c692c8a688912e5aca90af7ebcb6780d90e34', 'message': 'Add spec safe-side-containers\n\nThis is an alternative pattern which can be used to launch\nside containers in a safe manner within our current architecture.\n\nA specific focus here is Neutron which requires its side container\nprocesses to run in network namespaces.\n\nChange-Id: I352b0fbad444f8f340e53da0b758287f55e1c752\n'}]",34,620062,827c692c8a688912e5aca90af7ebcb6780d90e34,39,7,2,360,,,0,"Add spec safe-side-containers

This is an alternative pattern which can be used to launch
side containers in a safe manner within our current architecture.

A specific focus here is Neutron which requires its side container
processes to run in network namespaces.

Change-Id: I352b0fbad444f8f340e53da0b758287f55e1c752
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/62/620062/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/safe-side-containers.rst'],1,4d34f9a3d53232317354d495a96005a36bdd05e0,safe-side-containers,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================== TripleO - Pattern to safely spawn a container from a container ============================================================== This spec describes a pattern which can be used as an alternative to what TripleO does today to allow certain containers (Neutron, etc.) to spawn side processes. Specifically it avoids exposing the docker socker or using Podman nsenter hacks that have recently entered the codebase in Stein. Problem Description =================== In Queens TripleO implemented a containerized architecture with the goal of containerizing all OpenStack services. This architecture was a success but a few applications had regressions when compared with their baremetal deployed equivalent. One of these applications was Neutron, which requires the ability to spawn long lived ""side"" processes that are launched directly from the Neutron agents themselves. In the original Queens architecture Neutron launched these side processes inside of the agent container itself which caused a service disruption if the neutron agents themselves were restarted. This was previously not the case on baremetal as these processes would continue running across an agent restart/upgrade. The work around in Rocky was to add ""wrapper"" scripts for Neutron agents and to expose the docker socket to each agent container. These wrappers scripts were bind mounted into the containers so that they overwrote the normal location of the side process. Using this crude mechanism binaries like 'dnsmasq' and 'haproxy' would instead launch a shell script instead of the normal binary and these custom shell scripts relied on the an exposed docker socket from the host to be able to launch a side container with the same arguments supplied to the script. This mechanism functionally solved the issues with our containerization but exposed some security problems in that we were now exposing the ability to launch any container to these Neutron agent containers (privileged containers with access to a docker socket). In Stien things changed with our desire to support Podman. Unlike Docker Podman does not include a daemon on the host. All Podman commands are executed via a CLI which runs the command on the host directly. In Rocky we landed patches which required Podman commands to use nsenter to enter the hosts namespace and run the commands there directly. Again this mechanism requires extra privileges to be granted to the Neutron agent containers in order for them to be able to launch these commands. Furthermore the mechanism is a bit cryptic to support and debug in the field. Proposed Change =============== Overview -------- Use systemd on the host to launch the side process containers directly. The benefit of this approach is that we no longer have to give the Neutron containers privs to launch containers which they shouldn't require. The pattern could work like this: #. A systemd.path file monitors a know location on the host for changes. Example (neutron-dhcp-dnsmasq.path): .. code-block:: yaml [Path] PathModified=/var/lib/neutron/neutron-dnsmasq-processes-timestamp PathChanged=/var/lib/neutron/neutron-dnsmasq-processes-timestamp [Install] WantedBy=multi-user.target #. When systemd.path notices a change it fires the service for this path file: Example (neutron-dhcp-dnsmasq.service): .. code-block:: yaml [Unit] Description=neutron dhcp dnsmasq sync service [Service] Type=oneshot ExecStart=/usr/local/bin/neutron-dhcp-dnsmasq-process-sync User=root #. We use the same ""wrapper scripts"" used today to write two files. The first file is a dump of CLI arguments used to launch the process on the host. This file can optionally include extra data like network namespaces which are required for some neutron side processes. The second file is a timestamp which is monitored by systemd.path on the host for changes and is used as a signal that it needs to process the first file with arguments. # When a change is detected the systemd.service above executes a script on the host to cleanly launch containerized side processes. When the script finishes launching processes it truncates the file to start with a clean slate. # Both the wrapper scripts and the host scripts use flock to eliminate race conditions which could cause issues in relaunching or missed containers. Alternatives ------------ With Podman an API like varlink would be an option however it would likely still required exposure to a socket on the host which would involve extra privileges like what we have today. This would avoid the nsenter hacks however. An architecture like Kubernetes would give us an API which could be used to launch containers directly via the COE. Additionally an external process manager in Neutron that is ""containers aware"" could be written to improve either of the above options. The current python in Neutron was writtin primarily for launching processes on baremetal with assumptions that some of the processes it launches are meant to live across a contain restart. Implementing a class that can launch side processes via a clean interface rather than overwriting binaries would be desirable. Classes which supported launching containers via Kubernetes and or Systemd via the host directly could be supported. Security Impact --------------- This mechanism should allow us to remove some of the container privileges for neutron agents which in the past were used to execute containers. It is a more restrictive crude interface that allows the containers only to launch a specific type of process rather than any container it chooses. Upgrade Impact -------------- The side process containers should be the same regardless of how they are launched so the upgrade should be minimal. Implementation ============== Assignee(s) ----------- Primary assignee: dan-prince Other contributors: emilienm Work Items ---------- # Ansible playbook to create systemd files, wrappers # TripleO Heat template updates to use the new playbooks # Remove/deprecate the old docker.socket and nsenter code from puppet-tripleo ",,160,0
openstack%2Fnova-powervm~master~Id5b00f1805b150c825070d79531be85092dce1a5,openstack/nova-powervm,master,Id5b00f1805b150c825070d79531be85092dce1a5,Add use_cache kwarg to get_info,MERGED,2019-03-01 15:36:23.000000000,2019-03-05 10:53:08.000000000,2019-03-05 10:53:08.000000000,"[{'_account_id': 10608}, {'_account_id': 13637}, {'_account_id': 14581}, {'_account_id': 22348}, {'_account_id': 28222}]","[{'number': 1, 'created': '2019-03-01 15:36:23.000000000', 'files': ['nova_powervm/virt/powervm/driver.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b3e195041d710135e53e51d17c0b007ea865d850', 'message': ""Add use_cache kwarg to get_info\n\nNova has changed the interface of the ComputeDriver.get_info method [1],\nadding a use_cache kwarg. The change preserves backward compatibility,\nbut that's removed in Stein [2]. This patch changes the signature of\nPowerVMDriver.get_info to match.\n\n[1] https://review.openstack.org/#/c/636699/\n[2] https://review.openstack.org/#/c/640043/\n\nDepends-On: https://review.openstack.org/636699\nChange-Id: Id5b00f1805b150c825070d79531be85092dce1a5\n""}]",0,640402,b3e195041d710135e53e51d17c0b007ea865d850,11,5,1,14070,,,0,"Add use_cache kwarg to get_info

Nova has changed the interface of the ComputeDriver.get_info method [1],
adding a use_cache kwarg. The change preserves backward compatibility,
but that's removed in Stein [2]. This patch changes the signature of
PowerVMDriver.get_info to match.

[1] https://review.openstack.org/#/c/636699/
[2] https://review.openstack.org/#/c/640043/

Depends-On: https://review.openstack.org/636699
Change-Id: Id5b00f1805b150c825070d79531be85092dce1a5
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/02/640402/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_powervm/virt/powervm/driver.py'],1,b3e195041d710135e53e51d17c0b007ea865d850,get_info-use_cache," def get_info(self, instance, use_cache=True): :param use_cache: unused in this driver"," def get_info(self, instance):",2,1
openstack%2Frpm-packaging~master~I78da9108ed8556ebd9fbd4b97e39ba19958005b6,openstack/rpm-packaging,master,I78da9108ed8556ebd9fbd4b97e39ba19958005b6,Fix os-api-ref unit tests,ABANDONED,2019-03-05 09:48:45.000000000,2019-03-05 10:44:57.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-05 09:48:45.000000000', 'files': ['openstack/os-api-ref/os-api-ref.spec.j2', 'openstack/os-api-ref/0001-Fix-microversion-test-handle-different-HTML-renderin.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f45aed19dd59812414f81b93b1b15fd6a3646000', 'message': 'Fix os-api-ref unit tests\n\nChange-Id: I78da9108ed8556ebd9fbd4b97e39ba19958005b6\n'}]",0,640965,f45aed19dd59812414f81b93b1b15fd6a3646000,4,2,1,8482,,,0,"Fix os-api-ref unit tests

Change-Id: I78da9108ed8556ebd9fbd4b97e39ba19958005b6
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/65/640965/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/os-api-ref/os-api-ref.spec.j2', 'openstack/os-api-ref/0001-Fix-microversion-test-handle-different-HTML-renderin.patch']",2,f45aed19dd59812414f81b93b1b15fd6a3646000,fix-api-ref,"From 4e56d09dafaa7e2b2dc9fd2cd1864ffe6c39e219 Mon Sep 17 00:00:00 2001 From: Luigi Toscano <ltoscano@redhat.com> Date: Fri, 11 Jan 2019 11:58:11 +0100 Subject: [PATCH] Fix microversion test: handle different HTML renderings The rendered HTML changes a bit between beautifulsoup4 4.6.3 and 4.7.1. A regular expression can handle both cases. Change-Id: I64d4c56b480d54b50e58141999636b91b5fb4f94 --- os_api_ref/tests/test_microversions.py | 12 ++++++------ 1 file changed, 6 insertions(+), 6 deletions(-) diff --git a/os_api_ref/tests/test_microversions.py b/os_api_ref/tests/test_microversions.py index b58f6a6..d58f673 100644 --- a/os_api_ref/tests/test_microversions.py +++ b/os_api_ref/tests/test_microversions.py @@ -45,13 +45,13 @@ class TestMicroversions(base.TestCase): def test_rest_method(self): """"""Test that min / max mv css class attributes are set"""""" content = self.soup.find_all(class_='rp_min_ver_2_17') - self.assertIn( - '<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 "">', - str(content[0])) + self.assertRegexpMatches( + str(content[0]), + '^<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 ?""') content = self.soup.find_all(class_='rp_max_ver_2_19') - self.assertIn( - '<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 "">', - str(content[0])) + self.assertRegexpMatches( + str(content[0]), + '^<div class=""operation-grp rp_min_ver_2_17 rp_max_ver_2_19 ?""') def test_parameters_table(self): """"""Test that min / max mv css class attributes are set in params"""""" -- 2.21.0 ",,41,0
openstack%2Fkuryr-libnetwork~master~I76107a34b44c53835a7d6a4cd6828e8d76077e7d,openstack/kuryr-libnetwork,master,I76107a34b44c53835a7d6a4cd6828e8d76077e7d,add python 3.7 unit test job,MERGED,2019-02-19 09:06:25.000000000,2019-03-05 10:25:26.000000000,2019-03-05 10:25:26.000000000,"[{'_account_id': 6598}, {'_account_id': 9414}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 11536}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 09:06:25.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/e028d0c178abeac0924578ef974c13d60dd34b57', 'message': 'add python 3.7 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.7.\n\nSee ML discussion here [1] for context.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html\n\nChange-Id: I76107a34b44c53835a7d6a4cd6828e8d76077e7d\nStory: #2004073\nTask: #27424\n'}]",0,637767,e028d0c178abeac0924578ef974c13d60dd34b57,8,8,1,9414,,,0,"add python 3.7 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.7.

See ML discussion here [1] for context.

[1] http://lists.openstack.org/pipermail/openstack-dev/2018-October/135626.html

Change-Id: I76107a34b44c53835a7d6a4cd6828e8d76077e7d
Story: #2004073
Task: #27424
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/67/637767/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e028d0c178abeac0924578ef974c13d60dd34b57,py37-job, - openstack-python37-jobs,,1,0
openstack%2Frequirements~master~I7bc129074f6d8a109fe83e2a8b2f2c3d89db4085,openstack/requirements,master,I7bc129074f6d8a109fe83e2a8b2f2c3d89db4085,Updated from generate-constraints,MERGED,2019-03-02 06:10:50.000000000,2019-03-05 10:20:38.000000000,2019-03-05 10:20:38.000000000,"[{'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28543}, {'_account_id': 29759}]","[{'number': 1, 'created': '2019-03-02 06:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fb7b164d8f2e66fb664ec609b662f4a858ed9f53', 'message': 'Updated from generate-constraints\n\nChange-Id: I7bc129074f6d8a109fe83e2a8b2f2c3d89db4085\n'}, {'number': 2, 'created': '2019-03-02 08:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e3534dba152ec22b5e831e573be5e6b8a6a8c91e', 'message': 'Updated from generate-constraints\n\nChange-Id: I7bc129074f6d8a109fe83e2a8b2f2c3d89db4085\n'}, {'number': 3, 'created': '2019-03-04 00:24:40.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/349e5795fb56458be010e4bb4f2eba397d84116a', 'message': 'Updated from generate-constraints\n\nChange-Id: I7bc129074f6d8a109fe83e2a8b2f2c3d89db4085\n'}]",0,640579,349e5795fb56458be010e4bb4f2eba397d84116a,36,7,3,11131,,,0,"Updated from generate-constraints

Change-Id: I7bc129074f6d8a109fe83e2a8b2f2c3d89db4085
",git fetch https://review.opendev.org/openstack/requirements refs/changes/79/640579/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,fb7b164d8f2e66fb664ec609b662f4a858ed9f53,openstack/requirements/constraints/noclob,relativetimebuilder===0.2.0tornado===5.1.1;python_version=='2.7'stestr===2.3.0os-service-types===1.6.0opentracing===2.0.0botocore===1.12.106aniso8601===5.1.0scikit-learn===0.20.3,tornado===4.5.3;python_version=='2.7'stestr===2.2.0os-service-types===1.5.0opentracing===1.3.0botocore===1.12.105aniso8601===4.1.0scikit-learn===0.20.2,8,7
openstack%2Fnova~master~I483750462b80aac609f0c2deb783b389ff5156c3,openstack/nova,master,I483750462b80aac609f0c2deb783b389ff5156c3,Make move_allocations handle empty source allocations,MERGED,2019-02-12 18:28:20.000000000,2019-03-05 10:20:33.000000000,2019-03-05 10:20:33.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11564}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-12 18:28:20.000000000', 'files': ['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/55f455262144ab319a9ff480850aeece88b1dedb', 'message': 'Make move_allocations handle empty source allocations\n\nDuring a resize/cold migration, conductor moves the\ninstance allocations on the source compute node to the\nmigration record and then the scheduler creates allocations\nfor the instance on the destination compute node.\n\nWhen resize fails, the allocations are swapped back from\nthe migration record to the instance so that the instance\nconsumer holds the same source node allocations as before\nthe resize, and the allocations against the destination\ncompute node are dropped.\n\nDepending on the order of calls to do this revert/move,\nthe allocations may have already been moved so the\nsource node consumer (the migration record in this case)\nwill not have any allocations and if the target consumer\n(the instance in this case) has allocations, we should\nassume there is nothing to do and just return True.\n\nChange-Id: I483750462b80aac609f0c2deb783b389ff5156c3\n'}]",18,636412,55f455262144ab319a9ff480850aeece88b1dedb,52,16,1,6873,,,0,"Make move_allocations handle empty source allocations

During a resize/cold migration, conductor moves the
instance allocations on the source compute node to the
migration record and then the scheduler creates allocations
for the instance on the destination compute node.

When resize fails, the allocations are swapped back from
the migration record to the instance so that the instance
consumer holds the same source node allocations as before
the resize, and the allocations against the destination
compute node are dropped.

Depending on the order of calls to do this revert/move,
the allocations may have already been moved so the
source node consumer (the migration record in this case)
will not have any allocations and if the target consumer
(the instance in this case) has allocations, we should
assume there is nothing to do and just return True.

Change-Id: I483750462b80aac609f0c2deb783b389ff5156c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/636412/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py']",2,55f455262144ab319a9ff480850aeece88b1dedb,bp/cross-cell-resize," If the target consumer has allocations but the source consumer does not, this method assumes the allocations were already moved and returns True. :returns: True if the move was successful (or already done), False otherwise. # Check to see if the source allocations still exist because if # they don't they might have already been moved to the target. if not (source_alloc and source_alloc['allocations']): LOG.info('Allocations not found for consumer %s; assuming ' 'they were already moved to consumer %s', source_consumer_uuid, target_consumer_uuid) return True", :returns: True if the move was successful False otherwise.,33,1
openstack%2Frpm-packaging~master~I2a083743a7b0dc4446287cdb9243e1d3eb0c4d28,openstack/rpm-packaging,master,I2a083743a7b0dc4446287cdb9243e1d3eb0c4d28,automaton: Update to 1.16.0,MERGED,2019-03-02 05:59:38.000000000,2019-03-05 10:14:51.000000000,2019-03-05 10:14:51.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-02 05:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1cfd1befed50be07bb98fe10e1f71cbdb1175dfb', 'message': 'automaton: Update to 1.16.0\n\nChange-Id: I2a083743a7b0dc4446287cdb9243e1d3eb0c4d28\n'}, {'number': 2, 'created': '2019-03-05 07:49:42.000000000', 'files': ['openstack/automaton/automaton.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4f2b646c63bdc1d321c53071169ca91eca7464cf', 'message': 'automaton: Update to 1.16.0\n\nChange-Id: I2a083743a7b0dc4446287cdb9243e1d3eb0c4d28\n'}]",0,640573,4f2b646c63bdc1d321c53071169ca91eca7464cf,18,5,2,7102,,,0,"automaton: Update to 1.16.0

Change-Id: I2a083743a7b0dc4446287cdb9243e1d3eb0c4d28
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/73/640573/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/automaton/automaton.spec.j2'],1,1cfd1befed50be07bb98fe10e1f71cbdb1175dfb,,{% set upstream_version = upstream_version('1.16.0') %},"{% set upstream_version = upstream_version('1.15.0') %}BuildRequires: {{ py2pkg('debtcollector', py_versions=['py2', 'py3']) }}Requires: {{ py2pkg('debtcollector') }}",1,3
openstack%2Fnetworking-ovn~master~Icf38d25bf6d2410a2e7c4827335617dccf698cfa,openstack/networking-ovn,master,Icf38d25bf6d2410a2e7c4827335617dccf698cfa,Switch released jobs to OVS 2.11,MERGED,2019-03-04 16:21:20.000000000,2019-03-05 10:14:50.000000000,2019-03-05 10:14:49.000000000,"[{'_account_id': 5756}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-03-04 16:21:20.000000000', 'files': ['devstack/devstackgaterc', 'zuul.d/networkin-ovn-jobs.yaml', 'devstack/upgrade/settings'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7e5c8a13ed7baac6fa4ec323cd60c29ad3ed23ef', 'message': 'Switch released jobs to OVS 2.11\n\nOVS 2.11 is now released. This patch is bumping the version of the\nstable jobs to use it.\n\nChange-Id: Icf38d25bf6d2410a2e7c4827335617dccf698cfa\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",0,640800,7e5c8a13ed7baac6fa4ec323cd60c29ad3ed23ef,7,3,1,6773,,,0,"Switch released jobs to OVS 2.11

OVS 2.11 is now released. This patch is bumping the version of the
stable jobs to use it.

Change-Id: Icf38d25bf6d2410a2e7c4827335617dccf698cfa
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/00/640800/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/devstackgaterc', 'zuul.d/networkin-ovn-jobs.yaml', 'devstack/upgrade/settings']",3,7e5c8a13ed7baac6fa4ec323cd60c29ad3ed23ef,ovs-2.11,"devstack_localrc base OVN_BRANCH=""branch-2.11""","devstack_localrc base OVN_BRANCH=""branch-2.10""",4,4
openstack%2Fpython-openstackclient~master~Ie10b67864c912ee5c33e90b10c3d9705ee8307e7,openstack/python-openstackclient,master,Ie10b67864c912ee5c33e90b10c3d9705ee8307e7,Remove str() when setting network objects names,MERGED,2019-01-28 14:23:09.000000000,2019-03-05 10:00:41.000000000,2019-02-27 22:15:41.000000000,"[{'_account_id': 841}, {'_account_id': 970}, {'_account_id': 1131}, {'_account_id': 6482}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-28 14:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/376c2a396934b63e6842f66030d2a9194ebb6379', 'message': 'Use six string type to convert network objects names\n\nMost network commands use str() on name argument, which fails on python\n2 with Unicode characters. We can use text_type from six to support both\nversions here.\n\nSample command failing with current code:\nopenstack network create test_unicode™\n\nChange-Id: Ie10b67864c912ee5c33e90b10c3d9705ee8307e7\nStory: 2004356\nTask: 27955\n'}, {'number': 2, 'created': '2019-01-28 15:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/67f194c5b8639724a189186b3c83e2a853443515', 'message': 'Use six string type to convert network objects names\n\nMost network commands use str() on name argument, which fails on python\n2 with Unicode characters. We can use text_type from six to support both\nversions here.\n\nSample command failing with current code:\nopenstack network create test_unicode™\n\nChange-Id: Ie10b67864c912ee5c33e90b10c3d9705ee8307e7\nStory: 2004356\nTask: 27955\n'}, {'number': 3, 'created': '2019-02-13 09:52:01.000000000', 'files': ['openstackclient/network/v2/network_agent.py', 'openstackclient/network/v2/router.py', 'openstackclient/network/v2/network_qos_policy.py', 'openstackclient/network/v2/subnet_pool.py', 'openstackclient/network/v2/subnet.py', 'openstackclient/network/v2/network.py', 'openstackclient/network/v2/port.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/05521bf84cb108c73bb36b270569b1986ad13f53', 'message': 'Remove str() when setting network objects names\n\nMost network commands use str() on name argument, which fails on python\n2 with Unicode characters. This comes from parsed arguments so does not\nactually need this call.\n\nSample command failing with current code:\nopenstack network create test_unicode™\n\nChange-Id: Ie10b67864c912ee5c33e90b10c3d9705ee8307e7\nStory: 2004356\nTask: 27955\n'}]",5,633508,05521bf84cb108c73bb36b270569b1986ad13f53,17,6,3,21798,,,0,"Remove str() when setting network objects names

Most network commands use str() on name argument, which fails on python
2 with Unicode characters. This comes from parsed arguments so does not
actually need this call.

Sample command failing with current code:
openstack network create test_unicode™

Change-Id: Ie10b67864c912ee5c33e90b10c3d9705ee8307e7
Story: 2004356
Task: 27955
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/08/633508/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2/network_agent.py', 'openstackclient/network/v2/router.py', 'openstackclient/network/v2/network_qos_policy.py', 'openstackclient/network/v2/subnet_pool.py', 'openstackclient/network/v2/subnet.py', 'openstackclient/network/v2/network.py', 'openstackclient/network/v2/port.py']",7,376c2a396934b63e6842f66030d2a9194ebb6379,story/2004356,import six ,,21,7
openstack%2Fcharm-nova-cloud-controller~master~Iddb4f1f068b982dcd9a70b11b89df1be9f8aaf20,openstack/charm-nova-cloud-controller,master,Iddb4f1f068b982dcd9a70b11b89df1be9f8aaf20,Update default scheduler filters,MERGED,2019-03-04 16:22:06.000000000,2019-03-05 09:50:52.000000000,2019-03-05 09:50:52.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-04 16:22:06.000000000', 'files': ['config.yaml', 'hooks/nova_cc_context.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/b99d806cf3dccab76161883a6d521231971070c0', 'message': 'Update default scheduler filters\n\nMake the default set of scheduler filters conditional on the release\nbeing deployed; For Pike or later the CoreFilter, RamFilter and\nDiskFilter are superfluous to requirements as this filters are in\neffect completed by the Placement API.\n\nAdd DiskFilter to list of filters for older OpenStack releases.\n\nChange-Id: Iddb4f1f068b982dcd9a70b11b89df1be9f8aaf20\nCloses-Bug: 1731302\nCloses-Bug: 1732164\n'}]",0,640802,b99d806cf3dccab76161883a6d521231971070c0,9,4,1,935,,,0,"Update default scheduler filters

Make the default set of scheduler filters conditional on the release
being deployed; For Pike or later the CoreFilter, RamFilter and
DiskFilter are superfluous to requirements as this filters are in
effect completed by the Placement API.

Add DiskFilter to list of filters for older OpenStack releases.

Change-Id: Iddb4f1f068b982dcd9a70b11b89df1be9f8aaf20
Closes-Bug: 1731302
Closes-Bug: 1732164
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/02/640802/1 && git format-patch -1 --stdout FETCH_HEAD,"['config.yaml', 'hooks/nova_cc_context.py', 'unit_tests/test_nova_cc_contexts.py']",3,b99d806cf3dccab76161883a6d521231971070c0,bug/1731302," self.os_release.return_value = 'icehouse' self.test_config.set('scheduler-default-filters', 'TestFilter') def test_default_enabled_filters_icehouse(self): self.os_release.return_value = 'icehouse' self.assertEqual(context.default_enabled_filters(), context._base_enabled_filters) def test_default_enabled_filters_pike(self): self.os_release.return_value = 'pike' self.assertEqual(context.default_enabled_filters(), context._pike_enabled_filters) def test_default_enabled_filters_rocky(self): self.os_release.return_value = 'rocky' self.assertEqual(context.default_enabled_filters(), context._pike_enabled_filters)",,65,3
openstack%2Frpm-packaging~master~Icb737c121ccddad2647e2d20e2aad1a3be090c6e,openstack/rpm-packaging,master,Icb737c121ccddad2647e2d20e2aad1a3be090c6e,oslo.service: Update to 1.38.0,MERGED,2019-03-02 07:07:15.000000000,2019-03-05 09:50:17.000000000,2019-03-05 09:50:17.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-03-02 07:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1cae220d31c2ab8f8c562738d54a227665cda3a4', 'message': 'oslo.service: Update to 1.38.0\n\nChange-Id: Icb737c121ccddad2647e2d20e2aad1a3be090c6e\n'}, {'number': 2, 'created': '2019-03-05 05:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/114a753b52c131eb4c58a799f4870d778651e881', 'message': 'oslo.service: Update to 1.38.0\n\nChange-Id: Icb737c121ccddad2647e2d20e2aad1a3be090c6e\n'}, {'number': 3, 'created': '2019-03-05 07:50:03.000000000', 'files': ['openstack/oslo.service/oslo.service.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6d5c021a16a8eef4ad41ecfc49901555ff55305e', 'message': 'oslo.service: Update to 1.38.0\n\nChange-Id: Icb737c121ccddad2647e2d20e2aad1a3be090c6e\n'}]",0,640586,6d5c021a16a8eef4ad41ecfc49901555ff55305e,21,6,3,7102,,,0,"oslo.service: Update to 1.38.0

Change-Id: Icb737c121ccddad2647e2d20e2aad1a3be090c6e
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/86/640586/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.service/oslo.service.spec.j2'],1,1cae220d31c2ab8f8c562738d54a227665cda3a4,,"{% set upstream_version = upstream_version('1.38.0') %}BuildRequires: {{ py2pkg('yappi', py_versions=['py2', 'py3']) }}Requires: {{ py2pkg('debtcollector') }}Requires: {{ py2pkg('yappi') }}",{% set upstream_version = upstream_version('1.34.0') %},4,1
openstack%2Fkuryr-kubernetes~master~I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca,openstack/kuryr-kubernetes,master,I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca,Fix LBaaS sg rules update on deployment scale,MERGED,2019-02-15 13:54:45.000000000,2019-03-05 09:46:13.000000000,2019-03-05 09:46:12.000000000,"[{'_account_id': 6598}, {'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-02-15 13:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/6a5979f391afdd44a9776ab03a453bbe7a3e83ba', 'message': 'Fix service sg rules update on deployment scale\n\nWhen deployments are scaled up or down SG rules must be also updated\non the LBaaS/Service side, by removing or adding new ones. Right now,\nthe LBaaS/Service do not react on deployment scales.\n\nThis commit fixes the issue by ensuring that the service SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 2, 'created': '2019-02-15 14:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/80415c19f4f5932a1787b6aa235e5c85680d65bc', 'message': 'Fix service sg rules update on deployment scale\n\nWhen deployments are scaled up or down SG rules must be also updated\non the LBaaS/Service side, by removing or adding new ones. Right now,\nthe LBaaS/Service do not react on deployment scales.\n\nThis commit fixes the issue by ensuring that the service SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 3, 'created': '2019-02-17 09:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/fb34d079c67e52c6a9dcff058e084474aa1cf47b', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a NP applied and deployments are scaled\nup or down, SG rules must be updated accordindly on the LBaaS/Service side.\nRight now, the LBaaS/Service do not react on deployment scales.\n\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 4, 'created': '2019-02-18 13:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2ba4524770b9e7c19207d30c6e3c4bdd78348be1', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 5, 'created': '2019-02-18 23:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/d4f92d6a48ab0f53aba147f64af7a4d24d567b90', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 6, 'created': '2019-02-19 15:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/658b23ea7e12ff8845111dde4b94c4073aa6d50e', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 7, 'created': '2019-02-22 09:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/dc4aaf0f488f2f4164aed9253730387e2b56b2e8', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 8, 'created': '2019-02-22 12:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/701e1b5d0462806a6211c97a8ee4dd84d316b4e8', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 9, 'created': '2019-02-22 16:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/6261bdb3f46d3de13a1ebcc0a989f98e3f125409', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\nAlso, if Pods, Network Policies and SVCs are created together it might\nhappen that the LBaaS SG remains with default SG rules, even though\nthe policy is being enforced. This commit also fixes this issue by\nsetting the LBaaS Spec annotation, which is used to update the LBaaS\nSG, with the SGs retrieved from the service.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 10, 'created': '2019-02-25 08:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/be40dac3ff43f9998c8e7190ae2d51c52c9945fa', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nAlso, when Pods, Network Policies and SVCs are created together it might\nhappen that the LBaaS SG remains with default SG rules, even though\nthe policy is being enforced. This commit ensures the right SG rules\nare applied on a LBaaS regardless the order of k8s resources creation.\nThis happens by setting the LBaaS Spec annotation whenever a request\nto update the SG rules has been made and retrieving the Spec again\nwhenever a LBaaS member is created.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 11, 'created': '2019-03-04 13:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/62ddc37210e4ae9e7f3ea246e877be3de751deb2', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nAlso, when Pods, Network Policies and SVCs are created together it might\nhappen that the LBaaS SG remains with default SG rules, even though\nthe policy is being enforced. This commit ensures the right SG rules\nare applied on a LBaaS regardless the order of k8s resources creation.\nThis happens by setting the LBaaS Spec annotation whenever a request\nto update the SG rules has been made and retrieving the Spec again\nwhenever a LBaaS member is created.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}, {'number': 12, 'created': '2019-03-04 15:57:59.000000000', 'files': ['kuryr_kubernetes/controller/handlers/lbaas.py', 'kuryr_kubernetes/controller/drivers/utils.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_vif.py', 'kuryr_kubernetes/controller/drivers/lbaasv2.py', 'kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_policy.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_lbaas.py', 'kuryr_kubernetes/utils.py', 'kuryr_kubernetes/controller/handlers/policy.py', 'kuryr_kubernetes/tests/unit/test_utils.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ba89bd027f465cd69e9114b800e6fd077cd09b47', 'message': 'Fix LBaaS sg rules update on deployment scale\n\nWhen a service is created with a Network Policy applied and\ndeployments are scaled up or down, the LBaaS SG rules should be\nupdated accordindly. Right now, the LBaaS/Service do not react on\ndeployment scales.\nThis commit fixes the issue by ensuring that the LBaaS SG is updated\non pod events.\n\nAlso, when Pods, Network Policies and SVCs are created together it might\nhappen that the LBaaS SG remains with default SG rules, even though\nthe policy is being enforced. This commit ensures the right SG rules\nare applied on a LBaaS regardless the order of k8s resources creation.\nThis happens by setting the LBaaS Spec annotation whenever a request\nto update the SG rules has been made and retrieving the Spec again\nwhenever a LBaaS member is created.\n\nChange-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca\nCloses-Bug: 1816015\n'}]",9,637186,ba89bd027f465cd69e9114b800e6fd077cd09b47,45,6,12,27032,,,0,"Fix LBaaS sg rules update on deployment scale

When a service is created with a Network Policy applied and
deployments are scaled up or down, the LBaaS SG rules should be
updated accordindly. Right now, the LBaaS/Service do not react on
deployment scales.
This commit fixes the issue by ensuring that the LBaaS SG is updated
on pod events.

Also, when Pods, Network Policies and SVCs are created together it might
happen that the LBaaS SG remains with default SG rules, even though
the policy is being enforced. This commit ensures the right SG rules
are applied on a LBaaS regardless the order of k8s resources creation.
This happens by setting the LBaaS Spec annotation whenever a request
to update the SG rules has been made and retrieving the Spec again
whenever a LBaaS member is created.

Change-Id: I1c54d17a5fcff5387ffae2b132f5036ee9bf07ca
Closes-Bug: 1816015
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/86/637186/12 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/drivers/utils.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_vif.py', 'kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_policy.py', 'kuryr_kubernetes/controller/handlers/policy.py']",5,6a5979f391afdd44a9776ab03a453bbe7a3e83ba,bug/1816015, services = driver_utils.get_services( policy['metadata']['namespace']) services = driver_utils.get_services(policy['metadata']['namespace']),"from kuryr_kubernetes import exceptions services = self._get_services(policy['metadata']['namespace']) services = self._get_services(policy['metadata']['namespace']) def _get_services(self, namespace): kubernetes = clients.get_kubernetes_client() services = {""items"": []} try: services = kubernetes.get( '{}/namespaces/{}/services'.format(k_const.K8S_API_BASE, namespace)) except exceptions.K8sClientException: LOG.exception(""Kubernetes Client Exception."") raise return services",49,26
openstack%2Frpm-packaging~master~I4a3b74d9eac4144aa2a677c5fd174897bf2799bf,openstack/rpm-packaging,master,I4a3b74d9eac4144aa2a677c5fd174897bf2799bf,Added initial spec file for keystone-tempest-plugin,ABANDONED,2017-09-11 10:41:35.000000000,2019-03-05 09:34:13.000000000,,"[{'_account_id': 1955}, {'_account_id': 7102}, {'_account_id': 10384}, {'_account_id': 12393}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-09-11 10:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2f617f9f9a146112f3bcf9191311507e0b8e7545', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\nDepends-On: Ib27208b55dfb7ac3c64f587aca541528d0305a1f\n'}, {'number': 2, 'created': '2017-09-11 16:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4b80091ac32cc502bfa6889d8e58a6b96972a53d', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 3, 'created': '2017-09-11 16:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a3e6fe4307787dbdf16e51e240f9614ed3f4dfc3', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 4, 'created': '2017-09-12 09:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/680f70c1353dda49616bd71dbfcddb2b9944fc85', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 5, 'created': '2017-09-12 09:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0d1be7535c05613cec2be62e08f50785d2af3303', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 6, 'created': '2017-09-12 10:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0e85f3ea0305649b28f0b99e196d577e40d0b6fe', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 7, 'created': '2017-09-12 10:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/771673cda447268c5cfe8030b278f839a41b8771', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 8, 'created': '2017-09-12 11:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fc1185a7cf8b6295cd2836d353de53a818420c1c', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 9, 'created': '2017-09-12 11:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/926fdee8724e7875d4063ccd483cedf01ee4d0e6', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 10, 'created': '2017-09-12 12:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/438c54f1c0a8892af65a1ec34c4c8c6e16ca7bf5', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 11, 'created': '2018-01-22 08:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8d8d216edb6ffbc7b16028b7b9d51359edca39f7', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}, {'number': 12, 'created': '2018-01-22 09:48:49.000000000', 'files': ['openstack/keystone-tempest-plugin/keystone-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bfa5f8032baa8324d88297e93347cbe6f411a8b2', 'message': 'Added initial spec file for keystone-tempest-plugin\n\nChange-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf\n'}]",6,502445,bfa5f8032baa8324d88297e93347cbe6f411a8b2,56,8,12,12393,,,0,"Added initial spec file for keystone-tempest-plugin

Change-Id: I4a3b74d9eac4144aa2a677c5fd174897bf2799bf
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/45/502445/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/keystone-tempest-plugin/python-keystone-tests-tempest.spec.j2'],1,2f617f9f9a146112f3bcf9191311507e0b8e7545,add-keystone-tempest-plugin,"%global module keystone_tempest_plugin %global plugin keystone-tempest-plugin %global with_doc 1 {% set source = fetch_source('http://tarballs.openstack.org/%{plugin}/%{plugin}-master.tar.gz') %} {% set upstream_version = upstream_version() %} %global common_desc \ This package contains Tempest plugin for functional testing of keystone \ LDAP and federation features. Additionally it provides a plugin to \ automatically load these tests into Tempest. Name: {{ py2name('keystone-tempest-plugin') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for the keystone project. License: {{ license('Apache-2.0') }} URL: https://git.openstack.org/cgit/openstack/%{plugin}/ Source0: {{ source|basename }} BuildArch: noarch %description %{common_desc} BuildRequires: {{ py2pkg('devel') }} BuildRequires: {{ py2pkg('pbr') }} BuildRequires: {{ py2pkg('setuptools') }} BuildRequires: openstack-macros Requires: {{ py2pkg('Tempest') }} Requires: {{ py2pkg('lxml') }} Requires: {{ py2pkg('oslo.config') }} Requires: {{ py2pkg('six') }} Requires: {{ py2pkg('testtools') }} Requires: {{ py2pkg('') }} %if 0%{?with_doc} %package doc Summary: python-%{service}-tests-tempest documentation BuildRequires: {{ py2pkg('Sphinx') }} BuildRequires: {{ py2pkg('oslo.sphinx') }} %description doc It contains the documentation for the Keystone tempest tests. %endif %prep %autosetup -n %{module}-%{upstream_version} # Let's handle dependencies ourseleves %py_req_cleanup # Remove bundled egg-ingo rm -rf %{module}.egg-info %build %{py2_build} # Generate Docs %if 0%{?with_doc} %{__python2} setup.py build_sphinx # remove the sphinx build leftovers rm -rf doc/build/html/.{doctrees,buildinfo} %endif %install %{py2_install} %files %license LICENSE %doc README.rst %{python2_sitelib}/%{module} %{python2_sitelib}/*.egg-info %if 0%{?with_doc} %files doc %doc doc/build/html %license LICENSE %endif %changelog ",,84,0
openstack%2Fmasakari-dashboard~master~I4e62491ac9a9996cfd910e7d69897b92072bb1eb,openstack/masakari-dashboard,master,I4e62491ac9a9996cfd910e7d69897b92072bb1eb,Run all jobs by default using python3,MERGED,2019-02-19 07:10:10.000000000,2019-03-05 09:23:43.000000000,2019-03-05 09:23:42.000000000,"[{'_account_id': 1011}, {'_account_id': 1736}, {'_account_id': 8716}, {'_account_id': 12950}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-19 07:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari-dashboard/commit/01fe445687a9d41600b65c141cc0f6dad971cf4b', 'message': 'Run all jobs by default using python3\n\nThis patch implements the community wide goal to run all jobs by\ndefault using python3.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I4e62491ac9a9996cfd910e7d69897b92072bb1eb\n'}, {'number': 2, 'created': '2019-02-26 06:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari-dashboard/commit/e1e1baf6ca8f279846a2251719a3e0c90cddd94b', 'message': 'Run all jobs by default using python3\n\nThis patch implements the community wide goal to run all jobs by\ndefault using python3.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I4e62491ac9a9996cfd910e7d69897b92072bb1eb\n'}, {'number': 3, 'created': '2019-03-05 09:01:29.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/masakari-dashboard/commit/d3b34063a19d7ecd598bafbcd0e60dd9a5f13136', 'message': 'Run all jobs by default using python3\n\nThis patch implements the community wide goal to run all jobs by\ndefault using python3.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I4e62491ac9a9996cfd910e7d69897b92072bb1eb\n'}]",0,637713,d3b34063a19d7ecd598bafbcd0e60dd9a5f13136,12,5,3,26541,,,0,"Run all jobs by default using python3

This patch implements the community wide goal to run all jobs by
default using python3.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I4e62491ac9a9996cfd910e7d69897b92072bb1eb
",git fetch https://review.opendev.org/openstack/masakari-dashboard refs/changes/13/637713/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,01fe445687a9d41600b65c141cc0f6dad971cf4b,python3-first,"envlist = pep8,py27,py35,py36[testenv:py36] basepython = python3.6 commands = {[testenv]commands} stestr run {posargs} ","envlist = py35,py27,pep8",12,3
