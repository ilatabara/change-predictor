id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fnova-specs~master~I64f530d84b56b7e2365dc041689dc034f9b91f42,openstack/nova-specs,master,I64f530d84b56b7e2365dc041689dc034f9b91f42,Cells v2 mapping,MERGED,2014-11-18 21:01:20.000000000,2014-12-12 00:16:12.000000000,2014-12-12 00:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 1849}, {'_account_id': 2033}, {'_account_id': 2271}, {'_account_id': 3031}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9420}, {'_account_id': 12548}, {'_account_id': 12898}, {'_account_id': 13530}]","[{'number': 1, 'created': '2014-11-18 21:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7b98369f79a9e7ebbefef55257348909603cb4db', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 2, 'created': '2014-11-18 21:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5d5d32814b7b1e505cf6ac6777605aa9c5b62129', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 3, 'created': '2014-11-19 14:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/be0f7db40474c701693933b682b65c9097cc10fc', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 4, 'created': '2014-11-21 21:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/25cda1a444301b0ac80624d1abeddbcdac16f6a4', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 5, 'created': '2014-11-24 19:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/207eca82b859ea6fedb8b81a8cf52887cf7cfb51', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 6, 'created': '2014-12-02 20:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9462b070c3b021497ccf5145adaaa5fdcabcf250', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 7, 'created': '2014-12-05 20:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7b2e8d54bbbef4678401aa5f7989ed24c8a5717e', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 8, 'created': '2014-12-11 13:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4019c848239c84073270ff62adda0963404b87b9', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}, {'number': 9, 'created': '2014-12-11 20:52:25.000000000', 'files': ['specs/kilo/approved/cells-v2-mapping.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9775e90de458ee49a0ece14c83b14dc85663ea1f', 'message': 'Cells v2 mapping\n\nSpec for adding a new mapping table for cell and making the rpc and\ndatabase layers able to communicate with an arbitrary cell per call.\n\nbp cells-v2-mapping\nChange-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42\n'}]",82,135424,9775e90de458ee49a0ece14c83b14dc85663ea1f,69,14,9,5441,,,0,"Cells v2 mapping

Spec for adding a new mapping table for cell and making the rpc and
database layers able to communicate with an arbitrary cell per call.

bp cells-v2-mapping
Change-Id: I64f530d84b56b7e2365dc041689dc034f9b91f42
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/24/135424/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/cells-v2-mapping.rst'],1,7b98369f79a9e7ebbefef55257348909603cb4db,bp/cells-v2-mapping,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Cells v2 mapping ========================================== https://blueprints.launchpad.net/nova/+spec/cells-v2-mapping The existing cells implementation depends on a nova-cells service for communication between the Nova API and instances/hosts within a cell. The compute api should be able to communicate with a cells database and message queue directly. Problem description =================== There have been a number of challenges with the current cells approach such as unimplemented features in the nova-cells proxy layer, and a large difference in the deployment model when using cells vs not. This is the start of an effort to move Nova to a single deployment model which addresses the needs of current cells and non cells deployers. Use Cases ---------- This addresses a few use cases. Deployers who use, or want to use, cells and want full feature parity with a non cells Nova. Deployers who want to use cells as a buildout model for their deployment but don't want to have to change their architecture to go from 0 to 1 cell. And developers who want to add features to Nova without needing to understand the hidden cells proxy layer. Project Priority ----------------- Cells v2 has been made a project priority for Kilo. Proposed change =============== In order to solve some of the issues and at the same time bring some of the benefits of a cells deployment into a standard Nova deployment we are going to rebuild cells like functionality without a nova-cells service. The change being proposed is a new database and table for storing a mapping of cell to database and message queue. This is similar to the current cells table, but the concepts of weight and is_parent aren't needed and a database connection is needed. Additionally the database and rpc abstractions in Nova need to be capable of communicating with an arbitrary endpoint for every call/query. There is nothing in place to use this yet so the scope of work ends at just having the capability to do it. Alternatives ------------ We could continue to use the nova-cells model in place today. The downsides of this have been described above. Data model impact ----------------- A new 'cell_mapping' table will be added. And it should be added outside of the current 'nova' database in a new 'nova_api' database. The table will look approximately like: CREATE TABLE `cell_mapping` ( `created_at` datetime DEFAULT NULL, `updated_at` datetime DEFAULT NULL, `deleted_at` datetime DEFAULT NULL, `id` int(11) NOT NULL AUTO_INCREMENT, `uuid` varchar(36) NOT NULL, `name` varchar(255) DEFAULT NULL, `deleted` int(11) DEFAULT NULL, `transport_url` mediumtext NOT NULL, `database_connection` mediumtext NOT NULL) REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ On its own this change does not introduce a performance impact. When it's used by later specs it does introduce another database lookup for many actions within Nova. For example a 'nova show <uuid>' will require Nova to look up the database that an instance is in before it can query it for instance data. Other deployer impact --------------------- This blueprint introduces the concept of a database that is conceptually distinct from the current nova database. Deployers will need to consider how they want to manage a second database, whether it resides with the current nova database or not. Developer impact ---------------- This change means that developers should understand that RPC messages or database queries may hit one of many endpoints. At this point it should not affect developers work within Nova or require a change in thinking. Implementation ============== Assignee(s) ----------- Primary assignee: alaski Other contributors: <launchpad-id or None> Work Items ---------- * Ensure Nova database api can communicate with an arbitrary database on each call. * Setup separate database migration path for migrations on a new database. * Add database migration for 'cell_mapping' table. Dependencies ============ None Testing ======= Since this is designed to be an internal re-architecting of Nova with no user visible changes the current suite of Tempest or functional tests should suffice. At some point we will want to look at how to test multiple cells or potentially exposing the concept of a cell in the API and we will tackle testing requirements then. Documentation Impact ==================== There should be no documentation impact at this time. There will be a series of specs/blueprints leading up to a functional cells v2 and documentation will need to be a part of that, but nothing documentation worthy is happening here. References ========== ``https://etherpad.openstack.org/p/kilo-nova-cells`` ",,181,0
openstack%2Fnova-specs~master~Ib46b73ae87321f48edb47ab8a12ea0d143b84825,openstack/nova-specs,master,Ib46b73ae87321f48edb47ab8a12ea0d143b84825,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:42:40.000000000,2014-12-12 00:10:03.000000000,2014-12-12 00:10:01.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-05 03:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/754694064f364aa4d956b2f6f4468e8921e251ed', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: Ib46b73ae87321f48edb47ab8a12ea0d143b84825\n'}, {'number': 2, 'created': '2014-12-11 20:51:38.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/507f16bb23fbeef0e589c19213b8d61b20f3a4cd', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: Ib46b73ae87321f48edb47ab8a12ea0d143b84825\n'}]",0,139341,507f16bb23fbeef0e589c19213b8d61b20f3a4cd,14,4,2,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: Ib46b73ae87321f48edb47ab8a12ea0d143b84825
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/41/139341/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,754694064f364aa4d956b2f6f4468e8921e251ed,infra-manual,"For more information about working with gerrit, see http://docs.openstack.org/infra/manual/developers.html#development-workflow","For more information about working with gerrit, see https://wiki.openstack.org/wiki/Gerrit_Workflow",1,1
openstack%2Fneutron-specs~master~Iab062490c7c01a1ef7c5cc175c7c9f324a892744,openstack/neutron-specs,master,Iab062490c7c01a1ef7c5cc175c7c9f324a892744,Full-stack white-box tests framework,MERGED,2014-10-14 12:37:48.000000000,2014-12-12 00:08:34.000000000,2014-12-12 00:08:33.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 6524}, {'_account_id': 6579}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9970}, {'_account_id': 12444}]","[{'number': 1, 'created': '2014-10-14 12:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cda6859411714be20d32d999697ec8dcd0360541', 'message': 'Integration Tests framework\n\nThis blueprint proposes a new framework for integration tests which will\nbe implemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 2, 'created': '2014-10-14 12:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/645235075eb03485e1f61f28d10d1c2c2b86ea33', 'message': 'Integration Tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 3, 'created': '2014-10-15 08:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/fc2da2b1ea659e39c58ae2f4c65e323ecf775760', 'message': 'Integration Tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 4, 'created': '2014-10-19 10:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e7d3f4ad7aec1b4b75b8a43196d1a452f35afaf7', 'message': 'Integration Tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 5, 'created': '2014-11-03 14:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cd6aa29d6d5b1a8910dd49e99ed3ba85af90126d', 'message': 'Integration Tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 6, 'created': '2014-11-04 06:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b74fb740945a9cbd81b48d586725e97939209831', 'message': 'Integration Tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 7, 'created': '2014-11-04 06:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b4c78484820b74d827163a3b5a4d5db9ed47a63e', 'message': 'Full-stack integration testing framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 8, 'created': '2014-11-10 16:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a86affaa4cbdf2cbd49e7c8970401c74b46495d0', 'message': 'Integration Tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 9, 'created': '2014-11-10 17:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/def09741a62d9217236f00122e6d49442c513bd4', 'message': 'Full-stack integration tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 10, 'created': '2014-11-17 12:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6233628dc97c07e770523f37d6959373f6caf17c', 'message': 'Full-stack integration tests framework\n\nThis proposes a new framework for integration tests which will be\nimplemented overtime. Integration tests are designed to check Neutron\nas a project, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 11, 'created': '2014-11-19 19:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6e92df1b76e04abd15d2985cbd6a0d5518c7eed1', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 12, 'created': '2014-11-19 19:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/588cd209bbacf43b3c014489298afc38cefc8d73', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 13, 'created': '2014-11-19 19:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/614c79882f4d6abdbf60bc115ba103934017ccb3', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 14, 'created': '2014-11-26 09:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/afa9b1ab3a3c74a9a8e343c4820d8a6e946c1067', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 15, 'created': '2014-11-26 10:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3f930034a4d28a505004caa10355d4bb1fc75378', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 16, 'created': '2014-12-08 09:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8566189fcbcefe2b7abe07fdb2bf40860279fe57', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 17, 'created': '2014-12-08 09:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4ac927efd17ac4cfcfd44cf28634e8ba7f8e36d3', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}, {'number': 18, 'created': '2014-12-09 06:31:58.000000000', 'files': ['specs/kilo/full-stack-white-box-tests.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/94d1837f9aecd991e4702c5b7a3b19fcdcfedc82', 'message': 'Full-stack white-box tests framework\n\nThis proposes a new framework for white-box tests which will be\nimplemented overtime. Full-stack tests are designed to check Neutron\nas a whole, with no dependencies from other projects (like keystone).\n\nbp integration-tests\n\nChange-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744\n'}]",208,128257,94d1837f9aecd991e4702c5b7a3b19fcdcfedc82,82,17,18,12444,,,0,"Full-stack white-box tests framework

This proposes a new framework for white-box tests which will be
implemented overtime. Full-stack tests are designed to check Neutron
as a whole, with no dependencies from other projects (like keystone).

bp integration-tests

Change-Id: Iab062490c7c01a1ef7c5cc175c7c9f324a892744
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/57/128257/18 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/integration-tests.rst'],1,cda6859411714be20d32d999697ec8dcd0360541,bp/integration-tests,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Neutron/Integration Tests Framework =================================== Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/integration-tests This blueprint specifies the framework needed to write new integration tests (which use running Neutron processes instead of importing neutron code and calling functions.) Problem Description =================== Currently there are 3 main types of tests for Neutron: 1. Unit tests, which intend to check the code mostly at the function level where each function is tested separately. For example: make sure that function X returns value Y when the arguments are A, B and C. 2. Functional tests, which intend to check that the code in question does what was intended, or that features are actually working. The features are tested on a process level. For example: make sure that the L3 HA fail-over functionality works. 3. Tempest tests, which check that OpenStack as a whole and Neutron is particular behave as intended. For example: start a new instance and make sure that the instance has connectivity to the external network. There is currently no way to check Neutron as a black box - test Neutron as a whole, but without other OpenStack components such as Nova or Cinder. Proposed Change =============== Integration tests fall between Functional and Tempest tests - they intend to check specific Neutron features as a whole but without interacting with outside components. The framework will be written in the Neutron tree, thus allowing for higher code flexibility than offered for Tempest tests, but also allowing more infrastructure than Functional tests. The framework will support: 1. Writing integration tests using the unittest module, 2. Restarting all the Neutron processes which are needed (neutron-server, L3 agent, etc...) between each test, 3. Wiping the databases and cleaning up resources (specifically running neutron-ovs-cleanup and neutron-netns-cleanup), 4. Using python-neutronclient to communicate with Neutron. No other interaction with a running neutron process should be needed. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- Running integration tests involves wiping the databases after each test and cleaning up other Neutron resources, thus integration tests should not be ran on a production setup. Notifications Impact -------------------- None Other End User Impact --------------------- Users will be able to manually execute integration tests using normal tools (such as tox.) No changes to python-neutronclient are needed. Performance Impact ------------------ Running integration tests involves wiping the databases and running Neutron processes depending on the needs of each test suite, thus integration tests should not be ran on a production setup. Other Deployer Impact --------------------- Running integration tests will be available using the tox, similarly to current unit and functional tests. Developer Impact ---------------- Writing new features might require writing integration tests for them, as well as unit and function tests. Community Impact ---------------- Integration tests will increase the level of credibility and reliability of new and existing Neutron features. Alternatives ------------ Writing these kind of tests could be done in tempest. Implementation ============== The framework requires 2 new classes that support creating temporary configuration files (which may differ between each test suite), cleaning up resources and spawning and killing Neutron processes between tests. For this purpose, the following new classes are implemented: 1. Template: a class responsible for generating temporary configuration files (later passed to processes with --config-file) and retrieving configuration options from them. 2. ResourceFixture: a class responsible for spawning a process which cleans up a resource. For example: neutron-netns-cleanup and neutron-ovs-cleanup will be used by this class to clean up the respective resource. 3. ProcessFixture: a class responsible for spawning and killing Neutron processes before and after each test. Each ProcessFixture should accept 2 templates (one representing the core config file and one representing the plugin config file). When killing a process, the class should make sure the process is actually killed before deleting the temporary configuration files created by the Templates. 4. BaseIntegrationTestCase: Should know to receive any number of ResourceFixtures and ProcessFixtures, set them up before each test and clean them up after each test. Also, before each test a new database should be created and initialized for maintaining segregation between tests. Notes: 1. The difference between ResourceFixture and ProcessFixture is that the former only knows to execute a process whenever cleanUp is called (after each test) whereas ProcessFixture manages a process for the duration of a test (ranging from spawning the process pre-test and killing it post-test). 2. Currently, the framework doesn't support concurrency (running more than one test at a time), but this can be implemented with some extra thought and attention. For example, each test suite should be assign their own OS-level integration bridge, different SQL databases, etc, but that can be configured using various Templates. 3. In the future, HA and DVR integration tests for the L3 agent will be written. This will require running 2 or more l3 agents (and 2 or more ovs agents) in one machine. This functionality should be developed and is outside the scope of this blueprint. Assignee(s) ----------- Primary assignee: John Schwarz <jschwarz@redhat.com> Other contributors: Assaf Muller <amuller@redhat.com> Maru Newby <marun@redhat.com> Work Items ---------- 1. Add ability to run daemonized Neutron processes, 2. Actual Integration Tests framework, 3. An example integration test for future reference. Dependencies ============ 1. https://review.openstack.org/#/c/124136/ 2. https://review.openstack.org/#/c/125109/ Testing ======= Tempest Tests ------------- Since the changes proposed in this blueprint are actual tests, no new tempest tests need to be added. Unit tests where appropriate will be added. Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== User Documentation ------------------ None Developer Documentation ----------------------- The new framework should be documented thoroughly somewhere (maybe a wiki page?) References ========== None ",,220,0
openstack%2Fneutron~master~I9758ad4ca9f7e8534abf38f5064b01b0c353e904,openstack/neutron,master,I9758ad4ca9f7e8534abf38f5064b01b0c353e904,Disallow log hints in LOG.debug,MERGED,2014-12-08 15:31:35.000000000,2014-12-11 23:57:15.000000000,2014-12-11 23:18:30.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11126}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-08 15:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8101516406ee31b344022d40b6ea6674cb035d3c', 'message': 'Disallow log hints in LOG.debug\n\nCurrently LOG.debug(_(...)) is disallowed but not LOG.debug(_Lx(...)).\nThis change disallows all log hints in LOG.debug calls.\n\nChange-Id: I9758ad4ca9f7e8534abf38f5064b01b0c353e904\nPartial-bug: #1320867\n'}, {'number': 2, 'created': '2014-12-08 18:59:48.000000000', 'files': ['neutron/tests/unit/test_hacking.py', 'neutron/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7bdbd6f3345e416e4f8e8c0e8f2741081ea339c6', 'message': 'Disallow log hints in LOG.debug\n\nCurrently LOG.debug(_(...)) is disallowed but not LOG.debug(_Lx(...)).\nThis change disallows all log hints in LOG.debug calls.\n\nChange-Id: I9758ad4ca9f7e8534abf38f5064b01b0c353e904\nPartial-bug: #1320867\n'}]",0,140026,7bdbd6f3345e416e4f8e8c0e8f2741081ea339c6,56,32,2,8124,,,0,"Disallow log hints in LOG.debug

Currently LOG.debug(_(...)) is disallowed but not LOG.debug(_Lx(...)).
This change disallows all log hints in LOG.debug calls.

Change-Id: I9758ad4ca9f7e8534abf38f5064b01b0c353e904
Partial-bug: #1320867
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/140026/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_hacking.py', 'neutron/hacking/checks.py']",2,8101516406ee31b344022d40b6ea6674cb035d3c,," """"""Check for 'LOG.debug(_(' and 'LOG.debug(_Lx(' for hint in _all_hints: if logical_line.startswith(""LOG.debug(%s("" % hint): yield(0, ""N319 Don't translate debug level logs"")"," """"""Check for 'LOG.debug(_(' if logical_line.startswith(""LOG.debug(_(""): yield(0, ""N319 Don't translate debug level logs"")",10,3
openstack%2Fqa-specs~master~I127cd5d9d0bd9f0519718c76114e35a5afc669d7,openstack/qa-specs,master,I127cd5d9d0bd9f0519718c76114e35a5afc669d7,Move implemented specs into implemented dir,MERGED,2014-12-03 07:23:03.000000000,2014-12-11 23:52:49.000000000,2014-12-11 23:52:49.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-12-03 07:23:03.000000000', 'files': ['specs/implemented/cinder-v2-api-tests.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/911be9a06e46f71d4ff54bd486bdcb17d40b1332', 'message': 'Move implemented specs into implemented dir\n\nChange-Id: I127cd5d9d0bd9f0519718c76114e35a5afc669d7\n'}]",0,138655,911be9a06e46f71d4ff54bd486bdcb17d40b1332,9,5,1,12393,,,0,"Move implemented specs into implemented dir

Change-Id: I127cd5d9d0bd9f0519718c76114e35a5afc669d7
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/55/138655/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/implemented/cinder-v2-api-tests.rst'],1,911be9a06e46f71d4ff54bd486bdcb17d40b1332,close_blueprint,Other Contributors: Chandan Kumar <chkumar246@gmail.com> jun xie <junxiebj@cn.ibm.com> ,,4,0
openstack%2Fkeystonemiddleware~master~I4d09a30c0163106dab52062fab6000aaec0efb5d,openstack/keystonemiddleware,master,I4d09a30c0163106dab52062fab6000aaec0efb5d,Allow loading other auth methods in auth_token,MERGED,2014-10-20 08:59:02.000000000,2014-12-11 23:52:09.000000000,2014-12-11 23:52:08.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-10-20 08:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f600c12c9746078d316d5770debf48b39a352ee0', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 2, 'created': '2014-10-23 16:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6a9ba4d104a249a4705cc16b29398055ee31a162', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 3, 'created': '2014-10-24 15:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8823fa35383fc3834386919aee4916e06b765559', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 4, 'created': '2014-10-27 16:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d292d745694d6c07cd3ab92a4fc7e7d31eb33d8d', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 5, 'created': '2014-10-28 09:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d06dcf0ebb59b9e133884fdc5a8fb3e64cb7de17', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 6, 'created': '2014-11-18 20:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/9fb1956f657c1370e4eaa3732afea019ec01ee16', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 7, 'created': '2014-11-19 00:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/cdfc47748f5301bd54b0360279a88a024d872b24', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 8, 'created': '2014-12-03 01:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/801cc516dd8fb3d31374731509523841985e8886', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 9, 'created': '2014-12-03 01:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/99397569eb0af9c7d3218573dcdb4e26c0db465b', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 10, 'created': '2014-12-03 02:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/b0628e367c58d6d9bb18b423e9b4bf51d1f1a57e', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 11, 'created': '2014-12-04 01:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/2207dcc54378a753aaa02bc7f2f10d6f727507b6', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 12, 'created': '2014-12-05 00:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/01d69241117c8a523ab4ec12a7dc5be2d523391f', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 13, 'created': '2014-12-07 23:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/b6e602527b6f02b39f0fc58316548eec536811d1', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 14, 'created': '2014-12-08 04:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/9dee99c4a2fef7e21599a26f8b22c22436035d5d', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 15, 'created': '2014-12-08 23:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/dbf57075359592e73df9a92280cd0c0534dcd87d', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}, {'number': 16, 'created': '2014-12-09 04:03:04.000000000', 'files': ['keystonemiddleware/auth_token.py', 'keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f8b09b565f56e76fe4ea253ff39f313501a2d4f3', 'message': 'Allow loading other auth methods in auth_token\n\nAdd handlers for loading user specified authentication plugins from the\nconfig file. If an auth plugin is not specified then we fall back to\nusing the older legacy options.\n\nChange-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d\nCloses-Bug: #1372142\nBlueprint: pluggable-auth\n'}]",5,129552,f8b09b565f56e76fe4ea253ff39f313501a2d4f3,54,10,16,7191,,,0,"Allow loading other auth methods in auth_token

Add handlers for loading user specified authentication plugins from the
config file. If an auth plugin is not specified then we fall back to
using the older legacy options.

Change-Id: I4d09a30c0163106dab52062fab6000aaec0efb5d
Closes-Bug: #1372142
Blueprint: pluggable-auth
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/52/129552/16 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,f600c12c9746078d316d5770debf48b39a352ee0,bug/1372142,"auth.register_conf_options(CONF, 'keystone_authtoken') # NOTE(jamielennox): Using auth plugins can only be done via the config # file. These values cannot be provided by the paste config file. This # is intentional to deprecate those paste provided config values, also # it's really hard to support the paste dictionary format using the # auth loading functions available in keystoneclient. auth_plugin = auth.load_from_conf_options(CONF, _AUTHTOKEN_GROUP) if auth_plugin is None: # NOTE(jamielennox): The legacy case. If an auth plugin is not # specified directly then load it from the old config values. auth_plugin = _AuthTokenPlugin( auth_host=self._conf_get('auth_host'), auth_port=int(self._conf_get('auth_port')), auth_protocol=self._conf_get('auth_protocol'), auth_admin_prefix=self._conf_get('auth_admin_prefix'), username=self._conf_get('admin_user'), password=self._conf_get('admin_password'), tenant_name=self._conf_get('admin_tenant_name'), admin_token=self._conf_get('admin_token'), identity_uri=self._conf_get('identity_uri'), log=self._LOG) # FIXME(jamielennox): Session.construct doesn't take a auth plugin as # argument because it is designed as a legacy handler for older code # that specifies CA arguments differently. So we have to set it # manually. We should fix construct or add a better method. sess.auth = auth_plugin"," sess.auth = _AuthTokenPlugin( auth_host=self._conf_get('auth_host'), auth_port=int(self._conf_get('auth_port')), auth_protocol=self._conf_get('auth_protocol'), auth_admin_prefix=self._conf_get('auth_admin_prefix'), username=self._conf_get('admin_user'), password=self._conf_get('admin_password'), tenant_name=self._conf_get('admin_tenant_name'), admin_token=self._conf_get('admin_token'), identity_uri=self._conf_get('identity_uri'), log=self._LOG)",28,11
openstack%2Fpython-keystoneclient~master~I1a6ded02b75a3bc9b1ca880db8a9b9b460d36774,openstack/python-keystoneclient,master,I1a6ded02b75a3bc9b1ca880db8a9b9b460d36774,Log the CA cert with the debug statement,MERGED,2014-10-24 11:31:44.000000000,2014-12-11 23:49:25.000000000,2014-12-11 23:49:24.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-10-24 11:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/eaab9dfa39c8f4ea5164014ebc524f32a9252e7b', 'message': 'Log the CA cert with the debug statement\n\nIf you are using a custom CA bundle rather than the default OS one then\nwe should log that as part of the curl statement to make debugging\neasier.\n\nChange-Id: I1a6ded02b75a3bc9b1ca880db8a9b9b460d36774\n'}, {'number': 2, 'created': '2014-10-24 12:44:51.000000000', 'files': ['keystoneclient/tests/test_session.py', 'keystoneclient/session.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/89d9411afd701f25742f3261301860fd58e2bbc2', 'message': 'Log the CA cert with the debug statement\n\nIf you are using a custom CA bundle rather than the default OS one then\nwe should log that as part of the curl statement to make debugging\neasier.\n\nChange-Id: I1a6ded02b75a3bc9b1ca880db8a9b9b460d36774\n'}]",1,130754,89d9411afd701f25742f3261301860fd58e2bbc2,15,6,2,7191,,,0,"Log the CA cert with the debug statement

If you are using a custom CA bundle rather than the default OS one then
we should log that as part of the curl statement to make debugging
easier.

Change-Id: I1a6ded02b75a3bc9b1ca880db8a9b9b460d36774
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/54/130754/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/test_session.py', 'keystoneclient/session.py']",2,eaab9dfa39c8f4ea5164014ebc524f32a9252e7b,printcacert," elif isinstance(self.verify, six.string_types): string_parts.append('--cacert ""%s""' % self.verify)",,12,0
openstack%2Fmonasca-api~master~I5c2a057911e4c0f4a9f738dddffe0fb4930f287f,openstack/monasca-api,master,I5c2a057911e4c0f4a9f738dddffe0fb4930f287f,Removed swagger,MERGED,2014-12-11 18:40:47.000000000,2014-12-11 23:36:32.000000000,2014-12-11 23:36:32.000000000,"[{'_account_id': 3}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-11 18:40:47.000000000', 'files': ['src/main/resources/swagger-ui/css/reset.css', 'src/main/resources/swagger-ui/lib/swagger-oauth.js', 'src/main/resources/swagger-ui/swagger-ui.min.js', 'src/main/java/monasca/api/resource/MetricResource.java', 'src/main/resources/swagger-ui/lib/jquery.slideto.min.js', 'src/main/resources/swagger-ui/lib/underscore-min.js', 'src/main/resources/swagger-ui/lib/jquery.wiggle.min.js', 'src/main/java/monasca/api/domain/model/alarm/Alarm.java', 'src/main/java/monasca/api/resource/VersionResource.java', 'src/main/resources/swagger-ui/images/wordnik_api.png', 'pom.xml', 'src/main/resources/swagger-ui/images/explorer_icons.png', 'src/main/resources/swagger-ui/lib/shred.bundle.js', 'src/main/resources/swagger-ui/lib/jquery.ba-bbq.min.js', 'src/main/resources/swagger-ui/images/throbber.gif', 'src/main/resources/swagger-ui/lib/shred/content.js', 'src/main/java/monasca/api/MonApiApplication.java', 'src/main/resources/swagger-ui/lib/jquery-1.8.0.min.js', 'src/main/java/monasca/api/domain/model/alarmdefinition/AlarmDefinition.java', 'src/main/resources/swagger-ui/lib/backbone-min.js', 'src/main/resources/swagger-ui/lib/handlebars-1.0.0.js', 'src/main/resources/swagger-ui/css/screen.css', 'src/main/resources/swagger-ui/images/pet_store_api.png', 'src/main/java/monasca/api/resource/MeasurementResource.java', 'src/main/resources/swagger-ui/lib/swagger.js', 'src/main/java/monasca/api/bundle/SwaggerBundle.java', 'src/main/resources/swagger-ui/lib/highlight.7.3.pack.js', 'src/main/java/monasca/api/resource/NotificationMethodResource.java', 'src/main/java/monasca/api/resource/AlarmDefinitionResource.java', 'src/main/java/monasca/api/resource/StatisticResource.java', 'src/main/resources/swagger-ui/index.html', 'src/main/resources/swagger-ui/images/logo_small.png', 'src/main/java/monasca/api/resource/AlarmResource.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/29a5f948aed3052bc7297516f882efab0be85fe6', 'message': 'Removed swagger\n\nChange-Id: I5c2a057911e4c0f4a9f738dddffe0fb4930f287f\n'}]",0,141123,29a5f948aed3052bc7297516f882efab0be85fe6,6,3,1,2419,,,0,"Removed swagger

Change-Id: I5c2a057911e4c0f4a9f738dddffe0fb4930f287f
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/23/141123/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/main/resources/swagger-ui/css/reset.css', 'src/main/resources/swagger-ui/lib/swagger-oauth.js', 'src/main/resources/swagger-ui/swagger-ui.min.js', 'src/main/java/monasca/api/resource/MetricResource.java', 'src/main/resources/swagger-ui/lib/jquery.slideto.min.js', 'src/main/resources/swagger-ui/lib/underscore-min.js', 'src/main/resources/swagger-ui/lib/jquery.wiggle.min.js', 'src/main/java/monasca/api/domain/model/alarm/Alarm.java', 'src/main/java/monasca/api/resource/VersionResource.java', 'src/main/resources/swagger-ui/images/wordnik_api.png', 'pom.xml', 'src/main/resources/swagger-ui/images/explorer_icons.png', 'src/main/resources/swagger-ui/lib/shred.bundle.js', 'src/main/resources/swagger-ui/lib/jquery.ba-bbq.min.js', 'src/main/resources/swagger-ui/images/throbber.gif', 'src/main/resources/swagger-ui/lib/shred/content.js', 'src/main/java/monasca/api/MonApiApplication.java', 'src/main/resources/swagger-ui/lib/jquery-1.8.0.min.js', 'src/main/java/monasca/api/domain/model/alarmdefinition/AlarmDefinition.java', 'src/main/resources/swagger-ui/lib/backbone-min.js', 'src/main/resources/swagger-ui/lib/handlebars-1.0.0.js', 'src/main/resources/swagger-ui/css/screen.css', 'src/main/resources/swagger-ui/images/pet_store_api.png', 'src/main/java/monasca/api/resource/MeasurementResource.java', 'src/main/resources/swagger-ui/lib/swagger.js', 'src/main/java/monasca/api/bundle/SwaggerBundle.java', 'src/main/resources/swagger-ui/lib/highlight.7.3.pack.js', 'src/main/java/monasca/api/resource/NotificationMethodResource.java', 'src/main/java/monasca/api/resource/AlarmDefinitionResource.java', 'src/main/java/monasca/api/resource/StatisticResource.java', 'src/main/resources/swagger-ui/index.html', 'src/main/resources/swagger-ui/images/logo_small.png', 'src/main/java/monasca/api/resource/AlarmResource.java']",33,29a5f948aed3052bc7297516f882efab0be85fe6,remove_swagger,"import com.google.common.base.Strings; import com.codahale.metrics.annotation.Timed; import com.fasterxml.jackson.databind.JsonMappingException; import org.hibernate.validator.constraints.NotEmpty; import org.joda.time.DateTime; import monasca.common.model.alarm.AlarmState; @Context UriInfo uriInfo,","import org.hibernate.validator.constraints.NotEmpty; import org.joda.time.DateTime; import com.codahale.metrics.annotation.Timed; import com.fasterxml.jackson.databind.JsonMappingException; import com.google.common.base.Strings;import monasca.common.model.alarm.AlarmState;import monasca.api.domain.model.alarmdefinition.AlarmDefinition;import com.wordnik.swagger.annotations.Api; import com.wordnik.swagger.annotations.ApiOperation; import com.wordnik.swagger.annotations.ApiParam; import com.wordnik.swagger.annotations.ApiResponse; import com.wordnik.swagger.annotations.ApiResponses;@Api(value = ""/v2.0/alarms"", description = ""Operations for accessing alarms"") @ApiOperation(value = ""Delete alarm"") @ApiOperation(value = ""Get alarm"", response = Alarm.class) @ApiResponses(value = {@ApiResponse(code = 400, message = ""Invalid ID supplied""), @ApiResponse(code = 404, message = ""Alarm not found"")}) @ApiParam(value = ""ID of alarm to fetch"", required = true) @Context UriInfo uriInfo, @ApiOperation(value = ""Get alarm state history"", response = AlarmStateHistory.class, responseContainer = ""List"") @ApiOperation(value = ""List alarms"", response = Alarm.class, responseContainer = ""List"") @ApiOperation(value = ""List alarm state history"", response = AlarmDefinition.class, responseContainer = ""List"") @ApiOperation(value = ""Update alarm"", response = Alarm.class)",89,8641
openstack%2Fcongress~master~Icf5018c45dd9b3286156366c7e11341e5fd0ef32,openstack/congress,master,Icf5018c45dd9b3286156366c7e11341e5fd0ef32,Fix tempest integration due to change in tempest,MERGED,2014-12-11 20:59:19.000000000,2014-12-11 23:29:44.000000000,2014-12-11 23:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-11 20:59:19.000000000', 'files': ['contrib/tempest/tempest/scenario/manager_congress.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/f8af19260a14cf44588378f74425691d64b9dcd9', 'message': 'Fix tempest integration due to change in tempest\n\nThis patch fixes the tempest integration with congress. The following\nchange:  Ia1ed4ab3cd2e4941fb072b3390f4859420989e74 in tempest removed\nthe debug file so this patch updates the congress manager to reflect\nthat change.\n\nChange-Id: Icf5018c45dd9b3286156366c7e11341e5fd0ef32\nCloses-bug: 1401665\n'}]",0,141161,f8af19260a14cf44588378f74425691d64b9dcd9,11,4,1,4395,,,0,"Fix tempest integration due to change in tempest

This patch fixes the tempest integration with congress. The following
change:  Ia1ed4ab3cd2e4941fb072b3390f4859420989e74 in tempest removed
the debug file so this patch updates the congress manager to reflect
that change.

Change-Id: Icf5018c45dd9b3286156366c7e11341e5fd0ef32
Closes-bug: 1401665
",git fetch https://review.opendev.org/openstack/congress refs/changes/61/141161/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/manager_congress.py'],1,f8af19260a14cf44588378f74425691d64b9dcd9,bug/1401665,,from tempest.common import debug debug.log_ip_ns(),0,2
openstack%2Fheat~master~I338e92d349bdf8fff13de81865bccb76016dae88,openstack/heat,master,I338e92d349bdf8fff13de81865bccb76016dae88,Correct '_refresh_instance' method in OSDBInstance,MERGED,2014-12-09 13:22:17.000000000,2014-12-11 23:29:07.000000000,2014-12-11 23:29:05.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-09 13:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/33f32b5ad77335742f4f87b338d24b83c2cfd7e0', 'message': ""Correct '_refresh_instance' method in OSDBInstance\n\nChange-Id: I338e92d349bdf8fff13de81865bccb76016dae88\nCloses-Bud: #1400305\n""}, {'number': 2, 'created': '2014-12-09 13:27:49.000000000', 'files': ['heat/tests/test_os_database.py', 'heat/engine/resources/os_database.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/448cb7b69ebb3ed966ee84a9d30654a2f8387c73', 'message': ""Correct '_refresh_instance' method in OSDBInstance\n\nChange-Id: I338e92d349bdf8fff13de81865bccb76016dae88\nCloses-Bug: #1400305""}]",0,140325,448cb7b69ebb3ed966ee84a9d30654a2f8387c73,9,3,2,13323,,,0,"Correct '_refresh_instance' method in OSDBInstance

Change-Id: I338e92d349bdf8fff13de81865bccb76016dae88
Closes-Bug: #1400305",git fetch https://review.opendev.org/openstack/heat refs/changes/25/140325/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_os_database.py', 'heat/engine/resources/os_database.py']",2,33f32b5ad77335742f4f87b338d24b83c2cfd7e0,bug/1400305, instance = self.trove().instances.get(instance.id) return instance return instance instance = self._refresh_instance(instance) # get updated attributes, instance.get() self._refresh_instance(instance) # get updated attributes,47,23
openstack%2Fmonasca-thresh~master~I79b5fdac18598a4d082285057d7045c3f88c7a9a,openstack/monasca-thresh,master,I79b5fdac18598a4d082285057d7045c3f88c7a9a,Update the README and arch diagram for Alarmed Metrics,MERGED,2014-12-11 23:00:24.000000000,2014-12-11 23:28:48.000000000,2014-12-11 23:28:48.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-12-11 23:00:24.000000000', 'files': ['mon-thresh-architecture.png', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/ff975db6f3bea9e0686518a636c428137286dfff', 'message': 'Update the README and arch diagram for Alarmed Metrics\n\nChange-Id: I79b5fdac18598a4d082285057d7045c3f88c7a9a\n'}]",0,141201,ff975db6f3bea9e0686518a636c428137286dfff,6,2,1,11809,,,0,"Update the README and arch diagram for Alarmed Metrics

Change-Id: I79b5fdac18598a4d082285057d7045c3f88c7a9a
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/01/141201/1 && git format-patch -1 --stdout FETCH_HEAD,"['mon-thresh-architecture.png', 'README.md']",2,ff975db6f3bea9e0686518a636c428137286dfff,,"Computes thresholds on metrics and publishes alarms to Kafka when exceeded. The current state is also saved in the MySQL datbase. Alarms have three possible states: `UNDETERMINED`, `OK` and `ALARM`. Alarms are defined by an expression that comes from the Alarm Definition. For example: The flow of Metrics is MetricSpout to MetricFilteringBolt to MetricAggregationBolt. The MetricSpout reads metrics from Kakfa and sends them on through Storm. Metrics are routed to a specific MetricFilteringBolt based on a routing algorithm that computes a hash code like value based on the Metric Definition so a Metric with the same MetricDefinition is always routed to the same MetricFilteringBolt. The MetricFilteringBolt checks what Alarm Definitions this metric matches, if any. If it matches a new Alarm Definition, the MetricFilteringBolt first sends it to the AlarmCreationBolt. It thens sends the metric to the MetricAggregationBolts once for each matching ALarm Definition. The routing is done by the combination of metric name and tenant id to ensure the same MetricAggregationBolt gets the metric each time.The MetricAggregationBolt adds the Metric information to its total for each SubAlarms. Once a minute, the MetricAggregationBolts use the Aggregated Metrics to evaluate each Sub Alarms. If the state changes on the Sub Alarm, the state change is forwarded to the AlarmThresholdingBolts. The AlarmThresholdingBolts look at the entire Alarm Expression to evaluate the state of the Alarm. The AlarmCreationBolt looks at its incoming metrics and creates new Alarms as needed. It may also add the metric to an existing Alarm if it fits there. The metrics are routed to the AlarmCreationBolt by the AlarmDefinitionId. The AlarmCreationBolt forwards new SubAlarms to the MetricAggregationBolts when an Alarm is created.","Computes thresholds on metrics and publishes alarms to the MessageQ when exceeded.Alarms have three possible states: `UNDETERMINED`, `OK` and `ALARM`. Alarms are defined by an expression. For example: The flow of Metrics is MetricSpout to MetricFilteringBolt to MetricAggregationBolt. The MetricSpout reads from Kakfa and sends it on through Storm. Metrics are routed to a specific MetricFilteringBolt based on a routing algorithm that computes a hash code like value based on the Metric Definition so a Metric with the same MetricDefinition is always routed to the same MetricFilteringBolt. The MetricFilteringBolt looks up the Metric Definition and decides if it should be sent on to a MetricAggregationBolt using the same routing algorithm. The MetricAggregationBolt adds the Metric information to its total for each SubAlarms and once a minute evaluates each SubAlarm it has.Once a minute, the MetricAggregationBolts use the Aggregated Metrics to evaluate each Sub Alarms. If the state changes on the Sub Alarm, the state change is forwarded to the AlarmThresholdingBolts. The AlarmThresholdingBolts look at the entire Alarm Expression to evaluate the state of the Alarm.",9,4
openstack%2Fglance-specs~master~I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85,openstack/glance-specs,master,I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85,Adds Image service v1 and v2 specification info in general,MERGED,2014-10-17 19:51:45.000000000,2014-12-11 23:11:32.000000000,2014-12-11 23:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 8127}]","[{'number': 1, 'created': '2014-10-17 19:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/7bdcadd90fe6ba00c75309e5e7f44452f0952756', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 2, 'created': '2014-10-17 20:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d6e0726aa7384a974fd9230d089d036203a3ae40', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 3, 'created': '2014-10-17 20:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/bb3cb101d21a3af9e951efa790f3c3f9a1254320', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 4, 'created': '2014-10-17 20:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/1a3ab1e165a011ed32270a182462520a39d27626', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 5, 'created': '2014-10-17 22:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/ee3e99a8fecb3436aea5348a831f8448c7b4c6ba', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 6, 'created': '2014-10-17 23:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/4ebd6951071e312e2d3015a71746a9ad21d078c0', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 7, 'created': '2014-10-20 01:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/aa55f73b90aa21ed6babe6daf352d465d811cbaf', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 8, 'created': '2014-10-20 19:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/7f40c9e2902b0476379d844b1d5d81c4631309bc', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 9, 'created': '2014-10-20 19:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d83e4b1ca762ba8bee16804bb275b9ab39131782', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 10, 'created': '2014-10-20 19:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/7a5439f00265c12ec1aa55d4d1bf539a48a8eaf3', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 11, 'created': '2014-10-20 19:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d6e4098cb340aed0af533a88348e8d5dcfea6abf', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project and to eliminate the image-api repo.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}, {'number': 12, 'created': '2014-12-05 22:50:42.000000000', 'files': ['specs/api/v1/authentication.rst', 'specs/api/v2/image-binary-data-api-v2.rst', 'specs/api/v2/lists-image-api-v2.rst', '.gitignore', 'tests/test_titles.py', 'specs/template.rst', 'specs/api/v1/filtering_images_returned_via_get__images_and_get__images_detail.rst', 'specs/api/v2/image-api-v2.rst', 'specs/api/v1/adding_a_new_virtual_machine_image.rst', 'specs/api/v1/image_service_v1_api.rst', 'specs/api/v1/replacing_a_membership_list_for_an_image.rst', 'specs/api/v1/requesting_image_memberships.rst', 'specs/api/v1/requesting_detailed_metadata_on_public_vm_images.rst', 'specs/api/v2/delete-image-api-v2.rst', 'specs/api/v2/retrieve-image-api-v2.rst', 'specs/api/v1/retrieving_a_virtual_machine_image.rst', 'specs/api/v1/adding_a_member_to_an_image.rst', 'specs/api/v1/requesting_detailed_metadata_on_a_specific_image.rst', 'specs/api/v2/http-patch-image-api-v2.rst', 'specs/api/v1/requesting_shared_images.rst', 'specs/api/v2/sharing-image-api-v2.rst', 'doc/source/index.rst', 'specs/api/v1/removing_a_member_from_an_image.rst', 'specs/api/v2/image-metadata-api-v2.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/f46438ab1ce8d51781aee39ded2fe83b8b045490', 'message': 'Adds Image service v1 and v2 specification info in general\n\nGoal is to maintain API specs in the specs repo for each project\nand to eliminate the image-api repo.\n\nSplits up original v2 API document into multiple files.\n\nChange-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85\n'}]",1,129367,f46438ab1ce8d51781aee39ded2fe83b8b045490,31,5,12,964,,,0,"Adds Image service v1 and v2 specification info in general

Goal is to maintain API specs in the specs repo for each project
and to eliminate the image-api repo.

Splits up original v2 API document into multiple files.

Change-Id: I7b6fbb1ee4a9a2e04395a7aa942d9ebdb011cc85
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/67/129367/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/api/v1/authentication.rst', 'specs/api/v2/image-api-v2.0.rst', 'specs/api/v1/requesting_detailed_metadata_on_a_specific_image.rst', 'specs/api/v1/requesting_shared_images.rst', 'specs/api/v1/filtering_images_returned_via_get__images_and_get__images_detail.rst', 'specs/api/v1/adding_a_new_virtual_machine_image.rst', 'specs/api/v1/image_service_v1_api.rst', 'specs/api/v1/openstack_image_service_api_v1_reference.rst', 'specs/api/v1/replacing_a_membership_list_for_an_image.rst', 'specs/api/v1/requesting_image_memberships.rst', 'specs/api/v1/requesting_detailed_metadata_on_public_vm_images.rst', 'doc/source/index.rst', 'specs/api/v1/removing_a_member_from_an_image.rst', 'specs/api/v1/retrieving_a_virtual_machine_image.rst', 'specs/api/v1/adding_a_member_to_an_image.rst']",15,7bdcadd90fe6ba00c75309e5e7f44452f0952756,129367,"=========================== Adding a Member to an Image =========================== We want to authorize a tenant to access a private image. We issue a ``PUT`` request to ``http://glance.example.com/images/1/members/tenant1``. With no body, this will add the membership to the image, leaving existing memberships unmodified and defaulting new memberships to have \`can\_share\` set to \`false\`. We may also optionally attach a body of the following form: .. code:: literallayout {'member': {'can_share': true} } If such a body is provided, both existing and new memberships will have \`can\_share\` set to the provided value (either \`true\` or \`false\`). This query will return a 204 (""No Content"") status code. ",,1999,0
openstack%2Foslo-incubator~master~I16970ddf3f78fc844d8795c6a9428c7b9c23ae59,openstack/oslo-incubator,master,I16970ddf3f78fc844d8795c6a9428c7b9c23ae59,Port processutils to Python 3,ABANDONED,2014-11-27 11:15:22.000000000,2014-12-11 23:11:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 7491}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-11-27 11:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/77c88e7252acaa2583910aefd8fb0bb470a1547c', 'message': 'Port processutils to Python 3\n\nProcessExecutionError now decodes stdout and stderr to build the\nexception message. It avoids to see ""stdout: b\'...\'"" in the message (you\nget ""stdout: \'...\'"" instead).\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nTo have a full support of Python 3, you need also the following change\nfor strutils.mask_password() of oslo.utils, so mask_password(bytes)\nreturns bytes instead of unicode on Python 3:\nhttps://review.openstack.org/137600\n\nChange-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59\n'}, {'number': 2, 'created': '2014-11-27 12:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7fb44dd5b644e051d1572ace80a85b246d1bd658', 'message': 'Port processutils to Python 3\n\nProcessExecutionError now decodes stdout and stderr to build the\nexception message. It avoids to see ""stdout: b\'...\'"" in the message (you\nget ""stdout: \'...\'"" instead).\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nTo have a full support of Python 3, you need also the following change\nfor strutils.mask_password() of oslo.utils, so mask_password(bytes)\nreturns bytes instead of unicode on Python 3:\nhttps://review.openstack.org/137600\n\nChange-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59\n'}, {'number': 3, 'created': '2014-11-27 14:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f18695b1f03c03e7b497652dc34fb975770dbcec', 'message': 'Port processutils to Python 3\n\nProcessExecutionError now decodes stdout and stderr to build the\nexception message. It avoids to see ""stdout: b\'...\'"" in the message (you\nget ""stdout: \'...\'"" instead).\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nTo have a full support of Python 3, you need also the following change\nfor strutils.mask_password() of oslo.utils, so mask_password(bytes)\nreturns bytes instead of unicode on Python 3:\nhttps://review.openstack.org/137600\n\nChange-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59\n'}, {'number': 4, 'created': '2014-11-27 21:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/cd330388fe58217377f9fa8b80861322e4a7ef10', 'message': 'Port processutils to Python 3\n\nProcessExecutionError now decodes stdout and stderr to build the\nexception message. It avoids to see ""stdout: b\'...\'"" in the message (you\nget ""stdout: \'...\'"" instead).\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nThe mask_password() function is wrapped to return bytes strings when the\ninput message is a bytes string.\n\nChange-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59\n'}, {'number': 5, 'created': '2014-12-01 09:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f440b2df5851e68d61892e856eb6584cced6f058', 'message': ""Port processutils to Python 3\n\nAdd encoding and errors parameters to execute() and ssh_execute(). By\ndefault, use the locale encoding in strict mode on Python 2, or the\nlocale encoding with the 'surrogateescape' error handler on Python 3.\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nChange-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59\n""}, {'number': 6, 'created': '2014-12-01 09:15:39.000000000', 'files': ['tests/unit/test_processutils.py', 'openstack/common/processutils.py', 'test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/edce0fce3a87a723e2d936ec3334ab6ced7c67d5', 'message': ""Port processutils to Python 3\n\nAdd encoding and errors parameters to execute() and ssh_execute(). By\ndefault, use the locale encoding in strict mode on Python 2, or the\nlocale encoding with the 'surrogateescape' error handler on Python 3.\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nChange-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59\n""}]",6,137604,edce0fce3a87a723e2d936ec3334ab6ced7c67d5,37,7,6,9107,,,0,"Port processutils to Python 3

Add encoding and errors parameters to execute() and ssh_execute(). By
default, use the locale encoding in strict mode on Python 2, or the
locale encoding with the 'surrogateescape' error handler on Python 3.

Fix also unit tests to use bytes strings for stdin, stdout and stderr.

Change-Id: I16970ddf3f78fc844d8795c6a9428c7b9c23ae59
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/04/137604/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_processutils.py', 'openstack/common/processutils.py']",2,77c88e7252acaa2583910aefd8fb0bb470a1547c,processutils_py3,"import sys if six.PY3: data = {'description': description, 'cmd': cmd, 'exit_code': exit_code, 'stdout': os.fsdecode(stdout) if stdout is not None else None, 'stderr': os.fsdecode(stderr) if stderr is not None else None} else: data = {'description': description, 'cmd': cmd, 'exit_code': exit_code, 'stdout': stdout, 'stderr': stderr} 'Stderr: %(stderr)r') % data cmd = list(map(str, cmd))"," 'Stderr: %(stderr)r') % {'description': description, 'cmd': cmd, 'exit_code': exit_code, 'stdout': stdout, 'stderr': stderr} cmd = map(str, cmd)",20,11
openstack%2Fhorizon~master~I4c79550b9c36da325d384f08b45dce0bca69a148,openstack/horizon,master,I4c79550b9c36da325d384f08b45dce0bca69a148,[Sahara] Do not request for nodegroup template if not present,MERGED,2014-11-22 00:35:39.000000000,2014-12-11 22:50:48.000000000,2014-12-11 22:50:46.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 2750}, {'_account_id': 7132}, {'_account_id': 8411}, {'_account_id': 9622}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-11-22 00:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/97dc9f676b21643af1e7095c4dffdff9c92c5fff', 'message': '[Sahara] Do not request for nodegroup template if not present\n\nThere is no sense in API call to Sahara about nodegroup template\ninformation in case if node group was created without template.\n\nChange-Id: I4c79550b9c36da325d384f08b45dce0bca69a148\nCloses-Bug: #1389868\n'}, {'number': 2, 'created': '2014-11-24 23:11:11.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/clusters/tabs.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b7cee5d9e7c0de94135b9be97d4143e40de8b8dd', 'message': '[Sahara] Do not request for nodegroup template if not present\n\nThere is no sense in API call to Sahara about nodegroup template\ninformation in case if node group was created without template.\n\nChange-Id: I4c79550b9c36da325d384f08b45dce0bca69a148\nCloses-Bug: #1389868\n'}]",4,136539,b7cee5d9e7c0de94135b9be97d4143e40de8b8dd,18,8,2,8411,,,0,"[Sahara] Do not request for nodegroup template if not present

There is no sense in API call to Sahara about nodegroup template
information in case if node group was created without template.

Change-Id: I4c79550b9c36da325d384f08b45dce0bca69a148
Closes-Bug: #1389868
",git fetch https://review.opendev.org/openstack/horizon refs/changes/39/136539/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/data_processing/clusters/tabs.py'],1,97dc9f676b21643af1e7095c4dffdff9c92c5fff,bug/1389868," if ng.get(""node_group_template_id"", None): ng[""node_group_template""] = helpers.safe_call( sahara.node_group_templates.get, ng.get(""node_group_template_id"", None))"," ng[""node_group_template""] = helpers.safe_call( sahara.node_group_templates.get, ng.get(""node_group_template_id"", None))",4,3
openstack%2Fmistral~master~Ie78273854d8bcbca5033266f98ce53e7544dd61f,openstack/mistral,master,Ie78273854d8bcbca5033266f98ce53e7544dd61f,Add test case for dataflow to test action input,MERGED,2014-12-10 23:26:57.000000000,2014-12-11 22:42:23.000000000,2014-12-11 22:42:23.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 14272}]","[{'number': 1, 'created': '2014-12-10 23:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/21f6e5539bf822bd9e03ca0546c45bf0af1aaa71', 'message': 'Add test case for dataflow to test action input\n\n  Closes-Bug: 1396461\n\n  Description:\n\n    * Action input specified inline should work with dots.\n      For example, action: std.echo output=""{$.farewell}.Amigo""\n    * Added test case for the above in dataflow tests.\n\nChange-Id: Ie78273854d8bcbca5033266f98ce53e7544dd61f\n'}, {'number': 2, 'created': '2014-12-10 23:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/eda235b438b5090791fa344fcb2849f3b1debaa8', 'message': 'Add test case for dataflow to test action input\n\n  Closes-Bug: 1396461\n\n  Description:\n\n    * Action input specified inline should work with dots.\n      For example, action: std.echo output=""{$.farewell}.Amigo""\n    * Added test case for the above in dataflow tests.\n\nChange-Id: Ie78273854d8bcbca5033266f98ce53e7544dd61f\n'}, {'number': 3, 'created': '2014-12-11 00:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d8b4c9bb8f7b4b092b28e134d211ac010c9fa9bb', 'message': 'Add test case for dataflow to test action input\n\n  Closes-Bug: 1396461\n\n  Description:\n\n    * Action input specified inline should work with dots.\n      For example, action: std.echo output=""{$.farewell}.Amigo""\n    * Amended test case in dataflow tests to account for above.\n\nChange-Id: Ie78273854d8bcbca5033266f98ce53e7544dd61f\n'}, {'number': 4, 'created': '2014-12-11 00:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/19eb76f31517be3e4e1018357bbc864c5a4f1f60', 'message': 'Add test case for dataflow to test action input\n\n  Closes-Bug: 1396461\n\n  Description:\n\n    * Action input specified inline should work with dots.\n      For example, action: std.echo output=""{$.farewell}.Amigo""\n    * Amended test case in dataflow tests to account for above.\n\nChange-Id: Ie78273854d8bcbca5033266f98ce53e7544dd61f\n'}, {'number': 5, 'created': '2014-12-11 22:12:18.000000000', 'files': ['mistral/tests/unit/engine1/test_dataflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/d8e4f1b95befb7ee1069a4a13b196c4c2a95c10a', 'message': 'Add test case for dataflow to test action input\n\n  Closes-Bug: 1396461\n\n  Description:\n\n    * Action input specified inline should work with dots.\n      For example, action: std.echo output=""{$.farewell}.Amigo""\n    * Amended test case in dataflow tests to account for above.\n\nChange-Id: Ie78273854d8bcbca5033266f98ce53e7544dd61f\n'}]",2,140865,d8e4f1b95befb7ee1069a4a13b196c4c2a95c10a,26,7,5,14272,,,0,"Add test case for dataflow to test action input

  Closes-Bug: 1396461

  Description:

    * Action input specified inline should work with dots.
      For example, action: std.echo output=""{$.farewell}.Amigo""
    * Amended test case in dataflow tests to account for above.

Change-Id: Ie78273854d8bcbca5033266f98ce53e7544dd61f
",git fetch https://review.opendev.org/openstack/mistral refs/changes/65/140865/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/tests/unit/engine1/test_dataflow.py'],1,21f6e5539bf822bd9e03ca0546c45bf0af1aaa71,bug/1396461," wf2: type: direct input: - param1 tasks: task1: action: std.echo output=""{$.param1}"" publish: result1: $ on-success: - task2 task2: action: std.echo output=""{$.result1}.Hola"" publish: result2: $ def setUp(self): super(DataFlowEngineTest, self).setUp() def test_trivial_dataflow(self): def test_dataflow_dot_in_action_input_inline(self): """""" Validate that a dot in action input specified inline doesn't blow up. """""" # Start workflow. exec_db = self.engine.start_workflow('wb.wf2', {'param1': ""Amigos""}) self._await( lambda: self.is_execution_success(exec_db.id), ) # Note: We need to reread execution to access related tasks. exec_db = db_api.get_execution(exec_db.id) self.assertEqual(states.SUCCESS, exec_db.state) tasks = exec_db.tasks task2 = self._assert_single_item(tasks, name='task2') self.assertEqual(states.SUCCESS, task2.state) self.assertDictEqual( { 'task': { 'task2': {'result2': 'Amigos.Hola'}, }, 'result2': 'Amigos.Hola', }, task2.output ) def tearDown(self): super(DataFlowEngineTest, self).tearDown() # XXX: Remove the workbook artifacts from db. # XXX: wb_service doesn't have remove_workbook_v2(WORKBOOK) pass", def test_trivial_dataflow(self):,61,1
openstack%2Fpuppet-monasca~master~I80b222fd9570fbc9930a9b8dc3906d7f4f6d5768,openstack/puppet-monasca,master,I80b222fd9570fbc9930a9b8dc3906d7f4f6d5768,Fixed admin_name and password for api template,MERGED,2014-12-11 21:50:28.000000000,2014-12-11 22:35:53.000000000,2014-12-11 22:35:53.000000000,"[{'_account_id': 3}, {'_account_id': 8126}]","[{'number': 1, 'created': '2014-12-11 21:50:28.000000000', 'files': ['manifests/api.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/557c2f87b80a8394fc90dca01fa296f2177e2a11', 'message': 'Fixed admin_name and password for api template\n\nChange-Id: I80b222fd9570fbc9930a9b8dc3906d7f4f6d5768\n'}]",0,141179,557c2f87b80a8394fc90dca01fa296f2177e2a11,6,2,1,11155,,,0,"Fixed admin_name and password for api template

Change-Id: I80b222fd9570fbc9930a9b8dc3906d7f4f6d5768
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/79/141179/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/api.pp'],1,557c2f87b80a8394fc90dca01fa296f2177e2a11,, $admin_password = $::monasca::params::admin_password $admin_name = $::monasca::params::admin_name, $admin_password = ::monasca::params::admin_password $admin_name = ::monasca::params::admin_name,2,2
openstack%2Fopenstack-ansible~master~Ib707d7462e5e444dddceff105b219263d0283e0c,openstack/openstack-ansible,master,Ib707d7462e5e444dddceff105b219263d0283e0c,Correctly pipe the sshd check to /dev/null,MERGED,2014-12-11 15:21:40.000000000,2014-12-11 22:30:39.000000000,2014-12-11 22:30:38.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-11 15:21:40.000000000', 'files': ['scripts/os-ansible-aio-check.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6c7e170d98031e3da15a4b57c761cd702bdda23d', 'message': ""Correctly pipe the sshd check to /dev/null\n\nThis patch corrects the pipe of the sshd configuration check to\n/dev/null. The script therefore no longer leaves a file called 'null'\nbehind on the deployment host.\n\nChange-Id: Ib707d7462e5e444dddceff105b219263d0283e0c\nCloses-Bug: #1401567\n""}]",0,141068,6c7e170d98031e3da15a4b57c761cd702bdda23d,8,4,1,6816,,,0,"Correctly pipe the sshd check to /dev/null

This patch corrects the pipe of the sshd configuration check to
/dev/null. The script therefore no longer leaves a file called 'null'
behind on the deployment host.

Change-Id: Ib707d7462e5e444dddceff105b219263d0283e0c
Closes-Bug: #1401567
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/68/141068/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/os-ansible-aio-check.sh'],1,6c7e170d98031e3da15a4b57c761cd702bdda23d,bug/1401567,"if grep ""^PermitRootLogin"" /etc/ssh/sshd_config > /dev/null; then","if grep ""^PermitRootLogin"" /etc/ssh/sshd_config > null; then",1,1
openstack%2Fpython-keystoneclient~master~Icf700c30d01e0700e437437a23e63a7f100ce4d3,openstack/python-keystoneclient,master,Icf700c30d01e0700e437437a23e63a7f100ce4d3,Expose version matching functions to the public,MERGED,2014-10-21 15:20:43.000000000,2014-12-11 22:29:25.000000000,2014-12-11 22:29:24.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 9101}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-10-21 15:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ec119aebcd262d9dc1fcf6440e62d0c04ad25501', 'message': ""Expose version matching functions to the public\n\nThe functions to match a version or convert a string version number into\na tuple have shown to be useful in at least auth_token middleware. I\nthink this is also better as _discover should really only be a shadow\nfor the discover file because of the circular dependency problems.\n_discover shouldn't really need to be used even within client.\n\nChange-Id: Icf700c30d01e0700e437437a23e63a7f100ce4d3\n""}, {'number': 2, 'created': '2014-12-03 02:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a79df3a2bc0103f3ea7692d96ef32f9aa5e63c25', 'message': ""Expose version matching functions to the public\n\nThe functions to match a version or convert a string version number into\na tuple have shown to be useful in at least auth_token middleware. I\nthink this is also better as _discover should really only be a shadow\nfor the discover file because of the circular dependency problems.\n_discover shouldn't really need to be used even within client.\n\nChange-Id: Icf700c30d01e0700e437437a23e63a7f100ce4d3\n""}, {'number': 3, 'created': '2014-12-10 06:15:47.000000000', 'files': ['keystoneclient/auth/identity/generic/password.py', 'keystoneclient/discover.py', 'keystoneclient/auth/identity/generic/token.py', 'keystoneclient/auth/identity/generic/base.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ff1c0e1347ddb3f07103c238b642f78780f80022', 'message': ""Expose version matching functions to the public\n\nThe functions to match a version or convert a string version number into\na tuple have shown to be useful in at least auth_token middleware. I\nthink this is also better as _discover should really only be a shadow\nfor the discover file because of the circular dependency problems.\n_discover shouldn't really need to be used even within client.\n\nCloses-Bug: #1400998\nChange-Id: Icf700c30d01e0700e437437a23e63a7f100ce4d3\n""}]",3,129935,ff1c0e1347ddb3f07103c238b642f78780f80022,22,9,3,7191,,,0,"Expose version matching functions to the public

The functions to match a version or convert a string version number into
a tuple have shown to be useful in at least auth_token middleware. I
think this is also better as _discover should really only be a shadow
for the discover file because of the circular dependency problems.
_discover shouldn't really need to be used even within client.

Closes-Bug: #1400998
Change-Id: Icf700c30d01e0700e437437a23e63a7f100ce4d3
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/35/129935/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/auth/identity/generic/password.py', 'keystoneclient/discover.py', 'keystoneclient/auth/identity/generic/token.py', 'keystoneclient/auth/identity/generic/base.py']",4,ec119aebcd262d9dc1fcf6440e62d0c04ad25501,expose_discover_functions,"from keystoneclient import discover if (discover.version_match((2,), version) and","from keystoneclient import _discover if (_discover.version_match((2,), version) and",13,8
openstack%2Fpuppet-monasca~master~I0866b9924a6c8d4c1fdc88761a1faf552de0e862,openstack/puppet-monasca,master,I0866b9924a6c8d4c1fdc88761a1faf552de0e862,Update storm mirror and version (to 0.9.3),ABANDONED,2014-12-10 21:05:54.000000000,2014-12-11 22:14:53.000000000,,"[{'_account_id': 3}, {'_account_id': 8126}, {'_account_id': 9500}, {'_account_id': 11155}]","[{'number': 1, 'created': '2014-12-10 21:05:54.000000000', 'files': ['manifests/storm/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/92f2148f646f131825892e241544f8f21b768669', 'message': 'Update storm mirror and version (to 0.9.3)\n\nChange-Id: I0866b9924a6c8d4c1fdc88761a1faf552de0e862\n'}]",0,140836,92f2148f646f131825892e241544f8f21b768669,5,4,1,8126,,,0,"Update storm mirror and version (to 0.9.3)

Change-Id: I0866b9924a6c8d4c1fdc88761a1faf552de0e862
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/36/140836/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/storm/config.pp'],1,92f2148f646f131825892e241544f8f21b768669,feature/update_storm_mirror," $storm_version = 'apache-storm-0.9.3', $mirror = 'http://apache.arvixe.com/storm',"," $storm_version = 'apache-storm-0.9.2-incubating', $mirror = 'http://mirror.cogentco.com/pub/apache/incubator/storm',",2,2
openstack%2Fneutron~master~I4002e96b5aea9375346ac1d13e756e5ee5494ead,openstack/neutron,master,I4002e96b5aea9375346ac1d13e756e5ee5494ead,Mock resource attribute dicts in tests,ABANDONED,2014-03-08 11:58:58.000000000,2014-12-11 22:07:29.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-03-08 11:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/353cc3ff8c4b760ec485e2c1256017cad184d7ce', 'message': 'Mock resource attribute dicts in tests\n\nPreviously, setup for neutron unit tests might include saving a copy\nof resource attribute dicts so that they could be restored to a\npristine state on teardown.  This patch adds a helper method on the\nbase test class that uses mock.patch.dict() to accomplish the same\ngoal more cleanly, and ensures that test classes only mock if their\nparent classes have not yet done so.\n\nChange-Id: I4002e96b5aea9375346ac1d13e756e5ee5494ead\n'}, {'number': 2, 'created': '2014-03-22 06:31:59.000000000', 'files': ['neutron/tests/unit/test_quota_ext.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/tests/unit/vmware/extensions/test_networkgw.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/tests/unit/nec/test_security_group.py', 'neutron/tests/unit/test_extension_extended_attribute.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/test_policy.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/test_extension_pnet.py', 'neutron/tests/unit/test_api_v2_extension.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/tests/unit/test_agent_ext_plugin.py', 'neutron/tests/unit/mlnx/test_mlnx_security_group.py', 'neutron/tests/base.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/tests/unit/linuxbridge/test_lb_security_group.py', 'neutron/tests/unit/vmware/extensions/test_maclearning.py', 'neutron/tests/unit/ml2/test_security_group.py', 'neutron/tests/unit/oneconvergence/test_security_group.py', 'neutron/tests/unit/test_api_v2.py', 'neutron/tests/unit/ryu/test_ryu_security_group.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/813ce77ca8d92cb4273e4715a7bef32c4da5f581', 'message': 'Mock resource attribute dicts in tests\n\nPreviously, setup for neutron unit tests might include saving a copy\nof resource attribute dicts so that they could be restored to a\npristine state on teardown.  This patch adds a helper method on the\nbase test class that uses mock.patch.dict() to accomplish the same\ngoal more cleanly, and ensures that test classes only mock if their\nparent classes have not yet done so.\n\nChange-Id: I4002e96b5aea9375346ac1d13e756e5ee5494ead\n'}]",0,79141,813ce77ca8d92cb4273e4715a7bef32c4da5f581,65,15,2,2035,,,0,"Mock resource attribute dicts in tests

Previously, setup for neutron unit tests might include saving a copy
of resource attribute dicts so that they could be restored to a
pristine state on teardown.  This patch adds a helper method on the
base test class that uses mock.patch.dict() to accomplish the same
goal more cleanly, and ensures that test classes only mock if their
parent classes have not yet done so.

Change-Id: I4002e96b5aea9375346ac1d13e756e5ee5494ead
",git fetch https://review.opendev.org/openstack/neutron refs/changes/41/79141/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_quota_ext.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'neutron/tests/unit/nec/test_security_group.py', 'neutron/tests/unit/test_extension_extended_attribute.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/test_extension_pnet.py', 'neutron/tests/unit/test_api_v2_extension.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/tests/unit/test_agent_ext_plugin.py', 'neutron/tests/unit/mlnx/test_mlnx_security_group.py', 'neutron/tests/base.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/tests/unit/linuxbridge/test_lb_security_group.py', 'neutron/tests/unit/vmware/extensions/test_maclearning.py', 'neutron/tests/unit/ml2/test_security_group.py', 'neutron/tests/unit/test_api_v2.py', 'neutron/tests/unit/ryu/test_ryu_security_group.py']",24,353cc3ff8c4b760ec485e2c1256017cad184d7ce,79141,," self._attribute_map_bk_ = {} for item in attributes.RESOURCE_ATTRIBUTE_MAP: self._attribute_map_bk_[item] = (attributes. RESOURCE_ATTRIBUTE_MAP[item]. copy()) def tearDown(self): super(RyuSecurityGroupsTestCase, self).tearDown() attributes.RESOURCE_ATTRIBUTE_MAP = self._attribute_map_bk_ ",43,259
openstack%2Fheat-templates~master~I497f2d2286025e48e42691bfe178fc9c491928ea,openstack/heat-templates,master,I497f2d2286025e48e42691bfe178fc9c491928ea,heat-config-puppet: support hiera,MERGED,2014-12-02 20:45:30.000000000,2014-12-11 22:05:31.000000000,2014-12-11 22:05:30.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6554}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-02 20:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/42ccf1213121e60f6582b7497a43f9a63a47e755', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 2, 'created': '2014-12-02 21:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/6aceb8d04b2bd37183e2c544249c862076c3131e', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 3, 'created': '2014-12-03 19:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/f7aac8f8e644aba0a8fe6af7ac61f9e404998596', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing Facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 4, 'created': '2014-12-03 19:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/c52dd76fe70844fe82828fdabe8f437d14a64f08', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing Facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 5, 'created': '2014-12-04 02:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/1f0d79419f98d982c20551e2bd03a2034fb999da', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing Facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 6, 'created': '2014-12-04 17:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/584a18333db433558a03effb761f979f7fe1f8c1', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing Facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 7, 'created': '2014-12-09 18:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/5ee7e61f02f02dc93efc39d2efb7135afb769f95', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing Facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}, {'number': 8, 'created': '2014-12-11 20:29:46.000000000', 'files': ['hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py', 'tests/software_config/test_hook_puppet.py', 'hot/software-config/elements/heat-config-puppet/README.rst'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/94bd31e45e82e199239d1300b4a425c1cd14a2fb', 'message': ""heat-config-puppet: support hiera\n\nUpdates the puppet hook so that we support using Hiera in addition\nto the existing Facter based input mechanism. Hiera provides\na more flexible way of dealing with puppet parameters and\nseems to be prefered in the Puppet community as well.\n\nUse of the Hiera data will also require an additional\n'hiera' element which will probably live in the\ntriple-puppet-elements tree.\n\nChange-Id: I497f2d2286025e48e42691bfe178fc9c491928ea\n""}]",15,138532,94bd31e45e82e199239d1300b4a425c1cd14a2fb,33,7,8,360,,,0,"heat-config-puppet: support hiera

Updates the puppet hook so that we support using Hiera in addition
to the existing Facter based input mechanism. Hiera provides
a more flexible way of dealing with puppet parameters and
seems to be prefered in the Puppet community as well.

Use of the Hiera data will also require an additional
'hiera' element which will probably live in the
triple-puppet-elements tree.

Change-Id: I497f2d2286025e48e42691bfe178fc9c491928ea
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/32/138532/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config-puppet/install.d/hook-puppet.py', 'hot/software-config/elements/heat-config-puppet/README.rst']",2,42ccf1213121e60f6582b7497a43f9a63a47e755,puppet_hiera,"Config inputs are passed in as facts, and output values are read from written-out files. A Puppet Hiera YAML datafile is written out to /etc/puppet/hieradata/heat.yaml which may optionally be used instead of facts within puppet manifests. ","Config inputs are passed in as facts, and output values are read from written-out files.",19,7
openstack%2Frally~master~Ia3c26afec69db53ae131fe2f326a7db2d172c3ae,openstack/rally,master,Ia3c26afec69db53ae131fe2f326a7db2d172c3ae,Fix nested snapshot job,MERGED,2014-12-10 11:23:15.000000000,2014-12-11 21:46:20.000000000,2014-12-11 21:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-12-10 11:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/784970ab458bd13259e8e63a71384149634f3ad9', 'message': 'Fix nested snapshot job: add sla section\n\nChange-Id: Ia3c26afec69db53ae131fe2f326a7db2d172c3ae\n'}, {'number': 2, 'created': '2014-12-10 12:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2c5f8c7368d58160e8683eb6cacce7cec34245d5', 'message': 'Fix nested snapshot job\n\nAdd sla section, change max volume size,\ntimes and concurrency\n\nChange-Id: Ia3c26afec69db53ae131fe2f326a7db2d172c3ae\n'}, {'number': 3, 'created': '2014-12-11 09:00:29.000000000', 'files': ['rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/b020890a7d20512e0fbcc7262d04e0107c836b1c', 'message': 'Fix nested snapshot job\n\nAdd sla section, change max volume size,\ntimes and concurrency\n\nChange-Id: Ia3c26afec69db53ae131fe2f326a7db2d172c3ae\n'}]",1,140646,b020890a7d20512e0fbcc7262d04e0107c836b1c,18,4,3,13636,,,0,"Fix nested snapshot job

Add sla section, change max volume size,
times and concurrency

Change-Id: Ia3c26afec69db53ae131fe2f326a7db2d172c3ae
",git fetch https://review.opendev.org/openstack/rally refs/changes/46/140646/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-jobs/rally.yaml'],1,784970ab458bd13259e8e63a71384149634f3ad9,nested-snapshots, sla: failure_rate: max: 0,,3,1
openstack%2Fpuppet-monasca~master~Idc53584c1f4c408dd6624d9feb2f32bf042f0b57,openstack/puppet-monasca,master,Idc53584c1f4c408dd6624d9feb2f32bf042f0b57,Refactor to clean up duplicate resources and vars,MERGED,2014-12-11 19:38:30.000000000,2014-12-11 21:31:36.000000000,2014-12-11 21:31:36.000000000,"[{'_account_id': 3}, {'_account_id': 8126}]","[{'number': 1, 'created': '2014-12-11 19:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/4e1da1d59b4719cc115b8518c5691b65ebd4fedf', 'message': 'Refactor to clean up duplicate resources and vars\n\nChange-Id: Idc53584c1f4c408dd6624d9feb2f32bf042f0b57\n'}, {'number': 2, 'created': '2014-12-11 20:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/95fb101c82dede2d01b2f4ecd135e37c4dfd70c6', 'message': 'Refactor to clean up duplicate resources and vars\n\nChange-Id: Idc53584c1f4c408dd6624d9feb2f32bf042f0b57\n'}, {'number': 3, 'created': '2014-12-11 20:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/e4dd5944082d927a13b3f3d67f6a3102aa73d46c', 'message': 'Refactor to clean up duplicate resources and vars\n\nChange-Id: Idc53584c1f4c408dd6624d9feb2f32bf042f0b57\n'}, {'number': 4, 'created': '2014-12-11 21:24:52.000000000', 'files': ['manifests/storm/config.pp', 'templates/api-config.yml.erb', 'manifests/storm/startup_script.pp', 'manifests/thresh.pp', 'manifests/persister.pp', 'manifests/api.pp', 'manifests/init.pp', 'manifests/apiserver.pp', 'manifests/db/mysql.pp', 'manifests/apiserver/config.pp', 'manifests/agent.pp', 'manifests/params.pp', 'manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/13888f568a8d49ec050f414c509e9cc2f8a46973', 'message': 'Refactor to clean up duplicate resources and vars\n\nChange-Id: Idc53584c1f4c408dd6624d9feb2f32bf042f0b57\n'}]",0,141141,13888f568a8d49ec050f414c509e9cc2f8a46973,13,2,4,11155,,,0,"Refactor to clean up duplicate resources and vars

Change-Id: Idc53584c1f4c408dd6624d9feb2f32bf042f0b57
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/41/141141/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/api-config.yml.erb', 'manifests/storm/startup_script.pp', 'manifests/thresh.pp', 'manifests/persister.pp', 'manifests/api.pp', 'manifests/init.pp', 'manifests/apiserver.pp', 'manifests/db/mysql.pp', 'manifests/apiserver/config.pp', 'manifests/agent.pp', 'manifests/params.pp', 'manifests/keystone/auth.pp']",12,4e1da1d59b4719cc115b8518c5691b65ebd4fedf,refactor,"# [*auth_name*] # Username for Monasca service. Optional. Defaults to 'monasca'. # # [*admin_name*] # Username for Monasca admin service. Optional. Defaults to 'monasca-admin'. # # [*agent_name*] # Username for Monasca agent service. Optional. Defaults to 'monasca-agent'.# Password for Monasca admin user. Required.# Password for Monasca agent user. Required. $auth_name = 'monasca', $admin_email = 'monasca@localhost', $agent_email = 'monasca@localhost', $configure_user = true, $configure_user_role = true, $service_name = undef, $service_type = 'monitoring', $public_address = '127.0.0.1', $admin_address = '127.0.0.1', $internal_address = '127.0.0.1', $tenant = 'services', $public_protocol = 'http', $admin_protocol = 'http', $internal_protocol = 'http', $configure_endpoint = true, $public_url = undef, $admin_url = undef, $internal_url = undef, ) { include monasca::params $admin_name = $::monasca::params::admin_name $agent_name = $::monasca::params::agent_name $admin_password = $::monasca::params::admin_password $agent_password = $::monasca::params::agent_password $port = $::monasca::params::port $region = $::monasca::params::region keystone_user { $admin_name: keystone_user { $agent_name: Keystone_user_role[""${admin_name}@${tenant}""] ~> Keystone_user_role[""${agent_name}@${tenant}""] ~> keystone_user_role { ""${agent_name}@${tenant}"":","# Password for Monasca admin user. Required.# Password for Monasca agent user. Required.# [*auth_name*] # Username for Monasca service. Optional. Defaults to 'monasca'. # # [*admin_auth_name*] # Username for Monasca admin service. Optional. Defaults to 'monasca'. # # [*agent_auth_name*] # Username for Monasca agent service. Optional. Defaults to 'monasca'. # $admin_password = false, $agent_password = false, $admin_email = 'monasca@localhost', $agent_email = 'monasca@localhost', $auth_name = 'monasca', $admin_auth_name = undef, $agent_auth_name = undef, $configure_user = true, $configure_user_role = true, $service_name = undef, $service_type = 'monitoring', $public_address = '127.0.0.1', $admin_address = '127.0.0.1', $internal_address = '127.0.0.1', $port = '8082', $region = 'RegionOne', $tenant = 'services', $public_protocol = 'http', $admin_protocol = 'http', $internal_protocol = 'http', $configure_endpoint = true, $public_url = undef, $admin_url = undef, $internal_url = undef, ) { validate_string($admin_password) validate_string($agent_password) if $admin_auth_name { $admin_auth_name_real = $admin_auth_name } else { $admin_auth_name_real = ""${auth_name}-admin"" } if $agent_auth_name { $agent_auth_name_real = $agent_auth_name } else { $agent_auth_name_real = ""${auth_name}-agent"" } keystone_user { $admin_auth_name_real: keystone_user { $agent_auth_name_real: Keystone_user_role[""${admin_auth_name_real}@${tenant}""] ~> Keystone_user_role[""${agent_auth_name_real}@${tenant}""] ~> keystone_user_role { ""${agent_auth_name_real}@${tenant}"":",290,291
openstack%2Fdiskimage-builder~master~Ib31b369a94c33fb7508f0539c2b2f14177e507e0,openstack/diskimage-builder,master,Ib31b369a94c33fb7508f0539c2b2f14177e507e0,Use env python,MERGED,2014-12-08 21:46:12.000000000,2014-12-11 21:26:04.000000000,2014-12-11 21:26:03.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 8399}, {'_account_id': 8532}, {'_account_id': 12459}]","[{'number': 1, 'created': '2014-12-08 21:46:12.000000000', 'files': ['bin/element-info'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fc862f460c6b43732d1e204d4b603add56f765a4', 'message': ""Use env python\n\nChange the shebang from /usr/bin/python to /usr/bin/env python\nSome users, especially on older systems don't use the python\nsupplied with the OS. This has an impact with module loading if\nthe python in /usr/bin is 2.6, and user wants to use 2.7\nin /usr/local/bin, for example\n\nChange-Id: Ib31b369a94c33fb7508f0539c2b2f14177e507e0\n""}]",0,140154,fc862f460c6b43732d1e204d4b603add56f765a4,10,5,1,12092,,,0,"Use env python

Change the shebang from /usr/bin/python to /usr/bin/env python
Some users, especially on older systems don't use the python
supplied with the OS. This has an impact with module loading if
the python in /usr/bin is 2.6, and user wants to use 2.7
in /usr/local/bin, for example

Change-Id: Ib31b369a94c33fb7508f0539c2b2f14177e507e0
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/54/140154/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/element-info'],1,fc862f460c6b43732d1e204d4b603add56f765a4,env-python,#!/usr/bin/env python,#!/usr/bin/python,1,1
openstack%2Fglance~master~I3c0441bcffffe671cf974dc7af14cbac66709d85,openstack/glance,master,I3c0441bcffffe671cf974dc7af14cbac66709d85,Remove openstack.common.gettextutils module,MERGED,2014-11-27 13:14:17.000000000,2014-12-11 21:25:27.000000000,2014-12-11 21:25:26.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6484}, {'_account_id': 8158}, {'_account_id': 11391}]","[{'number': 1, 'created': '2014-11-27 13:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/12d71e898fd837c049e89fd8fedb2f29ce869eb6', 'message': 'Remove openstack.common.gettextutils module\n\nRemove obsolete module from glance.\n\nWith the dependent change I84511ab1ee600e618985448dfbfbdc26cb130370,\nGlance do not use obsolete modules from oslo-incubator anymore.\n\nCloses bug: #1381870\nChange-Id: I3c0441bcffffe671cf974dc7af14cbac66709d85\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-12-09 19:57:36.000000000', 'files': ['openstack-common.conf', 'glance/openstack/common/gettextutils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/36d46bb0b1b0d7b7904c514356c05e99e257d63a', 'message': 'Remove openstack.common.gettextutils module\n\nRemove obsolete module from glance.\n\nWith the dependent change I84511ab1ee600e618985448dfbfbdc26cb130370,\nGlance do not use obsolete modules from oslo-incubator anymore.\n\nCloses bug: #1381870\nChange-Id: I3c0441bcffffe671cf974dc7af14cbac66709d85\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}]",0,137631,36d46bb0b1b0d7b7904c514356c05e99e257d63a,11,5,2,6549,,,0,"Remove openstack.common.gettextutils module

Remove obsolete module from glance.

With the dependent change I84511ab1ee600e618985448dfbfbdc26cb130370,
Glance do not use obsolete modules from oslo-incubator anymore.

Closes bug: #1381870
Change-Id: I3c0441bcffffe671cf974dc7af14cbac66709d85
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>",git fetch https://review.opendev.org/openstack/glance refs/changes/31/137631/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-common.conf', 'glance/openstack/common/gettextutils.py']",2,12d71e898fd837c049e89fd8fedb2f29ce869eb6,,,"# Copyright 2012 Red Hat, Inc. # Copyright 2013 IBM Corp. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" gettext for openstack-common modules. Usual usage in an openstack.common module: from glance.openstack.common.gettextutils import _ """""" import copy import functools import gettext import locale from logging import handlers import os from babel import localedata import six _AVAILABLE_LANGUAGES = {} # FIXME(dhellmann): Remove this when moving to oslo.i18n. USE_LAZY = False class TranslatorFactory(object): """"""Create translator functions """""" def __init__(self, domain, lazy=False, localedir=None): """"""Establish a set of translation functions for the domain. :param domain: Name of translation domain, specifying a message catalog. :type domain: str :param lazy: Delays translation until a message is emitted. Defaults to False. :type lazy: Boolean :param localedir: Directory with translation catalogs. :type localedir: str """""" self.domain = domain self.lazy = lazy if localedir is None: localedir = os.environ.get(domain.upper() + '_LOCALEDIR') self.localedir = localedir def _make_translation_func(self, domain=None): """"""Return a new translation function ready for use. Takes into account whether or not lazy translation is being done. The domain can be specified to override the default from the factory, but the localedir from the factory is always used because we assume the log-level translation catalogs are installed in the same directory as the main application catalog. """""" if domain is None: domain = self.domain if self.lazy: return functools.partial(Message, domain=domain) t = gettext.translation( domain, localedir=self.localedir, fallback=True, ) if six.PY3: return t.gettext return t.ugettext @property def primary(self): ""The default translation function."" return self._make_translation_func() def _make_log_translation_func(self, level): return self._make_translation_func(self.domain + '-log-' + level) @property def log_info(self): ""Translate info-level log messages."" return self._make_log_translation_func('info') @property def log_warning(self): ""Translate warning-level log messages."" return self._make_log_translation_func('warning') @property def log_error(self): ""Translate error-level log messages."" return self._make_log_translation_func('error') @property def log_critical(self): ""Translate critical-level log messages."" return self._make_log_translation_func('critical') # NOTE(dhellmann): When this module moves out of the incubator into # oslo.i18n, these global variables can be moved to an integration # module within each application. # Create the global translation functions. _translators = TranslatorFactory('glance') # The primary translation function using the well-known name ""_"" _ = _translators.primary # Translators for log levels. # # The abbreviated names are meant to reflect the usual use of a short # name like '_'. The ""L"" is for ""log"" and the other letter comes from # the level. _LI = _translators.log_info _LW = _translators.log_warning _LE = _translators.log_error _LC = _translators.log_critical # NOTE(dhellmann): End of globals that will move to the application's # integration module. def enable_lazy(): """"""Convenience function for configuring _() to use lazy gettext Call this at the start of execution to enable the gettextutils._ function to use lazy gettext functionality. This is useful if your project is importing _ directly instead of using the gettextutils.install() way of importing the _ function. """""" # FIXME(dhellmann): This function will be removed in oslo.i18n, # because the TranslatorFactory makes it superfluous. global _, _LI, _LW, _LE, _LC, USE_LAZY tf = TranslatorFactory('glance', lazy=True) _ = tf.primary _LI = tf.log_info _LW = tf.log_warning _LE = tf.log_error _LC = tf.log_critical USE_LAZY = True def install(domain, lazy=False): """"""Install a _() function using the given translation domain. Given a translation domain, install a _() function using gettext's install() function. The main difference from gettext.install() is that we allow overriding the default localedir (e.g. /usr/share/locale) using a translation-domain-specific environment variable (e.g. NOVA_LOCALEDIR). :param domain: the translation domain :param lazy: indicates whether or not to install the lazy _() function. The lazy _() introduces a way to do deferred translation of messages by installing a _ that builds Message objects, instead of strings, which can then be lazily translated into any available locale. """""" if lazy: from six import moves tf = TranslatorFactory(domain, lazy=True) moves.builtins.__dict__['_'] = tf.primary else: localedir = '%s_LOCALEDIR' % domain.upper() if six.PY3: gettext.install(domain, localedir=os.environ.get(localedir)) else: gettext.install(domain, localedir=os.environ.get(localedir), unicode=True) class Message(six.text_type): """"""A Message object is a unicode object that can be translated. Translation of Message is done explicitly using the translate() method. For all non-translation intents and purposes, a Message is simply unicode, and can be treated as such. """""" def __new__(cls, msgid, msgtext=None, params=None, domain='glance', *args): """"""Create a new Message object. In order for translation to work gettext requires a message ID, this msgid will be used as the base unicode text. It is also possible for the msgid and the base unicode text to be different by passing the msgtext parameter. """""" # If the base msgtext is not given, we use the default translation # of the msgid (which is in English) just in case the system locale is # not English, so that the base text will be in that locale by default. if not msgtext: msgtext = Message._translate_msgid(msgid, domain) # We want to initialize the parent unicode with the actual object that # would have been plain unicode if 'Message' was not enabled. msg = super(Message, cls).__new__(cls, msgtext) msg.msgid = msgid msg.domain = domain msg.params = params return msg def translate(self, desired_locale=None): """"""Translate this message to the desired locale. :param desired_locale: The desired locale to translate the message to, if no locale is provided the message will be translated to the system's default locale. :returns: the translated message in unicode """""" translated_message = Message._translate_msgid(self.msgid, self.domain, desired_locale) if self.params is None: # No need for more translation return translated_message # This Message object may have been formatted with one or more # Message objects as substitution arguments, given either as a single # argument, part of a tuple, or as one or more values in a dictionary. # When translating this Message we need to translate those Messages too translated_params = _translate_args(self.params, desired_locale) translated_message = translated_message % translated_params return translated_message @staticmethod def _translate_msgid(msgid, domain, desired_locale=None): if not desired_locale: system_locale = locale.getdefaultlocale() # If the system locale is not available to the runtime use English if not system_locale[0]: desired_locale = 'en_US' else: desired_locale = system_locale[0] locale_dir = os.environ.get(domain.upper() + '_LOCALEDIR') lang = gettext.translation(domain, localedir=locale_dir, languages=[desired_locale], fallback=True) if six.PY3: translator = lang.gettext else: translator = lang.ugettext translated_message = translator(msgid) return translated_message def __mod__(self, other): # When we mod a Message we want the actual operation to be performed # by the parent class (i.e. unicode()), the only thing we do here is # save the original msgid and the parameters in case of a translation params = self._sanitize_mod_params(other) unicode_mod = super(Message, self).__mod__(params) modded = Message(self.msgid, msgtext=unicode_mod, params=params, domain=self.domain) return modded def _sanitize_mod_params(self, other): """"""Sanitize the object being modded with this Message. - Add support for modding 'None' so translation supports it - Trim the modded object, which can be a large dictionary, to only those keys that would actually be used in a translation - Snapshot the object being modded, in case the message is translated, it will be used as it was when the Message was created """""" if other is None: params = (other,) elif isinstance(other, dict): # Merge the dictionaries # Copy each item in case one does not support deep copy. params = {} if isinstance(self.params, dict): for key, val in self.params.items(): params[key] = self._copy_param(val) for key, val in other.items(): params[key] = self._copy_param(val) else: params = self._copy_param(other) return params def _copy_param(self, param): try: return copy.deepcopy(param) except Exception: # Fallback to casting to unicode this will handle the # python code-like objects that can't be deep-copied return six.text_type(param) def __add__(self, other): msg = _('Message objects do not support addition.') raise TypeError(msg) def __radd__(self, other): return self.__add__(other) if six.PY2: def __str__(self): # NOTE(luisg): Logging in python 2.6 tries to str() log records, # and it expects specifically a UnicodeError in order to proceed. msg = _('Message objects do not support str() because they may ' 'contain non-ascii characters. ' 'Please use unicode() or translate() instead.') raise UnicodeError(msg) def get_available_languages(domain): """"""Lists the available languages for the given translation domain. :param domain: the domain to get languages for """""" if domain in _AVAILABLE_LANGUAGES: return copy.copy(_AVAILABLE_LANGUAGES[domain]) localedir = '%s_LOCALEDIR' % domain.upper() find = lambda x: gettext.find(domain, localedir=os.environ.get(localedir), languages=[x]) # NOTE(mrodden): en_US should always be available (and first in case # order matters) since our in-line message strings are en_US language_list = ['en_US'] # NOTE(luisg): Babel <1.0 used a function called list(), which was # renamed to locale_identifiers() in >=1.0, the requirements master list # requires >=0.9.6, uncapped, so defensively work with both. We can remove # this check when the master list updates to >=1.0, and update all projects list_identifiers = (getattr(localedata, 'list', None) or getattr(localedata, 'locale_identifiers')) locale_identifiers = list_identifiers() for i in locale_identifiers: if find(i) is not None: language_list.append(i) # NOTE(luisg): Babel>=1.0,<1.3 has a bug where some OpenStack supported # locales (e.g. 'zh_CN', and 'zh_TW') aren't supported even though they # are perfectly legitimate locales: # https://github.com/mitsuhiko/babel/issues/37 # In Babel 1.3 they fixed the bug and they support these locales, but # they are still not explicitly ""listed"" by locale_identifiers(). # That is why we add the locales here explicitly if necessary so that # they are listed as supported. aliases = {'zh': 'zh_CN', 'zh_Hant_HK': 'zh_HK', 'zh_Hant': 'zh_TW', 'fil': 'tl_PH'} for (locale_, alias) in six.iteritems(aliases): if locale_ in language_list and alias not in language_list: language_list.append(alias) _AVAILABLE_LANGUAGES[domain] = language_list return copy.copy(language_list) def translate(obj, desired_locale=None): """"""Gets the translated unicode representation of the given object. If the object is not translatable it is returned as-is. If the locale is None the object is translated to the system locale. :param obj: the object to translate :param desired_locale: the locale to translate the message to, if None the default system locale will be used :returns: the translated object in unicode, or the original object if it could not be translated """""" message = obj if not isinstance(message, Message): # If the object to translate is not already translatable, # let's first get its unicode representation message = six.text_type(obj) if isinstance(message, Message): # Even after unicoding() we still need to check if we are # running with translatable unicode before translating return message.translate(desired_locale) return obj def _translate_args(args, desired_locale=None): """"""Translates all the translatable elements of the given arguments object. This method is used for translating the translatable values in method arguments which include values of tuples or dictionaries. If the object is not a tuple or a dictionary the object itself is translated if it is translatable. If the locale is None the object is translated to the system locale. :param args: the args to translate :param desired_locale: the locale to translate the args to, if None the default system locale will be used :returns: a new args object with the translated contents of the original """""" if isinstance(args, tuple): return tuple(translate(v, desired_locale) for v in args) if isinstance(args, dict): translated_dict = {} for (k, v) in six.iteritems(args): translated_v = translate(v, desired_locale) translated_dict[k] = translated_v return translated_dict return translate(args, desired_locale) class TranslationHandler(handlers.MemoryHandler): """"""Handler that translates records before logging them. The TranslationHandler takes a locale and a target logging.Handler object to forward LogRecord objects to after translating them. This handler depends on Message objects being logged, instead of regular strings. The handler can be configured declaratively in the logging.conf as follows: [handlers] keys = translatedlog, translator [handler_translatedlog] class = handlers.WatchedFileHandler args = ('/var/log/api-localized.log',) formatter = context [handler_translator] class = openstack.common.log.TranslationHandler target = translatedlog args = ('zh_CN',) If the specified locale is not available in the system, the handler will log in the default locale. """""" def __init__(self, locale=None, target=None): """"""Initialize a TranslationHandler :param locale: locale to use for translating messages :param target: logging.Handler object to forward LogRecord objects to after translation """""" # NOTE(luisg): In order to allow this handler to be a wrapper for # other handlers, such as a FileHandler, and still be able to # configure it using logging.conf, this handler has to extend # MemoryHandler because only the MemoryHandlers' logging.conf # parsing is implemented such that it accepts a target handler. handlers.MemoryHandler.__init__(self, capacity=0, target=target) self.locale = locale def setFormatter(self, fmt): self.target.setFormatter(fmt) def emit(self, record): # We save the message from the original record to restore it # after translation, so other handlers are not affected by this original_msg = record.msg original_args = record.args try: self._translate_and_log_record(record) finally: record.msg = original_msg record.args = original_args def _translate_and_log_record(self, record): record.msg = translate(record.msg, self.locale) # In addition to translating the message, we also need to translate # arguments that were passed to the log method that were not part # of the main message e.g., log.info(_('Some message %s'), this_one)) record.args = _translate_args(record.args, self.locale) self.target.emit(record) ",0,499
openstack%2Fmanila~master~I910e87f00e4d309419f81469da27e70c069e6ada,openstack/manila,master,I910e87f00e4d309419f81469da27e70c069e6ada,Enhance devstack plugin,MERGED,2014-11-20 13:54:21.000000000,2014-12-11 21:15:28.000000000,2014-12-11 21:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 9521}, {'_account_id': 11047}]","[{'number': 1, 'created': '2014-11-20 13:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0faa367017f819046b75eeb28ed0af63ef78bf4b', 'message': 'Enhance devstack plugin [WIP]\n\nAdded several features:\n- possibility to set any opt to any group\n- possibility configure and enable any set of share backends\n\nImplements bp enhance-devstack-plugin\n\nChange-Id: I910e87f00e4d309419f81469da27e70c069e6ada\n'}, {'number': 2, 'created': '2014-12-11 19:03:07.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/1a2ec3da9b4bb392b11e36c3bd2fa831007544a0', 'message': ""Enhance devstack plugin\n\nAdd several features:\n- possibility to set any opt to any group\n- possibility to configure and enable any set of share backends\n\nDetails:\n1) It is possible to set any custom opt to any config group using following:\n$ export MANILA_OPTGROUP_foo_bar=value\nwhere 'foo' is name of config group and 'bar' is name of option.\n\n2) 'MANILA_CONFIGURE_GROUPS' contains list of config group names used to create\nconfig groups, but 'MANILA_ENABLED_BACKENDS' is used to set config groups as\nManila share back ends. Both can be set like following:\n$ export MANILA_ENABLED_BACKENDS=foo,bar\nwhere 'foo' and 'bar' are names of config groups with opts for some share\ndrivers. By default they are equal. Also be attentive, if you modify both,\nmake sure 'MANILA_CONFIGURE_GROUPS' contains all values from\n'MANILA_ENABLED_BACKENDS'.\n\n3) Two default backends are used for compatibility with previous approach.\nTwo defaults backends have same configuration except name of backend.\nBoth use generic driver.\nThey can be enabled by adding values of following env vars:\n'MANILA_BACKEND1_CONFIG_GROUP_NAME' and 'MANILA_BACKEND2_CONFIG_GROUP_NAME'\nto the env var 'MANILA_ENABLED_BACKENDS' or will be enabled\nif 'MANILA_ENABLED_BACKENDS' is empty.\n\nImplements bp enhance-devstack-plugin\n\nChange-Id: I910e87f00e4d309419f81469da27e70c069e6ada\n""}]",3,135953,1a2ec3da9b4bb392b11e36c3bd2fa831007544a0,13,5,2,8851,,,0,"Enhance devstack plugin

Add several features:
- possibility to set any opt to any group
- possibility to configure and enable any set of share backends

Details:
1) It is possible to set any custom opt to any config group using following:
$ export MANILA_OPTGROUP_foo_bar=value
where 'foo' is name of config group and 'bar' is name of option.

2) 'MANILA_CONFIGURE_GROUPS' contains list of config group names used to create
config groups, but 'MANILA_ENABLED_BACKENDS' is used to set config groups as
Manila share back ends. Both can be set like following:
$ export MANILA_ENABLED_BACKENDS=foo,bar
where 'foo' and 'bar' are names of config groups with opts for some share
drivers. By default they are equal. Also be attentive, if you modify both,
make sure 'MANILA_CONFIGURE_GROUPS' contains all values from
'MANILA_ENABLED_BACKENDS'.

3) Two default backends are used for compatibility with previous approach.
Two defaults backends have same configuration except name of backend.
Both use generic driver.
They can be enabled by adding values of following env vars:
'MANILA_BACKEND1_CONFIG_GROUP_NAME' and 'MANILA_BACKEND2_CONFIG_GROUP_NAME'
to the env var 'MANILA_ENABLED_BACKENDS' or will be enabled
if 'MANILA_ENABLED_BACKENDS' is empty.

Implements bp enhance-devstack-plugin

Change-Id: I910e87f00e4d309419f81469da27e70c069e6ada
",git fetch https://review.opendev.org/openstack/manila refs/changes/53/135953/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,0faa367017f819046b75eeb28ed0af63ef78bf4b,bp/enhance-devstack-plugin,"# Configuration of ""manila-share"" (m-shr) service # 1) Env var ""MANILA_ENABLED_BACKENDS"" is used to specify enabled backends. # If not set, default backends will be used. Can be set as following: # MANILA_ENABLED_BACKENDS=foo,bar # where 'foo' and 'bar' are names of config groups with opts for some share drivers. # # 2) It is possible to set any custom opt to any config group. Use following: # export MANILA_OPTGROUP_foo_bar=value # where 'foo' is name of config group and 'bar' is name of option. # Config group name should not contain underscores. # # 3) Two default backends are used for compatibility with previous approach. # Two defaults backends have same configuration except name of backend. # Both use generic driver. # They can be enabled by adding values of following env vars: # 'MANILA_BACKEND1_CONFIG_GROUP_NAME' and 'MANILA_BACKEND2_CONFIG_GROUP_NAME' # to the env var 'MANILA_ENABLED_BACKENDS' or will be enabled # if 'MANILA_ENABLED_BACKENDS' is empty. MANILA_REPO_ROOT=${MANILA_REPO_ROOT:-openstack}MANILA_BRANCH=${MANILA_BRANCH:-master}MANILACLIENT_BRANCH=${MANILACLIENT_BRANCH:-master}MANILA_CONF_DIR=${MANILA_CONF_DIR:-/etc/manila}# Common opts# Common info for Generic driver(s) SHARE_DRIVER=${SHARE_DRIVER:-manila.share.drivers.generic.GenericShareDriver} eval USER_HOME=~# Support for multi backend configuration (default is no support) # deprecated. Makes influence only when is set to True and ""$MANILA_ENABLED_BACKENDS"" is not set MANILA_MULTI_BACKEND=$(trueorfalse False $MANILA_MULTI_BACKEND) # deprecated, use MANILA_ENABLED_BACKENDS instead # First share backend data, that will be used in any installation MANILA_BACKEND1_CONFIG_GROUP_NAME=${MANILA_BACKEND1_CONFIG_GROUP_NAME:-generic1} # deprecated MANILA_SHARE_BACKEND1_NAME=${MANILA_SHARE_BACKEND1_NAME:-GENERIC1} # deprecated # Second share backend data, that will be used only with MANILA_MULTI_BACKEND=True MANILA_BACKEND2_CONFIG_GROUP_NAME=${MANILA_BACKEND2_CONFIG_GROUP_NAME:-generic2} # deprecated MANILA_SHARE_BACKEND2_NAME=${MANILA_SHARE_BACKEND2_NAME:-GENERIC2} # deprecated function configure_default_backends { # Configure two default backends with generic drivers onboard for group_name in $MANILA_BACKEND1_CONFIG_GROUP_NAME $MANILA_BACKEND2_CONFIG_GROUP_NAME do iniset $MANILA_CONF $group_name share_driver $SHARE_DRIVER if [ ""$MANILA_BACKEND1_CONFIG_GROUP_NAME"" == ""$group_name"" ]; then iniset $MANILA_CONF $group_name share_backend_name $MANILA_SHARE_BACKEND1_NAME else iniset $MANILA_CONF $group_name share_backend_name $MANILA_SHARE_BACKEND2_NAME fi iniset $MANILA_CONF $group_name path_to_public_key $MANILA_PATH_TO_PUBLIC_KEY iniset $MANILA_CONF $group_name path_to_private_key $MANILA_PATH_TO_PRIVATE_KEY iniset $MANILA_CONF $group_name service_image_name $MANILA_SERVICE_IMAGE_NAME iniset $MANILA_CONF $group_name service_instance_user $MANILA_SERVICE_INSTANCE_USER iniset $MANILA_CONF $group_name service_instance_password $MANILA_SERVICE_INSTANCE_PASSWORD done # Note: set up config group does not mean that this backend will be enabled. # To enable it, specify its name explicitly using ""enabled_share_backends"" opt. configure_default_backends default_backends=$MANILA_BACKEND1_CONFIG_GROUP_NAME default_backends+=,$MANILA_BACKEND2_CONFIG_GROUP_NAME if [ ! $MANILA_ENABLED_BACKENDS ]; then # If $MANILA_ENABLED_BACKENDS is not set, use configured backends by default MANILA_ENABLED_BACKENDS=$default_backends fi iniset $MANILA_CONF DEFAULT enabled_share_backends $MANILA_ENABLED_BACKENDS if [[ -n ""$MANILA_ENABLED_BACKENDS"" ]]; then for be in ${MANILA_ENABLED_BACKENDS//,/ }; do # get backend_specific opt values echo ""group = $be"" prefix=MANILA_OPTGROUP_$be\_ env | grep $prefix | while read -r line ; do # parse it to opt names and values opt=${line#$prefix} opt_name=${opt%%=*} opt_value=${opt##*=} echo ""opt_name = $opt_name"" echo ""opt_value = $opt_value"" iniset $MANILA_CONF $be $opt_name $opt_value done done fi","MANILA_REPO_ROOT=openstackMANILA_BRANCH=masterMANILACLIENT_BRANCH=masterMANILA_MNT_DIR=${MANILA_MNT_DIR:=$MANILA_STATE_PATH/mnt}MANILA_CONF_DIR=/etc/manila# Support for multi backend configuration (default is no support) MANILA_MULTI_BACKEND=$(trueorfalse False $MANILA_MULTI_BACKEND) # First share backend data, that will be used in any installation MANILA_BACKEND1_CONFIG_GROUP_NAME=${MANILA_BACKEND1_CONFIG_GROUP_NAME:-backend1} MANILA_SHARE_BACKEND1_NAME=${MANILA_SHARE_BACKEND1_NAME:-BACKEND1} # Second share backend data, that will be used only with MANILA_MULTI_BACKEND=True MANILA_BACKEND2_CONFIG_GROUP_NAME=${MANILA_BACKEND2_CONFIG_GROUP_NAME:-backend2} MANILA_SHARE_BACKEND2_NAME=${MANILA_SHARE_BACKEND2_NAME:-BACKEND2} SHARE_DRIVER=${SHARE_DRIVER:-manila.share.drivers.generic.GenericShareDriver} eval USER_HOME=~ # These are used by generic driverfunction add_share_backend { # Expects two args: # 1: config group name # 2: share_backend_name iniset $MANILA_CONF $1 share_driver $SHARE_DRIVER iniset $MANILA_CONF $1 share_backend_name $2 iniset $MANILA_CONF $1 path_to_public_key $MANILA_PATH_TO_PUBLIC_KEY iniset $MANILA_CONF $1 path_to_private_key $MANILA_PATH_TO_PRIVATE_KEY iniset $MANILA_CONF $1 service_image_name $MANILA_SERVICE_IMAGE_NAME iniset $MANILA_CONF $1 service_instance_user $MANILA_SERVICE_INSTANCE_USER iniset $MANILA_CONF $1 service_instance_password $MANILA_SERVICE_INSTANCE_PASSWORD add_share_backend $MANILA_BACKEND1_CONFIG_GROUP_NAME $MANILA_SHARE_BACKEND1_NAME enabled_backends=$MANILA_BACKEND1_CONFIG_GROUP_NAME add_share_backend $MANILA_BACKEND2_CONFIG_GROUP_NAME $MANILA_SHARE_BACKEND2_NAME enabled_backends+=,$MANILA_BACKEND2_CONFIG_GROUP_NAME iniset $MANILA_CONF DEFAULT enabled_share_backends $enabled_backends",83,38
openstack%2Frally~master~I32811974d88f414c4508dfed19a7c5dc5e80fd98,openstack/rally,master,I32811974d88f414c4508dfed19a7c5dc5e80fd98,Change TaskNotFound traceback info to user-friendly message,MERGED,2014-11-23 08:33:50.000000000,2014-12-11 21:15:09.000000000,2014-12-11 21:15:08.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7805}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-11-23 08:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/486fd5c05c8d2fb5054316b6879421253657b34e', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}, {'number': 2, 'created': '2014-11-23 08:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fe09f244b51bd7f78588bd93a0efd33161ed91da', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}, {'number': 3, 'created': '2014-11-25 06:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/116e802727785e8685e7afe4d96ea1f9df54bbd1', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}, {'number': 4, 'created': '2014-11-25 10:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7ca210a111c98a4984607da92fd03c187199ce07', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}, {'number': 5, 'created': '2014-11-25 13:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7d8af94e611ae6064aacaa395eba1319468c7b11', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}, {'number': 6, 'created': '2014-12-10 16:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/304ec6479d42095625c063616367c854b8398e18', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nThe unit test and functional test are both provided.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}, {'number': 7, 'created': '2014-12-11 04:31:22.000000000', 'files': ['tests/functional/test_cli_task.py', 'tests/unit/cmd/test_cliutils.py', 'rally/cmd/cliutils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/7dcf0e68df0c259dcd1c6623b75031c44b3ec41f', 'message': 'Change TaskNotFound traceback info to user-friendly message\n\nIn some common cases (like detecting absense of requested object),\nCLI shows exception traceback instead of just a simple message\nthat ""<something> is not found"".\n\nThis traceback is redundant and confusing users - they think that\nrally went into trouble, but all that actually happened is wrong\nuuid specified.\n\nThe traceback must be shown only with `--debug\' option explicitly\nspecified.\n\nThe unit test and functional test are both provided.\n\nChange-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98\nCloses-Bug: #1392354\n'}]",4,136612,7dcf0e68df0c259dcd1c6623b75031c44b3ec41f,30,5,7,7805,,,0,"Change TaskNotFound traceback info to user-friendly message

In some common cases (like detecting absense of requested object),
CLI shows exception traceback instead of just a simple message
that ""<something> is not found"".

This traceback is redundant and confusing users - they think that
rally went into trouble, but all that actually happened is wrong
uuid specified.

The traceback must be shown only with `--debug' option explicitly
specified.

The unit test and functional test are both provided.

Change-Id: I32811974d88f414c4508dfed19a7c5dc5e80fd98
Closes-Bug: #1392354
",git fetch https://review.opendev.org/openstack/rally refs/changes/12/136612/7 && git format-patch -1 --stdout FETCH_HEAD,['rally/cmd/commands/task.py'],1,486fd5c05c8d2fb5054316b6879421253657b34e,bug/1392354,"import tracebackfrom rally import log as loggingLOG = logging.getLogger(__name__) try: task = db.task_get(task_id) print(_(""Task %(task_id)s is %(status)s."") % {'task_id': task_id, 'status': task['status']}) except exceptions.TaskNotFound as e: print(_(""Task %(task_id)s is not found."") % {'task_id': task_id}) LOG.debug(traceback.format_exc())"," task = db.task_get(task_id) print(_(""Task %(task_id)s is %(status)s."") % {'task_id': task_id, 'status': task['status']})",13,3
openstack%2Frally~master~Ic39ec84607f064cc638e333e5f6eab7e62c3f607,openstack/rally,master,Ic39ec84607f064cc638e333e5f6eab7e62c3f607,Updated from global requirements,MERGED,2014-12-11 07:21:31.000000000,2014-12-11 21:09:11.000000000,2014-12-11 21:09:09.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-12-11 07:21:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/a6e4aa90f1c6b19889e98706d805015f5032fce0', 'message': 'Updated from global requirements\n\nChange-Id: Ic39ec84607f064cc638e333e5f6eab7e62c3f607\n'}]",0,140965,a6e4aa90f1c6b19889e98706d805015f5032fce0,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ic39ec84607f064cc638e333e5f6eab7e62c3f607
",git fetch https://review.opendev.org/openstack/rally refs/changes/65/140965/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a6e4aa90f1c6b19889e98706d805015f5032fce0,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fglance-specs~master~I2eab7dc2c23894897bb053926baeac917dbd2bfe,openstack/glance-specs,master,I2eab7dc2c23894897bb053926baeac917dbd2bfe,Tag Catalog Support For Metadata Definitions,MERGED,2014-10-14 00:14:50.000000000,2014-12-11 21:03:49.000000000,2014-12-11 21:03:48.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 8759}, {'_account_id': 8959}, {'_account_id': 10383}, {'_account_id': 12231}]","[{'number': 1, 'created': '2014-10-14 00:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/069206c9460ea0fef4cf735b897dd17840ebddd6', 'message': ""Tag Catalog Support For Metadata Definitions\n\nThis blueprint adds the tag catalog back after it was deferred from Juno due\nto time constraints. The original, approved spec included supporting tag\nlibraries in the metadata definitions catalog. However, at the end of\nJuno, the original spec was updated to remove tags since they weren't\nimplemented.\n\nThe implemented juno spec is here for reference:\n\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\nChange-Id: I2eab7dc2c23894897bb053926baeac917dbd2bfe\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Wayne Okuma <wayne.okuma@hp.com>\nCo-Authored-By: Lakshmi N Sampath <lakshmi.sampath@hp.com>\nCo-Authored-By: murali sundar <murali.sundar@intel.com>\n""}, {'number': 2, 'created': '2014-10-29 00:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/c9c6102ec285ea74bf837c24ddba66efeb624246', 'message': ""Tag Catalog Support For Metadata Definitions\n\nThis blueprint adds the tag catalog back after it was deferred from Juno due\nto time constraints. The original, approved spec included supporting tag\nlibraries in the metadata definitions catalog. However, at the end of\nJuno, the original spec was updated to remove tags since they weren't\nimplemented.\n\nThe implemented juno spec is here for reference:\n\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\nChange-Id: I2eab7dc2c23894897bb053926baeac917dbd2bfe\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Wayne Okuma <wayne.okuma@hp.com>\nCo-Authored-By: Lakshmi N Sampath <lakshmi.sampath@hp.com>\nCo-Authored-By: murali sundar <murali.sundar@intel.com>\n""}, {'number': 3, 'created': '2014-10-29 00:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/a3eb34d2324ad3ecbc2961507bf40aeb24d78b7e', 'message': ""Tag Catalog Support For Metadata Definitions\n\nThis blueprint adds the tag catalog back after it was deferred from Juno due\nto time constraints. The original, approved spec included supporting tag\nlibraries in the metadata definitions catalog. However, at the end of\nJuno, the original spec was updated to remove tags since they weren't\nimplemented.\n\nThe implemented juno spec is here for reference:\n\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\nChange-Id: I2eab7dc2c23894897bb053926baeac917dbd2bfe\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Wayne Okuma <wayne.okuma@hp.com>\nCo-Authored-By: Lakshmi N Sampath <lakshmi.sampath@hp.com>\nCo-Authored-By: murali sundar <murali.sundar@intel.com>\n""}, {'number': 4, 'created': '2014-11-20 23:20:52.000000000', 'files': ['specs/kilo/metadefs-tags.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/6354130bf52d9dfad54534f7087c9ee3766bf0dc', 'message': ""Tag Catalog Support For Metadata Definitions\n\nThis blueprint adds the basic tag catalog back after it was deferred from Juno\ndue to time constraints. The original, approved spec included supporting tag\nlibraries in the metadata definitions catalog. However, at the end of\nJuno, the original spec was updated to remove tags since they weren't\nimplemented.\n\nThis spec is actually a reduction of the tag concepts in the original\napproved Juno spec. In the original Juno spec, tags had a dynamic hierarchy\ncapability.  This spec does not include the tag hierarchy in order to\nsimplify this spec. That aspect of tags will be deferred to a later spec.\n\nThe implemented juno spec is here for reference:\n\nhttps://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst\n\nChange-Id: I2eab7dc2c23894897bb053926baeac917dbd2bfe\nCo-Authored-By: Travis Tripp <travis.tripp@hp.com>\nCo-Authored-By: Wayne Okuma <wayne.okuma@hp.com>\nCo-Authored-By: Lakshmi N Sampath <lakshmi.sampath@hp.com>\nCo-Authored-By: murali sundar <murali.sundar@intel.com>\n""}]",0,128143,6354130bf52d9dfad54534f7087c9ee3766bf0dc,23,10,4,7665,,,0,"Tag Catalog Support For Metadata Definitions

This blueprint adds the basic tag catalog back after it was deferred from Juno
due to time constraints. The original, approved spec included supporting tag
libraries in the metadata definitions catalog. However, at the end of
Juno, the original spec was updated to remove tags since they weren't
implemented.

This spec is actually a reduction of the tag concepts in the original
approved Juno spec. In the original Juno spec, tags had a dynamic hierarchy
capability.  This spec does not include the tag hierarchy in order to
simplify this spec. That aspect of tags will be deferred to a later spec.

The implemented juno spec is here for reference:

https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst

Change-Id: I2eab7dc2c23894897bb053926baeac917dbd2bfe
Co-Authored-By: Travis Tripp <travis.tripp@hp.com>
Co-Authored-By: Wayne Okuma <wayne.okuma@hp.com>
Co-Authored-By: Lakshmi N Sampath <lakshmi.sampath@hp.com>
Co-Authored-By: murali sundar <murali.sundar@intel.com>
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/43/128143/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/metadefs-tags.rst'],1,069206c9460ea0fef4cf735b897dd17840ebddd6,bp/metadefs-tags,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Tag Catalog Support For Metadata Definitions ============================================ https://blueprints.launchpad.net/glance/+spec/metadefs-tags This blueprint adds the tag catalog back after it was deferred from Juno due to time constraints. The original, approved spec included supporting tag libraries in the metadata definitions catalog. However, at the end of Juno, the original spec was updated to remove tags since they weren't implemented. The implemented juno spec is here for reference: https://github.com/openstack/glance-specs/blob/master/specs/juno/metadata-schema-catalog.rst Problem description =================== A challenge with using OpenStack is discovering, sharing, and correlating tags across services and different types of resources. We believe this affects both end users and administrators. For example, a cloud operator or vendor may have a predefined set of ""tags"" they want to be used as a starting point for images and instances. Currently, OpenStack does not have a facility for the cloud operator to include that base set of tags. This means that every deployment and every project may end up with its own disparate set of tags. This leads to inconsistencies, but also is extra hassle for end users who end up reinventing all the ""tags"" in every project. For example, is the tag ""postgres"" the same as ""PostgreSQL""? If a base library of tags is used, any user typing ""pos"" would be prompted with the one that already exists in the tag library and would choose it. Future searches based on tags would ensure consistent results. **Terminology** The term metadata can become very overloaded and confusing. This proposed enhancement is about the additional metadata that is set as ""tags"" (name only) across various artifacts and OpenStack services. Different APIs may use tags and key / value pairs differently. Tags typically are not used to drive runtime behavior. However, key / value pairs are often used by the system to potentially drive runtime, such as scheduling, quality of service, or driver behavior. A few examples of metadata today: +-------------------------+---------------------------+----------------------+ | Nova | Cinder | Glance | +-------------------------+---------------------------+----------------------+ | Flavor | Volume & Snapshot | Image & Snapshot | | + extra specs | + image metadata | + properties | | Host Aggregate | + metadata | + tags | | + metadata | VolumeType | | | Instances | + extra specs | | | + metadata | + qos specs | | | + tags | | | +-------------------------+---------------------------+----------------------+ Proposed change =============== We are proposing enhancements to the Metadata Definitions Catalog. The following subsections detail the enhancements to the catalog. **Tags** A catalog of possible tags that can be used to help ensure tag name consistency across users, resource types, and services. So, when a user goes to apply a tag on a resource, they will be able to either create new tags or choose from tags that have been used elsewhere in the system on different types of resources. For example, the same tag could be used for Images, Volumes, and Instances. Tags are not case sensitive (BigData is equivalent to bigdata but is different from Big-Data). **Tag Hierarchy (Kilo release)** The notion of hierarchy has come up in various application related discussions. It is very simple to support hierarchy. For example, tags of ""MySQL"" and ""Postgres"" could be created and set as having a parent of the ""Databases"" tag. A user could then tag just ""MySQL"" on something like an image or software template. Subsequent searches for resources could be performed for all ""Databases"" by simply retrieving the list of tags that are children of the ""Databases"" tag. Alternatives ------------ A key use case is the collaboration on tags using a common catalog. This is complementary to tags being added ad-hoc across all services. We think the metadata API could also be backed by a search indexer across services to include ad-hoc metadata as well as defined metadata. However, that is not the focus of this blueprint. Data model impact ----------------- This will use a relational database and exist in the same database as the existing Glance Metadata Definitions Catalog. It will be additive to the existing schema. The following DB schema is the initial suggested schema. We will improve and take comments during code review. Constraints not shown for readability. Suggested Basic Schema:: CREATE TABLE `metadef_tags` ( `id` int(11) NOT NULL AUTO_INCREMENT, `namespace_id` int(11) NOT NULL, `name` varchar(80) NOT NULL, `created_at` timestamp NOT NULL, `updated_at` timestamp ) CREATE TABLE `metadef_tag_parents` ( `child_tag_id` int(11) NOT NULL, `parent_tag_id` int(11) NOT NULL ) REST API impact --------------- In the REST API everything is referred by namespace and name rather than synthetic IDs. This helps to achieve portability (import / export using JSON). APIs should allow coarse grain and fine grain access to information in order to control data transfer bandwidth requirements. Working with Namespaces Basic interaction is: #. Get list of namespaces with overview info based on the desired filters. #. Get tags **Common Response Codes** * Create Success: `201 Created` * Modify Success: `200 OK` * Delete Success: `204 No Content` * Failure: `400 Bad Request` with details. * Forbidden: `403 Forbidden` * Not found: `404 Not found` if specific entity not found **API Version** All URLS will be under the v2 Glance API. If it is not explicitly specified assume /v2/<url> Namespace may optionally contain the following in addition to basic fields. * resource_types * properties * objects * tags This spec adds Tags. **Tags** List All Tags visible to user: GET /metadefs/tags Filters by adding query parameters:: tag_prefix = Support now with only case insensitive, prefix search, e.g. ""CEN"" would find CENTOS namespaces = <comma separated list> resource_types = <comma separated list> e.g. OS::Glance::Image visibility = Valid values are public, private. Default is to return both public namespaces and private namespaces visible to the user making the request. limit = Use to request a specific page size. Expect a response to a limited request to return between zero and limit items. marker = Specifies the namespace of the last-seen namespace. The typical pattern of limit and marker is to make an initial limited request and then to use the last namespace from the response as the marker parameter in a subsequent limited request. Pattern filter could be supported in future blueprint that incorporates elasticsearch across OpenStack. Example Body:: { ""tags"": [ { ""name"": ""Databases"" }, { ""name"": ""BigData"" }, { ""name"": ""MySQL"", ""parents"": [ ""Databases"" ] }, { ""name"": ""PostgreSQL"", ""parents"": [ ""Databases"" ] }, { ""name"": ""MongoDB"", ""parents"": [ ""Databases"", ""BigData"" ] } ] } Create / Replace all tags in a specific namespace: POST /metadefs/namespaces/{namespace}/tags/ Add tag in a specific namespace: POST /metadefs/namespaces/{namespace}/tags/{tag} Delete tag in specific namespace: DELETE /metadefs/namespaces/{namespace}/tags/{tag} Delete all tags in specific namespace: DELETE /metadefs/namespaces/{namespace}/tags List Tags that are descendants (any level) of a specific tag (Hierarchy): GET /metadefs/namespaces/{namespace}/tags/{tag}/descendants e.g. /metadefs/namespaces/default/tags/Databases/descendants This uses the popular ""flare.json"" sub format with the ""tags"" array because it which is used with many javascript graphing libraries as simple way to support hierarchy. It also allows adding more fields in the future (e.g. description). Example Body:: { ""tags"": [ { ""name"": ""Databases"", ""children"": [ { ""name"": ""MySQL"", ""children"" : [] }, { ""name"": ""PostgreSQL"", ""children"" : [] }, { ""name"": ""MongoDB"", ""children"" : [] } ] } ] } Add parent tag to a tag: PUT /metadefs/namespaces/{namespace}/tags/{tag}/parent/{tag} e.g. PUT /metadefs/namespaces/default/tags/MySQL/parent/Databases JSON Schema for Tags:: TBD Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- We intend to expose this via Horizon and are working on related blueprints. Update python-glanceclient as needed. Performance Impact ------------------ None anticipated. This is expected to be called from Horizon when an admin wants to annotate tags onto things likes images and instances. This API would be hit for them to get available tags or create new ones. Other deployer impact --------------------- DB Schema Creation for new API Default / Sample tag libraries will be checked into Glance. Deployers can customize these and provide additional definition files suitable to their cloud deployment. glance-manage will include loading tags. Developer impact ---------------- None (New API) Implementation ============== Assignee(s) ----------- Primary assignee: wayne-okuma Other contributors: lakshmi-sampath pawel-skowron travis-tripp Work Items ---------- Changes would be made to: #. The database API layer to add support for CRUD operations on tags #. The REST API for CRUD operations on the namespaces (add tags) #. The REST API for CRUD operations on the tags #. The python-glanceClient to support operations #. glance-manage to handle tags Dependencies ============ Same dependencies as Glance. Testing ======= Unit tests will be added for all possible code with a goal of being able to isolate functionality as much as possible. Tempest tests will be added wherever possible. Documentation Impact ==================== Docs needed for new API extension and usage References ========== .. Had to format links strangely in order to meet 80 character limit `Youtube summit recap of Graffiti Juno POC demo that included tags. <https://www.youtube.com/watch?v=Dhrthnq1bnw>`_ `Current glance metadata definition catalog documentation. <http://docs.openstack.org/developer/glance/metadefs-concepts.html>`_ Hierarchical tagging concepts were partially inspired by AWS marketplace. In the marketplace, you can filter by a hierarchy of categories. It made sense to us that this would be easy to achieve across various kinds of artifacts and resources through tags. `AWS Categories <https://aws.amazon.com/marketplace/help/200901100#step1>`_ *Simple application category tags (no hierarchy)* Images, volumes, software applications can be assigned to a category. Similarly, a flavor or host aggregate could be ""tagged"" with supporting a category of application, such as ""Big Data"" or ""Encryption"". Using the matching of categories, flavors or host aggregates that support that category of application can be easily paired up. Note: If a resource type doesnt provide a ""Tag"" mechanism (only key value pairs), a blueprint should be added to support tags on that type of resource. In lieu of that, a key of ""tags"" with a comma separated list of tags as the value be set on the resource *Namespace with hierarchical tags* Images, volumes, software applications can be assigned to a category. Similarly, a flavor or host aggregate could be ""tagged"" with supporting a category of application, such as ""CRM"". Using the matching of categories, flavors or hosts that support that category of application can be easily paired up. Adding the notion of hierarchy allows searching based on the hierarchy (show me all applications that are type ""BusinessSoftware""). - Application Categories - Business Software + Business Intelligence + Collaboration + Content Management ",,414,0
openstack%2Fpython-troveclient~master~Ib397d5791e9a6f10c10c2ab3160401c1c7cfa214,openstack/python-troveclient,master,Ib397d5791e9a6f10c10c2ab3160401c1c7cfa214,Fixes trove show output,MERGED,2014-10-22 07:43:38.000000000,2014-12-11 20:58:33.000000000,2014-12-11 20:58:32.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7634}, {'_account_id': 7806}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 11783}]","[{'number': 1, 'created': '2014-10-22 07:43:38.000000000', 'files': ['troveclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/dc21242144fdf520d065e2648c6f6d56b06fcee2', 'message': 'Fixes trove show output\n\nReasons:\n- trove show gives different output for id and names as input,\n  as explained in bug, with name it shows less information.\n\nChanges:\n- Returns the object found by id after finding the matching object\n  from the list of obtained instances, which results in getting\n  same attributes for output\n  irrespective whichever way the command is used.\n\nChange-Id: Ib397d5791e9a6f10c10c2ab3160401c1c7cfa214\nCloses-Bug: #1384055\n'}]",0,130150,dc21242144fdf520d065e2648c6f6d56b06fcee2,12,7,1,7806,,,0,"Fixes trove show output

Reasons:
- trove show gives different output for id and names as input,
  as explained in bug, with name it shows less information.

Changes:
- Returns the object found by id after finding the matching object
  from the list of obtained instances, which results in getting
  same attributes for output
  irrespective whichever way the command is used.

Change-Id: Ib397d5791e9a6f10c10c2ab3160401c1c7cfa214
Closes-Bug: #1384055
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/50/130150/1 && git format-patch -1 --stdout FETCH_HEAD,['troveclient/base.py'],1,dc21242144fdf520d065e2648c6f6d56b06fcee2,bug/1384055, found.append(self.get(obj.id)), found.append(obj),1,1
openstack%2Ftrove-integration~master~If0500c73a6f10d03d043fec26078782ca4f42c0d,openstack/trove-integration,master,If0500c73a6f10d03d043fec26078782ca4f42c0d,Add instructions for running int tests,MERGED,2014-12-10 19:29:25.000000000,2014-12-11 20:58:26.000000000,2014-12-11 20:58:25.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 8214}]","[{'number': 1, 'created': '2014-12-10 19:29:25.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/48d59c2bcd4e580028d8ffd5348a4e42b46e0b9a', 'message': 'Add instructions for running int tests\n\nThe best instructions online are on the wiki and are out of date.\nThis moves the intructions into the README and corrects them.\n\nChange-Id: If0500c73a6f10d03d043fec26078782ca4f42c0d\nCloses-Bug: 1401232\n'}]",0,140813,48d59c2bcd4e580028d8ffd5348a4e42b46e0b9a,7,3,1,11783,,,0,"Add instructions for running int tests

The best instructions online are on the wiki and are out of date.
This moves the intructions into the README and corrects them.

Change-Id: If0500c73a6f10d03d043fec26078782ca4f42c0d
Closes-Bug: 1401232
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/13/140813/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,48d59c2bcd4e580028d8ffd5348a4e42b46e0b9a,bug/1401232,"### Running Integration Tests Once Trove is running on DevStack, you can use the dev scripts to run the integration tests locally. $./redstack int-tests This will runs all of the blackbox tests by default. Use the --group option to run a different group: $./redstack int-tests --group=simple_blackbox You can also specify the TESTS_USE_INSTANCE_ID environment variable to have the integration tests use an existing instance for the tests rather than creating a new one. $./TESTS_DO_NOT_DELETE_INSTANCE=True TESTS_USE_INSTANCE_ID=INSTANCE_UUID ./redstack int-tests --group=simple_blackbox *** ",,15,0
openstack%2Fopenstack-manuals~master~I2b6179bec34e1ebaa7f4678f43f69385691c615b,openstack/openstack-manuals,master,I2b6179bec34e1ebaa7f4678f43f69385691c615b,Adds swift object versioning to End User Guide,MERGED,2014-12-10 22:20:04.000000000,2014-12-11 20:53:21.000000000,2014-12-11 20:53:19.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-10 22:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5324611ce5147b21530438d05ee877cb014a1f74', 'message': 'Adds swift object versioning to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I2b6179bec34e1ebaa7f4678f43f69385691c615b\nPartial-bug: 1392382\n'}, {'number': 2, 'created': '2014-12-11 16:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5dc389b6b84fc48a3bdd0b44b8a739a9a2755373', 'message': 'Adds swift object versioning to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I2b6179bec34e1ebaa7f4678f43f69385691c615b\nPartial-bug: 1392382\n'}, {'number': 3, 'created': '2014-12-11 19:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c441ac1eb2fb334ba4748b17f2edeb3f15da1dbb', 'message': 'Adds swift object versioning to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I2b6179bec34e1ebaa7f4678f43f69385691c615b\nPartial-bug: 1392382\n'}, {'number': 4, 'created': '2014-12-11 19:24:11.000000000', 'files': ['doc/user-guide/section_object-api-versioning.xml', 'doc/user-guide/section_cli_swift_howto.xml', 'doc/common/entities/openstack.ent'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/042d662c58b68958c69ee698dbb24edc76bd9d47', 'message': 'Adds swift object versioning to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I2b6179bec34e1ebaa7f4678f43f69385691c615b\nPartial-bug: 1392382\n'}]",3,140846,042d662c58b68958c69ee698dbb24edc76bd9d47,16,3,4,12454,,,0,"Adds swift object versioning to End User Guide

With the moving of the Object Storage API content from a
long-form dev guide to a specification, some topics needed
To be added to the End User Guide.

Change-Id: I2b6179bec34e1ebaa7f4678f43f69385691c615b
Partial-bug: 1392382
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/46/140846/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/section_object-api-versioning.xml', 'doc/user-guide/section_cli_swift_howto.xml']",2,5324611ce5147b21530438d05ee877cb014a1f74,bug/1392382," <para>To list all containers, run the following command:</para> <para>To download an object from a container, run the following command:</para> <xi:include href=""section_object-api-versioning.xml""/>"," <para>To list all containers: run the following command:</para> <para>To download an object from a container:, run the following command:</para>",184,3
openstack%2Fpython-glanceclient~master~I24fbba80831c311b42d1abb08487cc29c8b5b162,openstack/python-glanceclient,master,I24fbba80831c311b42d1abb08487cc29c8b5b162,Add release notes for 0.15.0,MERGED,2014-12-08 17:07:28.000000000,2014-12-11 20:48:13.000000000,2014-12-11 20:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-08 17:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/6e8a7eb442c018bbec1bdb3e93f56ad94f402085', 'message': ""Add release notes for 0.14.3\n\nThis adds release notes for the folowing commits:\n\n    $ git log --oneline --no-merges 0.14.2..HEAD\n    8e02b2a Allow --file in image-create with v2 Image API\n    d5a0e65 Add useful error on invalid --os-image-api-version\n    49f38a4 Add release notes for 0.14.0 - 0.14.2\n    5080d10 Send `identity_headers` through the wire\n    d0851c3 Remove readonly options from v2 shell commands\n    4194a55 Add --property-filter option to v2 image-list\n    ef0abdc Fix py34 failure for glance client\n    8c159a2 Don't set X-Auth-Token key in http session header if no token provided\n    b83a672 Refactor method of constructing dicts in some tests\n    751e064 Adds tty password entry for glanceclient\n    597da8a '--public' ignored on image create\n    cbbfbc9 Fix to ensure endpoint_type is used by _get_endpoint()\n    12a3a82 Add bash completion to glance client\n\nChange-Id: I24fbba80831c311b42d1abb08487cc29c8b5b162\n""}, {'number': 2, 'created': '2014-12-08 17:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/6dd205fb61e5422cbff598d5d95dfa4a5163fabb', 'message': ""Add release notes for 0.14.3\n\nThis adds release notes for the folowing commits:\n\n    $ git log --oneline --no-merges 0.14.2..HEAD\n    8e02b2a Allow --file in image-create with v2 Image API\n    d5a0e65 Add useful error on invalid --os-image-api-version\n    49f38a4 Add release notes for 0.14.0 - 0.14.2\n    5080d10 Send `identity_headers` through the wire\n    d0851c3 Remove readonly options from v2 shell commands\n    4194a55 Add --property-filter option to v2 image-list\n    ef0abdc Fix py34 failure for glance client\n    8c159a2 Don't set X-Auth-Token key in http session header if no token provided\n    b83a672 Refactor method of constructing dicts in some tests\n    751e064 Adds tty password entry for glanceclient\n    597da8a '--public' ignored on image create\n    cbbfbc9 Fix to ensure endpoint_type is used by _get_endpoint()\n    12a3a82 Add bash completion to glance client\n\nChange-Id: I24fbba80831c311b42d1abb08487cc29c8b5b162\n""}, {'number': 3, 'created': '2014-12-11 16:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5a7115c7a4c805351fd9a552ac9af5fef36f32e3', 'message': ""Add release notes for 0.14.3\n\nThis adds release notes for the folowing commits:\n\n    $ git log --oneline --no-merges 0.14.2..HEAD\n    9a4d858 Support Pagination for namespace list\n    3989cd2 Support schema types with non-str value\n    9829d7b Don't require version to create Client instance\n    8e02b2a Allow --file in image-create with v2 Image API\n    d5a0e65 Add useful error on invalid --os-image-api-version\n    49f38a4 Add release notes for 0.14.0 - 0.14.2\n    5080d10 Send `identity_headers` through the wire\n    d0851c3 Remove readonly options from v2 shell commands\n    4194a55 Add --property-filter option to v2 image-list\n    ef0abdc Fix py34 failure for glance client\n    8c159a2 Don't set X-Auth-Token key in http session header if no token provided\n    b83a672 Refactor method of constructing dicts in some tests\n    751e064 Adds tty password entry for glanceclient\n    597da8a '--public' ignored on image create\n    cbbfbc9 Fix to ensure endpoint_type is used by _get_endpoint()\n    12a3a82 Add bash completion to glance client\n\nChange-Id: I24fbba80831c311b42d1abb08487cc29c8b5b162\n""}, {'number': 4, 'created': '2014-12-11 16:45:57.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/385d97ef38fd7b976ea24653a2b4514dee62ffb8', 'message': ""Add release notes for 0.15.0\n\nThis adds release notes for the folowing commits:\n\n    $ git log --oneline --no-merges 0.14.2..HEAD\n    9a4d858 Support Pagination for namespace list\n    3989cd2 Support schema types with non-str value\n    9829d7b Don't require version to create Client instance\n    8e02b2a Allow --file in image-create with v2 Image API\n    d5a0e65 Add useful error on invalid --os-image-api-version\n    49f38a4 Add release notes for 0.14.0 - 0.14.2\n    5080d10 Send `identity_headers` through the wire\n    d0851c3 Remove readonly options from v2 shell commands\n    4194a55 Add --property-filter option to v2 image-list\n    ef0abdc Fix py34 failure for glance client\n    8c159a2 Don't set X-Auth-Token key in http session header if no token provided\n    b83a672 Refactor method of constructing dicts in some tests\n    751e064 Adds tty password entry for glanceclient\n    597da8a '--public' ignored on image create\n    cbbfbc9 Fix to ensure endpoint_type is used by _get_endpoint()\n    12a3a82 Add bash completion to glance client\n\nChange-Id: I24fbba80831c311b42d1abb08487cc29c8b5b162\n""}]",0,140079,385d97ef38fd7b976ea24653a2b4514dee62ffb8,13,3,4,11356,,,0,"Add release notes for 0.15.0

This adds release notes for the folowing commits:

    $ git log --oneline --no-merges 0.14.2..HEAD
    9a4d858 Support Pagination for namespace list
    3989cd2 Support schema types with non-str value
    9829d7b Don't require version to create Client instance
    8e02b2a Allow --file in image-create with v2 Image API
    d5a0e65 Add useful error on invalid --os-image-api-version
    49f38a4 Add release notes for 0.14.0 - 0.14.2
    5080d10 Send `identity_headers` through the wire
    d0851c3 Remove readonly options from v2 shell commands
    4194a55 Add --property-filter option to v2 image-list
    ef0abdc Fix py34 failure for glance client
    8c159a2 Don't set X-Auth-Token key in http session header if no token provided
    b83a672 Refactor method of constructing dicts in some tests
    751e064 Adds tty password entry for glanceclient
    597da8a '--public' ignored on image create
    cbbfbc9 Fix to ensure endpoint_type is used by _get_endpoint()
    12a3a82 Add bash completion to glance client

Change-Id: I24fbba80831c311b42d1abb08487cc29c8b5b162
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/79/140079/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,6e8a7eb442c018bbec1bdb3e93f56ad94f402085,0.15.0-release-notes,0.14.3 ------ * Add bash completion to glance client. The new bash completion files are stored in `tools/glance.bash_completion` * Add tty password entry. This prompts for a password if neither --os-password nor OS_PASSWORD have been set * Add the --property-filter option from the v1 client to v2 image-list. This allows you to do something similar to::: $ glance --os-image-api-version 2 image-list --property-filter os_distro=NixOS * 1324067_: Allow --file flag in v2 image-create. This selects a local disk image to upload during the creation of the image * 1395841_: Output a useful error on an invalid --os-image-api-version argument * 1394965_: Add `identity_headers` back into the request headers * 1350802_: Remove read only options from v2 shell commands. The options omitted are - `created_at` - `updated_at` - `file` - `checksum` - `virtual_size` - `size` - `status` - `schema` - `direct_url` * 1381295_: Stop setting X-Auth-Token key in http session header if there is no token provided * 1378844_: Fix '--public' being ignored on image-create * 1367782_: Fix to ensure endpoint_type is used by _get_endpoint() .. _1324067: https://bugs.launchpad.net/python-glanceclient/+bug/1324067 .. _1395841: https://bugs.launchpad.net/python-glanceclient/+bug/1395841 .. _1394965: https://bugs.launchpad.net/python-glanceclient/+bug/1394965 .. _1350802: https://bugs.launchpad.net/python-glanceclient/+bug/1350802 .. _1381295: https://bugs.launchpad.net/python-glanceclient/+bug/1381295 .. _1378844: https://bugs.launchpad.net/python-glanceclient/+bug/1378844 .. _1367782: https://bugs.launchpad.net/python-glanceclient/+bug/1367782 ,,37,0
openstack%2Fnova-specs~master~I21b0100b34b475ac40c0d590affafda6627b65a0,openstack/nova-specs,master,I21b0100b34b475ac40c0d590affafda6627b65a0,"(Re)Propose ""Add DB2 as an option for backend database""",MERGED,2014-12-11 16:46:47.000000000,2014-12-11 20:42:14.000000000,2014-12-11 20:42:13.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-12-11 16:46:47.000000000', 'files': ['specs/kilo/approved/db2-database.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ea08644e90efb680f1eeba5731d01315b12e8d6f', 'message': '(Re)Propose ""Add DB2 as an option for backend database""\n\nPreviously-approved: juno\n\nSpec for blueprint db2-database\n\nChange-Id: I21b0100b34b475ac40c0d590affafda6627b65a0\n'}]",1,141097,ea08644e90efb680f1eeba5731d01315b12e8d6f,7,3,1,6873,,,0,"(Re)Propose ""Add DB2 as an option for backend database""

Previously-approved: juno

Spec for blueprint db2-database

Change-Id: I21b0100b34b475ac40c0d590affafda6627b65a0
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/97/141097/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/db2-database.rst'],1,ea08644e90efb680f1eeba5731d01315b12e8d6f,bp/db2-database,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Add Support for DB2 (v10.5+) ============================ https://blueprints.launchpad.net/nova/+spec/db2-database The community currently supports MySQL and PostgreSQL production databases. Several other integrated projects already support DB2. This blueprint adds support to Nova for DB2 as a production database. Problem description =================== * Currently there is no support in the community for a deployer to run Nova against a DB2 backend database. * For anyone running applications against an existing DB2 database that wants to move to OpenStack, they'd have to use a different database engine to run Nova in OpenStack. * There is currently an inconsistent support matrix across the core projects since the majority of core projects support DB2 but Nova does not yet. Use Cases --------- As a deployer, I want to run Nova against a DB2 backend database so I can use a single DB2 database engine for multiple integrated OpenStack services. Project Priority ---------------- None, however, most of the other integrated projects in OpenStack already support a DB2 backend database or are working toward that. The integrated projects that currently support DB2 today: * Ceilometer * Cinder * Glance * Heat * Keystone * Neutron The integrated projects that do not yet have DB2 support: * Ironic * Sahara * Trove Also, oslo.db has DB2 support. Proposed change =============== Add code to support migrating the Nova database against a DB2 backend. This would require a fresh deployment of Nova since there are no plans to migrate an existing Nova database from another engine, e.g. MySQL to DB2. Unit test code would also be updated to support running tests against a DB2 backend with the ibm_db_sa driver and all Nova patches will be tested against a Tempest full run with 3rd party CI running DB2 that IBM will maintain. There is already some code in Oslo's db.api layer to support common function with DB2 like duplicate entry error handling and connection trace, so that is not part of this spec. Alternatives ------------ Deployers can use other supported database backends like MySQL or PostgreSQL, but this may not be an ideal option for customers already running applications with DB2 that want to integrate with OpenStack. In addition, you could run other core projects with multiple schemas in a single DB2 OpenStack database, but you'd have to run Nova separately which is a maintenance/configuration problem. Data model impact ----------------- #. The 216 migration will be updated to handle conditions with DB2 like index and foreign key creation. The main issue here is that DB2 does not support unique constraints over nullable columns, it will instead create a unique index that excludes null keys. Most unique constraints created in Nova are on non-nullable columns, but the instances.uuid column is nullable and the 216 migration creates a unique index on it, but this will not allow any foreign keys on the instances.uuid column to be created with DB2 since the reference column has to be a unique or primary key constraint. #. In order to support creating the same foreign keys that reference the instances.uuid column as other database engines, the instances.uuid column must be made non-nullable and a unique constraint must be created on it. The dependent blueprint ""Enforce unique instance uuid in data model"" is used to handle this change. #. Finally, add another migration script which creates the previously excluded foreign keys from the 216 migration script for DB2. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ The only performance impact on existing deployments is in the migration script changes which would be tested with turbo-hipster. Other deployer impact --------------------- The new database migration which creates the missing foreign keys since the control node needs to be down when running the migration. However, the new migration only creates foreign keys if the backend is DB2, which would be a new installation as noted in the `Proposed change`_ section so the impact should be minimal. Developer impact ---------------- The only impact on developers is if they are adding DB API code or migrations that do not work with DB2 they will have to adjust those appropriately, just like we do today with MySQL and PostgreSQL. IBM active technical contributors would provide support/guidance on issues like this which require specific conditions for DB2, although for the most part the DB2 InfoCenter provides adequate detail on how to work with the engine and provides details on error codes. * DB2 SQL error message explanations can be found here: http://pic.dhe.ibm.com/infocenter/db2luw/v10r5/index.jsp?topic=%2Fcom.ibm.db2.luw.messages.sql.doc%2Fdoc%2Frsqlmsg.html * Information on developing with DB2 using python can be found here: http://pic.dhe.ibm.com/infocenter/db2luw/v10r5/index.jsp?topic=%2Fcom.ibm.swg.im.dbclient.python.doc%2Fdoc%2Fc0054366.html * Main contacts for DB2 questions in OpenStack: * Matt Riedemann (mriedem@us.ibm.com) - Nova core member * Brant Knudson (bknudson@us.ibm.com) - Keystone core member * Jay Bryant (jsbryant@us.ibm.com) - Cinder core member * Rahul Priyadarshi (rahul.priyadarshi@in.ibm.com) - ibm_db_sa maintainer * The DB2 CI wiki page also provides contact information for issues with third party testing failures: https://wiki.openstack.org/wiki/IBM/DB2-TEST Implementation ============== Assignee(s) ----------- Primary assignee: mriedem@us.ibm.com Work Items ---------- #. Change the 216 migration to work with DB2. #. Add a new migration to create the excluded foreign keys from the 216 script for DB2. #. Make the test_migrations.py module work with a configured DB2 backend for running unit tests. See the WIP patch for details: https://review.openstack.org/#/c/69047/ Dependencies ============ * Blueprint ""Enforce unique instance uuid in data model"" (completed in Kilo): https://blueprints.launchpad.net/nova/+spec/enforce-unique-instance-uuid-in-db * DB2 10.5 support was added to sqlalchemy-migrate 0.9 during Icehouse: https://blueprints.launchpad.net/sqlalchemy-migrate/+spec/add-db2-support * There are no requirements changes in Nova for the unit tests to work. The runtime requirements are the ibm-db-sa and ibm_db modules, which are both available from pypi. sqlalchemy-migrate optionally imports ibm-db-sa. The ibm-db-sa module requires a natively compiled ibm_db which has the c binding that talks to the DB2 ODBC/CLI driver. * Note that only DB2 10.5+ is supported since that's what added unique index support over nullable columns which is how sqlalchemy-migrate handles unique constraints over nullable columns. Testing ======= There are three types of testing requirements, Tempest, unit test and turbo-hipster performance/scale tests. Each have different timelines for when they are proposed to be implemented. * IBM is already running 3rd party CI for DB2 on the existing Nova WIP patch that adds DB2 support. The same 3rd party CI is running against all sqlalchemy-migrate changes with DB2 on py26/py27 and runs Tempest against Keystone/Glance/Cinder/Heat/Neutron patches with a DB2 backend. Once the DB2 support is merged the DB2 3rd party CI would run against all Nova patches with a full Tempest run. This is considered required testing for this blueprint to merge in the Kilo release. * While code will be added to make the Nova unit tests work against a DB2 backend, running Nova unit tests against DB2 with third party CI is not considered in the scope of this blueprint for Kilo, but long-term this is something IBM wants to get running for additional QA coverage for DB2 in Nova. This is something that would be worked on after getting Tempest running. The plan for delivering third party unit test coverage is in the 2015.2 'L' release. * Running 3rd party turbo-hipster CI against DB2 is not in plan for this blueprint in Kilo but like running unit tests against DB2 in 3rd party CI, running turbo-hipster against DB2 in 3rd party CI would be a long-term goal for QA and the IBM team will work on that after Tempest is running and after unit test CI is worked on. The plan for delivering third party turbo-hipster performance test coverage is in the 2015.2 'L' release. * The proposed penalty for failing to deliver third party unit test and/or turbo-hipster performance test coverage in the L release is that the Nova team will turn off voting/reporting of DB2 third party CI and not allow DB2 fixes to Nova until the third party CI is available. * More discussion in the mailing list here: http://lists.openstack.org/pipermail/openstack-dev/2014-May/035009.html Documentation Impact ==================== * The install guides in the community do not go into specifics about setting up the database. The RHEL/Fedora install guide says to use the openstack-db script provided by openstack-utils in RDO which uses MySQL. The other install guides just say that SQLite3, MySQL and PostgreSQL are widely used databases. So for the install guides, those generic statements about supported databases would be updated to add DB2 to the list. Similar generic statements are also made in the following places which would be updated as well: * http://docs.openstack.org/training-guides/content/developer-getting-started.html * http://docs.openstack.org/admin-guide-cloud/content/compute-service.html * http://docs.openstack.org/trunk/openstack-ops/content/cloud_controller_design.html * There are database topics in the security guide, chapters 32-34, so there would be DB2 considerations there as well, specifically: * http://docs.openstack.org/security-guide/content/ch041_database-backend-considerations.html * http://docs.openstack.org/security-guide/content/ch042_database-overview.html * http://docs.openstack.org/security-guide/content/ch043_database-transport-security.html References ========== * Work in progress nova patch: https://review.openstack.org/#/c/69047/ * ""Enforce unique instance uuid in data model"" spec: http://specs.openstack.org/openstack/nova-specs/specs/kilo/approved/enforce-unique-instance-uuid-in-db.html * There are Chef cookbooks on stackforge which support configuring OpenStack to run with an existing DB2 installation: http://git.openstack.org/cgit/stackforge/cookbook-openstack-common/ * Mailing list thread on third party testing: http://lists.openstack.org/pipermail/openstack-dev/2014-May/035009.html * DB2 10.5 InfoCenter: http://pic.dhe.ibm.com/infocenter/db2luw/v10r5/index.jsp * Some older manual setup instructions for DB2 with OpenStack: http://www.ibm.com/developerworks/cloud/library/cl-openstackdb2/index.html * ibm-db-sa: https://code.google.com/p/ibm-db/source/clones?repo=ibm-db-sa * DB2 Third Party CI Wiki: https://wiki.openstack.org/wiki/IBM/DB2-TEST ",,295,0
openstack%2Fsahara~master~I947e06a21722a992a2747939dbb1c54405b998f7,openstack/sahara,master,I947e06a21722a992a2747939dbb1c54405b998f7,Update oslo-incubator log,MERGED,2014-12-04 18:42:05.000000000,2014-12-11 20:38:54.000000000,2014-12-11 17:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-04 18:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fa1c9730f2ea932e40ae8beb015f5fcfd2168872', 'message': 'Update oslo-incubator log\n\nChanges -\n * Make use_syslog=True log to syslog via /dev/log\n * Import PublishErrorsHandler from oslo.messaging\n * add list_opts to all modules with configuration options\n * Delete graduated serialization files\n * Remove code that moved to oslo.i18n\n * Switch oslo-incubator to use oslo.utils and remove old modules\n * log: add missing space in error message\n\nChange-Id: I947e06a21722a992a2747939dbb1c54405b998f7\n'}, {'number': 2, 'created': '2014-12-04 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dd4f6b6f9d293220e8eed715f36774c9868e8437', 'message': 'Update oslo-incubator log\n\nChanges -\n * Make use_syslog=True log to syslog via /dev/log\n * Import PublishErrorsHandler from oslo.messaging\n * add list_opts to all modules with configuration options\n * Delete graduated serialization files\n * Remove code that moved to oslo.i18n\n * Switch oslo-incubator to use oslo.utils and remove old modules\n * log: add missing space in error message\n\nChange-Id: I947e06a21722a992a2747939dbb1c54405b998f7\n'}, {'number': 3, 'created': '2014-12-05 17:53:18.000000000', 'files': ['sahara/openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c4daf9cb720b4a370cb35666f4009be60389c603', 'message': 'Update oslo-incubator log\n\nChanges -\n * Make use_syslog=True log to syslog via /dev/log\n * Import PublishErrorsHandler from oslo.messaging\n * add list_opts to all modules with configuration options\n * Delete graduated serialization files\n * Remove code that moved to oslo.i18n\n * Switch oslo-incubator to use oslo.utils and remove old modules\n * log: add missing space in error message\n\nChange-Id: I947e06a21722a992a2747939dbb1c54405b998f7\n'}]",0,139148,c4daf9cb720b4a370cb35666f4009be60389c603,31,11,3,7555,,,0,"Update oslo-incubator log

Changes -
 * Make use_syslog=True log to syslog via /dev/log
 * Import PublishErrorsHandler from oslo.messaging
 * add list_opts to all modules with configuration options
 * Delete graduated serialization files
 * Remove code that moved to oslo.i18n
 * Switch oslo-incubator to use oslo.utils and remove old modules
 * log: add missing space in error message

Change-Id: I947e06a21722a992a2747939dbb1c54405b998f7
",git fetch https://review.opendev.org/openstack/sahara refs/changes/48/139148/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/log.py'],1,fa1c9730f2ea932e40ae8beb015f5fcfd2168872,,"import copy def list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(common_cli_opts)), (None, copy.deepcopy(logging_cli_opts)), (None, copy.deepcopy(generic_log_opts)), (None, copy.deepcopy(log_opts)), ] handler = importutils.import_object( ""oslo.messaging.notify.log_handler.PublishErrorsHandler"", logging.ERROR) syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility)"," try: handler = importutils.import_object( ""sahara.openstack.common.log_handler.PublishErrorsHandler"", logging.ERROR) except ImportError: handler = importutils.import_object( ""oslo.messaging.notify.log_handler.PublishErrorsHandler"", logging.ERROR) syslog = RFCSysLogHandler(facility=facility) else: syslog = logging.handlers.SysLogHandler(facility=facility)",18,10
openstack%2Fmagnum~master~If69557b7ca02e48c65372cbb200d2f648613778e,openstack/magnum,master,If69557b7ca02e48c65372cbb200d2f648613778e,Remove conductor,MERGED,2014-12-11 20:04:12.000000000,2014-12-11 20:38:50.000000000,2014-12-11 20:38:49.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 20:04:12.000000000', 'files': ['magnum/conductor/handlers/default.py', 'magnum/conductor/api.py', 'magnum/conductor/config.py', 'setup.cfg', 'magnum/cmd/conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/54411f6265d5ab27ebb14087ccd00464763dca2a', 'message': 'Remove conductor\n\nRemove conductor.  The backend will replace the conductor as the process\nname to be more consistent with other OpenStack projects.\n\nChange-Id: If69557b7ca02e48c65372cbb200d2f648613778e\n'}]",0,141149,54411f6265d5ab27ebb14087ccd00464763dca2a,6,2,1,2834,,,0,"Remove conductor

Remove conductor.  The backend will replace the conductor as the process
name to be more consistent with other OpenStack projects.

Change-Id: If69557b7ca02e48c65372cbb200d2f648613778e
",git fetch https://review.opendev.org/openstack/magnum refs/changes/49/141149/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/default.py', 'magnum/conductor/api.py', 'magnum/conductor/config.py', 'setup.cfg', 'magnum/cmd/conductor.py']",5,54411f6265d5ab27ebb14087ccd00464763dca2a,,,"# Copyright 2014 - Rackspace Hosting # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Starter script for the Magnum Conductor service."""""" import logging as std_logging import os import sys from oslo.config import cfg from magnum.common.rpc import service from magnum.conductor.handlers import default as default_handler from magnum.openstack.common._i18n import _ from magnum.openstack.common import log as logging LOG = logging.getLogger(__name__) def main(): cfg.CONF(sys.argv[1:], project='magnum') logging.setup('magnum') LOG.info(_('Starting server in PID %s') % os.getpid()) LOG.debug(""Configuration:"") cfg.CONF.log_opt_values(LOG, std_logging.DEBUG) cfg.CONF.import_opt('topic', 'magnum.conductor.config', group='conductor') cfg.CONF.import_opt('host', 'magnum.conductor.config', group='conductor') endpoints = [ default_handler.Handler(), ] server = service.Service(cfg.CONF.conductor.topic, cfg.CONF.conductor.host, endpoints) server.serve() ",0,250
openstack%2Fnova-specs~master~Iabafb517f3410e4e441462645c62f5e0c24591ed,openstack/nova-specs,master,Iabafb517f3410e4e441462645c62f5e0c24591ed,Adds content for Compute API v2.0,ABANDONED,2014-10-23 14:16:04.000000000,2014-12-11 20:29:36.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-10-23 14:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b4e24958f404e861c0eb39abe073304b984e2f7d', 'message': 'Adds content for Compute API v2.0\n\n- This content should match the code as it has been around for 3 years.\n- Separating the content from the framework.\n\nChange-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed\n'}, {'number': 2, 'created': '2014-10-25 04:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b266cb59be532a3cf0c8c6ef8ddde14f2f73bf5d', 'message': 'Adds content for Compute API v2.0\n\n- This content should match the code as it has been around for 3 years.\n- Separating the content from the framework.\n\nChange-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed\n'}, {'number': 3, 'created': '2014-10-25 04:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fd1040dc0e168de2683ead7b10b112901785fb64', 'message': 'Adds content for Compute API v2.0\n\n- This content should match the code as it has been around for 3 years.\n- Separating the content from the framework.\n\nChange-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed\n'}, {'number': 4, 'created': '2014-10-25 15:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5920a7b74c791359c0fd355f7d473df5cde26265', 'message': 'Adds content for Compute API v2.0\n\n- This content should match the code as it has been around for 3 years.\n- Separating the content from the framework.\n\nChange-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed\n'}, {'number': 5, 'created': '2014-11-10 20:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cc6e93d2515c76045c04611f178e0dbbe2136090', 'message': 'Adds content for Compute API v2.0\n\n- Bug tracking shows this is accurate as all the doc bugs\nare against the extensions, see https://bugs.launchpad.net/\nopenstack-api-site/+bugs/?field.tag=compute-api\n- Separating the content from the framework.\n\nChange-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed\n'}, {'number': 6, 'created': '2014-11-11 20:23:57.000000000', 'files': ['specs/v2.0-api/compute_api_v2.0_paginated_collections.rst', 'specs/v2.0-api/compute_api_v2.0_polling_changes-since_parameter.rst', 'specs/v2.0-api/compute_api_v2.0_faults.rst', 'doc/source/conf.py', 'specs/v2.0-api/compute_api_v2.0_general_info.rst', 'specs/v2.0-api/compute_api_v2.0_request_and_response_formats.rst', 'specs/v2.0-api/compute_api_v2.0_versions.rst', 'doc/source/index.rst', 'specs/v2.0-api/compute_api_v2.0_server_concepts.rst', 'specs/v2.0-api/compute_api_v2.0_authentication.rst', 'specs/v2.0-api/compute_api_v2.0_extensions.rst', 'specs/v2.0-api/compute_api_v2.0_links_and_references.rst', 'specs/v2.0-api/compute_api_v2.0_limits.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3fc84791a42dc53f1c1ccadc2adc7c1562ef9603', 'message': 'Adds content for Compute API v2.0\n\n- Bug tracking shows this is accurate as all the doc bugs\nare against the extensions, see https://bugs.launchpad.net/\nopenstack-api-site/+bugs/?field.tag=compute-api\n- Separating the content from the framework.\n\nChange-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed\n'}]",4,130550,3fc84791a42dc53f1c1ccadc2adc7c1562ef9603,18,4,6,964,,,0,"Adds content for Compute API v2.0

- Bug tracking shows this is accurate as all the doc bugs
are against the extensions, see https://bugs.launchpad.net/
openstack-api-site/+bugs/?field.tag=compute-api
- Separating the content from the framework.

Change-Id: Iabafb517f3410e4e441462645c62f5e0c24591ed
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/50/130550/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/api/v2.0/juno-template.rst', 'specs/api/v2.0/request_and_response_formats.rst', 'specs/api/v2.0/links_and_references.rst', 'specs/api/v2.0/versions.rst', 'specs/api/v2.0/server_concepts.rst', 'specs/api/v2.0/faults.rst', 'specs/api/v2.0/compute_api_v2_general_info.rst', 'specs/api/v2.0/kilo-template.rst', 'specs/api/v2.0/limits.rst', 'specs/api/v2.0/efficient_polling_with_the_changes-since_parameter.rst', 'specs/api/v2.0/extensions.rst', 'specs/api/v2.0/authentication.rst', 'specs/api/v2.0/paginated_collections.rst']",13,b4e24958f404e861c0eb39abe073304b984e2f7d,nova-api-v2-content,"===================== Paginated collections ===================== To reduce load on the service, list operations return a maximum number of items at a time. The maximum number of items returned is determined by the compute provider. To navigate the collection, the *``limit``* and *``marker``* parameters can be set in the URI. For example: .. code:: ?limit=100&marker=1234 The *``marker``* parameter is the ID of the last item in the previous list. Items are sorted by create time in descending order. When a create time is not available they are sorted by ID. The *``limit``* parameter sets the page size. Both parameters are optional. If the client requests a *``limit``* beyond that which is supported by the deployment an overLimit (413) fault may be thrown. A marker with an invalid ID returns a badRequest (400) fault. For convenience, collections are required to contain atom ``next`` links. They may optionally also contain ``previous`` links. The last page in the list does not contain a ""next"" link. The following examples illustrate three pages in a collection of images. The first page was retrieved through a **GET** to ``http://servers.api.openstack.org/v2/1234/images?limit=1``. In these examples, the *``limit``* parameter sets the page size to a single item. Subsequent links honor the initial page size. Thus, a client can follow links to traverse a paginated collection without having to input the *``marker``* parameter. **Example 1.12. Images collection: XML (first page)** .. code:: <?xml version=""1.0"" encoding=""UTF-8""?> <images xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:atom=""http://www.w3.org/2005/Atom""> <image id=""52415800-8b69-11e0-9b19-734f6f006e54"" name=""CentOS 5.2""> <atom:link rel=""self"" href=""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" /> </image> <atom:link rel=""next"" href=""http://servers.api.openstack.org/v2/1234/images?limit=1&amp;marker=52415800-8b69-11e0-9b19-734f6f006e54"" /> </images> | **Example 1.13. Images collection: JSON (first page)** .. code:: { ""images"": [ { ""id"": ""52415800-8b69-11e0-9b19-734f6f006e54"", ""name"": ""CentOS 5.2"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" } ] } ], ""images_links"" : [ { ""rel"": ""next"", ""href"": ""http://servers.api.openstack.org/v2/1234/images?limit=1&marker=52415800-8b69-11e0-9b19-734f6f006e54"" } ] } | **Example 1.14. Images collection: XML (second page)** .. code:: <?xml version=""1.0"" encoding=""UTF-8""?> <images xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:atom=""http://www.w3.org/2005/Atom""> <image id=""52415800-8b69-11e0-9b19-734f5736d2a2"" name=""My Server Backup""> <atom:link rel=""self"" href=""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f5736d2a2""/> </image> <atom:link rel=""next"" href=""http://servers.api.openstack.org/v2/1234/images?limit=1&amp;marker=52415800-8b69-11e0-9b19-734f5736d2a2"" /> </images> | **Example 1.15. Images collection: JSON (second page)** .. code:: { ""images"" : [ { ""id"" : ""52415800-8b69-11e0-9b19-734f5736d2a2"", ""name"" : ""My Server Backup"", ""links"": [ { ""rel"" : ""self"", ""href"" : ""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f5736d2a2"" } ] } ], ""images_links"": [ { ""rel"" : ""next"", ""href"" : ""http://servers.api.openstack.org/v2/1234/images?limit=1&marker=52415800-8b69-11e0-9b19-734f5736d2a2"" } ] } | **Example 1.16. Images collection: XML (last page)** .. code:: <?xml version=""1.0"" encoding=""UTF-8""?> <images xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:atom=""http://www.w3.org/2005/Atom""> <image id=""52415800-8b69-11e0-9b19-734f6ff7c475"" name=""Backup 2""> <atom:link rel=""self"" href=""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6ff7c475"" /> </image> </images> | **Example 1.17. Images collection: JSON (last page)** .. code:: { ""images"": [ { ""id"": ""52415800-8b69-11e0-9b19-734f6ff7c475"", ""name"": ""Backup 2"", ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6ff7c475"" } ] } ] } | In JSON, members in a paginated collection are stored in a JSON array named after the collection. A JSON object may also be used to hold members in cases where using an associative array is more practical. Properties about the collection itself, including links, are contained in an array with the name of the entity an underscore (\_) and ``links``. The combination of the objects and arrays that start with the name of the collection and an underscore represent the collection in JSON. The approach allows for extensibility of paginated collections by allowing them to be associated with arbitrary properties. It also allows collections to be embedded in other objects as illustrated below. Here, a subset of metadata items are presented within the image. Clients must follow the ""next"" link to retrieve the full set of metadata. **Example 1.18. Paginated image metadata: XML** .. code:: <?xml version=""1.0"" encoding=""UTF-8""?> <image xmlns=""http://docs.openstack.org/compute/api/v1.1"" xmlns:atom=""http://www.w3.org/2005/Atom"" id=""52415800-8b69-11e0-9b19-734f6f006e54"" name=""CentOS 5.2""> <metadata> <meta key=""ImageVersion"">1.5</meta> <meta key=""ImageType"">Gold</meta> <atom:link rel=""next"" href=""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6f006e54/meta?marker=ImageType"" /> </metadata> <atom:link rel=""self"" href=""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" /> </image> | **Example 1.19. Paginated image metadata: JSON** .. code:: { ""image"": { ""id"": ""52415800-8b69-11e0-9b19-734f6f006e54"", ""name"": ""CentOS 5.2"", ""metadata"": { ""ImageVersion"": ""1.5"", ""ImageType"": ""Gold"" }, ""metadata_links"": [ { ""rel"": ""next"", ""href"": ""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6f006e54/meta?marker=ImageType"" } ], ""links"": [ { ""rel"": ""self"", ""href"": ""http://servers.api.openstack.org/v2/1234/images/52415800-8b69-11e0-9b19-734f6f006e54"" } ] } } | ",,2579,0
openstack%2Fnova-specs~master~I203629aa003b508f9e31e34d0949d75da5ced884,openstack/nova-specs,master,I203629aa003b508f9e31e34d0949d75da5ced884,Adds descriptive framework for Compute API specs,ABANDONED,2014-10-17 16:51:45.000000000,2014-12-11 20:29:10.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 964}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5292}, {'_account_id': 6547}, {'_account_id': 6864}]","[{'number': 1, 'created': '2014-10-17 16:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4e552d68c11dff6dac36590bc03a594761345cfd', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\nRefer to the blueprint for docs:\nhttps://wiki.openstack.org/wiki/Blueprint-os-api-docs#BLUEPRINT:_API_References_.28specs.29_.28move_to_project_specs_repos.29\n\nBuild automation coming as well; just wanting to be sure this info\nmakes sense in these files.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 2, 'created': '2014-10-17 19:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4df2b779d2b2af0481d3c35f5dd453013c4a9c05', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 3, 'created': '2014-10-17 20:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/346c0ac4d939cd627277d179db581bc6775f06bc', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 4, 'created': '2014-10-17 20:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/173c29d251c46383b3d844fd6c2a076ed5777803', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 5, 'created': '2014-10-17 20:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/331b55467d9b76e6a611965f471857a58dea71de', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 6, 'created': '2014-10-17 20:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5f74612bf59ab64b5160f8d560e32aae76a7e2dd', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 7, 'created': '2014-10-17 21:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2b32f5a4be545408d8de3e13fb3e37a7110fee01', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 8, 'created': '2014-10-17 22:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0b4dcd15812e0c7e033faf6d2309d2f463df8b06', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 9, 'created': '2014-10-18 00:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2bfe795d7b34c14ac339e4d55822aa713286efe5', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 10, 'created': '2014-10-18 01:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5c87357cbfe2ac94b4b6fa001b6b1813749535b8', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 11, 'created': '2014-10-18 01:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/582cb52753ee1322a29c281ee941c3a915257683', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 12, 'created': '2014-10-18 21:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/27afd8f1c0aad9f9422398306fd9423acd0eb0b2', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 13, 'created': '2014-10-18 23:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/752af9c2ef2bf1037a8a93839fbc2f12d21a14d4', 'message': 'Adds Compute v2 API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 14, 'created': '2014-10-22 13:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fad90212e4b8b6c386d06fd1c97a2b3f815269a5', 'message': 'Adds descriptive framework for Compute API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nWill send subsequent patches with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 15, 'created': '2014-10-23 14:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e6d59e144f3a7a631a7b176a8673e7cedd59ff1f', 'message': 'Adds descriptive framework for Compute API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nWill send subsequent patches with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 16, 'created': '2014-10-25 04:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a911a38259285e94fe87abf9d55e4934f0047e8d', 'message': 'Adds descriptive framework for Compute API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nWill send subsequent patches with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 17, 'created': '2014-10-28 00:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9106b161905b981826b6c822babf7a66417bd9b6', 'message': 'Adds descriptive framework for Compute API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nWill send subsequent patches with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 18, 'created': '2014-11-10 20:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3eef553cfaae8349c49ce8bc1dda090743fef303', 'message': 'Adds descriptive framework for Compute API specification information in general\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nWill send subsequent patches with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 19, 'created': '2014-11-10 20:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4c930d45a212b8ce42f1fadd780011368b7433a5', 'message': 'Adds descriptive framework for Compute API specs\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nDependent patch https://review.openstack.org/#/c/130550/ with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 20, 'created': '2014-11-11 20:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0145965b811bd723fae498aef8f627469110b4c0', 'message': 'Adds descriptive framework for Compute API specs\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nDependent patch https://review.openstack.org/#/c/130550/ with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}, {'number': 21, 'created': '2014-11-11 20:21:08.000000000', 'files': ['specs/api-template.rst', '.gitignore', 'tests/test_titles.py', 'README.rst', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fe37b92c232d40aa942008e99b64b5666f6a859d', 'message': 'Adds descriptive framework for Compute API specs\n\nGoal is to start maintaining API specs in the specs repos for each project\nto eliminate maintenance of <project>-api repos.\n\nDependent patch https://review.openstack.org/#/c/130550/ with content.\n\nChange-Id: I203629aa003b508f9e31e34d0949d75da5ced884\n'}]",16,129329,fe37b92c232d40aa942008e99b64b5666f6a859d,66,8,21,964,,,0,"Adds descriptive framework for Compute API specs

Goal is to start maintaining API specs in the specs repos for each project
to eliminate maintenance of <project>-api repos.

Dependent patch https://review.openstack.org/#/c/130550/ with content.

Change-Id: I203629aa003b508f9e31e34d0949d75da5ced884
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/29/129329/18 && git format-patch -1 --stdout FETCH_HEAD,"['specs/api/links_and_references.rst', 'specs/api/limits.rst', 'specs/api/paginated_collections.rst', 'specs/api/request_and_response_formats.rst', 'specs/api/extensions.rst', 'specs/api/server_concepts.rst', 'specs/api/versions.rst', 'specs/api/authentication.rst', 'specs/api/faults.rst', 'specs/api/compute_api_general_info.rst', 'specs/api/efficient_polling_with_the_changes-since_parameter.rst']",11,4e552d68c11dff6dac36590bc03a594761345cfd,nova-api-v2-content,"================================================== Efficient polling with the Changes-Since parameter ================================================== The ReST API allows you to poll for the status of certain operations by performing a **GET** on various elements. Rather than re-downloading and re-parsing the full status at each polling interval, your ReST client may use the *``changes-since``* parameter to check for changes since a previous request. The *``changes-since``* time is specified as an `ISO 8601 <http://en.wikipedia.org/wiki/ISO_8601>`__ dateTime (2011-01-24T17:08Z). The form for the timestamp is CCYY-MM-DDThh:mm:ss. An optional time zone may be written in by appending the form hh:mm which describes the timezone as an offset from UTC. When the timezone is not specified (2011-01-24T17:08), the UTC timezone is assumed. If nothing has changed since the *``changes-since``* time, an empty list is returned. If data has changed, only the items changed since the specified time are returned in the response. For example, performing a **GET** against https://api.servers.openstack.org/v2/224532/servers?\ *``changes-since``*\ =2011-01-24T17:08Z would list all servers that have changed since Mon, 24 Jan 2011 17:08:00 UTC. To allow clients to keep track of changes, the changes-since filter displays items that have been *recently* deleted. Both images and servers contain a ``DELETED`` status that indicates that the resource has been removed. Implementations are not required to keep track of deleted resources indefinitely, so sending a changes since time in the distant past may miss deletions. ",,1936,0
openstack%2Fnova-specs~master~I92c20913c11476722f2ab79233352bafb9705bfd,openstack/nova-specs,master,I92c20913c11476722f2ab79233352bafb9705bfd,Add soft policies for server-group feature,MERGED,2014-12-08 14:27:52.000000000,2014-12-11 20:23:34.000000000,2014-12-11 20:23:33.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5754}, {'_account_id': 6772}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-08 14:27:52.000000000', 'files': ['specs/kilo/approved/soft-affinity-for-server-group.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fbdbed180df4fe9b01dd4e5053ac8fdda4f897f9', 'message': 'Add soft policies for server-group feature\n\nThis spec describes the need and a possible implementation\nof soft-affinty and soft-anti-affinty policies for the\nserver group feature.\n\nbp soft-affinity-for-server-group\nChange-Id: I92c20913c11476722f2ab79233352bafb9705bfd\n'}]",1,140017,fbdbed180df4fe9b01dd4e5053ac8fdda4f897f9,9,7,1,9708,,,0,"Add soft policies for server-group feature

This spec describes the need and a possible implementation
of soft-affinty and soft-anti-affinty policies for the
server group feature.

bp soft-affinity-for-server-group
Change-Id: I92c20913c11476722f2ab79233352bafb9705bfd
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/17/140017/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/soft-affinity-for-server-group.rst'],1,fbdbed180df4fe9b01dd4e5053ac8fdda4f897f9,bp/soft-affinity-for-server-group,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Add soft affinity support for server group ============================================= https://blueprints.launchpad.net/nova/+spec/soft-affinity-for-server-group As a tenant I would like to schedule instances on the same host if possible, so that I can achieve collocation. However if it is not possible to schedule some instance to the same host then I still want that the subsequent instances are scheduled together on another host. In this way I can express a good-to-have relationship between a group of instances. As a tenant I would like to schedule instances on different hosts if possible. However if it is not possible I still want my instances to be scheduled even if it means that some of them are placed on a host where another instances are running from the same group. Problem description =================== Use Cases ---------- End User might want to have a less strict affinity and anti-affinity rule than what is today available in server-group API extension. With the proposed good-to-have affinity rule the End User can request nova to schedule the instance to the same host if possible. However if it is not possible (e.g. due to resource limitations) then End User still wants to keep the instances on a small amount of different host. With the proposed good-to-have anti-affinity rule the End User can request nova to spread the instances in the same group as much as possible. Project Priority ----------------- Not a priority in kilo Proposed change =============== This change would extend the existing server-group API extension with two new policies soft-affinity and soft-anti-affinity. When a instance is booted into a group with soft-affinity policy the scheduler will use a new weight AffinityWeight to sort the available hosts according to the number of instances running on them from the same server-group in a descending order. When an instance is booted into a group with soft-anti-affinity policy the scheduler will use a new weight AntiAffinityWeight to sort the available hosts according to the number of instances running on them from the same server-group in a ascending order. The two new weights will get the necessary information about the number of instances per host through the weight_properties (filter_properties) in a similar way as the GroupAntiAffinityFilter gets the list of hosts used by a group via the filter_properties. These new soft-affinity and soft-anti-affinity policies are mutually exclusive with each other and with the other existing server-group policies. If the scheduler sees a request which requires any of the new weigh classes but those classes are not configured then the scheduler will reject the request with an exception similarly to the case when affinity policy is requested but ServerGroupAffinityFilter is not configured. Alternatives ------------ Alternatively End User can use the server-group with affinity policy and if the instance cannot be scheduled because the host associated to the group is full then End User can create a new server-group for the subsequent instances. However with large amount of instances that occupy many hosts this manual process can become quite cumbersome. Data model impact ----------------- No schema change is needed. There will be two new possible values soft-affinity and soft-anti-affinity for the policy column of the instance_group_policy table. REST API impact --------------- POST: v2/{tenant-id}/os-server-groups The value of the policy request parameter can be soft-affinity and soft-anti-affinity as well. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: balazs-gibizer Work Items ---------- * Add two new weights to the filter scheduler. These weights will sort the available hosts by the number of instances from the same server-group. * Update FilterScheduler to use to reject the request if the new policy is requested but the related weigh is not configured * Update the server-group API extension to allow soft-affinity and soft-anti-affinity as the policy of a group. Dependencies ============ None Testing ======= Unit test coverage will be provided. New tempest test case will be provided that will try to boot two servers into the same server group with soft-anti-affinity policy. The boot shall be successful even if we have only one compute host. Documentation Impact ==================== New weights need to be described in filter_scheduler.rst References ========== * instance-group-api-extension BP https://blueprints.launchpad.net/nova/+spec/instance-group-api-extension * Group API wiki https://wiki.openstack.org/wiki/GroupApiExtension ",,173,0
openstack%2Ftrove~master~Ife30227ffa4b1107273d62a89526cf306d870092,openstack/trove,master,Ife30227ffa4b1107273d62a89526cf306d870092,Updated from global requirements,MERGED,2014-12-09 14:40:01.000000000,2014-12-11 20:19:36.000000000,2014-12-11 20:19:35.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 8214}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-12-09 14:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9dddb95582a7cc0f448420f4e72ec3dfaeb0a609', 'message': 'Updated from global requirements\n\nChange-Id: Ife30227ffa4b1107273d62a89526cf306d870092\n'}, {'number': 2, 'created': '2014-12-11 07:21:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/fd0966935e5ac5007560d0032f7dee1fe5f660dc', 'message': 'Updated from global requirements\n\nChange-Id: Ife30227ffa4b1107273d62a89526cf306d870092\n'}]",0,140345,fd0966935e5ac5007560d0032f7dee1fe5f660dc,13,4,2,11131,,,0,"Updated from global requirements

Change-Id: Ife30227ffa4b1107273d62a89526cf306d870092
",git fetch https://review.opendev.org/openstack/trove refs/changes/45/140345/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9dddb95582a7cc0f448420f4e72ec3dfaeb0a609,openstack/requirements,oslo.utils>=1.0.0 # Apache-2.0,oslo.utils>=1.0.0,1,1
openstack%2Fnova-specs~master~I9f9a5d48b1203c619b2e9033a9b65934811c996f,openstack/nova-specs,master,I9f9a5d48b1203c619b2e9033a9b65934811c996f,Change select_destinations() to use request spec,MERGED,2014-10-10 18:14:12.000000000,2014-12-11 20:17:20.000000000,2014-12-11 20:17:19.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 1849}, {'_account_id': 1981}, {'_account_id': 2271}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 7664}]","[{'number': 1, 'created': '2014-10-10 18:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dd46ae0b384f3ac0e1c7cbbe7eae20e4abd5f5c2', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 2, 'created': '2014-10-13 16:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1a4968f783703fe444be0612b25d51c8d5005d05', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 3, 'created': '2014-10-13 16:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bc7bfd8a8ce6fd0116a46f8c4c7abde061b153e2', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 4, 'created': '2014-10-13 16:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9a83e6e257f3984c0a77beb4fd3d480e039895b3', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 5, 'created': '2014-10-13 17:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/93aafb9cb5dc57530892067193a762e24ab137b9', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 6, 'created': '2014-10-13 20:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e918c6bc0aac43fa23fa43e551bee9288e7b3590', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 7, 'created': '2014-10-14 00:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3192930a58b501451bdf3110205c274a517d7010', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 8, 'created': '2014-10-14 00:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9368a7dd89404b6821b672520ed6078137077da0', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 9, 'created': '2014-11-11 09:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/25243bce28d1c93959f5c3b044ad7c38deed2031', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 10, 'created': '2014-11-11 14:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6a13d96349448812ad138b1ad46520503b372721', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 11, 'created': '2014-11-17 15:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/44e023f4a2d813a5c24888c3efda88b37895a9bb', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 12, 'created': '2014-11-19 10:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2e66ecd01ab9d410cd93e96205cb70a157909342', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object'}, {'number': 13, 'created': '2014-11-19 10:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2784185aaea27f8cddd1fe20fad4ffe43ec10376', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 14, 'created': '2014-11-20 15:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/76802ba1be964312f1111eeb606ecd6031eafc5c', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 15, 'created': '2014-11-21 21:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/fab8bf484770115da6675dd382c84a28dcc8e487', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 16, 'created': '2014-11-26 17:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/63e59ef2a698fe88ed70a457759ee8b68a540e12', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 17, 'created': '2014-11-26 17:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5cc6ee24938ea92ed8c5ee87df5ddadda466467e', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}, {'number': 18, 'created': '2014-12-11 20:09:33.000000000', 'files': ['specs/kilo/approved/sched-select-destinations-use-request-spec-object.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ce03343c2b0680c3fa79b9926100537f5e199eea', 'message': 'Change select_destinations() to use request spec\n\nSpecification to change the `select_destinations()` scheduler RPC API\nmethod to use a `nova.objects.request_spec.RequestSpec` object instead\nof a nested dict.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\n\nChange-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f\nBlueprint: sched-select-destinations-use-request-spec-object\n'}]",8,127612,ce03343c2b0680c3fa79b9926100537f5e199eea,59,11,18,7,,,0,"Change select_destinations() to use request spec

Specification to change the `select_destinations()` scheduler RPC API
method to use a `nova.objects.request_spec.RequestSpec` object instead
of a nested dict.

Co-Authored-By: Sylvain Bauza <sbauza@redhat.com>

Change-Id: I9f9a5d48b1203c619b2e9033a9b65934811c996f
Blueprint: sched-select-destinations-use-request-spec-object
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/12/127612/18 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/sched-select-destinations-use-request-spec-object.rst'],1,dd46ae0b384f3ac0e1c7cbbe7eae20e4abd5f5c2,bp/sched-select-destinations-use-request-spec-object,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================================ Change select_destinations() scheduler RPC API method to pass RequestSpec object ================================================================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/sched-select-destinations-use-request-spec-object Change the `select_destinations()` scheduler RPC API method to use a `nova.objects.request_spec.RequestSpec` object instead of a nested dict. Problem description =================== The main interface into the scheduler, the `select_destinations()` method, accepts a `request_spec` parameter that is a nested dict. This nested dict is constructed in `nova.scheduler.utils.build_request_spec()`, which is called by nova-conductor before asking the scheduler to find compute nodes on which to put one or more requested virtual machine instances. Previous blueprints have introduced a `nova.objects.request_spec.RequestSpec` object that can model the entire request for multiple instance launches. However, the scheduler RPC API has not been changed to use this new object. Instead, nova-scheduler constructs the `RequestSpec` object Use Cases ---------- Nova contributors wish to extend the functionality of the scheduler and intend to break the scheduler out into the Gantt project. In order to do this effectively, the internal interfaces around the resource tracker and the scheduler must be cleaned up to use structured objects. Project Priority ----------------- Falls under the technical debt reduction category. Proposed change =============== A new class called `RequestSpec` will be created that models a request to launch multiple virtual machine instances. The first version of the `RequestSpec` object will simply be an objectified version of the current dictionary parameter. The scheduler will construct this `RequestSpec` object from the `request_spec` dictionary itself. The existing `nova.scheduler.utils.build_request_spec` method will be removed in favor of a factory method on `nova.scheduler.request_spec.RequestSpec` that will construct a `RequestSpec` from the existing key/value pairs in the `request_spec` parameter supplied to `select_destinations`. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None, besides making the scheduler call interfaces gradually easier to read and understand. Implementation ============== Assignee(s) ----------- Primary assignee: jaypipes Implementation ============== We will increment the version of the scheduler RPC API and insert translation blocks in the `select_destinations` method to handle an older nova-conductor node sending the old-style dictionary `request_spec` parameter to a newer nova-scheduler node that expects a `RequestSpec` object. The nova-conductor manager code will then be updated to construct a `RequestSpec` object to pass to the `select_destinations()` scheduler RPC API instead of calling `nova.scheduler.utils.build_request_spec()`. The `build_request_spec()` method will then be removed. The code added in the `request-spec-objects` blueprint that constructed a `RequestSpec` object in the `FilterScheduler._schedule()` method will then be removed, as it will no longer be needed since the `request_spec` parameter will already be an object. Assignee(s) ----------- Primary assignee: jaypipes Work Items ---------- - Increment the scheduler RPC API `select_destinations()` method to take a `RequestSpec` object instead of a dictionary for the `request_spec` parameter. In the same patch, modify the conductor manager to construct a `RequestSpec` object and pass that to `select_destinations()` instead of dict. Remove the code in filter_scheduler.FilterScheduler._schedule() that constructs a `RequestSpec` object, since the object is now being passed to `select_destinations()` - Remove the `nova.scheduler.utils.build_request_spec` function. Dependencies ============ This blueprint is dependent on the completion of the following blueprints: - `request-spec-object` Testing ======= New unit tests for the request spec objects will be added. The existing unit tests of the scheduler will be overhauled in the patch set that converts the filters to use the new request_spec object model instead of its current free-form `filter_properties` dictionary of things. Documentation Impact ==================== Developer reference material that explains the new placement spec class will be delivered as a part of this blueprint. References ========== This blueprint is part of an overall effort to clean up, version, and stabilize the interfaces between the nova-api, nova-scheduler, nova-conductor and nova-compute daemons that involve scheduling and resource decisions. Blueprints involved in this effort include: - `detach-service-from-computenode` - `resource-objects` - `request-spec-object` - `sched-select-destinations-use-request-spec-object` <-- this blueprint - `placement-spec-object` - `condition-objects` - `sched-placement-spec-use-resource-objects` - `sched-placement-spec-use-condition-objects` - `sched-get-placement-claims` ",,190,0
openstack%2Fcinder~stable%2Fjuno~Ifba55616dfd634f9186d336e45f2e7e0179fe7a8,openstack/cinder,stable/juno,Ifba55616dfd634f9186d336e45f2e7e0179fe7a8,EE-53 Changed SSH findHost to REST based queryHost,ABANDONED,2014-12-11 17:28:05.000000000,2014-12-11 20:12:38.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-11 17:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15e62ea45f92c880677dce4645a7cf4d565cb2bc', 'message': 'EE-53 Changed SSH findHost to REST based queryHost\n\nThe SSH findHost call was failing after the session key expired and\nany attach/detach fould fail after that.\nThis patch uses the REST based queryHost that has built in retries\nif the session key has expired.\n\nCloses-Bug: EE-53\nUpstream-Ref: https://review.openstack.org/138212/\n\nChange-Id: Ifba55616dfd634f9186d336e45f2e7e0179fe7a8\n'}, {'number': 2, 'created': '2014-12-11 20:11:33.000000000', 'files': ['cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8d75ab9bd9b09f684de6c563fe2c235bec0e74fb', 'message': 'EE-53 Changed SSH findHost to REST based queryHost\n\nThe SSH findHost call was failing after the session key expired and\nany attach/detach fould fail after that.\nThis patch uses the REST based queryHost that has built in retries\nif the session key has expired.\n\nCloses-Bug: EE-53\nUpstream-Ref: https://review.openstack.org/138212/\nChange-Id: Ifba55616dfd634f9186d336e45f2e7e0179fe7a8\n'}]",0,141106,8d75ab9bd9b09f684de6c563fe2c235bec0e74fb,4,1,2,6043,,,0,"EE-53 Changed SSH findHost to REST based queryHost

The SSH findHost call was failing after the session key expired and
any attach/detach fould fail after that.
This patch uses the REST based queryHost that has built in retries
if the session key has expired.

Closes-Bug: EE-53
Upstream-Ref: https://review.openstack.org/138212/
Change-Id: Ifba55616dfd634f9186d336e45f2e7e0179fe7a8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/06/141106/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py']",3,15e62ea45f92c880677dce4645a7cf4d565cb2bc,hp/stable/2.0," mock_client.queryHost.return_value = { 'members': [{ 'name': self.FAKE_HOST }] } mock_client.queryHost.return_value = None mock.call.queryHost(wwns=['123456789012345', '123456789054321']), mock_client.queryHost.return_value = { 'members': [{ 'name': 'fakehost.foo' }] } mock.call.queryHost(wwns=['123456789012345', '123456789054321']), mock_client.queryHost.return_value = { 'members': [{ 'name': self.FAKE_HOST }] } mock.ANY, mock_client.queryHost.return_value = None mock.call.queryHost(iqns=['iqn.1993-08.org.debian:01:222']), mock_client.queryHost.return_value = None mock.call.queryHost(iqns=['iqn.1993-08.org.debian:01:222']), mock_client.queryHost.return_value = { 'members': [{ 'name': 'fakehost.foo' }] } mock.call.queryHost(iqns=['iqn.1993-08.org.debian:01:222']), mock_client.queryHost.return_value = { 'members': [{ 'name': 'fakehost.foo' }] } mock.call.queryHost(iqns=['iqn.1993-08.org.debian:01:222']),"," mock_client.findHost.return_value = self.FAKE_HOST mock_client.findHost.return_value = None mock.call.findHost(wwn='123456789012345'), mock.call.findHost(wwn='123456789054321'), mock_client.findHost.return_value = 'fakehost.foo' mock.call.findHost(wwn='123456789012345'), mock_client.findHost.return_value = self.FAKE_HOST mock.call.findHost(iqn='iqn.1993-08.org.debian:01:222'), mock_client.findHost.return_value = None mock.call.findHost(iqn='iqn.1993-08.org.debian:01:222'), mock_client.findHost.return_value = None mock.call.findHost(iqn='iqn.1993-08.org.debian:01:222'), mock_client.findHost.return_value = 'fakehost.foo' mock.call.findHost(iqn='iqn.1993-08.org.debian:01:222'), mock_client.findHost.return_value = 'fakehost.foo' mock.call.findHost(iqn='iqn.1993-08.org.debian:01:222'),",53,24
openstack%2Foslo.concurrency~master~I3abea460f228517807b0462e683ca56d9f971d6e,openstack/oslo.concurrency,master,I3abea460f228517807b0462e683ca56d9f971d6e,Updated from global requirements,MERGED,2014-12-10 17:36:20.000000000,2014-12-11 20:11:19.000000000,2014-12-11 20:11:17.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6601}, {'_account_id': 6873}, {'_account_id': 8574}]","[{'number': 1, 'created': '2014-12-10 17:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/53f8c99d437e2dd83af63d852f5b36371972a3e6', 'message': 'Updated from global requirements\n\nChange-Id: I3abea460f228517807b0462e683ca56d9f971d6e\n'}, {'number': 2, 'created': '2014-12-11 07:19:22.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/deb0152cbc53639079b6baa3ad9a62e0fe5a8e2f', 'message': 'Updated from global requirements\n\nChange-Id: I3abea460f228517807b0462e683ca56d9f971d6e\n'}]",0,140780,deb0152cbc53639079b6baa3ad9a62e0fe5a8e2f,10,5,2,11131,,,0,"Updated from global requirements

Change-Id: I3abea460f228517807b0462e683ca56d9f971d6e
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/80/140780/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,53f8c99d437e2dd83af63d852f5b36371972a3e6,openstack/requirements,"retrying>=1.2.3,!=1.3.0 # Apache-2.0","retrying>=1.2.2,!=1.3.0 # Apache-2.0",2,2
openstack%2Fpython-keystoneclient~master~I310b618dc066c8405da6ffd9a28baf8754b3399c,openstack/python-keystoneclient,master,I310b618dc066c8405da6ffd9a28baf8754b3399c,Add an example script for role_assignments module,ABANDONED,2014-06-03 19:15:57.000000000,2014-12-11 20:04:38.000000000,,"[{'_account_id': 3}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 11045}, {'_account_id': 11333}, {'_account_id': 11387}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-06-03 19:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/8662f989ab8d48ed18a572a61b31c89bfc83b02f', 'message': 'Add example script for role_assignments module\n\nAdd a python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}, {'number': 2, 'created': '2014-06-05 13:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/59a66853e4c5fefeb79e59f9a4d7722e6f864fbc', 'message': 'Add example script for role_assignments module\n\nAdd a python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}, {'number': 3, 'created': '2014-06-11 18:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/4b683af657dc94d62ace90cced83457e91ca7bed', 'message': 'Add example script for role_assignments module\n\nAdd a python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}, {'number': 4, 'created': '2014-06-11 19:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b8321eb9e7b0f228ffb5d9bd08659ac9f09d0c95', 'message': 'Add example script for role_assignments module\n\nAdd a python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}, {'number': 5, 'created': '2014-06-11 20:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d7c2e07499192e90acab30a38e705f985cc6ceb3', 'message': 'Add example script for role_assignments module\n\nAdd a python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}, {'number': 6, 'created': '2014-06-16 02:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/91c180b01b081aebb0b03f2cdec027c2bb880d90', 'message': 'Add an example script for role_assignments module\n\nAdd a python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}, {'number': 7, 'created': '2014-09-18 21:53:32.000000000', 'files': ['examples/scripts/exercise_v3_role_assignments.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/720caee045aac6ae58ffd856e40909827170dd55', 'message': 'Add an example script for role_assignments module\n\nAdd a Python script to illustrate how to use\nthe role_assignments module.\n\nChange-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c\n'}]",16,97600,720caee045aac6ae58ffd856e40909827170dd55,46,10,7,11022,,,0,"Add an example script for role_assignments module

Add a Python script to illustrate how to use
the role_assignments module.

Change-Id: I310b618dc066c8405da6ffd9a28baf8754b3399c
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/00/97600/6 && git format-patch -1 --stdout FETCH_HEAD,['examples/scripts/exercise_v3_role_assignments.py'],1,8662f989ab8d48ed18a572a61b31c89bfc83b02f,role_assignments_example,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import uuid from keystoneclient.v3 import client """""" This script illustrates the usage of the role assignments module. It depends on an admin role, project, user and group. For more information about the role assignments module, check the keystoneclient Modules page: http://docs.openstack.org/developer/python-keystoneclient/api/\ keystoneclient.v3.html#module-keystoneclient.v3.role_assignments """""" try: # Used for creating the ADMIN user OS_PASSWORD = os.environ['OS_PASSWORD'] OS_USERNAME = os.environ['OS_USERNAME'] OS_AUTH_URL = os.environ['OS_AUTH_URL'] OS_PROJECT_NAME = os.environ['OS_PROJECT_NAME'] OS_DOMAIN_NAME = os.environ['OS_DOMAIN_NAME'] except KeyError as e: raise SystemExit('%s environment variable not set.' % e.message) def client_for_admin_user(): return client.Client(auth_url=OS_AUTH_URL, username=OS_USERNAME, password=OS_PASSWORD, project_name=OS_PROJECT_NAME, project_domain_name=OS_DOMAIN_NAME) def create_project(client, name, domain): try: p = client.projects.create(name=name, domain=domain) except: p = client.projects.find(name=name) return p def create_user(client, name, password, default_project, domain): try: u = client.users.create(name=name, password=password, default_project=default_project, domain=domain) except: u = client.users.find(name=name) return u def create_group(client, name, domain): try: g = client.groups.create(name=name, domain=domain) except Exception: g = client.groups.find(name=name) return g def initialize(): print('Creating Client based on Admin Username and Password') client = client_for_admin_user() print('\nCreating Projects') proj1 = create_project(client, uuid.uuid4().hex, OS_DOMAIN_NAME) print('proj1: id=%s' % proj1.id) proj2 = create_project(client, uuid.uuid4().hex, OS_DOMAIN_NAME) print('proj2: id=%s' % proj2.id) print('\nCreating Users') user1 = create_user(client, uuid.uuid4().hex, uuid.uuid4().hex, proj1, OS_DOMAIN_NAME) print('user1: id=%s' % user1.id) user2 = create_user(client, uuid.uuid4().hex, uuid.uuid4().hex, proj2, OS_DOMAIN_NAME) print('user2: id=%s' % user2.id) print('\nCreating Group') group1 = create_group(client, uuid.uuid4().hex, OS_DOMAIN_NAME) print('group1: id=%s' % group1.id) print('\nGrant roles at projects') print('Assigning Member role to user1 at proj1') client.roles.grant(client.roles.find(name='Member'), user=user1, project=proj1) print('Assigning Member role to user2 at proj1') client.roles.grant(client.roles.find(name='Member'), user=user2, project=proj1) print('Assigning Member role to group1 at proj1') client.roles.grant(client.roles.find(name='Member'), group=group1, project=proj1) print('Assigning Member role to user2 at proj2') client.roles.grant(client.roles.find(name='Member'), user=user2, project=proj2) print('\nList proj1 Role Assignments') print(client.assignments.list(project=proj1)) print('\nList proj2 Role Assignments') print(client.assignments.list(project=proj2)) print('\nList proj1 and user1 Role Assignments') print(client.assignments.list(project=proj1, user=user1)) print('\nList proj1 effective Role Assignments') print(client.assignments.list(project=proj1, effective=True)) print('\nList user2 Role Assignments') print(client.assignments.list(user=user2)) print('\nDeleting created Projects, Users and Group') client.projects.delete(proj1) client.projects.delete(proj2) client.users.delete(user1) client.users.delete(user2) if __name__ == '__main__': initialize() ",,135,0
openstack%2Fsolum~master~I2d097e6689d3cba7f1dbb997cafd559ef2625d93,openstack/solum,master,I2d097e6689d3cba7f1dbb997cafd559ef2625d93,Fix missing config options,ABANDONED,2014-10-13 20:34:32.000000000,2014-12-11 19:57:49.000000000,,"[{'_account_id': 3}, {'_account_id': 1375}]","[{'number': 1, 'created': '2014-10-13 20:34:32.000000000', 'files': ['etc/solum/solum.conf.sample'], 'web_link': 'https://opendev.org/openstack/solum/commit/df853c9f8fa162aa1eff7cd4b276101937be34b7', 'message': 'Fix missing config options\n\nSome config options were missing from upstream components\n\nChange-Id: I2d097e6689d3cba7f1dbb997cafd559ef2625d93\n'}]",0,128092,df853c9f8fa162aa1eff7cd4b276101937be34b7,4,2,1,7770,,,0,"Fix missing config options

Some config options were missing from upstream components

Change-Id: I2d097e6689d3cba7f1dbb997cafd559ef2625d93
",git fetch https://review.opendev.org/openstack/solum refs/changes/92/128092/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/solum/solum.conf.sample'],1,df853c9f8fa162aa1eff7cd4b276101937be34b7,config_fix,# (optional) number of seconds memcached server is considered # dead before it is tried again. (integer value) #memcache_pool_dead_retry=300 # (optional) max total number of open connections to every # memcached server. (integer value) #memcache_pool_maxsize=10 # (optional) socket timeout in seconds for communicating with # a memcache server. (integer value) #memcache_pool_socket_timeout=3 # (optional) number of seconds a connection to memcached is # held unused in the pool before it is closed. (integer value) #memcache_pool_unused_timeout=60 # (optional) number of seconds that an operation will wait to # get a memcache client connection from the pool. (integer # value) #memcache_pool_conn_get_timeout=10 # (optional) use the advanced (eventlet safe) memcache client # pool. The advanced pool will only work under python 2.x. # (boolean value) #memcache_use_advanced_pool=false ,,26,0
openstack%2Fmagnum~master~Ifefaa25297d9737e8644948f4faed9c0abea6b38,openstack/magnum,master,Ifefaa25297d9737e8644948f4faed9c0abea6b38,Rename the test_functional.py to the api,MERGED,2014-12-11 19:45:40.000000000,2014-12-11 19:51:39.000000000,2014-12-11 19:51:38.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 19:45:40.000000000', 'files': ['magnum/tests/api/controllers/v1/__init__.py', 'magnum/tests/api/controllers/__init__.py', 'magnum/tests/api/__init__.py', 'magnum/tests/api/controllers/v1/test_all_objects.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/34886de0ae7939e95d2cbfde1a98c00868540c16', 'message': 'Rename the test_functional.py to the api\n\nThis test case really only unit tests the ReST API.  So rename it as such.\n\nThis file probably needs to be split into the separate objects in the tree.\n\nChange-Id: Ifefaa25297d9737e8644948f4faed9c0abea6b38\n'}]",0,141143,34886de0ae7939e95d2cbfde1a98c00868540c16,6,2,1,2834,,,0,"Rename the test_functional.py to the api

This test case really only unit tests the ReST API.  So rename it as such.

This file probably needs to be split into the separate objects in the tree.

Change-Id: Ifefaa25297d9737e8644948f4faed9c0abea6b38
",git fetch https://review.opendev.org/openstack/magnum refs/changes/43/141143/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/api/controllers/v1/__init__.py', 'magnum/tests/api/controllers/__init__.py', 'magnum/tests/api/__init__.py', 'magnum/tests/api/controllers/v1/test_all_objects.py']",4,34886de0ae7939e95d2cbfde1a98c00868540c16,,,,0,0
openstack%2Frequirements~master~I6b9f05a2c2c6512a113d8fcf13e2d54addd03658,openstack/requirements,master,I6b9f05a2c2c6512a113d8fcf13e2d54addd03658,tooz was missing from projects.txt,ABANDONED,2014-12-11 05:17:41.000000000,2014-12-11 19:48:45.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-12-11 05:17:41.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b5be94be1515089b096c378416542f7f46fb0a5b', 'message': 'tooz was missing from projects.txt\n\nWe need to enable requirements check for tooz, so adding it to\nthe projects list.\n\nChange-Id: I6b9f05a2c2c6512a113d8fcf13e2d54addd03658\n'}]",0,140922,b5be94be1515089b096c378416542f7f46fb0a5b,6,3,1,5638,,,0,"tooz was missing from projects.txt

We need to enable requirements check for tooz, so adding it to
the projects list.

Change-Id: I6b9f05a2c2c6512a113d8fcf13e2d54addd03658
",git fetch https://review.opendev.org/openstack/requirements refs/changes/22/140922/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,b5be94be1515089b096c378416542f7f46fb0a5b,,openstack/tooz,,1,0
openstack%2Fmagnum~master~I384994584ad7f928df9366a2e6f677951a450e40,openstack/magnum,master,I384994584ad7f928df9366a2e6f677951a450e40,Add RPC backend service,MERGED,2014-12-06 20:15:53.000000000,2014-12-11 19:48:04.000000000,2014-12-11 19:48:02.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 8580}]","[{'number': 1, 'created': '2014-12-06 20:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/af56d29b6a58e6c1c6a5e32ff58ac708d822e5a5', 'message': 'Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 2, 'created': '2014-12-06 21:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b690996c356107c5668528269ece4b4e6f19f868', 'message': 'Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 3, 'created': '2014-12-06 21:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4dc75fec5c393a8d67686a966ed2ed8c9624fd4a', 'message': 'Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 4, 'created': '2014-12-06 21:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b18d7a86a3bbabb62855d5770ec786f9d76329d5', 'message': 'Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 5, 'created': '2014-12-06 21:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0f9d1f76e884279d3bfd9a52e62d185b0c4d24f3', 'message': 'Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 6, 'created': '2014-12-06 21:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7abf39a0de895549848cc8e6a7fed94f5e53a07a', 'message': ""Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nAdding eventlet.sleep(0) to the following line in oslo.messaging gets\nthis patch to work.  I'm sure sure why.  If reviewers have ideas, I'd\nlove to know ;-)\n\nhttps://github.com/openstack/oslo.messaging/blob/master/oslo/messaging/_executors/impl_eventlet.py#L92\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n""}, {'number': 7, 'created': '2014-12-07 00:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2503fd2b0d9ffeb9059381af81531511132b9eba', 'message': ""Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nAdding eventlet.sleep(0) to the following line in oslo.messaging gets\nthis patch to work.  I'm sure sure why.  If reviewers have ideas, I'd\nlove to know ;-)\n\nhttps://github.com/openstack/oslo.messaging/blob/master/oslo/messaging/_executors/impl_eventlet.py#L92\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n""}, {'number': 8, 'created': '2014-12-07 00:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/535cc118e608b65bddcc1319b10f31a139476179', 'message': ""Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nAdding eventlet.sleep(0) to the following line in oslo.messaging gets\nthis patch to work.  I'm sure sure why.  If reviewers have ideas, I'd\nlove to know ;-)\n\nhttps://github.com/openstack/oslo.messaging/blob/master/oslo/messaging/_executors/impl_eventlet.py#L92\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n""}, {'number': 9, 'created': '2014-12-07 00:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/88baa66deab56311332a3215a247488b571f601b', 'message': ""Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nAdding eventlet.sleep(0) to the following line in oslo.messaging gets\nthis patch to work.  I'm sure sure why.  If reviewers have ideas, I'd\nlove to know ;-)\n\nhttps://github.com/openstack/oslo.messaging/blob/master/oslo/messaging/_executors/impl_eventlet.py#L92\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n""}, {'number': 10, 'created': '2014-12-07 04:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c9ae099495856c71a10ff1e8f9d69274d48afdf5', 'message': ""Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nAdding eventlet.sleep(0) to the following line in oslo.messaging gets\nthis patch to work.  I'm not sure why.  If reviewers have ideas, I'd\nlove to know ;-)\n\nhttps://github.com/openstack/oslo.messaging/blob/master/oslo/messaging/_executors/impl_eventlet.py#L92\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n""}, {'number': 11, 'created': '2014-12-07 04:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8173f6d91d385a4d76b2ebbc0ce1fe8724250542', 'message': ""Add RPC backend service\n\nThe RPC backend service uses significant amounts of code design copy from\nironic to implement an RPC backend.\n\nAdding eventlet.sleep(0) to the following line in oslo.messaging gets\nthis patch to work.  I'm not sure why.  If reviewers have ideas, I'd\nlove to know ;-)\n\nhttps://github.com/openstack/oslo.messaging/blob/master/oslo/messaging/_executors/impl_eventlet.py#L92\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n""}, {'number': 12, 'created': '2014-12-10 18:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7f7789fe3a8e78ac14c4b84b388787c69138f9c8', 'message': 'Add RPC backend service\n\nThis uses a simplified RPC model while integrating with the\nversioned objects serializer.\n\nbay-create is handled by the backend.\nbay-list is handled by the RPC service.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 13, 'created': '2014-12-10 20:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a4609e84d630bf2a3bb36b520256305f8ac1596d', 'message': 'Add RPC backend service\n\nThis uses a simplified RPC model while integrating with the\nversioned objects serializer.\n\nbay-create is handled by the backend.\nbay-list is handled by the RPC service.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 14, 'created': '2014-12-10 20:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ea1ff6a8072da7be37538f842ac2da6f03a7102a', 'message': 'Add RPC backend service\n\nThis uses a simplified RPC model while integrating with the\nversioned objects serializer.\n\nbay-create is handled by the backend.\nbay-list is handled by the RPC service.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 15, 'created': '2014-12-11 19:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e9888ceb17371c3e0e567485444edc4e700afa7d', 'message': 'Add RPC backend service\n\nThis uses a simplified RPC model while integrating with the\nversioned objects serializer.\n\nbay-create is handled by the backend.\nbay-list is handled by the RPC service.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}, {'number': 16, 'created': '2014-12-11 19:30:54.000000000', 'files': ['magnum/cmd/backend.py', 'magnum/backend/manager.py', 'magnum/backend/handlers/docker.py', 'magnum/tests/test_functional.py', 'magnum/backend/handlers/bay_heat.py', 'magnum/api/controllers/v1/bay.py', 'magnum/backend/handlers/bay_ironic.py', 'magnum/common/rpc_service.py', 'magnum/backend/api.py', 'magnum/backend/handlers/k8s.py', 'magnum/common/service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6349b4e3847fbf3f074fb6c089d3a126f596d054', 'message': 'Add RPC backend service\n\nThis uses a simplified RPC model while integrating with the\nversioned objects serializer.\n\nbay-create is handled by the backend.\nbay-list is handled by the RPC service.\n\nChange-Id: I384994584ad7f928df9366a2e6f677951a450e40\n'}]",2,139834,6349b4e3847fbf3f074fb6c089d3a126f596d054,36,4,16,2834,,,0,"Add RPC backend service

This uses a simplified RPC model while integrating with the
versioned objects serializer.

bay-create is handled by the backend.
bay-list is handled by the RPC service.

Change-Id: I384994584ad7f928df9366a2e6f677951a450e40
",git fetch https://review.opendev.org/openstack/magnum refs/changes/34/139834/9 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/cmd/backend.py', 'magnum/backend/manager.py', 'magnum/api/controllers/v1/__init__.py', 'magnum/api/controllers/v1/bay.py', 'magnum/backend/api.py']",5,af56d29b6a58e6c1c6a5e32ff58ac708d822e5a5,,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg from oslo import messaging from magnum.common import rpc from magnum import objects from magnum.objects import base as objects_base rpcapi_opts = [ cfg.StrOpt('backend_topic', default='magnum_backend', help='The topic backends nodes listen on'), ] CONF = cfg.CONF CONF.register_opts(rpcapi_opts) rpcapi_cap_opt = cfg.StrOpt('backend', help='Set a version cap for messages sent to compute services. If you ' 'plan to do a live upgrade from havana to icehouse, you should ' 'set this option to ""icehouse-compat"" before beginning the live ' 'upgrade procedure.') CONF.register_opt(rpcapi_cap_opt, 'upgrade_levels') class BayAPI(object): def list(self, context, limit, marker, sort_key, sort_dir): """"""List all bays."""""" return objects.Bay.list(context, limit, marker, sort_key, sort_dir) class BackendAPI(object): """"""Client side of the backend API"""""" VERSION_ALIASES = { 'kilo': '1.0' } def __init__(self): super(BackendAPI, self).__init__() target = messaging.Target(topic=cfg.CONF.backend_topic, version='1.0') version_cap = self.VERSION_ALIASES.get(CONF.upgrade_levels.backend, CONF.upgrade_levels.backend) version_cap = '1.0' serializer = objects_base.MagnumObjectSerializer() self.client = self.get_client(target, version_cap, serializer) def get_client(self, target, version_cap, serializer): return rpc.get_client(target, version_cap=version_cap, serializer=serializer) def create_bay(self, ctxt, bay): """"""Create a bay."""""" version = '1.0' cctxt = self.client.prepare(version=version) return cctxt.call(ctxt, 'create_bay', bay=bay) ",,193,34
openstack%2Fopenstack-manuals~master~I89ddbf8f418e27f5768a002ee8999e08dde887bf,openstack/openstack-manuals,master,I89ddbf8f418e27f5768a002ee8999e08dde887bf,Fixes an error for common client named OpenStack (not common),MERGED,2014-12-04 13:57:55.000000000,2014-12-11 19:42:43.000000000,2014-12-11 19:32:50.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-04 13:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f60ed8745babb191a51d186d1f6cf4274f19ea05', 'message': 'Fixes an error for common client named OpenStack (not common)\n\nChange-Id: I89ddbf8f418e27f5768a002ee8999e08dde887bf\n'}, {'number': 2, 'created': '2014-12-11 16:25:20.000000000', 'files': ['doc/common/section_cli_install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dce3a06f49cf191771adbe60b5881adb1e51a4cd', 'message': 'Fixes an error for common client named OpenStack (not common)\n\nChange-Id: I89ddbf8f418e27f5768a002ee8999e08dde887bf\n'}]",1,139058,dce3a06f49cf191771adbe60b5881adb1e51a4cd,13,4,2,964,,,0,"Fixes an error for common client named OpenStack (not common)

Change-Id: I89ddbf8f418e27f5768a002ee8999e08dde887bf
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/58/139058/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_cli_install.xml'],1,f60ed8745babb191a51d186d1f6cf4274f19ea05,commonclient, <para><literal>openstack</literal> - Common OpenStack client supporting multiple services</para> <para>The following example shows the command for installing the nova client with <replaceable>pip</replaceable>.</para>, <para><literal>common</literal> - Common OpenStack client </para> <para>The following example shows the command for installing the nova client with <replaceable>pip</replaceable>.</para>,4,5
openstack%2Fopenstack-manuals~stable%2Ficehouse~I051317cbf7768253f63c72666734be90a7fb8e87,openstack/openstack-manuals,stable/icehouse,I051317cbf7768253f63c72666734be90a7fb8e87,Added admin_token deprecation notice in the Identity management section,MERGED,2014-12-11 02:44:14.000000000,2014-12-11 19:32:39.000000000,2014-12-11 19:32:38.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 10497}]","[{'number': 1, 'created': '2014-12-11 02:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a38a6f8a714f083f2c113400ad029aad3b8d5f3a', 'message': 'Added admin_token deprecation notice in the Identity management section\n\nCherry-pick changes in http://review.openstack.org/#/c/138240/1 for stable/juno\n\nChange-Id: I051317cbf7768253f63c72666734be90a7fb8e87\nbackport: none\nCloses-Bug: #131191\n'}, {'number': 2, 'created': '2014-12-11 02:45:37.000000000', 'files': ['doc/admin-guide-cloud/ch_identity_mgmt.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4a4e294bccb1dbe86755bc14b112ef9b8a2c340d', 'message': 'Added admin_token deprecation notice in the Identity management section\n\nCherry-pick changes in http://review.openstack.org/#/c/138240/1 for stable/juno\n\nChange-Id: I051317cbf7768253f63c72666734be90a7fb8e87\nbackport: none\nCloses-Bug: #1313191\n'}]",0,140900,4a4e294bccb1dbe86755bc14b112ef9b8a2c340d,9,4,2,10705,,,0,"Added admin_token deprecation notice in the Identity management section

Cherry-pick changes in http://review.openstack.org/#/c/138240/1 for stable/juno

Change-Id: I051317cbf7768253f63c72666734be90a7fb8e87
backport: none
Closes-Bug: #1313191
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/00/140900/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/ch_identity_mgmt.xml'],1,a38a6f8a714f083f2c113400ad029aad3b8d5f3a,admintoken_juno/darren," <option>admin_password</option> options.</para> <note><para>The <option>admin_token</option> parameter is deprecated, and no longer used for configuring auth_token middleware.</para></note>"," <option>admin_password</option> options. When using the <option>admin_user</option> and <option>admin_password</option> options the <option>admin_token</option> parameter is optional. If <option>admin_token</option> is specified, it is used only if the specified token is still valid.</para>",3,6
openstack%2Fmagnum~master~Ia8b757d5bbe477c2de09b65f35409847fd1623c3,openstack/magnum,master,Ia8b757d5bbe477c2de09b65f35409847fd1623c3,Add bay uuid to Service Objects,MERGED,2014-12-11 17:41:45.000000000,2014-12-11 19:26:41.000000000,2014-12-11 19:26:40.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6924}]","[{'number': 1, 'created': '2014-12-11 17:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/13e588767e3b1c526cc687a687ea15cc32325431', 'message': 'Add bay uuid to Service Objects\n\nChange-Id: Ia8b757d5bbe477c2de09b65f35409847fd1623c3\n'}, {'number': 2, 'created': '2014-12-11 19:19:44.000000000', 'files': ['magnum/objects/service.py', 'magnum/db/sqlalchemy/api.py', 'magnum/db/sqlalchemy/alembic/versions/2581ebaf0cb2_initial_migration.py', 'magnum/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/71458fb8ea775646219daacf7908d6277ccdb812', 'message': 'Add bay uuid to Service Objects\n\nChange-Id: Ia8b757d5bbe477c2de09b65f35409847fd1623c3\n'}]",1,141111,71458fb8ea775646219daacf7908d6277ccdb812,10,3,2,6924,,,0,"Add bay uuid to Service Objects

Change-Id: Ia8b757d5bbe477c2de09b65f35409847fd1623c3
",git fetch https://review.opendev.org/openstack/magnum refs/changes/11/141111/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/objects/service.py', 'magnum/db/sqlalchemy/api.py', 'magnum/db/sqlalchemy/models.py']",3,13e588767e3b1c526cc687a687ea15cc32325431,service_bay,class ServiceObject(Base): bay_uuid = Column(String(36)),class AbrviceObject(Base):,22,1
openstack%2Fdiskimage-builder~master~I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a,openstack/diskimage-builder,master,I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a,Rework package-installs to collapse on build host,MERGED,2014-12-10 18:22:34.000000000,2014-12-11 19:21:46.000000000,2014-12-11 19:21:45.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 12092}]","[{'number': 1, 'created': '2014-12-10 18:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6de00ae1d320a31e565cd6e6b927fafc01dc7a25', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}, {'number': 2, 'created': '2014-12-10 20:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d3a95a9df97d987617305691cbe04b6583d755e4', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}, {'number': 3, 'created': '2014-12-10 20:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b39b5b980fe3f2a1f87228d3863f4550a13b81b2', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}, {'number': 4, 'created': '2014-12-10 20:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/579640cd34c0c4caca6671fd23edd369d3cd608c', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}, {'number': 5, 'created': '2014-12-10 21:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e9d9a11ee00d3de98d82198e6b18183ffae8a4ce', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}, {'number': 6, 'created': '2014-12-11 02:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9cfd69d50be849ab2807ff124b10ec4ec406a2cd', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}, {'number': 7, 'created': '2014-12-11 08:04:17.000000000', 'files': ['elements/package-installs/pre-install.d/99-package-uninstalls', 'elements/package-installs/extra-data.d/11-create-package-installs-dir', 'elements/package-installs/post-install.d/99-package-uninstalls', 'elements/package-installs/post-install.d/00-package-installs', 'elements/package-installs/install.d/00-package-installs', 'elements/package-installs/bin/package-installs-squash', 'elements/package-installs/install.d/99-package-uninstalls', 'elements/package-installs/pre-install.d/02-package-installs', 'elements/package-installs/bin/package-installs-v2', 'elements/package-installs/extra-data.d/99-squash-package-install'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/98d008c6affcc5e6eeb8ed146cd74cad77c144cb', 'message': ""Rework package-installs to collapse on build host\n\nInstead of doing the work in the image of parsing through the element's\npackage-install declarations, we can squash it on hostside, where we\nhave both YAML and JSON available to us, and then emit a single\npre-processed file into the target to be used later.\n\nChange-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a\n""}]",3,140795,98d008c6affcc5e6eeb8ed146cd74cad77c144cb,29,5,7,2,,,0,"Rework package-installs to collapse on build host

Instead of doing the work in the image of parsing through the element's
package-install declarations, we can squash it on hostside, where we
have both YAML and JSON available to us, and then emit a single
pre-processed file into the target to be used later.

Change-Id: I3f182aa3aae0a79b2f3ea4e66c1878ad12878b0a
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/95/140795/6 && git format-patch -1 --stdout FETCH_HEAD,"['elements/package-installs/extra-data.d/11-create-package-installs-dir', 'elements/package-installs/bin/package-installs-squash', 'elements/package-installs/bin/package-installs-v2']",3,6de00ae1d320a31e565cd6e6b927fafc01dc7a25,140795,"import json parser.add_argument('--phase', required=True, parser.add_argument('-n', '--noop', action=""store_true"", help=""Don't actually install, just print the command"") packages = json.load(open('package-installs.json')) if args.uninstall: install = ""uninstall"" else: install = ""install"" pkgs = list() for (pkg, element) in packages[args.phase][install]: print(""Installing %s from %s"" % (pkg, element)) pkg_map_args = [""pkg-map"", ""--missing-ok"", ""--element"", element] pkg_map_args += pkg map_output = subprocess.check_output( pkg_map_args, stderr=subprocess.STDOUT) except subprocess.CalledProcessError as e: if e.returncode == 1: if args.noop: pkgs.append(pkg) continue else: elif e.returncode == 2: pkgs.append(pkg) continue pkgs.extend(map_output.strip().split('\n')) install_args.extend(list(set(pkgs))) if args.noop: print("" "".join(install_args)) else: try: subprocess.check_output(install_args) except subprocess.CalledProcessError as e: print(""install failed with error %s"" % e.output) sys.exit(1)","from json import load as json_load import ostry: from yaml import load as yaml_load except ImportError: yaml_load = None class PackageInstalls(object): @classmethod def phase_to_attr(cls, phase): return phase.replace('.', '_').replace('-', '_') @classmethod def from_yaml_path(cls, path): if yaml_load is None: print( ""YAML file %s but PyYAML is not installed in the image"" % path) sys.exit(1) with open(path) as fp: return PackageInstalls.from_native_objs(yaml_load(fp)) @classmethod def from_json_path(cls, path): with open(path) as fp: return PackageInstalls.from_native_objs(json_load(fp)) @classmethod def from_native_objs(cls, objs): init_args = {} for pkg_name, params in objs.items(): uninstall = False phase = ""install.d"" try: phase = params[""phase""] except (KeyError, TypeError): pass try: uninstall = bool(params[""uninstall""]) except (KeyError, TypeError): pass init_arg = PackageInstalls.phase_to_attr(phase) if uninstall: init_arg = init_arg + '_uninst' init_args[init_arg] = init_args.get(init_arg, []) + [pkg_name] return PackageInstalls(**init_args) def __init__(self, **phase_installs): for phase, pkgs in phase_installs.items(): setattr(self, phase, pkgs) class PackageInstallsController(object): def __init__(self, path='/usr/share/package-installs'): self.path = path def package_installs(self): for installs_path in os.listdir(self.path): full_path = os.path.join(self.path, installs_path) if full_path.endswith('.yaml'): pi = PackageInstalls.from_yaml_path(full_path) elif full_path.endswith('.json'): pi = PackageInstalls.from_json_path(full_path) else: print(""No decoder known for %s, skipping"" % full_path) continue yield (installs_path[:-5], pi) parser.add_argument('--phase', if not args.phase: print(""Please specify an install phase."") sys.exit(1) pi_c = PackageInstallsController() pkgs = [] for element, pi in pi_c.package_installs(): installs_attr = PackageInstalls.phase_to_attr(args.phase) if args.uninstall: installs_attr += '_uninst' phase_installs = getattr(pi, installs_attr) except AttributeError: continue for pkg in phase_installs: print(""Installing %s from %s"" % (phase_installs, element)) pkg_map_args = [""pkg-map"", ""--missing-ok"", ""--element"", element] pkg_map_args += phase_installs try: map_output = subprocess.check_output(pkg_map_args) except subprocess.CalledProcessError as e: if e.returncode == 1: elif e.returncode == 2: pkgs += phase_installs continue pkgs += map_output.strip().split('\n') install_args.extend(pkgs) try: subprocess.check_output(install_args) except subprocess.CalledProcessError as e: print(""install failed with error %s"" % e.output) sys.exit(1)",108,118
openstack%2Fopenstack-manuals~master~I2f10119c7d461cc11919b68657eea6cb9ccfd3fd,openstack/openstack-manuals,master,I2f10119c7d461cc11919b68657eea6cb9ccfd3fd,"Removal of passive voice from chap 1, arch guide",MERGED,2014-12-11 01:38:30.000000000,2014-12-11 19:18:14.000000000,2014-12-11 07:47:30.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10897}]","[{'number': 1, 'created': '2014-12-11 01:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f761c48c316fd7c79d84a4264c3b62da5b93054f', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_operational_considerations\n\nChange-Id: I2f10119c7d461cc11919b68657eea6cb9ccfd3fd\nPartial-bug: #1400550\n'}, {'number': 2, 'created': '2014-12-11 01:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/be278188d39f65e7e7d3e150bd74972d1a7bd74c', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_operational_considerations\n\nChange-Id: I2f10119c7d461cc11919b68657eea6cb9ccfd3fd\nPartial-bug: #1400550\n'}, {'number': 3, 'created': '2014-12-11 02:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1bec98bbbb6634eb5975c1941af0d6f45e24be4a', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_operational_considerations\n\nChange-Id: I2f10119c7d461cc11919b68657eea6cb9ccfd3fd\nPartial-bug: #1400550\n'}, {'number': 4, 'created': '2014-12-11 02:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f3c2ec365a3e870c4287fbc795bab8a116b39747', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_operational_considerations\n\nChange-Id: I2f10119c7d461cc11919b68657eea6cb9ccfd3fd\nPartial-bug: #1400550\n'}, {'number': 5, 'created': '2014-12-11 04:22:43.000000000', 'files': ['doc/arch-design/generalpurpose/section_operational_considerations_general_purpose.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e68cd33d834b2e2e3ed881ca4af90237cfb6951d', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_operational_considerations\n\nChange-Id: I2f10119c7d461cc11919b68657eea6cb9ccfd3fd\nPartial-bug: #1400550\n'}]",4,140892,e68cd33d834b2e2e3ed881ca4af90237cfb6951d,16,5,5,10607,,,0,"Removal of passive voice from chap 1, arch guide

Removal of passive voice from section_operational_considerations

Change-Id: I2f10119c7d461cc11919b68657eea6cb9ccfd3fd
Partial-bug: #1400550
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/140892/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/generalpurpose/section_operational_considerations_general_purpose.xml'],1,f761c48c316fd7c79d84a4264c3b62da5b93054f,asettle/bug1400550," <para>In the planning and design phases of the build out, it is important to include the operations function. Operational factors affect the design choices for general purpose cloud, and operations staff are often tasked with the maintenance of cloud environments for larger installations.</para> <para>Knowing when and where to implement redundancy and high availability is directly affected by expectations set by the terms of the Service Level Agreements (SLAs). SLAs are contractual obligations that provide assurances for service availability. They define the levels of availability that drive the technical design, often with penalties for not meeting contractual obligations.</para> <para>SLA terms that will affect the design include:</para> <para>API availability guarantees implying multiple infrastructure services, and highly available <para>Network uptime guarantees affecting switch <para>Network security policies requirements needing to be <para>To be able to support and maintain an installation, OpenStack cloud management requires operations staff to understand and comprehend design architecture content. The operations and engineering staff skill level, and level of separation, are dependent on size and purpose of the installation. Large cloud service providers, or a telecom provider, are more likely to be managed by specially trained, dedicated operations organization. Smaller implementations are more likely to rely on support staff that need to take on combined engineering, design and operations functions.</para> <para>Maintaining OpenStack installations requires a variety of technical skills. For example, if you are to incorporate features into an architecture and design that reduce the operations burden, it is advised to automate the operations functions. It may, however, be beneficial to use third party management companies with special expertise in managing OpenStack deployment.</para> </section> <para>OpenStack clouds require appropriate monitoring platorms to ensure errors are caught and managed appropriately. Specific metrics that are critically important to monitor include: <itemizedlist> <listitem> <para> Image disk utilization </para> </listitem> <listitem> <para> Response time to the Compute API </para> </listitem> </itemizedlist> <para>Leveraging existing monitoring systems is an effective check to ensure OpenStack environments can be monitored.</para> </section> <para>To effectively run cloud installations, initial downtime planning includes creating processes and architectures that supports the following:</para> <itemizedlist> <listitem> <para> Planned (maintenance) </para> </listitem> <listitem> <para> Unplanned (system faults) </para> </listitem> </itemizedlist> <para>Resiliency of overall system and individual components are going to be dictated by the requirements of the SLA, meaning designing for high availability (HA) can have cost ramifications.</para> <para>For example, if a compute host failed, this would be an operational consideration; requiring the restoration of instances from a snapshot or respawning an instance. The overall application design is impacted, general purpose clouds should not need to provide abilities to migrate instances from one host to another. Additional considerations need to be made around supporting instance migration if the expectation is that the application will be designed to tolerate failure. Extra support services, including shared storage attached to compute hosts, might need to be deployed in this example.</para> </section> <para>Capacity constraints for a general purpose cloud environment include:</para> <itemizedlist> <listitem> <para> Compute limits </para> </listitem> <listitem> <para> Storage limits </para> </listitem> </itemizedlist> <para>A relationship exists between the size of the compute environment and the supporting OpenStack infrastructure controller nodes requiring support.</para> <para>Increasing the size of the supporting compute environment increases the network traffic and messages, adding load to the controller or networking nodes. Effective monitoring of the environment will help with capacity decisions on scaling.</para> <para>Compute nodes automatically attach to OpenStack clouds, resulting in a horizontally scaling process when adding extra compute capacity to an OpenStack cloud. Additional processes are required to place nodes into appropriate availability zones and host aggregates. When adding additional compute nodes to environments, ensure identical or functional compatible CPUs are used, otherwise live migration features will break. It is necessary to add rack capacity or network switches as scaling out compute hosts directly affects network and datacenter resources. </para> <para>Assessing the average workloads and increasing the number of instances that can run within the compute environment by adjusting the overcommit ratio is another option. It is important to remember changing the CPU overcommit ratio can have a detrimental effect and cause potential increase in noisy neighbor. The additional risk of increasing the overcommit ratio is more instances failing when a compute host fails.</para> Storage layer, capacity includes adding disk shelves to storage nodes. Upgrading directly attached storage installed in compute hosts or add capacity to the shared storage to provide additional ephemeral storage to instances may be necessary.</para>"," <para>Many operational factors will affect general purpose cloud design choices. In larger installations, it is not uncommon for operations staff to be tasked with maintaining cloud environments. This differs from the operations staff that is responsible for building or designing the infrastructure. It is important to include the operations function in the planning and design phases of the build out.</para> <para>Service Level Agreements (SLAs) are contractual obligations that provide assurances for service availability. SLAs define levels of availability that drive the technical design, often with penalties for not meeting the contractual obligations. The strictness of the SLA dictates the level of redundancy and resiliency in the OpenStack cloud design. Knowing when and where to implement redundancy and high availability is directly affected by expectations set by the terms of the SLA. Some of the SLA terms that will affect the design include:</para> <para>Guarantees for API availability imply multiple infrastructure services combined with highly available <para>Network uptime guarantees will affect the switch <para>Network security policies requirements need to be <para>OpenStack cloud management requires operations staff to be able to understand and comprehend design architecture content on some level. The level of skills and the level of separation of the operations and engineering staff are dependent on the size and purpose of the installation. A large cloud service provider or a telecom provider is more likely to be managed by a specially trained, dedicated operations organization. A smaller implementation is more likely to rely on a smaller support staff that might need to take on the combined engineering, design and operations functions.</para> <para>Furthermore, maintaining OpenStack installations requires a variety of technical skills. Some of these skills may include the ability to debug Python log output to a basic level and an understanding of networking concepts.</para> <para>Consider incorporating features into the architecture and design that reduce the operations burden. This is accomplished by automating some of the operations functions. In some cases it may be beneficial to use a third party management company with special expertise in managing OpenStack deployments.</para></section> <para>Like any other infrastructure deployment, OpenStack clouds need an appropriate monitoring platform to ensure any errors are caught and managed appropriately. Consider leveraging any existing monitoring system to see if it will be able to effectively monitor an OpenStack environment. While there are many aspects that need to be monitored, specific metrics that are critically important to capture include image disk utilization, or response time to the Compute API.</para></section> <para>No matter how robust the architecture is, at some point components will fail. Designing for high availability (HA) can have significant cost ramifications, therefore the resiliency of the overall system and the individual components is going to be dictated by the requirements of the SLA. Downtime planning includes creating processes and architectures that support planned (maintenance) and unplanned (system faults) downtime.</para> <para>An example of an operational consideration is the recovery of a failed compute host. This might mean requiring the restoration of instances from a snapshot or respawning an instance on another available compute host. This could have consequences on the overall application design. A general purpose cloud should not need to provide an ability to migrate instances from one host to another. If the expectation is that the application will be designed to tolerate failure, additional considerations need to be made around supporting instance migration. In this scenario, extra supporting services, including shared storage attached to compute hosts, might need to be deployed.</para></section> <para>Capacity planning for future growth is a critically important and often overlooked consideration. Capacity constraints in a general purpose cloud environment include compute and storage limits. There is a relationship between the size of the compute environment and the supporting OpenStack infrastructure controller nodes required to support it. As the size of the supporting compute environment increases, the network traffic and messages will increase which will add load to the controller or networking nodes. While no hard and fast rule exists, effective monitoring of the environment will help with capacity decisions on when to scale the back-end infrastructure as part of the scaling of the compute resources.</para> <para>Adding extra compute capacity to an OpenStack cloud is a horizontally scaling process as consistently configured compute nodes automatically attach to an OpenStack cloud. Be mindful of any additional work that is needed to place the nodes into appropriate availability zones and host aggregates. Make sure to use identical or functionally compatible CPUs when adding additional compute nodes to the environment otherwise live migration features will break. Scaling out compute hosts will directly affect network and other datacenter resources so it will be necessary to add rack capacity or network switches.</para> <para>Another option is to assess the average workloads and increase the number of instances that can run within the compute environment by adjusting the overcommit ratio. While only appropriate in some environments, it's important to remember that changing the CPU overcommit ratio can have a detrimental effect and cause a potential increase in noisy neighbor. The added risk of increasing the overcommit ratio is more instances will fail when a compute host fails.</para> Storage layer, capacity might include adding disk shelves to storage nodes. It may also be necessary to upgrade directly attached storage installed in compute hosts or add capacity to the shared storage to provide additional ephemeral storage to instances.</para>",121,106
openstack%2Foslo.messaging~master~Ic37eabb6f211fb68ca567ed4c400a1314e25cc68,openstack/oslo.messaging,master,Ic37eabb6f211fb68ca567ed4c400a1314e25cc68,Make the RPCVersionCapError message clearer,MERGED,2014-12-04 11:06:43.000000000,2014-12-11 19:17:35.000000000,2014-12-11 19:17:34.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5511}, {'_account_id': 8415}, {'_account_id': 8688}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-12-04 11:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3212a44cdcb4d07e1c616c6d64ccc73d08a1abfe', 'message': 'Make the RPCVersionCapError message clearer\n\nIt is confusing to report that the version cap is too low, rather we\nshould report that the message version is too high.\n\nChange-Id: Ic37eabb6f211fb68ca567ed4c400a1314e25cc68\n'}, {'number': 2, 'created': '2014-12-04 11:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c18eea221655eea5108b786bd367170f1f165855', 'message': 'Make the RPCVersionCapError message clearer\n\nIt is confusing to report that the version cap is too low, rather we\nshould report that the message version is too high.\n\nChange-Id: Ic37eabb6f211fb68ca567ed4c400a1314e25cc68\n'}, {'number': 3, 'created': '2014-12-04 11:14:13.000000000', 'files': ['oslo/messaging/rpc/client.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4e6dabb6982471c94e8656b0d8137d651f551f8b', 'message': 'Make the RPCVersionCapError message clearer\n\nIt is confusing to report that the version cap is too low, rather we\nshould report that the message version is too high.\n\nChange-Id: Ic37eabb6f211fb68ca567ed4c400a1314e25cc68\n'}]",2,139012,4e6dabb6982471c94e8656b0d8137d651f551f8b,18,7,3,5511,,,0,"Make the RPCVersionCapError message clearer

It is confusing to report that the version cap is too low, rather we
should report that the message version is too high.

Change-Id: Ic37eabb6f211fb68ca567ed4c400a1314e25cc68
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/12/139012/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/rpc/client.py'],1,3212a44cdcb4d07e1c616c6d64ccc73d08a1abfe,RPCVersionCapError_message_fix," msg = (""Requested message versino, %(version)s, is too high. Needs"" ""to be lower than the cpecified version cap %(version_cap)s."" %"," msg = (""Specified RPC version cap, %(version_cap)s, is too low. "" ""Needs to be higher than %(version)s."" %",2,2
openstack%2Fironic~master~I4a787039b7bc0f13c29455f041120e9e43e7c46b,openstack/ironic,master,I4a787039b7bc0f13c29455f041120e9e43e7c46b,Correct vmware ssh power manager,MERGED,2014-12-06 15:22:44.000000000,2014-12-11 19:17:27.000000000,2014-12-11 19:17:26.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3068}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-06 15:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/eee18fdb5086d18715a361493c8f5c205b4a6088', 'message': 'Correct vmware ssh power manager\n\n{_NodeName_} in list_running has to be replaced since the power\nmanager relies on it.\n\nChange-Id: I4a787039b7bc0f13c29455f041120e9e43e7c46b\n'}, {'number': 2, 'created': '2014-12-06 17:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ed0754fdb51c39cc764ef0f735cfd20493e870dd', 'message': 'Correct vmware ssh power manager\n\n{_NodeName_} in list_running has to be replaced since the power manager\nrelies on it.\n\nNow _get_hosts_name_for_node is called before list_running, so unit\ntests are modified too.\n\nChange-Id: I4a787039b7bc0f13c29455f041120e9e43e7c46b\n'}, {'number': 3, 'created': '2014-12-09 12:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6502a77e2b437f63c7bf652260b7d6aa84036a66', 'message': 'Correct vmware ssh power manager\n\n{_NodeName_} in list_running has to be replaced since the power manager\nrelies on it.\n\nNow _get_hosts_name_for_node is called before list_running, so unit\ntests are modified too.\n\nChange-Id: I4a787039b7bc0f13c29455f041120e9e43e7c46b\nCloses-Bug: #1400674\n'}, {'number': 4, 'created': '2014-12-10 09:33:25.000000000', 'files': ['ironic/tests/drivers/test_ssh.py', 'ironic/drivers/modules/ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/af21ffd9867a175469ac1f11a394486b43abd519', 'message': 'Correct vmware ssh power manager\n\n{_NodeName_} in list_running has to be replaced since the power manager\nrelies on it.\n\nNow _get_hosts_name_for_node is called before list_running, so unit\ntests are modified too.\n\nChange-Id: I4a787039b7bc0f13c29455f041120e9e43e7c46b\nCloses-Bug: #1400674\n'}]",11,139810,af21ffd9867a175469ac1f11a394486b43abd519,33,7,4,3068,,,0,"Correct vmware ssh power manager

{_NodeName_} in list_running has to be replaced since the power manager
relies on it.

Now _get_hosts_name_for_node is called before list_running, so unit
tests are modified too.

Change-Id: I4a787039b7bc0f13c29455f041120e9e43e7c46b
Closes-Bug: #1400674
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/139810/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/ssh.py'],1,eee18fdb5086d18715a361493c8f5c205b4a6088,vmware-power," # Command should return a list of running vms. If the current node is # not listed then we can assume it is not powered on. cmd_to_exec = ""%s %s"" % (driver_info['cmd_set']['base_cmd'], driver_info['cmd_set']['list_running']) # Replace for vmware, which has {_NodeName_} in list_running cmd_to_exec = cmd_to_exec.replace('{_NodeName_}', node_name) running_list = _ssh_execute(ssh_obj, cmd_to_exec)"," cmd_to_exec = ""%s %s"" % (driver_info['cmd_set']['base_cmd'], driver_info['cmd_set']['list_running']) running_list = _ssh_execute(ssh_obj, cmd_to_exec) # Command should return a list of running vms. If the current node is # not listed then we can assume it is not powered on.",7,5
openstack%2Fironic~master~Ie753774f865e2d40125bea988bf75d02097d03c1,openstack/ironic,master,Ie753774f865e2d40125bea988bf75d02097d03c1,Updated from global requirements,MERGED,2014-12-11 07:13:58.000000000,2014-12-11 19:17:19.000000000,2014-12-11 19:17:18.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-11 07:13:58.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0473104ed9bb4576108b0052f178c6de1f6f1b4f', 'message': 'Updated from global requirements\n\nChange-Id: Ie753774f865e2d40125bea988bf75d02097d03c1\n'}]",0,140941,0473104ed9bb4576108b0052f178c6de1f6f1b4f,10,4,1,11131,,,0,"Updated from global requirements

Change-Id: Ie753774f865e2d40125bea988bf75d02097d03c1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/41/140941/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0473104ed9bb4576108b0052f178c6de1f6f1b4f,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fpycadf~master~If18f264561eb84f0a0695c41b53c7b539cee6f35,openstack/pycadf,master,If18f264561eb84f0a0695c41b53c7b539cee6f35,Updated from global requirements,MERGED,2014-12-04 22:42:44.000000000,2014-12-11 19:13:04.000000000,2014-12-11 19:13:04.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-12-04 22:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/2a7258968c656788f62531c921eefcbe7567aeaf', 'message': 'Updated from global requirements\n\nChange-Id: If18f264561eb84f0a0695c41b53c7b539cee6f35\n'}, {'number': 2, 'created': '2014-12-06 00:08:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/c3c74ea7d3f0573c91f5d5dbfa1913d9eb2a4524', 'message': 'Updated from global requirements\n\nChange-Id: If18f264561eb84f0a0695c41b53c7b539cee6f35\n'}]",0,139236,c3c74ea7d3f0573c91f5d5dbfa1913d9eb2a4524,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: If18f264561eb84f0a0695c41b53c7b539cee6f35
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/36/139236/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2a7258968c656788f62531c921eefcbe7567aeaf,openstack/requirements,"oslo.messaging>=1.4.0,!=1.5.0",oslo.messaging>=1.4.0,1,1
openstack%2Ffuel-main~stable%2F5.0~I81d9ccae672ec52e1fe213fbae1d4067d71ce613,openstack/fuel-main,stable/5.0,I81d9ccae672ec52e1fe213fbae1d4067d71ce613,Up version to 5.0.3,MERGED,2014-10-23 14:09:34.000000000,2014-12-11 18:56:47.000000000,2014-12-11 18:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-23 14:09:34.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ecde705c24e2fcf1876923b4212305b28284f313', 'message': 'Up version to 5.0.3\n\nChange-Id: I81d9ccae672ec52e1fe213fbae1d4067d71ce613\n'}]",0,130546,ecde705c24e2fcf1876923b4212305b28284f313,10,4,1,8789,,,0,"Up version to 5.0.3

Change-Id: I81d9ccae672ec52e1fe213fbae1d4067d71ce613
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/46/130546/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,ecde705c24e2fcf1876923b4212305b28284f313,5_0_3,PRODUCT_VERSION:=5.0.3,PRODUCT_VERSION:=5.0.2,1,1
openstack%2Fpython-novaclient~master~I7ef8410576abe82bb1b5a0dda983ad103c688509,openstack/python-novaclient,master,I7ef8410576abe82bb1b5a0dda983ad103c688509,Updated from global requirements,MERGED,2014-12-11 07:20:11.000000000,2014-12-11 18:51:34.000000000,2014-12-11 18:51:32.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-12-11 07:20:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/60d7baf2afdf5d14fecd0c24e54252876a1f7640', 'message': 'Updated from global requirements\n\nChange-Id: I7ef8410576abe82bb1b5a0dda983ad103c688509\n'}]",0,140957,60d7baf2afdf5d14fecd0c24e54252876a1f7640,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I7ef8410576abe82bb1b5a0dda983ad103c688509
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/57/140957/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,60d7baf2afdf5d14fecd0c24e54252876a1f7640,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fpython-cinderclient~master~I07f04ba5357e0196fe43b510e1d2fff5afa02faa,openstack/python-cinderclient,master,I07f04ba5357e0196fe43b510e1d2fff5afa02faa,Reuse exceptions from Oslo,ABANDONED,2014-01-29 16:24:11.000000000,2014-12-11 18:48:27.000000000,,"[{'_account_id': 3}, {'_account_id': 8041}, {'_account_id': 8871}, {'_account_id': 9545}, {'_account_id': 9550}]","[{'number': 1, 'created': '2014-01-29 16:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a90d752b6866fb52fe845da8f99fed09cefc55d3', 'message': 'Reuse exceptions from Oslo\n\nIn the process of unification of clients code we should\nreuse common functionality from Oslo, other modules from Oslo\nrequire usage of oslo exceptions.\n\nChange-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa\n'}, {'number': 2, 'created': '2014-01-29 16:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/358f2c5fe1d590d216f451ad00836c094f24f3e6', 'message': 'Reuse exceptions from Oslo\n\nIn the process of unification of clients code we should\nreuse common functionality from Oslo, other modules from Oslo\nrequire usage of oslo exceptions.\n\nbp common-client-library-2\n\nChange-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa\n'}, {'number': 4, 'created': '2014-01-29 17:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/19d55dad369196e806bbc2f6f673def063edaa2e', 'message': 'Reuse exceptions from Oslo\n\nIn the process of unification of clients code we should\nreuse common functionality from Oslo, other modules from Oslo\nrequire usage of oslo exceptions.\n\nbp common-client-library-2\n\nChange-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa\n'}, {'number': 3, 'created': '2014-01-29 17:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/90697defa92f434fa7805a1f5198517e40104722', 'message': 'Reuse exceptions from Oslo\n\nIn the process of unification of clients code we should\nreuse common functionality from Oslo, other modules from Oslo\nrequire usage of oslo exceptions.\n\nbp common-client-library-2\n\nChange-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa\n'}, {'number': 5, 'created': '2014-04-29 15:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/43816de6bcc2bf8ec730e800889135e2d6035221', 'message': 'Reuse exceptions from Oslo\n\nIn the process of unification of clients code we should\nreuse common functionality from Oslo, other modules from Oslo\nrequire usage of oslo exceptions.\n\nbp common-client-library-2\n\nChange-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa\n'}, {'number': 6, 'created': '2014-05-06 13:51:16.000000000', 'files': ['cinderclient/client.py', 'cinderclient/exceptions.py', 'cinderclient/shell.py', 'cinderclient/v1/shell.py', 'cinderclient/openstack/common/apiclient/exceptions.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/47b9d6647f93cc6cd7584dc67f414567f4119744', 'message': 'Reuse exceptions from Oslo\n\nIn the process of unification of clients code we should\nreuse common functionality from Oslo, other modules from Oslo\nrequire usage of oslo exceptions.\n\nbp common-client-library-2\n\nChange-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa\n'}]",4,69898,47b9d6647f93cc6cd7584dc67f414567f4119744,38,5,6,9550,,,0,"Reuse exceptions from Oslo

In the process of unification of clients code we should
reuse common functionality from Oslo, other modules from Oslo
require usage of oslo exceptions.

bp common-client-library-2

Change-Id: I07f04ba5357e0196fe43b510e1d2fff5afa02faa
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/98/69898/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/client.py', 'cinderclient/exceptions.py', 'cinderclient/shell.py', 'cinderclient/v1/shell.py', 'cinderclient/v2/shell.py']",5,a90d752b6866fb52fe845da8f99fed09cefc55d3,bp/common-client-library-2, raise exceptions.ClientException(msg) raise exceptions.ClientException(msg)," raise exceptions.ClientException(code=1, message=msg) raise exceptions.ClientException(code=1, message=msg)",14,122
openstack%2Fneutron-specs~master~I717a9eb6257c2b6bec1d2332c5e7d2d00778773c,openstack/neutron-specs,master,I717a9eb6257c2b6bec1d2332c5e7d2d00778773c,Introducing Tap-as-a-Service,ABANDONED,2014-12-09 10:41:21.000000000,2014-12-11 18:42:27.000000000,,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 11578}]","[{'number': 1, 'created': '2014-12-09 10:41:21.000000000', 'files': ['specs/kilo/tap-as-a-service.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6979c3c124a0af57eb941cd53e541c85134edeb5', 'message': 'Introducing Tap-as-a-Service\n\nThe proposal is to introduce a new neutron service, called Tap-as-a-Service,\nwhich provides tapping (port-mirroring) capability for tenant networks. This\nservice will be modeled similar to other neutron services such as the firewall,\nload-balancer, L3-router etc.\n\nChange-Id: I717a9eb6257c2b6bec1d2332c5e7d2d00778773c\n'}]",0,140292,6979c3c124a0af57eb941cd53e541c85134edeb5,5,3,1,11674,,,0,"Introducing Tap-as-a-Service

The proposal is to introduce a new neutron service, called Tap-as-a-Service,
which provides tapping (port-mirroring) capability for tenant networks. This
service will be modeled similar to other neutron services such as the firewall,
load-balancer, L3-router etc.

Change-Id: I717a9eb6257c2b6bec1d2332c5e7d2d00778773c
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/92/140292/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/tap-as-a-service.rst'],1,6979c3c124a0af57eb941cd53e541c85134edeb5,master,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Tap-as-a-Service for Neutron ============================ This neutron spec is an extension of the port mirroring blueprint. while the blueprint proposes the functionality of mirroring neutron ports as an extension to the port object, the spec proposes to offer port mirroring as a service which enables more advance usecases (ex. intrution detection) to be deployed using the service. The above mentioned blueprint aims to add port mirroring capabilities in neutron. Port mirroring allows sending a copy of packets ingressing (entering a VM) or egressing (leaving the VM) one port to another port (usually distinct from the packets destination). From the source VMs perspective, mirrored ingress packets are captured after passing the inbound Security Group filter. Mirrored egress packets are captured before passing the outbound Security Group filter. All captured packets are forwarded to the mirrors destination port without passing through its inbound filters. The proposed port mirroring capability shall be introduced in Neutron as a service called 'Tap-as-a-Service'. Problem Description =================== Neutron currently does not support the functionality of port mirroring in tenant networks. This feature could be of benefit to tenants who would like to debug, monitor and analyze (ex. IDS) traffic in their virtual networks. The use-case is to debug network traffic by ""tapping"" (or mirroring) packets traversing a neutron port. This neutron spec focuses on mirroring traffic from one neutron port to another; future versions may address mirroring from a neutron port to an arbitrary interface on a compute host or on the network controller. Mirroring traffic has many uses, as it provides visibility into VM network traffic which can be used for monitoring, debugging and analyzing network traffic ingressing and egressing a VM. (ex. IDS). Different usage scenarios for the service are listed below: 1. Tapping/Mirroring network traffic ingressing and/or egressing from a particular neutron port. 2. Tapping/Mirroring all network traffic on an entire tenant network. Proposed Change =============== The proposal is to introduce a new neutron service, called Tap-as-a-Service, which provides tapping (port-mirroring) capability for tenant networks. This service will be modeled similar to other neutron services such as the firewall, load-balancer, L3-router etc. The proposed service will allow the tenants to create a tap service instance to which they can add neutron ports that need to be mirrored by creating tap flows. The tap service itself will be a neutron port, which will be the destination port for the mirrored traffic. The destination Tap-as-a-Service neutron port will be created on a network owned by the tenant who is requesting for the service. The port(s) to be mirrored that are added to the service must be owned by the same tenant who created the tap service instance. Even on a shared network, a tenant will only be allowed to mirror the traffic from port(s) that they own on the shared network and not traffic from port that they do not own on the shared network. So in essence tenants can only mirror traffic from port(s) that they own, even on a shared network. Keeping in mind the data privacy aspects and avoiding the data center admin from snooping on tenant traffic, the admin shall not be allowed to mirror traffic from any port(s) that belong to tenants. The port(s) owned by the tenant that are mirrored can be on network(s) other than the network on which tap service port is created. This allow the tenant to mirror traffic from any port(s) it owns on any network(s) on to the same Tap-as-a-Serivce neutron port. In the first version of this service, the tenant can launch a VM specifying the tap port id (resulting from the creation of tap service) for the VM interface (--nic port-id=tap_port_uuid), thus receiving mirrored traffic for further processing (dependent on use case) on the VM.In latter versions, the neutron port instantiated by the service can be used for purposes other than just launching a VM on them, for example the port could be used as an 'external-port' [1]_ to get the mirrored data out from the tenant virtual network on a device or network not managed by openstack. The following would be the work flow for using this service from a tenants point of view 1. Create a tap service instance. If successful, the UUID of a new Neutron port (the destination port for the tap service instance) will be returned (this port is created on the specified tenant network). 2. Launch a monitoring or traffic analysis VM and connect it to the destination port for the tap service instance. 3. Associat Neutron ports with a tap service instance if/when they need to be monitored. 4. Disassociate Neutron ports from a tap service instance if/when then no longer need to be monitored. 5. Destroy a tap-service instance when it is no longer needed. This will remove the Neutron port that was serving as the destination port for the tap service. Please not that the normal work flow of launching a VM is not effected while using TaaS. Alternatives ------------ As an alternative to introducing port mirroring functionality under neutron services, it could be added as an extension to the existing neutron v2 APIs. Data Model Impact ----------------- Tap-as-a-Service introduces the following data models into neutron as database schemas. 1. Tap_Service +-------------+--------+----------+-----------+---------------+-------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | (CRUD) | Value | Conversion | | +=============+========+==========+===========+===============+=========================+ | id | UUID | CR, all | generated | N/A | UUID of the tap | | | | | | | service inst. | +-------------+--------+----------+-----------+---------------+-------------------------+ | tenant_id | UUID | CR, all | N/A | UUID of a | UUID of the | | | | | | valid | tenant creating | | | | | | tenant | the service | +-------------+--------+----------+-----------+---------------+-------------------------+ | name | String | CRU, all | N/A | N/A | Name for the service | | | | | | | inst. | +-------------+--------+----------+-----------+---------------+-------------------------+ | description | String | CRU, all | N/A | N/A | Description of the | | | | | | | service inst. | +-------------+--------+----------+-----------+---------------+-------------------------+ | network_id | UUID + CR, all | N/A | UUID of a | A neutron network | | | | | | valid neutron | on which the port is | | | | | | network | to be created | | | | | | | | +-------------+--------+----------+-----------+---------------+-------------------------+ | port_id | UUID + R, all | N/A | UUID of a | A neutron port | | | | | | valid neutron | is created by the | | | | | | port | service for destination | | | | | | | of mirrored traffic | +-------------+--------+----------+-----------+---------------+-------------------------+ 2. Tap_Flow +----------------+--------+----------+-----------+---------------+-------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | (CRUD) | Value | Conversion | | +================+========+==========+===========+===============+=========================+ | id | UUID | CR, all | generated | N/A | UUID of the | | | | | | | tap flow instance. | +----------------+--------+----------+-----------+---------------+-------------------------+ | name | String | CRU, all | N/A | N/A | Name for the tap flow | | | | | | | inst. | +----------------+--------+----------+-----------+---------------+-------------------------+ | description | String | CRU, all | N/A | N/A | Description of the | | | | | | | tap flow inst. | +----------------+--------+----------+-----------+---------------+-------------------------+ | tap_service_id | UUID | CR, all | N/A | Valid tap | UUID of the tap | | | | | | service UUID | service instance. | +----------------+--------+----------+-----------+---------------+-------------------------+ | source_port | UUID | CR, all | N/A | UUID of a | UUID of the neutron | | | | | | valid neutron | port that needed to be | | | | | | port | mirrored | +----------------+--------+----------+-----------+---------------+-------------------------+ | direction | ENUM | CRU, all | BOTH | | Whether to mirror the | | | (IN, | | | | traffic leaving or | | | OUT, | | | | arriving at the | | | BOTH) | | | | source port | +----------------+--------+----------+-----------+---------------+-------------------------+ REST API Impact --------------- The Tap-as-a-Serivice shall be offered over the RESTFull API interface under the following namespace: http://wiki.openstack.org/Neutron/TaaS/API_1.0 The resource attribute map for the TaaS is provided below: .. code-block:: python direction_enum = [None, 'IN', 'OUT', 'BOTH'] RESOURCE_ATTRIBUTE_MAP = { Tap_Service: { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'description': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'port_id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True}, 'network_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': False} }, Tap_Flow: { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'description': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tap_service_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'required_by_policy': True, 'is_visible': True}, 'source_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'required_by_policy': True, 'is_visible': True}, 'direction': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': direction_enum}, 'is_visible': True} } } Security Impact --------------- The tap port to which the tap service forwards mirrored packets should have its security groups disabled. Mac address filter check should also be disabled. Any anti-spoofing rules associated with port which receives the mirrored traffic should also be removed. There are ongoing discussion which deal with circumventing security groups which can be used by TaaS to diable security groups while mirroring traffic [3]_. Keeping in mind the data privacy aspects and avoiding the data center admin from snooping on tenant traffic, the admin shall not be allowed to mirror traffic from any port(s) that belong to tenants. Hence creation of 'Tap_Flow'(s) is only allowed on ports that are owned by the creating tenant. If an admin wants to monitor tenants traffic, the admin will have to join the tenant as a member. This will ensure that the tenant is in the know that the admin is monitoring their traffic. Notifications Impact -------------------- None IPv6 Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ The performance impact of mirroring traffic needs to be examined and quantified. The impact of a tenant potentially mirroring all traffic from all ports could be large and needs more examination. Some alternatives to reduce the amount of mirrored traffic. 1. Rate limiting on the ports being mirrored. 2. Filters to select certain flows ingressing/egressing a port to be mirrored. 3. Having a quota on the number of TaaS Flows that can be defined by the tenant. Other Deployer Impact --------------------- None Developer Impact ---------------- This will be a new extension API, and will not affect the existing API. Community Impact ---------------- None Follow up work -------------- Going forward, TaaS would be incorporated with Service Insertion [2]_ similar to other existing services like FWaaS, LBaaS, and VPNaaS. While integrating Tap-as-a-Service with Service Insertion the key changes to the data model needed would be the removal of 'network_id' and 'port_id' from the 'Tap_Service' data model. Implementation ============== The reference implementation for this service will be based on the OVS driver. The implementation will use a separate bridge 'br-tap'. This will allow implementation of advanced features (e.g., filtering mirrored packets) in the future. Egress packets will be mirrored from 'br-int' to 'br-tap', by adding a higher priority flow that forwards the packet to both 'br-tap' and to the normal processing. Similarly, ingress packets will be mirrored from 'br-tun' to 'br-tap' by adding a higher priority flow that forwards the packet to both 'br-int' and 'br-tap'. Internally the Tap service will use VLAN tags to identify the tap instances. In the initial release these tags will be reserved from highest to lower; in later release it should be coordinated with the Neutron service. To transfer mirrored packets across compute hosts (OVS switches), VXLAN tunnels will be used (separate tunnels from those used by Neutron). To reduce load on the control plane, the Tap service will use distributed learning similar to the Neutron L2 service. Basically the 'br-tap' will broadcast packets on all VXLAN or GRE tunnels established for Tap-as-a-service with a special tag. We dont create separate (VxLAN tunnels). Rather we use the same tunnel mesh (GRE or VxLAN) that is already in place. The tap destination port will reply with a dummy packet to such broadcast packets to facilitate learning. Assignee(s) ----------- Vinay Yadhav Work Items ---------- * TaaS API and data model implementation. * TaaS OVS driver. * OVS agent changes for port mirroring. Dependencies ============ None Testing ======= Tempest Tests ------------- Unit Tests to be added. Functional Tests ---------------- Functional tests in tempest to be added. API Tests --------- API Tests in Tempest to be added. Documentation Impact ==================== User Documentation ------------------ User Documentation needs to be updated Developer Documentation ----------------------- Developer Documentation needs to be updated References ========== .. [1] External port https://review.openstack.org/#/c/87825 .. [2] Service base and insertion https://review.openstack.org/#/c/93128 .. [3] NFV unaddressed interfaces https://review.openstack.org/#/c/97715/ ",,400,0
openstack%2Fkeystone~master~I191600653a23a36bd126aa1b2f461d20aa5b4f08,openstack/keystone,master,I191600653a23a36bd126aa1b2f461d20aa5b4f08,TestAuthPlugin doesn't use test_auth_plugin.conf,MERGED,2014-11-26 14:43:15.000000000,2014-12-11 18:42:19.000000000,2014-12-11 18:42:18.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-11-26 14:43:15.000000000', 'files': ['keystone/tests/test_auth_plugin.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/50a9d6837c3a7bc6f73d17085150e874496a324b', 'message': ""TestAuthPlugin doesn't use test_auth_plugin.conf\n\nTestAuthPlugin doesn't use test_auth_plugin.conf, so there's no\nneed to load it.\n\nChange-Id: I191600653a23a36bd126aa1b2f461d20aa5b4f08\n""}]",0,137367,50a9d6837c3a7bc6f73d17085150e874496a324b,9,5,1,6486,,,0,"TestAuthPlugin doesn't use test_auth_plugin.conf

TestAuthPlugin doesn't use test_auth_plugin.conf, so there's no
need to load it.

Change-Id: I191600653a23a36bd126aa1b2f461d20aa5b4f08
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/137367/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_auth_plugin.py'],1,50a9d6837c3a7bc6f73d17085150e874496a324b,dependency_injection,," def config_files(self): config_files = super(TestAuthPlugin, self).config_files() config_files.append(tests.dirs.tests_conf('test_auth_plugin.conf')) return config_files ",0,5
openstack%2Fkeystone~master~I2966c42ceae91630fe8cef7fc5ba7eb76fc73b1c,openstack/keystone,master,I2966c42ceae91630fe8cef7fc5ba7eb76fc73b1c,Add missing translation marker for dependency,MERGED,2014-11-24 16:56:25.000000000,2014-12-11 18:36:36.000000000,2014-12-11 18:36:35.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-11-24 16:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a55830b9cef620cbc89f162a46885295e292d80b', 'message': 'Add missing translation marker for depenency\n\nThe string was missing a translation marker.\n\nChange-Id: I2966c42ceae91630fe8cef7fc5ba7eb76fc73b1c\n'}, {'number': 2, 'created': '2014-11-24 17:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/30e90be6da0dbe836cde98aa2fa4f4cfb8c8a52b', 'message': 'Add missing translation marker for dependency\n\nThe string was missing a translation marker.\n\nChange-Id: I2966c42ceae91630fe8cef7fc5ba7eb76fc73b1c\n'}, {'number': 3, 'created': '2014-11-26 14:43:15.000000000', 'files': ['keystone/common/dependency.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/81dbe04edca8ebc7ba8ed31ad157e6e5468e79d9', 'message': 'Add missing translation marker for dependency\n\nThe string was missing a translation marker.\n\nChange-Id: I2966c42ceae91630fe8cef7fc5ba7eb76fc73b1c\n'}]",1,136824,81dbe04edca8ebc7ba8ed31ad157e6e5468e79d9,13,6,3,6486,,,0,"Add missing translation marker for dependency

The string was missing a translation marker.

Change-Id: I2966c42ceae91630fe8cef7fc5ba7eb76fc73b1c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/24/136824/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/dependency.py'],1,a55830b9cef620cbc89f162a46885295e292d80b,dependency_injection, msg = _('Unregistered dependency: %(name)s') % {'name': name}, msg = 'Unregistered dependency: %s' % name,1,1
openstack%2Fneutron-vpnaas~master~Iad845a5771cf2503f1135e0a3a92f7bcc807a275,openstack/neutron-vpnaas,master,Iad845a5771cf2503f1135e0a3a92f7bcc807a275,Init separate alembic migration chain,MERGED,2014-12-10 00:55:01.000000000,2014-12-11 18:27:41.000000000,2014-12-11 18:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 00:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/2170d1292ce0ce0f290f231640254a062c782d50', 'message': 'Init separate alembic migration chain\n\nChange-Id: Iad845a5771cf2503f1135e0a3a92f7bcc807a275\n'}, {'number': 2, 'created': '2014-12-10 06:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/7c5ca1fe235c230b11a2e1632c0d3993ed6e763f', 'message': 'Init separate alembic migration chain\n\nChange-Id: Iad845a5771cf2503f1135e0a3a92f7bcc807a275\n'}, {'number': 3, 'created': '2014-12-10 23:57:27.000000000', 'files': ['neutron_vpnaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_vpnaas/db/migration/alembic_migrations/README', 'neutron_vpnaas/db/migration/alembic_migrations/script.py.mako', 'neutron_vpnaas/db/migration/alembic_migrations/versions/start_neutron_vpnaas.py', 'neutron_vpnaas/db/migration/alembic_migrations/env.py', 'neutron_vpnaas/db/migration/alembic.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/8629af8e7ff33978936b62561ea67988d1de80ff', 'message': 'Init separate alembic migration chain\n\nChange-Id: Iad845a5771cf2503f1135e0a3a92f7bcc807a275\n'}]",0,140547,8629af8e7ff33978936b62561ea67988d1de80ff,13,3,3,6951,,,0,"Init separate alembic migration chain

Change-Id: Iad845a5771cf2503f1135e0a3a92f7bcc807a275
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/47/140547/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_vpnaas/db/migration/alembic_migrations/README', 'neutron_vpnaas/db/migration/alembic_migrations/script.py.mako', 'neutron_vpnaas/db/migration/alembic_migrations/versions/start_neutron_vpnaas.py', 'neutron_vpnaas/db/migration/alembic_migrations/env.py', 'neutron_vpnaas/db/migration/alembic.ini']",6,2170d1292ce0ce0f290f231640254a062c782d50,140547,"# A generic, single database configuration. [alembic] # path to migration scripts script_location = alembic_migrations # template used to generate migration files # file_template = %%(rev)s_%%(slug)s # max length of characters to apply to the # ""slug"" field #truncate_slug_length = 40 # set to 'true' to run the environment during # the 'revision' command, regardless of autogenerate # revision_environment = false # set to 'true' to allow .pyc and .pyo files without # a source .py file to be detected as revisions in the # versions/ directory # sourceless = false sqlalchemy.url = driver://user:pass@localhost/dbname # Logging configuration [loggers] keys = root,sqlalchemy,alembic [handlers] keys = console [formatters] keys = generic [logger_root] level = WARN handlers = console qualname = [logger_sqlalchemy] level = WARN handlers = qualname = sqlalchemy.engine [logger_alembic] level = INFO handlers = qualname = alembic [handler_console] class = StreamHandler args = (sys.stderr,) level = NOTSET formatter = generic [formatter_generic] format = %(levelname)-5.5s [%(name)s] %(message)s datefmt = %H:%M:%S ",,206,0
openstack%2Fneutron-lbaas~master~I260f80b57945ab3263d7f561678c3c9494a61b7c,openstack/neutron-lbaas,master,I260f80b57945ab3263d7f561678c3c9494a61b7c,Initializing alembic for separate chain,MERGED,2014-12-09 20:41:14.000000000,2014-12-11 18:27:04.000000000,2014-12-11 18:27:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 6951}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-09 20:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/2522fe1e4384faf0ab77d93606eec748a6c2ea12', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 2, 'created': '2014-12-09 20:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/89ed996473e505e662fe7b5b1b8ff46fb8282f38', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 3, 'created': '2014-12-09 20:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e4887c810dca53ad8223e2cbe98381eba733c194', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 4, 'created': '2014-12-10 00:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/262c7c9a65398babd894519822751350cc0ecb6c', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 5, 'created': '2014-12-10 00:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/1dd545ea976ff1a097fb1b8989ab2fc242e2c5f9', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 6, 'created': '2014-12-10 00:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/58c8e38522db6090ddf8591a53ecf48e2db0f2d9', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 7, 'created': '2014-12-10 21:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/977a462bc17ca6abb55c2eae60dbd3d51e56e8de', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 8, 'created': '2014-12-10 21:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/18b028f4c642e4a72475eedab2333697c96251b0', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}, {'number': 9, 'created': '2014-12-10 23:54:31.000000000', 'files': ['neutron_lbaas/db/migration/alembic_migrations/README', 'neutron_lbaas/db/migration/alembic.ini', 'neutron_lbaas/db/migration/alembic_migrations/versions/start_neutron_lbaas.py', 'neutron_lbaas/db/migration/__init__.py', 'neutron_lbaas/db/migration/alembic_migrations/script.py.mako', 'neutron_lbaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_lbaas/db/migration/alembic_migrations/env.py', 'neutron_lbaas/db/migration/alembic_migrations/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/298012697fdad8868bed306a88bba472cfaa498b', 'message': 'Initializing alembic for separate chain\n\nChange-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c\n'}]",3,140472,298012697fdad8868bed306a88bba472cfaa498b,27,5,9,6951,,,0,"Initializing alembic for separate chain

Change-Id: I260f80b57945ab3263d7f561678c3c9494a61b7c
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/72/140472/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/db/migration/alembic_migrations/README', 'neutron_lbaas/db/migration/alembic.ini', 'neutron_lbaas/db/migration/alembic_migrations/loadbalancer_init_ops.py', 'neutron_lbaas/db/migration/cli.py', 'neutron_lbaas/db/migration/__init__.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/108518e64249_start_neutron_lbaas_chain.py', 'neutron_lbaas/db/migration/alembic_migrations/script.py.mako', 'neutron_lbaas/db/migration/alembic_migrations/__init__.py', 'neutron_lbaas/db/migration/alembic_migrations/env.py']",9,2522fe1e4384faf0ab77d93606eec748a6c2ea12,140472,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from logging import config as logging_config from alembic import context from neutron.db import model_base from oslo.config import cfg from oslo.db.sqlalchemy import session import sqlalchemy as sa from sqlalchemy import event from neutron.db.migration.models import head # noqa from neutron.db.migration.cli import * # noqa MYSQL_ENGINE = None LBAAS_VERSION_TABLE = 'alembic_version_lbaas' config = context.config neutron_config = config.neutron_config logging_config.fileConfig(config.config_file_name) target_metadata = model_base.BASEV2.metadata def set_mysql_engine(): try: mysql_engine = neutron_config.command.mysql_engine except cfg.NoSuchOptError: mysql_engine = None global MYSQL_ENGINE MYSQL_ENGINE = (mysql_engine or model_base.BASEV2.__table_args__['mysql_engine']) def run_migrations_offline(): set_mysql_engine() kwargs = dict() if neutron_config.database.connection: kwargs['url'] = neutron_config.database.connection else: kwargs['dialect_name'] = neutron_config.database.engine kwargs['version_table'] = LBAAS_VERSION_TABLE context.configure(**kwargs) with context.begin_transaction(): context.run_migrations() @event.listens_for(sa.Table, 'after_parent_attach') def set_storage_engine(target, parent): if MYSQL_ENGINE: target.kwargs['mysql_engine'] = MYSQL_ENGINE def run_migrations_online(): set_mysql_engine() engine = session.create_engine(neutron_config.database.connection) connection = engine.connect() context.configure( connection=connection, target_metadata=target_metadata, version_table=LBAAS_VERSION_TABLE ) try: with context.begin_transaction(): context.run_migrations() finally: connection.close() engine.dispose() if context.is_offline_mode(): run_migrations_offline() else: run_migrations_online()",,388,0
openstack%2Fmagnum~master~Idda4b0a39076e5f473cbb4182cdcba202267ab69,openstack/magnum,master,Idda4b0a39076e5f473cbb4182cdcba202267ab69,Add documentation for a developer quickstart guide,MERGED,2014-12-10 19:57:00.000000000,2014-12-11 18:15:26.000000000,2014-12-11 18:15:25.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 7770}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-12-10 19:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f4a078b3f067cda728eb7cc65fca57544709bb92', 'message': 'Add documentation for a developer quickstart guide\n\nChange-Id: Idda4b0a39076e5f473cbb4182cdcba202267ab69\n'}, {'number': 2, 'created': '2014-12-11 00:36:56.000000000', 'files': ['doc/source/dev/dev-quickstart.rst', 'doc/source/index.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/5b8036ea6f20e05bf97381bd02b693eae3b7e6f5', 'message': 'Add documentation for a developer quickstart guide\n\nChange-Id: Idda4b0a39076e5f473cbb4182cdcba202267ab69\n'}]",2,140825,5b8036ea6f20e05bf97381bd02b693eae3b7e6f5,11,5,2,2834,,,0,"Add documentation for a developer quickstart guide

Change-Id: Idda4b0a39076e5f473cbb4182cdcba202267ab69
",git fetch https://review.opendev.org/openstack/magnum refs/changes/25/140825/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/dev/dev-quickstart.rst', 'doc/source/index.rst', 'README.rst']",3,f4a078b3f067cda728eb7cc65fca57544709bb92,,"* ReST Client: http://git.openstack.org/cgit/stackforge/python-magnumclientTwo binaries work together to compose the Magnum system. The first binaryprocess. The ReST server is horizontally scalable. AT this time, the backend is limited to one process, but we intend to add horizontal scalability to the backend as well. The magnum-backend process runs on a controller machine and connects to a kubernetes or docker ReST API endpoint. The kubernetes and docker ReST API endpoints are managed by the bay object. When service or pod objects are created, Kubernetes is directly contacted via the k8s ReST API. When container objects are acted upon, the docker ReST API is directly contacted.Installation and Usage ---------------------- For installation and usage, please read the developer installation guide located at doc/source/dev/dev-quickstart.rst.","* ReST Client: http://github.com/stackforge/python-magnumclientThree binaries work together to compose the Magnum system. The first binaryprocess. The magnum-backend process runs on each machine where a docker server is running or where a k8s minion is located. The backend processor contacts the appropriate backend (for the container object, docker, for the server & pod objects, k8s). The backend then executes the operation requested and sends the results to the third binary. The third binary, magnum-conductor, reads and writes the database with information related to the object operated upon. The conductor then returns the new object back up the call stack, where it may be used to provide information to the client or used for processing the operation. There is only one magnum-conductor process running.Installation ------------ * Configure Keystone:: $ source openrc admin admin $ keystone user-create --name=magnum \ --pass=<secure-magnum-password> \ --email=magnum@example.com $ keystone service-create --name=container \ --type=container \ --description=""Magnum Container Service"" $ keystone endpoint-create --service=container \ --publicurl=http://127.0.0.1:9511/v1 \ --internalurl=http://127.0.0.1:9511/v1 \ --adminurl=http://127.0.0.1:9511/v1 * Install Magnum:: $ git clone http://github.com/stackforge/magnum $ cd magnum $ sudo python ./setup.py install $ cd .. * Install Magnum's Python Client:: $ git clone http://github.com/stackforge/python-magnumclient $ cd python-magnumclient $ sudo python ./setup.py install $ cd .. Run --- * Start magnum-api:: $ magnum-api & * Start magnum-conductor:: $ magnum-conductor & * Start magnum-backend (should be started where a docker server or kubernetes api server is running):: $ magnum-backend & Access Magnum via ReST API -------------------------- * Note the magnum ReST API is not yet plumbed * * select a subcommand:: bay-create bay-delete bay-list bay-show container-create container-delete container-execute container-list container-logs container-pause container-reboot container-show container-start container-stop container-unpause pod-create pod-delete pod-list pod-show service-create service-delete service-list service-show * Run the operation:: $ magnum bay-list",270,91
openstack%2Fsolum~master~I64c15abe6cef457e621e76e078d614108eba738a,openstack/solum,master,I64c15abe6cef457e621e76e078d614108eba738a,Mark assembly as ERROR on build failures,MERGED,2014-12-03 19:04:45.000000000,2014-12-11 18:06:57.000000000,2014-12-11 18:06:56.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-12-03 19:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/95f0ca97154888f82fe957a7df5cafdf6fb84bda', 'message': 'Mark assembly as ERROR on build failures\n\nAssemblies that failed during BUILD in a few cases\nwere stuck as BUILD forever because of premature exits\nfrom the build() method. This patch adds some calls to\nupdate_assembly_status to mark them as ERROR.\n\nCloses-Bug: #1391596\n\nChange-Id: I64c15abe6cef457e621e76e078d614108eba738a\n'}, {'number': 2, 'created': '2014-12-03 19:42:07.000000000', 'files': ['solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/5762bd8a38d186410e2cdadfa6f1317e927d5ff5', 'message': 'Mark assembly as ERROR on build failures\n\nAssemblies that failed during BUILD in a few cases\nwere stuck as BUILD forever because of premature exits\nfrom the build() method. This patch adds some calls to\nupdate_assembly_status to mark them as ERROR.\n\nCloses-Bug: #1391596\n\nChange-Id: I64c15abe6cef457e621e76e078d614108eba738a\n'}]",0,138829,5762bd8a38d186410e2cdadfa6f1317e927d5ff5,14,4,2,1375,,,0,"Mark assembly as ERROR on build failures

Assemblies that failed during BUILD in a few cases
were stuck as BUILD forever because of premature exits
from the build() method. This patch adds some calls to
update_assembly_status to mark them as ERROR.

Closes-Bug: #1391596

Change-Id: I64c15abe6cef457e621e76e078d614108eba738a
",git fetch https://review.opendev.org/openstack/solum refs/changes/29/138829/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py']",3,95f0ca97154888f82fe957a7df5cafdf6fb84bda,bug/1391596," @mock.patch('solum.conductor.api.API.update_assembly_status') def test_unittest_and_build(self, mock_uas, mock_b_update, mock_popen, mock_registry, mock_req, mock_get_env): cfg.CONF.set_override('log_url_prefix', 'https://log.com/commit/', group='worker') expected = [mock.call(44, 'UNIT_TESTING'), mock.call(44, 'READY')] self.assertEqual(expected, mock_uas.call_args_list) @mock.patch('solum.conductor.api.API.update_assembly_status') def test_unittest_no_build(self, mock_registry, mock_uas, cfg.CONF.set_override('log_url_prefix', 'https://log.com/commit/', group='worker') expected = [mock.call(44, 'UNIT_TESTING'), mock.call(44, 'UNIT_TESTING_FAILED')] self.assertEqual(expected, mock_uas.call_args_list)"," @mock.patch('solum.worker.handlers.shell.update_assembly_status') @mock.patch('solum.worker.handlers.shell_nobuild.update_assembly_status') def test_unittest_and_build(self, mock_a_update_nb, mock_a_update, mock_b_update, mock_popen, mock_registry, mock_req, mock_get_env): cfg.CONF.worker.log_url_prefix = ""https://log.com/commit/"" # The UNIT_TESTING update happens from shell... expected = [mock.call(self.ctx, 44, 'UNIT_TESTING')] self.assertEqual(expected, mock_a_update.call_args_list) # ...but the READY update happens in shell_nobuild. expected = [mock.call(self.ctx, 44, 'READY')] self.assertEqual(expected, mock_a_update_nb.call_args_list) @mock.patch('solum.worker.handlers.shell.update_assembly_status') def test_unittest_no_build(self, mock_registry, mock_a_update, cfg.CONF.worker.log_url_prefix = ""https://log.com/commit/"" expected = [mock.call(self.ctx, 44, 'UNIT_TESTING'), mock.call(self.ctx, 44, 'UNIT_TESTING_FAILED')] self.assertEqual(expected, mock_a_update.call_args_list)",63,22
openstack%2Fneutron~master~Ib43e92c6a05094fa3988486fd42dbf1ac560a565,openstack/neutron,master,Ib43e92c6a05094fa3988486fd42dbf1ac560a565,Fix for migration tests without adv services tables,ABANDONED,2014-12-11 00:44:24.000000000,2014-12-11 18:03:18.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6951}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 00:44:24.000000000', 'files': ['neutron/tests/unit/db/test_migration.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8880ca76ee7d3f1e2869f4e90d2e0ce762e844a', 'message': 'Fix for migration tests without adv services tables\n\nChange-Id: Ib43e92c6a05094fa3988486fd42dbf1ac560a565\n'}]",2,140880,f8880ca76ee7d3f1e2869f4e90d2e0ce762e844a,23,19,1,6951,,,0,"Fix for migration tests without adv services tables

Change-Id: Ib43e92c6a05094fa3988486fd42dbf1ac560a565
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/140880/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/db/test_migration.py'],1,f8880ca76ee7d3f1e2869f4e90d2e0ce762e844a,services-split-shims," # self.skipTest(""Temporarily disabled during services split"") diff2 = self.compare_foreign_keys(self.get_metadata(), self.get_engine()) diff = self._remove_adv_services(diff1 + diff2) result = filter(self.remove_unrelated_errors, diff) def _remove_adv_services(self, element): excluded_lbaas_tables = [ 'sessionpersistences', 'poolstatisticss', 'vips', 'pools', 'members', 'healthmonitors', 'poolmonitorassociations' ] excluded_fwaas_tables = [ 'firewall_rules', 'firewalls', 'firewall_policies' ] excluded_vpnaas_tables = [ 'ipsecpeercidrs', 'ipsecpolicies', 'ikepolicies', 'ipsec_site_connections', 'vpnservices' ] element_cp = element[:] for index, item in enumerate(element): print item[1] if item[1].name in (excluded_lbaas_tables + excluded_fwaas_tables + excluded_vpnaas_tables): del element_cp[index] return element_cp"," self.skipTest(""Temporarily disabled during services split"") diff2 = self.check_foreign_keys(self.get_metadata(), self.get_engine()) result = filter(self.remove_unrelated_errors, diff1 + diff2)",36,5
openstack%2Fdevstack-gate~master~I35657c79c5d05dd32353c2f7047dc0a9442beace,openstack/devstack-gate,master,I35657c79c5d05dd32353c2f7047dc0a9442beace,Add neutron advanced services to PROJECTS list,MERGED,2014-12-11 15:49:21.000000000,2014-12-11 18:02:13.000000000,2014-12-11 18:02:13.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2750}, {'_account_id': 4146}]","[{'number': 1, 'created': '2014-12-11 15:49:21.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/111043e49f785c46a6f2d42c348d97a463075ccb', 'message': 'Add neutron advanced services to PROJECTS list\n\nThis commit adds the new repos for the neutron advanced services into\nto the projects list which is a requirement for using them in dsvm\njobs.\n\nChange-Id: I35657c79c5d05dd32353c2f7047dc0a9442beace\n'}]",0,141077,111043e49f785c46a6f2d42c348d97a463075ccb,8,4,1,5196,,,0,"Add neutron advanced services to PROJECTS list

This commit adds the new repos for the neutron advanced services into
to the projects list which is a requirement for using them in dsvm
jobs.

Change-Id: I35657c79c5d05dd32353c2f7047dc0a9442beace
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/77/141077/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,111043e49f785c46a6f2d42c348d97a463075ccb,bug/1400370,"PROJECTS=""openstack/neutron-fwaas $PROJECTS"" PROJECTS=""openstack/neutron-lbaas $PROJECTS"" PROJECTS=""openstack/neutron-vpnaas $PROJECTS""",,3,0
openstack%2Fswift~master~Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417,openstack/swift,master,Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417,Refactoring functional tests,ABANDONED,2014-05-07 17:42:09.000000000,2014-12-11 18:01:53.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 597}, {'_account_id': 866}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8542}, {'_account_id': 9625}, {'_account_id': 10899}]","[{'number': 1, 'created': '2014-05-07 17:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/634c6ec556da305ce8bcbc479f82812242a0e5ea', 'message': 'refactoring functional tests\n\nThis is a break up of the long tests.py file into\nsmaller files. This is an attempt to improve\nmaintainability of the functional tests, by breaking\nthem up into functional areas.\n\nThis first commit pulled tests of slo, dlo and tempurl\nmiddleware and put them in their own files.\n\nChange-Id: Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 2, 'created': '2014-06-10 20:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f580face99ca236ee18fe06018bb0d60aa6b29ed', 'message': 'Refactoring functional tests\n\nThis is a break up of the long tests.py file into\nsmaller files. This is an attempt to improve\nmaintainability of the functional tests, by breaking\nthem up into functional areas.\n\nChange-Id: Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 3, 'created': '2014-07-08 20:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/416371b3f57d7ce9291e9a0ef9c0d61b2373d8b0', 'message': 'Refactoring functional tests\n\nThis is a break up of the long tests.py file into\nsmaller files. This is an attempt to improve\nmaintainability of the functional tests, by breaking\nthem up into functional areas.\n\nChange-Id: Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 4, 'created': '2014-08-11 19:01:52.000000000', 'files': ['test/functional/middleware/test_dlo.py', 'test/functional/test_swob.py', 'test/functional/test_account.py', 'test/functional/tests.py', 'test/functional/test_container_acl.py', 'test/functional/middleware/test_slo.py', 'test/functional/common.py', 'test/functional/test_object_copy.py', 'test/functional/middleware/test_tempurl.py', 'test/functional/test_object_cors.py', 'test/functional/test_account_acl.py', 'test/functional/test_account_metadata.py', 'test/functional/test_object_version.py', 'test/functional/test_object.py', 'test/functional/middleware/__init__.py', 'test/functional/test_container.py', 'test/functional/test_container_metadata.py', 'test/functional/test_object_acl.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/316efa526d18426ce6641144e3b8d204d8ca6e6e', 'message': 'Refactoring functional tests\n\nThis is a break up of the long tests.py file into\nsmaller files. This is an attempt to improve\nmaintainability of the functional tests, by breaking\nthem up into functional areas.\n\nChange-Id: Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",5,92643,316efa526d18426ce6641144e3b8d204d8ca6e6e,29,13,4,9625,,,0,"Refactoring functional tests

This is a break up of the long tests.py file into
smaller files. This is an attempt to improve
maintainability of the functional tests, by breaking
them up into functional areas.

Change-Id: Id0a2c383d4b3e24cf09ba0ccfcee6384a0a06417
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/92643/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/middleware/test_dlo.py', 'test/functional/tests.py', 'test/functional/middleware/__init__.py', 'test/functional/middleware/test_slo.py', 'test/functional/common.py', 'test/functional/middleware/test_tempurl.py']",6,634c6ec556da305ce8bcbc479f82812242a0e5ea,organize_func_test,"#!/usr/bin/python -u # Copyright (c) 2010-2014 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import hashlib import hmac import json import time import urllib from nose import SkipTest from test.functional import cluster_info import test.functional as tf from test.functional.common import Utils, Base, Base2 from test.functional.swift_test_client import Account, Connection, \ ResponseError class TestTempurlEnv(object): tempurl_enabled = None # tri-state: None initially, then True/False @classmethod def setUp(cls): cls.conn = Connection(tf.config) cls.conn.authenticate() if cls.tempurl_enabled is None: cls.tempurl_enabled = 'tempurl' in cluster_info if not cls.tempurl_enabled: return cls.tempurl_methods = cluster_info['tempurl']['methods'] cls.tempurl_key = Utils.create_name() cls.tempurl_key2 = Utils.create_name() cls.account = Account( cls.conn, tf.config.get('account', tf.config['username'])) cls.account.delete_containers() cls.account.update_metadata({ 'temp-url-key': cls.tempurl_key, 'temp-url-key-2': cls.tempurl_key2 }) cls.container = cls.account.container(Utils.create_name()) if not cls.container.create(): raise ResponseError(cls.conn.response) cls.obj = cls.container.file(Utils.create_name()) cls.obj.write(""obj contents"") cls.other_obj = cls.container.file(Utils.create_name()) cls.other_obj.write(""other obj contents"") class TestTempurl(Base): env = TestTempurlEnv set_up = False def setUp(self): super(TestTempurl, self).setUp() if self.env.tempurl_enabled is False: raise SkipTest(""TempURL not enabled"") elif self.env.tempurl_enabled is not True: # just some sanity checking raise Exception( ""Expected tempurl_enabled to be True/False, got %r"" % (self.env.tempurl_enabled,)) expires = int(time.time()) + 86400 sig = self.tempurl_sig( 'GET', expires, self.env.conn.make_path(self.env.obj.path), self.env.tempurl_key) self.obj_tempurl_parms = {'temp_url_sig': sig, 'temp_url_expires': str(expires)} def tempurl_sig(self, method, expires, path, key): return hmac.new( key, '%s\n%s\n%s' % (method, expires, urllib.unquote(path)), hashlib.sha1).hexdigest() def test_GET(self): contents = self.env.obj.read( parms=self.obj_tempurl_parms, cfg={'no_auth_token': True}) self.assertEqual(contents, ""obj contents"") # GET tempurls also allow HEAD requests self.assert_(self.env.obj.info(parms=self.obj_tempurl_parms, cfg={'no_auth_token': True})) def test_GET_with_key_2(self): expires = int(time.time()) + 86400 sig = self.tempurl_sig( 'GET', expires, self.env.conn.make_path(self.env.obj.path), self.env.tempurl_key2) parms = {'temp_url_sig': sig, 'temp_url_expires': str(expires)} contents = self.env.obj.read(parms=parms, cfg={'no_auth_token': True}) self.assertEqual(contents, ""obj contents"") def test_PUT(self): new_obj = self.env.container.file(Utils.create_name()) expires = int(time.time()) + 86400 sig = self.tempurl_sig( 'PUT', expires, self.env.conn.make_path(new_obj.path), self.env.tempurl_key) put_parms = {'temp_url_sig': sig, 'temp_url_expires': str(expires)} new_obj.write('new obj contents', parms=put_parms, cfg={'no_auth_token': True}) self.assertEqual(new_obj.read(), ""new obj contents"") # PUT tempurls also allow HEAD requests self.assert_(new_obj.info(parms=put_parms, cfg={'no_auth_token': True})) def test_HEAD(self): expires = int(time.time()) + 86400 sig = self.tempurl_sig( 'HEAD', expires, self.env.conn.make_path(self.env.obj.path), self.env.tempurl_key) head_parms = {'temp_url_sig': sig, 'temp_url_expires': str(expires)} self.assert_(self.env.obj.info(parms=head_parms, cfg={'no_auth_token': True})) # HEAD tempurls don't allow PUT or GET requests, despite the fact that # PUT and GET tempurls both allow HEAD requests self.assertRaises(ResponseError, self.env.other_obj.read, cfg={'no_auth_token': True}, parms=self.obj_tempurl_parms) self.assert_status([401]) self.assertRaises(ResponseError, self.env.other_obj.write, 'new contents', cfg={'no_auth_token': True}, parms=self.obj_tempurl_parms) self.assert_status([401]) def test_different_object(self): contents = self.env.obj.read( parms=self.obj_tempurl_parms, cfg={'no_auth_token': True}) self.assertEqual(contents, ""obj contents"") self.assertRaises(ResponseError, self.env.other_obj.read, cfg={'no_auth_token': True}, parms=self.obj_tempurl_parms) self.assert_status([401]) def test_changing_sig(self): contents = self.env.obj.read( parms=self.obj_tempurl_parms, cfg={'no_auth_token': True}) self.assertEqual(contents, ""obj contents"") parms = self.obj_tempurl_parms.copy() if parms['temp_url_sig'][0] == 'a': parms['temp_url_sig'] = 'b' + parms['temp_url_sig'][1:] else: parms['temp_url_sig'] = 'a' + parms['temp_url_sig'][1:] self.assertRaises(ResponseError, self.env.obj.read, cfg={'no_auth_token': True}, parms=parms) self.assert_status([401]) def test_changing_expires(self): contents = self.env.obj.read( parms=self.obj_tempurl_parms, cfg={'no_auth_token': True}) self.assertEqual(contents, ""obj contents"") parms = self.obj_tempurl_parms.copy() if parms['temp_url_expires'][-1] == '0': parms['temp_url_expires'] = parms['temp_url_expires'][:-1] + '1' else: parms['temp_url_expires'] = parms['temp_url_expires'][:-1] + '0' self.assertRaises(ResponseError, self.env.obj.read, cfg={'no_auth_token': True}, parms=parms) self.assert_status([401]) class TestTempurlUTF8(Base2, TestTempurl): set_up = False class TestSloTempurlEnv(object): enabled = None # tri-state: None initially, then True/False @classmethod def setUp(cls): cls.conn = Connection(tf.config) cls.conn.authenticate() if cls.enabled is None: cls.enabled = 'tempurl' in cluster_info and 'slo' in cluster_info cls.tempurl_key = Utils.create_name() cls.account = Account( cls.conn, tf.config.get('account', tf.config['username'])) cls.account.delete_containers() cls.account.update_metadata({'temp-url-key': cls.tempurl_key}) cls.manifest_container = cls.account.container(Utils.create_name()) cls.segments_container = cls.account.container(Utils.create_name()) if not cls.manifest_container.create(): raise ResponseError(cls.conn.response) if not cls.segments_container.create(): raise ResponseError(cls.conn.response) seg1 = cls.segments_container.file(Utils.create_name()) seg1.write('1' * 1024 * 1024) seg2 = cls.segments_container.file(Utils.create_name()) seg2.write('2' * 1024 * 1024) cls.manifest_data = [{'size_bytes': 1024 * 1024, 'etag': seg1.md5, 'path': '/%s/%s' % (cls.segments_container.name, seg1.name)}, {'size_bytes': 1024 * 1024, 'etag': seg2.md5, 'path': '/%s/%s' % (cls.segments_container.name, seg2.name)}] cls.manifest = cls.manifest_container.file(Utils.create_name()) cls.manifest.write( json.dumps(cls.manifest_data), parms={'multipart-manifest': 'put'}) class TestSloTempurl(Base): env = TestSloTempurlEnv set_up = False def setUp(self): super(TestSloTempurl, self).setUp() if self.env.enabled is False: raise SkipTest(""TempURL and SLO not both enabled"") elif self.env.enabled is not True: # just some sanity checking raise Exception( ""Expected enabled to be True/False, got %r"" % (self.env.enabled,)) def tempurl_sig(self, method, expires, path, key): return hmac.new( key, '%s\n%s\n%s' % (method, expires, urllib.unquote(path)), hashlib.sha1).hexdigest() def test_GET(self): expires = int(time.time()) + 86400 sig = self.tempurl_sig( 'GET', expires, self.env.conn.make_path(self.env.manifest.path), self.env.tempurl_key) parms = {'temp_url_sig': sig, 'temp_url_expires': str(expires)} contents = self.env.manifest.read( parms=parms, cfg={'no_auth_token': True}) self.assertEqual(len(contents), 2 * 1024 * 1024) # GET tempurls also allow HEAD requests self.assert_(self.env.manifest.info( parms=parms, cfg={'no_auth_token': True})) class TestSloTempurlUTF8(Base2, TestSloTempurl): set_up = False ",,850,761
openstack%2Fswift~master~Iea8f819062b7192e1cdef0a104df366566810957,openstack/swift,master,Iea8f819062b7192e1cdef0a104df366566810957,Changed the rsync-merge initiation criteria from percentage to difference,ABANDONED,2014-07-20 08:42:01.000000000,2014-12-11 18:01:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1216}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-07-20 08:42:01.000000000', 'files': ['swift/common/db_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/53d1c93080ef6ac9873fa56a747c775dca00c68d', 'message': 'Changed the rsync-merge initiation criteria from percentage to difference\n\nChange-Id: Iea8f819062b7192e1cdef0a104df366566810957\nCloses-Bug: 1019712\n'}]",1,108231,53d1c93080ef6ac9873fa56a747c775dca00c68d,8,5,1,12532,,,0,"Changed the rsync-merge initiation criteria from percentage to difference

Change-Id: Iea8f819062b7192e1cdef0a104df366566810957
Closes-Bug: 1019712
",git fetch https://review.opendev.org/openstack/swift refs/changes/31/108231/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/db_replicator.py'],1,53d1c93080ef6ac9873fa56a747c775dca00c68d,bug/1019712, self.rsync_merge_threshold = 10.0 if float(info['max_row']) - float(rinfo['max_row']) > self.rsync_merge_threshold:, if rinfo['max_row'] / float(info['max_row']) < 0.5:,2,1
openstack%2Fswift~master~I1aac09500a566204ff44848b6762fdc17a6e7f04,openstack/swift,master,I1aac09500a566204ff44848b6762fdc17a6e7f04,Add object-server partial write prevention tests,ABANDONED,2014-06-22 08:11:49.000000000,2014-12-11 18:01:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 8871}, {'_account_id': 9625}]","[{'number': 1, 'created': '2014-06-22 08:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd81ad273119a8dbfbbb2b44105e31c702e088dd', 'message': 'Add object-server partial write prevention tests\n\nThis change adds some addtional unit tests to test that partial\nwrites are handled correctly through the object-server.\n\nThe bug intially wanted to test for partial writes when the\nobject server wrapped up os.write. However, now that the writing out\nto disk is happening in the diskfile oject, the oject-server tests\nnow only have to deal with partial writes correcly when the written\nbyte counts are passed back from the diskfile object indicate a\npartial write.\n\nChange-Id: I1aac09500a566204ff44848b6762fdc17a6e7f04\nCloses-Bug: 1040883\n'}, {'number': 2, 'created': '2014-07-15 09:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1ef8c5f8a565d6e634dd30368c66c95813ddc0f9', 'message': 'Add object-server partial write prevention tests\n\nThis change adds some additional unit tests to test that partial\nwrites are handled correctly through the object-server.\n\nThe bug initially wanted to test for partial writes when the\nobject server wrapped up os.write. However, now that the writing out\nto disk is happening in the diskfile object, the object-server tests\nnow only have to deal with partial writes correctly when the written\nbyte counts are passed back from the diskfile object indicate a\npartial write.\n\nChange-Id: I1aac09500a566204ff44848b6762fdc17a6e7f04\nCloses-Bug: 1040883\n'}, {'number': 3, 'created': '2014-08-13 01:49:57.000000000', 'files': ['test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/fe2500bc785fb30ea1d81833f092026668aa2cb1', 'message': 'Add object-server partial write prevention tests\n\nThis change adds some additional unit tests to test that partial\nwrites are handled correctly through the object-server.\n\nThe bug initially wanted to test for partial writes when the\nobject server wrapped up os.write. However, now that the writing out\nto disk is happening in the diskfile object, the object-server tests\nnow only have to deal with partial writes correctly when the written\nbyte counts are passed back from the diskfile object indicate a\npartial write.\n\nChange-Id: I1aac09500a566204ff44848b6762fdc17a6e7f04\nCloses-Bug: 1040883\n'}]",16,101743,fe2500bc785fb30ea1d81833f092026668aa2cb1,31,6,3,7233,,,0,"Add object-server partial write prevention tests

This change adds some additional unit tests to test that partial
writes are handled correctly through the object-server.

The bug initially wanted to test for partial writes when the
object server wrapped up os.write. However, now that the writing out
to disk is happening in the diskfile object, the object-server tests
now only have to deal with partial writes correctly when the written
byte counts are passed back from the diskfile object indicate a
partial write.

Change-Id: I1aac09500a566204ff44848b6762fdc17a6e7f04
Closes-Bug: 1040883
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/101743/2 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_server.py'],1,cd81ad273119a8dbfbbb2b44105e31c702e088dd,bug/1040883," def test_PUT_partial_write(self): content_length = 100 content_length_written = 90 def mock_disk_file_writer_write(*args, **kargs): return content_length_written timestamp = normalize_timestamp(time()) with mock.patch(""swift.obj.diskfile.DiskFileWriter.write"", mock_disk_file_writer_write): req = Request.blank( '/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={'X-Timestamp': timestamp, 'Content-Length': str(content_length), 'Content-Type': 'application/octet-stream'}) req.body = 'VERIFY' resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 499) def test_PUT_partial_write_bigger_then_network_chunk(self): network_chunk_size = self.object_controller.network_chunk_size bytes_written = (b for b in (network_chunk_size, 5)) content_length = network_chunk_size + 6 def mock_disk_file_writer_write(*args, **kargs): bytes_written.next() timestamp = normalize_timestamp(time()) with mock.patch(""swift.obj.diskfile.DiskFileWriter.write"", mock_disk_file_writer_write): req = Request.blank( '/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={'X-Timestamp': timestamp, 'Content-Length': str(content_length), 'Content-Type': 'application/octet-stream'}) req.body = 'VERIFY' resp = req.get_response(self.object_controller) self.assertEquals(resp.status_int, 499) ",,39,0
openstack%2Fswift~master~Ibdc219eb1161663d2a7278505086524da29b3e34,openstack/swift,master,Ibdc219eb1161663d2a7278505086524da29b3e34,Add option to log container metadata,ABANDONED,2014-01-16 20:01:57.000000000,2014-12-11 18:01:25.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 917}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-01-16 20:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7b5e4f198b2e77ae5c16da10b622d2538ffbe07b', 'message': 'Add middleware for logging container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nThese cases are not meant to be exhaustive.\n\nlogmetadata uses the proxy_logging middleware and swift.log_info\nto forward additional log info to it.\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 2, 'created': '2014-01-17 06:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c6e78255f28df0836b61ee1b7ef92618c113a1a1', 'message': 'Add middleware for logging container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nThese cases are not meant to be exhaustive.\n\nlogmetadata uses the proxy_logging middleware and swift.log_info\nto forward additional log info to it.\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 3, 'created': '2014-01-17 11:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/54a73f9da0413beb3aa8c07ccc14b8d0701e725c', 'message': 'Add middleware for logging container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nThese cases are not meant to be exhaustive.\n\nlogmetadata uses the proxy_logging middleware and swift.log_info\nto forward additional log info to it.\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 4, 'created': '2014-03-05 11:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/925b6658bdd6b0c9359a3b92ce5a1388bcf94a40', 'message': 'Add option to log container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nTo avoid changing the existing log format all metadata entries are\nadded to the log_info field.\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 5, 'created': '2014-03-05 16:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3fe33f399f42b5e423ee7b4edd794e1e5a4cec49', 'message': 'Add option to log container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nTo avoid changing the existing log format all metadata entries are\nadded to the log_info field.\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 6, 'created': '2014-04-14 08:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a5b224296d22b72c7cbe5da4da909597a5eda550', 'message': 'Add option to log container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding, Gluster or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nTo avoid changing the existing log format all metadata entries are\nadded to the log_info field.\n\nDocImpact\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 7, 'created': '2014-08-28 10:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/980673785c859e8133c1e3e7abcb59fbd083d376', 'message': 'Add option to log container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding, Gluster or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nTo avoid changing the existing log format all metadata entries are\nadded to the log_info field.\n\nDocImpact\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}, {'number': 8, 'created': '2014-09-29 20:00:46.000000000', 'files': ['swift/common/middleware/proxy_logging.py', 'etc/proxy-server.conf-sample', 'test/unit/common/middleware/test_proxy_logging.py', 'doc/source/logs.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/0c457741b3c0af1c8b710f7758e4b7fe3fa4452a', 'message': 'Add option to log container metadata\n\nIn some cases it is useful to include some metadata in the log files.\n\nUse cases might be:\n\n1) Information which storage policy was used\n    This might be especially useful to monitor performance when using\n    other storage backends, for example Erasure Coding, Gluster or Ceph.\n\n2) ""Tag"" log entries for postprocessing\n    Setting a metadata entry on a container could be used to tag all\n    log entries for this container and objects therein. An additional\n    postprocessing could deliver these log entries to the owner of\n    the container, for example to deliver access logs to account\n    owners when using staticweb middleware.\n\nTo avoid changing the existing log format all metadata entries are\nadded to the log_info field.\n\nDocImpact\n\nChange-Id: Ibdc219eb1161663d2a7278505086524da29b3e34\n'}]",5,67282,0c457741b3c0af1c8b710f7758e4b7fe3fa4452a,49,8,8,6968,,,0,"Add option to log container metadata

In some cases it is useful to include some metadata in the log files.

Use cases might be:

1) Information which storage policy was used
    This might be especially useful to monitor performance when using
    other storage backends, for example Erasure Coding, Gluster or Ceph.

2) ""Tag"" log entries for postprocessing
    Setting a metadata entry on a container could be used to tag all
    log entries for this container and objects therein. An additional
    postprocessing could deliver these log entries to the owner of
    the container, for example to deliver access logs to account
    owners when using staticweb middleware.

To avoid changing the existing log format all metadata entries are
added to the log_info field.

DocImpact

Change-Id: Ibdc219eb1161663d2a7278505086524da29b3e34
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/67282/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/logmetadata.py', 'etc/proxy-server.conf-sample', 'setup.cfg', 'test/unit/common/middleware/test_logmetadata.py', 'doc/source/misc.rst']",5,7b5e4f198b2e77ae5c16da10b622d2538ffbe07b,logmetadata,Log Metadata middleware ======================= .. automodule:: swift.common.middleware.logmetadata :members: :show-inheritance: ,,207,0
openstack%2Fswift~master~I378d820bde0e45d934597b40dfbc5e42f0ffd3a0,openstack/swift,master,I378d820bde0e45d934597b40dfbc5e42f0ffd3a0,Add sort option to container listings,ABANDONED,2014-09-13 00:57:25.000000000,2014-12-11 18:01:12.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2649}, {'_account_id': 2828}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-09-13 00:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/aea60ee39b1ed3d731f6692875b6b65b2be977b3', 'message': 'Add sort and order to container listings\n\nThis changes adds 2 more options to the container listing.\n\n1. Order:\nYou can specify if the list or ordered in byte or alphabetical order.\nBy default sqlite\'s ordering is in byte order rather then alphabetic.\nThis change adds the option to tell the container server to use\nalphabetic ordering if required with:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/c/?order=alpha\n\nThe order option of byte (?order=byte) is also available but this is\nalso the default value so can be ommited.\n\nTaking the following list:\n\n  [\'o1\', \'O1\', \'o10\', \'o2\', \'O4\', \'o3\']\n\nByte order is:\n\n  [\'O1\', \'O4\', \'o1\', \'o10\', \'o2\', \'o3\']\n\nWhere are alphabetic ordering would be:\n\n  [\'O1\', \'o1\', \'o10\', \'o2\', \'o3\', \'O4\']\n\nNOTE: In byte order uppercase letters come before lowercase.\n\n2. Sort:\nYou can now choose to order the object names in the container\nlisting by one of:\n  - \'name\', The default value\n  - \'size\', the size of the object; or\n  - \'date\', the date the object was created.\n\nFor example:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/c/?sort=size\n\nThis can be combined with the other options, such as reverse:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN""\n$STORAGE_URL/c/?sort=size&reverse=on\n\nDocImpact\n\nChange-Id: I378d820bde0e45d934597b40dfbc5e42f0ffd3a0\n'}, {'number': 2, 'created': '2014-09-26 06:56:09.000000000', 'files': ['swift/container/server.py', 'test/functional/tests.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/476e2c7f16bf2e095d6a9ed74e57681916ba945a', 'message': 'Add sort option to container listings\n\nThis changes adds a new option to the container listing, sort.\n\nYou can now choose to order the object names in the container\nlisting by one of:\n  - \'name\', The default value (sorts object name (byte ordering)\n  - \'alpha\', Alphabetic ordering of the object name.\n  - \'size\', the size of the object; or\n  - \'date\', the date the object was created.\n\nFor example:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/c/?sort=size\n\nThis can be combined with the other options, such as reverse:\n\n  curl -i -X GET -H ""X-Auth-Token: $TOKEN""\n$STORAGE_URL/c/?sort=size&reverse=on\n\nDocImpact\n\nChange-Id: I378d820bde0e45d934597b40dfbc5e42f0ffd3a0\n'}]",0,121278,476e2c7f16bf2e095d6a9ed74e57681916ba945a,15,7,2,7233,,,0,"Add sort option to container listings

This changes adds a new option to the container listing, sort.

You can now choose to order the object names in the container
listing by one of:
  - 'name', The default value (sorts object name (byte ordering)
  - 'alpha', Alphabetic ordering of the object name.
  - 'size', the size of the object; or
  - 'date', the date the object was created.

For example:

  curl -i -X GET -H ""X-Auth-Token: $TOKEN"" $STORAGE_URL/c/?sort=size

This can be combined with the other options, such as reverse:

  curl -i -X GET -H ""X-Auth-Token: $TOKEN""
$STORAGE_URL/c/?sort=size&reverse=on

DocImpact

Change-Id: I378d820bde0e45d934597b40dfbc5e42f0ffd3a0
",git fetch https://review.opendev.org/openstack/swift refs/changes/78/121278/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py']",3,aea60ee39b1ed3d731f6692875b6b65b2be977b3,reverse_listing,"ORDER_TYPES = {'byte': '', 'alpha': 'COLLATE NOCASE'} SORT_TYPES = {'name': 'name', 'size': 'size', 'date': 'created_at'} path=None, storage_policy_index=0, reverse=False, sort='name', order='byte'): :param reverse: reverse the result order :param sort: Object column to sort by. Possible values: 'name', 'size' or 'date' :param order: The order to sort by. Possible values are 'byte' for byte ordering and 'alpha' for alphabetic ordering query += ' name < ? %s AND' % (ORDER_TYPES.get(order, '')) query += ' name >= ? %s AND' % (ORDER_TYPES.get(order, '')) query += ' name > ? %s AND' % (ORDER_TYPES.get(order, '')) query += ' name >= ? %s AND' % (ORDER_TYPES.get(order, '')) ORDER BY %s %s %s LIMIT ? ''' % (SORT_TYPES.get(sort, 'name'), ORDER_TYPES.get(order, ''), 'DESC' if reverse else '')"," path=None, storage_policy_index=0, reverse=False): :param reverse: reverse the result order. query += ' name < ? AND' query += ' name >= ? AND' query += ' name > ? AND' query += ' name >= ? AND' ORDER BY name %s LIMIT ? ''' % ('DESC' if reverse else '')",63,17
openstack%2Fpython-swiftclient~master~I40dbd7ec344d1ecaac5f7574d6f27095c9c3e4bc,openstack/python-swiftclient,master,I40dbd7ec344d1ecaac5f7574d6f27095c9c3e4bc,Fix race condition with _retry,ABANDONED,2014-09-22 12:56:39.000000000,2014-12-11 18:01:00.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7069}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-09-22 12:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/4b96f1fa2dd02a3780a13e601918e7ec51aa7f0f', 'message': 'Fix race condition with _retry\n\nStoring the attempts as an instance variable on _retry() is a race\ncondition where multiple api calls may clash causing the count\nto be wrong.\n\nAs attempts should be a local variable it is untestable without\nmocking the whole method. Rather the unittests should ensure that\n_retry does the right thing without worrying about its internals.\n\nChange-Id: I40dbd7ec344d1ecaac5f7574d6f27095c9c3e4bc\nPartial-Bug: #1372429\n'}, {'number': 2, 'created': '2014-10-01 10:19:49.000000000', 'files': ['tests/unit/test_swiftclient.py', 'swiftclient/client.py', 'swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/6527f3c1b1ee62afce8d80ec009ff9604bcc086e', 'message': 'Fix race condition with _retry\n\nStoring the attempts as an instance variable on _retry() is a race\ncondition where multiple api calls may clash causing the count\nto be wrong.\n\nAs attempts should be a local variable it is untestable without\nmocking the whole method. Rather the unittests should ensure that\n_retry does the right thing without worrying about its internals.\n\nChange-Id: I40dbd7ec344d1ecaac5f7574d6f27095c9c3e4bc\nPartial-Bug: #1372429\n'}]",2,123118,6527f3c1b1ee62afce8d80ec009ff9604bcc086e,14,6,2,7069,,,0,"Fix race condition with _retry

Storing the attempts as an instance variable on _retry() is a race
condition where multiple api calls may clash causing the count
to be wrong.

As attempts should be a local variable it is untestable without
mocking the whole method. Rather the unittests should ensure that
_retry does the right thing without worrying about its internals.

Change-Id: I40dbd7ec344d1ecaac5f7574d6f27095c9c3e4bc
Partial-Bug: #1372429
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/18/123118/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_swiftclient.py', 'swiftclient/client.py']",2,4b96f1fa2dd02a3780a13e601918e7ec51aa7f0f,123118, attempts = 0 while attempts <= self.retries: attempts += 1 if attempts > self.retries: if attempts > self.retries:, self.attempts = 0 while self.attempts <= self.retries: self.attempts += 1 if self.attempts > self.retries: if self.attempts > self.retries:,5,10
openstack%2Fswift~master~I01f03ef602ac4ce0bb24a34b928688b62d71d63e,openstack/swift,master,I01f03ef602ac4ce0bb24a34b928688b62d71d63e,Don't need to initialize dict explicitly,ABANDONED,2014-10-12 16:03:02.000000000,2014-12-11 18:00:49.000000000,,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7479}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-10-12 16:03:02.000000000', 'files': ['swift/account/auditor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/90f770328e8010b81c00d3a4a79f52f4d08b8683', 'message': ""Don't need to initialize dict explicitly\n\nUse defaultdict instead. It's more concise.\n\nCloses-Bug: 1380325\n\nChange-Id: I01f03ef602ac4ce0bb24a34b928688b62d71d63e\n""}]",1,127840,90f770328e8010b81c00d3a4a79f52f4d08b8683,7,5,1,11203,,,0,"Don't need to initialize dict explicitly

Use defaultdict instead. It's more concise.

Closes-Bug: 1380325

Change-Id: I01f03ef602ac4ce0bb24a34b928688b62d71d63e
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/127840/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/account/auditor.py'],1,90f770328e8010b81c00d3a4a79f52f4d08b8683,bug/1380325,from collections import defaultdict policy_totals = defaultdict(int) for policy_stat in policy_stats.values(): for key in policy_stat:," policy_totals = { 'container_count': 0, 'object_count': 0, 'bytes_used': 0, } for policy_stat in policy_stats.values(): for key in policy_totals:",3,6
openstack%2Fswift-specs~master~I1b396a7afc8db7c5d1d8727716ef9b46577272d5,openstack/swift-specs,master,I1b396a7afc8db7c5d1d8727716ef9b46577272d5,Add log translation hints for swift,ABANDONED,2014-07-10 03:12:07.000000000,2014-12-11 18:00:31.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}]","[{'number': 1, 'created': '2014-07-10 03:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/870e2a84d2371d3e5d180eec2c7709daf2ca27ac', 'message': 'Add log translation hints for swift\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So swift should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I1b396a7afc8db7c5d1d8727716ef9b46577272d5\n'}, {'number': 2, 'created': '2014-07-10 03:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/603e85c857112320b85bfb47592fdc2907c11389', 'message': 'Add log translation hints for swift\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So swift should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I1b396a7afc8db7c5d1d8727716ef9b46577272d5\n'}, {'number': 3, 'created': '2014-07-10 03:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/827a68879ffd73eb388c800e4e51cd28794460bb', 'message': 'Add log translation hints for swift\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So swift should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I1b396a7afc8db7c5d1d8727716ef9b46577272d5\n'}, {'number': 4, 'created': '2014-07-10 03:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/b030894e4f43f2b354a3661cfe3b7e4363d4afb2', 'message': 'Add log translation hints for swift\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So swift should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I1b396a7afc8db7c5d1d8727716ef9b46577272d5\n'}, {'number': 5, 'created': '2014-07-10 04:00:13.000000000', 'files': ['specs/swift/support-log-translation-hints.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/cdefd9eb8fdabb705d96f59080314ba13bd47240', 'message': 'Add log translation hints for swift\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So swift should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I1b396a7afc8db7c5d1d8727716ef9b46577272d5\n'}]",0,105955,cdefd9eb8fdabb705d96f59080314ba13bd47240,21,3,5,8874,,,0,"Add log translation hints for swift

Current oslo libraries support translating log messages using different
translation domains and oslo would like to see hints in all of our code
by the end of juno. So swift should handle the changes out over the
release.Relate info about log translation hints as follows:
    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout
    https://review.openstack.org/#/c/70455

blueprint support-log-translation-hints

Change-Id: I1b396a7afc8db7c5d1d8727716ef9b46577272d5
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/55/105955/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/swift/juno/support-log-translation-hints.rst'],1,870e2a84d2371d3e5d180eec2c7709daf2ca27ac,bp/s,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Add log translation hints for swift =================================== https://blueprints.launchpad.net/swift/+spec/support-log-translation-hints To update swift log messages to take advantage of oslo's new feature of supporting translating log messages using different translation domains. Problem description =================== Current oslo libraries support translating log messages using different translation domains and oslo would like to see hints in all of our code by the end of juno. So swift should handle the changes out over the release. Proposed change =============== Since there are too many files need to change, so divide this bp into 20 patches according to swift directories:: swift  account  common   middleware   ring  container  obj  proxy  controllers test functional functionalnosetests probe unit For each directory's files, we change all the log messages as follows. 1. Change ""LOG.exception(_("" to ""LOG.exception(_LE"". 2. Change ""LOG.warn(_("" to ""LOG.warn(_LW("". 3. Change ""LOG.info(_("" to ""LOG.info(_LI("". 4. Change ""LOG.critical(_("" to ""LOG.info(_LC("". Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: ling-yun<zengyunling@huawei.com> Work Items ---------- For each directory's files, we change all the log messages as follows. 1. Change ""LOG.exception(_("" to ""LOG.exception(_LE"". 2. Change ""LOG.warn(_("" to ""LOG.warn(_LW("". 3. Change ""LOG.info(_("" to ""LOG.info(_LI("". 4. Change ""LOG.critical(_("" to ""LOG.info(_LC("". We handle these changes in the following order:: swift swift/account swift/common swift/container swift/obj swift/proxy test test/functional test/functionalnosetests test/probe test/unit Add a HACKING check rule to ensure that log messages to relative domain. Using regular expression to check whether log messages with relative _L* function. :: log_translation_domain_error = re.compile( r""(.)*LOG\.error\(\s*_LE\(('|\"")"") log_translation_domain_info = re.compile( r""(.)*LOG\.info\(\s*_LI\(('|\"")"") log_translation_domain_warn = re.compile( r""(.)*LOG\.(warn|warning)\(\s*_LW\(('|\"")"") log_translation_domain_critical = re.compile( r""(.)*LOG\.critical\(\s*_LC\(('|\"")"") Future lifecycle ================ None Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== [1]https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout [2]https://review.openstack.org/#/c/70455 [3]https://wiki.openstack.org/wiki/LoggingStandards",,168,0
openstack%2Fkeystone-specs~master~Ieafec9c9c8d277061b181df15926b5330b87c578,openstack/keystone-specs,master,Ieafec9c9c8d277061b181df15926b5330b87c578,Scope federated tokens with ``token`` auth method.,MERGED,2014-11-25 11:06:36.000000000,2014-12-11 17:59:30.000000000,2014-12-11 17:59:30.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-11-25 11:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/2dfca49733f9e2e9b3bf7e96bbf7c530bb037127', 'message': 'Scope federated tokens with ``token`` auth method.\n\nFor a greater unification, process of scoping federated tokens should\nuse ``token`` auth method instead of ``saml2``.\nRequired code changes are in https://review.openstack.org/#/c/130593\nThis patch reflects the changes in the documentation.\n\nChange-Id: Ieafec9c9c8d277061b181df15926b5330b87c578\n'}, {'number': 2, 'created': '2014-11-26 11:29:04.000000000', 'files': ['api/v3/identity-api-v3-os-federation-ext.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/06fb16ad1eb55b62429159de5de1298545de3b49', 'message': 'Scope federated tokens with ``token`` auth method.\n\nFor a greater unification, process of scoping federated tokens should\nuse ``token`` auth method instead of ``saml2``.\nRequired code changes are in https://review.openstack.org/#/c/130593\nThis patch reflects the changes in the documentation.\n\nChange-Id: Ieafec9c9c8d277061b181df15926b5330b87c578\n'}]",0,137020,06fb16ad1eb55b62429159de5de1298545de3b49,10,12,2,8978,,,0,"Scope federated tokens with ``token`` auth method.

For a greater unification, process of scoping federated tokens should
use ``token`` auth method instead of ``saml2``.
Required code changes are in https://review.openstack.org/#/c/130593
This patch reflects the changes in the documentation.

Change-Id: Ieafec9c9c8d277061b181df15926b5330b87c578
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/20/137020/1 && git format-patch -1 --stdout FETCH_HEAD,['api/v3/identity-api-v3-os-federation-ext.rst'],1,2dfca49733f9e2e9b3bf7e96bbf7c530bb037127,137020," ""token"" ""token: {"," ""saml2"" ""saml2"": {",2,2
openstack%2Fswift-specs~master~I14555cd6dd8b5f5286ac1ef7aa1c87005eaf8ea4,openstack/swift-specs,master,I14555cd6dd8b5f5286ac1ef7aa1c87005eaf8ea4,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:52:25.000000000,2014-12-11 17:57:50.000000000,2014-12-11 17:57:48.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-12-05 03:52:25.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/532b4669a3f2b21f6ba71e7310dfeb54c084c5b1', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I14555cd6dd8b5f5286ac1ef7aa1c87005eaf8ea4\n'}]",0,139394,532b4669a3f2b21f6ba71e7310dfeb54c084c5b1,8,4,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I14555cd6dd8b5f5286ac1ef7aa1c87005eaf8ea4
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/94/139394/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,532b4669a3f2b21f6ba71e7310dfeb54c084c5b1,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer, start here"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",3,4
openstack%2Fpython-novaclient~master~I1089901de769df3312d4a15b6d6e5e60b1ed51e0,openstack/python-novaclient,master,I1089901de769df3312d4a15b6d6e5e60b1ed51e0,"Avoid ""ambiguous option"" when only current/deprecated forms match",MERGED,2014-10-13 09:19:27.000000000,2014-12-11 17:51:56.000000000,2014-12-11 17:51:55.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1501}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 8124}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-13 09:19:27.000000000', 'files': ['novaclient/tests/test_shell.py', 'novaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f4709f02c24fdb3259d07057b9912e8e49229f1d', 'message': 'Avoid ""ambiguous option"" when only current/deprecated forms match\n\nargparse.ArgumentParser allows to specify partially options:\n\n  nova boot ... --key-nam mykey\n  # is equivalent to\n  nova boot ... --key-name mykey\n\nan error is raised if the provided prefix matchs 0 or 2+ options:\n\n  nova boot ... --os value\n  # raises an ""ambiguous option"" error because --os could match\n  # --os-username, --os_username ...\n\neven if the provided prefix matchs only the current/deprecated\nforms of the same attribute:\n\n  nova boot ... --key mykey\n  # raises an ""ambiguous option"" error because --key could match\n  # --my-key, --my_key ...\n\nThis change extends argparse.ArgumentParser to avoid raising an\n""ambiguous option"" when the provided prefix matchs only the current and\ndeprecated forms of the same attribute.\n\nChange-Id: I1089901de769df3312d4a15b6d6e5e60b1ed51e0\n'}]",7,127910,f4709f02c24fdb3259d07057b9912e8e49229f1d,20,8,1,8124,,,0,"Avoid ""ambiguous option"" when only current/deprecated forms match

argparse.ArgumentParser allows to specify partially options:

  nova boot ... --key-nam mykey
  # is equivalent to
  nova boot ... --key-name mykey

an error is raised if the provided prefix matchs 0 or 2+ options:

  nova boot ... --os value
  # raises an ""ambiguous option"" error because --os could match
  # --os-username, --os_username ...

even if the provided prefix matchs only the current/deprecated
forms of the same attribute:

  nova boot ... --key mykey
  # raises an ""ambiguous option"" error because --key could match
  # --my-key, --my_key ...

This change extends argparse.ArgumentParser to avoid raising an
""ambiguous option"" when the provided prefix matchs only the current and
deprecated forms of the same attribute.

Change-Id: I1089901de769df3312d4a15b6d6e5e60b1ed51e0
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/10/127910/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/test_shell.py', 'novaclient/shell.py']",2,f4709f02c24fdb3259d07057b9912e8e49229f1d,less-ambiguous," def _get_option_tuples(self, option_string): """"""returns (action, option, value) candidates for an option prefix Returns [first candidate] if all candidates refers to current and deprecated forms of the same options: ""nova boot ... --key KEY"" parsing succeed because --key could only match --key-name, --key_name which are current/deprecated forms of the same option. """""" option_tuples = (super(NovaClientArgumentParser, self) ._get_option_tuples(option_string)) if len(option_tuples) > 1: normalizeds = [option.replace('_', '-') for action, option, value in option_tuples] if len(set(normalizeds)) == 1: return option_tuples[:1] return option_tuples ",,42,0
openstack%2Foslo.vmware~master~Iedcf94964907d2682df9f329b617b5d45e3f9667,openstack/oslo.vmware,master,Iedcf94964907d2682df9f329b617b5d45e3f9667,Updated from global requirements,MERGED,2014-12-11 07:19:40.000000000,2014-12-11 17:50:05.000000000,2014-12-11 17:50:04.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 9008}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-12-11 07:19:40.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/77dc51eeed6b4b501c52aa92526012dcc03b2cc7', 'message': 'Updated from global requirements\n\nChange-Id: Iedcf94964907d2682df9f329b617b5d45e3f9667\n'}]",0,140952,77dc51eeed6b4b501c52aa92526012dcc03b2cc7,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: Iedcf94964907d2682df9f329b617b5d45e3f9667
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/52/140952/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,77dc51eeed6b4b501c52aa92526012dcc03b2cc7,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,2,2
openstack%2Ffuel-library~stable%2F6.0~Ia1b6fc205ae040b7cabd60e3104ea97d565d797a,openstack/fuel-library,stable/6.0,Ia1b6fc205ae040b7cabd60e3104ea97d565d797a,Fix for murano-manage package-import,MERGED,2014-12-11 16:08:37.000000000,2014-12-11 17:49:57.000000000,2014-12-11 17:49:57.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-11 16:08:37.000000000', 'files': ['deployment/puppet/murano/manifests/application_package.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/46306387dff9ce61d602dad67fa121cd2c7b7988', 'message': 'Fix for murano-manage package-import\n\n* This patchset resolves issue with re-upload of already existing murano application package\n\nChange-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a\nRelated-Bug: # 1401503\n'}]",0,141084,46306387dff9ce61d602dad67fa121cd2c7b7988,10,5,1,7613,,,0,"Fix for murano-manage package-import

* This patchset resolves issue with re-upload of already existing murano application package

Change-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a
Related-Bug: # 1401503
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/84/141084/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/murano/manifests/application_package.pp'],1,46306387dff9ce61d602dad67fa121cd2c7b7988,," '' => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' --update"", default => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' -c '${package_category}' --update"","," '' => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}'"", default => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' -c '${package_category}'"",",2,2
openstack%2Foctavia~master~I3e72db6d2f19fe45138758eb0821e27aa1c2542a,openstack/octavia,master,I3e72db6d2f19fe45138758eb0821e27aa1c2542a,Add Amphora base image creation scripts for Octavia,MERGED,2014-11-05 19:09:54.000000000,2014-12-11 17:44:50.000000000,2014-12-11 17:44:49.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 10806}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-11-05 19:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2631104098cac5082ff5c0382cea2b72f028efc7', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 2, 'created': '2014-11-14 00:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f8cf7f4bee9e4ddf21e0275a3e3bf065bed4a6c1', 'message': ' Add Amphora base image creation scripts for Octavia\n\n TODO: Add tests\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 3, 'created': '2014-11-14 00:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cfbfbed93fbb615b3c8e0327563214dc82df1e89', 'message': ' Add Amphora base image creation scripts for Octavia\n\n TODO: Add tests\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 4, 'created': '2014-11-15 02:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/96165a3147f025384028375c89e0919c34001c9f', 'message': ' Add Amphora base image creation scripts for Octavia\n\n TODO: Add tests\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 5, 'created': '2014-11-18 02:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/858d275356d587cd904b4fd0ab6430b3ede411fa', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 6, 'created': '2014-11-18 21:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9ec04460e4edfdee373d795f102b36d193f9c503', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 7, 'created': '2014-11-20 00:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1d72b3e01e9b3e7c41f3e59709bcfe19d24d7db2', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 8, 'created': '2014-11-21 01:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e2c2f46b6ddbf4f9080d6e142d70805a84dd79da', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 9, 'created': '2014-12-05 22:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8b5ea9a4fb071b5e5c3801d83e0f50f172820564', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 10, 'created': '2014-12-11 01:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a2a4ef085e5423ca7db23fa231013f3d745ef38d', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}, {'number': 11, 'created': '2014-12-11 01:31:25.000000000', 'files': ['elements/haproxy-octavia/install.d/package-installs-haproxy', 'elements/centos-mirror/pre-install.d/00-yum', 'elements/centos-mirror/root.d/0-check', 'elements/root-passwd/post-install.d/99-setup', 'elements/apt-mirror/pre-install.d/00-apt', 'elements/haproxy-octavia/element-deps', 'diskimage-create/diskimage-create.sh', 'diskimage-create/tox.ini', 'elements/haproxy-octavia/os-refresh-config/configure.d/20-haproxy-tune-kernel', 'elements/fedora-mirror/finalise.d/99-setup', 'specs/version0.5/base-image.rst', 'diskimage-create/version.txt', 'elements/haproxy-octavia/README.rst', 'elements/root-passwd/README.rst', 'diskimage-create/image-tests.sh', 'elements/fedora-mirror/README.rst', 'elements/fedora-mirror/root.d/0-check', 'elements/centos-mirror/finalise.d/99-setup', 'diskimage-create/test-requirements.txt', 'elements/haproxy-octavia/svc-map', 'elements/apt-mirror/finalise.d/99-setup', 'elements/fedora-mirror/pre-install.d/00-yum', 'diskimage-create/requirements.txt', 'elements/apt-mirror/README.rst', 'diskimage-create/README.rst', 'elements/centos-mirror/README.rst', 'elements/haproxy-octavia/install.d/76-haproxy', 'elements/apt-mirror/root.d/0-check', 'elements/haproxy-octavia/os-refresh-config/configure.d/20-haproxy-selinux'], 'web_link': 'https://opendev.org/openstack/octavia/commit/9df9ff9137af0d4602283232dc1352cb6b43a3d1', 'message': ' Add Amphora base image creation scripts for Octavia\n\n Implements: blueprint base-image\n\nChange-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a\n'}]",33,132904,9df9ff9137af0d4602283232dc1352cb6b43a3d1,45,6,11,11628,,,0," Add Amphora base image creation scripts for Octavia

 Implements: blueprint base-image

Change-Id: I3e72db6d2f19fe45138758eb0821e27aa1c2542a
",git fetch https://review.opendev.org/openstack/octavia refs/changes/04/132904/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/centos-mirror/README.md', 'elements/centos-mirror/pre-install.d/00-yum', 'elements/fedora-mirror/README.md', 'elements/fedora-mirror/root.d/0-check', 'elements/centos-mirror/finalise.d/99-setup', 'elements/centos-mirror/root.d/0-check', 'elements/apt-mirror/pre-install.d/00-apt', 'diskimage-create/diskimage-create.sh', 'elements/apt-mirror/finalise.d/99-setup', 'elements/fedora-mirror/pre-install.d/00-yum', 'diskimage-create/README.rst', 'elements/apt-mirror/README.md', 'elements/fedora-mirror/finalise.d/99-setup', 'specs/version0.5/base-image.rst', 'elements/apt-mirror/root.d/0-check']",15,2631104098cac5082ff5c0382cea2b72f028efc7,bp/base-image,"#!/bin/bash if [ -z ""$UBUNTU_MIRROR"" ]; then echo ""You should specify parameter 'UBUNTU_MIRROR'"" exit 2 fi ",,502,2
openstack%2Fneutron-vpnaas~master~I3529fe4146c50c940f41eb26d0b5efc5870b3af9,openstack/neutron-vpnaas,master,I3529fe4146c50c940f41eb26d0b5efc5870b3af9,Move classes out of l3_agent.py,MERGED,2014-12-10 18:24:19.000000000,2014-12-11 17:35:00.000000000,2014-12-11 17:34:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 18:24:19.000000000', 'files': ['neutron_vpnaas/tests.skip/unit/services/vpn/test_vpn_agent.py', 'neutron_vpnaas/services/vpn/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b807d2c52253767f25a3325d6c0eaf245ebb6747', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\nRelates-to: https://review.openstack.org/#/c/130300/\n""}]",1,140798,b807d2c52253767f25a3325d6c0eaf245ebb6747,14,7,1,1131,,,0,"Move classes out of l3_agent.py

The file l3_agent.py has become too large.  This patch is a simple
pure refactor to move some of the functionality in to other files
where things aren't too tangled up.  There is no functional change
with this patch and I avoided gratuitous other fixups in this patch in
order to make it easier to review.

I plan to follow up on the new l3_dvr and l3_agent_router modules with
more restructuring in the near future.

Partially-Implements: bp restructure-l3-agent

Change-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9
Relates-to: https://review.openstack.org/#/c/130300/
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/98/140798/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests.skip/unit/services/vpn/test_vpn_agent.py', 'neutron_vpnaas/services/vpn/agent.py']",2,b807d2c52253767f25a3325d6c0eaf245ebb6747,bp/restructure-l3-agent,from neutron.agent.l3 import agentclass VPNAgent(agent.L3NATAgentWithStateReport): agent.main(,from neutron.agent import l3_agentclass VPNAgent(l3_agent.L3NATAgentWithStateReport): l3_agent.main(,15,14
openstack%2Fopenstack-ansible~master~I412549bca87d81b4c82bf88046b23c5ba8921f84,openstack/openstack-ansible,master,I412549bca87d81b4c82bf88046b23c5ba8921f84,[WIP] Download tars rather than cloning git repos,ABANDONED,2014-12-11 10:50:51.000000000,2014-12-11 17:32:46.000000000,,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 9884}, {'_account_id': 14119}]","[{'number': 1, 'created': '2014-12-11 10:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/141df36ebd5bef7559fe3f1e605e692664297362', 'message': '[WIP] Try tarball before cloning repos\n\nMay make things faster.\n\nChange-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84\n'}, {'number': 2, 'created': '2014-12-11 10:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9f79ac1cb040e41a3d42f7ad54a607fa660eb6ff', 'message': '[WIP] Try tarball before cloning repos\n\nMay make things faster.\n\nChange-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84\n'}, {'number': 3, 'created': '2014-12-11 10:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/037bbff0a5adc179810c00e45984f46276fe2127', 'message': '[WIP] Try tarball before cloning repos\n\nMay make things faster.\n\nChange-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84\n'}, {'number': 4, 'created': '2014-12-11 12:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ca610cb8de9398a97de37d1e52da765274dd9ad3', 'message': ""[WIP] Download tars rather than cloning git repos\n\n* Attempt to download tarball from github, fall back to git.openstack on\n  failure\n* Store sha in src dir for comparison on the next run\n* Remove src dir and re-download if:\n  * .verison file doesn't exist in src dir\n  * git_install_branch in upstream repo points to different sha\n  * git_install_branch in our config has changed\n\nChange-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84\n""}, {'number': 5, 'created': '2014-12-11 13:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/acad0a28aba14dddd422daba7d984dc8825ab307', 'message': ""[WIP] Download tars rather than cloning git repos\n\n* Attempt to download tarball from github, fall back to git.openstack on\n  failure\n* Store sha in src dir for comparison on the next run\n* Remove src dir and re-download if:\n  * .verison file doesn't exist in src dir\n  * git_install_branch in upstream repo points to different sha\n  * git_install_branch in our config has changed\n\nChange-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84\n""}, {'number': 6, 'created': '2014-12-11 15:20:42.000000000', 'files': ['rpc_deployment/roles/openstack_common/tasks/install_git_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9320437e32e6b46f1c122fd40675c8403e997d68', 'message': ""[WIP] Download tars rather than cloning git repos\n\n* Attempt to download tarball from github, fall back to git.openstack on\n  failure\n* Store sha in src dir for comparison on the next run\n* Remove src dir and re-download if:\n  * .verison file doesn't exist in src dir\n  * git_install_branch in upstream repo points to different sha\n  * git_install_branch in our config has changed\n\nChange-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84\n""}]",0,141008,9320437e32e6b46f1c122fd40675c8403e997d68,19,4,6,7217,,,0,"[WIP] Download tars rather than cloning git repos

* Attempt to download tarball from github, fall back to git.openstack on
  failure
* Store sha in src dir for comparison on the next run
* Remove src dir and re-download if:
  * .verison file doesn't exist in src dir
  * git_install_branch in upstream repo points to different sha
  * git_install_branch in our config has changed

Change-Id: I412549bca87d81b4c82bf88046b23c5ba8921f84
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/08/141008/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/openstack_common/tasks/install_git_source.yml'],1,141df36ebd5bef7559fe3f1e605e692664297362,fasterate_clones,"- name: Create repo dir file: path: ""{{ git_dest }}"" state: directory - name: Get tarball from github shell: | curl https://codeload.github.com/{{ git_namespace|default('openstack') }}/{{ repo_package_name }}/tar.gz/{{ git_install_branch }} \ |tar xz -C {{ git_dest }} --strip-compontents=1 args: creates: {{ git_dest }} register: get_tarball - name: Clone package from primary git source when: get_tarball|failed- name: Clone package from fallback git repo",- name: Get package from git- name: Get package from fallback git repo,16,2
openstack%2Fapi-site~master~I19003b284696c3fe53de22bd27437dc0749edc33,openstack/api-site,master,I19003b284696c3fe53de22bd27437dc0749edc33,Adds WADL doc for os-flavor-swap Compute API ext,MERGED,2014-11-17 21:36:20.000000000,2014-12-11 17:29:59.000000000,2014-12-11 17:29:58.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-11-17 21:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/f14a8d56bfc8a0fc74f874db29326da09aec1f00', 'message': 'Adds WADL doc for os-flavor-swap Compute API ext\n\nChange-Id: I19003b284696c3fe53de22bd27437dc0749edc33\nCloses-bug: 1097785\n'}, {'number': 2, 'created': '2014-11-18 23:17:12.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/ext/os-flavor-swap.wadl', 'api-ref/src/docbkx/ch_compute-v2-ext.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/49a3f4d27e65c8775f2e5099eb231e3bbbb70486', 'message': 'Adds WADL doc for os-flavor-swap Compute API ext\n\nChange-Id: I19003b284696c3fe53de22bd27437dc0749edc33\nCloses-bug: 1097785\n'}]",0,135088,49a3f4d27e65c8775f2e5099eb231e3bbbb70486,9,3,2,964,,,0,"Adds WADL doc for os-flavor-swap Compute API ext

Change-Id: I19003b284696c3fe53de22bd27437dc0749edc33
Closes-bug: 1097785
",git fetch https://review.opendev.org/openstack/api-site refs/changes/88/135088/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/docbkx/ch_compute-v2-ext.xml', 'api-ref/src/wadls/compute-api/src/v2/ext/os-flavor-swap.wadl']",2,f14a8d56bfc8a0fc74f874db29326da09aec1f00,bug/1097785,"<?xml version=""1.0"" encoding=""UTF-8""?> <!-- (C) 2012-2014 OpenStack Foundation, All Rights Reserved --> <application xmlns=""http://wadl.dev.java.net/2009/02"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:xsdxt=""http://docs.rackspacecloud.com/xsd-ext/v1.0"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <resources base=""https://servers.api.openstack.com"" xml:id=""os-flavor-swap-v2""> <resource id=""version"" type=""#VersionDetails"" path=""//v2""> <resource id=""tenant_id"" path=""{tenant_id}""> <param name=""tenant_id"" style=""template"" type=""xsd:string""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""><para>The ID for the tenant or account in a multi-tenancy cloud.</para></wadl:doc> </param> <resource id=""flavors"" path=""flavors""> <resource path=""{flavor_id}"" id=""flavor_id""> <param name=""flavor_id"" style=""template"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""><para>The ID of the flavor of interest to you. </para></wadl:doc> </param> <resource path=""os-flavor-swap"" id=""os-flavor-swap""> <method href=""#listFlavor-swap""/> <method href=""#createFlavor-swap""/> </resource> </resource> </resource> </resource> </resource> </resources> <method name=""GET"" id=""listFlavor-swap""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""List flavor extra specs""> <para role=""shortdesc"">Lists the flavor specs including swap value for the specified flavor. The swap value is the amount of swap disk space, in GBs, to allocate to a server.</para> </wadl:doc> <response status=""200""> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/os-flavor-swap/flavor-swap-list-resp.json"" /> </wadl:doc> </representation> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/os-flavor-swap/flavor-swap-list-resp.xml"" /> </wadl:doc> </representation> </response> </method> <method name=""POST"" id=""createflavor-swap""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Create flavor extra specs""> <para role=""shortdesc"">Creates flavor including swap value for the specified flavor. The swap value is the amount of swap disk space, in GBs, to allocate to a server.</para> </wadl:doc> <request> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/os-flavor-swap/flavor-swap-post-req.json"" /> </wadl:doc> </representation> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/os-flavor-swap/flavor-swap-post-req.xml"" /> </wadl:doc> </representation> </request> <response status=""200""> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/os-flavor-swap/flavor-swap-post-resp.json"" /> </wadl:doc> </representation> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../api_samples/os-flavor-swap/flavor-swap-post-resp.xml"" /> </wadl:doc> </representation> </response> </method> </application> ",,118,0
openstack%2Fneutron-fwaas~master~I3529fe4146c50c940f41eb26d0b5efc5870b3af9,openstack/neutron-fwaas,master,I3529fe4146c50c940f41eb26d0b5efc5870b3af9,Move classes out of l3_agent.py,MERGED,2014-12-10 18:23:01.000000000,2014-12-11 17:29:51.000000000,2014-12-11 17:29:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 10980}, {'_account_id': 11822}]","[{'number': 1, 'created': '2014-12-10 18:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/0787cbdfc7a4a6a31f433abe821993d18d572ea1', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\nRelates-to: https://review.openstack.org/#/c/130300/\n""}, {'number': 2, 'created': '2014-12-10 21:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/d98086f896ac633f1af6311c5345daaa0964de4c', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\nRelates-to: https://review.openstack.org/#/c/130300/\n""}, {'number': 3, 'created': '2014-12-10 22:35:43.000000000', 'files': ['neutron_fwaas/tests.skip/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/services/firewall/agents/varmour/varmour_router.py', 'neutron_fwaas/tests.skip/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests.skip/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f0d2bd631b7195c737db6888311a9baedf30319f', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\nRelates-to: https://review.openstack.org/#/c/130300/\n""}]",1,140797,f0d2bd631b7195c737db6888311a9baedf30319f,16,8,3,1131,,,0,"Move classes out of l3_agent.py

The file l3_agent.py has become too large.  This patch is a simple
pure refactor to move some of the functionality in to other files
where things aren't too tangled up.  There is no functional change
with this patch and I avoided gratuitous other fixups in this patch in
order to make it easier to review.

I plan to follow up on the new l3_dvr and l3_agent_router modules with
more restructuring in the near future.

Partially-Implements: bp restructure-l3-agent

Change-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9
Relates-to: https://review.openstack.org/#/c/130300/
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/97/140797/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests.skip/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/services/firewall/agents/varmour/varmour_router.py', 'neutron_fwaas/tests.skip/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests.skip/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py']",4,0787cbdfc7a4a6a31f433abe821993d18d572ea1,bp/restructure-l3-agent,"from neutron.agent import.l3 agent from neutron.agent import.l3 ha from neutron.agent import.l3 router_info self.conf.register_opts(agent.L3NATAgent.OPTS) self.conf.register_opts(ha.OPTS) return router_info.RouterInfo(router['id'], self.conf.root_helper, router=router, ns_name=ns)","from neutron.agent import l3_agent from neutron.agent import l3_ha_agent self.conf.register_opts(l3_agent.L3NATAgent.OPTS) self.conf.register_opts(l3_ha_agent.OPTS) return l3_agent.RouterInfo(router['id'], self.conf.root_helper, router=router, ns_name=ns)",27,25
openstack%2Fpuppet-nova~stable%2Fjuno~I8f226442f120ca07cd4e959c740aefa0c9012a2d,openstack/puppet-nova,stable/juno,I8f226442f120ca07cd4e959c740aefa0c9012a2d,Configure database parameters on the right nodes,MERGED,2014-12-02 16:13:23.000000000,2014-12-11 17:26:13.000000000,2014-12-11 17:26:12.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}]","[{'number': 1, 'created': '2014-12-02 16:13:23.000000000', 'files': ['spec/classes/nova_api_spec.rb', 'manifests/scheduler.pp', 'manifests/conductor.pp', 'manifests/api.pp', 'manifests/db.pp', 'manifests/init.pp', 'spec/classes/nova_scheduler_spec.rb', 'spec/classes/nova_db_spec.rb', 'spec/classes/nova_init_spec.rb', 'spec/classes/nova_conductor_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/467be679757b99f11f8c8994f07d3a34ae6234ed', 'message': 'Configure database parameters on the right nodes\n\nSince Grizzly, nova-compute does not need database access anymore.\nCurrently, only nova-api, nova-scheduler and nova-conductor really need\ndatabase access.\n\n* Keep original nova parameters with backward compatibility\n* Create nova::db with database parameters\n* Import nova::db in nova::init for backward compatibility\n* Import nova::db in nova::{api,conductor,scheduler}\n* Refactorize unit tests for conductor & scheduler\n\nImplements: blueprint move-db-params\n(cherry picked from commit 30b6a9c4c7d9b662eb8e70b58a1ad63d1c4e89aa)\n\nConflicts:\n\tmanifests/init.pp\n\nChange-Id: I8f226442f120ca07cd4e959c740aefa0c9012a2d\n'}]",0,138425,467be679757b99f11f8c8994f07d3a34ae6234ed,7,5,1,3153,,,0,"Configure database parameters on the right nodes

Since Grizzly, nova-compute does not need database access anymore.
Currently, only nova-api, nova-scheduler and nova-conductor really need
database access.

* Keep original nova parameters with backward compatibility
* Create nova::db with database parameters
* Import nova::db in nova::init for backward compatibility
* Import nova::db in nova::{api,conductor,scheduler}
* Refactorize unit tests for conductor & scheduler

Implements: blueprint move-db-params
(cherry picked from commit 30b6a9c4c7d9b662eb8e70b58a1ad63d1c4e89aa)

Conflicts:
	manifests/init.pp

Change-Id: I8f226442f120ca07cd4e959c740aefa0c9012a2d
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/25/138425/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_api_spec.rb', 'manifests/scheduler.pp', 'manifests/conductor.pp', 'manifests/api.pp', 'manifests/db.pp', 'manifests/init.pp', 'spec/classes/nova_scheduler_spec.rb', 'spec/classes/nova_db_spec.rb', 'spec/classes/nova_init_spec.rb', 'spec/classes/nova_conductor_spec.rb']",10,467be679757b99f11f8c8994f07d3a34ae6234ed,bp/move-db-params," let :params do { :enabled => true } end shared_examples 'nova-conductor' do it { should contain_package('nova-conductor').with( :name => platform_params[:conductor_package_name], :ensure => 'present' ) } it { should contain_service('nova-conductor').with( :name => platform_params[:conductor_service_name], :hasstatus => 'true', :ensure => 'running' )} context 'with manage_service as false' do let :params do { :enabled => true, :manage_service => false } end it { should contain_service('nova-conductor').without_ensure } end context 'with package version' do let :params do { :ensure_package => '2012.1-2' } end it { should contain_package('nova-conductor').with( :ensure => params[:ensure_package] )} end context 'with overriden workers parameter' do before do params.merge!({:workers => '5' }) end it { should contain_nova_config('conductor/workers').with_value('5') } end context 'with default database parameters' do let :pre_condition do ""include nova"" end it { should_not contain_nova_config('database/connection') } it { should_not contain_nova_config('database/idle_timeout').with_value('3600') } end context 'with overridden database parameters' do let :pre_condition do ""class { 'nova': database_connection => 'mysql://user:pass@db/db', database_idle_timeout => '30', } "" end it { should contain_nova_config('database/connection').with_value('mysql://user:pass@db/db').with_secret(true) } it { should contain_nova_config('database/idle_timeout').with_value('30') } end end let :platform_params do { :conductor_package_name => 'nova-conductor', :conductor_service_name => 'nova-conductor' } it_configures 'nova-conductor' context 'on Redhat platforms' do let :platform_params do { :conductor_package_name => 'openstack-nova-conductor', :conductor_service_name => 'openstack-nova-conductor' } it_configures 'nova-conductor'"," it_behaves_like 'generic nova service', { :name => 'nova-conductor', :package_name => 'nova-conductor', :service_name => 'nova-conductor' } it { should_not contain_nova_config('conductor/workers') } describe 'when overriding params' do let :params do {:workers => '5' } end it { should contain_nova_config('conductor/workers').with_value('5') } context 'on RedHat platforms' do it_behaves_like 'generic nova service', { :name => 'nova-conductor', :package_name => 'openstack-nova-conductor', :service_name => 'openstack-nova-conductor' } it { should_not contain_nova_config('conductor/workers') } describe 'when overriding params' do let :params do {:workers => '5' } end it { should contain_nova_config('conductor/workers').with_value('5') }",287,91
openstack%2Fpuppet-nova~stable%2Fjuno~Id222c943ac2f0957e1354a739ca42dde1162d1ae,openstack/puppet-nova,stable/juno,Id222c943ac2f0957e1354a739ca42dde1162d1ae,crontab: ensure the script is run with shell,MERGED,2014-12-10 13:14:11.000000000,2014-12-11 17:23:22.000000000,2014-12-11 17:23:21.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7195}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-10 13:14:11.000000000', 'files': ['manifests/cron/archive_deleted_rows.pp', 'spec/classes/nova_cron_archive_deleted_rows_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6734903d342ef22977121ae3fde1f76f50f1f767', 'message': 'crontab: ensure the script is run with shell\n\nSome distros does not provide a default shell for Nova user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae\n(cherry picked from commit 8897ab59088b89770a6754bee7d94156922e19ee)\n'}]",0,140672,6734903d342ef22977121ae3fde1f76f50f1f767,8,6,1,3153,,,0,"crontab: ensure the script is run with shell

Some distros does not provide a default shell for Nova user.
We can run the crontab by force shell usage and avoid running
issues.

Change-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae
(cherry picked from commit 8897ab59088b89770a6754bee7d94156922e19ee)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/72/140672/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/cron/archive_deleted_rows.pp', 'spec/classes/nova_cron_archive_deleted_rows_spec.rb']",2,6734903d342ef22977121ae3fde1f76f50f1f767,," :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/sh',"," :environment => 'PATH=/bin:/usr/bin:/usr/sbin',",2,2
openstack%2Fneutron~master~I5466984a9e57128266f97e9bd5c265f4dc3cba7b,openstack/neutron,master,I5466984a9e57128266f97e9bd5c265f4dc3cba7b,"Split services code out of Neutron, pass 1",MERGED,2014-12-08 04:24:54.000000000,2014-12-11 17:15:39.000000000,2014-12-10 00:23:42.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 9008}, {'_account_id': 9375}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-08 04:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5925cc9304277d0daa5f776eabaa867e9ce8c3b4', 'message': 'Split services code out of Neutron, pass 1\n\n- After l3_agent is refactored, need to remove services/firewall\n- After vmware plugin moves services out of monolothic,\n  remove model copies and services/loadbalancer/constants,\n  and re-enable unit tests.\n- After alembic chain gets split in four, tweak models/head and\n  fix heal/current chain.\n- Re-factor test_routerserviceinsertion into one of the service repos\n\nPartially-Implements: blueprint services-split\nChange-Id: I5466984a9e57128266f97e9bd5c265f4dc3cba7b\n'}, {'number': 2, 'created': '2014-12-08 22:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a1790f3ec457b8881f06997f843d30a7ea8eacf', 'message': 'Split services code out of Neutron, pass 1\n\n- After l3_agent is refactored, need to remove services/firewall\n- After vmware plugin moves services out of monolothic,\n  remove model copies and services/loadbalancer/constants,\n  and re-enable unit tests.\n- After alembic chain gets split in four, tweak models/head and\n  fix heal/current chain.\n- Re-factor test_routerserviceinsertion into one of the service repos\n\nPartially-Implements: blueprint services-split\nChange-Id: I5466984a9e57128266f97e9bd5c265f4dc3cba7b\n'}, {'number': 3, 'created': '2014-12-08 23:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b15a5e0f9fe6780d43542a54452777cb28b3a15', 'message': 'Split services code out of Neutron, pass 1\n\n- After l3_agent is refactored, need to remove services/firewall\n- After vmware plugin moves services out of monolothic,\n  remove model copies and services/loadbalancer/constants,\n  and re-enable unit tests.\n- After alembic chain gets split in four, tweak models/head and\n  fix heal/current chain.\n- Re-factor test_routerserviceinsertion into one of the service repos\n\nPartially-Implements: blueprint services-split\nChange-Id: I5466984a9e57128266f97e9bd5c265f4dc3cba7b\n'}, {'number': 4, 'created': '2014-12-08 23:39:17.000000000', 'files': ['neutron/services/loadbalancer/drivers/driver_base.py', 'neutron/tests/unit/db/firewall/__init__.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/tests/unit/services/loadbalancer/drivers/__init__.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/__init__.py', 'neutron/tests/unit/services/vpn/device_drivers/test_cisco_ipsec.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py.skip', 'neutron/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron/tests/unit/services/vpn/device_drivers/test_cisco_csr_rest.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/db/migration/models/head.py', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/services/firewall/drivers/__init__.py', 'neutron/tests/unit/vmware/vshield/test_firewall_driver.py.skip', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py', 'neutron/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron/services/firewall/drivers/linux/__init__.py', 'neutron/services/vpn/common/__init__.py', 'neutron/services/firewall/drivers/linux/iptables_fwaas.py', 'neutron/services/firewall/agents/varmour/varmour_utils.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/vpn/__init__.py', 'neutron/services/firewall/drivers/varmour/varmour_fwaas.py', 'neutron/services/firewall/drivers/varmour/__init__.py', 'neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py', 'neutron/services/loadbalancer/drivers/radware/__init__.py', 'neutron/services/loadbalancer/drivers/a10networks/README.txt', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron/tests/unit/services/loadbalancer/drivers/logging_noop/__init__.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/services/vpn/device_drivers/template/openswan/ipsec.secret.template', 'neutron/services/loadbalancer/drivers/netscaler/__init__.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron/services/loadbalancer/drivers/a10networks/__init__.py', 'neutron/services/loadbalancer/drivers/common/__init__.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/__init__.py', 'neutron/services/loadbalancer/drivers/a10networks/driver_v1.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py.skip', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/tests/unit/db/vpn/__init__.py', 'neutron/services/vpn/device_drivers/cisco_csr_rest_client.py', 'neutron/services/loadbalancer/agent/__init__.py', 'neutron/services/loadbalancer/agent/agent_api.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron/services/loadbalancer/agent/agent_device_driver.py', 'neutron/services/loadbalancer/drivers/netscaler/netscaler_driver.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/services/loadbalancer/agent/agent_manager.py', 'neutron/services/loadbalancer/drivers/logging_noop/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py', 'neutron/tests/unit/services/loadbalancer/drivers/netscaler/__init__.py', 'neutron/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/tests/unit/services/vpn/test_vpnaas_extension.py', 'neutron/services/loadbalancer/drivers/haproxy/cfg.py', 'neutron/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron/services/firewall/drivers/fwaas_base.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/tests/unit/services/firewall/drivers/__init__.py', 'neutron/services/loadbalancer/drivers/netscaler/ncc_client.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py.skip', 'neutron/services/vpn/device_drivers/template/openswan/ipsec.conf.template', 'neutron/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron/tests/unit/test_routerserviceinsertion.py.skip', 'neutron/services/vpn/agent.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/services/vpn/device_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/cisco_validator.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/tests/unit/services/loadbalancer/agent/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py', 'neutron/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron/tests/unit/db/loadbalancer/__init__.py', 'neutron/services/loadbalancer/drivers/radware/exceptions.py', 'neutron/tests/unit/services/firewall/__init__.py', 'neutron/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/a10networks/__init__.py', 'neutron/services/vpn/common/topics.py', 'neutron/services/loadbalancer/drivers/driver_mixins.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron/tests/unit/services/firewall/agents/__init__.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/vmware/vshield/test_loadbalancer_driver.py.skip', 'neutron/services/firewall/agents/varmour/__init__.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/407ee801e3f4a9f489062c1446ba128d25da6db5', 'message': 'Split services code out of Neutron, pass 1\n\n- After l3_agent is refactored, need to remove services/firewall\n- After vmware plugin moves services out of monolothic,\n  remove model copies and services/loadbalancer/constants,\n  and re-enable unit tests.\n- After alembic chain gets split in four, tweak models/head and\n  fix heal/current chain.\n- Re-factor test_routerserviceinsertion into one of the service repos\n\nPartially-Implements: blueprint services-split\nChange-Id: I5466984a9e57128266f97e9bd5c265f4dc3cba7b\n'}]",0,139901,407ee801e3f4a9f489062c1446ba128d25da6db5,106,32,4,10980,,,0,"Split services code out of Neutron, pass 1

- After l3_agent is refactored, need to remove services/firewall
- After vmware plugin moves services out of monolothic,
  remove model copies and services/loadbalancer/constants,
  and re-enable unit tests.
- After alembic chain gets split in four, tweak models/head and
  fix heal/current chain.
- Re-factor test_routerserviceinsertion into one of the service repos

Partially-Implements: blueprint services-split
Change-Id: I5466984a9e57128266f97e9bd5c265f4dc3cba7b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/139901/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/driver_base.py', 'neutron/tests/unit/db/firewall/__init__.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/services/loadbalancer/drivers/embrane/__init__.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron/tests/unit/services/loadbalancer/drivers/__init__.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/__init__.py', 'neutron/tests/unit/services/vpn/device_drivers/test_cisco_ipsec.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py.skip', 'neutron/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron/tests/unit/services/vpn/device_drivers/test_cisco_csr_rest.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/db/migration/models/head.py', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/services/firewall/drivers/__init__.py', 'neutron/services/loadbalancer/agent_scheduler.py', 'neutron/tests/unit/vmware/vshield/test_firewall_driver.py.skip', 'neutron/tests/unit/services/vpn/device_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py', 'neutron/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron/services/firewall/drivers/linux/__init__.py', 'neutron/services/vpn/common/__init__.py', 'neutron/services/firewall/drivers/linux/iptables_fwaas.py', 'neutron/services/firewall/agents/varmour/varmour_utils.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/vpn/__init__.py', 'neutron/services/firewall/drivers/varmour/varmour_fwaas.py', 'neutron/services/loadbalancer/drivers/embrane/agent/__init__.py', 'neutron/services/firewall/drivers/varmour/__init__.py', 'neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron/services/loadbalancer/drivers/embrane/agent/lb_operations.py', 'neutron/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron/services/loadbalancer/drivers/embrane/models.py', 'neutron/services/loadbalancer/drivers/__init__.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py', 'neutron/services/loadbalancer/drivers/radware/__init__.py', 'neutron/services/loadbalancer/drivers/a10networks/README.txt', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron/tests/unit/services/loadbalancer/drivers/logging_noop/__init__.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/services/vpn/device_drivers/template/openswan/ipsec.secret.template', 'neutron/services/loadbalancer/drivers/netscaler/__init__.py', 'neutron/services/loadbalancer/drivers/embrane/poller.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron/services/loadbalancer/drivers/a10networks/__init__.py', 'neutron/services/loadbalancer/drivers/common/__init__.py', 'neutron/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron/tests/unit/services/loadbalancer/drivers/radware/__init__.py', 'neutron/services/loadbalancer/drivers/a10networks/driver_v1.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py.skip', 'neutron/services/vpn/device_drivers/__init__.py', 'neutron/tests/unit/db/vpn/__init__.py', 'neutron/services/vpn/device_drivers/cisco_csr_rest_client.py', 'neutron/services/loadbalancer/drivers/embrane/constants.py', 'neutron/services/loadbalancer/agent/__init__.py', 'neutron/services/loadbalancer/agent/agent_api.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron/services/loadbalancer/agent/agent_device_driver.py', 'neutron/services/loadbalancer/drivers/netscaler/netscaler_driver.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/services/loadbalancer/agent/agent_manager.py', 'neutron/services/loadbalancer/drivers/logging_noop/__init__.py', 'neutron/services/loadbalancer/drivers/embrane/config.py', 'neutron/services/vpn/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py', 'neutron/tests/unit/services/loadbalancer/drivers/netscaler/__init__.py', 'neutron/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/tests/unit/services/vpn/test_vpnaas_extension.py', 'neutron/services/loadbalancer/drivers/haproxy/cfg.py', 'neutron/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron/services/firewall/drivers/fwaas_base.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron/tests/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron/services/loadbalancer/drivers/embrane/driver.py', 'neutron/tests/unit/services/firewall/drivers/__init__.py', 'neutron/services/loadbalancer/drivers/netscaler/ncc_client.py', 'neutron/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron/services/loadbalancer/drivers/embrane/agent/dispatcher.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py.skip', 'neutron/services/vpn/device_drivers/template/openswan/ipsec.conf.template', 'neutron/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron/tests/unit/test_routerserviceinsertion.py.skip', 'neutron/services/vpn/agent.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron/services/vpn/device_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/cisco_validator.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/tests/unit/services/loadbalancer/agent/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py', 'neutron/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron/tests/unit/db/loadbalancer/__init__.py', 'neutron/services/loadbalancer/drivers/radware/exceptions.py', 'neutron/tests/unit/services/firewall/__init__.py', 'neutron/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron/tests/unit/services/loadbalancer/drivers/a10networks/__init__.py', 'neutron/services/vpn/common/topics.py', 'neutron/services/loadbalancer/drivers/driver_mixins.py', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron/tests/unit/services/firewall/agents/__init__.py', 'neutron/services/vpn/service_drivers/cisco_csr_db.py', 'neutron/services/loadbalancer/drivers/embrane/db.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/vmware/vshield/test_loadbalancer_driver.py.skip', 'neutron/services/firewall/agents/varmour/__init__.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/ipsec.py', 'neutron/services/firewall/agents/varmour/varmour_api.py', 'neutron/services/loadbalancer/drivers/embrane/README', 'neutron/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py']",130,5925cc9304277d0daa5f776eabaa867e9ce8c3b4,bp/services-split,,"# Copyright 2013 Mirantis, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import mock from neutron.services.loadbalancer.drivers.haproxy import cfg from neutron.tests import base class TestHaproxyCfg(base.BaseTestCase): def test_save_config(self): with contextlib.nested( mock.patch('neutron.services.loadbalancer.' 'drivers.haproxy.cfg._build_global'), mock.patch('neutron.services.loadbalancer.' 'drivers.haproxy.cfg._build_defaults'), mock.patch('neutron.services.loadbalancer.' 'drivers.haproxy.cfg._build_frontend'), mock.patch('neutron.services.loadbalancer.' 'drivers.haproxy.cfg._build_backend'), mock.patch('neutron.agent.linux.utils.replace_file') ) as (b_g, b_d, b_f, b_b, replace): test_config = ['globals', 'defaults', 'frontend', 'backend'] b_g.return_value = [test_config[0]] b_d.return_value = [test_config[1]] b_f.return_value = [test_config[2]] b_b.return_value = [test_config[3]] cfg.save_config('test_path', mock.Mock()) replace.assert_called_once_with('test_path', '\n'.join(test_config)) def test_build_global(self): expected_opts = ['global', '\tdaemon', '\tuser nobody', '\tgroup test_group', '\tlog /dev/log local0', '\tlog /dev/log local1 notice', '\tstats socket test_path mode 0666 level user'] opts = cfg._build_global(mock.Mock(), 'test_path', 'test_group') self.assertEqual(expected_opts, list(opts)) def test_build_defaults(self): expected_opts = ['defaults', '\tlog global', '\tretries 3', '\toption redispatch', '\ttimeout connect 5000', '\ttimeout client 50000', '\ttimeout server 50000'] opts = cfg._build_defaults(mock.Mock()) self.assertEqual(expected_opts, list(opts)) def test_build_frontend(self): test_config = {'vip': {'id': 'vip_id', 'protocol': 'HTTP', 'port': {'fixed_ips': [ {'ip_address': '10.0.0.2'}] }, 'protocol_port': 80, 'connection_limit': 2000, }, 'pool': {'id': 'pool_id'}} expected_opts = ['frontend vip_id', '\toption tcplog', '\tbind 10.0.0.2:80', '\tmode http', '\tdefault_backend pool_id', '\tmaxconn 2000', '\toption forwardfor'] opts = cfg._build_frontend(test_config) self.assertEqual(expected_opts, list(opts)) test_config['vip']['connection_limit'] = -1 expected_opts.remove('\tmaxconn 2000') opts = cfg._build_frontend(test_config) self.assertEqual(expected_opts, list(opts)) def test_build_backend(self): test_config = {'pool': {'id': 'pool_id', 'protocol': 'HTTP', 'lb_method': 'ROUND_ROBIN'}, 'members': [{'status': 'ACTIVE', 'admin_state_up': True, 'id': 'member1_id', 'address': '10.0.0.3', 'protocol_port': 80, 'weight': 1}, {'status': 'INACTIVE', 'admin_state_up': True, 'id': 'member2_id', 'address': '10.0.0.4', 'protocol_port': 80, 'weight': 1}, {'status': 'PENDING_CREATE', 'admin_state_up': True, 'id': 'member3_id', 'address': '10.0.0.5', 'protocol_port': 80, 'weight': 1}], 'healthmonitors': [{'admin_state_up': True, 'delay': 3, 'max_retries': 4, 'timeout': 2, 'type': 'TCP'}], 'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}} expected_opts = ['backend pool_id', '\tmode http', '\tbalance roundrobin', '\toption forwardfor', '\ttimeout check 2s', '\tcookie SRV insert indirect nocache', '\tserver member1_id 10.0.0.3:80 weight 1 ' 'check inter 3s fall 4 cookie 0', '\tserver member2_id 10.0.0.4:80 weight 1 ' 'check inter 3s fall 4 cookie 1', '\tserver member3_id 10.0.0.5:80 weight 1 ' 'check inter 3s fall 4 cookie 2'] opts = cfg._build_backend(test_config) self.assertEqual(expected_opts, list(opts)) def test_get_server_health_option(self): test_config = {'healthmonitors': [{'admin_state_up': False, 'delay': 3, 'max_retries': 4, 'timeout': 2, 'type': 'TCP', 'http_method': 'GET', 'url_path': '/', 'expected_codes': '200'}]} self.assertEqual(('', []), cfg._get_server_health_option(test_config)) self.assertEqual(('', []), cfg._get_server_health_option(test_config)) test_config['healthmonitors'][0]['admin_state_up'] = True expected = (' check inter 3s fall 4', ['timeout check 2s']) self.assertEqual(expected, cfg._get_server_health_option(test_config)) test_config['healthmonitors'][0]['type'] = 'HTTPS' expected = (' check inter 3s fall 4', ['timeout check 2s', 'option httpchk GET /', 'http-check expect rstatus 200', 'option ssl-hello-chk']) self.assertEqual(expected, cfg._get_server_health_option(test_config)) def test_has_http_cookie_persistence(self): config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}} self.assertTrue(cfg._has_http_cookie_persistence(config)) config = {'vip': {'session_persistence': {'type': 'SOURCE_IP'}}} self.assertFalse(cfg._has_http_cookie_persistence(config)) config = {'vip': {'session_persistence': {}}} self.assertFalse(cfg._has_http_cookie_persistence(config)) def test_get_session_persistence(self): config = {'vip': {'session_persistence': {'type': 'SOURCE_IP'}}} self.assertEqual(cfg._get_session_persistence(config), ['stick-table type ip size 10k', 'stick on src']) config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}, 'members': []} self.assertEqual([], cfg._get_session_persistence(config)) config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}} self.assertEqual([], cfg._get_session_persistence(config)) config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}, 'members': [{'id': 'member1_id'}]} self.assertEqual(cfg._get_session_persistence(config), ['cookie SRV insert indirect nocache']) config = {'vip': {'session_persistence': {'type': 'APP_COOKIE', 'cookie_name': 'test'}}} self.assertEqual(cfg._get_session_persistence(config), ['appsession test len 56 timeout 3h']) config = {'vip': {'session_persistence': {'type': 'APP_COOKIE'}}} self.assertEqual(cfg._get_session_persistence(config), []) config = {'vip': {'session_persistence': {'type': 'UNSUPPORTED'}}} self.assertEqual(cfg._get_session_persistence(config), []) def test_expand_expected_codes(self): exp_codes = '' self.assertEqual(cfg._expand_expected_codes(exp_codes), set([])) exp_codes = '200' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200'])) exp_codes = '200, 201' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200', '201'])) exp_codes = '200, 201,202' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200', '201', '202'])) exp_codes = '200-202' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200', '201', '202'])) exp_codes = '200-202, 205' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200', '201', '202', '205'])) exp_codes = '200, 201-203' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200', '201', '202', '203'])) exp_codes = '200, 201-203, 205' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['200', '201', '202', '203', '205'])) exp_codes = '201-200, 205' self.assertEqual(cfg._expand_expected_codes(exp_codes), set(['205'])) ",43,26393
openstack%2Fpuppet-ceilometer~stable%2Fjuno~I3a4d5c958a4620335d062baecfc362fd758768b6,openstack/puppet-ceilometer,stable/juno,I3a4d5c958a4620335d062baecfc362fd758768b6,crontab: ensure the script is run with shell,MERGED,2014-12-10 13:14:47.000000000,2014-12-11 17:15:00.000000000,2014-12-11 17:15:00.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7195}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-10 13:14:47.000000000', 'files': ['spec/classes/ceilometer_expirer_spec.rb', 'manifests/expirer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/953ce5032cb332bf8a15e78358ee8af6f14dd7f0', 'message': 'crontab: ensure the script is run with shell\n\nSome distros does not provide a default shell for Ceilometer user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nCloses-bug: #1400523\nChange-Id: I3a4d5c958a4620335d062baecfc362fd758768b6\n(cherry picked from commit a83673c3bae7d560680cb77f2a2cc8c998fac2b7)\n'}]",0,140674,953ce5032cb332bf8a15e78358ee8af6f14dd7f0,8,6,1,3153,,,0,"crontab: ensure the script is run with shell

Some distros does not provide a default shell for Ceilometer user.
We can run the crontab by force shell usage and avoid running
issues.

Closes-bug: #1400523
Change-Id: I3a4d5c958a4620335d062baecfc362fd758768b6
(cherry picked from commit a83673c3bae7d560680cb77f2a2cc8c998fac2b7)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/74/140674/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_expirer_spec.rb', 'manifests/expirer.pp']",2,953ce5032cb332bf8a15e78358ee8af6f14dd7f0,," environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/sh',"," environment => 'PATH=/bin:/usr/bin:/usr/sbin',",2,2
openstack%2Fpuppet-nova~stable%2Fhavana~I05e83f07570d4a0e67a700bd9d9030eef1c261c3,openstack/puppet-nova,stable/havana,I05e83f07570d4a0e67a700bd9d9030eef1c261c3,Don't define virsh secret if already defined,MERGED,2014-09-04 11:52:00.000000000,2014-12-11 17:14:51.000000000,2014-12-11 17:14:51.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 9061}]","[{'number': 1, 'created': '2014-09-04 11:52:00.000000000', 'files': ['manifests/compute/rbd.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ef63ceeb4ec589611e99a79e82c9e4a4a46bf403', 'message': ""Don't define virsh secret if already defined\n\nWe test to see if the ceph secret already has been defined before\ninstalling the secret again.\n\nThis is mainly done to keep our Foreman runs clean, as it reports\non hosts that have had changes applied. Without the 'unless' clause\nany node that has the nova compute class installed will report as\nhaving changes applied.\n\nChange-Id: I05e83f07570d4a0e67a700bd9d9030eef1c261c3\n(cherry picked from commit 69b7a3c36645630aa668fe60639417fcbc24ce32)\n""}]",0,119041,ef63ceeb4ec589611e99a79e82c9e4a4a46bf403,9,4,1,9061,,,0,"Don't define virsh secret if already defined

We test to see if the ceph secret already has been defined before
installing the secret again.

This is mainly done to keep our Foreman runs clean, as it reports
on hosts that have had changes applied. Without the 'unless' clause
any node that has the nova compute class installed will report as
having changes applied.

Change-Id: I05e83f07570d4a0e67a700bd9d9030eef1c261c3
(cherry picked from commit 69b7a3c36645630aa668fe60639417fcbc24ce32)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/41/119041/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/compute/rbd.pp'],1,ef63ceeb4ec589611e99a79e82c9e4a4a46bf403,," unless => ""/usr/bin/virsh secret-list | grep ${libvirt_rbd_secret_uuid}"",",,1,0
openstack%2Fpuppet-keystone~stable%2Fjuno~Ib05522d922fecfbd28aa8a8b092b4d3b47172d00,openstack/puppet-keystone,stable/juno,Ib05522d922fecfbd28aa8a8b092b4d3b47172d00,crontab: ensure the script is run with shell,MERGED,2014-12-10 13:15:24.000000000,2014-12-11 17:14:02.000000000,2014-12-11 17:14:02.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7195}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-10 13:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a751b24e2142e4319999085445494159da181878', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Keystone user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00\n(cherry picked from commit c39fca28e68cbfdcfb64efb91ec9927a9385cdd3)\n'}, {'number': 2, 'created': '2014-12-10 13:18:38.000000000', 'files': ['manifests/cron/token_flush.pp', 'spec/classes/keystone_cron_token_flush_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/71a9df884b7a81bf86b6e897c16171bf556f1ea4', 'message': 'crontab: ensure the script is run with shell\n\nSome distros does not provide a default shell for Keystone user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00\n(cherry picked from commit c39fca28e68cbfdcfb64efb91ec9927a9385cdd3)'}]",0,140675,71a9df884b7a81bf86b6e897c16171bf556f1ea4,9,6,2,3153,,,0,"crontab: ensure the script is run with shell

Some distros does not provide a default shell for Keystone user.
We can run the crontab by force shell usage and avoid running
issues.

Change-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00
(cherry picked from commit c39fca28e68cbfdcfb64efb91ec9927a9385cdd3)",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/75/140675/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/cron/token_flush.pp', 'spec/classes/keystone_cron_token_flush_spec.rb']",2,a751b24e2142e4319999085445494159da181878,," :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/sh', :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/sh', :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/sh',"," :environment => 'PATH=/bin:/usr/bin:/usr/sbin', :environment => 'PATH=/bin:/usr/bin:/usr/sbin', :environment => 'PATH=/bin:/usr/bin:/usr/sbin',",4,4
openstack%2Fapi-site~master~I93652f905a319694dc55014da1f5e00ef9c19d43,openstack/api-site,master,I93652f905a319694dc55014da1f5e00ef9c19d43,Adds information about boot from volume for Compute API,MERGED,2014-11-19 20:07:00.000000000,2014-12-11 17:05:51.000000000,2014-12-11 17:05:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 8878}]","[{'number': 1, 'created': '2014-11-19 20:07:00.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/common.ent', 'api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8c1c71b4ae845084f71f87c253dbfbcaa1ce4459', 'message': 'Adds information about boot from volume for Compute API\n\nDescribes block_device_mapping_v2 parameter on a create server call.\nCloses-bug: 1215115\n\nChange-Id: I93652f905a319694dc55014da1f5e00ef9c19d43\n'}]",0,135707,8c1c71b4ae845084f71f87c253dbfbcaa1ce4459,8,4,1,964,,,0,"Adds information about boot from volume for Compute API

Describes block_device_mapping_v2 parameter on a create server call.
Closes-bug: 1215115

Change-Id: I93652f905a319694dc55014da1f5e00ef9c19d43
",git fetch https://review.opendev.org/openstack/api-site refs/changes/07/135707/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2/common.ent', 'api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl']",2,8c1c71b4ae845084f71f87c253dbfbcaa1ce4459,bug/1215115," <para>You can boot a server from a volume by including block-device-mapping-v2 parameters in the create request.</para> <xsdxt:code href=""../api_samples/os-block-device-mapping-v2-boot/server-post-req.json""/> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"">",,93,7
openstack%2Fapi-site~master~I825a303f398ec6e2a775c81c1bbf2378c3adf4a2,openstack/api-site,master,I825a303f398ec6e2a775c81c1bbf2378c3adf4a2,Adds PUT for volume types and extra specs: Volume API v1 and v2,MERGED,2014-11-19 23:28:21.000000000,2014-12-11 17:05:45.000000000,2014-12-11 17:05:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-11-19 23:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/3030a0016ec6fc746ca36a7572eef4c6bb81115f', 'message': 'Adds PUT for volume types and extra specs for Volume API v1\n\nChange-Id: I825a303f398ec6e2a775c81c1bbf2378c3adf4a2\nCloses-bug: 1330620\n'}, {'number': 2, 'created': '2014-11-20 23:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/ecbab64205af08286fba6a8c7392e4cd655480e2', 'message': 'Adds PUT for volume types and extra specs: Volume API v1 and v2\n\nChange-Id: I825a303f398ec6e2a775c81c1bbf2378c3adf4a2\nCloses-bug: 1330620\n'}, {'number': 3, 'created': '2014-12-01 21:28:53.000000000', 'files': ['api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl', 'api-ref/src/wadls/volume-api/src/v2/volume-api-v2.wadl', 'api-ref/src/wadls/volume-api/src/v2/api_samples/volume_type_show.xml', 'api-ref/src/wadls/volume-api/src/v2/api_samples/volume_type_show.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/310b12ac4b25a1a8c7cf2ed3291e0d4844a7a3af', 'message': 'Adds PUT for volume types and extra specs: Volume API v1 and v2\n\nChange-Id: I825a303f398ec6e2a775c81c1bbf2378c3adf4a2\nCloses-bug: 1330620\n'}]",0,135777,310b12ac4b25a1a8c7cf2ed3291e0d4844a7a3af,12,3,3,964,,,0,"Adds PUT for volume types and extra specs: Volume API v1 and v2

Change-Id: I825a303f398ec6e2a775c81c1bbf2378c3adf4a2
Closes-bug: 1330620
",git fetch https://review.opendev.org/openstack/api-site refs/changes/77/135777/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/volume-api/src/v1/volume-api-v1.wadl'],1,3030a0016ec6fc746ca36a7572eef4c6bb81115f,bug/1330620," <method href=""#updateVolumeType""/> <method href=""#updateVolumeTypeExtraSpecs""/> <method name=""PUT"" id=""updateVolumeType""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Update volume type""> <para role=""shortdesc"">Updates a volume type.</para> </wadl:doc> <request> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_create_request.xml""/> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_create_request.json""/> </wadl:doc> <param name=""volume_type"" style=""plain"" required=""true"" type=""csapi:string""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para>A volume type offers a way to categorize or group volumes.</para> </wadl:doc> </param> </representation> </request> <response status=""200""> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_show.xml""/> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_show.json""/> </wadl:doc> </representation> </response> </method> <method name=""PUT"" id=""updateVolumeTypeExtraSpecs""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Update extra specs for a volume type""> <para role=""shortdesc"">Updates the extra specifications assigned to a volume type.</para> </wadl:doc> <request> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_create_request.xml""/> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_create_request.json""/> </wadl:doc> <param name=""volume_type"" style=""plain"" required=""true"" type=""csapi:string""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para>A volume type offers a way to categorize or group volumes.</para> </wadl:doc> </param> <param name=""extra_specs"" style=""plain"" required=""true"" type=""csapi:string""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para>A key:value pair that offers a way to show additional specifications associated with the volume type. Examples include capabilities, capacity, compression, and so on, depending on the storage driver in use.</para> </wadl:doc> </param> </representation> </request> <response status=""200""> <representation mediaType=""application/xml""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_show.xml""/> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""api_samples/volume_type_show.json""/> </wadl:doc> </representation> </response> </method>",,85,0
openstack%2Fapi-site~master~Ie7e10b6844ba4c36f6b00d170008c0d8b12cdbf3,openstack/api-site,master,Ie7e10b6844ba4c36f6b00d170008c0d8b12cdbf3,Adds namespace to disk-config API examples for Compute API,MERGED,2014-11-20 22:48:34.000000000,2014-12-11 17:05:37.000000000,2014-12-11 17:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-11-20 22:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/e78cee02c6750ade2a176989b45a98b52df6fd08', 'message': 'Adds namespace to disk-config API examples for Compute API\n\nChange-Id: Ie7e10b6844ba4c36f6b00d170008c0d8b12cdbf3\nCloses-bug: 1252577\n'}, {'number': 2, 'created': '2014-11-20 23:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/25a2d262951ac38472bfddee7567afac1f7b7483', 'message': 'Adds namespace to disk-config API examples for Compute API\n\nChange-Id: Ie7e10b6844ba4c36f6b00d170008c0d8b12cdbf3\nCloses-bug: 1252577\n'}, {'number': 3, 'created': '2014-11-21 00:12:10.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-req.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/list-servers-detail-get.json', 'api-ref/src/wadls/compute-api/src/v2/api_samples/OS-DCF/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-disk-config-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/image-get-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-get-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-req.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/image-list-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-resize-post-req.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-req.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/db8e8a655d092200b3fc44527211e64e03d590f0', 'message': 'Adds namespace to disk-config API examples for Compute API\n\nChange-Id: Ie7e10b6844ba4c36f6b00d170008c0d8b12cdbf3\nCloses-bug: 1252577\n'}]",0,136162,db8e8a655d092200b3fc44527211e64e03d590f0,11,3,3,964,,,0,"Adds namespace to disk-config API examples for Compute API

Change-Id: Ie7e10b6844ba4c36f6b00d170008c0d8b12cdbf3
Closes-bug: 1252577
",git fetch https://review.opendev.org/openstack/api-site refs/changes/62/136162/3 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-req.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/list-servers-detail-get.json', 'api-ref/src/wadls/compute-api/src/v2/api_samples/OS-DCF/server-post-req.xml', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-disk-config-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/image-get-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-get-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-post-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-req.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/image-list-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-action-rebuild-resp.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-resize-post-req.json', 'api-ref/src/wadls/compute-api/src/v2.1/api_samples/os-disk-config/server-update-put-req.json']",13,e78cee02c6750ade2a176989b45a98b52df6fd08,bug/1252577," ""OS-DCF:diskConfig"": ""AUTO"""," ""os-disk-config:disk_config"": ""AUTO""",674,64
openstack%2Fironic~master~Ie0d87c96c80dab23ea81011413600d9dbbf50177,openstack/ironic,master,Ie0d87c96c80dab23ea81011413600d9dbbf50177,Do not strip 'glance://' prefix from image hrefs,MERGED,2014-12-04 13:56:18.000000000,2014-12-11 17:05:29.000000000,2014-12-11 17:05:28.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 9315}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-12-04 13:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a3b00fb2696003d3b3c76d3c66de1e2126e80f1d', 'message': ""Remove 'glance://' prefix strip from image hrefs\n\npxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info\nfunctions strip 'glance://' prefix from image references while it's\nnot necessary as Glance service can download images by such refs.\nAlso some refactoring done as these references are not just uuids.\n\nChange-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177\n""}, {'number': 2, 'created': '2014-12-05 11:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d312feee616a23ac0becee926d34b123133e07cd', 'message': ""Remove 'glance://' prefix strip from image hrefs\n\npxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info\nfunctions strip 'glance://' prefix from image references while it's\nnot necessary as Glance service can download images by such refs.\nAlso some refactoring done as these references are not just uuids.\n\nChange-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177\n""}, {'number': 3, 'created': '2014-12-09 10:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bff31ef55ddc5e7392fe3fee633b67f3ce925a62', 'message': ""Do not strip 'glance://' prefix from image hrefs\n\npxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info\nfunctions strip 'glance://' prefix from image references while it's\nnot necessary as Glance service can download images by such refs.\nAlso some refactoring done as these references are not just uuids.\n\nChange-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177\n""}, {'number': 4, 'created': '2014-12-09 12:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bcb4dadcf3feca41e8043305944f72245de10660', 'message': ""Do not strip 'glance://' prefix from image hrefs\n\npxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info\nfunctions strip 'glance://' prefix from image references while it's\nnot necessary as Glance service can download images by such refs.\nAlso some refactoring done as these references are not just uuids.\n\nChange-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177\n""}, {'number': 5, 'created': '2014-12-09 13:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f629203721f31731881f6604967dfa6185a5f1f2', 'message': ""Do not strip 'glance://' prefix from image hrefs\n\npxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info\nfunctions strip 'glance://' prefix from image references while it's\nnot necessary as Glance service can download images by such refs.\nAlso some refactoring done as these references are not just uuids.\n\nPartially implements: blueprint non-glance-image-refs\n\nChange-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177\n""}, {'number': 6, 'created': '2014-12-11 15:26:57.000000000', 'files': ['ironic/drivers/modules/image_cache.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/common/pxe_utils.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/test_pxe_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c19286ed5e587301c1e2def9ad6b16d5f8ebcb0', 'message': ""Do not strip 'glance://' prefix from image hrefs\n\npxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info\nfunctions strip 'glance://' prefix from image references while it's\nnot necessary as Glance service can download images by such refs.\nAlso some refactoring done as these references are not just uuids.\n\nPartially implements: blueprint non-glance-image-refs\n\nChange-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177\n""}]",9,139057,7c19286ed5e587301c1e2def9ad6b16d5f8ebcb0,49,7,6,12356,,,0,"Do not strip 'glance://' prefix from image hrefs

pxe_utils.get_deploy_kr_info and drivers.modules.pxe._get_image_info
functions strip 'glance://' prefix from image references while it's
not necessary as Glance service can download images by such refs.
Also some refactoring done as these references are not just uuids.

Partially implements: blueprint non-glance-image-refs

Change-Id: Ie0d87c96c80dab23ea81011413600d9dbbf50177
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/139057/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/image_cache.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/pxe.py', 'ironic/common/pxe_utils.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/test_pxe_utils.py']",6,a3b00fb2696003d3b3c76d3c66de1e2126e80f1d,bp/non-glance-image-refs," 'deploy_kernel': ('glance://deploy-kernel', 'deploy_ramdisk': ('glance://deploy-ramdisk',"," 'deploy_kernel': ('deploy-kernel', 'deploy_ramdisk': ('deploy-ramdisk',",24,23
openstack%2Fnova~master~I829465d1612f42e7af92927584b31ca6a2349d5a,openstack/nova,master,I829465d1612f42e7af92927584b31ca6a2349d5a,libvirt: un-cruft _get_guest_numa_config,MERGED,2014-12-08 18:45:21.000000000,2014-12-11 17:05:01.000000000,2014-12-11 17:04:58.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 18:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aac2cb3bb38665a85c73cca77d56c7530564b6c2', 'message': 'libvirt: un-cruft _get_guest_numa_config\n\nSeveral issues get cleaned up with this patch - all of which will make\nadding CPU pinning into the mix a lot cleaner.\n\n1) Unecessary context argument to the method is dropped.\n\n2) Secondly - we pass in the InstanceNUMATopology object (or None)\ninstead of passing in the whole instance and then getting the topology\nout - this is useful as we will need instance NUMA for generating topology\nas well, and this avoids repetitive code in a lot of places as we now grab\nit in the top level method, and just pass it in where needed.\n\nChange-Id: I829465d1612f42e7af92927584b31ca6a2349d5a\n'}, {'number': 2, 'created': '2014-12-09 09:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a02756984cbba4f52314bfca3caa4afac62987c', 'message': 'libvirt: un-cruft _get_guest_numa_config\n\nSeveral issues get cleaned up with this patch - all of which will make\nadding CPU pinning into the mix a lot cleaner.\n\n1) Unecessary context argument to the method is dropped.\n\n2) Secondly - we pass in the InstanceNUMATopology object (or None)\ninstead of passing in the whole instance and then getting the topology\nout - this is useful as we will need instance NUMA for generating topology\nas well, and this avoids repetitive code in a lot of places as we now grab\nit in the top level method, and just pass it in where needed.\n\n3) Add missing tests for updated method the method\nget_cpu_numa_config_from_instance\n\nChange-Id: I829465d1612f42e7af92927584b31ca6a2349d5a\n'}, {'number': 3, 'created': '2014-12-09 15:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d4fa0766fe24ff18d2a5bef50833fcf11eafd3b', 'message': 'libvirt: un-cruft _get_guest_numa_config\n\nSeveral issues get cleaned up with this patch - all of which will make\nadding CPU pinning into the mix a lot cleaner.\n\n1) Unecessary context argument to the method is dropped.\n\n2) Secondly - we pass in the InstanceNUMATopology object (or None)\ninstead of passing in the whole instance and then getting the topology\nout - this is useful as we will need instance NUMA for generating topology\nas well, and this avoids repetitive code in a lot of places as we now grab\nit in the top level method, and just pass it in where needed.\n\n3) Add missing tests for updated method the method\nget_cpu_numa_config_from_instance\n\nChange-Id: I829465d1612f42e7af92927584b31ca6a2349d5a\n'}, {'number': 4, 'created': '2014-12-09 18:08:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1231c469d2a6ed480e47b1a21b15aea98b1852f5', 'message': 'libvirt: un-cruft _get_guest_numa_config\n\nSeveral issues get cleaned up with this patch - all of which will make\nadding CPU pinning into the mix a lot cleaner.\n\n1) Unecessary context argument to the method is dropped.\n\n2) Secondly - we pass in the InstanceNUMATopology object (or None)\ninstead of passing in the whole instance and then getting the topology\nout - this is useful as we will need instance NUMA for generating topology\nas well, and this avoids repetitive code in a lot of places.\n\n3) Add missing tests for updated method the method\nget_cpu_numa_config_from_instance\n\nChange-Id: I829465d1612f42e7af92927584b31ca6a2349d5a\n'}]",10,140111,1231c469d2a6ed480e47b1a21b15aea98b1852f5,41,11,4,5511,,,0,"libvirt: un-cruft _get_guest_numa_config

Several issues get cleaned up with this patch - all of which will make
adding CPU pinning into the mix a lot cleaner.

1) Unecessary context argument to the method is dropped.

2) Secondly - we pass in the InstanceNUMATopology object (or None)
instead of passing in the whole instance and then getting the topology
out - this is useful as we will need instance NUMA for generating topology
as well, and this avoids repetitive code in a lot of places.

3) Add missing tests for updated method the method
get_cpu_numa_config_from_instance

Change-Id: I829465d1612f42e7af92927584b31ca6a2349d5a
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/140111/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,aac2cb3bb38665a85c73cca77d56c7530564b6c2,bp/virt-driver-cpu-pinning," def _get_cpu_numa_config_from_instance(self, instance_numa_topology): if instance_numa_topology: for instance_cell in instance_numa_topology.cells: def _get_guest_numa_config(self, instance_numa_topology, flavor, guest_cpu_numa_config = self._get_cpu_numa_config_from_instance( instance_numa_topology) if not guest_cpu_numa_config: for guest_config_cell in guest_cpu_numa_config.cells: if guest_config_cell.id == host_cell.id: node.cellid = guest_config_cell.id for cpu in guest_config_cell.cpus: zip(guest_cpu_numa_config.cells, guest_numa_tune.memnodes)): return (None, guest_cpu_tune, guest_cpu_numa_config, guest_numa_tune) else: return allowed_cpus, None, guest_cpu_numa_config, None instance_numa_topology = hardware.instance_topology_from_instance( instance) instance_numa_topology, flavor, allowed_cpus) "," def _get_cpu_numa_config_from_instance(self, context, instance): instance_topology = hardware.instance_topology_from_instance(instance) if instance_topology: for instance_cell in instance_topology.cells: def _get_guest_numa_config(self, context, instance, flavor, guest_cpu_numa = self._get_cpu_numa_config_from_instance( context, instance) if not guest_cpu_numa: for guest_cell in guest_cpu_numa.cells: if guest_cell.id == host_cell.id: node.cellid = guest_cell.id for cpu in guest_cell.cpus: zip(guest_cpu_numa.cells, guest_numa_tune.memnodes)): return None, guest_cpu_tune, guest_cpu_numa, guest_numa_tune else: return allowed_cpus, None, guest_cpu_numa, None context, instance, flavor, allowed_cpus)",20,17
openstack%2Fheat~master~Idbaf867f71feacb4a1f382eb7233fb69517603a9,openstack/heat,master,Idbaf867f71feacb4a1f382eb7233fb69517603a9,Added tests for pseudo params,MERGED,2014-12-08 05:03:50.000000000,2014-12-11 17:04:40.000000000,2014-12-11 17:04:39.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-12-08 05:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d85b2dd9b29336ac9fed82e42dd7154eb8d67ea0', 'message': ""Added tests for pseudo params\n\nTo cover 'OS::stack_id' and 'OS::stack_name'.\n\nChange-Id: Idbaf867f71feacb4a1f382eb7233fb69517603a9\n""}, {'number': 2, 'created': '2014-12-09 11:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa7cb905c36a563140cac6ff9af54b9e6fc2fa7c', 'message': ""Added tests for pseudo params\n\nTo cover 'OS::stack_id' and 'OS::stack_name'.\n\nChange-Id: Idbaf867f71feacb4a1f382eb7233fb69517603a9\n""}, {'number': 3, 'created': '2014-12-10 03:34:36.000000000', 'files': ['heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1e04de7c0648a3515dc461eb62a25a541db5f65c', 'message': ""Added tests for pseudo params\n\nTo cover 'OS::stack_id' and 'OS::stack_name'.\n\nChange-Id: Idbaf867f71feacb4a1f382eb7233fb69517603a9\n""}]",3,139907,1e04de7c0648a3515dc461eb62a25a541db5f65c,23,7,3,7761,,,0,"Added tests for pseudo params

To cover 'OS::stack_id' and 'OS::stack_name'.

Change-Id: Idbaf867f71feacb4a1f382eb7233fb69517603a9
",git fetch https://review.opendev.org/openstack/heat refs/changes/07/139907/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_hot.py'],1,d85b2dd9b29336ac9fed82e42dd7154eb8d67ea0,hot_pseudo_param_tenant," ('pseudo_stack_id', dict(params={}, snippet={'properties': {'prop1': {'get_param': 'OS::stack_id'}}}, expected={'properties': {'prop1': '1ba8c334-2297-4312-8c7c-43763a988ced'}})), ('pseudo_stack_name', dict(params={}, snippet={'properties': {'prop1': {'get_param': 'OS::stack_name'}}}, expected={'properties': {'prop1': 'test'}})), stack = parser.Stack(utils.dummy_context(), 'test', tmpl, env, stack_id='1ba8c334-2297-4312-8c7c-43763a988ced', tenant_id='9913ef0a-b8be-4b33-b574-9061441bd373')"," stack = parser.Stack(utils.dummy_context(), 'test', tmpl, env)",15,1
openstack%2Fheat~master~I77d7fb38b852590a3004532d28b9b9fcf29dc819,openstack/heat,master,I77d7fb38b852590a3004532d28b9b9fcf29dc819,Rename the remaining instance group tests for clarity,MERGED,2014-12-09 06:16:28.000000000,2014-12-11 17:03:45.000000000,2014-12-11 17:03:43.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 06:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cda72fc71fb6a2fd2f8e535c393b3de1f5a32fcb', 'message': 'Rename the remaining instance group tests for clarity\n\nIn preparation to move these tests to functional tests rename and\ndocument what they do.\nThis also simplifies the launch config test as it does not need\nthe scaling group for this test.\n\nChange-Id: I77d7fb38b852590a3004532d28b9b9fcf29dc819\n'}, {'number': 2, 'created': '2014-12-10 08:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b4ee6ba693a376f09c74fabf72b494dd0eefbd3c', 'message': 'Rename the remaining instance group tests for clarity\n\nIn preparation to move these tests to functional tests rename and\ndocument what they do.\nThis also simplifies the launch config test as it does not need\nthe scaling group for this test.\n\nPart of blueprint decouple-nested\nChange-Id: I77d7fb38b852590a3004532d28b9b9fcf29dc819\n'}, {'number': 3, 'created': '2014-12-10 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3349c947da7cf451ff28227c4f7c05753dfc0e3f', 'message': 'Rename the remaining instance group tests for clarity\n\nIn preparation to move these tests to functional tests rename and\ndocument what they do.\nThis also simplifies the launch config test as it does not need\nthe scaling group for this test.\n\nPart of blueprint decouple-nested\nChange-Id: I77d7fb38b852590a3004532d28b9b9fcf29dc819\n'}, {'number': 4, 'created': '2014-12-11 10:17:36.000000000', 'files': ['heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3626409a6b06ae4ece1058ba6abbd6bc91295093', 'message': 'Rename the remaining instance group tests for clarity\n\nIn preparation to move these tests to functional tests rename and\ndocument what they do.\nThis also simplifies the launch config test as it does not need\nthe scaling group for this test.\n\nPart of blueprint decouple-nested\nChange-Id: I77d7fb38b852590a3004532d28b9b9fcf29dc819\n'}]",1,140244,3626409a6b06ae4ece1058ba6abbd6bc91295093,29,8,4,4715,,,0,"Rename the remaining instance group tests for clarity

In preparation to move these tests to functional tests rename and
document what they do.
This also simplifies the launch config test as it does not need
the scaling group for this test.

Part of blueprint decouple-nested
Change-Id: I77d7fb38b852590a3004532d28b9b9fcf29dc819
",git fetch https://review.opendev.org/openstack/heat refs/changes/44/140244/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_instance_group.py'],1,cda72fc71fb6a2fd2f8e535c393b3de1f5a32fcb,bug/1360292," def test_basic_create_works(self): """"""Make sure the working case is good."""""" def test_override_aws_ec2_instance(self): def test_create_config_prop_validation(self): """"""Make sure that during a group create the instance properties are validated. And an error causes the group to fail. """""" def test_size_updates_work(self): def test_create_instance_error_causes_group_error(self): def test_update_instance_error_causes_group_error(self): def test_update_group_replace(self): """"""Make sure that during a group update the non updatable properties cause a replacement. """""" class TestLaunchConfig(common.HeatTestCase): def create_resource(self, t, stack, resource_name): # subsequent resources may need to reference previous created resources # use the stack's resource objects instead of instantiating new ones rsrc = stack[resource_name] self.assertIsNone(rsrc.validate()) scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) return rsrc def test_update_metadata_replace(self): """"""Updating the config's metadata causes a config replacement."""""" ig_template = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Resources"": { ""JobServerConfig"" : { ""Type"" : ""AWS::AutoScaling::LaunchConfiguration"", ""Metadata"": {""foo"": ""bar""}, ""Properties"": { ""ImageId"" : ""foo"", ""InstanceType"" : ""m1.large"", ""KeyName"" : ""test"", } } } } ''' self.stub_ImageConstraint_validate() self.stub_FlavorConstraint_validate() self.stub_KeypairConstraint_validate() self.stub_SnapshotConstraint_validate() t = template_format.parse(ig_template) stack = utils.parse_stack(t) rsrc = self.create_resource(t, stack, 'JobServerConfig') props = copy.copy(rsrc.properties.data) metadata = copy.copy(rsrc.metadata_get()) update_snippet = rsrc_defn.ResourceDefinition(rsrc.name, rsrc.type(), props, metadata) # Change nothing in the first update scheduler.TaskRunner(rsrc.update, update_snippet)() self.assertEqual('bar', metadata['foo']) metadata['foo'] = 'wibble' update_snippet = rsrc_defn.ResourceDefinition(rsrc.name, rsrc.type(), props, metadata) # Changing metadata in the second update triggers UpdateReplace updater = scheduler.TaskRunner(rsrc.update, update_snippet) self.assertRaises(resource.UpdateReplace, updater)"," def test_instance_group(self): def test_instance_group_custom_resource(self): def test_missing_image(self): def test_handle_update_size(self): def test_create_error(self): def test_update_error(self): def test_update_fail_badprop(self): def test_update_config_metadata(self): t = template_format.parse(ig_template) properties = t['Resources']['JobServerGroup']['Properties'] properties['Size'] = '2' stack = utils.parse_stack(t) self._stub_create(2) self.m.ReplayAll() rsrc = self.create_resource(t, stack, 'JobServerConfig') self.create_resource(t, stack, 'JobServerGroup') props = copy.copy(rsrc.properties.data) metadata = copy.copy(rsrc.metadata_get()) update_snippet = rsrc_defn.ResourceDefinition(rsrc.name, rsrc.type(), props, metadata) # Change nothing in the first update scheduler.TaskRunner(rsrc.update, update_snippet)() self.assertEqual('bar', metadata['foo']) metadata['foo'] = 'wibble' update_snippet = rsrc_defn.ResourceDefinition(rsrc.name, rsrc.type(), props, metadata) # Changing metadata in the second update triggers UpdateReplace updater = scheduler.TaskRunner(rsrc.update, update_snippet) self.assertRaises(resource.UpdateReplace, updater) self.m.VerifyAll() ",69,40
openstack%2Fironic~master~I0bbd61d43daaffe9de579b1a6b50ea6826bdfd50,openstack/ironic,master,I0bbd61d43daaffe9de579b1a6b50ea6826bdfd50,Use Literal Blocks to write code sample in docstring,MERGED,2014-12-08 10:44:51.000000000,2014-12-11 17:03:17.000000000,2014-12-11 17:03:16.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 9066}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-08 10:44:51.000000000', 'files': ['ironic/drivers/modules/agent.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9efc942e51c24b62d3377e5243fbfc37c189941d', 'message': 'Use Literal Blocks to write code sample in docstring\n\nIn python docstring, one should use Literal Blocks to write sample\ncode otherwise one gets build warnings and badly formatted documents.\n\nAlso, because sphinx treats the line which starts "".."" as a comment,\nthis patch moves ""..."" to the end of the previous line.\n\nChange-Id: I0bbd61d43daaffe9de579b1a6b50ea6826bdfd50\nPartial-bug: 1277282\n'}]",0,139965,9efc942e51c24b62d3377e5243fbfc37c189941d,20,5,1,9066,,,0,"Use Literal Blocks to write code sample in docstring

In python docstring, one should use Literal Blocks to write sample
code otherwise one gets build warnings and badly formatted documents.

Also, because sphinx treats the line which starts "".."" as a comment,
this patch moves ""..."" to the end of the previous line.

Change-Id: I0bbd61d43daaffe9de579b1a6b50ea6826bdfd50
Partial-bug: 1277282
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/139965/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/agent.py'],1,9efc942e51c24b62d3377e5243fbfc37c189941d,bug/1277282," as a kwarg. kwargs should have the following format:: { 'agent_url': 'http://AGENT_HOST:AGENT_PORT' } AGENT_PORT defaults to 9999. kwargs should have the following format:: { ""version"": ""2"" ""inventory"": { ""interfaces"": [ { ""name"": ""eth0"", ""mac_address"": ""00:11:22:33:44:55"", ""switch_port_descr"": ""port24"" ""switch_chassis_descr"": ""tor1"" }, ... ], ... } }"," as a kwarg. kwargs should have the following format: { 'agent_url': 'http://AGENT_HOST:AGENT_PORT' } AGENT_PORT defaults to 9999. kwargs should have the following format: { ""version"": ""2"" ""inventory"": { ""interfaces"": [ { ""name"": ""eth0"", ""mac_address"": ""00:11:22:33:44:55"", ""switch_port_descr"": ""port24"" ""switch_chassis_descr"": ""tor1"" }, ... ], ... } }",21,21
openstack%2Fnova~master~I3174ab7968b51c43c0711033bac5d4bc30938b95,openstack/nova,master,I3174ab7968b51c43c0711033bac5d4bc30938b95,Make scheduler filters/weighers only load once,MERGED,2014-10-31 12:32:22.000000000,2014-12-11 17:02:52.000000000,2014-12-11 17:02:49.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-31 12:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93e4f2f58375f5bbb738ce7f2646638fdee47cc5', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 2, 'created': '2014-11-03 11:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d5f8805cba4fb1f23b23047b22410b09bad6d28', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 3, 'created': '2014-11-04 09:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55c74584e60966e8b481a97cd532d6643c3bd4ad', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 4, 'created': '2014-11-10 12:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4078ffa1e4d4ca6a8c675e8fe451e13593a78ce8', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 5, 'created': '2014-11-13 08:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6397b4e91fbf6908e5f5d1e3765457886dda03af', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 6, 'created': '2014-11-19 19:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8d716bcc939510cdbb2fb31e0b451de9875be7e', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 7, 'created': '2014-12-08 20:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3493d080d6e832c0c346749824b76beebf779cf0', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 8, 'created': '2014-12-09 07:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cda1082d1e59435fe98d863e9521a5c8ff3bf99', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}, {'number': 9, 'created': '2014-12-09 18:08:31.000000000', 'files': ['nova/tests/unit/cells/test_cells_weights.py', 'nova/filters.py', 'nova/tests/unit/cells/test_cells_filters.py', 'nova/tests/unit/scheduler/test_host_manager.py', 'nova/tests/unit/scheduler/test_filters.py', 'nova/tests/unit/scheduler/test_ironic_host_manager.py', 'nova/tests/unit/cells/test_cells_scheduler.py', 'nova/tests/unit/scheduler/test_weights.py', 'nova/weights.py', 'nova/scheduler/host_manager.py', 'nova/cells/scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c126d36640e0398e76ba01783b7f21f01f53a5f5', 'message': 'Make scheduler filters/weighers only load once\n\nRight now, filters/weighers are instantiated on every invocation of the\nscheduler. This is both time consuming and unnecessary. In cases where\na filter/weigher tries to be smart and store/cache something in between\ninvocations this actually prohibits that.\n\nThis change make base filter/weigher functions take objects instead of\nclasses and then let schedulers create objects only once and then reuse\nthem.\n\nThis fixes a known bug in trusted_filter that tries to cache things.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95\nCloses-Bug: #1223450\n'}]",0,132229,c126d36640e0398e76ba01783b7f21f01f53a5f5,70,10,9,6450,,,0,"Make scheduler filters/weighers only load once

Right now, filters/weighers are instantiated on every invocation of the
scheduler. This is both time consuming and unnecessary. In cases where
a filter/weigher tries to be smart and store/cache something in between
invocations this actually prohibits that.

This change make base filter/weigher functions take objects instead of
classes and then let schedulers create objects only once and then reuse
them.

This fixes a known bug in trusted_filter that tries to cache things.

Related to blueprint scheduler-optimization

Change-Id: I3174ab7968b51c43c0711033bac5d4bc30938b95
Closes-Bug: #1223450
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/132229/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/filters.py', 'nova/tests/cells/test_cells_filters.py', 'nova/tests/scheduler/test_filters.py', 'nova/tests/scheduler/test_ironic_host_manager.py', 'nova/tests/cells/test_cells_scheduler.py', 'nova/tests/cells/test_cells_weights.py', 'nova/tests/scheduler/test_host_manager.py', 'nova/tests/scheduler/test_weights.py', 'nova/weights.py', 'nova/scheduler/host_manager.py', 'nova/cells/scheduler.py']",11,93e4f2f58375f5bbb738ce7f2646638fdee47cc5,bp/scheduler-optimization," filter_classes = self.filter_handler.get_matching_classes( self.filters = [cls() for cls in filter_classes] weigher_classes = self.weight_handler.get_matching_classes( self.weighers = [cls() for cls in weigher_classes] cells = self.filter_handler.get_filtered_objects(self.filters, cells, self.weighers, cells, filter_properties)"," self.filter_classes = self.filter_handler.get_matching_classes( self.weigher_classes = self.weight_handler.get_matching_classes( cells = self.filter_handler.get_filtered_objects(self.filter_classes, cells, self.weigher_classes, cells, filter_properties)",77,77
openstack%2Fnova~master~Ifd3577aec6c5fc82e4864623e0545f380fb75b6e,openstack/nova,master,Ifd3577aec6c5fc82e4864623e0545f380fb75b6e,Refactor unit tests for scheduler weights,MERGED,2014-10-31 12:32:22.000000000,2014-12-11 17:00:36.000000000,2014-12-11 17:00:33.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-31 12:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0392b5923f979d42e2fbea462832b24ce9334a73', 'message': ""Refactor unit tests for scheduler weights\n\nThis change simplifies tests by making use of FakeHostState() to avoid\nhaving to go through host manager and to mock it's db calls.\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 2, 'created': '2014-11-03 11:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a34d75c9156ddc48127d4bdaca9198d67f2bf2b', 'message': ""Refactor unit tests for scheduler weights\n\nThis change simplifies tests by making use of FakeHostState() to avoid\nhaving to go through host manager and to mock it's db calls.\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 3, 'created': '2014-11-04 09:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf18466a4b0569cb2bb9b22e38b0a3d98027f5d0', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 4, 'created': '2014-11-10 12:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f1ee4f68a89d626be4a8a86e8180f4659b3f8e7', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 5, 'created': '2014-11-13 08:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab3bbfc4e750324150b113026b91c65730d4e889', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 6, 'created': '2014-11-19 19:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0ee60bce4064faffd04f45602d8383fc2624509', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 7, 'created': '2014-12-08 20:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ae62a6fbb3a09f24f76da64562e8a2f8721e587', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 8, 'created': '2014-12-09 07:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3899ab420fd1be720de4ff6ded59ad4fb7396d5b', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}, {'number': 9, 'created': '2014-12-09 18:08:31.000000000', 'files': ['nova/tests/unit/scheduler/test_weights.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/551cf196df6b5602242155a8acee88be443f12d1', 'message': ""Refactor unit tests for scheduler weights\n\nRemove external depenencies from scheduler weight tests in an attempt\nto make the tests cleaner and to only test the weight code itself.\n\nFakeHostState() is used to avoid having to go through host manager and\nthen mock it's db calls. Additionally, weigher classes are referenced\ndirectly instead of having the weight handler load them first.\n\nRelated to blueprint scheduler-optimization\n\nChange-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e\n""}]",4,132228,551cf196df6b5602242155a8acee88be443f12d1,75,11,9,6450,,,0,"Refactor unit tests for scheduler weights

Remove external depenencies from scheduler weight tests in an attempt
to make the tests cleaner and to only test the weight code itself.

FakeHostState() is used to avoid having to go through host manager and
then mock it's db calls. Additionally, weigher classes are referenced
directly instead of having the weight handler load them first.

Related to blueprint scheduler-optimization

Change-Id: Ifd3577aec6c5fc82e4864623e0545f380fb75b6e
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/132228/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/scheduler/test_weights.py'],1,0392b5923f979d42e2fbea462832b24ce9334a73,bp/scheduler-optimization,"from nova.scheduler import host_managerfrom nova.scheduler.weights import io_ops from nova.scheduler.weights import metrics from nova.scheduler.weights import ram self.assertIn(ram.RAMWeigher, classes) self.assertIn(metrics.MetricsWeigher, classes) self.assertIn(io_ops.IoOpsWeigher, classes) self.weight_classes = [ram.RAMWeigher] host_values = [ ('host1', 'node1', {'free_ram_mb': 512}), ('host2', 'node2', {'free_ram_mb': 1024}), ('host3', 'node3', {'free_ram_mb': 3072}), ('host4', 'node4', {'free_ram_mb': 8192}) ] return [fakes.FakeHostState(host, node, values) for host, node, values in host_values] self.weight_classes = [metrics.MetricsWeigher] def fake_metric(value): return host_manager.MetricItem(value=value, timestamp='fake-time', source='fake-source') host_values = [ ('host1', 'node1', {'metrics': {'foo': fake_metric(512), 'bar': fake_metric(1)}}), ('host2', 'node2', {'metrics': {'foo': fake_metric(1024), 'bar': fake_metric(2)}}), ('host3', 'node3', {'metrics': {'foo': fake_metric(3072), 'bar': fake_metric(1)}}), ('host4', 'node4', {'metrics': {'foo': fake_metric(8192), 'bar': fake_metric(0)}}), ('host5', 'node5', {'metrics': {'foo': fake_metric(768), 'bar': fake_metric(0), 'zot': fake_metric(1)}}), ('host6', 'node6', {'metrics': {'foo': fake_metric(2048), 'bar': fake_metric(0), 'zot': fake_metric(2)}}), ] return [fakes.FakeHostState(host, node, values) for host, node, values in host_values] def test_single_resource_negtive_ratio(self): self.weight_classes = [io_ops.IoOpsWeigher] host_values = [ ('host1', 'node1', {'num_io_ops': 1}), ('host2', 'node2', {'num_io_ops': 2}), ('host3', 'node3', {'num_io_ops': 0}), ('host4', 'node4', {'num_io_ops': 4}) ] return [fakes.FakeHostState(host, node, values) for host, node, values in host_values]","from oslo.serialization import jsonutils from nova import contextfrom nova.openstack.common.fixture import mockpatch class_names = [cls.__name__ for cls in classes] self.assertIn('RAMWeigher', class_names) self.assertIn('MetricsWeigher', class_names) self.assertIn('IoOpsWeigher', class_names) self.useFixture(mockpatch.Patch( 'nova.db.compute_node_get_all', return_value=fakes.COMPUTE_NODES)) self.host_manager = fakes.FakeHostManager() self.weight_classes = self.weight_handler.get_matching_classes( ['nova.scheduler.weights.ram.RAMWeigher']) ctxt = context.get_admin_context() return self.host_manager.get_all_host_states(ctxt) self.useFixture(mockpatch.Patch( 'nova.db.compute_node_get_all', return_value=fakes.COMPUTE_NODES_METRICS)) self.host_manager = fakes.FakeHostManager() self.weight_classes = self.weight_handler.get_matching_classes( ['nova.scheduler.weights.metrics.MetricsWeigher']) ctxt = context.get_admin_context() return self.host_manager.get_all_host_states(ctxt) def test_single_resourcenegtive_ratio(self):COMPUTE_NODES_IO_OPS = [ # host1: num_io_ops=1 dict(id=1, local_gb=1024, memory_mb=1024, vcpus=1, disk_available_least=None, free_ram_mb=512, vcpus_used=1, free_disk_gb=512, local_gb_used=0, updated_at=None, service=dict(host='host1', disabled=False), hypervisor_hostname='node1', host_ip='127.0.0.1', hypervisor_version=0, numa_topology=None, stats=jsonutils.dumps({'io_workload': '1'})), # host2: num_io_ops=2 dict(id=2, local_gb=2048, memory_mb=2048, vcpus=2, disk_available_least=1024, free_ram_mb=1024, vcpus_used=2, free_disk_gb=1024, local_gb_used=0, updated_at=None, service=dict(host='host2', disabled=True), hypervisor_hostname='node2', host_ip='127.0.0.1', hypervisor_version=0, numa_topology=None, stats=jsonutils.dumps({'io_workload': '2'})), # host3: num_io_ops=0, so host3 should win in the case of default # io_ops_weight_multiplier configure. dict(id=3, local_gb=4096, memory_mb=4096, vcpus=4, disk_available_least=3333, free_ram_mb=3072, vcpus_used=1, free_disk_gb=3072, local_gb_used=0, updated_at=None, service=dict(host='host3', disabled=False), hypervisor_hostname='node3', host_ip='127.0.0.1', hypervisor_version=0, numa_topology=None, stats=jsonutils.dumps({'io_workload': '0'})), # host4: num_io_ops=4, so host4 should win in the case of positive # io_ops_weight_multiplier configure. dict(id=4, local_gb=8192, memory_mb=8192, vcpus=8, disk_available_least=8192, free_ram_mb=8192, vcpus_used=0, free_disk_gb=8888, local_gb_used=0, updated_at=None, service=dict(host='host4', disabled=False), hypervisor_hostname='node4', host_ip='127.0.0.1', hypervisor_version=0, numa_topology=None, stats=jsonutils.dumps({'io_workload': '4'})), # Broken entry dict(id=5, local_gb=1024, memory_mb=1024, vcpus=1, service=None), ] self.useFixture(mockpatch.Patch( 'nova.db.compute_node_get_all', return_value=COMPUTE_NODES_IO_OPS)) self.host_manager = fakes.FakeHostManager() self.weight_classes = self.weight_handler.get_matching_classes( ['nova.scheduler.weights.io_ops.IoOpsWeigher']) ctxt = context.get_admin_context() return self.host_manager.get_all_host_states(ctxt)",49,73
openstack%2Fhorizon~master~I8df2a3f8b7c6b26c37e9e59ef2f7ce7aacd94607,openstack/horizon,master,I8df2a3f8b7c6b26c37e9e59ef2f7ce7aacd94607,Remove Filter button from query-type filters,MERGED,2014-07-31 19:53:38.000000000,2014-12-11 17:00:20.000000000,2014-12-11 17:00:19.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6825}, {'_account_id': 7012}, {'_account_id': 8040}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9647}, {'_account_id': 10068}, {'_account_id': 10295}, {'_account_id': 11881}, {'_account_id': 11902}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-07-31 19:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/535aa45d4445a24ba8bdcfbeb999391eaeff9d2d', 'message': '1350885 Remove Filter button from query-type filters\n\nChange-Id: I8df2a3f8b7c6b26c37e9e59ef2f7ce7aacd94607\n'}, {'number': 2, 'created': '2014-07-31 20:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5bba89c1f8038ff29f80d08919cb4aa8acb7a4cb', 'message': 'Remove Filter button from query-type filters\n\nFor query filters, the table is filtered as the user types. The Filter button has no function, except to needlessly refresh the page. This patch removes the Filter button. It is still present on server-type filters.\n\nChange-Id: I8df2a3f8b7c6b26c37e9e59ef2f7ce7aacd94607\nCloses-Bug: 1350885\n'}, {'number': 3, 'created': '2014-07-31 20:03:29.000000000', 'files': ['horizon/templates/horizon/common/_data_table_table_actions.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/af10611c902db7c4381bcd010391d60f41b3b3fa', 'message': 'Remove Filter button from query-type filters\n\nFor query filters, the table is filtered as the user types.\nThe Filter button has no function, except to needlessly refresh the page.\nThis patch removes the Filter button.\nIt is still present on server-type filters.\n\nChange-Id: I8df2a3f8b7c6b26c37e9e59ef2f7ce7aacd94607\nCloses-Bug: 1350885\n'}]",0,111062,af10611c902db7c4381bcd010391d60f41b3b3fa,35,15,3,11902,,,0,"Remove Filter button from query-type filters

For query filters, the table is filtered as the user types.
The Filter button has no function, except to needlessly refresh the page.
This patch removes the Filter button.
It is still present on server-type filters.

Change-Id: I8df2a3f8b7c6b26c37e9e59ef2f7ce7aacd94607
Closes-Bug: 1350885
",git fetch https://review.opendev.org/openstack/horizon refs/changes/62/111062/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_data_table_table_actions.html'],1,535aa45d4445a24ba8bdcfbeb999391eaeff9d2d,bug/1350885,," <button type=""submit"" {{ filter.attr_string|safe }}>{% trans ""Filter"" %}</button>",0,1
openstack%2Fhorizon~master~I768682fdc65e47d1b28648240b074da1a1d7629f,openstack/horizon,master,I768682fdc65e47d1b28648240b074da1a1d7629f,[Sahara] Fixed display of nodegroup template service parameters,MERGED,2014-12-09 21:07:12.000000000,2014-12-11 17:00:09.000000000,2014-12-11 17:00:08.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8090}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-12-09 21:07:12.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/559620cc861efd6ebb005b317c7eb9ce8364e6cf', 'message': ""[Sahara] Fixed display of nodegroup template service parameters\n\nLooks like typo in variable name (can't check history sinse it is\nin other repo).\n\nChange-Id: I768682fdc65e47d1b28648240b074da1a1d7629f\nCloses-Bug: #1400873\n""}]",0,140476,559620cc861efd6ebb005b317c7eb9ce8364e6cf,16,7,1,8411,,,0,"[Sahara] Fixed display of nodegroup template service parameters

Looks like typo in variable name (can't check history sinse it is
in other repo).

Change-Id: I768682fdc65e47d1b28648240b074da1a1d7629f
Closes-Bug: #1400873
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/140476/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html'],1,559620cc861efd6ebb005b317c7eb9ce8364e6cf,bug/1400873, {% blocktrans %}{{ conf_name }}: {{ conf_val }}{% endblocktrans %}, {% blocktrans %}{{ conf_name }}: {{ conf_value }}{% endblocktrans %},1,1
openstack%2Fhorizon~master~I87b37d90a8f6dcb933ed4689d35bbfb7e560fd9c,openstack/horizon,master,I87b37d90a8f6dcb933ed4689d35bbfb7e560fd9c,Updated from global requirements,MERGED,2014-12-11 07:13:50.000000000,2014-12-11 16:58:22.000000000,2014-12-11 16:58:21.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-12-11 07:13:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e1617a21912410e1a9a08664079c58d99ed05502', 'message': 'Updated from global requirements\n\nChange-Id: I87b37d90a8f6dcb933ed4689d35bbfb7e560fd9c\n'}]",0,140940,e1617a21912410e1a9a08664079c58d99ed05502,10,5,1,11131,,,0,"Updated from global requirements

Change-Id: I87b37d90a8f6dcb933ed4689d35bbfb7e560fd9c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/40/140940/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e1617a21912410e1a9a08664079c58d99ed05502,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Ftrove-integration~master~Id478178f93d3c014c14e709d20c153084d56104e,openstack/trove-integration,master,Id478178f93d3c014c14e709d20c153084d56104e,Add osprofiler dep to guest image,MERGED,2014-12-09 19:35:34.000000000,2014-12-11 16:58:14.000000000,2014-12-11 16:58:13.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6549}, {'_account_id': 8415}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-12-09 19:35:34.000000000', 'files': ['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/8f58c790ed973c535c68a6422a669f828dbcffc7', 'message': 'Add osprofiler dep to guest image\n\nTo support the change of integrating osprofiler with Trove [0], We need\nto make sure osprofiler lib are installed on the trove guest image.\n\n[0] I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nChange-Id: Id478178f93d3c014c14e709d20c153084d56104e\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}]",0,140453,8f58c790ed973c535c68a6422a669f828dbcffc7,12,5,1,6549,,,0,"Add osprofiler dep to guest image

To support the change of integrating osprofiler with Trove [0], We need
to make sure osprofiler lib are installed on the trove guest image.

[0] I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5

Change-Id: Id478178f93d3c014c14e709d20c153084d56104e
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/53/140453/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep']",2,8f58c790ed973c535c68a6422a669f828dbcffc7,, oslo.config>=1.2.0 oslo.messaging>=1.4.0 oslo.i18n>=1.0.0 oslo.serialization>=1.0.0 oslo.utils>=1.0.0 \ osprofiler>=0.3.0, oslo.config>=1.2.0 oslo.messaging>=1.4.0 oslo.i18n>=1.0.0 oslo.serialization>=1.0.0 oslo.utils>=1.0.0,4,2
openstack%2Fneutron~master~Ia3410609208e937a47f72643a14bab9c30953bf4,openstack/neutron,master,Ia3410609208e937a47f72643a14bab9c30953bf4,Updated from global requirements,MERGED,2014-12-11 07:15:03.000000000,2014-12-11 16:22:16.000000000,2014-12-11 16:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 07:15:03.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/daf7de66c4d81c76c83a75c84bc3e0e735c4c404', 'message': 'Updated from global requirements\n\nChange-Id: Ia3410609208e937a47f72643a14bab9c30953bf4\n'}]",0,140944,daf7de66c4d81c76c83a75c84bc3e0e735c4c404,28,19,1,11131,,,0,"Updated from global requirements

Change-Id: Ia3410609208e937a47f72643a14bab9c30953bf4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/140944/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,daf7de66c4d81c76c83a75c84bc3e0e735c4c404,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fceilometer~master~I99037f99f3fcb40eb27b56e1581bf60f32ff3051,openstack/ceilometer,master,I99037f99f3fcb40eb27b56e1581bf60f32ff3051,Improve links in config docs,MERGED,2014-12-11 09:23:05.000000000,2014-12-11 16:16:26.000000000,2014-12-11 16:16:25.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6763}, {'_account_id': 7052}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-11 09:23:05.000000000', 'files': ['doc/source/events.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/979af9b1c4eb25c4c2b1f64796735c2518bb048e', 'message': 'Improve links in config docs\n\nCurrently duplication part from configuration.rst file was removed\n(patch https://review.openstack.org/#/c/133035) but links in events.rst are\nstill refering to removed part of docs.\n\nThis patch improves links.\n\nCloses-bug: #1401444\nChange-Id: I99037f99f3fcb40eb27b56e1581bf60f32ff3051\n'}]",0,140987,979af9b1c4eb25c4c2b1f64796735c2518bb048e,13,8,1,10987,,,0,"Improve links in config docs

Currently duplication part from configuration.rst file was removed
(patch https://review.openstack.org/#/c/133035) but links in events.rst are
still refering to removed part of docs.

This patch improves links.

Closes-bug: #1401444
Change-Id: I99037f99f3fcb40eb27b56e1581bf60f32ff3051
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/87/140987/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/events.rst'],1,979af9b1c4eb25c4c2b1f64796735c2518bb048e,Docs,.. _definitions_cfg_file: http://docs.openstack.org/trunk/config-reference/content/ch_configuring-openstack-telemetry.html .. _drop_unmatched_notifications: http://docs.openstack.org/trunk/config-reference/content/ch_configuring-openstack-telemetry.html,.. _definitions_cfg_file: configuration.html#event-conversion .. _drop_unmatched_notifications: configuration.html#event-conversion,2,2
openstack%2Fdevstack~master~I90ffae49212e68749b8331edc278228419317453,openstack/devstack,master,I90ffae49212e68749b8331edc278228419317453,add the kernel/ramdisk id to driver_info,MERGED,2014-11-20 10:00:58.000000000,2014-12-11 16:16:22.000000000,2014-12-11 16:16:21.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 6773}, {'_account_id': 7118}, {'_account_id': 7882}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-20 10:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9b60ef33a589562d1c242fecc54fa80ab87d5076', 'message': ""add the kernel/ramdisk id to driver_info\n\nBecause bp https://blueprints.launchpad.net/ironic/+spec/add-node-instance-info\nhas been completed,\nadd the deploy_kernel_id and deploy_ramdisk_id to ironic node's driver_info\nin stead of to flavor.\n\nChange-Id: I90ffae49212e68749b8331edc278228419317453\n""}, {'number': 2, 'created': '2014-11-25 10:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c2b85d51508d97b651dd19cee710bbce9a366979', 'message': ""add the kernel/ramdisk id to driver_info\n\nBecause bp https://blueprints.launchpad.net/ironic/+spec/add-node-instance-info\nhas been completed,\nadd the deploy_kernel_id and deploy_ramdisk_id to ironic node's driver_info\nin stead of to flavor.\n\nChange-Id: I90ffae49212e68749b8331edc278228419317453\n""}, {'number': 3, 'created': '2014-12-08 04:02:37.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7d5bf6e9d2140e932419fd0cce11afe161dc73e', 'message': ""add the kernel/ramdisk id to driver_info\n\nBecause bp https://blueprints.launchpad.net/ironic/+spec/add-node-instance-info\nhas been completed,\nadd the deploy_kernel_id and deploy_ramdisk_id to ironic node's driver_info\nin stead of to flavor.\n\nChange-Id: I90ffae49212e68749b8331edc278228419317453\n""}]",4,135897,b7d5bf6e9d2140e932419fd0cce11afe161dc73e,18,8,3,7882,,,0,"add the kernel/ramdisk id to driver_info

Because bp https://blueprints.launchpad.net/ironic/+spec/add-node-instance-info
has been completed,
add the deploy_kernel_id and deploy_ramdisk_id to ironic node's driver_info
in stead of to flavor.

Change-Id: I90ffae49212e68749b8331edc278228419317453
",git fetch https://review.opendev.org/openstack/devstack refs/changes/97/135897/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,9b60ef33a589562d1c242fecc54fa80ab87d5076,bp/https," -i pxe_deploy_kernel=$IRONIC_DEPLOY_KERNEL_ID \ -i pxe_deploy_ramdisk=$IRONIC_DEPLOY_RAMDISK_ID \ nova flavor-key baremetal set ""cpu_arch""=""x86_64"""," # TODO(lucasagomes): Remove the 'baremetal:deploy_kernel_id' # and 'baremetal:deploy_ramdisk_id' parameters # from the flavor after the completion of # https://blueprints.launchpad.net/ironic/+spec/add-node-instance-info nova flavor-key baremetal set ""cpu_arch""=""x86_64"" ""baremetal:deploy_kernel_id""=""$IRONIC_DEPLOY_KERNEL_ID"" ""baremetal:deploy_ramdisk_id""=""$IRONIC_DEPLOY_RAMDISK_ID""",3,5
openstack%2Fkeystone~master~I772f2984868c434c16e8d6992537aa47b7646303,openstack/keystone,master,I772f2984868c434c16e8d6992537aa47b7646303,Updated from global requirements,MERGED,2014-12-11 07:14:12.000000000,2014-12-11 16:16:11.000000000,2014-12-11 16:16:10.000000000,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-12-11 07:14:12.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/735f66141245c33e497613ddf9e6750bfba40704', 'message': 'Updated from global requirements\n\nChange-Id: I772f2984868c434c16e8d6992537aa47b7646303\n'}]",0,140942,735f66141245c33e497613ddf9e6750bfba40704,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I772f2984868c434c16e8d6992537aa47b7646303
",git fetch https://review.opendev.org/openstack/keystone refs/changes/42/140942/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,735f66141245c33e497613ddf9e6750bfba40704,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,2,2
openstack%2Fkeystone~master~Ia9cc6e3c9807e00e7291cf9bb2f3451fbe2bf94f,openstack/keystone,master,Ia9cc6e3c9807e00e7291cf9bb2f3451fbe2bf94f,Remove endpoint_substitution_whitelist config option,MERGED,2014-10-27 00:03:08.000000000,2014-12-11 16:14:58.000000000,2014-12-11 16:14:56.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9142}]","[{'number': 1, 'created': '2014-10-27 00:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1968728572633fe257eef53703f5a75d1da663dc', 'message': 'Remove endpoint_substitution_whitelist config option\n\nThe endpoint_substitution_whitelist was actually scheduled to be\nremoved in Juno.\n\nThe whitelisted substitution items are the same as was the default\nin previous releases.\n\nbp removed-as-of-kilo\nDocImpact\n\nChange-Id: Ia9cc6e3c9807e00e7291cf9bb2f3451fbe2bf94f\n'}, {'number': 2, 'created': '2014-12-05 22:47:46.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/tests/unit/catalog/test_core.py', 'keystone/common/config.py', 'keystone/catalog/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/93311737973866fc0c459f6aabaec0b55db21b23', 'message': 'Remove endpoint_substitution_whitelist config option\n\nThe endpoint_substitution_whitelist was actually scheduled to be\nremoved in Juno.\n\nThe whitelisted substitution items are the same as was the default\nin previous releases.\n\nbp removed-as-of-kilo\nDocImpact\n\nChange-Id: Ia9cc6e3c9807e00e7291cf9bb2f3451fbe2bf94f\n'}]",2,131007,93311737973866fc0c459f6aabaec0b55db21b23,15,7,2,6486,,,0,"Remove endpoint_substitution_whitelist config option

The endpoint_substitution_whitelist was actually scheduled to be
removed in Juno.

The whitelisted substitution items are the same as was the default
in previous releases.

bp removed-as-of-kilo
DocImpact

Change-Id: Ia9cc6e3c9807e00e7291cf9bb2f3451fbe2bf94f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/07/131007/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/tests/unit/catalog/test_core.py', 'keystone/common/config.py', 'keystone/catalog/core.py']",4,1968728572633fe257eef53703f5a75d1da663dc,bp/removed-as-of-kilo," WHITELISTED_PROPERTIES = [ 'tenant_id', 'user_id', 'public_bind_host', 'admin_bind_host', 'compute_host', 'compute_port', 'admin_port', 'public_port', 'public_endpoint', 'admin_endpoint', ] WHITELISTED_PROPERTIES,"," CONF.catalog.endpoint_substitution_whitelist,",21,38
openstack%2Fopenstacksdk~master~I1f6e27703ebcd0b3e9ae27095aa90d6c0318231d,openstack/openstacksdk,master,I1f6e27703ebcd0b3e9ae27095aa90d6c0318231d,Updated from global requirements,MERGED,2014-12-11 07:21:27.000000000,2014-12-11 16:09:49.000000000,2014-12-11 16:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-12-11 07:21:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/225d8bfa041b080ffd860d5fae41f5cfc110f94e', 'message': 'Updated from global requirements\n\nChange-Id: I1f6e27703ebcd0b3e9ae27095aa90d6c0318231d\n'}]",0,140964,225d8bfa041b080ffd860d5fae41f5cfc110f94e,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1f6e27703ebcd0b3e9ae27095aa90d6c0318231d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/64/140964/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,225d8bfa041b080ffd860d5fae41f5cfc110f94e,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fpuppet-horizon~master~I54ccc3c08ddb63edc3815ef0ee66675e867b84c9,openstack/puppet-horizon,master,I54ccc3c08ddb63edc3815ef0ee66675e867b84c9,Add ability to configure simple HORIZON_CONFIG entries,ABANDONED,2014-10-20 20:36:36.000000000,2014-12-11 15:59:17.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-10-20 20:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/8da8e259cd6ade065242eee810eb6bdb3edcd6ee', 'message': 'Add ability to configure simple HORIZON_CONFIG entries\n\nIntroduce the horizon_config parameter to add\nsimple HORIZON_CONFIG entries to local_settings.py\n\nChange-Id: I54ccc3c08ddb63edc3815ef0ee66675e867b84c9\nCloses-bug: #1383471\n'}, {'number': 2, 'created': '2014-10-23 19:53:02.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/6afc71208200c190d3221514b4f3b581abfcc15e', 'message': 'Add ability to configure simple HORIZON_CONFIG entries\n\nIntroduce the horizon_config parameter to add\nsimple HORIZON_CONFIG entries to local_settings.py\n\nChange-Id: I54ccc3c08ddb63edc3815ef0ee66675e867b84c9\nCloses-bug: #1383471\n'}]",1,129724,6afc71208200c190d3221514b4f3b581abfcc15e,10,4,2,7156,,,0,"Add ability to configure simple HORIZON_CONFIG entries

Introduce the horizon_config parameter to add
simple HORIZON_CONFIG entries to local_settings.py

Change-Id: I54ccc3c08ddb63edc3815ef0ee66675e867b84c9
Closes-bug: #1383471
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/24/129724/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,8da8e259cd6ade065242eee810eb6bdb3edcd6ee,bug/1383471," context 'with horizon_config parameter' do before do params.merge!({ :horizon_config => { 'customization_module' => 'my_project.overrides', 'foo' => 'bar', } }) end it 'HORIZON_CONFIG entries are added' do verify_contents(subject, platforms_params[:config_file], [ ""HORIZON_CONFIG['customization_module'] = 'my_project.overrides'"", ""HORIZON_CONFIG['foo'] = 'bar'"", ]) end end ",,25,0
openstack%2Ftripleo-image-elements~master~I6b390e168c2f972b0beab52815922bb6b2ccf786,openstack/tripleo-image-elements,master,I6b390e168c2f972b0beab52815922bb6b2ccf786,System dnsmasq daemon should only listen on lo,MERGED,2014-12-07 16:39:22.000000000,2014-12-11 15:38:25.000000000,2014-12-11 15:38:25.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 8449}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-07 16:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bedb72d67241b778f2566e11aad215aad28d3a98', 'message': ""System dnsmasq daemon should only listen on lo\n\nNeutron runs dnsmasq. That's all nice and good.\n\nBut just having dnsmasq installed means that the system runs a different\ndnsmasq, which by default listens (and response) on all interfaces.\n\nFor machines that are accessible on the public internet, this means they\ncan be used in dns-amplification DOS attacks. This tends to make\nsecurity and network people sad.\n\nThis patch drops some config for the system dnsmasq which tell it to\nonly listen on 127.0.0.1.\n\nIf the deployer needs dnsmasq listening on other interfaces, another\nfile dropped in /etc/dnsmasq.conf can be used to specifiy additional\ninterfaces or IP addreses.\n\nChange-Id: I6b390e168c2f972b0beab52815922bb6b2ccf786\nPartial-bug: 1188067\n""}, {'number': 2, 'created': '2014-12-10 07:35:33.000000000', 'files': ['elements/neutron/os-apply-config/etc/dnsmasq.d/only-lo'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b77ec5cb5b3ed400b44302bdbd76e2275d819da3', 'message': ""System dnsmasq daemon should only listen on lo\n\nNeutron runs dnsmasq. That's all nice and good.\n\nBut just having dnsmasq installed means that the system runs a different\ndnsmasq, which by default listens (and response) on all interfaces.\n\nFor machines that are accessible on the public internet, this means they\ncan be used in dns-amplification DOS attacks. This tends to make\nsecurity and network people sad.\n\nThis patch drops some config for the system dnsmasq which tell it to\nonly listen on 127.0.0.1.\n\nIf the deployer needs dnsmasq listening on other interfaces, another\nfile dropped in /etc/dnsmasq.d can be used to specifiy additional\ninterfaces or IP addreses.\n\nChange-Id: I6b390e168c2f972b0beab52815922bb6b2ccf786\nPartial-bug: 1188067\n""}]",2,139865,b77ec5cb5b3ed400b44302bdbd76e2275d819da3,15,5,2,9453,,,0,"System dnsmasq daemon should only listen on lo

Neutron runs dnsmasq. That's all nice and good.

But just having dnsmasq installed means that the system runs a different
dnsmasq, which by default listens (and response) on all interfaces.

For machines that are accessible on the public internet, this means they
can be used in dns-amplification DOS attacks. This tends to make
security and network people sad.

This patch drops some config for the system dnsmasq which tell it to
only listen on 127.0.0.1.

If the deployer needs dnsmasq listening on other interfaces, another
file dropped in /etc/dnsmasq.d can be used to specifiy additional
interfaces or IP addreses.

Change-Id: I6b390e168c2f972b0beab52815922bb6b2ccf786
Partial-bug: 1188067
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/65/139865/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/neutron/os-apply-config/etc/dnsmasq.d/only-lo'],1,bedb72d67241b778f2566e11aad215aad28d3a98,bug/1188067,interface=lo bind-interfaces,,2,0
openstack%2Fpython-ceilometerclient~master~Ie3dd873d681b85749d48a3bb1abc90a8e8fa92c7,openstack/python-ceilometerclient,master,Ie3dd873d681b85749d48a3bb1abc90a8e8fa92c7,Updated from global requirements,MERGED,2014-12-11 07:19:48.000000000,2014-12-11 15:30:01.000000000,2014-12-11 15:30:00.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-11 07:19:48.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/989ff3a83d7fc6d7907517206f41732b34c6ab7d', 'message': 'Updated from global requirements\n\nChange-Id: Ie3dd873d681b85749d48a3bb1abc90a8e8fa92c7\n'}]",0,140954,989ff3a83d7fc6d7907517206f41732b34c6ab7d,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ie3dd873d681b85749d48a3bb1abc90a8e8fa92c7
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/54/140954/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,989ff3a83d7fc6d7907517206f41732b34c6ab7d,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Ffuel-astute~master~I91e0a764faa987a49b1b9b81e0e30529535a3acb,openstack/fuel-astute,master,I91e0a764faa987a49b1b9b81e0e30529535a3acb,Add check nodes availabilities via mcollective,MERGED,2014-11-27 11:32:53.000000000,2014-12-11 15:26:39.000000000,2014-12-11 15:26:39.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 14042}]","[{'number': 1, 'created': '2014-11-27 11:32:53.000000000', 'files': ['spec/unit/orchestrator_spec.rb', 'lib/astute/orchestrator.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/84704c65fcb78ccf15b0eb8cf9547abb82d4a1de', 'message': 'Add check nodes availabilities via mcollective\n\nNetwork validation could take a lot of time\nespecially if nodes not availablity via mcollective\n\nBefore network check we just run mcollective check\nand if it failed, report about it and do not\nrun network check.\n\nChange-Id: I91e0a764faa987a49b1b9b81e0e30529535a3acb\nCloses-Bug: #1394973\n'}]",0,137610,84704c65fcb78ccf15b0eb8cf9547abb82d4a1de,11,5,1,8776,,,0,"Add check nodes availabilities via mcollective

Network validation could take a lot of time
especially if nodes not availablity via mcollective

Before network check we just run mcollective check
and if it failed, report about it and do not
run network check.

Change-Id: I91e0a764faa987a49b1b9b81e0e30529535a3acb
Closes-Bug: #1394973
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/10/137610/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/orchestrator_spec.rb', 'lib/astute/orchestrator.rb']",2,84704c65fcb78ccf15b0eb8cf9547abb82d4a1de,bug/1394973," ctx = Context.new(task_id, reporter) validate_nodes_access(ctx, nodes) Network.check_network(ctx, nodes) ctx = Context.new(task_id, reporter) validate_nodes_access(ctx, nodes) Network.check_dhcp(ctx, nodes) ctx = Context.new(task_id, reporter) validate_nodes_access(ctx, nodes) Network.multicast_verification(ctx, nodes) def validate_nodes_access(ctx, nodes) nodes_types = node_type(ctx.reporter, ctx.task_id, nodes.map{ |n| n['uid'] }, timeout=10) not_avaliable_nodes = nodes.map { |n| n['uid'].to_s } - nodes_types.map { |n| n['uid'].to_s } unless not_avaliable_nodes.empty? raise ""Network verification not avaliable because nodes #{not_avaliable_nodes} "" \ ""not avaliable via mcollective"" end end "," Network.check_network(Context.new(task_id, reporter), nodes) Network.check_dhcp(Context.new(task_id, reporter), nodes) Network.multicast_verification(Context.new(task_id, reporter), nodes)",37,3
openstack%2Fsahara~master~I23f7340e254ec249f00c6de9a980adac9e637983,openstack/sahara,master,I23f7340e254ec249f00c6de9a980adac9e637983,Fixed subprocess error reporting,MERGED,2014-12-05 22:40:15.000000000,2014-12-11 15:25:54.000000000,2014-12-11 15:25:52.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-05 22:40:15.000000000', 'files': ['sahara/exceptions.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2f9a12bcb270c5fc00b5ec3cb495155d510b5762', 'message': ""Fixed subprocess error reporting\n\nMoved stdout and stderr decoding to earlier stage to prevent\ndecode error.\n\nNote, the code is not py3 compatible. But this change doesn't\nintroduce any new incompatibility, it changes order of existing\ndecode calls.\n\nChange-Id: I23f7340e254ec249f00c6de9a980adac9e637983\nCloses-Bug: #1399490\n""}]",0,139742,2f9a12bcb270c5fc00b5ec3cb495155d510b5762,15,7,1,8411,,,0,"Fixed subprocess error reporting

Moved stdout and stderr decoding to earlier stage to prevent
decode error.

Note, the code is not py3 compatible. But this change doesn't
introduce any new incompatibility, it changes order of existing
decode calls.

Change-Id: I23f7340e254ec249f00c6de9a980adac9e637983
Closes-Bug: #1399490
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/139742/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/exceptions.py'],1,2f9a12bcb270c5fc00b5ec3cb495155d510b5762,bug/1399490," self.message = '%s\nSTDERR:\n%s' % ( self.message, stderr.decode('ascii', 'ignore')) self.message = '%s\nSTDOUT:\n%s' % ( self.message, stdout.decode('ascii', 'ignore')) "," self.message = '%s\nSTDERR:\n%s' % (self.message, stderr) self.message = '%s\nSTDOUT:\n%s' % (self.message, stdout) self.message = self.message.decode('ascii', 'ignore')",4,3
openstack%2Fbarbican~master~Ifcd773b31f65704737f2925ee67743df39ec50f7,openstack/barbican,master,Ifcd773b31f65704737f2925ee67743df39ec50f7,Replace model related instances of tenant,MERGED,2014-12-10 11:12:21.000000000,2014-12-11 15:23:43.000000000,2014-12-11 15:23:41.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-10 11:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/528ab2532081e03b9ce76eb2a6f29c72e79ba819', 'message': 'Replace model related instances of tenant\n\nThis CR renames the instances of the word tenant for projects in the\ncases where there is a relation to the models. In addition, the proper\nmigration scripts where writen.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: Ifcd773b31f65704737f2925ee67743df39ec50f7\n'}, {'number': 2, 'created': '2014-12-10 12:05:14.000000000', 'files': ['barbican/api/controllers/orders.py', 'barbican/plugin/resources.py', 'barbican/openstack/common/policy.py', 'barbican/tasks/certificate_resources.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/model/test_repositories.py', 'barbican/tests/tasks/test_resources.py', 'barbican/model/repositories.py', 'barbican/tests/tasks/test_certificate_resources.py', 'barbican/tasks/resources.py', 'barbican/model/migration/alembic_migrations/versions/795737bb3c3_change_tenants_to_projects.py', 'barbican/plugin/store_crypto.py', 'barbican/api/middleware/context.py', 'barbican/model/models.py', 'barbican/tests/plugin/test_store_crypto.py', 'barbican/common/resources.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c2b32c54504c595c2ba44217d2ac358685a22bfe', 'message': 'Replace model related instances of tenant\n\nThis CR renames the instances of the word tenant for projects in the\ncases where there is a relation to the models. In addition, the proper\nmigration scripts where writen.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: Ifcd773b31f65704737f2925ee67743df39ec50f7\n'}]",3,140645,c2b32c54504c595c2ba44217d2ac358685a22bfe,14,13,2,10873,,,0,"Replace model related instances of tenant

This CR renames the instances of the word tenant for projects in the
cases where there is a relation to the models. In addition, the proper
migration scripts where writen.

Partially implements: blueprint replace-concept-of-tenants-for-projects

Change-Id: Ifcd773b31f65704737f2925ee67743df39ec50f7
",git fetch https://review.opendev.org/openstack/barbican refs/changes/45/140645/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/api/controllers/orders.py', 'barbican/plugin/resources.py', 'barbican/openstack/common/policy.py', 'barbican/tasks/certificate_resources.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/model/test_repositories.py', 'barbican/tests/tasks/test_resources.py', 'barbican/model/repositories.py', 'barbican/tests/tasks/test_certificate_resources.py', 'barbican/tasks/resources.py', 'barbican/model/migration/alembic_migrations/versions/795737bb3c3_change_tenants_to_projects.py', 'barbican/plugin/store_crypto.py', 'barbican/api/middleware/context.py', 'barbican/model/models.py', 'barbican/tests/plugin/test_store_crypto.py', 'barbican/common/resources.py', 'barbican/tests/api/test_resources.py']",19,528ab2532081e03b9ce76eb2a6f29c72e79ba819,bp/replace-concept-of-tenants-for-projects," test.assertIsNotNone(datum.kek_meta_project) test.assertTrue(datum.kek_meta_project.bind_completed) test.assertIsNotNone(datum.kek_meta_project.plugin_name) test.assertIsNotNone(datum.kek_meta_project.kek_label) self.project = models.Project() self.assertIsInstance(project, models.Project) self.assertIsInstance(project_secret, models.ProjectSecret) self.assertEqual(project_secret.project_id, self.project_entity_id) self.project = models.Project() self.project = models.Project() self.project = models.Project() self.project = models.Project() self.project = models.Project() self.project = models.Project() self.project = models.Project()"," test.assertIsNotNone(datum.kek_meta_tenant) test.assertTrue(datum.kek_meta_tenant.bind_completed) test.assertIsNotNone(datum.kek_meta_tenant.plugin_name) test.assertIsNotNone(datum.kek_meta_tenant.kek_label) self.project = models.Tenant() self.assertIsInstance(project, models.Tenant) self.assertIsInstance(project_secret, models.TenantSecret) self.assertEqual(project_secret.tenant_id, self.project_entity_id) self.project = models.Tenant() self.project = models.Tenant() self.project = models.Tenant() self.project = models.Tenant() self.project = models.Tenant() self.project = models.Tenant() self.project = models.Tenant()",178,117
openstack%2Fproject-config~master~I621307d9e735d6c1a5d72458bdac85c0b4db16fa,openstack/project-config,master,I621307d9e735d6c1a5d72458bdac85c0b4db16fa,Run ceilometer rally scenarios,MERGED,2014-11-04 10:52:05.000000000,2014-12-11 15:21:35.000000000,2014-12-11 15:21:34.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6133}, {'_account_id': 6172}, {'_account_id': 6554}, {'_account_id': 6676}, {'_account_id': 6786}, {'_account_id': 7069}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-11-04 10:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/99f0766a3da7c716eb7906ae59a308e75e34b400', 'message': 'Run ceilometer rally scenarios\n\nDepends on https://review.openstack.org/132649\n\nChange-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa\n'}, {'number': 2, 'created': '2014-11-25 09:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/db85887ca378e74a4a108f25e98374a4da2f33c5', 'message': 'Run ceilometer rally scenarios\n\nDepends on https://review.openstack.org/132649\n\nImplements blueprint rally-check-gate\n\nChange-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa\n'}, {'number': 3, 'created': '2014-11-25 09:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bdc91b92f76cd20b02af64924a48688749116a4b', 'message': 'Run ceilometer rally scenarios\n\nDepends on https://review.openstack.org/132649\n\nImplements blueprint rally-gate-check\n\nChange-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa\n'}, {'number': 4, 'created': '2014-11-28 13:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b7b6118535c023e8968bbee00ba6bd143c0109f5', 'message': 'Run ceilometer rally scenarios\n\nDepends on https://review.openstack.org/132649\n\nImplements blueprint rally-gate-check\n\nChange-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa\n'}, {'number': 5, 'created': '2014-12-03 06:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e5a9dcaa43f3f2972c04bc57d21d5e5c6d30382a', 'message': 'Run ceilometer rally scenarios\n\nDepends on https://review.openstack.org/132649\n\nImplements blueprint rally-gate-check\n\nChange-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa\n'}, {'number': 6, 'created': '2014-12-03 17:29:12.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ec2b14a87b4e7aee06e24cc344f7c08fd5fbb91d', 'message': 'Run ceilometer rally scenarios\n\nDepends on https://review.openstack.org/132649\n\nImplements blueprint rally-gate-check\n\nChange-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa\n'}]",6,132650,ec2b14a87b4e7aee06e24cc344f7c08fd5fbb91d,35,11,6,2813,,,0,"Run ceilometer rally scenarios

Depends on https://review.openstack.org/132649

Implements blueprint rally-gate-check

Change-Id: I621307d9e735d6c1a5d72458bdac85c0b4db16fa
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/132650/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,99f0766a3da7c716eb7906ae59a308e75e34b400,bp/rally-gate-check, - name: gate-rally-dsvm-ceilometer voting: false - gate-rally-dsvm-ceilometer,,4,0
openstack%2Fopenstack-manuals~master~Id1d6d6cc624fd29c5af72e35a06c62200dcca62b,openstack/openstack-manuals,master,Id1d6d6cc624fd29c5af72e35a06c62200dcca62b,Updated CLI reference for ironic 0.3.2,MERGED,2014-12-11 12:23:42.000000000,2014-12-11 15:15:40.000000000,2014-12-11 15:15:39.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-11 12:23:42.000000000', 'files': ['doc/cli-reference/generated/ch_cli_ironic_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab516cee79b4deefa112a8d7b783406469b79e2d', 'message': 'Updated CLI reference for ironic 0.3.2\n\nChange-Id: Id1d6d6cc624fd29c5af72e35a06c62200dcca62b\n'}]",0,141030,ab516cee79b4deefa112a8d7b783406469b79e2d,6,2,1,167,,,0,"Updated CLI reference for ironic 0.3.2

Change-Id: Id1d6d6cc624fd29c5af72e35a06c62200dcca62b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/30/141030/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/generated/ch_cli_ironic_commands.xml'],1,ab516cee79b4deefa112a8d7b783406469b79e2d,update_client_ironic," <literal>0.3.2</literal>. <screen><computeroutput>usage: ironic [--version] [--debug] [-v] [--cert-file OS_CERT] [--key-file OS_KEY] [--ca-file OS_CACERT] [--os-endpoint-type OS_ENDPOINT_TYPE] [--insecure] [--os-cacert &lt;ca-certificate&gt;] [--os-cert &lt;certificate&gt;] [--os-key &lt;key&gt;] [--timeout &lt;seconds&gt;] [--os-user-domain-id OS_USER_DOMAIN_ID] [--os-user-domain-name OS_USER_DOMAIN_NAME] [--os-project-id OS_PROJECT_ID] [--os-project-name OS_PROJECT_NAME] [--os-project-domain-id OS_PROJECT_DOMAIN_ID] [--os-project-domain-name OS_PROJECT_DOMAIN_NAME] <term><command>node-set-maintenance</command></term> <listitem> <para> Set maintenance mode on or off. </para> </listitem> </varlistentry> <varlistentry> Power the node on or off or reboot. Provision, rebuild or delete an instance. <term><command>--cert-file OS_CERT</command></term> <emphasis>DEPRECATED!</emphasis> Use --os-cert. <term><command>--key-file OS_KEY</command></term> <emphasis>DEPRECATED!</emphasis> Use --os-key. <term><command>--ca-file OS_CACERT</command></term> <emphasis>DEPRECATED!</emphasis> Use --os-cacert. <varlistentry> <term><command>--insecure</command></term> <listitem> <para> Explicitly allow client to perform ""insecure"" TLS (https) requests. The server's certificate will not be verified against any certificate authorities. This option should be used with caution. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-cacert &lt;ca-certificate&gt;</command></term> <listitem> <para> Specify a CA bundle file to use in verifying a TLS (https) server certificate. Defaults to <code>env[OS_CACERT]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-cert &lt;certificate&gt;</command></term> <listitem> <para> Defaults to <code>env[OS_CERT]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-key &lt;key&gt;</command></term> <listitem> <para> Defaults to <code>env[OS_KEY]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--timeout &lt;seconds&gt;</command></term> <listitem> <para> Set request timeout (in seconds). </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-user-domain-id OS_USER_DOMAIN_ID</command></term> <listitem> <para> Defaults to <code>env[OS_USER_DOMAIN_ID]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-user-domain-name OS_USER_DOMAIN_NAME</command></term> <listitem> <para> Defaults to <code>env[OS_USER_DOMAIN_NAME]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-project-id OS_PROJECT_ID</command></term> <listitem> <para> Another way to specify tenant ID. This option is mutually exclusive with --os-tenant-id. Defaults to <code>env[OS_PROJECT_ID]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-project-name OS_PROJECT_NAME</command></term> <listitem> <para> Another way to specify tenant name. This option is mutually exclusive with --os-tenant-name. Defaults to <code>env[OS_PROJECT_NAME]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-project-domain-id OS_PROJECT_DOMAIN_ID</command></term> <listitem> <para> Defaults to <code>env[OS_PROJECT_DOMAIN_ID]</code>. </para> </listitem> </varlistentry> <varlistentry> <term><command>--os-project-domain-name OS_PROJECT_DOMAIN_NAME</command></term> <listitem> <para> Defaults to <code>env[OS_PROJECT_DOMAIN_NAME]</code>. </para> </listitem> </varlistentry> <screen><computeroutput>usage: ironic driver-vendor-passthru [--http_method &lt;http_method&gt;] &lt;driver_name&gt; &lt;method&gt; <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>--http_method &lt;http_method&gt;</command></term> <listitem> <para> The HTTP method to use in the request. Valid HTTP methods are: 'POST', 'PUT', 'GET', 'DELETE', 'PATCH'. Defaults to 'POST'. </para> </listitem> </varlistentry> </variablelist> [-p &lt;key=value&gt;] [-e &lt;key=value&gt;] [-u &lt;uuid&gt;]</computeroutput></screen> <varlistentry> <term><command>-u &lt;uuid&gt;, --uuid &lt;uuid&gt;</command></term> <listitem> <para> Unique UUID for the node </para> </listitem> </varlistentry> <section xml:id=""ironicclient_subcommand_node-set-maintenance""> <title>ironic node-set-maintenance</title> <screen><computeroutput>usage: ironic node-set-maintenance [--reason &lt;reason&gt;] &lt;node id&gt; &lt;maintenance mode&gt;</computeroutput></screen> <para> Set maintenance mode on or off. </para> <variablelist wordsize=""10""> <title>Positional arguments</title> <varlistentry> <term><command>&lt;node id&gt;</command></term> <listitem> <para> UUID of node </para> </listitem> </varlistentry> <varlistentry> <term><command>&lt;maintenance mode&gt;</command></term> <listitem> <para> Supported states: 'on' or 'off' </para> </listitem> </varlistentry> </variablelist> <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>--reason &lt;reason&gt;</command></term> <listitem> <para> The reason for setting maintenance mode to ""on""; not valid when setting to ""off"". </para> </listitem> </varlistentry> </variablelist> </section>Power the node on or off or reboot.Provision, rebuild or delete an instance. <screen><computeroutput>usage: ironic node-vendor-passthru [--http_method &lt;http_method&gt;] &lt;node id&gt; &lt;method&gt; <variablelist wordsize=""10""> <title>Optional arguments</title> <varlistentry> <term><command>--http_method &lt;http_method&gt;</command></term> <listitem> <para> The HTTP method to use in the request. Valid HTTP methods are: 'POST', 'PUT', 'GET', 'DELETE', 'PATCH'. Defaults to 'POST'. </para> </listitem> </varlistentry> </variablelist>"," <literal>0.3.1</literal>. <screen><computeroutput>usage: ironic [--version] [--debug] [-v] [-k] [--cert-file CERT_FILE] [--key-file KEY_FILE] [--ca-file CA_FILE] [--timeout TIMEOUT] [--os-endpoint-type OS_ENDPOINT_TYPE] Power the node on or off. Provision an instance on, or delete an instance from a node. <term><command>-k, --insecure</command></term> Explicitly allow ironicclient to perform ""insecure"" SSL (https) requests. The server's certificate will not be verified against any certificate authorities. This option should be used with caution <term><command>--cert-file CERT_FILE</command></term> Path of certificate file to use in SSL connection. This file can optionally be prepended with the private key <term><command>--key-file KEY_FILE</command></term> Path of client key to use in SSL connection. This option is not necessary if your key is prepended to your cert file </para> </listitem> </varlistentry> <varlistentry> <term><command>--ca-file CA_FILE</command></term> <listitem> <para> Path of CA SSL certificate(s) used to verify the remote server certificate. Without this option ironic looks for the default system CA certificates </para> </listitem> </varlistentry> <varlistentry> <term><command>--timeout TIMEOUT</command></term> <listitem> <para> Number of seconds to wait for a response; defaults to 600 <screen><computeroutput>usage: ironic driver-vendor-passthru &lt;driver_name&gt; &lt;method&gt; [-p &lt;key=value&gt;] [-e &lt;key=value&gt;]</computeroutput></screen>Power the node on or off.Provision an instance on, or delete an instance from a node. <screen><computeroutput>usage: ironic node-vendor-passthru &lt;node id&gt; &lt;method&gt;",204,44
openstack%2Fkeystonemiddleware~master~I222d1e8d6d508196bc5d95ce406e876a0fd5d447,openstack/keystonemiddleware,master,I222d1e8d6d508196bc5d95ce406e876a0fd5d447,Updated from global requirements,MERGED,2014-12-11 07:14:14.000000000,2014-12-11 15:03:37.000000000,2014-12-11 15:03:37.000000000,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-12-11 07:14:14.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f4805de073d949da38d7ad0ed3dbdacbdf843af0', 'message': 'Updated from global requirements\n\nChange-Id: I222d1e8d6d508196bc5d95ce406e876a0fd5d447\n'}]",0,140943,f4805de073d949da38d7ad0ed3dbdacbdf843af0,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I222d1e8d6d508196bc5d95ce406e876a0fd5d447
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/43/140943/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f4805de073d949da38d7ad0ed3dbdacbdf843af0,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fsahara-extra~master~Icd79a400b90b4cd19ac093355a9f731a2195de10,openstack/sahara-extra,master,Icd79a400b90b4cd19ac093355a9f731a2195de10,Adds hadoop2 maven profile and fixes tests,MERGED,2014-12-10 13:44:39.000000000,2014-12-11 14:56:20.000000000,2014-12-11 14:56:19.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-10 13:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/97ab6798467d73167d1fe5aa3cb83122986d3b16', 'message': 'Adds hadoop2 maven profile and fixes tests\n\n* adds ""hadoop2"" maven profile\n* switches tests depended by hadoop version\n\nChange-Id: Icd79a400b90b4cd19ac093355a9f731a2195de10\nCloses-Bug: 1401027\n'}, {'number': 2, 'created': '2014-12-10 13:50:36.000000000', 'files': ['hadoop-swiftfs/pom.xml', 'hadoop-swiftfs/src/test/java/org/apache/hadoop/fs/swift/TestSwiftConfig.java', 'hadoop-swiftfs/README.rst', 'hadoop-swiftfs/src/test/java/org/apache/hadoop/fs/swift/TestUtils.java'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/32a61dcdde68c33c7b61d82cdc163d78522d43e1', 'message': 'Adds hadoop2 maven profile and fixes tests\n\n* adds ""hadoop2"" maven profile\n* switches tests depended by hadoop version\n\nChange-Id: Icd79a400b90b4cd19ac093355a9f731a2195de10\nCloses-Bug: 1401027\n'}]",0,140683,32a61dcdde68c33c7b61d82cdc163d78522d43e1,9,3,2,11059,,,0,"Adds hadoop2 maven profile and fixes tests

* adds ""hadoop2"" maven profile
* switches tests depended by hadoop version

Change-Id: Icd79a400b90b4cd19ac093355a9f731a2195de10
Closes-Bug: 1401027
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/83/140683/2 && git format-patch -1 --stdout FETCH_HEAD,"['hadoop-swiftfs/pom.xml', 'hadoop-swiftfs/src/test/java/org/apache/hadoop/fs/swift/TestSwiftConfig.java', 'hadoop-swiftfs/README.rst']",3,97ab6798467d73167d1fe5aa3cb83122986d3b16,bug/1401027,* pom.xml was updated to use hadoop-core 1.1.2 dependency and adds hadoop2 profile,* pom.xml was updated to use hadoop-core 1.1.2 dependency,34,8
openstack%2Fpython-barbicanclient~master~I38b7a9d0c9e60c95c302c904961d4ac8197b5c15,openstack/python-barbicanclient,master,I38b7a9d0c9e60c95c302c904961d4ac8197b5c15,Updated from global requirements,MERGED,2014-12-11 07:19:46.000000000,2014-12-11 14:43:29.000000000,2014-12-11 14:43:29.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 10035}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-11 07:19:46.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/21ab8aaed6ec2828a1874980e297acae4d0f8285', 'message': 'Updated from global requirements\n\nChange-Id: I38b7a9d0c9e60c95c302c904961d4ac8197b5c15\n'}]",0,140953,21ab8aaed6ec2828a1874980e297acae4d0f8285,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I38b7a9d0c9e60c95c302c904961d4ac8197b5c15
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/53/140953/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,21ab8aaed6ec2828a1874980e297acae4d0f8285,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fsahara~master~I1b0d3c376d0c861ff3ea4199312b4fa9e3fbda4e,openstack/sahara,master,I1b0d3c376d0c861ff3ea4199312b4fa9e3fbda4e,Update oslo-incubator lockutils,MERGED,2014-12-04 18:42:05.000000000,2014-12-11 14:35:50.000000000,2014-12-11 14:35:49.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-12-04 18:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ac9cc584f7bdba224e707f6ff58af97c0bd63ef7', 'message': 'Update oslo-incubator lockutils\n\nChanges -\n * Allow tempest to use new log w/o oslo.i18n\n * Switch fileutils to use python logging\n * Fix i18n import\n * Remove code that moved to oslo.i18n\n * Switch oslo-incubator to use oslo.utils and remove old modules\n\nChange-Id: I1b0d3c376d0c861ff3ea4199312b4fa9e3fbda4e\n'}, {'number': 2, 'created': '2014-12-04 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c9d764d06d1ac14c4d3794136e7b979203b74bc8', 'message': 'Update oslo-incubator lockutils\n\nChanges -\n * Allow tempest to use new log w/o oslo.i18n\n * Switch fileutils to use python logging\n * Fix i18n import\n * Remove code that moved to oslo.i18n\n * Switch oslo-incubator to use oslo.utils and remove old modules\n\nChange-Id: I1b0d3c376d0c861ff3ea4199312b4fa9e3fbda4e\n'}, {'number': 3, 'created': '2014-12-05 17:53:18.000000000', 'files': ['sahara/openstack/common/_i18n.py', 'sahara/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/de98be864d58f58677a8cf5ded60965cb3274cf4', 'message': 'Update oslo-incubator lockutils\n\nChanges -\n * Allow tempest to use new log w/o oslo.i18n\n * Switch fileutils to use python logging\n * Fix i18n import\n * Remove code that moved to oslo.i18n\n * Switch oslo-incubator to use oslo.utils and remove old modules\n\nChange-Id: I1b0d3c376d0c861ff3ea4199312b4fa9e3fbda4e\n'}]",2,139147,de98be864d58f58677a8cf5ded60965cb3274cf4,19,5,3,7555,,,0,"Update oslo-incubator lockutils

Changes -
 * Allow tempest to use new log w/o oslo.i18n
 * Switch fileutils to use python logging
 * Fix i18n import
 * Remove code that moved to oslo.i18n
 * Switch oslo-incubator to use oslo.utils and remove old modules

Change-Id: I1b0d3c376d0c861ff3ea4199312b4fa9e3fbda4e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/47/139147/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/openstack/common/_i18n.py', 'sahara/openstack/common/fileutils.py']",2,ac9cc584f7bdba224e707f6ff58af97c0bd63ef7,,import logging,from sahara.openstack.common import log as logging ,25,21
openstack%2Fpython-saharaclient~master~I4ec828b0b709669e2eec25c05423f9d6c3442acd,openstack/python-saharaclient,master,I4ec828b0b709669e2eec25c05423f9d6c3442acd,Updated from global requirements,MERGED,2014-12-11 07:20:16.000000000,2014-12-11 14:27:38.000000000,2014-12-11 14:27:37.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-12-11 07:20:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/09f33b180f830e171e4b9b11936c78bbe2e07b4d', 'message': 'Updated from global requirements\n\nChange-Id: I4ec828b0b709669e2eec25c05423f9d6c3442acd\n'}]",0,140959,09f33b180f830e171e4b9b11936c78bbe2e07b4d,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I4ec828b0b709669e2eec25c05423f9d6c3442acd
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/59/140959/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,09f33b180f830e171e4b9b11936c78bbe2e07b4d,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fgnocchi~master~I58644e17ba7a9bf32ca9ae246ff1ccac3b7ee906,openstack/gnocchi,master,I58644e17ba7a9bf32ca9ae246ff1ccac3b7ee906,rest: add policy to list all resource,MERGED,2014-12-10 10:03:17.000000000,2014-12-11 14:22:37.000000000,2014-12-11 14:22:36.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-10 10:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b736654c1634a0f6a48c99d5fb259311ce6020d7', 'message': 'rest: add policy to list all resource\n\nThis limits the scope of resource listing to the authenticated\nuser/project and allows to retrieve all the resources using a special\npolicy.\n\nChange-Id: I58644e17ba7a9bf32ca9ae246ff1ccac3b7ee906\n'}, {'number': 2, 'created': '2014-12-10 10:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/efd90000c38f06cce0ca44968988b9f9b3eae2c7', 'message': 'rest: add policy to list all resource\n\nThis limits the scope of resource listing to the authenticated\nuser/project and allows to retrieve all the resources using a special\npolicy.\n\nChange-Id: I58644e17ba7a9bf32ca9ae246ff1ccac3b7ee906\n'}, {'number': 3, 'created': '2014-12-11 13:43:33.000000000', 'files': ['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8a0e241593f54a673b2903fbc08c59c40eb95d0a', 'message': 'rest: add policy to list all resource\n\nThis limits the scope of resource listing to the authenticated\nuser/project and allows to retrieve all the resources using a special\npolicy.\n\nChange-Id: I58644e17ba7a9bf32ca9ae246ff1ccac3b7ee906\n'}]",0,140626,8a0e241593f54a673b2903fbc08c59c40eb95d0a,12,2,3,1669,,,0,"rest: add policy to list all resource

This limits the scope of resource listing to the authenticated
user/project and allows to retrieve all the resources using a special
policy.

Change-Id: I58644e17ba7a9bf32ca9ae246ff1ccac3b7ee906
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/26/140626/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py']",3,b736654c1634a0f6a48c99d5fb259311ce6020d7,jd/policy," class GenericResourceTest(RestTest): def test_list_resources_tied_to_user(self): resource_id = str(uuid.uuid4()) self.app.post_json( ""/v1/resource/generic"", params={ ""id"": resource_id, ""started_at"": ""2014-01-01 02:02:02"", ""user_id"": str(uuid.uuid4()), ""project_id"": str(uuid.uuid4()), }) with self.app.use_another_user(): result = self.app.get(""/v1/resource/generic"") resources = json.loads(result.text) for resource in resources: if resource['id'] == resource_id: self.fail(""Resource found"") ",,33,3
openstack%2Fgnocchi~master~If6620bc62fd4e38a7e01a067dfe9412119001b46,openstack/gnocchi,master,If6620bc62fd4e38a7e01a067dfe9412119001b46,rest: add policy for resources,MERGED,2014-12-10 10:03:17.000000000,2014-12-11 14:19:42.000000000,2014-12-11 14:19:42.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-10 10:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b8fcc4bb94b2429f48d3720710c67d721fd20e26', 'message': 'rest: add policy for resources\n\nChange-Id: If6620bc62fd4e38a7e01a067dfe9412119001b46\n'}, {'number': 2, 'created': '2014-12-10 10:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0d77955ea6669b7cf63ce4c7daf45876f2bdd781', 'message': 'rest: add policy for resources\n\nChange-Id: If6620bc62fd4e38a7e01a067dfe9412119001b46\n'}, {'number': 3, 'created': '2014-12-11 13:43:33.000000000', 'files': ['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/156c85ccc3a6c9960f4f5ed5b75aff7b2ee1b70b', 'message': 'rest: add policy for resources\n\nChange-Id: If6620bc62fd4e38a7e01a067dfe9412119001b46\n'}]",1,140625,156c85ccc3a6c9960f4f5ed5b75aff7b2ee1b70b,14,2,3,1669,,,0,"rest: add policy for resources

Change-Id: If6620bc62fd4e38a7e01a067dfe9412119001b46
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/25/140625/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py']",3,b8fcc4bb94b2429f48d3720710c67d721fd20e26,jd/policy," def test_get_resource_unauthorized(self): self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes, status=201) with self.app.use_another_user(): self.app.get(""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id'], status=403) def test_patch_resource_attributes_unauthorized(self): self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes, status=201) with self.app.use_another_user(): self.app.patch_json( ""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id'], params=self.patchable_attributes, status=403) def test_delete_resource_unauthoeized(self): self.app.post_json(""/v1/resource/"" + self.resource_type, params=self.attributes) with self.app.use_another_user(): self.app.delete(""/v1/resource/"" + self.resource_type + ""/"" + self.attributes['id'], status=403) ",,58,0
openstack%2Ffuel-main~master~Id804ff9358d56446fbec4c30f8bab498433c9734,openstack/fuel-main,master,Id804ff9358d56446fbec4c30f8bab498433c9734,Fix wrong script path in rollback tests,MERGED,2014-12-11 12:40:45.000000000,2014-12-11 14:18:47.000000000,2014-12-11 13:11:51.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-12-11 12:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/45b7494c32c6ef810431eccfcd1a7100b2baee41', 'message': 'Fix wrong script path in rollback tests\n\nSome time ago upgrade script was moved\nto other folder.\n\nCloses-Bug:#1401511\n\nChange-Id: Id804ff9358d56446fbec4c30f8bab498433c9734\n'}, {'number': 2, 'created': '2014-12-11 12:42:03.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b9d3597a4b5e2a17937e8f44365fbed2aa4c25a9', 'message': 'Fix wrong script path in rollback tests\n\nSome time ago engines were moved to other folder.\n\nCloses-Bug:#1401511\n\nChange-Id: Id804ff9358d56446fbec4c30f8bab498433c9734\n'}]",0,141035,b9d3597a4b5e2a17937e8f44365fbed2aa4c25a9,14,4,2,8882,,,0,"Fix wrong script path in rollback tests

Some time ago engines were moved to other folder.

Closes-Bug:#1401511

Change-Id: Id804ff9358d56446fbec4c30f8bab498433c9734
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/35/141035/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,45b7494c32c6ef810431eccfcd1a7100b2baee41,(detached, '/var/upgrade/.fuel-upgrade-venv/lib/' 'python2.6/site-packages/' '/var/upgrade/.fuel-upgrade-venv/lib/' 'python2.6/site-packages/', '/var/upgrade/site-packages/' '/var/upgrade/site-packages/',4,2
openstack%2Fcinder~master~I964852f08b500400a27bff99e5200386e00643c9,openstack/cinder,master,I964852f08b500400a27bff99e5200386e00643c9,Add support in Cinder for volume replication - driver approach,MERGED,2014-08-09 02:28:47.000000000,2014-12-11 14:14:19.000000000,2014-08-24 07:46:29.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4418}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8587}, {'_account_id': 8871}, {'_account_id': 9751}, {'_account_id': 11036}, {'_account_id': 11047}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12780}, {'_account_id': 14296}]","[{'number': 1, 'created': '2014-08-09 02:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f9c856428b545fd2788e53c88522c739e086924', 'message': 'Add support in Cinder for volume replication\n\nProvide support in Cinder to manage volume replication.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 2, 'created': '2014-08-09 02:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3dcd79e2e1bf35be307a5df0f7d79bff60deb222', 'message': 'Add support in Cinder for volume replication - driver approach\n\nProvide support in Cinder to manage volume replication.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 3, 'created': '2014-08-09 07:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/94a1d89b990b9c8a73f9da46309f5e8d2758f24b', 'message': 'Add support in Cinder for volume replication - driver approach\n\nProvide support in Cinder to manage volume replication.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 4, 'created': '2014-08-10 14:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/675f5d510c8937010ec319fbf00f48479e475d86', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 5, 'created': '2014-08-11 05:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5eb9af8c0174573c5caedd96af16f046bba26682', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 6, 'created': '2014-08-11 09:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3cc29935e2b2f4f09bf442959dabdd3b6e07e706', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 7, 'created': '2014-08-11 11:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0afcc8b04fc556f28b93fa8c7db0acb38567d241', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegated most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver expose replication capabilities via volume type convention.\n2. Extend volume table to include columns to suppor replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at (to be created)\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 8, 'created': '2014-08-17 16:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d0902fe2f9a36e2ef193e0534ac900b3b977c617', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 9, 'created': '2014-08-18 12:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/811a3b29829736364e722fc207b5779ef0525ce4', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 10, 'created': '2014-08-18 13:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e1e289c890f18e05aeb8f09f7bdfeb2644efe59c', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 11, 'created': '2014-08-18 18:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f449c436cc7f1b1fb5f19b1be64096eff03b0dce', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 12, 'created': '2014-08-18 19:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cea5289db2b9946ea6b2d5a172428afb942462cd', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 13, 'created': '2014-08-20 04:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6876b4559f99256599b5442c8c641f42198d860', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 14, 'created': '2014-08-20 15:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7a2797b577660c8f4269437ac67c42071be53258', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 15, 'created': '2014-08-20 17:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/07b4d6dcd3f1a4e94e97571c763679f801eb912a', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 16, 'created': '2014-08-21 12:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0741731b771ff7ff5a8319247e3f4d6f2adb35c6', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 17, 'created': '2014-08-21 14:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4464026b938e493585688d70b98cc10a54391cf', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 18, 'created': '2014-08-22 17:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2604c252fe68189e0a2c2a4d2c011c1b05ed6c2', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 19, 'created': '2014-08-22 20:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/17cdeb2102ed2f771dfce5f6601677ba3aebaffc', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they wil now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 20, 'created': '2014-08-22 20:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/104fd6634e50969f5e324192e6916eeb5eb516b5', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they will now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}, {'number': 21, 'created': '2014-08-23 15:53:55.000000000', 'files': ['cinder/api/v2/views/volumes.py', 'cinder/tests/test_replication.py', 'cinder/volume/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/flows/api/create_volume.py', 'etc/cinder/policy.json', 'cinder/tests/test_create_volume_flow.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_rpcapi.py', 'cinder/tests/api/v2/stubs.py', 'cinder/api/v2/volumes.py', 'cinder/db/sqlalchemy/migrate_repo/versions/024_add_replication_support.py', 'cinder/exception.py', 'cinder/tests/test_migrations.py', 'cinder/tests/utils.py', 'cinder/tests/policy.json', 'cinder/common/config.py', 'cinder/tests/api/v2/test_volumes.py', 'cinder/volume/utils.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/driver.py', 'cinder/replication/api.py', 'cinder/api/contrib/volume_replication.py', 'cinder/replication/__init__.py', 'cinder/volume/rpcapi.py', 'cinder/tests/api/contrib/test_admin_actions.py', 'cinder/tests/api/contrib/test_volume_replication.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1c8f49bfe9fe3abd713e28922d5551f71228624c', 'message': 'Add support in Cinder for volume replication - driver approach\n\nThis is take #2 for managing replicaiton in Cinder.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nIn this version Cinder delegates most the work on replication\nto the driver itself.\n\nThis includes:\n1. Driver exposes replication capabilities via volume type convention.\n2. Extend volume table to include columns to support replicaion.\n3. Create replicas in the driver, making it transparant to Cinder.\n4. Volume manager code to handle API, updates to create_volume to\n   support creating test replicas.\n5. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nVolume replication use-case: Simplified disaster recovery\nThe OpenStack cloud is deployed across two metro distance data centers.\nStorage backends are available in both data ceneters. The backends\nare managed by either a single Cinder host or two, depending on the\nstorage backend requirements.\nStorage admin configures the Cinder volume driver to support\nreplication.\nCloud admin creates a volume type ""replicated"" with extra-specs:\n   capabilities:replication=""<is> True""\nEvery volume created in type ""replicated"" has a copy on both\nbackends.\nIn case of data center failure in first data center, the cloud admin\npromotes the replica, and redeploy the VMs - they will now run on\na host in the secondary data center using the storage on the\nsecondary data center.\n\nImplements: blueprint volume-replication\nDocImpact\n\nChange-Id: I964852f08b500400a27bff99e5200386e00643c9\n'}]",56,113054,1c8f49bfe9fe3abd713e28922d5551f71228624c,145,21,21,4418,,,0,"Add support in Cinder for volume replication - driver approach

This is take #2 for managing replicaiton in Cinder.

This patch provides the foundation in Cinder to make volume
replication available to the cloud admin. It makes Cinder aware
of volume replicas, and allows the cloud admin to define storage
policies (volume types) that will enable replication.

In this version Cinder delegates most the work on replication
to the driver itself.

This includes:
1. Driver exposes replication capabilities via volume type convention.
2. Extend volume table to include columns to support replicaion.
3. Create replicas in the driver, making it transparant to Cinder.
4. Volume manager code to handle API, updates to create_volume to
   support creating test replicas.
5. Driver methods to expose per replication functions

Cinder-specs available at https://review.openstack.org/#/c/98308/

Volume replication use-case: Simplified disaster recovery
The OpenStack cloud is deployed across two metro distance data centers.
Storage backends are available in both data ceneters. The backends
are managed by either a single Cinder host or two, depending on the
storage backend requirements.
Storage admin configures the Cinder volume driver to support
replication.
Cloud admin creates a volume type ""replicated"" with extra-specs:
   capabilities:replication=""<is> True""
Every volume created in type ""replicated"" has a copy on both
backends.
In case of data center failure in first data center, the cloud admin
promotes the replica, and redeploy the VMs - they will now run on
a host in the secondary data center using the storage on the
secondary data center.

Implements: blueprint volume-replication
DocImpact

Change-Id: I964852f08b500400a27bff99e5200386e00643c9
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/113054/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/tests/test_replication.py', 'cinder/volume/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/flows/api/create_volume.py', 'etc/cinder/policy.json', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_rpcapi.py', 'cinder/api/v2/volumes.py', 'cinder/db/sqlalchemy/migrate_repo/versions/024_add_replication_support.py', 'cinder/exception.py', 'cinder/tests/db/test_replication.py', 'cinder/tests/test_migrations.py', 'cinder/tests/utils.py', 'cinder/scheduler/driver.py', 'cinder/tests/policy.json', 'cinder/common/config.py', 'cinder/tests/scheduler/fakes.py', 'cinder/volume/utils.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/driver.py', 'cinder/replication/api.py', 'cinder/tests/scheduler/test_filter_scheduler.py', 'cinder/api/contrib/volume_replication.py', 'cinder/replication/__init__.py', 'cinder/volume/rpcapi.py', 'cinder/tests/api/contrib/test_volume_replication.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py']",30,0f9c856428b545fd2788e53c88522c739e086924,bp/volume-replication," scheduler_hints=None, backup_source_volume=None, source_replica=None): # When cloning replica, volume type must be omitted if source_replica and volume_type: msg = _(""Invalid volume_type provided (when creating test "" ""replicas type must be omitted). "" ""You should omit the argument."") raise exception.InvalidInput(reason=msg) 'source_replica': source_replica, filters['no_secondary_replicas'] = True if volume['status'].startswith('replica_'): # Can't snapshot secondary replica msg = _(""Snapshot of secondary replica is not allowed."") raise exception.InvalidVolume(reason=msg) # We only handle non-replicated volumes for now try: rel = self.db.replication_relationship_get_by_volume_id( context, volume['id']) except exception.VolReplicationRelationshipNotFound: rel = None if rel: msg = _(""Volume must not be replicated."") LOG.error(msg) raise exception.InvalidVolume(reason=msg) "," scheduler_hints=None, backup_source_volume=None):",2091,53
openstack%2Fheat~master~I45604648e3078f8ec6ba8b87a1c08eb6fca790ae,openstack/heat,master,I45604648e3078f8ec6ba8b87a1c08eb6fca790ae,Handle error with non existing template file,MERGED,2014-12-09 12:22:19.000000000,2014-12-11 14:11:42.000000000,2014-12-11 14:11:41.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 12:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9339b8a38c581f5f73890857734b439a5bb115f2', 'message': ""Handle error with non existing template file\n\nThis patch allows to propagate IOError instead of returning\nTemplateResource which does not contain property_schema.\nIt's the second attempt to adopt fix introduced here:\nIb1e09de8c10672312eea09f62a28f0885d98b089.\n\nChange-Id: I45604648e3078f8ec6ba8b87a1c08eb6fca790ae\nCloses-Bug: #1394552\n""}, {'number': 2, 'created': '2014-12-09 15:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b266da951a8cfa888bfc2face93975731956bb3', 'message': ""Handle error with non existing template file\n\nThis patch allows to propagate IOError instead of returning\nTemplateResource which does not contain property_schema.\nIt's the second attempt to adopt fix introduced here:\nIb1e09de8c10672312eea09f62a28f0885d98b089.\n\nChange-Id: I45604648e3078f8ec6ba8b87a1c08eb6fca790ae\nCloses-Bug: #1394552\n""}, {'number': 3, 'created': '2014-12-09 15:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/af6109596f1fc07c8e5f0f6f81d802330d142b40', 'message': ""Handle error with non existing template file\n\nThis patch allows to propagate IOError instead of returning\nTemplateResource which does not contain property_schema.\nIt's the second attempt to adopt fix introduced here:\nIb1e09de8c10672312eea09f62a28f0885d98b089.\n\nChange-Id: I45604648e3078f8ec6ba8b87a1c08eb6fca790ae\nCloses-Bug: #1394552\n""}, {'number': 4, 'created': '2014-12-10 07:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b1bff85f0e12aa7b6ba364402ed20d03b0dfdb7', 'message': ""Handle error with non existing template file\n\nThis patch allows to propagate IOError instead of returning\nTemplateResource which does not contain property_schema.\nIt's the second attempt to adopt fix introduced here:\nIb1e09de8c10672312eea09f62a28f0885d98b089.\n\nChange-Id: I45604648e3078f8ec6ba8b87a1c08eb6fca790ae\nCloses-Bug: #1394552\n""}, {'number': 5, 'created': '2014-12-10 09:50:31.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/resources/resource_group.py', 'heat/tests/test_provider_template.py', 'heat/engine/resources/template_resource.py', 'heat/engine/service.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a2a41b585b5aebaeedac5dcc5604686b7eec4ce0', 'message': ""Handle error with non existing template file\n\nThis patch allows to propagate IOError instead of returning\nTemplateResource which does not contain property_schema.\nIt's the second attempt to adopt fix introduced here:\nIb1e09de8c10672312eea09f62a28f0885d98b089.\n\nChange-Id: I45604648e3078f8ec6ba8b87a1c08eb6fca790ae\nCloses-Bug: #1394552\n""}]",0,140315,a2a41b585b5aebaeedac5dcc5604686b7eec4ce0,25,6,5,6577,,,0,"Handle error with non existing template file

This patch allows to propagate IOError instead of returning
TemplateResource which does not contain property_schema.
It's the second attempt to adopt fix introduced here:
Ib1e09de8c10672312eea09f62a28f0885d98b089.

Change-Id: I45604648e3078f8ec6ba8b87a1c08eb6fca790ae
Closes-Bug: #1394552
",git fetch https://review.opendev.org/openstack/heat refs/changes/15/140315/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/test_provider_template.py', 'heat/engine/resources/template_resource.py', 'heat/engine/resource.py', 'heat/engine/service.py']",5,9339b8a38c581f5f73890857734b439a5bb115f2,bug/1394552, except exception.NotFound as ex: raise exception.StackValidationFailed(message=ex.message) except exception.NotFound as ex: raise exception.StackValidationFailed(message=ex.message),,43,12
openstack%2Fnova~master~I50eb07a84336160b8120ca294598576eeb982d28,openstack/nova,master,I50eb07a84336160b8120ca294598576eeb982d28,Add shelve and unshelve info into devref doc,MERGED,2014-11-20 06:07:37.000000000,2014-12-11 14:11:13.000000000,2014-12-11 14:11:09.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-20 06:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c244f85a0f8d6ae808ed438da992fb9edae88325', 'message': 'Add shelve and unshelve info into devref doc\n\nThe diagram on http://docs.openstack.org/developer/nova/devref/vmstates.html\ndoes not currently show the ""SHELVED_OFFLOADED"" state and the\nassociated ""shelve"", ""shelveOffload"" and ""unshelve"" state transitions.\n\nChange-Id: I50eb07a84336160b8120ca294598576eeb982d28\nCloses-Bug: #1394215\n'}, {'number': 2, 'created': '2014-12-05 16:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b292d4ea0bd37e1b2429a94f823f01fdc0f7685', 'message': 'Add shelve and unshelve info into devref doc\n\nThe diagram on http://docs.openstack.org/developer/nova/devref/vmstates.html\ndoes not currently show the ""SHELVED_OFFLOADED"" state and the\nassociated ""shelve"", ""shelveOffload"" and ""unshelve"" state transitions.\n\nChange-Id: I50eb07a84336160b8120ca294598576eeb982d28\nCloses-Bug: #1394215\n'}, {'number': 3, 'created': '2014-12-06 15:03:09.000000000', 'files': ['doc/source/devref/vmstates.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/da10530b7bc6419b99ea806378e973f0a697f0f8', 'message': 'Add shelve and unshelve info into devref doc\n\nThe diagram on http://docs.openstack.org/developer/nova/devref/vmstates.html\ndoes not currently show the ""SHELVED_OFFLOADED"" state and the\nassociated ""shelve"", ""shelveOffload"" and ""unshelve"" state transitions.\n\nChange-Id: I50eb07a84336160b8120ca294598576eeb982d28\nCloses-Bug: #1394215\n'}]",4,135851,da10530b7bc6419b99ea806378e973f0a697f0f8,36,9,3,6062,,,0,"Add shelve and unshelve info into devref doc

The diagram on http://docs.openstack.org/developer/nova/devref/vmstates.html
does not currently show the ""SHELVED_OFFLOADED"" state and the
associated ""shelve"", ""shelveOffload"" and ""unshelve"" state transitions.

Change-Id: I50eb07a84336160b8120ca294598576eeb982d28
Closes-Bug: #1394215
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/135851/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/vmstates.rst'],1,c244f85a0f8d6ae808ed438da992fb9edae88325,bug/1394215," shelved [label=""SHELVED""] shelved_offloaded [label=""SHELVED_OFFLOADED""] shelve [shape=""rectangle""] shelve -> shelved shelve -> shelved_offloaded shelve -> error active -> shelve stopped -> shelve paused -> shelve suspended -> shelve shelve_offload [shape=""rectangle""] shelve_offload -> shelved_offloaded shelved_offload -> error shelved -> shelve_offload unshelve [shape=""rectangle""] unselve -> active unshelve -> error shelved -> unshelve shelved_offloaded -> unshelve",,22,0
openstack%2Fsahara-specs~master~Ib07e667e019c0002fe11ac1889751844e7435bd6,openstack/sahara-specs,master,Ib07e667e019c0002fe11ac1889751844e7435bd6,[EDP] Add options supporting DataSource identifiers in job_configs,MERGED,2014-12-03 18:09:09.000000000,2014-12-11 14:06:17.000000000,2014-12-11 14:06:16.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-03 18:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/613a69efe4e699ae36ada3632e036811e26c7f2e', 'message': '[EDP] Add an option supporting data_source names as job execution args\n\nGeneral job types (Java and Spark) do not require data sources since they have\nno fixed arg list (this differs from traditional map reduce jobs, for example,\nwhich require input and output parameters). However, it would be\nconvenient if users had a way to pass a data_source object as an argument to\ntake advantage of the data codified in the data source object.\n\nblueprint edp-data-source-name-args\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 2, 'created': '2014-12-03 18:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/816f083ece425b34fcfe4c5243e0aef36e2b5909', 'message': '[EDP] Add an option supporting data_source names as job execution args\n\nGeneral job types (Java and Spark) do not require data sources since they have\nno fixed arg list (this differs from traditional map reduce jobs, for example,\nwhich require input and output parameters). However, it would be\nconvenient if users had a way to pass a data_source object as an argument to\ntake advantage of the data codified in the data source object.\n\nblueprint edp-data-source-name-args\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 3, 'created': '2014-12-03 18:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/6f6700a41e7eeb0bab7178f6abaf64cdba5bd227', 'message': '[EDP] Add an option supporting data_source names as job execution args\n\nGeneral job types (Java and Spark) do not require data sources since they have\nno fixed arg list (this differs from traditional map reduce jobs, for example,\nwhich require input and output parameters). However, it would be\nconvenient if users had a way to pass a data_source object as an argument to\ntake advantage of the data codified in the data source object.\n\nblueprint edp-data-source-name-args\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 4, 'created': '2014-12-03 18:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/7bf1e2023aef1bf6f7173d80a95c93239c62f893', 'message': '[EDP] Add an option supporting data_source names as job execution args\n\nGeneral job types (Java and Spark) do not require data sources since they have\nno fixed arg list (this differs from traditional map reduce jobs, for example,\nwhich require input and output parameters). However, it would be\nconvenient if users had a way to pass a data_source object as an argument to\ntake advantage of the data codified in the data source object.\n\nblueprint edp-data-source-name-args\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 5, 'created': '2014-12-03 19:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/c7f1a76f8f45e48c757306ef7690743ca520562f', 'message': '[EDP] Add an option supporting data_source names as job execution args\n\nGeneral job types (Java and Spark) do not require data sources since they have\nno fixed arg list (this differs from traditional map reduce jobs, for example,\nwhich require input and output parameters). However, it would be\nconvenient if users had a way to pass a data_source object as an argument to\ntake advantage of the data codified in the data source object.\n\nblueprint edp-data-source-name-args\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 6, 'created': '2014-12-04 19:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/680fcf993d92f394be18b2cff5e4f823ea176a8c', 'message': '[EDP] Add options supporting DataSource identifiers in job_configs\n\nIn some cases it would be convenient if users had a way to pass a DataSource\nobject as a job configuration value to take advantage of the data codified in\nthe object instead of copying and specifying that information manually.  This\nspecification describes options that allow users to reference DataSource\nobjects in configuration values, parameters, and arguments in a JobExecution\nrecord.\n\nblueprint edp-data-source-name-args\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 7, 'created': '2014-12-04 19:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/c9a8dd20b3ba4f1b116ed383b0fcb69fa3420284', 'message': '[EDP] Add options supporting DataSource identifiers in job_configs\n\nIn some cases it would be convenient if users had a way to pass a DataSource\nobject as a job configuration value to take advantage of the data codified in\nthe object instead of copying and specifying that information manually.  This\nspecification describes options that allow users to reference DataSource\nobjects in configuration values, parameters, and arguments in a JobExecution\nrecord.\n\nblueprint edp-data-sources-in-job-configs\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}, {'number': 8, 'created': '2014-12-05 14:57:41.000000000', 'files': ['specs/kilo/edp-data-sources-in-job-configs.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/6c831901795c7236c4bac155b174f423005963d6', 'message': '[EDP] Add options supporting DataSource identifiers in job_configs\n\nIn some cases it would be convenient if users had a way to pass a DataSource\nobject as a job configuration value to take advantage of the data codified in\nthe object instead of copying and specifying that information manually.  This\nspecification describes options that allow users to reference DataSource\nobjects in configuration values, parameters, and arguments in a JobExecution\nrecord.\n\nblueprint edp-data-sources-in-job-configs\n\nChange-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6\n'}]",5,138809,6c831901795c7236c4bac155b174f423005963d6,32,7,8,8091,,,0,"[EDP] Add options supporting DataSource identifiers in job_configs

In some cases it would be convenient if users had a way to pass a DataSource
object as a job configuration value to take advantage of the data codified in
the object instead of copying and specifying that information manually.  This
specification describes options that allow users to reference DataSource
objects in configuration values, parameters, and arguments in a JobExecution
record.

blueprint edp-data-sources-in-job-configs

Change-Id: Ib07e667e019c0002fe11ac1889751844e7435bd6
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/09/138809/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/edp-data-source-name-args.rst'],1,613a69efe4e699ae36ada3632e036811e26c7f2e,bp/edp-data-sources-in-job-configs,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================================== [EDP] Add an option supporting data_source names as job execution args ====================================================================== https://blueprints.launchpad.net/sahara/+spec/edp-data-source-name-args General job types (Java and Spark) do not require data sources since they have no fixed arg list (this differs from traditional map reduce jobs, for example, which require input and output parameters). However, it would be convenient if users had a way to pass a data_source object as an argument to take advantage of the data codified in the data source object. Problem description =================== Most job types require input and output data_source objects. The data_source object ids are passed as part of a job execution request and Sahara configures the job based on the information in the objects. This works well for the contrained job types supported by Oozie/hadoop (mapreduce, pig, hive, etc) where there are mechanisms for passing the values to the job (config parameters for mapreduce and key/value pairs for pig and hive). The Java and Spark job types however are general and do not have any fixed argument list or convention for specifying input/output sources. If an application uses IO paths, they are passed as arguments and the order is dictated by the application. Therefore, there is no standard action for Sahara to take and data_source objects are not required. Consequently, users cannot make use of data_source objects when running Java or Spark jobs. Paths and authentication values must be specified manually, even if data_source objects exist which reference the desired locations. Sahara should provide a mechanism so that users can effectively use data_source objects as arguments to Java and Spark jobs. Proposed change =============== Add an optional boolean config value on a job_execution that instructs Sahara to treat all arguments as the potential name of a data_source object. If a data_source can be identified by name, Sahara will replace the argument with the path information from the data_source object and update authentication configuration values as necessary. If an arugment does not name a data_source, the argument will be left alone. The default for the config value will be False. This option will initially be supported for Java and Spark job types. It could potentially be used with hive and pig jobs as well since these job types can actually take multiple IO paths specified as parameters (but this should be revisited). It doesn't make sense for mapreduce in any way. This change will be usable from all interfaces: client, CLI, and UI. The UI may choose to wrap the feature in some way but it is not required. A user could simply specify the config value and the data_source names on the job execution configuration panel. Alternatives ------------ A slightly diferent approach could be taken where data_source object names are identified syntactically, for example by a leading '*' character. This could eliminate the need for a config value to turn the feature on, and allow individual args to be looked up rather than all arguments. However, it presents problems for literal values starting with a sentinel value. What if someone wanted to pass '*input' as a literal argument to an application? Using the optional config makes it simple to turn the feature on and off, and the user may choose to use it or not. If an argument happens to be the name of a data_source object, and the argument is meant as a literal, the user will not enable the feature. Data model impact ----------------- None REST API impact --------------- None Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- None Sahara-image-elements impact ---------------------------- None Sahara-dashboard / Horizon impact --------------------------------- None required. However, I can imagine that the UI might benefit from some simple tooling around this feature, like a checkbox to enable the feature on a Spark or Java job submission panel. Implementation ============== Assignee(s) ----------- Primary assignee: <tmckay> Other contributors: <croberts> Work Items ---------- * Support in Sahara * Document * Support in the UI (optional, it will work without additional work) Dependencies ============ Testing ======= Unit tests Documentation Impact ==================== We will need to document this in the sections covering submission of jobs to Sahara References ========== ",,155,0
openstack%2Fanchor~master~If41df58de094a8cee586285255663cf4fa1a61df,openstack/anchor,master,If41df58de094a8cee586285255663cf4fa1a61df,Improves documentation for test/dev configuration.,MERGED,2014-12-10 14:29:37.000000000,2014-12-11 13:59:56.000000000,2014-12-11 13:59:56.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-12-10 14:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/baab1caa3323c94fd38f62f5a85d43bc1df96fee', 'message': ""Improves documentation for test/dev configuration.\n\nExpands README.md to cover installation of forked M2Crypto, removes\nm2crypto install from setup.py to prevent inadvertant installation\nof wrong version. Adds documentation describing generation of CA\ncertificate and private key for testing, generation of valid test\ncertificate. Reformats README.md to pep8 requirements. Removes\n'clark.com' as valid domain in config.py and adds 'anchor.test'\n\nChange-Id: If41df58de094a8cee586285255663cf4fa1a61df\nCloses-Bug: 1398804\n""}, {'number': 2, 'created': '2014-12-10 14:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/d3ef0464a3ca546af5cb7bf050d1ba3593982fd8', 'message': ""Improves documentation for test/dev configuration.\n\nExpands README.md to cover installation of forked M2Crypto, removes\nm2crypto install from setup.py to prevent inadvertant installation\nof wrong version. Adds documentation describing generation of CA\ncertificate and private key for testing, generation of valid test\ncertificate. Reformats README.md to pep8 requirements. Removes\n'clark.com' as valid domain in config.py and adds 'anchor.test'\n\nChange-Id: If41df58de094a8cee586285255663cf4fa1a61df\nCloses-Bug: 1398804\n""}, {'number': 3, 'created': '2014-12-11 13:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/b2c2ee9793d740d6c5b25a2c9d77e0fc7083956e', 'message': ""Improves documentation for test/dev configuration.\n\nExpands README.md to cover installation of forked M2Crypto, removes\nm2crypto install from setup.py to prevent inadvertant installation\nof wrong version. Adds documentation describing generation of CA\ncertificate and private key for testing, generation of valid test\ncertificate. Reformats README.md to pep8 requirements. Removes\n'clark.com' as valid domain in config.py and adds 'anchor.test'\n\nChange-Id: If41df58de094a8cee586285255663cf4fa1a61df\nCloses-Bug: 1398804\n""}, {'number': 4, 'created': '2014-12-11 13:22:08.000000000', 'files': ['setup.py', 'config.py', 'README.md'], 'web_link': 'https://opendev.org/openstack/anchor/commit/ec69b9a51db7a3bb9c955c4442bfb0dac8605c40', 'message': ""Improves documentation for test/dev configuration.\n\nExpands README.md to cover installation of forked M2Crypto, removes\nm2crypto install from setup.py to prevent inadvertant installation\nof wrong version. Adds documentation describing generation of CA\ncertificate and private key for testing, generation of valid test\ncertificate. Reformats README.md to pep8 requirements. Removes\n'clark.com' as valid domain in config.py and adds 'anchor.test'\n\nChange-Id: If41df58de094a8cee586285255663cf4fa1a61df\nCloses-Bug: 1398804\n""}]",3,140693,ec69b9a51db7a3bb9c955c4442bfb0dac8605c40,17,4,4,11397,,,0,"Improves documentation for test/dev configuration.

Expands README.md to cover installation of forked M2Crypto, removes
m2crypto install from setup.py to prevent inadvertant installation
of wrong version. Adds documentation describing generation of CA
certificate and private key for testing, generation of valid test
certificate. Reformats README.md to pep8 requirements. Removes
'clark.com' as valid domain in config.py and adds 'anchor.test'

Change-Id: If41df58de094a8cee586285255663cf4fa1a61df
Closes-Bug: 1398804
",git fetch https://review.opendev.org/openstack/anchor refs/changes/93/140693/4 && git format-patch -1 --stdout FETCH_HEAD,"['config.py', 'setup.py', 'README.md']",3,baab1caa3323c94fd38f62f5a85d43bc1df96fee,bug/1398804,"Anchor is an ephemeral PKI service that, based on certain conditions, automates the verification of CSRs and signs certificates for clients. The validity period can be set in the config file with hour resolution. There are checks done against the certificate inside of the validate() function. Currently some of the checks are: is the domain in CN ending with one of the suffixes allowed n the config file and does the server prefix match the ldap user's team (for example is ""nv-..."" requested by a member of ""Nova\_Team"".This service requires either a python virtual environment and python/ssl/ldap/sasl development system packages, or system python-ldap, python-pecan packages.Currently Anchor requires a modified varient of M2Crypto, which must be installed manually. Prior to installing M2Crypto, SWIG must be installed if this is not already present on your system. Test with: swig If this results with 'command not found' or similar, then install swig by downloading from http://www.swig.org/download.html or using your preferred package manager. Download and install the modified M2crypto: git clone https://github.com/viraptor/M2Crypto.git cd M2Crypto python setup.py build && python setup.py install cd .. Depending on your platform, you may need to add a link between the location of your openssl libraries and the path used by swig: (/usr/include) To install a development version of Anchor, run:To install a production version with some authentication backend, run (where `auth_xxx` may be `auth_keystone` and/or `auth_ldap`):The chosen authentication backend is only enabled if it's defined in the config file. The config file should be copied from `config.py` with any details updated. Anchor requires you to provide a CA signing certificate and private key which is stored in the CA subdirectory by default (as specified in config.py). This can be generated using the certificate provider of your choice, or a test signing certificate can be generated using openssl: Create a private key: cd CA openssl genrsa -des3 -passout pass:x -out ca.p.key 2048 openssl rsa -passin pass:x -in ca.p.key -out root-ca-unwrapped.key Then create a CSR from that key, specify 'Test Anchor CA' or similar as the Common Name for the certificate: openssl req -new -key root-ca-unwrapped.key -out ca.csr openssl x509 -req -days 365 -in ca.csr \ -signkey root-ca-unwrapped.key -out root-ca.crt rm ca.p.key ca.csr And the debug option in `config.py` has to be turned off. Service can be started via the uwsgi server, for example (with 4 processes): uwsgi --http-socket :5000 --venv /path/to/the/virtualenv \ --pecan /path/to/config.py -p 4 To test the service, generate the certificate request using default values and submit it using curl (change the user and secret if you have changed them in config.py): openssl req -text -newkey rsa:384 -nodes \ -out some.name.hpcloud.net.csr curl http://0:5000/sign -F user='woot' -F secret='woot' \ -F encoding=pem -F 'csr=<some.name.hpcloud.net.csr' Assuming the installation is successful and the default config is unchanged, this will fail validation, but should not give a M2Crypto or other error. Now generate a valid csr that should pass validation and check that it is issued, by specifying a common name of 'valid.cert.anchor.test' when prompted: openssl req -text -newkey rsa:384 -nodes \ -out valid.cert.anchor.test.csr curl http://0:5000/sign -F user='woot' -F secret='woot' \ -F encoding=pem -F 'csr=<valid.cert.anchor.test' If Anchor is correctly configured, the CA will return a certificate. ","Anchor is an ephemeral PKI service that, based on certain conditions, automates the verification of CSRs and signs certificates for clients. The validity period can be set in the config file with hour resolution. There are checks done against the certificate inside of the validate() function. Currently some of the checks are: is the domain in CN ending with one of the suffixes allowed n the config file and does the server prefix match the ldap user's team (for example is ""nv-..."" requested by a member of ""Nova\_Team"".This service requires either a python virtual environment and python/ssl/ldap/sasl development system packages, or system python-ldap, python-pecan packages.To install a development version, run:To install a production version with some authentication backend, run (where `auth_xxx` may be `auth_keystone` and/or `auth_ldap`):The chosen authentication backend is only enabled if it's defined in the config file. The config file should be copied from `config.py` with any details updated.And the debug option in `config.py` has to be turned off. Service can be started via the uwsgi server, for example (with 4 processes): uwsgi --http-socket :5000 --venv /path/to/the/virtualenv --pecan /path/to/config.py -p 4 To test the service, generate the certificate request and submit it using curl: openssl req -text -newkey rsa:384 -nodes -out some.name.hpcloud.net.csr curl http://0:5000/sign -F user=sso_username -F secret=sso_password -F encoding=pem -F 'csr=<some.name.hpcloud.net.csr'",88,16
openstack%2Fcinder~master~Ibf1dc3472acf90a4929047fcdefc98dfa141a48a,openstack/cinder,master,Ibf1dc3472acf90a4929047fcdefc98dfa141a48a,Volume replication,ABANDONED,2013-12-25 13:20:45.000000000,2014-12-11 13:53:30.000000000,,"[{'_account_id': 3}, {'_account_id': 428}, {'_account_id': 1297}, {'_account_id': 2243}, {'_account_id': 2401}, {'_account_id': 2417}, {'_account_id': 4355}, {'_account_id': 4418}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 7689}, {'_account_id': 8587}, {'_account_id': 8649}, {'_account_id': 10677}, {'_account_id': 14296}]","[{'number': 1, 'created': '2013-12-25 13:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e1676469972174077e02604b97db0928f89ae3f6', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\nTODO: unit tests\n""}, {'number': 2, 'created': '2013-12-26 12:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ef94ee1bbb6088dd64dec13e3a90a0780599265', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\nTODO: finish writing unit tests\n""}, {'number': 3, 'created': '2013-12-29 14:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f4608ee0613ca414da7825c07955c8e6610e3cf2', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 4, 'created': '2013-12-30 12:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3bd5a4429aee3904645f6c20e4d03f580b0519f5', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 5, 'created': '2014-01-07 10:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c5a1df27d97fc0c12404623d6bacf24850c5ca98', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 6, 'created': '2014-01-14 11:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e0cb89a72f4854ab96dec2064ab79b6878599c7', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 7, 'created': '2014-01-14 15:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/52179fa002b46f897be9513ee772bc7e046c6b99', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 8, 'created': '2014-01-22 09:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb7204b28dd785cac7d7f0aa9ee82af40f4dfe2e', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 9, 'created': '2014-01-28 14:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/45b9b3acea76697a32c2d46c79111a6796fa1688', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 10, 'created': '2014-01-30 11:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e5c61474752dcf28a6364e88ec271f3a97e2a5ce', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy. This\n   will be submitted in a separate patch after retype is merged.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 11, 'created': '2014-02-02 19:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/796644b92b916899177a7a6ff2f94ea0322d7703', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 12, 'created': '2014-02-03 18:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d9d4aadb3a4d57be67e8361eb76cb17930ff365a', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 13, 'created': '2014-02-05 18:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d1390378c2d467b168d6c0aea6e8467be151cd0e', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 14, 'created': '2014-02-06 06:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0cdeebccb1d53bc87f9a504f9638065852ef1df2', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 15, 'created': '2014-02-06 11:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bcd4fb4552c181334c825ab21043ee18b14241ac', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 16, 'created': '2014-02-10 11:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f899a62ba278b65d18a3deced5ce67fa577976d5', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 17, 'created': '2014-02-17 08:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2cf81a9c0f53c354ddf2472c36a03e2800489bb3', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. This\n      entails two driver functions (create_replica and enable_replica),\n      and each driver is expected to implement any necessary function\n      for replication to work correctly (i.e., some drivers may not\n      need to implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica on the primary copy's manager and then\n   delete_replica on the second copy's manager.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 18, 'created': '2014-02-17 12:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a4bdd50c8afe9b8b41bb2d4490e7c8d3f046404d', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 19, 'created': '2014-02-24 17:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d2ad19817d9e14eb6743eefb202b30e7d758badd', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}, {'number': 20, 'created': '2014-02-28 07:13:01.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/tests/test_replication.py', 'cinder/volume/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_rpcapi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/023_add_replication_relationships.py', 'cinder/exception.py', 'cinder/tests/db/test_replication.py', 'cinder/tests/test_migrations.py', 'cinder/scheduler/driver.py', 'cinder/tests/policy.json', 'cinder/common/config.py', 'cinder/db/api.py', 'cinder/tests/scheduler/fakes.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/driver.py', 'cinder/replication/api.py', 'cinder/tests/scheduler/test_filter_scheduler.py', 'cinder/api/contrib/volume_replication.py', 'cinder/api/views/replications.py', 'cinder/replication/__init__.py', 'cinder/volume/rpcapi.py', 'cinder/tests/api/contrib/test_volume_replication.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5bd12b36a67842f3c7cb5a37ac9697e5afb57432', 'message': ""Volume replication\n\nThis allows Cinder to manage volume replication. Replication is\ntransparent to non-admin users, who enable replication by choosing a\nsuitable volume type.\n\nOverview:\n1. Drivers report replication capabilities\n2. In the DB, each copy is a separate Volume. The secondary copy is\n   hidden from non-admin users. There is a new replication relationship\n   table that defines a relationship between two volumes.\n3. create_volume:\n   1) The filter scheduler finds two suitable backends according to the\n      volume type's extra_specs.\n   2) The primary copy's manager will call the secondary copy's manager\n      to create a replica, and then it will enable the replica. Each\n      driver is expected to implement any necessary function for\n      replication to work correctly (i.e., some drivers may not need to\n      implement both).\n4. A periodic task calls the driver to check the status of each\n   replication relationship and update when necessary. Sends\n   notification if relationship goes into error state.\n5. delete_volume: If a replicated volume is being deleted, we first\n   call disable_replica and delete_replica.\n6. Admins can list and show replication relationships, and can swap\n   roles between the primary and secondary copies (usually in case\n   the primary went down).\n7. Bringing a degraded relationship (i.e., one working copy) back to\n   replicated involves the use of retype - the admin will change to a\n   non-replicated type which will cause the non-working copy to be\n   deleted, and back to replicated, which will create a new copy.\n\nDocImpact\n\nImplements: blueprint volume-mirroring\n\nChange-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a\n""}]",56,64026,5bd12b36a67842f3c7cb5a37ac9697e5afb57432,91,17,20,4355,,,0,"Volume replication

This allows Cinder to manage volume replication. Replication is
transparent to non-admin users, who enable replication by choosing a
suitable volume type.

Overview:
1. Drivers report replication capabilities
2. In the DB, each copy is a separate Volume. The secondary copy is
   hidden from non-admin users. There is a new replication relationship
   table that defines a relationship between two volumes.
3. create_volume:
   1) The filter scheduler finds two suitable backends according to the
      volume type's extra_specs.
   2) The primary copy's manager will call the secondary copy's manager
      to create a replica, and then it will enable the replica. Each
      driver is expected to implement any necessary function for
      replication to work correctly (i.e., some drivers may not need to
      implement both).
4. A periodic task calls the driver to check the status of each
   replication relationship and update when necessary. Sends
   notification if relationship goes into error state.
5. delete_volume: If a replicated volume is being deleted, we first
   call disable_replica and delete_replica.
6. Admins can list and show replication relationships, and can swap
   roles between the primary and secondary copies (usually in case
   the primary went down).
7. Bringing a degraded relationship (i.e., one working copy) back to
   replicated involves the use of retype - the admin will change to a
   non-replicated type which will cause the non-working copy to be
   deleted, and back to replicated, which will create a new copy.

DocImpact

Implements: blueprint volume-mirroring

Change-Id: Ibf1dc3472acf90a4929047fcdefc98dfa141a48a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/64026/12 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/volume/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/scheduler/driver.py', 'cinder/tests/policy.json', 'cinder/common/config.py', 'cinder/db/api.py', 'cinder/volume/flows/create_volume/__init__.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/driver.py', 'cinder/db/sqlalchemy/migrate_repo/versions/023_add_replication_relationships.py', 'cinder/replication/api.py', 'cinder/api/contrib/volume_replication.py', 'cinder/api/views/replications.py', 'cinder/replication/__init__.py', 'cinder/exception.py', 'cinder/volume/rpcapi.py', 'cinder/tests/test_migrations.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py']",20,e1676469972174077e02604b97db0928f89ae3f6,bp/ibm-storwize-volume-replication," filters['no_secondary_replicas'] = True def _check_secondary(volume, searchdict): if volume['status'].startswith('replica_'): return False return True 'no_migration_targets': _check_migration_target, 'no_secondary_replicas': _check_secondary} if volume['status'].startswith('replica_'): # Can't snapshot secondary replica msg = _(""Snapshot of secondary replica is not allowed."") raise exception.InvalidVolume(reason=msg) ", 'no_migration_targets': _check_migration_target},1061,18
openstack%2Fcinder~master~I012b53c3435112140d894c79fb61cae896a03ce5,openstack/cinder,master,I012b53c3435112140d894c79fb61cae896a03ce5,Add support in Cinder for volume replication,ABANDONED,2014-07-14 09:32:33.000000000,2014-12-11 13:52:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4418}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 6816}, {'_account_id': 7198}, {'_account_id': 8415}, {'_account_id': 8463}, {'_account_id': 8587}, {'_account_id': 8871}, {'_account_id': 8874}, {'_account_id': 10621}, {'_account_id': 10796}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 14296}]","[{'number': 1, 'created': '2014-07-14 09:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e1044d449b6f3681b75e6395dc24e870b69482e4', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nThis is a first work-in-progress to demonstrate the driver API\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 2, 'created': '2014-07-21 12:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d58381fca1a854bce7e9bddf20cb3549e80c3af', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nThis is work-in-progress.\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 3, 'created': '2014-07-25 10:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d3ab766abc69f3aac8339846552caa49ce091c9', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nThis is work-in-progress. Need to complete the unit tests.\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 4, 'created': '2014-07-25 12:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9369f2236ca95361390e9facf61a42441422e3a7', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nThis is work-in-progress. Need to complete the unit tests.\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 5, 'created': '2014-07-25 19:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4909b0d96464d3359fdf7e8b4aa20846d011d21a', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nThis is work-in-progress. Need to complete the unit tests.\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 6, 'created': '2014-07-26 14:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/94b724711b787cbe3fa2bffbc25cfb217a4beab5', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 7, 'created': '2014-07-26 17:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8401b4b13937ac65eed56cf93734099d06bd88ed', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 8, 'created': '2014-07-30 16:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/32e5096ed2d31e4172f5e2e92a1ef7c2e0a34b3a', 'message': 'Add support in Cinder for volume replication\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 9, 'created': '2014-08-02 04:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a78f95110972899d685a2fdf84c970b431f9478e', 'message': 'Add support in Cinder for volume replication\n\nProvide support in Cinder to manage volume replication.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nThe replication support in Cinder reduces the work and amount of\ncode needed by volume driver to enable replication in their\ndrivers, and make it easier in the future to implement cross\nback-end replication, as support is not driver specific.\n\nThis includes:\n1. Make volume driver expose replication capabilities\n2. Extend the Cinder db to add know-how about replicas\n3. Enable scheduler to select back-end for replica\n4. Create replicas through create-volume and volume re-type\n5. Common code in volume manager to handle API\n6. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\nDocImpact\n'}, {'number': 10, 'created': '2014-08-04 16:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a6f768fb9710278e3c71744e96f35733912adbd', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 11, 'created': '2014-08-04 18:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/631943fbd826307f08e56f6ccddf87b029f1d72c', 'message': 'Add support in Cinder for volume replication\n\nProvide support in Cinder to manage volume replication.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nThe replication support in Cinder reduces the work and amount of\ncode needed by volume driver to enable replication in their\ndrivers, and make it easier in the future to implement cross\nback-end replication, as support is not driver specific.\n\nThis includes:\n1. Make volume driver expose replication capabilities\n2. Extend the Cinder db to add know-how about replicas\n3. Enable scheduler to select back-end for replica\n4. Create replicas through create-volume and volume re-type\n5. Common code in volume manager to handle API\n6. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\nDocImpact\n'}, {'number': 12, 'created': '2014-08-05 02:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ca4f8f068c6634e67800a5e068b9d57a4206d4b', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 13, 'created': '2014-08-05 09:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8adadb73f9e8bc7d359b486134c552738153a03f', 'message': 'Add support in Cinder for volume replication.\n\nProvide support in Cinder to manage volume replication.\nThe actual implementation of the replication mechanism is up\nto the backend driver.\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\n'}, {'number': 14, 'created': '2014-08-06 07:08:39.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/tests/test_replication.py', 'cinder/volume/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/flows/api/create_volume.py', 'etc/cinder/policy.json', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_rpcapi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/024_add_replication_relationships.py', 'cinder/exception.py', 'cinder/tests/db/test_replication.py', 'cinder/tests/test_migrations.py', 'cinder/scheduler/driver.py', 'cinder/tests/policy.json', 'cinder/common/config.py', 'cinder/db/api.py', 'cinder/tests/scheduler/fakes.py', 'cinder/volume/utils.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/driver.py', 'cinder/replication/api.py', 'cinder/tests/scheduler/test_filter_scheduler.py', 'cinder/api/contrib/volume_replication.py', 'cinder/api/views/replications.py', 'cinder/replication/__init__.py', 'cinder/volume/rpcapi.py', 'cinder/tests/api/contrib/test_volume_replication.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e11fe78b09c52866e8756165e1ad31c5346fe5f2', 'message': 'Add support in Cinder for volume replication\n\nProvide support in Cinder to manage volume replication.\n\nThis patch provides the foundation in Cinder to make volume\nreplication available to the cloud admin. It makes Cinder aware\nof volume replicas, and allows the cloud admin to define storage\npolicies (volume types) that will enable replication.\n\nThe replication support in Cinder reduces the work and amount of\ncode needed by volume driver to enable replication in their\ndrivers, and make it easier in the future to implement cross\nback-end replication, as support is not driver specific.\n\nThis includes:\n1. Make volume driver expose replication capabilities\n2. Extend the Cinder db to add know-how about replicas\n3. Enable scheduler to select back-end for replica\n4. Create replicas through create-volume and volume re-type\n5. Common code in volume manager to handle API\n6. Driver methods to expose per replication functions\n\nCinder-specs available at https://review.openstack.org/#/c/98308/\n\nChange-Id: I012b53c3435112140d894c79fb61cae896a03ce5\nImplements: blueprint volume-replication\nDocImpact\n'}]",134,106718,e11fe78b09c52866e8756165e1ad31c5346fe5f2,101,20,14,4418,,,0,"Add support in Cinder for volume replication

Provide support in Cinder to manage volume replication.

This patch provides the foundation in Cinder to make volume
replication available to the cloud admin. It makes Cinder aware
of volume replicas, and allows the cloud admin to define storage
policies (volume types) that will enable replication.

The replication support in Cinder reduces the work and amount of
code needed by volume driver to enable replication in their
drivers, and make it easier in the future to implement cross
back-end replication, as support is not driver specific.

This includes:
1. Make volume driver expose replication capabilities
2. Extend the Cinder db to add know-how about replicas
3. Enable scheduler to select back-end for replica
4. Create replicas through create-volume and volume re-type
5. Common code in volume manager to handle API
6. Driver methods to expose per replication functions

Cinder-specs available at https://review.openstack.org/#/c/98308/

Change-Id: I012b53c3435112140d894c79fb61cae896a03ce5
Implements: blueprint volume-replication
DocImpact
",git fetch https://review.opendev.org/openstack/cinder refs/changes/18/106718/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/volume/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_volume_rpcapi.py', 'cinder/db/sqlalchemy/migrate_repo/versions/023_add_replication_relationships.py', 'cinder/exception.py', 'cinder/tests/test_migrations.py', 'cinder/scheduler/driver.py', 'cinder/tests/policy.json', 'cinder/common/config.py', 'cinder/db/api.py', 'cinder/tests/scheduler/fakes.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/driver.py', 'cinder/replication/api.py', 'cinder/tests/scheduler/test_filter_scheduler.py', 'cinder/api/contrib/volume_replication.py', 'cinder/api/views/replications.py', 'cinder/replication/__init__.py', 'cinder/volume/rpcapi.py', 'cinder/db/sqlalchemy/models.py', 'cinder/volume/api.py']",24,e1044d449b6f3681b75e6395dc24e870b69482e4,bp/volume-replication," filters['no_secondary_replicas'] = True if volume['status'].startswith('replica_'): # Can't snapshot secondary replica msg = _(""Snapshot of secondary replica is not allowed."") raise exception.InvalidVolume(reason=msg) # We only handle non-replicated volumes for now try: rel = self.db.replication_relationship_get_by_volume_id( context, volume['id']) except exception.VolReplicationRelationshipNotFound: rel = None if rel: msg = _(""volume must not be replicated"") LOG.error(msg) raise exception.InvalidVolume(reason=msg) ",,1697,42
openstack%2Fironic-inspector~master~I63976d01f265d18c385f6a30f1f2884c58ca5a43,openstack/ironic-inspector,master,I63976d01f265d18c385f6a30f1f2884c58ca5a43,Support updating IPMI credentials from within ramdisk,MERGED,2014-12-10 19:37:39.000000000,2014-12-11 13:45:15.000000000,2014-12-11 13:45:14.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-10 19:37:39.000000000', 'files': ['ironic_discoverd/process.py', 'README.rst', 'ironic_discoverd/conf.py', 'example.conf', 'ironic_discoverd/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/43b0769703dfa4604615dff4d0420e0122df40a2', 'message': 'Support updating IPMI credentials from within ramdisk\n\nIf ipmi_setup_credentials is set to true in Node.extra, return\ndesired credentials back to the ramdisk and wait for power management\ninterface to pass validation.\n\nUnfortunately, due to newly revealed problems, this is reverting\na big part of blueprint returning-to-ramdisk.\n\nChange-Id: I63976d01f265d18c385f6a30f1f2884c58ca5a43\nImplements: blueprint setup-ipmi-credentials\n'}]",2,140814,43b0769703dfa4604615dff4d0420e0122df40a2,7,3,1,10239,,,0,"Support updating IPMI credentials from within ramdisk

If ipmi_setup_credentials is set to true in Node.extra, return
desired credentials back to the ramdisk and wait for power management
interface to pass validation.

Unfortunately, due to newly revealed problems, this is reverting
a big part of blueprint returning-to-ramdisk.

Change-Id: I63976d01f265d18c385f6a30f1f2884c58ca5a43
Implements: blueprint setup-ipmi-credentials
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/14/140814/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/process.py', 'README.rst', 'ironic_discoverd/conf.py', 'example.conf', 'ironic_discoverd/test/test_process.py']",5,43b0769703dfa4604615dff4d0420e0122df40a2,bp/setup-ipmi-credentials," self.fake_result_json = 'node json' process_mock.return_value = self.fake_result_json self.assertEqual(self.fake_result_json, res) process.process(self.data) process.process(self.data) process.process(self.data) self.validate_attempts = 5 self.cli.node.validate.side_effect = self.fake_validate() def fake_validate(self): # Simulate long ramdisk task for _ in range(self.validate_attempts): yield mock.Mock(power={'result': False, 'reason': 'boom!'}) yield mock.Mock(power={'result': True}) self.cli.node.set_power_state.assert_called_once_with(self.uuid, 'off') self.assertFalse(self.cli.node.validate.called) def test_ipmi_setup_credentials(self, filters_mock, post_hook_mock): self.node.extra['ipmi_setup_credentials'] = True self.call() self.cli.node.set_power_state.assert_called_once_with(self.uuid, 'off') self.cli.node.validate.assert_called_with(self.uuid) self.assertEqual(self.validate_attempts + 1, self.cli.node.validate.call_count) def test_ipmi_setup_credentials_timeout(self, time_mock, filters_mock, post_hook_mock): self.node.extra['ipmi_setup_credentials'] = True self.assertFalse(self.cli.node.set_power_state.called) def test_power_off_failed(self, filters_mock, post_hook_mock):"," self.fake_node_json = 'node json' process_mock.return_value.to_dict.return_value = ( self.fake_node_json) self.assertEqual({'node': self.fake_node_json}, res) res = process.process(self.data) self.assertEqual({'node': self.fake_node_json}, res) res = process.process(self.data) self.assertEqual({'node': self.fake_node_json}, res) res = process.process(self.data) self.assertEqual({'node': self.fake_node_json}, res) self.power_off_repeats = 5 self.cli.node.get.side_effect = self.fake_get() def fake_get(self): # Simulate long power off for _ in range(self.power_off_repeats): yield self.node self.node.power_state = 'power off' yield self.node self.cli.node.get.assert_called_with(self.uuid) self.assertEqual(self.power_off_repeats + 1, self.cli.node.get.call_count) self.assertFalse(self.cli.node.set_power_state.called) def test_power_timeout(self, time_mock, filters_mock, post_hook_mock): def test_force_power_off(self, filters_mock, post_hook_mock): conf.CONF.set('discoverd', 'power_off_after_discovery', 'true') self.call() self.cli.node.set_power_state.assert_called_once_with(self.uuid, 'off') def test_force_power_off_failed(self, filters_mock, post_hook_mock): conf.CONF.set('discoverd', 'power_off_after_discovery', 'true')",65,65
openstack%2Fdesignate~master~I75ce3f17f892a619889f7d3a0a8f66c1ff788849,openstack/designate,master,I75ce3f17f892a619889f7d3a0a8f66c1ff788849,Standardize creation of rpcapi client instances,MERGED,2014-12-09 14:42:25.000000000,2014-12-11 13:42:55.000000000,2014-12-11 13:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2014-12-09 14:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ca1476d48b0b43699f71b67bd063aefeded1217c', 'message': ""Standardize creation of rpcapi client instances\n\nThis cleans up where the get_foo_api() is placed, so it's only placed in the\nrespective svc.rpcapi.SvcApi.get_instance() vs in multiple locations.\n\nChange-Id: I75ce3f17f892a619889f7d3a0a8f66c1ff788849\n""}, {'number': 2, 'created': '2014-12-09 15:05:27.000000000', 'files': ['designate/api/v1/limits.py', 'designate/central/service.py', 'designate/pool_manager/rpcapi.py', 'designate/api/v1/domains.py', 'designate/pool_manager/__init__.py', 'designate/api/v1/records.py', 'designate/api/__init__.py', 'designate/central/rpcapi.py', 'designate/mdns/__init__.py', 'designate/agent/service.py', 'designate/api/v1/servers.py', 'designate/api/v1/tsigkeys.py', 'designate/central/__init__.py', 'designate/pool_manager/service.py', 'designate/mdns/notify.py', 'designate/api/v2/controllers/rest.py', 'designate/mdns/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/22db5ad7395c061dbc55bb74775d39586e12eadf', 'message': ""Standardize creation of rpcapi client instances\n\nThis cleans up where the get_foo_api() is placed, so it's only placed in the\nrespective svc.rpcapi.SvcApi.get_instance() vs in multiple locations.\n\nChange-Id: I75ce3f17f892a619889f7d3a0a8f66c1ff788849\n""}]",4,140347,22db5ad7395c061dbc55bb74775d39586e12eadf,18,6,2,395,,,0,"Standardize creation of rpcapi client instances

This cleans up where the get_foo_api() is placed, so it's only placed in the
respective svc.rpcapi.SvcApi.get_instance() vs in multiple locations.

Change-Id: I75ce3f17f892a619889f7d3a0a8f66c1ff788849
",git fetch https://review.opendev.org/openstack/designate refs/changes/47/140347/2 && git format-patch -1 --stdout FETCH_HEAD,"['designate/api/v1/limits.py', 'designate/central/service.py', 'designate/pool_manager/rpcapi.py', 'designate/api/v1/domains.py', 'designate/pool_manager/__init__.py', 'designate/api/v1/records.py', 'designate/api/__init__.py', 'designate/central/rpcapi.py', 'designate/mdns/__init__.py', 'designate/agent/service.py', 'designate/api/v1/servers.py', 'designate/api/v1/tsigkeys.py', 'designate/central/__init__.py', 'designate/pool_manager/service.py', 'designate/mdns/notify.py', 'designate/api/v2/controllers/rest.py', 'designate/mdns/rpcapi.py']",17,ca1476d48b0b43699f71b67bd063aefeded1217c,rpcapi-standardize,"MDNS_API = None @classmethod def get_instance(cls): """""" The rpc.get_client() which is called upon the API object initialization will cause a assertion error if the designate.rpc.TRANSPORT isn't setup by rpc.init() before. This fixes that by creating the rpcapi when demanded. """""" global MDNS_API if not MDNS_API: MDNS_API = cls() return MDNS_API ",,143,148
openstack%2Ffuel-web~master~Iaabd455edcf1311b162ceb3403879313e6e67825,openstack/fuel-web,master,Iaabd455edcf1311b162ceb3403879313e6e67825,Allow to use socket to connect to DB in Nailgun,MERGED,2014-12-03 11:17:31.000000000,2014-12-11 13:36:00.000000000,2014-12-11 13:35:59.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6476}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-03 11:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/234053a64a160e7fb58809dfb7d3d8a7dcfbb76c', 'message': 'Allow to use socket to connect to DB in Nailgun\n\nDocImpact\nCloses-Bug: #1398728\n\nChange-Id: Iaabd455edcf1311b162ceb3403879313e6e67825\n'}, {'number': 2, 'created': '2014-12-10 07:21:00.000000000', 'files': ['nailgun/nailgun/db/sqlalchemy/utils.py', 'nailgun/nailgun/db/sqlalchemy/__init__.py', 'nailgun/nailgun/test/unit/test_db.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f6179863c94086b88f662d3be8d48baba319872c', 'message': 'Allow to use socket to connect to DB in Nailgun\n\nRight now it is possible to specify a unix-socket in settings\nas a way to connect to the PostgreSQL database. It must be specified\nas the \'host\' settings:\n\nDATABASE:\n  engine: ""postgresql""\n  name: ""nailgun""\n  host: ""/var/run/postgresql""\n  port: """"\n  user: ""nailgun""\n  passwd: ""nailgun""\n\n\nDocImpact\nCloses-Bug: #1398728\nChange-Id: Iaabd455edcf1311b162ceb3403879313e6e67825\n'}]",0,138682,f6179863c94086b88f662d3be8d48baba319872c,33,13,2,12200,,,0,"Allow to use socket to connect to DB in Nailgun

Right now it is possible to specify a unix-socket in settings
as a way to connect to the PostgreSQL database. It must be specified
as the 'host' settings:

DATABASE:
  engine: ""postgresql""
  name: ""nailgun""
  host: ""/var/run/postgresql""
  port: """"
  user: ""nailgun""
  passwd: ""nailgun""


DocImpact
Closes-Bug: #1398728
Change-Id: Iaabd455edcf1311b162ceb3403879313e6e67825
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/82/138682/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/sqlalchemy/utils.py', 'nailgun/nailgun/db/sqlalchemy/__init__.py', 'nailgun/nailgun/test/unit/test_db.py']",3,234053a64a160e7fb58809dfb7d3d8a7dcfbb76c,bug/1398728,"# -*- coding: utf-8 -*- # Copyright 2014 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nailgun.db.sqlalchemy import utils from nailgun.test import base class TestDbUtils(base.BaseUnitTest): def setUp(self): super(TestDbUtils, self).setUp() self.default_settings = { 'engine': 'db_engine', 'host': 'localhost', 'port': '8080', 'name': 'database', 'user': 'db_user', 'passwd': 'db_pass', } def test_make_dsn_with_regular_host(self): dsn = utils.make_dsn(**self.default_settings) self.assertEqual( dsn, 'db_engine://db_user:db_pass@localhost:8080/database' ) def test_make_dsn_with_socket(self): self.default_settings['host'] = '/path/to/socket' dsn = utils.make_dsn(**self.default_settings) self.assertEqual( dsn, 'db_engine://db_user:db_pass@/database?host=/path/to/socket' ) ",,94,4
openstack%2Fceilometer~master~I49ed3025bb90355b851526af9b5a469c7c84fdc9,openstack/ceilometer,master,I49ed3025bb90355b851526af9b5a469c7c84fdc9,Add some rally scenarios,MERGED,2014-11-04 10:51:07.000000000,2014-12-11 13:33:01.000000000,2014-12-11 13:32:59.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6172}, {'_account_id': 7052}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-11-04 10:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b3572b2ea5d9ba9d80331ede0f5e1d04ba13aedd', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}, {'number': 2, 'created': '2014-11-25 09:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/190ae1f7a2eba4587893748bfef540ce68631934', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nImplements: blueprint rally-check-gate\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}, {'number': 3, 'created': '2014-11-25 09:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/18b548783c1dbe3128ee962376809410c97eeb95', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nImplements blueprint rally-check-gate\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}, {'number': 4, 'created': '2014-11-25 09:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5974463f2c0827b04f73e503e7ba5eceba1f00bf', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nImplements blueprint rally-gate-check\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}, {'number': 5, 'created': '2014-11-25 11:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fb9fa59a6352709dffe20f3fa38472fdd56b3747', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nImplements blueprint rally-gate-check\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}, {'number': 6, 'created': '2014-11-26 10:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/91678606d1aa9d3492ed0a4c70de97778b532c08', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nImplements blueprint rally-gate-check\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}, {'number': 7, 'created': '2014-12-03 06:39:17.000000000', 'files': ['rally-jobs/ceilometer.yaml', 'rally-jobs/extra/fake.img', 'rally-jobs/extra/README.rst', 'rally-jobs/plugins/plugin_sample.py', 'rally-jobs/README.rst', 'rally-jobs/plugins/README.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e6e36815b201f0aa5a84facd63f58141bdba3a92', 'message': 'Add some rally scenarios\n\nThis change adds configuration directory for rally.\n\nImplements blueprint rally-gate-check\n\nChange-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9\n'}]",1,132649,e6e36815b201f0aa5a84facd63f58141bdba3a92,38,10,7,2813,,,0,"Add some rally scenarios

This change adds configuration directory for rally.

Implements blueprint rally-gate-check

Change-Id: I49ed3025bb90355b851526af9b5a469c7c84fdc9
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/49/132649/6 && git format-patch -1 --stdout FETCH_HEAD,"['rally-scenarios/ceilometer.yaml', 'rally-scenarios/README.rst']",2,b3572b2ea5d9ba9d80331ede0f5e1d04ba13aedd,bp/rally-gate-check,This directory contains rally benchmark scenarios to be run by OpenStack CI. * more about rally: https://wiki.openstack.org/wiki/Rally * how to add rally-gates: https://wiki.openstack.org/wiki/Rally/RallyGates ,,218,0
openstack%2Fglance~master~I21351880db0848b860e7c61d4a8c711be2a49de0,openstack/glance,master,I21351880db0848b860e7c61d4a8c711be2a49de0,Use testr directly from tox,MERGED,2014-12-10 19:54:53.000000000,2014-12-11 13:04:07.000000000,2014-12-11 13:04:05.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-10 19:54:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/glance/commit/50a5ffed129fe8dd955a526647196c884a9b9230', 'message': 'Use testr directly from tox\n\nInvoking testr directly lets us pass arguments to it through tox so we\ncan, for example, only run a subset of the tests.\n\nChange-Id: I21351880db0848b860e7c61d4a8c711be2a49de0\n'}]",0,140824,50a5ffed129fe8dd955a526647196c884a9b9230,10,5,1,2472,,,0,"Use testr directly from tox

Invoking testr directly lets us pass arguments to it through tox so we
can, for example, only run a subset of the tests.

Change-Id: I21351880db0848b860e7c61d4a8c711be2a49de0
",git fetch https://review.opendev.org/openstack/glance refs/changes/24/140824/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,50a5ffed129fe8dd955a526647196c884a9b9230,remove-oslo-db-import-side-effect,commands = python -m glance.openstack.common.lockutils python setup.py testr --slowest \,commands = python -m glance.openstack.common.lockutils python setup.py test --slowest \,1,1
openstack%2Fpython-glanceclient~master~Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a,openstack/python-glanceclient,master,Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a,Support Pagination for namespace list,MERGED,2014-10-15 23:48:49.000000000,2014-12-11 13:03:02.000000000,2014-12-11 13:03:01.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 8127}, {'_account_id': 8959}, {'_account_id': 11391}, {'_account_id': 11600}]","[{'number': 1, 'created': '2014-10-15 23:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8a036354502f4db22fb861bbee66a4079b71bf88', 'message': ""Support Pagination for namespace list\n\nThe rest api metadefs/namespaces supports pagination using the parameters\nof limit, marker, sort_dir, & sort_key. However, the glance client isn't\npassing those parameters through (they come in as kwargs). This is\npreventing pagination from working properly in horizon.\n\nThis is affecting Horizon support: https://review.openstack.org/#/c/104063/\n\nChange-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a\nCloses-Bug: 1381816\n""}, {'number': 2, 'created': '2014-10-18 07:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/7e3eb8458fb6bf53b092ccbb98b9944845307fb8', 'message': ""Support Pagination for namespace list\n\nThe rest api metadefs/namespaces supports pagination using the parameters\nof limit, marker, sort_dir, & sort_key. However, the glance client isn't\npassing those parameters through (they come in as kwargs). This is\npreventing pagination from working properly in horizon.\n\nThis is affecting Horizon support: https://review.openstack.org/#/c/104063/\n\nChange-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a\nCloses-Bug: 1381816\n""}, {'number': 3, 'created': '2014-12-08 19:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/a3823fa57641a35b7b51c0e0d48276a68dd9ac99', 'message': ""Support Pagination for namespace list\n\nThe rest api metadefs/namespaces supports pagination using the parameters\nof limit, marker, sort_dir, & sort_key. However, the glance client isn't\npassing those parameters through (they come in as kwargs). This is\npreventing pagination from working properly in horizon.\n\nThis is affecting Horizon support: https://review.openstack.org/#/c/104063/\n\nChange-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a\nCloses-Bug: 1381816\n""}, {'number': 4, 'created': '2014-12-09 01:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1813cd960d91e9adb5b404eec06ecca754c0e6f1', 'message': ""Support Pagination for namespace list\n\nThe rest api metadefs/namespaces supports pagination using the parameters\nof limit, marker, sort_dir, & sort_key. However, the glance client isn't\npassing those parameters through (they come in as kwargs). This is\npreventing pagination from working properly in horizon.\n\nThis is affecting Horizon support: https://review.openstack.org/#/c/104063/\n\nChange-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a\nCloses-Bug: 1381816\n""}, {'number': 5, 'created': '2014-12-11 05:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cd54e44097cfca2153f23aa031ed74a79943ec21', 'message': ""Support Pagination for namespace list\n\nThe rest api metadefs/namespaces supports pagination using the parameters\nof limit, marker, sort_dir, & sort_key. However, the glance client isn't\npassing those parameters through (they come in as kwargs). This is\npreventing pagination from working properly in horizon.\n\nThis is affecting Horizon support: https://review.openstack.org/#/c/104063/\n\nChange-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a\nCloses-Bug: 1381816\n""}, {'number': 6, 'created': '2014-12-11 06:21:54.000000000', 'files': ['glanceclient/v2/metadefs.py', 'tests/v2/test_metadefs_namespaces.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/9a4d8580e890c3c55c2d02904f5f6983bd06bd1c', 'message': ""Support Pagination for namespace list\n\nThe rest api metadefs/namespaces supports pagination using the parameters\nof limit, marker, sort_dir, & sort_key. However, the glance client isn't\npassing those parameters through (they come in as kwargs). This is\npreventing pagination from working properly in horizon.\n\nThis is affecting Horizon support: https://review.openstack.org/#/c/104063/\n\nChange-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a\nCloses-Bug: 1381816\n""}]",8,128791,9a4d8580e890c3c55c2d02904f5f6983bd06bd1c,31,10,6,7665,,,0,"Support Pagination for namespace list

The rest api metadefs/namespaces supports pagination using the parameters
of limit, marker, sort_dir, & sort_key. However, the glance client isn't
passing those parameters through (they come in as kwargs). This is
preventing pagination from working properly in horizon.

This is affecting Horizon support: https://review.openstack.org/#/c/104063/

Change-Id: Ib349cf3a3a437eb1711f350b37d0bd0e7d01330a
Closes-Bug: 1381816
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/91/128791/5 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/v2/metadefs.py', 'tests/v2/test_metadefs_namespaces.py']",2,8a036354502f4db22fb861bbee66a4079b71bf88,bug/1381816," ""/v2/metadefs/namespaces?sort_dir=asc&limit=20"": { ""GET"": ( {}, { ""first"": ""/v2/metadefs/namespaces?limit=1"", ""namespaces"": [ _get_namespace_fixture(NAMESPACE1), ], ""schema"": ""/v2/schemas/metadefs/namespaces"" } ) }, ""/v2/metadefs/namespaces?sort_key=created_at&limit=20"": { ""GET"": ( {}, { ""first"": ""/v2/metadefs/namespaces?limit=1"", ""namespaces"": [ _get_namespace_fixture(NAMESPACE1), ], ""schema"": ""/v2/schemas/metadefs/namespaces"" } ) }, }, def test_list_with_limit_greater_than_page_size(self): namespaces = list(self.controller.list(page_size=1, limit=2)) self.assertEqual(2, len(namespaces)) self.assertEqual(NAMESPACE7, namespaces[0]['namespace']) self.assertEqual(NAMESPACE8, namespaces[1]['namespace']) def test_list_with_marker(self): namespaces = list(self.controller.list(marker=NAMESPACE1, limit=3)) self.assertEqual(2, len(namespaces)) self.assertEqual(NAMESPACE1, namespaces[0]['namespace']) self.assertEqual(NAMESPACE2, namespaces[1]['namespace']) def test_list_with_sort_dir(self): namespaces = list(self.controller.list(sort_dir='asc', limit=1)) self.assertEqual(1, len(namespaces)) self.assertEqual(NAMESPACE1, namespaces[0]['namespace']) def test_list_with_sort_key(self): namespaces = list(self.controller.list(sort_key='created_at', limit=1)) self.assertEqual(1, len(namespaces)) self.assertEqual(NAMESPACE1, namespaces[0]['namespace']) ", },76,3
openstack%2Fglance~master~Ia2772030915061ff373e7b7dc77f161146b56e59,openstack/glance,master,Ia2772030915061ff373e7b7dc77f161146b56e59,Remove reliance on import order of oslo.db mods,MERGED,2014-12-10 14:56:59.000000000,2014-12-11 12:52:51.000000000,2014-12-11 12:52:49.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 7491}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-10 14:56:59.000000000', 'files': ['glance/db/metadata.py', 'glance/db/migration.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/d4371c5dff0620c7a903ba2d1b060c70b2276992', 'message': ""Remove reliance on import order of oslo.db mods\n\nThis change fixes a couple of import statements that rely on some import\norder and a bit of magic to make the oslo.db.options module visible\nunder the oslo.db package without importing it explicitly.\n\nThe old version of the imports relies on Python's import machinery to\nattach sub-modules to packages after import (see\nhttp://paste.openstack.org/show/148711/). It is safer to explicitly\nimport the module we need, to ensure that we are not relying on\nside-effects of importing other modules to configure global state for\nthe application.\n\nChange-Id: Ia2772030915061ff373e7b7dc77f161146b56e59\n""}]",0,140709,d4371c5dff0620c7a903ba2d1b060c70b2276992,14,6,1,2472,,,0,"Remove reliance on import order of oslo.db mods

This change fixes a couple of import statements that rely on some import
order and a bit of magic to make the oslo.db.options module visible
under the oslo.db package without importing it explicitly.

The old version of the imports relies on Python's import machinery to
attach sub-modules to packages after import (see
http://paste.openstack.org/show/148711/). It is safer to explicitly
import the module we need, to ensure that we are not relying on
side-effects of importing other modules to configure global state for
the application.

Change-Id: Ia2772030915061ff373e7b7dc77f161146b56e59
",git fetch https://review.opendev.org/openstack/glance refs/changes/09/140709/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/db/metadata.py', 'glance/db/migration.py']",2,d4371c5dff0620c7a903ba2d1b060c70b2276992,remove-oslo-db-import-side-effect,from oslo.db import options as db_optionsdb_options.set_defaults(cfg.CONF),from oslo import dbdb.options.set_defaults(cfg.CONF),4,4
openstack%2Foslo.serialization~master~Ice7c658e09fd99e66d38bb0cc8c774711b87feba,openstack/oslo.serialization,master,Ice7c658e09fd99e66d38bb0cc8c774711b87feba,Updated from global requirements,MERGED,2014-12-11 07:19:35.000000000,2014-12-11 12:50:08.000000000,2014-12-11 12:50:08.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-11 07:19:35.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/683920df7a1054a537bba9c5a3d6c11539bec5b8', 'message': 'Updated from global requirements\n\nChange-Id: Ice7c658e09fd99e66d38bb0cc8c774711b87feba\n'}]",0,140951,683920df7a1054a537bba9c5a3d6c11539bec5b8,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ice7c658e09fd99e66d38bb0cc8c774711b87feba
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/51/140951/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,683920df7a1054a537bba9c5a3d6c11539bec5b8,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fnova~master~Ibe59ddc53d074f5b8147e24b35066d38d73c7c33,openstack/nova,master,Ibe59ddc53d074f5b8147e24b35066d38d73c7c33,"Parse ""networks"" attribute if loading os-networks",MERGED,2014-12-08 00:35:40.000000000,2014-12-11 12:46:44.000000000,2014-12-11 12:46:41.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8412}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-12-08 00:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9ea4711d0fb4229126db9c2bc815bcd08400428', 'message': 'Parse ""networks"" attribute if loading os-networks\n\n""networks"" attribute of ""create a server"" API should be used when\nNeutron/os-network extension is loaded as TODO which is removed with\nthis patch mentions. V2.1 os-network extension has been implemented\nwith I94b7b476cbb02725a396725a379417b64afd58a7 already, so this patch\nenables ""networks"" attribute for os-network extension.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ibe59ddc53d074f5b8147e24b35066d38d73c7c33\n'}, {'number': 2, 'created': '2014-12-08 03:29:49.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6045b095f46ea463af266944169d14e85447de30', 'message': 'Parse ""networks"" attribute if loading os-networks\n\n""networks"" attribute of ""create a server"" API should be used when\nNeutron/os-network extension is loaded as TODO which is removed with\nthis patch mentions. V2.1 os-network extension has been implemented\nwith I94b7b476cbb02725a396725a379417b64afd58a7 already, so this patch\nenables ""networks"" attribute for os-network extension.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ibe59ddc53d074f5b8147e24b35066d38d73c7c33\n'}]",3,139893,6045b095f46ea463af266944169d14e85447de30,29,13,2,6167,,,0,"Parse ""networks"" attribute if loading os-networks

""networks"" attribute of ""create a server"" API should be used when
Neutron/os-network extension is loaded as TODO which is removed with
this patch mentions. V2.1 os-network extension has been implemented
with I94b7b476cbb02725a396725a379417b64afd58a7 already, so this patch
enables ""networks"" attribute for os-network extension.

Partially implements blueprint v2-on-v3-api

Change-Id: Ibe59ddc53d074f5b8147e24b35066d38d73c7c33
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/139893/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/servers.py'],1,f9ea4711d0fb4229126db9c2bc815bcd08400428,bp/v2-on-v3-api, if (self.ext_mgr.is_loaded('os-networks') or utils.is_neutron()):, # TODO(cyeoh): bp v3-api-core-as-extensions # Replace with an extension point when the os-networks # extension is ported. Currently reworked # to take into account is_neutron # if (self.ext_mgr.is_loaded('os-networks') # or utils.is_neutron()): # requested_networks = server_dict.get('networks') if utils.is_neutron():,3,9
openstack%2Fdesignate~master~Ic0bfd8927086aefad8519c19313387fad4a03d00,openstack/designate,master,Ic0bfd8927086aefad8519c19313387fad4a03d00,Imported Translations from Transifex,MERGED,2014-12-11 06:10:01.000000000,2014-12-11 12:27:09.000000000,2014-12-11 12:27:08.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-11 06:10:01.000000000', 'files': ['designate/locale/designate-log-warning.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-warning.po', 'designate/locale/fr/LC_MESSAGES/designate.po', 'designate/locale/designate.pot', 'designate/locale/designate-log-info.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-info.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/83ac8e7a1f142f981a5dbf9e96361a679ba76494', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic0bfd8927086aefad8519c19313387fad4a03d00\n'}]",0,140930,83ac8e7a1f142f981a5dbf9e96361a679ba76494,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ic0bfd8927086aefad8519c19313387fad4a03d00
",git fetch https://review.opendev.org/openstack/designate refs/changes/30/140930/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/locale/designate-log-warning.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-warning.po', 'designate/locale/designate.pot', 'designate/locale/fr/LC_MESSAGES/designate.po', 'designate/locale/designate-log-info.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-info.po']",6,83ac8e7a1f142f981a5dbf9e96361a679ba76494,transifex/translations,"""POT-Creation-Date: 2014-12-11 06:09+0000\n"" ""PO-Revision-Date: 2014-12-10 13:59+0000\n""#: designate/central/service.py:1759#: designate/central/service.py:2119#: designate/mdns/notify.py:184#: designate/mdns/rpcapi.py:60#: designate/mdns/service.py:143#: designate/openstack/common/eventlet_backdoor.py:147#: designate/openstack/common/policy.py:275 #, python-format msgid ""Can not find policy directory: %s"" msgstr """" #: designate/pool_manager/rpcapi.py:62","""POT-Creation-Date: 2014-11-24 06:10+0000\n"" ""PO-Revision-Date: 2014-11-20 20:54+0000\n""#: designate/central/service.py:1723#: designate/central/service.py:2035#: designate/mdns/notify.py:179#: designate/mdns/rpcapi.py:59#: designate/mdns/service.py:134#: designate/openstack/common/eventlet_backdoor.py:140#: designate/pool_manager/rpcapi.py:61",79,71
openstack%2Fdesignate~master~I92441970e0ad64a03234ee03eb1ce55afb38506c,openstack/designate,master,I92441970e0ad64a03234ee03eb1ce55afb38506c,Updated from global requirements,MERGED,2014-12-11 07:13:03.000000000,2014-12-11 12:27:03.000000000,2014-12-11 12:27:02.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-11 07:13:03.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/9783b10b2bad2ab35ca9555528c3582162ff3ec6', 'message': 'Updated from global requirements\n\nChange-Id: I92441970e0ad64a03234ee03eb1ce55afb38506c\n'}]",0,140939,9783b10b2bad2ab35ca9555528c3582162ff3ec6,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I92441970e0ad64a03234ee03eb1ce55afb38506c
",git fetch https://review.opendev.org/openstack/designate refs/changes/39/140939/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9783b10b2bad2ab35ca9555528c3582162ff3ec6,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fdesignate~master~I2a736be7c18290f7fcad65541d33dad9216e213f,openstack/designate,master,I2a736be7c18290f7fcad65541d33dad9216e213f,Adds negative tests to test_servers.py,MERGED,2014-12-11 07:32:53.000000000,2014-12-11 12:26:51.000000000,2014-12-11 12:26:50.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-11 07:32:53.000000000', 'files': ['designate/tests/test_api/test_v1/test_servers.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/dd918ff47027c69f517b21ac59eaf23e6598da9c', 'message': 'Adds negative tests to test_servers.py\n\nThis submission adds three negative tests under\n""designate/tests/test_api/test_v1/test_servers.py"" script.\n\nFollowing are the negative tests -\n\n        1. test_create_server_with_invalid_name\n        2. test_get_server_with_invalid_id\n        3. test_delete_server_with_invalid_id\n\nChange-Id: I2a736be7c18290f7fcad65541d33dad9216e213f\n'}]",0,140968,dd918ff47027c69f517b21ac59eaf23e6598da9c,7,3,1,1687,,,0,"Adds negative tests to test_servers.py

This submission adds three negative tests under
""designate/tests/test_api/test_v1/test_servers.py"" script.

Following are the negative tests -

        1. test_create_server_with_invalid_name
        2. test_get_server_with_invalid_id
        3. test_delete_server_with_invalid_id

Change-Id: I2a736be7c18290f7fcad65541d33dad9216e213f
",git fetch https://review.opendev.org/openstack/designate refs/changes/68/140968/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/tests/test_api/test_v1/test_servers.py'],1,dd918ff47027c69f517b21ac59eaf23e6598da9c,separate/designate_servers_unittests," def test_create_server_with_invalid_name(self): # Create a server fixture = self.get_server_fixture(0) # Add a invalid name fixture['name'] = '$#$%^^' # Ensure it fails with a 400 self.post('servers', data=fixture, status_code=400) def test_get_server_with_invalid_id(self): self.get('servers/2fdadfb1-cf96-4259-ac6b-bb7b6d2ff98GH', status_code=404) def test_delete_server_with_invalid_id(self): self.delete('servers/9fdadfb1-cf96-4259-ac6b-bb7b6d2ff98GH', status_code=404) ",,18,0
openstack%2Ffuel-web~master~I173cb51852ce82a9c6fa7868d68f1c1026cc3315,openstack/fuel-web,master,I173cb51852ce82a9c6fa7868d68f1c1026cc3315,Fix performance tests,MERGED,2014-12-10 12:38:14.000000000,2014-12-11 12:25:10.000000000,2014-12-11 12:25:09.000000000,"[{'_account_id': 3}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-10 12:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ddda1782f3e29bf0c3b15bf269d4f76592e71989', 'message': 'Fix performance tests\n\nChange-Id: I173cb51852ce82a9c6fa7868d68f1c1026cc3315\n'}, {'number': 2, 'created': '2014-12-11 09:03:22.000000000', 'files': ['nailgun/nailgun/test/performance/unit/test_node_operations.py', 'nailgun/nailgun/objects/cluster.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c703627753deff8bee48eb4925aa5aedf5892450', 'message': 'Fix performance tests\n\n* added changes missed during rebase in #118123\n* changed expected time in tests because tests\n  on jenkins running longer\n\nChange-Id: I173cb51852ce82a9c6fa7868d68f1c1026cc3315\n'}]",2,140661,c703627753deff8bee48eb4925aa5aedf5892450,20,7,2,11082,,,0,"Fix performance tests

* added changes missed during rebase in #118123
* changed expected time in tests because tests
  on jenkins running longer

Change-Id: I173cb51852ce82a9c6fa7868d68f1c1026cc3315
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/61/140661/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/performance/unit/test_node_operations.py', 'nailgun/nailgun/objects/cluster.py']",2,ddda1782f3e29bf0c3b15bf269d4f76592e71989,fix-performance-test," node_data = next((n for n in data if node.uid == n.get('uid')), {}) node_data = [n for n in data if node.uid == n.get('uid')]"," node_data = next((n for n in data if node.uid == n['uid']), {}) node_data = [n for n in data if node.uid == n['uid']]",3,3
openstack%2Ftempest-lib~master~I48d670353bb85f7f87a05041bed60ad131555057,openstack/tempest-lib,master,I48d670353bb85f7f87a05041bed60ad131555057,Add pretty_tox.sh wrapper script to use subunit-trace,MERGED,2014-10-18 05:28:02.000000000,2014-12-11 12:22:03.000000000,2014-12-11 12:22:02.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-10-18 05:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/278de38485a127e7a5a9785367136d11472d1538', 'message': 'Add pretty_tox.sh wrapper script to use subunit-trace\n\nThis commit adds a pretty_tox.sh wrapper script for the tempest-lib\nunit tests to use subunit-trace when running the tests. This should\nmake the output a bit more clear and help with future debugging.\n\nChange-Id: I48d670353bb85f7f87a05041bed60ad131555057\n'}, {'number': 2, 'created': '2014-10-18 05:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/c871eb9f30555e041fc03d8613f12c4bdb2e9741', 'message': 'Add pretty_tox.sh wrapper script to use subunit-trace\n\nThis commit adds a pretty_tox.sh wrapper script for the tempest-lib\nunit tests to use subunit-trace when running the tests. This should\nmake the output a bit more clear and help with future debugging.\n\nChange-Id: I48d670353bb85f7f87a05041bed60ad131555057\n'}, {'number': 3, 'created': '2014-11-20 03:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/bdf24a6a2b2f51859efb023cc903e48a27636713', 'message': 'Add pretty_tox.sh wrapper script to use subunit-trace\n\nThis commit adds a pretty_tox.sh wrapper script for the tempest-lib\nunit tests to use subunit-trace when running the tests. This should\nmake the output a bit more clear and help with future debugging.\n\nChange-Id: I48d670353bb85f7f87a05041bed60ad131555057\n'}, {'number': 4, 'created': '2014-12-03 00:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/898c759d53e69ff717d930248c46f117ddc01e28', 'message': 'Add pretty_tox.sh wrapper script to use subunit-trace\n\nThis commit adds a pretty_tox.sh wrapper script for the tempest-lib\nunit tests to use subunit-trace when running the tests. This should\nmake the output a bit more clear and help with future debugging.\n\nChange-Id: I48d670353bb85f7f87a05041bed60ad131555057\n'}, {'number': 5, 'created': '2014-12-03 00:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/40fe026db1123282600c7e44e4ae5797b1b35eb6', 'message': 'Add pretty_tox.sh wrapper script to use subunit-trace\n\nThis commit adds a pretty_tox.sh wrapper script for the tempest-lib\nunit tests to use subunit-trace when running the tests. This should\nmake the output a bit more clear and help with future debugging.\n\nChange-Id: I48d670353bb85f7f87a05041bed60ad131555057\n'}, {'number': 6, 'created': '2014-12-04 20:59:27.000000000', 'files': ['tox.ini', 'tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/dd266f725de573cd09c9e7bbb3c3ab20d49ec675', 'message': 'Add pretty_tox.sh wrapper script to use subunit-trace\n\nThis commit adds a pretty_tox.sh wrapper script for the tempest-lib\nunit tests to use subunit-trace when running the tests. This should\nmake the output a bit more clear and help with future debugging.\n\nChange-Id: I48d670353bb85f7f87a05041bed60ad131555057\n'}]",0,129419,dd266f725de573cd09c9e7bbb3c3ab20d49ec675,25,5,6,5196,,,0,"Add pretty_tox.sh wrapper script to use subunit-trace

This commit adds a pretty_tox.sh wrapper script for the tempest-lib
unit tests to use subunit-trace when running the tests. This should
make the output a bit more clear and help with future debugging.

Change-Id: I48d670353bb85f7f87a05041bed60ad131555057
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/19/129419/6 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'tools/pretty_tox.sh']",2,278de38485a127e7a5a9785367136d11472d1538,subunit-trace-imprvmnt,"#!/usr/bin/env bash set -o pipefail TESTRARGS=$1 python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | subunit-trace --no-failure-debug -f ",,8,1
openstack%2Ftempest-lib~master~I321d78390991eb90fbb4a176a12187b78edc9f31,openstack/tempest-lib,master,I321d78390991eb90fbb4a176a12187b78edc9f31,Fix migration script to use original SHA1 from tempest's commits,MERGED,2014-12-05 16:32:01.000000000,2014-12-11 12:20:16.000000000,2014-12-11 12:20:15.000000000,"[{'_account_id': 3}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-12-05 16:32:01.000000000', 'files': ['tools/migrate_from_tempest.sh'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/c9c9ff674b4d3b9e11a0a7b5e3676bcf109f59ec', 'message': ""Fix migration script to use original SHA1 from tempest's commits\n\nUse git log instead of git filter-branch - which rewrites the history - to get\nSHA1 from the commits that touch the files to be migrated from tempest to\ntempest_lib.\n\nChange-Id: I321d78390991eb90fbb4a176a12187b78edc9f31\nCloses-bug: #1386782\n""}]",0,139679,c9c9ff674b4d3b9e11a0a7b5e3676bcf109f59ec,14,4,1,5174,,,0,"Fix migration script to use original SHA1 from tempest's commits

Use git log instead of git filter-branch - which rewrites the history - to get
SHA1 from the commits that touch the files to be migrated from tempest to
tempest_lib.

Change-Id: I321d78390991eb90fbb4a176a12187b78edc9f31
Closes-bug: #1386782
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/79/139679/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/migrate_from_tempest.sh'],1,c9c9ff674b4d3b9e11a0a7b5e3676bcf109f59ec,bug/1386782,"# get only commits that touch our files commits=""$(git log --format=format:%h --no-merges --follow -- $files)"" # then their merge commits - which works fina since we merge commits # individually. merge_commits=""$(git log --format=format:%h --merges --first-parent -- $files)"" pattern=""\n$(echo $commits $merge_commits | sed -e 's/ /\\|/g')"" # order them by filtering each one in the order it appears on rev-list SHA1_LIST=$(git rev-list --oneline HEAD | grep $pattern)","# Build the grep pattern for ignoring files that we want to keep keep_pattern=""\($(echo $files | sed -e 's/ /\\|/g')\)"" # Prune all other files in every commit pruner=""git ls-files | grep -v \""$keep_pattern\"" | git update-index --force-remove --stdin; git ls-files > /dev/stderr"" # Find all first commits with listed files and find a subset of them that # predates all others roots="""" for file in $files; do file_root=""$(git rev-list --reverse HEAD -- $file | head -n1)"" fail=0 for root in $roots; do if git merge-base --is-ancestor $root $file_root; then fail=1 break elif ! git merge-base --is-ancestor $file_root $root; then new_roots=""$new_roots $root"" fi done if [ $fail -ne 1 ]; then roots=""$new_roots $file_root"" fi done set_roots="" if [ '' $(for root in $roots; do echo "" -o \""\$GIT_COMMIT\"" == '$root' ""; done) ]; then echo '' else cat fi"" # Enhance git_commit_non_empty_tree to skip merges with: # a) either two equal parents (commit that was about to land got purged as well # as all commits on mainline); # b) or with second parent being an ancestor to the first one (just as with a) # but when there are some commits on mainline). # In both cases drop second parent and let git_commit_non_empty_tree to decide # if commit worth doing (most likely not). skip_empty=$(cat << \EOF if [ $# = 5 ] && git merge-base --is-ancestor $5 $3; then git_commit_non_empty_tree $1 -p $3 else git_commit_non_empty_tree ""$@"" fi EOF ) # Prune just the commits relevant to what is being migrated git filter-branch --index-filter ""$pruner"" --parent-filter ""$set_roots"" --commit-filter ""$skip_empty"" HEAD SHA1_LIST=`git log --oneline`",8,51
openstack%2Fceilometer~master~I0f445013802273478f5f448fa0350b9a1b140414,openstack/ceilometer,master,I0f445013802273478f5f448fa0350b9a1b140414,Modify tests to support ordering of wsme types,MERGED,2014-12-10 02:54:22.000000000,2014-12-11 12:19:49.000000000,2014-12-11 12:19:47.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-10 02:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e636e1117f6504849309e6dd5fa87fb771260a32', 'message': 'Modify tests to support ordering of wsme types\n\nWhen PYTHONHASHSEED is enabled the ordering of the wsme types are changed.\nThis makes tests that take the type order into account when an assertEqual\nis checked on the error message fail. The assertEqual is now changed to an\nasserIn where the ordering of the types do not matter.\n\nChange-Id: I0f445013802273478f5f448fa0350b9a1b140414\nCloses-bug: #1399631\n'}, {'number': 2, 'created': '2014-12-10 03:00:36.000000000', 'files': ['ceilometer/tests/api/v2/test_alarm_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/969ae4296d6ddd2ceb040e2febb9dc9d1e618584', 'message': 'Modify tests to support ordering of wsme types\n\nWhen PYTHONHASHSEED is enabled the ordering of the wsme types are changed.\nThis fails the tests that take the type order into account when an assertEqual\nis checked on the error message. The assertEqual is now changed to an\nassertIn where the ordering of the types do not matter.\n\nChange-Id: I0f445013802273478f5f448fa0350b9a1b140414\nCloses-bug: #1399631\n'}]",0,140558,969ae4296d6ddd2ceb040e2febb9dc9d1e618584,12,8,2,13367,,,0,"Modify tests to support ordering of wsme types

When PYTHONHASHSEED is enabled the ordering of the wsme types are changed.
This fails the tests that take the type order into account when an assertEqual
is checked on the error message. The assertEqual is now changed to an
assertIn where the ordering of the types do not matter.

Change-Id: I0f445013802273478f5f448fa0350b9a1b140414
Closes-bug: #1399631
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/58/140558/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/api/v2/test_alarm_scenarios.py'],1,e636e1117f6504849309e6dd5fa87fb771260a32,bug/1399631," "" statistic. Value: 'magic'."") self.assertIn(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_state'."") self.assertIn(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_co'."") self.assertIn(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_type'."") self.assertIn(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_operator'."") self.assertIn(expected_err_msg, resp.json['error_message']['faultstring'])"," "" statistic."" "" Value: 'magic'."" "" Value should be one of:"" "" count, max, sum, avg, min"") self.assertEqual(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_state'."" "" Value should be one of:"" "" alarm, ok, insufficient data"") self.assertEqual(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_co'."" "" Value should be one of:"" "" gt, lt, ne, ge, le, eq"") self.assertEqual(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_type'."" "" Value should be one of:"" "" threshold, combination"") self.assertEqual(expected_err_msg, resp.json['error_message']['faultstring']) "" Value: 'bad_operator'."" "" Value should be one of: and, or"") self.assertEqual(expected_err_msg, resp.json['error_message']['faultstring'])",15,25
openstack%2Fheat-cfntools~master~I39ba2cca1f096e866f69fc016f78004ea991c0b6,openstack/heat-cfntools,master,I39ba2cca1f096e866f69fc016f78004ea991c0b6,Fixes cfn-hup hooks functionality,MERGED,2014-12-11 10:23:47.000000000,2014-12-11 11:59:16.000000000,2014-12-11 11:59:16.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-12-11 10:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-cfntools/commit/8da7ccae974b976210a520736223f6e37566c909', 'message': 'Fixes cfn-hup hooks functionality\n\nChange-Id: I39ba2cca1f096e866f69fc016f78004ea991c0b6\nCloses-Bug: 1234567\n'}, {'number': 2, 'created': '2014-12-11 10:28:11.000000000', 'files': ['heat_cfntools/cfntools/cfn_helper.py'], 'web_link': 'https://opendev.org/openstack/heat-cfntools/commit/d96f73c4ded3ece5c74096b652914491d3077b13', 'message': 'Fixes cfn-hup hooks functionality\n\nChange-Id: I39ba2cca1f096e866f69fc016f78004ea991c0b6\nCloses-Bug: 1387190\n'}]",0,141002,d96f73c4ded3ece5c74096b652914491d3077b13,9,5,2,13278,,,0,"Fixes cfn-hup hooks functionality

Change-Id: I39ba2cca1f096e866f69fc016f78004ea991c0b6
Closes-Bug: 1387190
",git fetch https://review.opendev.org/openstack/heat-cfntools refs/changes/02/141002/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_cfntools/cfntools/cfn_helper.py'],1,8da7ccae974b976210a520736223f6e37566c909,bug/1234567,, return,0,1
openstack%2Fpython-glanceclient~master~I250e8912aca262a56c54ac59bb24f917e5d8cfce,openstack/python-glanceclient,master,I250e8912aca262a56c54ac59bb24f917e5d8cfce,Support schema types with non-str value,MERGED,2014-12-10 09:51:12.000000000,2014-12-11 11:58:07.000000000,2014-12-11 11:58:07.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 7665}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-10 09:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/19fe660aad0ab328aa24315f701eff559d46abb2', 'message': ""Support schema types with non-str value\n\nChange I75da1e9309e0f7ef8839dea3ec9c99c58edc5d63 introduced some\nproperties' types which are not string. This broke the `schema_args`\nutility since lists are not hashable and there was no support for such\ntype values.\n\nThis patch fixes this issue with a very glance specific strategy in\nwhich this values are assumed to have a `null` type and another type -\nstring, integer, etc. The fix ignores `null` options and it takes the\nfirst non-null type as the valid one.\n\nThe patch adds support for enum types that accept `None`\n\nCloses-bug: #1401032\nChange-Id: I250e8912aca262a56c54ac59bb24f917e5d8cfce\n""}, {'number': 2, 'created': '2014-12-10 12:23:50.000000000', 'files': ['tests/test_utils.py', 'glanceclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/3989cd202de5d122da011be4f3bb9cede2fe8d45', 'message': ""Support schema types with non-str value\n\nChange I75da1e9309e0f7ef8839dea3ec9c99c58edc5d63 introduced some\nproperties' types which are not string. This broke the `schema_args`\nutility since lists are not hashable and there was no support for such\ntype values.\n\nThis patch fixes this issue with a very glance specific strategy in\nwhich this values are assumed to have a `null` type and another type -\nstring, integer, etc. The fix ignores `null` options and it takes the\nfirst non-null type as the valid one.\n\nThe patch adds support for enum types that accept `None`\n\nCloses-bug: #1401032\nChange-Id: I250e8912aca262a56c54ac59bb24f917e5d8cfce\n""}]",0,140624,3989cd202de5d122da011be4f3bb9cede2fe8d45,17,6,2,6159,,,0,"Support schema types with non-str value

Change I75da1e9309e0f7ef8839dea3ec9c99c58edc5d63 introduced some
properties' types which are not string. This broke the `schema_args`
utility since lists are not hashable and there was no support for such
type values.

This patch fixes this issue with a very glance specific strategy in
which this values are assumed to have a `null` type and another type -
string, integer, etc. The fix ignores `null` options and it takes the
first non-null type as the valid one.

The patch adds support for enum types that accept `None`

Closes-bug: #1401032
Change-Id: I250e8912aca262a56c54ac59bb24f917e5d8cfce
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/24/140624/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_utils.py', 'glanceclient/common/utils.py']",2,19fe660aad0ab328aa24315f701eff559d46abb2,bug/1401032," if isinstance(type_str, list): # NOTE(flaper87): This means the server has # returned something like `['null', 'string']`, # therfore we use the first non-`null` type as # the valid type. for t in type_str: if t != 'null': type_str = t break # NOTE(flaper87): Make sure all values are `str/unicode` # for the `join` to succeed. Enum types can also be `None` # therfore, join's call would fail without the following # list comprehension vals = [unicode(val) for val in property.get('enum')] description += ('Valid values: ' + ', '.join(vals))"," description += (""Valid values: "" + ', '.join(property.get('enum')))",62,2
openstack%2Fmistral~master~I5b89d9f1105e69b9af910820d9d0d254b942d5ab,openstack/mistral,master,I5b89d9f1105e69b9af910820d9d0d254b942d5ab,"Testing wait policies defined in ""task-defaults"" for reverse worklfow",MERGED,2014-12-11 08:23:27.000000000,2014-12-11 11:47:57.000000000,2014-12-11 11:47:57.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-11 08:23:27.000000000', 'files': ['mistral/tests/unit/engine1/test_task_defaults.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/63532f474eb3307cb71391a338094d1856366a8d', 'message': 'Testing wait policies defined in ""task-defaults"" for reverse worklfow\n\n* Added a unit test\n\nChange-Id: I5b89d9f1105e69b9af910820d9d0d254b942d5ab\nCloses-Bug: #1401391\n'}]",0,140974,63532f474eb3307cb71391a338094d1856366a8d,8,5,1,8731,,,0,"Testing wait policies defined in ""task-defaults"" for reverse worklfow

* Added a unit test

Change-Id: I5b89d9f1105e69b9af910820d9d0d254b942d5ab
Closes-Bug: #1401391
",git fetch https://review.opendev.org/openstack/mistral refs/changes/74/140974/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/tests/unit/engine1/test_task_defaults.py'],1,63532f474eb3307cb71391a338094d1856366a8d,bug/1401391,"import datetime as dtREVERSE_WF_WAIT = """""" --- version: '2.0' wf: type: reverse task-defaults: policies: wait-before: 1 wait-after: 1 tasks: task1: action: std.echo output=1 """""" def test_task_defaults_wait_policies(self): wf_service.create_workflows(REVERSE_WF_WAIT) time_before = dt.datetime.now() # Start workflow. exec_db = self.engine.start_workflow('wf', {}, task_name='task1') self._await(lambda: self.is_execution_success(exec_db.id)) # Workflow must work at least 2 seconds (1+1). self.assertGreater( (dt.datetime.now() - time_before).total_seconds(), 2 ) # Note: We need to reread execution to access related tasks. exec_db = db_api.get_execution(exec_db.id) tasks = exec_db.tasks self.assertEqual(1, len(tasks)) self._assert_single_item(tasks, name='task1', state=states.SUCCESS)",,43,0
openstack%2Fmistral~master~Ia535d80fa7702f907f8df6e522d665c0bf0f263d,openstack/mistral,master,Ia535d80fa7702f907f8df6e522d665c0bf0f263d,"Testing timeout policy defined in ""task-defaults"" for reverse workflow",MERGED,2014-12-11 08:00:07.000000000,2014-12-11 11:47:26.000000000,2014-12-11 11:47:25.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-11 08:00:07.000000000', 'files': ['mistral/tests/unit/engine1/test_task_defaults.py', 'mistral/actions/std_actions.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/mistral/commit/5aa2930c5a16c0a10d721cc54039962f3f220c05', 'message': 'Testing timeout policy defined in ""task-defaults"" for reverse workflow\n\n* Added a unit test\n* Added asynchronous version of no-op action (async_noop)\n\nChange-Id: Ia535d80fa7702f907f8df6e522d665c0bf0f263d\nCloses-Bug: #1401391\n'}]",0,140970,5aa2930c5a16c0a10d721cc54039962f3f220c05,8,5,1,8731,,,0,"Testing timeout policy defined in ""task-defaults"" for reverse workflow

* Added a unit test
* Added asynchronous version of no-op action (async_noop)

Change-Id: Ia535d80fa7702f907f8df6e522d665c0bf0f263d
Closes-Bug: #1401391
",git fetch https://review.opendev.org/openstack/mistral refs/changes/70/140970/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine1/test_task_defaults.py', 'mistral/actions/std_actions.py', 'setup.cfg']",3,5aa2930c5a16c0a10d721cc54039962f3f220c05,bug/1401391, std.async_noop = mistral.actions.std_actions:AsyncNoOpAction,,45,0
openstack%2Fmistral~master~Id92302c196539e80522768e956dc1ebd7de18456,openstack/mistral,master,Id92302c196539e80522768e956dc1ebd7de18456,"Testing retry policy defined in ""task-defaults"" for reverse workflow",MERGED,2014-12-11 07:32:14.000000000,2014-12-11 11:46:29.000000000,2014-12-11 11:46:28.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-12-11 07:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7facc16793b387635a7870ade1e3be5d650f02a8', 'message': 'Testing retry policy defined in ""task-defaults"" for reverse workflow\n\nChange-Id: Id92302c196539e80522768e956dc1ebd7de18456\n'}, {'number': 2, 'created': '2014-12-11 07:36:20.000000000', 'files': ['mistral/tests/unit/engine1/test_task_defaults.py', 'mistral/engine1/policies.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/34793ef08508a968d632c9969d3f03576545c289', 'message': 'Testing retry policy defined in ""task-defaults"" for reverse workflow\n\n* Added a unit test\n* Minor refactoring in retry policy\n\nCloses-Bug: #1401391\n\nChange-Id: Id92302c196539e80522768e956dc1ebd7de18456\n'}]",0,140967,34793ef08508a968d632c9969d3f03576545c289,10,6,2,8731,,,0,"Testing retry policy defined in ""task-defaults"" for reverse workflow

* Added a unit test
* Minor refactoring in retry policy

Closes-Bug: #1401391

Change-Id: Id92302c196539e80522768e956dc1ebd7de18456
",git fetch https://review.opendev.org/openstack/mistral refs/changes/67/140967/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine1/test_task_defaults.py', 'mistral/engine1/policies.py']",2,7facc16793b387635a7870ade1e3be5d650f02a8,bug/1401391, if not policies_spec: return None if not policies_spec: return None if not policies_spec: return None if not policies_spec: return None if 'retry_no' in policy_context: retry_no = policy_context['retry_no'] del policy_context['retry_no'] policy_context['retry_no'] = retry_no + 1," if ""retry_no"" in policy_context: retry_no = policy_context[""retry_no""] del policy_context[""retry_no""] retry_no += 1 policy_context.update({'retry_no': retry_no}) runtime_context.update({context_key: policy_context})",98,33
openstack%2Ftelemetry-specs~master~I5c1d6994edec171a5303244687564dd1f8466556,openstack/telemetry-specs,master,I5c1d6994edec171a5303244687564dd1f8466556,Add spec for self-disabled pollster,MERGED,2014-10-24 03:08:08.000000000,2014-12-11 11:44:44.000000000,2014-12-11 11:44:43.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 11235}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-10-24 03:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d752b482de2b2ced51fd1cbe486ac85187c6c0c7', 'message': 'Add spec for self-disabled pollster\n\nAvoid loading pollster if no required environment\n\nChange-Id: I5c1d6994edec171a5303244687564dd1f8466556\n'}, {'number': 2, 'created': '2014-11-24 10:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/e1014730ad15d8c0cfff041693d69f330a61778d', 'message': 'Add spec for self-disabled pollster\n\nAvoid loading pollster if no required environment\n\nChange-Id: I5c1d6994edec171a5303244687564dd1f8466556\n'}, {'number': 3, 'created': '2014-11-28 03:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/49694fd9fe8a99b5124287efcd38fbca2150428f', 'message': 'Add spec for self-disabled pollster\n\nAvoid loading pollster if no required environment\n\nChange-Id: I5c1d6994edec171a5303244687564dd1f8466556\n'}, {'number': 4, 'created': '2014-12-03 02:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/718e7d2641905c041dbada7586126edc3357173f', 'message': 'Add spec for self-disabled pollster\n\nAvoid loading pollster if no required environment\n\nChange-Id: I5c1d6994edec171a5303244687564dd1f8466556\n'}, {'number': 5, 'created': '2014-12-04 09:17:03.000000000', 'files': ['specs/kilo/self-disabled-pollster.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/1277c50d068a235fa35896f0498823f04c130e2a', 'message': 'Add spec for self-disabled pollster\n\nAvoid loading pollster if no required environment\n\nChange-Id: I5c1d6994edec171a5303244687564dd1f8466556\n'}]",11,130678,1277c50d068a235fa35896f0498823f04c130e2a,29,8,5,11235,,,0,"Add spec for self-disabled pollster

Avoid loading pollster if no required environment

Change-Id: I5c1d6994edec171a5303244687564dd1f8466556
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/78/130678/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/self-disabled-pollster.rst'],1,d752b482de2b2ced51fd1cbe486ac85187c6c0c7,bp/self-disable-pollster,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== Self-disabled Pollster ====================== https://blueprints.launchpad.net/ceilometer/+spec/self-disabled-pollster Avoid loading one pollster if required environment is not ready. Remove resources that cause continuous exception in polling time. Problem description =================== Currently pollsters are used in following way. 1. define via setup.cfg 2. load each pollster in initialization 3. pollster's get_samples get called in periodic way to collect metrics This fixed process is not flexible enough to handle various situation, like following cases: 1. One pollster depends on specific environment, e.g compute node pollsters need right hypervisor inspector, ipmi pollsters need ipmitool installed. Loading pollster unconditionally produces extra exceptions or dummy samples with minor performance drop. The perfect solution is that do not load the pollster if no required environment. 2. One pollster gets loaded and runs well, then some polling resource becomes unavailable, so the pollster fails to produce samples and probably throws exceptions with performance drop. We need detect such changes, then remove this resource from polling. Proposed change =============== Provides infrastructure to get pollster specific response then take different action. For case 1, need provide a hook called before pollster loading, to detect the hardware availability. Each pollster overwrites this hook if needed. For case 2, need provide a hook called before get_samples, to detect resources availability and remove missing ones. Resource detection should run in periodic way within same context as get_samples, or other context with lock for these resources. If new hook is not overwritten, pollsters act as original way. This minimize impact to existed pollsters. Alternatives ------------ We have alternatives regarding how deep the solution go. Only have case 1, or have both case 1 and 2. For case 2, only remove unavailable resources, or plus re-adding resources waking up. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- For case 1, we get performance improvement due to avoid loading unnecessary pollster. For case 2, we have both performance improvement due to removing unavailable resource, and performance drop due to periodic resource detection. The performance drop is tunable via resource detecting frequency. Other deployer impact --------------------- None Developer impact ---------------- Developer should implement hooks when adding new pollster in future. Implementation ============== Assignee(s) ----------- Primary assignee: edwin-zhai Other contributors: lianhao-lu Ongoing maintainer: edwin-zhai Work Items ---------- * Define new abstract function to check environment. Call this check function before load each pollster. * Add new environment checking function for required pollster * Implement periodic function to check resource availability before get_samples. Future lifecycle ================ Once this feature enabled, need test and bug fixing in next 2 releases to avoid regression Dependencies ============ None Testing ======= Need unit test Documentation Impact ==================== None References ========== None ",,166,0
openstack%2Foslo.messaging~stable%2Ficehouse~Id54ca1f448f466304b72b1695a5c646311bbd453,openstack/oslo.messaging,stable/icehouse,Id54ca1f448f466304b72b1695a5c646311bbd453,Make tests pass with random python hashseed,MERGED,2014-11-10 13:24:52.000000000,2014-12-11 11:43:16.000000000,2014-12-11 11:43:15.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 4146}, {'_account_id': 7536}, {'_account_id': 8415}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-11-10 13:24:52.000000000', 'files': ['tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1db42a1a68d99d2535905e651781de9065142ee6', 'message': 'Make tests pass with random python hashseed\n\nUnder python3 and latest tox a random python hashseed is used. Currently\noslo.messaging tests do not pass this because one test assumes the\nresulting list conversion from a list of lists has a specific order.\nSort both lists so that the order is explicit when checking for equality\nin this test. Doing so makes the test pass with a random python hash\nseed.\n\nNote I am not actually familiar enough with oslo.messaging to know if\nthis failure is correct and the drivers or something deeper should be\nreturning lists with an explicit order. This would be the case if order\nin these lists is important.\n\nConflicts:\n\ttests/test_notifier.py\n\nChange-Id: Id54ca1f448f466304b72b1695a5c646311bbd453\n(cherry picked from commit 220ccb816c75fe72f32a3112dae0b3c0790645fe)\n'}]",0,133468,1db42a1a68d99d2535905e651781de9065142ee6,11,6,1,9656,,,0,"Make tests pass with random python hashseed

Under python3 and latest tox a random python hashseed is used. Currently
oslo.messaging tests do not pass this because one test assumes the
resulting list conversion from a list of lists has a specific order.
Sort both lists so that the order is explicit when checking for equality
in this test. Doing so makes the test pass with a random python hash
seed.

Note I am not actually familiar enough with oslo.messaging to know if
this failure is correct and the drivers or something deeper should be
returning lists with an explicit order. This would be the case if order
in these lists is important.

Conflicts:
	tests/test_notifier.py

Change-Id: Id54ca1f448f466304b72b1695a5c646311bbd453
(cherry picked from commit 220ccb816c75fe72f32a3112dae0b3c0790645fe)
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/68/133468/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_notifier.py'],1,1db42a1a68d99d2535905e651781de9065142ee6,," self.assertEqual(sorted(pm.map.call_args[0][5]), sorted(['rpc', 'foo']))"," self.assertEqual(pm.map.call_args[0][5], ['rpc', 'foo'])",2,1
openstack%2Ftelemetry-specs~master~I34e483928a8d66641a62bdc041d0355a303879ab,openstack/telemetry-specs,master,I34e483928a8d66641a62bdc041d0355a303879ab,Implements: blueprint kafka-publisher,MERGED,2014-10-08 18:17:31.000000000,2014-12-11 11:40:02.000000000,2014-12-11 11:40:02.000000000,"[{'_account_id': 3}, {'_account_id': 681}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 8514}, {'_account_id': 12850}]","[{'number': 1, 'created': '2014-10-08 18:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/b976ea0f2fddade3f21a0b69d5e91a5b03a63856', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}, {'number': 2, 'created': '2014-10-08 18:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/ce00079c558334f8106cabb6005c67033a44c7e3', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}, {'number': 3, 'created': '2014-10-09 00:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/f0d41aabd81d64f3a018d24f3bbfd5c44fdb737b', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}, {'number': 4, 'created': '2014-10-16 20:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d8f088aad7e3e2cf1f6eb314e93a483d53569f54', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}, {'number': 5, 'created': '2014-10-20 18:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/91ec48725fa48ca1fd6b903ea7643598a61c95c9', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}, {'number': 6, 'created': '2014-11-13 19:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/ea13159e2e802df6b294ec89793dcc5a7c6e8877', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}, {'number': 7, 'created': '2014-12-07 02:31:01.000000000', 'files': ['specs/kilo/kafka-publisher.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/b387f26ba1336c3c4089daf35b300d7724be40bf', 'message': 'Implements: blueprint kafka-publisher\n\nChange-Id: I34e483928a8d66641a62bdc041d0355a303879ab\n'}]",28,126964,b387f26ba1336c3c4089daf35b300d7724be40bf,35,9,7,12850,,,0,"Implements: blueprint kafka-publisher

Change-Id: I34e483928a8d66641a62bdc041d0355a303879ab
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/64/126964/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/kafka-publisher.rst'],1,b976ea0f2fddade3f21a0b69d5e91a5b03a63856,bp/kafka-publisher,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Integrating Kafka Publisher into Ceilometer Publisher ========================================== https://blueprints.launchpad.net/ceilometer/+spec/kafka-publisher Apache kafka is messaging broker which enables publishing real-time metering data from more than one sources to clients with low-latency and high-throughput. Problem description =================== Ceilometer has to deal with a massive data with a high data rate. Kafka is able to deal with this problem, however Ceilometer does not have a support for kafka pubslisher. This means that to use Kafka service with Ceilometer, developers have to implement a Kafka publisher client by themselves. Proposed change =============== To reduce the cost of implementing Kafka publisher independently, Ceilometer has to provide the kafka publisher as a plugin. This automates publishing metering data, and developers only have to configure the kafka publisher plugin in pipeline.yaml file. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- Provide new options to specify kafka publiser as a ceilometer publisher Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <kshimamu> Other contributors: <yudupi> Ongoing maintainer: <kshimamu> Work Items ---------- * adding a kafka publisher as a ceilometer publisher Future lifecycle ================ None Dependencies ============ * https://github.com/mumrah/kafka-python.git Testing ======= None Documentation Impact ==================== None References ========== * Apache Kafka Project http://kafka.apache.org/ ",,124,0
openstack%2Fopenstack-ansible~master~I8c45ee13fb6b40e31bafa744f8fee5f4af7a90f5,openstack/openstack-ansible,master,I8c45ee13fb6b40e31bafa744f8fee5f4af7a90f5,Remove redundant [C|c]ritical|CRITICAL pattern,MERGED,2014-12-10 12:51:08.000000000,2014-12-11 11:30:18.000000000,2014-12-11 11:30:17.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-10 12:51:08.000000000', 'files': ['rpc_deployment/roles/logstash/templates/extras'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1ebd7e593924f8c04626764825a82289df2e1e96', 'message': ""Remove redundant [C|c]ritical|CRITICAL pattern\n\nThis patch removes '[C|c]ritical|CRITICAL' from the AUDITLOGLEVEL\npattern as this pattern is more completely covered by the later\n'[C|c]rit?(?:ical)?|CRIT?(?:ICAL)?' pattern.\n\nThis also removes a pattern bug as 'CRITICAL' should have been\n'CRITICAL|' anyway.\n\nChange-Id: I8c45ee13fb6b40e31bafa744f8fee5f4af7a90f5\nCloses-Bug: 1401091\n""}]",0,140666,1ebd7e593924f8c04626764825a82289df2e1e96,11,5,1,6816,,,0,"Remove redundant [C|c]ritical|CRITICAL pattern

This patch removes '[C|c]ritical|CRITICAL' from the AUDITLOGLEVEL
pattern as this pattern is more completely covered by the later
'[C|c]rit?(?:ical)?|CRIT?(?:ICAL)?' pattern.

This also removes a pattern bug as 'CRITICAL' should have been
'CRITICAL|' anyway.

Change-Id: I8c45ee13fb6b40e31bafa744f8fee5f4af7a90f5
Closes-Bug: 1401091
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/66/140666/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/logstash/templates/extras'],1,1ebd7e593924f8c04626764825a82289df2e1e96,bug/1401091,AUDITLOGLEVEL ([A|a]udit|AUDIT|[D|d]ebug|DEBUG|[N|n]otice|NOTICE|[I|i]nfo|INFO|[W|w]arn?(?:ing)?|WARN?(?:ING)?|[E|e]rr?(?:or)?|ERR?(?:OR)?|[C|c]rit?(?:ical)?|CRIT?(?:ICAL)?|[F|f]atal|FATAL|[S|s]evere|SEVERE|TRACE|[T|t]race),AUDITLOGLEVEL ([C|c]ritical|CRITICAL[A|a]udit|AUDIT|[D|d]ebug|DEBUG|[N|n]otice|NOTICE|[I|i]nfo|INFO|[W|w]arn?(?:ing)?|WARN?(?:ING)?|[E|e]rr?(?:or)?|ERR?(?:OR)?|[C|c]rit?(?:ical)?|CRIT?(?:ICAL)?|[F|f]atal|FATAL|[S|s]evere|SEVERE|TRACE|[T|t]race),1,1
openstack%2Fkeystone~master~Id723aef1542f890352394170833aba443057172b,openstack/keystone,master,Id723aef1542f890352394170833aba443057172b,remove implemented TODO in catalog/backends/sql.py,ABANDONED,2014-10-21 07:17:34.000000000,2014-12-11 11:25:12.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-21 07:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/28f21b06d35aecc49e44b055af44c5a35ba468d2', 'message': 'remove implemented TODO in catalog/backends/sql.py\n\nThe bug: https://bugs.launchpad.net/keystone/+bug/1265071 had been\nfixed, the TODO comments should be removed.\n\nChange-Id: Id723aef1542f890352394170833aba443057172b\n'}, {'number': 2, 'created': '2014-10-27 01:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/17578cbdace079a6b4c874386664f1e58b624101', 'message': 'remove implemented TODO in catalog/backends/sql.py\n\nThe bug: https://bugs.launchpad.net/keystone/+bug/1265071 had been\nfixed, the TODO comments should be removed.\n\nChange-Id: Id723aef1542f890352394170833aba443057172b\n'}, {'number': 3, 'created': '2014-10-28 01:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23522b228c7164d8f3ee0a434edc87a33e34d105', 'message': 'remove implemented TODO in catalog/backends/sql.py\n\nThe bug: https://bugs.launchpad.net/keystone/+bug/1265071 had been\nfixed, the TODO comments should be removed.\n\nChange-Id: Id723aef1542f890352394170833aba443057172b\n'}, {'number': 4, 'created': '2014-10-28 03:42:38.000000000', 'files': ['keystone/catalog/schema.py', 'keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/sql.py', 'keystone/tests/test_validation.py', 'keystone/tests/test_backend_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6c801c5517b7c2b31e2cb3598333e8ec51543e7d', 'message': 'remove implemented TODO in catalog/backends/sql.py\n\nThe bug: https://bugs.launchpad.net/keystone/+bug/1265071 had been\nfixed, the TODO comments should be removed.\nAnd remove extra attribute from region according to the todo comment.\n\nChange-Id: Id723aef1542f890352394170833aba443057172b\n'}]",5,129830,6c801c5517b7c2b31e2cb3598333e8ec51543e7d,21,8,4,9101,,,0,"remove implemented TODO in catalog/backends/sql.py

The bug: https://bugs.launchpad.net/keystone/+bug/1265071 had been
fixed, the TODO comments should be removed.
And remove extra attribute from region according to the todo comment.

Change-Id: Id723aef1542f890352394170833aba443057172b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/30/129830/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/catalog/backends/sql.py'],1,28f21b06d35aecc49e44b055af44c5a35ba468d2,todo,," # TODO(jaypipes): I think it's absolutely stupid that every single model # is required to have an ""extra"" column because of the # DictBase in the keystone.common.sql.core module. Forcing # tables to have pointless columns in the database is just # bad. Remove all of this extra JSON blob stuff. # See: https://bugs.launchpad.net/keystone/+bug/1265071",0,6
openstack%2Ffuel-web~stable%2F6.0~Ife1a6df8746930c56be2e661de2ada41815c02fb,openstack/fuel-web,stable/6.0,Ife1a6df8746930c56be2e661de2ada41815c02fb,Make bonding feature available only in experimental mode,MERGED,2014-12-11 10:13:50.000000000,2014-12-11 10:41:15.000000000,2014-12-11 10:41:15.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-12-11 10:13:50.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/01f1962638148357a0d6d785f5689b63916eee63', 'message': 'Make bonding feature available only in experimental mode\n\nChange-Id: Ife1a6df8746930c56be2e661de2ada41815c02fb\nCloses-Bug: #1401260\n'}]",0,140999,01f1962638148357a0d6d785f5689b63916eee63,12,7,1,8735,,,0,"Make bonding feature available only in experimental mode

Change-Id: Ife1a6df8746930c56be2e661de2ada41815c02fb
Closes-Bug: #1401260
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/99/140999/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js'],1,01f1962638148357a0d6d785f5689b63916eee63,," var isExperimental = _.contains(app.version.get('feature_groups'), 'experimental'); var iserDisabled = this.model.get('settings').get('storage.iser.value') != true; return !this.isLocked() && isExperimental && this.model.get('net_provider') == 'neutron' && iserDisabled && mellanoxSriovDisabled;", var iserDisabled = this.model.get('settings').get('storage.iser.value') != true; return !this.isLocked() && this.model.get('net_provider') == 'neutron' && iserDisabled && mellanoxSriovDisabled;,3,2
openstack%2Fglance~master~I05d475049f96057b06d3ae14ec33e0125b9c4dd5,openstack/glance,master,I05d475049f96057b06d3ae14ec33e0125b9c4dd5,Start server message changed,MERGED,2014-09-15 04:24:28.000000000,2014-12-11 10:40:26.000000000,2014-12-11 10:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6493}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8759}, {'_account_id': 9533}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 12363}, {'_account_id': 12395}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-09-15 04:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6b1f4594dcd07efc743dff0acb247d73b457f9fa', 'message': ""Start server message changed\n\nThe way that the user message was generated when it's launched a\nserver providing a configuration file was causing an error.  This is\nbecause the Message class doesn't support concatenation.\n\nChange-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5\nCloses-Bug: #1369390\n""}, {'number': 2, 'created': '2014-09-15 16:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/acd15626cf8ed7a2416a67b2fc972727017cf646', 'message': ""Start server message changed\n\nThe way that the user message was generated when it's launched a\nserver providing a configuration file was causing an error.  This is\nbecause the Message class doesn't support concatenation.\n\nChange-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5\nCloses-Bug: #1369390\n""}, {'number': 3, 'created': '2014-09-15 23:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6935d57ff3a530b1de3fd344d6f1f3b4423079eb', 'message': ""Start server message changed\n\nThe way that the user message was generated when it's launched a\nserver providing a configuration file was causing an error.  This is\nbecause the Message class doesn't support concatenation.\n\nChange-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5\nCloses-Bug: #1369390\n""}, {'number': 4, 'created': '2014-10-03 05:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/24e188263846103cf14b99b290d36e6d2ebc8fa6', 'message': ""Start server message changed\n\nThe way that the user message was generated when it's launched a\nserver providing a configuration file was causing an error. This is\nbecause the Message class doesn't support concatenation.\n\nChange-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5\nCloses-Bug: #1369390\n""}, {'number': 5, 'created': '2014-10-03 15:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6b10a70614066ad0fdf333763b436e8c2f6fe39d', 'message': ""Start server message changed\n\nThe way that the user message was generated when it's launched a\nserver providing a configuration file was causing an error. This is\nbecause the Message class doesn't support concatenation.\n\nChange-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5\nCloses-Bug: #1369390\n""}, {'number': 6, 'created': '2014-12-08 01:07:05.000000000', 'files': ['glance/cmd/control.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/21402a943a2f0199870f4f6d243c6c2f7bbab91b', 'message': ""Start server message changed\n\nThe way that the user message was generated when it's launched a\nserver providing a configuration file was causing an error. This is\nbecause the Message class doesn't support concatenation.\n\nChange-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5\nCloses-Bug: #1369390\n""}]",4,121442,21402a943a2f0199870f4f6d243c6c2f7bbab91b,37,12,6,8726,,,0,"Start server message changed

The way that the user message was generated when it's launched a
server providing a configuration file was causing an error. This is
because the Message class doesn't support concatenation.

Change-Id: I05d475049f96057b06d3ae14ec33e0125b9c4dd5
Closes-Bug: #1369390
",git fetch https://review.opendev.org/openstack/glance refs/changes/42/121442/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/cmd/control.py'],1,6b1f4594dcd07efc743dff0acb247d73b457f9fa,bug/1369390," msg = ('%(verb)sing %(serv)s') % {'verb': verb, 'serv': server} print(_(msg))"," msg = (_('%(verb)sing %(serv)s') % {'verb': verb, 'serv': server}) print(msg)",2,2
openstack%2Fglance~master~I9b4571906d39bcdb35048caa58d16ad5e888cce4,openstack/glance,master,I9b4571906d39bcdb35048caa58d16ad5e888cce4,Alter models and add migration,MERGED,2014-08-13 14:53:59.000000000,2014-12-11 10:39:44.000000000,2014-12-11 10:39:43.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5347}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 7763}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9236}, {'_account_id': 9751}, {'_account_id': 11356}, {'_account_id': 12363}, {'_account_id': 12395}]","[{'number': 1, 'created': '2014-08-13 14:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2bcf9c28b492cfc782fe300493f0595beb4baee2', 'message': 'Alter models and add migration\n\nUpdate models.py and add migration script to get rid\nof the differences between them.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 2, 'created': '2014-08-21 13:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2b127e9a9f78f6e176ec58069e07ce53e6897190', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 3, 'created': '2014-08-21 13:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f182d5f28885019bfd65f3fdaa56898324ad1bec', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 4, 'created': '2014-08-26 10:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/31b6764f49f4f3acd2196f7c482afb7e4425383a', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 5, 'created': '2014-08-26 13:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6bc99ad4873fb35219fa061ad800adedf62e4a8b', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 6, 'created': '2014-08-27 13:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8b42b85d108aabff8048a775457d7589cf2f7195', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 7, 'created': '2014-08-27 14:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/13eeabf32c5cfad83c38836e85e88469976e3e04', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 8, 'created': '2014-08-27 14:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4d7b533c7acb803ce4b367f097646ea242129ee6', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 9, 'created': '2014-08-28 16:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fcae390dd797a7d4b8808556cdb8b794e1007455', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 10, 'created': '2014-08-29 10:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7d295d0e2e91f4a9ecdd882cf68fafac6212291e', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 11, 'created': '2014-09-01 14:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b75027ae3fb4f2f2b39372ba3e73a411d560fdfc', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 12, 'created': '2014-09-02 10:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/084c03782f952c5d3988f80ee2170eac83e0a799', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 13, 'created': '2014-09-04 11:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1367ca1699613b450b6bfaa66f198944c571bca4', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-bug: 1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 14, 'created': '2014-09-04 11:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/353bc7ba4dd5f16f8055b897baa974f3705c5dfd', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 15, 'created': '2014-09-15 12:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/454508faede816d87c76da3ac0bfa9aaeab6562b', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 16, 'created': '2014-10-06 13:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fab3815311424ec0412bfecc5d283bec2beb2d59', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 17, 'created': '2014-10-07 12:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/98ef19469e6335afa532f38276218170965fa9e2', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 18, 'created': '2014-10-09 12:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a6fc4274e59e879f7b0c85966fb5ee289263b93f', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 19, 'created': '2014-10-10 11:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/89454acf7751f0f1e7f7bc201910f43ea932e167', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 20, 'created': '2014-11-20 14:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/451f1a70d2ae567f8825f36a735d99685a0f5222', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 21, 'created': '2014-11-24 12:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ab2ceb68465274d515363bea0a11a8ea4c1a6b22', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 22, 'created': '2014-11-25 12:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6b9f2664b9ef88d40afd52cdf99811b3fe7b2683', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\ndatabase schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 23, 'created': '2014-11-25 13:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8c89d1a1f09bc308fdd30300d0539000fc27725a', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\na database schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}, {'number': 24, 'created': '2014-11-25 16:38:56.000000000', 'files': ['glance/tests/unit/test_migrations.py', 'glance/db/sqlalchemy/migrate_repo/versions/037_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/037_sqlite_upgrade.sql', 'glance/db/sqlalchemy/models.py', 'glance/db/sqlalchemy/migrate_repo/versions/037_add_changes_to_satisfy_models.py', 'glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/9def368d07f9db8698c3c3b8b4db92aadd78dcbb', 'message': 'Alter models and add migration\n\nWe must have correct models i.e. models that correspond\na database schema to use sqlalchemy features.\nUpdate models.py and add migration script to correct\ndatabase schema and get rid of the difference between\nschema and models.\n\nPartial-Bug: #1365436\nChange-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4\n'}]",51,113916,9def368d07f9db8698c3c3b8b4db92aadd78dcbb,101,20,24,12363,,,0,"Alter models and add migration

We must have correct models i.e. models that correspond
a database schema to use sqlalchemy features.
Update models.py and add migration script to correct
database schema and get rid of the difference between
schema and models.

Partial-Bug: #1365436
Change-Id: I9b4571906d39bcdb35048caa58d16ad5e888cce4
",git fetch https://review.opendev.org/openstack/glance refs/changes/16/113916/5 && git format-patch -1 --stdout FETCH_HEAD,"['glance/db/sqlalchemy/migrate_repo/versions/035_add_changes_to_satisfy_models.py', 'glance/db/sqlalchemy/models.py']",2,2bcf9c28b492cfc782fe300493f0595beb4baee2,bug/1365436,"from sqlalchemy import sql nullable=True, onupdate=lambda: timeutils.utcnow()) protected = Column(Boolean, nullable=False, default=False, server_default=sql.expression.false()) status = Column(String(30), server_default='active', nullable=False) status = Column(String(20), nullable=False, default=""pending"", server_default='pending') type = Column(String(30), nullable=False, default='N/A', server_default='N/A') status = Column(String(30), nullable=False, default='pending', server_default='pending')"," nullable=False, onupdate=lambda: timeutils.utcnow()) protected = Column(Boolean, nullable=False, default=False) status = Column(String(30), default='active', nullable=False) status = Column(String(20), nullable=False, default=""pending"") type = Column(String(30)) status = Column(String(30))",110,6
openstack%2Ffuel-web~master~I8025f7272d428d120044c899034d9fbecf8215cc,openstack/fuel-web,master,I8025f7272d428d120044c899034d9fbecf8215cc,Generate password for wsrep user,MERGED,2014-11-26 16:46:41.000000000,2014-12-11 10:38:29.000000000,2014-12-11 10:38:28.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11082}, {'_account_id': 11090}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-11-26 16:46:41.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/226a59fe51fd8001423c2f19051881366f904efa', 'message': 'Generate password for wsrep user\n\n* Generate password for wsrep user which is used for galera replication.\n\nPartial-Bug: 1373630\nChange-Id: I8025f7272d428d120044c899034d9fbecf8215cc\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",0,137400,226a59fe51fd8001423c2f19051881366f904efa,16,8,1,11090,,,0,"Generate password for wsrep user

* Generate password for wsrep user which is used for galera replication.

Partial-Bug: 1373630
Change-Id: I8025f7272d428d120044c899034d9fbecf8215cc
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/00/137400/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,226a59fe51fd8001423c2f19051881366f904efa,bug/1373630," wsrep_password: generator: ""password""",,2,0
openstack%2Ffuel-web~master~I75056a593ee46f302c9916cc1201131965c1f657,openstack/fuel-web,master,I75056a593ee46f302c9916cc1201131965c1f657,run_tests.sh option fixes,MERGED,2014-11-24 15:14:10.000000000,2014-12-11 10:37:47.000000000,2014-12-11 10:37:45.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11082}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-11-24 15:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/234397743aa96610fa70d03c614b520364c23a7b', 'message': 'run_tests.sh option fixes\n\n* Options sorted alphabetically to find them more easily.\n* Duplicated -l option changed to -k for tasklib tests.\n\nChange-Id: I75056a593ee46f302c9916cc1201131965c1f657\n'}, {'number': 2, 'created': '2014-11-24 15:54:00.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b6331ee97f7e13b8440bdb4188d168d6c2a946e9', 'message': 'run_tests.sh option fixes\n\n* Options sorted alphabetically to find them more easily.\n* Duplicated -l option changed to -k for tasklib tests.\n\nChange-Id: I75056a593ee46f302c9916cc1201131965c1f657\n'}]",3,136787,b6331ee97f7e13b8440bdb4188d168d6c2a946e9,26,10,2,13445,,,0,"run_tests.sh option fixes

* Options sorted alphabetically to find them more easily.
* Duplicated -l option changed to -k for tasklib tests.

Change-Id: I75056a593ee46f302c9916cc1201131965c1f657
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/87/136787/2 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,234397743aa96610fa70d03c614b520364c23a7b,run-tests-option-fix," echo "" -h, --help Print this usage message"" echo "" -k, --tasklib Run tasklib unit and functional tests"" echo "" -n, --nailgun Run NAILGUN both unit and integration tests"" echo "" -N, --no-nailgun Don't run NAILGUN tests"" echo "" -p, --flake8 Run FLAKE8 and HACKING compliance check"" echo "" -P, --no-flake8 Don't run static code checks"" echo "" -s, --shotgun Run SHOTGUN tests"" echo "" -S, --no-shotgun Don't run SHOTGUN tests"" echo "" -u, --upgrade Run tests for UPGRADE system"" echo "" -U, --no-upgrade Don't run tests for UPGRADE system"" echo "" -w, --webui Run WEB-UI tests"" echo "" -W, --no-webui Don't run WEB-UI tests"" -k|--tasklib) tasklib_tests=1;;"," echo "" -n, --nailgun Run NAILGUN both unit and integration tests"" echo "" -l, --tasklib Run tasklib unit and functional tests"" echo "" -N, --no-nailgun Don't run NAILGUN tests"" echo "" -w, --webui Run WEB-UI tests"" echo "" -W, --no-webui Don't run WEB-UI tests"" echo "" -u, --upgrade Run tests for UPGRADE system"" echo "" -U, --no-upgrade Don't run tests for UPGRADE system"" echo "" -s, --shotgun Run SHOTGUN tests"" echo "" -S, --no-shotgun Don't run SHOTGUN tests"" echo "" -p, --flake8 Run FLAKE8 and HACKING compliance check"" echo "" -P, --no-flake8 Don't run static code checks"" echo "" -h, --help Print this usage message"" -l|--tasklib) tasklib_tests=1;;",13,13
openstack%2Ffuel-web~master~Ife1a6df8746930c56be2e661de2ada41815c02fb,openstack/fuel-web,master,Ife1a6df8746930c56be2e661de2ada41815c02fb,Make bonding feature available only in experimental mode,MERGED,2014-12-11 10:13:21.000000000,2014-12-11 10:36:36.000000000,2014-12-11 10:36:36.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-12-11 10:13:21.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b6772f6ba0a1198cd05ab5ae0168e7165ff85269', 'message': 'Make bonding feature available only in experimental mode\n\nChange-Id: Ife1a6df8746930c56be2e661de2ada41815c02fb\nCloses-Bug: #1401260\n'}]",0,140998,b6772f6ba0a1198cd05ab5ae0168e7165ff85269,14,7,1,8735,,,0,"Make bonding feature available only in experimental mode

Change-Id: Ife1a6df8746930c56be2e661de2ada41815c02fb
Closes-Bug: #1401260
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/98/140998/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.js'],1,b6772f6ba0a1198cd05ab5ae0168e7165ff85269,bug/1401260," var isExperimental = _.contains(app.version.get('feature_groups'), 'experimental'); var iserDisabled = this.model.get('settings').get('storage.iser.value') != true; return !this.isLocked() && isExperimental && this.model.get('net_provider') == 'neutron' && iserDisabled && mellanoxSriovDisabled;", var iserDisabled = this.model.get('settings').get('storage.iser.value') != true; return !this.isLocked() && this.model.get('net_provider') == 'neutron' && iserDisabled && mellanoxSriovDisabled;,3,2
openstack%2Ffuel-stats~master~I416e9815b8b4ace7b14c671b643d033e334b8326,openstack/fuel-stats,master,I416e9815b8b4ace7b14c671b643d033e334b8326,"Indexing of request_data, response_data disabled",MERGED,2014-12-10 14:19:12.000000000,2014-12-11 10:34:15.000000000,2014-12-11 10:34:15.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}]","[{'number': 1, 'created': '2014-12-10 14:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-stats/commit/3cfa458de04e1f300a769579208d70f42bced1b8', 'message': 'Indexing of request_data, response_data disabled\n\nIn old style action logs we have mixing of\nfield types in the lists inside request_data and response_data.\nFormat of action_logs is already changed. So we should just\nmigrate old-style action_logs into Elasticsearch.\n\nChange-Id: I416e9815b8b4ace7b14c671b643d033e334b8326\nCloses-Bug: #1401120\n'}, {'number': 2, 'created': '2014-12-10 14:22:37.000000000', 'files': ['migration/migration/test/test_es_mapping.py', 'migration/migration/config.py'], 'web_link': 'https://opendev.org/openstack/fuel-stats/commit/31f75bd5c6fc44760f2c28d690dd6bd4a057bf7a', 'message': 'Indexing of request_data, response_data disabled\n\nIn old style action logs we have mixing of\nfield types in the lists inside request_data and response_data.\nFormat of action_logs is already changed. So we should just\nmigrate old-style action_logs into Elasticsearch.\n\nCloses-Bug: #1401120\nChange-Id: I416e9815b8b4ace7b14c671b643d033e334b8326\n'}]",0,140692,31f75bd5c6fc44760f2c28d690dd6bd4a057bf7a,14,6,2,10959,,,0,"Indexing of request_data, response_data disabled

In old style action logs we have mixing of
field types in the lists inside request_data and response_data.
Format of action_logs is already changed. So we should just
migrate old-style action_logs into Elasticsearch.

Closes-Bug: #1401120
Change-Id: I416e9815b8b4ace7b14c671b643d033e334b8326
",git fetch https://review.opendev.org/openstack/fuel-stats refs/changes/92/140692/2 && git format-patch -1 --stdout FETCH_HEAD,"['migration/migration/test/test_es_mapping.py', 'migration/migration/config.py']",2,3cfa458de04e1f300a769579208d70f42bced1b8,action_logs_migration_fix," ""request_data"": { ""type"": ""object"", ""properties"": { ""data"": {""enabled"": False} } }, ""response_data"": { ""type"": ""object"", ""properties"": { ""data"": {""enabled"": False} } },"," ""request_data"": {""type"": ""object""}, ""response_data"": {""type"": ""object""},",44,12
openstack%2Ftricircle~master~I404a499ae60a6d23fe61682bf1f9ea3529112f1c,openstack/tricircle,master,I404a499ae60a6d23fe61682bf1f9ea3529112f1c,"Revert ""delete spaces in l2_proxy.py file""",ABANDONED,2014-12-11 10:30:03.000000000,2014-12-11 10:31:03.000000000,,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2014-12-11 10:30:03.000000000', 'files': ['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/2561c2e6f8685284738e99699beab80fd836252e', 'message': 'Revert ""delete spaces in l2_proxy.py file""\n\nThis reverts commit 7597fd6e6590b16eff72b6c64395a43025ccc3f4.\n\nChange-Id: I404a499ae60a6d23fe61682bf1f9ea3529112f1c\n'}]",0,141004,2561c2e6f8685284738e99699beab80fd836252e,3,2,1,9778,,,0,"Revert ""delete spaces in l2_proxy.py file""

This reverts commit 7597fd6e6590b16eff72b6c64395a43025ccc3f4.

Change-Id: I404a499ae60a6d23fe61682bf1f9ea3529112f1c
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/04/141004/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'],1,2561c2e6f8685284738e99699beab80fd836252e,, pagination_marker=None): , pagination_marker=None):,1,1
openstack%2Ftricircle~master~Ic73c6ebf2216e9a9acd29e4c7f0e0638dd4f5bc4,openstack/tricircle,master,Ic73c6ebf2216e9a9acd29e4c7f0e0638dd4f5bc4,delete spaces in l2_proxy.py file,MERGED,2014-12-11 09:54:12.000000000,2014-12-11 10:30:03.000000000,2014-12-11 09:54:42.000000000,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2014-12-11 09:54:12.000000000', 'files': ['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/7597fd6e6590b16eff72b6c64395a43025ccc3f4', 'message': 'delete spaces in l2_proxy.py file\n\nChange-Id: Ic73c6ebf2216e9a9acd29e4c7f0e0638dd4f5bc4\n'}]",0,140992,7597fd6e6590b16eff72b6c64395a43025ccc3f4,7,2,1,9778,,,0,"delete spaces in l2_proxy.py file

Change-Id: Ic73c6ebf2216e9a9acd29e4c7f0e0638dd4f5bc4
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/92/140992/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'],1,7597fd6e6590b16eff72b6c64395a43025ccc3f4,, pagination_marker=None):, pagination_marker=None): ,1,1
openstack%2Ffuel-main~stable%2F6.0~I0d11c23f20a97623efcd670fb499e2a435f44470,openstack/fuel-main,stable/6.0,I0d11c23f20a97623efcd670fb499e2a435f44470,Add additional wait for galera get synced,MERGED,2014-12-10 14:08:37.000000000,2014-12-11 10:27:53.000000000,2014-12-11 10:27:53.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-10 14:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/edb2b322264a8f8885e93ae98cfe5b33f49d3d54', 'message': ""Add additional wait for galera get synced\n\n- After killing mysql and starting mysql daemon again\nwe need to wait until Galera is synced because if it's\nnot synced and we kill mysql on next controller\nGalera will lose its quorum\n\nChange-Id: I0d11c23f20a97623efcd670fb499e2a435f44470\nCloses-Bug: #1400380\n(cherry picked from commit 87359485d88e857aead80d57841b86bd59fa7d12)\n""}, {'number': 2, 'created': '2014-12-11 08:47:04.000000000', 'files': ['fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cc3b95a609959c800260f381264ba74d8d824d39', 'message': ""Add additional wait for galera get synced\n\n- After killing mysql and starting mysql daemon again\nwe need to wait until Galera is synced because if it's\nnot synced and we kill mysql on next controller\nGalera will lose its quorum\n\nChange-Id: I0d11c23f20a97623efcd670fb499e2a435f44470\nCloses-Bug: #1400380\n(cherry picked from commit 87359485d88e857aead80d57841b86bd59fa7d12)\n""}]",1,140685,cc3b95a609959c800260f381264ba74d8d824d39,17,5,2,10136,,,0,"Add additional wait for galera get synced

- After killing mysql and starting mysql daemon again
we need to wait until Galera is synced because if it's
not synced and we kill mysql on next controller
Galera will lose its quorum

Change-Id: I0d11c23f20a97623efcd670fb499e2a435f44470
Closes-Bug: #1400380
(cherry picked from commit 87359485d88e857aead80d57841b86bd59fa7d12)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/85/140685/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/checkers.py'],1,edb2b322264a8f8885e93ae98cfe5b33f49d3d54,(detached," check_galera_cmd = (""mysql --connect_timeout=5 -sse \""SELECT"" "" VARIABLE_VALUE FROM"" "" information_schema.GLOBAL_STATUS"" "" WHERE VARIABLE_NAME"" "" = 'wsrep_local_state_comment';\"""") try: wait(lambda: ''.join(remote.execute( check_galera_cmd)['stdout']).rstrip() == 'Synced', timeout=600) except TimeoutError: logger.error('galera status is {0}'.format(''.join(remote.execute( check_galera_cmd)['stdout']).rstrip())) raise",,12,0
openstack%2Foslo.db~master~I976f8b8a7b3d31c7046ed53f6564c58af408b1b2,openstack/oslo.db,master,I976f8b8a7b3d31c7046ed53f6564c58af408b1b2,Updated from global requirements,MERGED,2014-12-11 07:19:26.000000000,2014-12-11 10:27:41.000000000,2014-12-11 10:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-12-11 07:19:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c6b352e50dc8b16c48b8cd53cc7af6815a2ead70', 'message': 'Updated from global requirements\n\nChange-Id: I976f8b8a7b3d31c7046ed53f6564c58af408b1b2\n'}]",0,140948,c6b352e50dc8b16c48b8cd53cc7af6815a2ead70,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I976f8b8a7b3d31c7046ed53f6564c58af408b1b2
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/48/140948/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c6b352e50dc8b16c48b8cd53cc7af6815a2ead70,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fcinder~stable%2Ficehouse~I188443730ce077a8117812f1089db36ece184e7a,openstack/cinder,stable/icehouse,I188443730ce077a8117812f1089db36ece184e7a,Fixes HostTestCase failures due to slow test run,MERGED,2014-12-09 19:26:48.000000000,2014-12-11 10:27:33.000000000,2014-12-11 10:27:32.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2472}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 10621}]","[{'number': 1, 'created': '2014-12-09 19:26:48.000000000', 'files': ['cinder/tests/api/contrib/test_hosts.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/97a7e20322499ffc748346d6ff1446d3a03e32d6', 'message': 'Fixes HostTestCase failures due to slow test run\n\nStatus check in _list_hosts() fails if tests take longer than the\nservice_down_time.\n\nStubbing utcnow() guarantees that status check passes for tests.\n\nChange-Id: I188443730ce077a8117812f1089db36ece184e7a\nCloses-Bug: 1292643\n(cherry picked from commit 4465cd20b42c0db0efd405b57d9dc141bf6ed918)\n'}]",0,140450,97a7e20322499ffc748346d6ff1446d3a03e32d6,7,6,1,7878,,,0,"Fixes HostTestCase failures due to slow test run

Status check in _list_hosts() fails if tests take longer than the
service_down_time.

Stubbing utcnow() guarantees that status check passes for tests.

Change-Id: I188443730ce077a8117812f1089db36ece184e7a
Closes-Bug: 1292643
(cherry picked from commit 4465cd20b42c0db0efd405b57d9dc141bf6ed918)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/140450/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/api/contrib/test_hosts.py'],1,97a7e20322499ffc748346d6ff1446d3a03e32d6,,"curr_time = datetime.datetime(2013, 7, 3, 0, 0, 1)def stub_utcnow(): return datetime.datetime(2013, 7, 3, 0, 0, 2) self.stubs.Set(timeutils, 'utcnow', stub_utcnow)",curr_time = timeutils.utcnow(),6,1
openstack%2Fheat-specs~master~I84a8ec283c3adbfbabade5cfc342b7c944e51f68,openstack/heat-specs,master,I84a8ec283c3adbfbabade5cfc342b7c944e51f68,Use oslo-versioned-objects to help with upgrades,MERGED,2014-10-31 04:34:30.000000000,2014-12-11 10:16:50.000000000,2014-12-11 10:16:49.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-10-31 04:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/83abd334d40e9372c4341850134716eeab92a7ee', 'message': 'Use oslo-versioned-objects to help with upgrades\n\nChange-Id: I84a8ec283c3adbfbabade5cfc342b7c944e51f68\n'}, {'number': 2, 'created': '2014-11-25 03:40:32.000000000', 'files': ['specs/kilo/versioned-objects.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/b643bfc4bede767ea0513af7ff4fd9e44e1fff4c', 'message': 'Use oslo-versioned-objects to help with upgrades\n\nChange-Id: I84a8ec283c3adbfbabade5cfc342b7c944e51f68\n'}]",1,132157,b643bfc4bede767ea0513af7ff4fd9e44e1fff4c,14,5,2,4715,,,0,"Use oslo-versioned-objects to help with upgrades

Change-Id: I84a8ec283c3adbfbabade5cfc342b7c944e51f68
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/57/132157/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/versioned-objects.rst'],1,83abd334d40e9372c4341850134716eeab92a7ee,oslo-versioned-obj,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ============================================================== Use oslo-versioned-objects to help with dealing with upgrades. ============================================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/versioned-objects Problem description =================== We are looking to impove the way we deal with versioning (of all sorts db/rpc/rest/templates/plugins). Nova has come up with the idea of versioned objects, that Ironic has also now used. This has now been proposed as an oslo library: https://review.openstack.org/#/c/127532/ https://etherpad.openstack.org/p/kilo-crossproject-upgrades-and-versioning This will help us deal with RPC client/server been at different versions and to deal with DB schema been at a different version than expected. NOTE: There is more to do here, this is just a place holder until we get more info from the discussions at summit. Proposed change =============== Use oslo-versioned-objects to pass though RPC API and DB API inorder to deal with changes in schema/API. Alternatives ------------ Implementation ============== Assignee(s) ----------- Primary assignee: Angus Salkeld <asalkeld@mirantis.com> <others are welcome to help out> Milestones ---------- Target Milestone for completion: Kilo sometime Work Items ---------- - Help out (if needed) with oslo-versioned-objects - TODO Dependencies ============ * oslo-versioned-objects ",,76,0
openstack%2Ffuel-web~master~I5059b299f126bad744a5b49d227fc3fa66cc42a8,openstack/fuel-web,master,I5059b299f126bad744a5b49d227fc3fa66cc42a8,Trying nightwatch for UI tests,ABANDONED,2014-08-18 13:23:42.000000000,2014-12-11 10:15:46.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-08-18 13:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ca6b7c9dbe339311f912aa0a1ea682d77fce533a', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 2, 'created': '2014-08-18 15:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/226a20dc2742e025b8de3650e0dbb4350621409d', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 3, 'created': '2014-08-18 16:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ba8b40481971438bbcf8fd9ec3efb0891008c727', 'message': '[tests] Trying Nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 4, 'created': '2014-08-21 12:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bf555219e469c4c4ec56987d1d1f56e65aff17ca', 'message': '[tests] Trying Nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 5, 'created': '2014-08-21 15:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f2d4c9a13d77656fc60498b0152110378230b4ed', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 6, 'created': '2014-08-21 16:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7a2d7586d652be61b8ff932d0edfdc8e6eeecba1', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 7, 'created': '2014-09-15 17:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e9c5d631fc72dc9500e11e885352d4b5a005c350', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 8, 'created': '2014-09-15 19:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b331ea5a471402b197d1acaca447663e2a618f09', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 9, 'created': '2014-09-15 23:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/863302a6f489968a8865a6dde3188cfda4d36f03', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 10, 'created': '2014-09-20 01:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/65e8d0c19adde23c0cce38dd02ddeb5cfb0a38da', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 11, 'created': '2014-09-25 15:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/29b255a347354cd8af48652f31c5e32241289d18', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n- needed updating ./run-tests.sh to drop/syncdb and start naigun in fake mode\n- may be needed change from firefox browser to phantomjs browser\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 12, 'created': '2014-10-01 07:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/018cc0a964227c6e8d7e927218b5ffc08038336b', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n- needed updating ./run-tests.sh to drop/syncdb and start naigun in fake mode\n- may be needed change from firefox browser to phantomjs browser\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 13, 'created': '2014-10-01 09:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/521a2b032b4eba103fde64a92121991878cd296d', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}, {'number': 14, 'created': '2014-10-03 11:30:02.000000000', 'files': ['nailgun/Gruntfile.js', 'nailgun/ui_tests/commands/start.js', 'nailgun/package.json', 'nailgun/ui_tests/test_cluster_network.js', 'nailgun/ui_tests/test_cluster_settings.js', 'nailgun/ui_tests/test_cluster_stop_reset_deployment.js', 'nailgun/ui_tests/test_node_disk.js', 'nailgun/ui_tests/tests/test_cluster_creation.js', 'run_tests.sh', 'nailgun/ui_tests/test_cluster_logs.js', 'nailgun/npm-shrinkwrap.json', 'nailgun/ui_tests/sinon-server.js', 'nailgun/ui_tests/test_clusters.js', 'nailgun/ui_tests/helpers.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/facbb631e99daef7ad5cb9e60f74cc7e9f80f008', 'message': 'Trying nightwatch for UI tests\n\n- added first test\n\nChange-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8\n'}]",0,114967,facbb631e99daef7ad5cb9e60f74cc7e9f80f008,79,7,14,9091,,,0,"Trying nightwatch for UI tests

- added first test

Change-Id: I5059b299f126bad744a5b49d227fc3fa66cc42a8
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/67/114967/3 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/tests/tests_one.js', 'nailgun/package.json', 'nailgun/npm-shrinkwrap.json']",3,ca6b7c9dbe339311f912aa0a1ea682d77fce533a,(detached," ""from"": ""colors@~0.6.0-1"" ""from"": ""nopt@~1.0.0"", ""from"": ""grunt-bower-task@~0.4.0"", ""version"": ""1.3.9"", ""from"": ""abbrev@1"" ""from"": ""archy@0.0.2"" ""version"": ""0.2.11"", ""from"": ""async@~0.2.8"" ""from"": ""esprima@~1.0.4"" ""version"": ""0.5.1"", ""from"": ""chalk@~0.5.0"", ""dependencies"": { ""ansi-styles"": { ""version"": ""1.1.0"", ""from"": ""ansi-styles@^1.1.0"" }, ""escape-string-regexp"": { ""version"": ""1.0.1"", ""from"": ""escape-string-regexp@^1.0.0"" }, ""has-ansi"": { ""version"": ""0.1.0"", ""from"": ""has-ansi@^0.1.0"", ""dependencies"": { ""ansi-regex"": { ""version"": ""0.2.1"", ""from"": ""ansi-regex@^0.2.1"" } } ""version"": ""0.3.0"", ""from"": ""strip-ansi@^0.3.0"", ""dependencies"": { ""ansi-regex"": { ""version"": ""0.2.1"", ""from"": ""ansi-regex@^0.2.1"" } } }, ""supports-color"": { ""version"": ""0.2.0"", ""from"": ""supports-color@^0.2.0"" ""version"": ""0.0.6"", ""from"": ""decompress-zip@0.0.6"", ""version"": ""0.1.31"", ""version"": ""0.0.6"", ""from"": ""fstream-ignore@0.0.6"", ""dependencies"": { ""minimatch"": { ""version"": ""0.2.14"", ""from"": ""minimatch@~0.2.0"", }, ""inherits"": { ""version"": ""1.0.0"", ""from"": ""inherits@~1.0.0"" ""version"": ""4.0.5"", ""from"": ""glob@^4.0.4"", ""version"": ""1.0.0"", ""from"": ""minimatch@^1.0.0"", ""from"": ""graceful-fs@^3.0.2"" ""version"": ""0.1.38"", ""version"": ""0.3.7"", ""from"": ""mute-stream@0.0.4"" }, ""chalk"": { ""version"": ""0.4.0"", ""from"": ""chalk@~0.4.0"", ""dependencies"": { ""has-color"": { ""version"": ""0.1.7"", ""from"": ""has-color@~0.1.0"" }, ""ansi-styles"": { ""version"": ""1.0.0"", ""from"": ""ansi-styles@~1.0.0"" }, ""strip-ansi"": { ""version"": ""0.1.1"", ""from"": ""strip-ansi@~0.1.0"" } } ""version"": ""0.4.2"", ""from"": ""insight@~0.4.1"", ""dependencies"": { ""async"": { ""version"": ""0.9.0"", ""from"": ""async@^0.9.0"" ""version"": ""0.3.1"", ""from"": ""configstore@^0.3.1"", ""dependencies"": { ""inquirer"": { ""version"": ""0.6.0"", ""from"": ""inquirer@^0.6.0"", ""dependencies"": { ""cli-color"": { ""version"": ""0.3.2"", ""from"": ""cli-color@~0.3.2"", ""dependencies"": { ""d"": { ""version"": ""0.1.1"", ""from"": ""d@~0.1.1"" }, ""es5-ext"": { ""version"": ""0.10.4"", ""from"": ""es5-ext@~0.10.2"", ""dependencies"": { ""es6-iterator"": { ""version"": ""0.1.1"", ""from"": ""es6-iterator@~0.1.1"" }, ""es6-symbol"": { ""version"": ""0.1.0"", ""from"": ""es6-symbol@0.1.x"" } } ""version"": ""0.3.7"", ""from"": ""memoizee@0.3.x"", ""version"": ""0.3.1"", ""from"": ""event-emitter@~0.3.1"" }, ""lru-queue"": { ""version"": ""0.1.0"", ""from"": ""lru-queue@0.1.x"" ""version"": ""0.2.2"", ""from"": ""next-tick@~0.2.2"" } } }, ""timers-ext"": { ""version"": ""0.1.0"", ""from"": ""timers-ext@0.1.x"", ""dependencies"": { ""next-tick"": { ""version"": ""0.2.2"", ""from"": ""next-tick@~0.2.2"" ""lodash"": { ""version"": ""2.4.1"", ""from"": ""lodash@~2.4.1"" }, ""readline2"": { ""version"": ""0.1.0"", ""from"": ""readline2@~0.1.0"", ""dependencies"": { ""chalk"": { ""version"": ""0.4.0"", ""from"": ""chalk@~0.4.0"", ""dependencies"": { ""has-color"": { ""version"": ""0.1.7"", ""from"": ""has-color@~0.1.0"" }, ""ansi-styles"": { ""version"": ""1.0.0"", ""from"": ""ansi-styles@~1.0.0"" }, ""strip-ansi"": { ""version"": ""0.1.1"", ""from"": ""strip-ansi@~0.1.0"" } } } } }, ""rx"": { ""version"": ""2.3.3"", ""from"": ""rx@^2.2.27"" }, ""from"": ""lodash.debounce@^2.4.1"", }, ""object-assign"": { ""version"": ""0.3.1"", ""from"": ""object-assign@^0.3.1"" }, ""os-name"": { ""version"": ""0.1.2"", ""from"": ""os-name@^0.1.2"", ""dependencies"": { ""minimist"": { ""version"": ""0.1.0"", ""from"": ""minimist@^0.1.0"" }, ""osx-release"": { ""version"": ""0.1.0"", ""from"": ""osx-release@^0.1.0"" } } }, ""request"": { ""version"": ""2.40.0"", ""from"": ""request@^2.40.0"", ""dependencies"": { ""qs"": { ""version"": ""1.0.2"", ""from"": ""qs@~1.0.0"" }, ""json-stringify-safe"": { ""version"": ""5.0.0"", ""from"": ""json-stringify-safe@~5.0.0"" }, ""mime-types"": { ""version"": ""1.0.2"", ""from"": ""mime-types@~1.0.1"" }, ""forever-agent"": { ""version"": ""0.5.2"", ""from"": ""forever-agent@~0.5.0"" }, ""node-uuid"": { ""version"": ""1.4.1"", ""from"": ""node-uuid@~1.4.0"" }, ""form-data"": { ""version"": ""0.1.4"", ""from"": ""form-data@~0.1.0"", ""dependencies"": { ""combined-stream"": { ""version"": ""0.0.5"", ""from"": ""combined-stream@~0.0.4"", ""dependencies"": { ""delayed-stream"": { ""version"": ""0.0.5"", ""from"": ""delayed-stream@0.0.5"" } } }, ""mime"": { ""version"": ""1.2.11"", ""from"": ""mime@~1.2.11"" } } }, ""tunnel-agent"": { ""version"": ""0.4.0"", ""from"": ""tunnel-agent@~0.4.0"" }, ""http-signature"": { ""version"": ""0.10.0"", ""from"": ""http-signature@~0.10.0"", ""dependencies"": { ""assert-plus"": { ""version"": ""0.1.2"", ""from"": ""assert-plus@0.1.2"" }, ""asn1"": { ""version"": ""0.1.11"", ""from"": ""asn1@0.1.11"" }, ""ctype"": { ""version"": ""0.5.2"", ""from"": ""ctype@0.5.2"" } } }, ""oauth-sign"": { ""version"": ""0.3.0"", ""from"": ""oauth-sign@~0.3.0"" }, ""hawk"": { ""version"": ""1.1.1"", ""from"": ""hawk@1.1.1"", ""dependencies"": { ""hoek"": { ""version"": ""0.9.1"", ""from"": ""hoek@0.9.x"" }, ""boom"": { ""version"": ""0.4.2"", ""from"": ""boom@0.4.x"" }, ""cryptiles"": { ""version"": ""0.2.2"", ""from"": ""cryptiles@0.2.x"" }, ""sntp"": { ""version"": ""0.2.4"", ""from"": ""sntp@0.2.x"" } } }, ""aws-sign2"": { ""version"": ""0.5.0"", ""from"": ""aws-sign2@~0.5.0"" }, ""stringstream"": { ""version"": ""0.0.4"", ""from"": ""stringstream@~0.0.4"" } } }, ""tough-cookie"": { ""version"": ""0.12.1"", ""from"": ""tough-cookie@^0.12.1"", ""dependencies"": { ""punycode"": { ""version"": ""1.3.1"", ""from"": ""punycode@>=0.2.0"" } } ""from"": ""lru-cache@2"" ""from"": ""nopt@^3.0.0"" ""from"": ""p-throttler@0.0.1"", ""version"": ""1.3.1"", ""version"": ""2.3.2"", ""from"": ""inherits@2"" ""version"": ""2.0.5"", ""version"": ""0.1.5"", ""version"": ""0.4.32"", ""version"": ""2.1.0"", ""from"": ""commander@~2.1.0"" ""version"": ""1.0.0"", ""from"": ""nan@~1.0.0"" ""version"": ""0.2.11"", ""version"": ""0.6.2"", ""version"": ""4.0.5"", ""version"": ""1.0.0"", ""from"": ""minimatch@^1.0.0"", ""grunt-nightwatch"": { ""version"": ""0.2.4"", ""from"": ""grunt-nightwatch@~0.2.2"", ""dependencies"": { ""nightwatch"": { ""version"": ""0.5.13"", ""from"": ""nightwatch@^0.5.13"", ""dependencies"": { ""ejs"": { ""version"": ""1.0.0"", ""from"": ""ejs@>=0.8.3"" }, ""optimist"": { ""version"": ""0.6.1"", ""from"": ""optimist@>=0.3.5"", ""dependencies"": { ""wordwrap"": { ""version"": ""0.0.2"", ""from"": ""wordwrap@~0.0.2"" }, ""minimist"": { ""version"": ""0.0.10"", ""from"": ""minimist@~0.0.1"" } } }, ""minimatch"": { ""version"": ""0.2.14"", ""from"": ""minimatch@~0.2.14"", ""dependencies"": { ""lru-cache"": { ""version"": ""2.5.0"", ""from"": ""lru-cache@2"" }, ""sigmund"": { ""version"": ""1.0.0"", ""from"": ""sigmund@~1.0.0"" } } }, ""mkpath"": { ""version"": ""0.1.0"", ""from"": ""mkpath@>=0.1.0"" } } } } }, ""version"": ""0.1.38"", ""version"": ""2.40.0"", ""version"": ""1.0.2"", ""from"": ""qs@~1.0.0"" ""version"": ""1.0.2"", ""version"": ""1.3.1"", ""version"": ""0.1.38"", ""nightwatch"": { ""version"": ""0.5.11"", ""from"": ""nightwatch@~0.5.11"", ""dependencies"": { ""ejs"": { ""version"": ""1.0.0"", ""from"": ""ejs@>=0.8.3"" }, ""optimist"": { ""version"": ""0.6.1"", ""from"": ""optimist@>=0.3.5"", ""dependencies"": { ""wordwrap"": { ""version"": ""0.0.2"", ""from"": ""wordwrap@~0.0.2"" }, ""minimist"": { ""version"": ""0.0.10"", ""from"": ""minimist@~0.0.1"" } } }, ""minimatch"": { ""version"": ""0.2.14"", ""from"": ""minimatch@~0.2.14"", ""dependencies"": { ""lru-cache"": { ""version"": ""2.5.0"", ""from"": ""lru-cache@2"" }, ""sigmund"": { ""version"": ""1.0.0"", ""from"": ""sigmund@~1.0.0"" } } }, ""mkpath"": { ""version"": ""0.1.0"", ""from"": ""mkpath@>=0.1.0"" } } }, ""version"": ""0.1.38"","," ""from"": ""colors@~0.6.2"" ""from"": ""nopt@~1.0.10"", ""from"": ""grunt-bower-task@"", ""version"": ""1.3.8"", ""from"": ""abbrev@~1.0.4"" ""from"": ""archy@~0.0.2"" ""version"": ""0.2.10"", ""from"": ""async@~0.2.6"" ""from"": ""esprima@~ 1.0.2"" ""version"": ""0.4.0"", ""from"": ""chalk@~0.4.0"", ""dependencies"": { ""has-color"": { ""version"": ""0.1.7"", ""from"": ""has-color@~0.1.0"" }, ""ansi-styles"": { ""version"": ""1.0.0"", ""from"": ""ansi-styles@~1.0.0"" ""version"": ""0.1.1"", ""from"": ""strip-ansi@~0.1.0"" ""version"": ""0.0.8"", ""from"": ""decompress-zip@~0.0.6"", ""version"": ""0.1.28"", }, ""mkdirp"": { ""version"": ""0.3.5"", ""from"": ""mkdirp@0.3"" ""version"": ""0.0.10"", ""from"": ""fstream-ignore@~0.0.6"", ""dependencies"": { ""inherits"": { ""version"": ""2.0.1"", ""from"": ""inherits@2"" }, ""minimatch"": { ""version"": ""0.3.0"", ""from"": ""minimatch@^0.3.0"", ""version"": ""4.0.4"", ""from"": ""glob@~4.0.2"", ""version"": ""0.3.0"", ""from"": ""minimatch@^0.3.0"", ""from"": ""graceful-fs@~3.0.1"" ""version"": ""0.1.37"", ""version"": ""0.3.5"", ""from"": ""mute-stream@~0.0.4"" ""version"": ""0.3.1"", ""from"": ""insight@~0.3.0"", ""dependencies"": { ""request"": { ""version"": ""2.27.0"", ""from"": ""request@~2.27.0"", ""dependencies"": { ""qs"": { ""version"": ""0.6.6"", ""from"": ""qs@~0.6.0"" }, ""json-stringify-safe"": { ""version"": ""5.0.0"", ""from"": ""json-stringify-safe@~5.0.0"" }, ""forever-agent"": { ""version"": ""0.5.2"", ""from"": ""forever-agent@~0.5.0"" }, ""tunnel-agent"": { ""version"": ""0.3.0"", ""from"": ""tunnel-agent@~0.3.0"" }, ""http-signature"": { ""version"": ""0.10.0"", ""from"": ""http-signature@~0.10.0"", ""dependencies"": { ""assert-plus"": { ""version"": ""0.1.2"", ""from"": ""assert-plus@0.1.2"" }, ""asn1"": { ""version"": ""0.1.11"", ""from"": ""asn1@0.1.11"" }, ""ctype"": { ""version"": ""0.5.2"", ""from"": ""ctype@0.5.2"" } } }, ""hawk"": { ""version"": ""1.0.0"", ""from"": ""hawk@~1.0.0"", ""dependencies"": { ""hoek"": { ""version"": ""0.9.1"", ""from"": ""hoek@0.9.x"" }, ""boom"": { ""version"": ""0.4.2"", ""from"": ""boom@0.4.x"" }, ""cryptiles"": { ""version"": ""0.2.2"", ""from"": ""cryptiles@0.2.x"" }, ""sntp"": { ""version"": ""0.2.4"", ""from"": ""sntp@0.2.x"" } } }, ""aws-sign"": { ""version"": ""0.3.0"", ""from"": ""aws-sign@~0.3.0"" }, ""oauth-sign"": { ""version"": ""0.3.0"", ""from"": ""oauth-sign@~0.3.0"" }, ""cookie-jar"": { ""version"": ""0.3.0"", ""from"": ""cookie-jar@~0.3.0"" }, ""node-uuid"": { ""version"": ""1.4.1"", ""from"": ""node-uuid@~1.4.0"" }, ""mime"": { ""version"": ""1.2.11"", ""from"": ""mime@~1.2.9"" }, ""form-data"": { ""version"": ""0.1.4"", ""from"": ""form-data@~0.1.0"", ""dependencies"": { ""combined-stream"": { ""version"": ""0.0.5"", ""from"": ""combined-stream@~0.0.4"", ""dependencies"": { ""delayed-stream"": { ""version"": ""0.0.5"", ""from"": ""delayed-stream@0.0.5"" } } }, ""async"": { ""version"": ""0.9.0"", ""from"": ""async@~0.9.0"" } } } } ""version"": ""0.2.3"", ""from"": ""configstore@~0.2.1"", ""dependencies"": { ""mkdirp"": { ""version"": ""0.3.5"", ""from"": ""mkdirp@0.3"" }, ""osenv"": { ""version"": ""0.0.3"", ""from"": ""osenv@0.0.3"" }, ""graceful-fs"": { ""version"": ""2.0.3"", ""from"": ""graceful-fs@~2.0.1"" }, ""async"": { ""version"": ""0.2.10"", ""from"": ""async@~0.2.9"" }, ""inquirer"": { ""version"": ""0.4.1"", ""from"": ""inquirer@~0.4.0"", ""dependencies"": { ""lodash"": { ""version"": ""2.4.1"", ""from"": ""lodash@~2.4.1"" }, ""cli-color"": { ""version"": ""0.2.3"", ""from"": ""cli-color@~0.2.2"", ""dependencies"": { ""es5-ext"": { ""version"": ""0.9.2"", ""from"": ""es5-ext@~0.9.2"" ""version"": ""0.2.6"", ""from"": ""memoizee@~0.2.5"", ""version"": ""0.2.2"", ""from"": ""event-emitter@~0.2.2"" ""version"": ""0.1.0"", ""from"": ""next-tick@0.1.x"" }, ""readline2"": { ""version"": ""0.1.0"", ""from"": ""readline2@~0.1.0"" ""object-assign"": { ""version"": ""0.1.2"", ""from"": ""object-assign@~0.1.2"" }, ""from"": ""lodash.debounce@~2.4.1"", ""from"": ""lru-cache@~2.5.0"" ""from"": ""nopt@~3.0.0"" ""from"": ""p-throttler@~0.0.1"", ""version"": ""1.3.0"", ""version"": ""2.3.1"", ""from"": ""inherits@~2.0.1"" ""chalk"": { ""version"": ""0.5.1"", ""from"": ""chalk@^0.5.0"", ""dependencies"": { ""ansi-styles"": { ""version"": ""1.1.0"", ""from"": ""ansi-styles@^1.1.0"" }, ""escape-string-regexp"": { ""version"": ""1.0.1"", ""from"": ""escape-string-regexp@^1.0.0"" }, ""has-ansi"": { ""version"": ""0.1.0"", ""from"": ""has-ansi@^0.1.0"", ""dependencies"": { ""ansi-regex"": { ""version"": ""0.2.1"", ""from"": ""ansi-regex@^0.2.1"" } } }, ""strip-ansi"": { ""version"": ""0.3.0"", ""from"": ""strip-ansi@^0.3.0"", ""dependencies"": { ""ansi-regex"": { ""version"": ""0.2.1"", ""from"": ""ansi-regex@^0.2.1"" } } }, ""supports-color"": { ""version"": ""0.2.0"", ""from"": ""supports-color@^0.2.0"" } } }, ""version"": ""2.0.3"", ""mkdirp"": { ""version"": ""0.3.5"", ""from"": ""mkdirp@~0.3.3"" }, ""version"": ""0.1.4"", ""version"": ""0.4.31"", ""version"": ""0.6.1"", ""from"": ""commander@~0.6.1"" ""version"": ""0.3.2"", ""from"": ""nan@~0.3.0"" ""version"": ""0.2.10"", ""version"": ""0.6.1"", ""version"": ""4.0.4"", ""version"": ""0.3.0"", ""from"": ""minimatch@^0.3.0"", ""version"": ""0.1.37"", ""version"": ""2.38.0"", ""version"": ""0.6.6"", ""from"": ""qs@~0.6.0"" ""version"": ""1.0.1"", ""version"": ""1.3.0"", ""version"": ""0.1.37"", ""version"": ""0.1.37"",",430,257
openstack%2Ffuel-web~master~Ie2402c43a52796d321509b9c9f1900894dd8e227,openstack/fuel-web,master,Ie2402c43a52796d321509b9c9f1900894dd8e227,[React] unit testing,ABANDONED,2014-08-28 16:13:16.000000000,2014-12-11 10:15:21.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-08-28 16:13:16.000000000', 'files': ['nailgun/static/js/__tests__/CheckboxWithLabel-test.js', 'nailgun/static/js/preprocessor.js', 'nailgun/package.json', 'nailgun/npm-shrinkwrap.json', 'nailgun/static/js/__tests__/sum-test.js', 'nailgun/static/js/CheckboxWithLabel.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3b3e4be6303711a0ed76f212870a7d7de7ad3630', 'message': '[React] unit testing\n\n - currently without requirejs support\n draft\n\nChange-Id: Ie2402c43a52796d321509b9c9f1900894dd8e227\n'}]",0,117553,3b3e4be6303711a0ed76f212870a7d7de7ad3630,8,6,1,9091,,,0,"[React] unit testing

 - currently without requirejs support
 draft

Change-Id: Ie2402c43a52796d321509b9c9f1900894dd8e227
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/53/117553/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/__tests__/CheckboxWithLabel-test.js', 'nailgun/static/js/preprocessor.js', 'nailgun/package.json', 'nailgun/npm-shrinkwrap.json', 'nailgun/static/js/__tests__/sum-test.js', 'nailgun/static/js/CheckboxWithLabel.jsx']",6,3b3e4be6303711a0ed76f212870a7d7de7ad3630,react_base," var React = require('react'); var CheckboxWithLabel = React.createClass({ getInitialState: function() { return { isChecked: false }; }, onChange: function() { this.setState({isChecked: !this.state.isChecked}); }, render: function() { return ( <label> <input type=""checkbox"" checked={this.state.isChecked} onChange={this.onChange} /> {this.state.isChecked ? this.props.labelOn : this.props.labelOff} </label> ); } }); module.exports = CheckboxWithLabel;",,966,304
openstack%2Ffuel-web~master~I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57,openstack/fuel-web,master,I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57,[tests] [karma] Initial unit tests configuration,ABANDONED,2014-06-13 08:28:22.000000000,2014-12-11 10:13:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-06-13 08:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/38815cb5dc86edd73536a959be0be1e616195666', 'message': 'Initial unit tests configuration\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 2, 'created': '2014-06-17 15:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ded46070684675ddcd8d85e1ac457551dd676f18', 'message': 'Initial unit tests configuration\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 3, 'created': '2014-06-17 15:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d25b37ac8ceebd5ade867e6e61864c6ebb3ab63d', 'message': 'Initial unit tests configuration\n\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 4, 'created': '2014-06-17 16:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3c916043e1960d967203abce698f03e2d5587a65', 'message': 'Initial unit tests configuration\n\nexpression parser via utils.evaluateExpression tested\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 5, 'created': '2014-06-17 17:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d50317852ce8b8742ce7a61c03e4edd1bf229c1c', 'message': 'Initial unit tests configuration\n\nexpression parser via utils.evaluateExpression tested\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 6, 'created': '2014-06-17 19:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3b9531fb1b4c370290c01358948c5d8b1ee00050', 'message': 'Initial unit tests configuration\n\nexpression parser via utils.evaluateExpression tested\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 7, 'created': '2014-07-16 16:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/044b0814d06f72ba40f7e4dc3d3efda761b2e58f', 'message': 'Initial unit tests configuration\n\nexpression parser via utils.evaluateExpression tested\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 8, 'created': '2014-08-11 11:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8202ff14dcfcd22b82d7f53851bcccf5a4a13e43', 'message': 'Initial unit tests configuration\n\nexpression parser via utils.evaluateExpression tested\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}, {'number': 9, 'created': '2014-08-18 16:03:29.000000000', 'files': ['nailgun/Gruntfile.js', 'nailgun/static/js/test/test-parser.js', 'nailgun/static/js/test/test-main.js', 'nailgun/package.json', 'nailgun/npm-shrinkwrap.json', 'nailgun/karma.conf.js', 'nailgun/static/js/libs/custom/chai.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/995d4f309b0644d6dfe426a25d906f48401e6d7d', 'message': '[tests] [karma] Initial unit tests configuration\n\nexpression parser via utils.evaluateExpression tested\nadded Grunt task - grunt karma\n\nChange-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57\nRelates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests\n'}]",7,99866,995d4f309b0644d6dfe426a25d906f48401e6d7d,61,6,9,9091,,,0,"[tests] [karma] Initial unit tests configuration

expression parser via utils.evaluateExpression tested
added Grunt task - grunt karma

Change-Id: I1ac6a57a54ac74d4935bd7ed6ae7b7676d0eca57
Relates-to-bp: https://blueprints.launchpad.net/fuel/+spec/ui-unit-tests
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/66/99866/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/Gruntfile.js', 'nailgun/static/js/test/test-parser.js', 'nailgun/static/js/test/test-main.js', 'nailgun/package.json', 'nailgun/karma.conf.js']",5,38815cb5dc86edd73536a959be0be1e616195666,bp/https,"// Karma configuration // Generated on Fri May 30 2014 20:43:19 GMT+0300 (EEST) module.exports = function(config) { config.set({ // base path that will be used to resolve all patterns (eg. files, exclude) basePath: '', // frameworks to use // available frameworks: https://npmjs.org/browse/keyword/karma-adapter frameworks: ['mocha', 'requirejs'], // list of files / patterns to load in the browser files: [ // libs required for test framework // {pattern: 'node_modules/chai/chai.js', included: false}, 'static/js/libs/bower/jquery/js/jquery.js', 'static/js/libs/bower/lodash/js/lodash.js', 'static/js/libs/custom/backbone.js', // {pattern: 'static/js/libs/**/*.js', included: false}, // {pattern: 'static/js/*', included: false}, // {pattern: 'static/js/views/*.js', included: false}, {pattern: 'static/js/test/test-parser.js', included: false}, 'static/js/test/test-main.js' // 'static/js/libs/**/*.js' ], // list of files to exclude exclude: [ 'static/js/libs/bower/require-css/**/*', ], plugins: [ 'karma-mocha', 'karma-chai', 'karma-coverage', 'karma-requirejs', 'karma-sinon', 'karma-phantomjs-launcher', 'karma-mocha-reporter', 'karma-firefox-launcher' ], // preprocess matching files before serving them to the browser // available preprocessors: https://npmjs.org/browse/keyword/karma-preprocessor preprocessors: { '*.js': 'coverage' // for coverage }, // test results reporter to use // possible values: 'dots', 'progress' // available reporters: https://npmjs.org/browse/keyword/karma-reporter reporters: ['mocha', 'coverage'], coverageReporter: { type: 'html', dir: 'coverage/' }, // web server port port: 9876, // enable / disable colors in the output (reporters and logs) colors: true, // level of logging // possible values: config.LOG_DISABLE || config.LOG_ERROR || config.LOG_WARN || config.LOG_INFO || config.LOG_DEBUG logLevel: config.LOG_INFO, // enable / disable watching file and executing tests whenever any file changes autoWatch: false, // start these browsers // available browser launchers: https://npmjs.org/browse/keyword/karma-launcher browsers: ['Firefox'], // If browser does not capture in given timeout [ms], kill it captureTimeout: 60000, // Continuous Integration mode // if true, Karma captures browsers, runs the tests and exits singleRun: false }); }; ",,217,2
openstack%2Foslo.db~master~Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661,openstack/oslo.db,master,Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661,Fix python3.x scoping issues with removed 'uee' variable,MERGED,2014-09-09 19:47:13.000000000,2014-12-11 10:13:20.000000000,2014-12-11 10:13:20.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5164}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 11816}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-09-09 19:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6c8b89ef2395d6fc22b7e29ef7d26f99ca629e59', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x isn't won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 2, 'created': '2014-09-11 04:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7ac8c2bce39c0b4d0c5f88e99d9475cb11cf0c73', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x isn't won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 3, 'created': '2014-09-23 01:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/94edab032435b9aed100cd8aab4a44477d22ce49', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x isn't won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 4, 'created': '2014-09-25 18:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/a66795d3132c77d8a3b18865e0cbe9aa9820e44d', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x isn't won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 5, 'created': '2014-09-26 21:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/f02a1e775df3291855ceebfdd2e4c54bd8606b05', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x isn't won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 6, 'created': '2014-10-24 16:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6dca768f2663e6f18c8effcc3063ab385706f23b', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x isn't won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 7, 'created': '2014-11-08 16:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6b1c554d3d6eac814526a38bed1ed4b91e4d54db', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 8, 'created': '2014-11-19 23:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e789f0c038b6867e660a88e96fd0dcfcc3a0157c', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 9, 'created': '2014-12-10 19:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d0d88154985834bc0b021ffbd08b51f60e6dc399', 'message': ""Fix more invalid encoding and scoping issues\n\nPython3.x won't be happy with creating temporary\nfiles with strings that don't support the buffer interface\nso ensure we correctly use byte strings.\n\nPython3.x always will warn about scoping visibility issues\nwhen a exception is used later after it has been caught so\nmake sure we initially set it to none.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}, {'number': 10, 'created': '2014-12-11 09:09:23.000000000', 'files': ['tests/sqlalchemy/test_exc_filters.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/b1af0f59194d500f12fa591aff950d3221adf903', 'message': ""Fix python3.x scoping issues with removed 'uee' variable\n\nIn python3.x the 'uee' variable will be removed from the\nscope after the except block exits (if it ever is entered)\nso we need to use a different variable name to ensure that\nit will not be deleted so we can use it later.\n\nChange-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661\n""}]",13,120198,b1af0f59194d500f12fa591aff950d3221adf903,44,7,10,1297,,,0,"Fix python3.x scoping issues with removed 'uee' variable

In python3.x the 'uee' variable will be removed from the
scope after the except block exits (if it ever is entered)
so we need to use a different variable name to ensure that
it will not be deleted so we can use it later.

Change-Id: Ia86a2bd1a46e57eaf47704eadc991fd0c9b08661
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/98/120198/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_exc_filters.py', 'tests/sqlalchemy/test_sqlalchemy.py']",2,6c8b89ef2395d6fc22b7e29ef7d26f99ca629e59,better-py34," paths = self.create_tempfiles([('db.master', b''), ('db.slave', b'')], [('db.master', b'')], ext='')[0]"," paths = self.create_tempfiles([('db.master', ''), ('db.slave', '')], [('db.master', '')], ext='')[0]",3,2
openstack%2Fmistral~master~I330aecce0b5bdcfe47b45f810afe3a5f5f49944b,openstack/mistral,master,I330aecce0b5bdcfe47b45f810afe3a5f5f49944b,Style changes in launch.py,MERGED,2014-12-11 09:42:50.000000000,2014-12-11 10:12:58.000000000,2014-12-11 10:12:57.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-12-11 09:42:50.000000000', 'files': ['mistral/config.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/d5a88ca2df1e56c1db8fdabf70282f3c63576bcd', 'message': 'Style changes in launch.py\n\nChange-Id: I330aecce0b5bdcfe47b45f810afe3a5f5f49944b\n'}]",0,140991,d5a88ca2df1e56c1db8fdabf70282f3c63576bcd,7,6,1,8731,,,0,"Style changes in launch.py

Change-Id: I330aecce0b5bdcfe47b45f810afe3a5f5f49944b
",git fetch https://review.opendev.org/openstack/mistral refs/changes/91/140991/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/config.py'],1,d5a88ca2df1e56c1db8fdabf70282f3c63576bcd,bug/1398793,"wf_trace_log_name_opt = cfg.StrOpt( 'workflow_trace_log_name', default='workflow_trace', help='Logger name for pretty ' 'workflow trace output.' ) logs_to_quieten = [ 'sqlalchemy=WARN', 'oslo.messaging=INFO', 'iso8601=WARN', 'eventlet.wsgi.server=WARN', 'stevedore=INFO', 'mistral.openstack.common.loopingcall=INFO', 'mistral.openstack.common.periodic_task=INFO', 'mistral.services.periodic=INFO' ] cfg.set_defaults( log.log_opts, default_log_levels=default_log_levels ) CONF( args=args, project='mistral', version=version, usage=usage, default_config_files=default_config_files )","wf_trace_log_name_opt = cfg.StrOpt('workflow_trace_log_name', default='workflow_trace', help='Logger name for pretty ' 'workflow trace output.')logs_to_quieten = ['sqlalchemy=WARN', 'oslo.messaging=INFO', 'iso8601=WARN', 'eventlet.wsgi.server=WARN', 'stevedore=INFO', 'mistral.openstack.common.loopingcall=INFO', 'mistral.openstack.common.periodic_task=INFO', 'mistral.services.periodic=INFO']cfg.set_defaults(log.log_opts, default_log_levels=default_log_levels) CONF(args=args, project='mistral', version=version, usage=usage, default_config_files=default_config_files)",30,19
openstack%2Foslo-incubator~master~I1cbb40e85dbbdb2c5e8426e1b40af9eb809fa9be,openstack/oslo-incubator,master,I1cbb40e85dbbdb2c5e8426e1b40af9eb809fa9be,Updated from global requirements,MERGED,2014-12-11 07:19:19.000000000,2014-12-11 10:12:34.000000000,2014-12-11 10:12:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-11 07:19:19.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/1cf2c61673be2fc077fa3445bcd4bc21fd0c298b', 'message': 'Updated from global requirements\n\nChange-Id: I1cbb40e85dbbdb2c5e8426e1b40af9eb809fa9be\n'}]",0,140947,1cf2c61673be2fc077fa3445bcd4bc21fd0c298b,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I1cbb40e85dbbdb2c5e8426e1b40af9eb809fa9be
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/47/140947/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1cf2c61673be2fc077fa3445bcd4bc21fd0c298b,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Frally~master~Ied2e74b29d6c2b303cafdf71fb97bdb5460f400a,openstack/rally,master,Ied2e74b29d6c2b303cafdf71fb97bdb5460f400a,Use HTTPS to fetch external js resources,MERGED,2014-12-10 19:40:30.000000000,2014-12-11 10:11:35.000000000,2014-12-11 10:11:34.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 10475}]","[{'number': 1, 'created': '2014-12-10 19:40:30.000000000', 'files': ['rally/ui/templates/verification/report.mako', 'rally/ui/templates/task/report.mako'], 'web_link': 'https://opendev.org/openstack/rally/commit/542bbffdebdc0a1ad14b5104700d37fc4f7d8e8c', 'message': 'Use HTTPS to fetch external js resources\n\nWhen putting a generated html on https capable webservers, external\nlibraries like AngularJS will be blocked by web browser as mixed content\nof http/https. For more detail, please refer to:\nhttps://developer.mozilla.org/docs/Security/MixedContent/How_to_fix_website_with_mixed_content\n\nChange-Id: Ied2e74b29d6c2b303cafdf71fb97bdb5460f400a\n'}]",0,140820,542bbffdebdc0a1ad14b5104700d37fc4f7d8e8c,14,4,1,8108,,,0,"Use HTTPS to fetch external js resources

When putting a generated html on https capable webservers, external
libraries like AngularJS will be blocked by web browser as mixed content
of http/https. For more detail, please refer to:
https://developer.mozilla.org/docs/Security/MixedContent/How_to_fix_website_with_mixed_content

Change-Id: Ied2e74b29d6c2b303cafdf71fb97bdb5460f400a
",git fetch https://review.opendev.org/openstack/rally refs/changes/20/140820/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/ui/templates/verification/report.mako', 'rally/ui/templates/task/report.mako']",2,542bbffdebdc0a1ad14b5104700d37fc4f7d8e8c,unblock-js-libs," <link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/nvd3/1.1.15-beta/nv.d3.min.css""> <script type=""text/javascript"" src=""https://ajax.googleapis.com/ajax/libs/angularjs/1.3.3/angular.min.js""></script> <script type=""text/javascript"" src=""https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3.min.js""></script> <script type=""text/javascript"" src=""https://cdnjs.cloudflare.com/ajax/libs/nvd3/1.1.15-beta/nv.d3.min.js""></script>"," <link rel=""stylesheet"" href=""http://cdnjs.cloudflare.com/ajax/libs/nvd3/1.1.15-beta/nv.d3.min.css""> <script type=""text/javascript"" src=""http://ajax.googleapis.com/ajax/libs/angularjs/1.3.3/angular.min.js""></script> <script type=""text/javascript"" src=""http://cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3.min.js""></script> <script type=""text/javascript"" src=""http://cdnjs.cloudflare.com/ajax/libs/nvd3/1.1.15-beta/nv.d3.min.js""></script>",5,5
openstack%2Ffuel-main~master~I043f000eca6f4aff1731e2bad49aae38e9a8d1f9,openstack/fuel-main,master,I043f000eca6f4aff1731e2bad49aae38e9a8d1f9,Remove unpacking for Docker images from upgrade.sh,MERGED,2014-11-12 14:03:54.000000000,2014-12-11 10:08:46.000000000,2014-12-11 10:08:45.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-11-12 14:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/506f4fabd77e1273dbc29d87e7554c6937839a18', 'message': 'Remove unpacking for Docker images from upgrade.sh\n\nAfter make system refactoring an upgrade tarball contains unpacked\nDocker images, therefore we need to remove unnecessary unpacking code\nfrom upgrade.sh in order to get rid of legacy code.\n\nChange-Id: I043f000eca6f4aff1731e2bad49aae38e9a8d1f9\nCloses-Bug: #1390030\n'}, {'number': 2, 'created': '2014-11-13 11:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/642647c1231eaf5907d5b175489bfdbee19a9d8a', 'message': 'Remove unpacking for Docker images from upgrade.sh\n\nAfter make system refactoring an upgrade tarball contains unpacked\nDocker images, therefore we need to remove unnecessary unpacking code\nfrom upgrade.sh in order to get rid of legacy code.\n\nAlso, the patch removes some obsolete targets from makefile.\n\nChange-Id: I043f000eca6f4aff1731e2bad49aae38e9a8d1f9\nCloses-Bug: #1390030\n'}, {'number': 3, 'created': '2014-11-17 17:02:38.000000000', 'files': ['upgrade/upgrade_template.sh', 'upgrade/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d0aa2868d88c60653e62666c568060370e913ee5', 'message': 'Remove unpacking for Docker images from upgrade.sh\n\nAfter make system refactoring an upgrade tarball contains unpacked\nDocker images, therefore we need to remove unnecessary unpacking code\nfrom upgrade.sh in order to get rid of legacy code.\n\nAlso, the patch removes some obsolete targets from makefile.\n\nChange-Id: I043f000eca6f4aff1731e2bad49aae38e9a8d1f9\nCloses-Bug: #1390030\n'}]",0,133961,d0aa2868d88c60653e62666c568060370e913ee5,26,8,3,10391,,,0,"Remove unpacking for Docker images from upgrade.sh

After make system refactoring an upgrade tarball contains unpacked
Docker images, therefore we need to remove unnecessary unpacking code
from upgrade.sh in order to get rid of legacy code.

Also, the patch removes some obsolete targets from makefile.

Change-Id: I043f000eca6f4aff1731e2bad49aae38e9a8d1f9
Closes-Bug: #1390030
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/61/133961/3 && git format-patch -1 --stdout FETCH_HEAD,['upgrade/upgrade_template.sh'],1,506f4fabd77e1273dbc29d87e7554c6937839a18,bug/1390030,,"function prepare_upgrade_files { DOCKER_IMAGES_DIR_PATH=$UPGRADE_PATH/images DOCKER_IMAGES_ARCHIVE_PATH=$DOCKER_IMAGES_DIR_PATH/fuel-images.tar.lrz if [ -r $DOCKER_IMAGES_ARCHIVE_PATH ]; then pushd $DOCKER_IMAGES_DIR_PATH >> /dev/null local err_msg=""Failed to uncompress docker "" err_msg+=""images ${DOCKER_IMAGES_ARCHIVE_PATH}, "" err_msg+=""check if you have enough free space"" lrzuntar -f $DOCKER_IMAGES_ARCHIVE_PATH || error ""$err_msg"" popd >> /dev/null fi } # decompress images iff the docker upgrader is used if [[ $UPGRADERS == *docker* ]]; then prepare_upgrade_files fi ",0,22
openstack%2Foslo.messaging~master~I93b8b2e92d0f2a353d3357a5e61f6d472ec84944,openstack/oslo.messaging,master,I93b8b2e92d0f2a353d3357a5e61f6d472ec84944,Add functional and unit 0mq driver tests,MERGED,2014-10-14 10:35:47.000000000,2014-12-11 09:55:33.000000000,2014-12-11 09:55:31.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7536}, {'_account_id': 7805}, {'_account_id': 8415}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-10-14 10:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2a41d22a7e12b6de0ab8130e73ddb0855e71620b', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 2, 'created': '2014-10-14 11:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f9373eff2df895cea3591c4d7f260c6ac3a2e34a', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver is directly dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 3, 'created': '2014-10-15 10:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3263eb5e697419cc8949cbfccd4ec8bcd0feeb76', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver is directly dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 4, 'created': '2014-10-15 11:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c9a6e1846f7b4d302f5ab58929b2cd0108a23a67', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver is directly dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 5, 'created': '2014-10-15 11:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/cf98cc893bee21c9b01abfcb4bae6de834152289', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver is directly dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 6, 'created': '2014-10-15 11:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/868f48c0f895c397543df468d26a5340e0b2406e', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a directly dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 7, 'created': '2014-10-15 11:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9c02b632847a170bf015cb2f4d0b8670634f120d', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 8, 'created': '2014-10-15 14:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7e4da44084056ddab809f40e5045f0cd9c4c4a37', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 9, 'created': '2014-11-13 11:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4a873543f85a5c31f1cf7a4eef23b7c10c5d0a5e', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Author: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Author: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 10, 'created': '2014-11-14 11:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/38beb287a83da6d04f902515c85608f73e4c1f6c', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Author: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Author: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 11, 'created': '2014-11-17 04:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/757a0287efb099097ef1faa67ec388a785d6d848', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 12, 'created': '2014-11-19 18:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7a4a4054f0d86cf9d5ac6ed00c0827bfc9771b3a', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 13, 'created': '2014-11-20 18:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8b9805ee62b4b0fe5d8501dbeb7919c3e7a8956c', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 14, 'created': '2014-11-24 11:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/06460ffc1a36a7c6e4c3788a725bdadcf1d5b788', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 15, 'created': '2014-11-27 16:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/53c1e71dd72213a3e63db8384a1fe4278eaa722a', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 16, 'created': '2014-11-28 14:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c91cca2919e2203aa69726369b36706fdcdb458f', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 17, 'created': '2014-11-28 15:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d783cca02a0992371503703efd6f4c23c45d1c1c', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 18, 'created': '2014-11-28 21:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bca357ed5acbcfa7ad7245db8d3d7978c7a17d5e', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 19, 'created': '2014-12-05 09:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/95ae95aaaa865a0a0285a1f2333502a450247af9', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 20, 'created': '2014-12-05 13:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/efe565ad6f05a60c888a40ec2e9eb21f521b371b', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}, {'number': 21, 'created': '2014-12-09 15:02:44.000000000', 'files': ['tests/drivers/test_impl_zmq.py', 'test-requirements.txt', 'tests/notify/test_logger.py', 'oslo/messaging/_drivers/impl_zmq.py', 'tests/notify/test_listener.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/cd71c47d326e8d5d2aa2d586e0f9874a45da4d6c', 'message': 'Add functional and unit 0mq driver tests\n\nBasic functional and unit tests for zmq driver.\n\nNote as the zmq driver is directly dependent on eventlet, this\nchange also updates the notify logger tests to remove the\ndirect dependency on threading which was being monkey patched,\ncausing test failures.\n\nAs the zmq driver has a direct dependency on eventlet, tests are\nskipped under py3.\n\nCo-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>\nCo-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>\n\nChange-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944\nPartial-bug: #1302941\n'}]",38,128233,cd71c47d326e8d5d2aa2d586e0f9874a45da4d6c,94,9,21,935,,,0,"Add functional and unit 0mq driver tests

Basic functional and unit tests for zmq driver.

Note as the zmq driver is directly dependent on eventlet, this
change also updates the notify logger tests to remove the
direct dependency on threading which was being monkey patched,
causing test failures.

As the zmq driver has a direct dependency on eventlet, tests are
skipped under py3.

Co-Authored-By: Kapil Thangavelu <kapil.thangavelu@canonical.com>
Co-Authored-By: Edward Hope-Morley <edward.hope-morley@canonical.com>

Change-Id: I93b8b2e92d0f2a353d3357a5e61f6d472ec84944
Partial-bug: #1302941
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/33/128233/21 && git format-patch -1 --stdout FETCH_HEAD,"['tests/drivers/test_impl_zmq.py', 'test-requirements.txt', 'tests/notify/test_logger.py', 'oslo/messaging/_drivers/impl_zmq.py']",4,2a41d22a7e12b6de0ab8130e73ddb0855e71620b,bug/1302941," @property def closed(self): return self.sock is None or self.sock.closed if not isinstance(ctx, dict): ctx_data = ctx.to_dict() else: ctx_data = ctx while not sock.closed: for t in self.threads: t.kill() conn = None if conn is not None: LOG.debug(""Sending cast: %s"", topic) if msg is None: raise rpc_common.Timeout() LOG.warning(""requeue not supported"") self.listeners = [] reply = _multi_send(method, ctxt, topic, message, self.listeners.append(conn) self.listeners.append(conn) for c in self.listeners: c.close() self.listeners = []"," ctx_data = ctx.to_dict() while True: for t in self.threads: t.kill() if 'conn' in vars(): LOG.debug(""Sending cast"") pass # FIXME(markmc): remove this temporary hack class Context(object): def __init__(self, d): self.d = d def to_dict(self): return self.d context = Context(ctxt) reply = _multi_send(method, context, topic, message,",586,75
openstack%2Fdjango_openstack_auth~master~I9d74a4f727d91e0db03988c00e5bc94979966e3b,openstack/django_openstack_auth,master,I9d74a4f727d91e0db03988c00e5bc94979966e3b,Domain enabled login screen needs focus on Domain field,MERGED,2014-11-27 02:07:03.000000000,2014-12-11 09:54:32.000000000,2014-12-11 09:54:31.000000000,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 1941}, {'_account_id': 4428}, {'_account_id': 6162}, {'_account_id': 6610}, {'_account_id': 8533}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-11-27 02:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/d8b041858532ded6d76eaa01469afc1fae3cb1ce', 'message': 'Domain enabled login screen needs focus on Domain field\n\nAfter you enable v3 support, you will see a Domain field on\nthe login screen. However, the focus is still on the Username\nfield. It should be on the first field which is Domain.\n\nChange-Id: I9d74a4f727d91e0db03988c00e5bc94979966e3b\nCloses-bug: #1396812\n'}, {'number': 2, 'created': '2014-11-27 07:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/19fcd75c7ed426e275f7dcd2bd4dad68578ab5d3', 'message': 'Domain enabled login screen needs focus on Domain field\n\nAfter you enable v3 support, you will see a Domain field on\nthe login screen. However, the focus is still on the Username\nfield. It should be on the first field which is Domain.\n\nChange-Id: I9d74a4f727d91e0db03988c00e5bc94979966e3b\nCloses-bug: #1396812\n'}, {'number': 3, 'created': '2014-12-02 00:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/adee7acebfb592c58d16a8f805115767548dfcf8', 'message': 'Domain enabled login screen needs focus on Domain field\n\nAfter you enable v3 support, you will see a Domain field on\nthe login screen. However, the focus is still on the Username\nfield. It should be on the first field which is Domain.\n\nChange-Id: I9d74a4f727d91e0db03988c00e5bc94979966e3b\nCloses-bug: #1396812\n'}, {'number': 4, 'created': '2014-12-02 03:09:34.000000000', 'files': ['openstack_auth/forms.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/5bc597c0ce45e7ec131a74c72ff193c25b7ac35d', 'message': 'Domain enabled login screen needs focus on Domain field\n\nAfter you enable v3 support, you will see a Domain field on\nthe login screen. However, the focus is still on the Username\nfield. It should be on the first field which is Domain.\n\nChange-Id: I9d74a4f727d91e0db03988c00e5bc94979966e3b\nCloses-bug: #1396812\n'}]",2,137499,5bc597c0ce45e7ec131a74c72ff193c25b7ac35d,28,8,4,4428,,,0,"Domain enabled login screen needs focus on Domain field

After you enable v3 support, you will see a Domain field on
the login screen. However, the focus is still on the Username
field. It should be on the first field which is Domain.

Change-Id: I9d74a4f727d91e0db03988c00e5bc94979966e3b
Closes-bug: #1396812
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/99/137499/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/forms.py'],1,d8b041858532ded6d76eaa01469afc1fae3cb1ce,domain-focus," self.fields['domain'] = forms.CharField( label=_(""Domain""), required=True, widget=forms.TextInput(attrs={""autofocus"": ""autofocus""}))"," self.fields['domain'] = forms.CharField(label=_(""Domain""), required=True)",4,2
openstack%2Fgnocchi~master~I0bb960ecd3e8d96c36fd106312d2cc69d071a593,openstack/gnocchi,master,I0bb960ecd3e8d96c36fd106312d2cc69d071a593,rest: add policy check for archive policy creation,MERGED,2014-12-08 14:17:20.000000000,2014-12-11 09:51:12.000000000,2014-12-11 09:51:10.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}]","[{'number': 1, 'created': '2014-12-08 14:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/be67f43f23d8e0f4f89594697b3f52c25d19cbb8', 'message': 'rest: add policy check for archive policy creation\n\nOnly allowed to admin by default.\n\nChange-Id: I0bb960ecd3e8d96c36fd106312d2cc69d071a593\n'}, {'number': 2, 'created': '2014-12-10 10:03:17.000000000', 'files': ['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/28d1216d380aac052f1a827655d4aeaf3ea8b43c', 'message': 'rest: add policy check for archive policy creation\n\nOnly allowed to admin by default.\n\nChange-Id: I0bb960ecd3e8d96c36fd106312d2cc69d071a593\n'}]",1,140015,28d1216d380aac052f1a827655d4aeaf3ea8b43c,10,4,2,1669,,,0,"rest: add policy check for archive policy creation

Only allowed to admin by default.

Change-Id: I0bb960ecd3e8d96c36fd106312d2cc69d071a593
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/15/140015/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json', 'gnocchi/tests/test_rest.py']",3,be67f43f23d8e0f4f89594697b3f52c25d19cbb8,jd/policy," def test_post_archive_policy_as_non_admin(self): with self.app.use_another_user(): self.app.post_json( ""/v1/archive_policy"", params={""name"": str(uuid.uuid4()), ""definition"": [{ ""granularity"": ""1 minute"", ""points"": 20, }]}, status=403) ",,14,1
openstack%2Ffuel-web~master~I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc,openstack/fuel-web,master,I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc,MultiSort util,MERGED,2014-11-18 09:35:05.000000000,2014-12-11 09:50:09.000000000,2014-12-11 09:50:09.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-11-18 09:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c7d264268952838495e1cbb5af89bf87c8010793', 'message': 'Fixes node collection sorting\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}, {'number': 2, 'created': '2014-11-24 15:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a58348c802125ec27ef0c84754683096776e3395', 'message': 'Fixes node collection sorting\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}, {'number': 3, 'created': '2014-11-28 10:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ad8e72f6692abd1d53f494769c66e8c80758a261', 'message': 'MultiSort util\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}, {'number': 4, 'created': '2014-11-28 10:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/44c436b53c55e993a47f2d26aa8ae692b697f231', 'message': 'MultiSort util\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}, {'number': 5, 'created': '2014-11-28 12:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/28fefc0066932fe6e65e427abd6ee3af7ec0af32', 'message': 'MultiSort util\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}, {'number': 6, 'created': '2014-12-02 10:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a5cac6d442ee0df305a8a0024076ea38da4986ba', 'message': 'MultiSort util\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}, {'number': 7, 'created': '2014-12-10 10:50:36.000000000', 'files': ['nailgun/static/js/utils.js', 'nailgun/static/js/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dc9a812ef40638909238caa9ca5d4fd914eb4f87', 'message': 'MultiSort util\n\nCloses-Bug: #1382530\n\nChange-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc\n'}]",26,135200,dc9a812ef40638909238caa9ca5d4fd914eb4f87,66,7,7,8766,,,0,"MultiSort util

Closes-Bug: #1382530

Change-Id: I483e7dddbdbbe2f4293f922c62422ec1d4d7f5bc
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/00/135200/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/models.js'],1,c7d264268952838495e1cbb5af89bf87c8010793,bug/1382530," comparator: function(node1, node2) { var onlineAttrDifference = node1.get('online') - node2.get('online'); if (onlineAttrDifference) return -onlineAttrDifference; return node1.id - node2.id;"," comparator: function(node) { return [!node.get('online'), node.id];",4,2
openstack%2Fgnocchi~master~I08cdf6afdaa6e2b81dd6eab0d342f095a8edcd03,openstack/gnocchi,master,I08cdf6afdaa6e2b81dd6eab0d342f095a8edcd03,rest: add policy for archive policies listing,MERGED,2014-12-08 14:17:20.000000000,2014-12-11 09:48:39.000000000,2014-12-11 09:48:39.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}]","[{'number': 1, 'created': '2014-12-08 14:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/98ed13a065ed29fa038ef580d68e4cb366670f7a', 'message': 'rest: add policy for archive policies listing\n\nChange-Id: I08cdf6afdaa6e2b81dd6eab0d342f095a8edcd03\n'}, {'number': 2, 'created': '2014-12-10 10:03:17.000000000', 'files': ['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/bdeb463c40326c04c2bb418818f9a8adf703bcfb', 'message': 'rest: add policy for archive policies listing\n\nChange-Id: I08cdf6afdaa6e2b81dd6eab0d342f095a8edcd03\n'}]",0,140014,bdeb463c40326c04c2bb418818f9a8adf703bcfb,10,4,2,1669,,,0,"rest: add policy for archive policies listing

Change-Id: I08cdf6afdaa6e2b81dd6eab0d342f095a8edcd03
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/14/140014/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json']",2,98ed13a065ed29fa038ef580d68e4cb366670f7a,jd/policy," ""list archive policy"": """",",,2,0
openstack%2Fgnocchi~master~I5f52cc34f2f3b843baaba26c2c37a3e908d72ead,openstack/gnocchi,master,I5f52cc34f2f3b843baaba26c2c37a3e908d72ead,rest: add policy enforcement for archive policy retrieval,MERGED,2014-12-08 14:17:20.000000000,2014-12-11 09:48:33.000000000,2014-12-11 09:48:32.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}]","[{'number': 1, 'created': '2014-12-08 14:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e936deaff2d39adfa6a49434056f34f6a8dfad1a', 'message': 'rest: add policy enforcement for archive policy retrieval\n\nChange-Id: I5f52cc34f2f3b843baaba26c2c37a3e908d72ead\n'}, {'number': 2, 'created': '2014-12-10 10:03:17.000000000', 'files': ['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4e296ef895122281fff2d8998f8e36b7a92ac6fe', 'message': 'rest: add policy enforcement for archive policy retrieval\n\nChange-Id: I5f52cc34f2f3b843baaba26c2c37a3e908d72ead\n'}]",0,140013,4e296ef895122281fff2d8998f8e36b7a92ac6fe,10,4,2,1669,,,0,"rest: add policy enforcement for archive policy retrieval

Change-Id: I5f52cc34f2f3b843baaba26c2c37a3e908d72ead
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/13/140013/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'etc/gnocchi/policy.json']",2,e936deaff2d39adfa6a49434056f34f6a8dfad1a,jd/policy," ""get archive policy"": """", ",,3,0
openstack%2Fgnocchi~master~I71d2ad35ae49adf431ecc3740117055fed406c2c,openstack/gnocchi,master,I71d2ad35ae49adf431ecc3740117055fed406c2c,rest: return 400 when creating resource with invalid metric,MERGED,2014-12-05 18:27:18.000000000,2014-12-11 09:46:11.000000000,2014-12-11 09:46:11.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-12-05 18:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ce5ad681d9feaab79c59f23ba24d6bbc677dec2b', 'message': 'rest: return 400 when creating resource with invalid metric\n\nChange-Id: I71d2ad35ae49adf431ecc3740117055fed406c2c\n'}, {'number': 2, 'created': '2014-12-05 18:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/91e488e9b99ceab8598bcfeefb303fb3dcebcac0', 'message': 'rest: return 400 when creating resource with invalid metric\n\nChange-Id: I71d2ad35ae49adf431ecc3740117055fed406c2c\n'}, {'number': 3, 'created': '2014-12-06 09:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d13b2a5f1eb489fa002903249c6d53ef7df3c150', 'message': 'rest: return 400 when creating resource with invalid metric\n\nChange-Id: I71d2ad35ae49adf431ecc3740117055fed406c2c\n'}, {'number': 4, 'created': '2014-12-07 10:54:53.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a551dbf9294d66b7e65c6e70eca8cd27ec3be811', 'message': 'rest: return 400 when creating resource with invalid metric\n\nChange-Id: I71d2ad35ae49adf431ecc3740117055fed406c2c\n'}]",0,139699,a551dbf9294d66b7e65c6e70eca8cd27ec3be811,14,4,4,1669,,,0,"rest: return 400 when creating resource with invalid metric

Change-Id: I71d2ad35ae49adf431ecc3740117055fed406c2c
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/99/139699/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py']",2,ce5ad681d9feaab79c59f23ba24d6bbc677dec2b,jd/doc," def test_post_resource_with_invalid_metric(self): metric_id = str(uuid.uuid4()) self.attributes['metrics'] = {""foo"": metric_id} result = self.app.post_json( ""/v1/resource/"" + self.resource_type, params=self.attributes, status=400) self.assertIn(""Metric %s does not exist"" % metric_id, result.text) ",,11,1
openstack%2Fgnocchi~master~Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc,openstack/gnocchi,master,Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc,rest: return 404 if metric id is empty,MERGED,2014-12-05 18:27:18.000000000,2014-12-11 09:46:05.000000000,2014-12-11 09:46:04.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-12-05 18:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e2e4163c8117653712a68747695cc11464b55782', 'message': 'rest: return 404 if metric id is empty\n\nChange-Id: Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc\n'}, {'number': 2, 'created': '2014-12-05 18:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/380c3b8233a40fe803d841068053b3faf5fb70fa', 'message': 'rest: return 404 if metric id is empty\n\nChange-Id: Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc\n'}, {'number': 3, 'created': '2014-12-06 09:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/2bfeeeab0a0170a13e9cdc4730d124538005f8b3', 'message': 'rest: return 404 if metric id is empty\n\nChange-Id: Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc\n'}, {'number': 4, 'created': '2014-12-07 10:54:53.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0caea5d4b2a40b4f9d30f0a3139fc5367cdb0a17', 'message': 'rest: return 404 if metric id is empty\n\nChange-Id: Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc\n'}]",1,139698,0caea5d4b2a40b4f9d30f0a3139fc5367cdb0a17,14,4,4,1669,,,0,"rest: return 404 if metric id is empty

Change-Id: Idec6bfed5731c3c37fe1114a0352698ce6a1c5cc
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/98/139698/2 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py']",2,e2e4163c8117653712a68747695cc11464b55782,jd/doc," def test_get_metric_empty(self): self.app.get(""/v1/metric/"", status=404) ",,6,0
openstack%2Fgnocchi~master~Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333,openstack/gnocchi,master,Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333,rest: return 404 on non existent archive policy,MERGED,2014-12-05 18:27:18.000000000,2014-12-11 09:45:58.000000000,2014-12-11 09:45:57.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-12-05 18:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f31ddda22bc17ec7c345509771e99bf61a824712', 'message': 'rest: return 404 on non existent archive policy\n\nChange-Id: Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333\n'}, {'number': 2, 'created': '2014-12-05 18:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7a681a52bc40902d6f4b8f65ae1c8f8acc1a829f', 'message': 'rest: return 404 on non existent archive policy\n\nChange-Id: Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333\n'}, {'number': 3, 'created': '2014-12-06 09:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e394ab593e856c77b9e209e54f5c5dfe4c3dfa5b', 'message': 'rest: return 404 on non existent archive policy\n\nChange-Id: Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333\n'}, {'number': 4, 'created': '2014-12-07 10:54:53.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6091dd18f044b24ce1845a2bbb896b59c6fd4be0', 'message': 'rest: return 404 on non existent archive policy\n\nChange-Id: Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333\n'}]",0,139697,6091dd18f044b24ce1845a2bbb896b59c6fd4be0,14,4,4,1669,,,0,"rest: return 404 on non existent archive policy

Change-Id: Ief31a9703c73ecc387ca3d11ed7cf5e44ae8e333
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/97/139697/4 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/test_rest.py']",2,f31ddda22bc17ec7c345509771e99bf61a824712,jd/doc,," expect_errors=True,",1,1
openstack%2Ffuel-web~master~If80dd3a5b06fbb06eebc81148edc9631dfa360db,openstack/fuel-web,master,If80dd3a5b06fbb06eebc81148edc9631dfa360db,Add support for external MongoDB,MERGED,2014-07-16 12:54:49.000000000,2014-12-11 09:45:26.000000000,2014-12-11 09:45:24.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-07-16 12:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/327a9a0bf989b594b6c0218d1d5f7fde8d858df2', 'message': 'Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db_name and hosts ips\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n'}, {'number': 2, 'created': '2014-07-17 08:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2082d582ebadeb46c47b72a7a516f77d21b68dea', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db_name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 3, 'created': '2014-07-17 09:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d2b6a96d1f33d3774f0ae660179cdb515cae8d4d', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, DB name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 4, 'created': '2014-07-17 15:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2b3a8e87e5f4ce0c16854c9342fa25b4448c11f8', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, DB name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 5, 'created': '2014-07-18 09:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bfba63743f9734fc6a443986938226154b67ac7f', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, DB name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 6, 'created': '2014-07-18 15:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/17ab741bd32d5a421c144251eb4c1c5e5da43522', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 7, 'created': '2014-09-11 09:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a7f81a32ea7e955536d7699783e6a9b9562bd159', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 8, 'created': '2014-09-11 14:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/68b2d22a8669325eaca8c48a8cb63819460799e9', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 9, 'created': '2014-09-11 16:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d02871e798deaff0c5636c04f9c6bac1cbbbbacf', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 10, 'created': '2014-09-12 09:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2668209162a48673e5fd9f93d9c7b1c45c3cb362', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 11, 'created': '2014-09-15 09:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ff0f12e2424a76db905d6606e4c6bc4f96bbaf9f', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 12, 'created': '2014-10-03 10:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/74e75ba7be5b43cd545d8b26f99ef90436dd4d77', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 13, 'created': '2014-10-03 11:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e0f26d9f50632b56a4c402b0c9a3417c0e51cf1e', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 14, 'created': '2014-10-07 10:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/808d421cabeb145c5bd57f196c53db74dcd019bb', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 15, 'created': '2014-10-23 16:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/17c1ce52ff4a405b071505d43af29f9d18659977', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 16, 'created': '2014-12-05 14:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2caf975f2ce1778577590baa582890862c9bae88', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 17, 'created': '2014-12-05 14:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4a3a61aecf2b43d11d1565811959e4d800099a36', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 18, 'created': '2014-12-08 08:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/45e2418f9db83c3d2509c1f94c7cf34adf391fd7', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 19, 'created': '2014-12-10 11:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fe43e5080441b16461ceed7c0f6b387a648b4526', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 20, 'created': '2014-12-10 15:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e5715a44babda920cfc726f774cb1acd79feb967', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}, {'number': 21, 'created': '2014-12-10 15:03:03.000000000', 'files': ['nailgun/static/js/views/dialogs.jsx', 'nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c06356f5aa70188af02d5816a56b870889bed9e8', 'message': ""Add support for external MongoDB\n\n* Add textboxes to specify MongoDB user, password, db name and hosts ips\n* Add validation checks for user input\n* Don't allow to choose mongo role for node if external mongo setup is set\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db\n""}]",4,107359,c06356f5aa70188af02d5816a56b870889bed9e8,156,11,21,7732,,,0,"Add support for external MongoDB

* Add textboxes to specify MongoDB user, password, db name and hosts ips
* Add validation checks for user input
* Don't allow to choose mongo role for node if external mongo setup is set

Partial implements blueprint external-mongodb-support

Change-Id: If80dd3a5b06fbb06eebc81148edc9631dfa360db
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/59/107359/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/templates/dialogs/display_changes.html', 'nailgun/nailgun/fixtures/openstack.yaml']",2,327a9a0bf989b594b6c0218d1d5f7fde8d858df2,bp/external-mongodb-support," external_mongo: metadata: label: ""External MongoDB"" weight: 20 restrictions: - condition: ""settings:additional_components.mongo.value == false"" action: ""hide"" use_ext_mongo: value: true label: """" description: """" weight: 05 type: ""hidden"" hosts_ip: value: """" label: ""MongoDB hosts IP"" description: ""IP Addresses of MongoDB. Use comma to split IPs"" weight: 30 type: ""text"" regex: source: '^(((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?),)*((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$' error: ""Invalid hosts ip sequence"" mongo_user: value: ""ceilometer"" label: ""Username"" description: ""Mongo database username"" weight: 30 type: ""text"" regex: source: '^\w+$' error: ""Empty username"" mongo_password: value: ""ceilometer"" label: ""Password"" description: ""Mongo database password"" weight: 30 type: ""password"" regex: source: '^\S*$' error: ""Password contains spaces"" mongo_db_name: value: ""ceilometer"" label: ""Database name"" description: ""Mongo database name"" weight: 30 type: ""text"" regex: source: '^\w+$' error: ""Invalid database name"" - condition: ""settings:additional_components.ceilometer.value == true and settings:additional_components.mongo.value == false"" warning: ""Ceilometer should be enabled or you are using external Mongo DB"" mongo: value: false label: ""Use external Mongo DB"" description: ""If selected, You can use external Mongo DB as ceilometer backend"" weight: 40 type: ""checkbox"" restrictions: - ""settings:additional_components.ceilometer.value == false"""," - condition: ""settings:additional_components.ceilometer.value == true"" warning: ""Ceilometer should be enabled""",67,7
openstack%2Ftricircle~master~I4cd422f277a441886e20b8a4bd78f30797445bf1,openstack/tricircle,master,I4cd422f277a441886e20b8a4bd78f30797445bf1,delete some spaces in l2_proxy.py file,MERGED,2014-12-11 09:33:02.000000000,2014-12-11 09:44:26.000000000,2014-12-11 09:44:26.000000000,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2014-12-11 09:33:02.000000000', 'files': ['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/3831e50de9feba1a462c6c63f916627a63c865b7', 'message': 'delete some spaces in l2_proxy.py file\n\nChange-Id: I4cd422f277a441886e20b8a4bd78f30797445bf1\n'}]",0,140990,3831e50de9feba1a462c6c63f916627a63c865b7,6,2,1,9778,,,0,"delete some spaces in l2_proxy.py file

Change-Id: I4cd422f277a441886e20b8a4bd78f30797445bf1
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/90/140990/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'],1,3831e50de9feba1a462c6c63f916627a63c865b7,," pagination_marker=None): 'Response:%s'), str(filters), str(since_time), if(not portResponse or"," pagination_marker=None): 'Response:%s'), str(filters), str(since_time), if(not portResponse or ",3,6
openstack%2Fgnocchi~master~I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32,openstack/gnocchi,master,I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32,tests: use SQL scripts to setup env and run any command,MERGED,2014-12-05 18:27:18.000000000,2014-12-11 09:40:14.000000000,2014-12-11 09:40:14.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-12-05 18:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6011daa60c3ef1ae47e22160fac1116ed1b32712', 'message': 'tests: use SQL scripts to setup env and run any command\n\nChange-Id: I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32\n'}, {'number': 2, 'created': '2014-12-05 18:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a775e6d8c98dd6fb66e4872e4e2954bcbbf27c0e', 'message': 'tests: use SQL scripts to setup env and run any command\n\nChange-Id: I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32\n'}, {'number': 3, 'created': '2014-12-06 09:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f8fce6df0ab9a98b03d202322c5c00f36de48e0a', 'message': 'tests: use SQL scripts to setup env and run any command\n\nChange-Id: I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32\n'}, {'number': 4, 'created': '2014-12-07 10:54:53.000000000', 'files': ['setup-mysql-tests.sh', 'setup-postgresql-tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/37cc1bff64c3c0bf4d4121d03601b079926f7cf7', 'message': 'tests: use SQL scripts to setup env and run any command\n\nChange-Id: I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32\n'}]",0,139696,37cc1bff64c3c0bf4d4121d03601b079926f7cf7,13,3,4,1669,,,0,"tests: use SQL scripts to setup env and run any command

Change-Id: I3a21775bc3879bf873f5dcfe3b4108d0b1a94e32
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/96/139696/4 && git format-patch -1 --stdout FETCH_HEAD,"['setup-mysql-tests.sh', 'setup-postgresql-tests.sh', 'tox.ini']",3,6011daa60c3ef1ae47e22160fac1116ed1b32712,jd/doc,"commands = {toxinidir}/setup-postgresql-tests.sh python setup.py testr --slowest --testr-args=""{posargs}""commands = {toxinidir}/setup-mysql-tests.sh python setup.py testr --slowest --testr-args=""{posargs}""commands = {toxinidir}/setup-postgresql-tests.sh python setup.py testr --slowest --testr-args=""{posargs}""commands = {toxinidir}/setup-postgresql-tests.sh python setup.py testr --slowest --testr-args=""{posargs}""",commands = {toxinidir}/run-postgresql-tests.sh {posargs}commands = {toxinidir}/run-mysql-tests.sh {posargs}commands = {toxinidir}/run-postgresql-tests.sh {posargs}commands = {toxinidir}/run-postgresql-tests.sh {posargs},7,6
openstack%2Fpython-saharaclient~master~I3d85f5afac1c001d4236bcf6864dae50c975e849,openstack/python-saharaclient,master,I3d85f5afac1c001d4236bcf6864dae50c975e849,Saharaclient tests for tempest,ABANDONED,2014-10-24 12:23:18.000000000,2014-12-11 09:22:34.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 10459}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-10-24 12:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/7463d9e7709ac3852baf3b3ddc1f24fb3104e61c', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 2, 'created': '2014-10-24 12:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/8d0e96b98a898d5a0eb335f906cd4863e1a9d777', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 3, 'created': '2014-10-29 09:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/b2c2b60cefa2283723eb757ada02099d599a7e89', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 4, 'created': '2014-10-30 11:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/7d215a1f556886eabff5c277f243cf2ec93ab53b', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 5, 'created': '2014-10-30 11:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/24f48f555682b289660a4a3b9b77b71142bd4f98', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 6, 'created': '2014-11-05 14:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/dc23c5340cb0b76c0cff83d9c7bb19c19cea1653', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 7, 'created': '2014-11-07 12:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/c488d3be1ff8b52e850dd15c1dd353a9af75e432', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 8, 'created': '2014-11-10 12:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/688c25f1b68389593430981da09bb43bd9f36185', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 9, 'created': '2014-11-18 13:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/e0d3832de15765095ddcf9a38d18206aad0204eb', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 10, 'created': '2014-11-18 13:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/1153d5fbfb579d4d0032dfd37771d9b6a2f845a1', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 11, 'created': '2014-11-18 15:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/ba593f53f5a1859042495c3bd83d6346bff9c898', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 12, 'created': '2014-11-18 15:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/709ea0b11c63fd272a17d64e2d256f2c8fabd385', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 13, 'created': '2014-11-19 10:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/138f966b690e34462d9a1aa478dd8adfdfb29fe2', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 14, 'created': '2014-11-19 10:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/a3c2f1b5d34dad2508b5c3999efe4f6af7395db3', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 15, 'created': '2014-11-21 13:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/135cd38d0f1e4c7f401802c16b384885e4cd49c8', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 16, 'created': '2014-11-24 14:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/a498727f6ce50ede5b4eae1d19bad291d606879f', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 17, 'created': '2014-11-27 08:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/18ebca7540ffacfed7b0ab9438e933b1190e23b7', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\n'}, {'number': 18, 'created': '2014-12-02 13:23:49.000000000', 'files': ['saharaclient/tests/tempest/scenario/data_processing/client_tests/__init__.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_plugins.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_node_group_templates.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/base.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_job_binary_internals.py', 'saharaclient/tests/tempest/scenario/data_processing/__init__.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_data_sources.py', 'saharaclient/tests/tempest/scenario/data_processing/config.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_jobs.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_job_binaries.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_job_executions.py', 'saharaclient/tests/tempest/scenario/data_processing/README.rst', 'saharaclient/tests/tempest/scenario/data_processing/etc/sahara_tests.conf.sample', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_cluster_templates.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/f956bf674d4bb6d916b2c9c48a6431e586739190', 'message': 'Saharaclient tests for tempest\n\nChange-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849\nimplements bp: saharaclient-tests-in-tempest\n'}]",12,130767,f956bf674d4bb6d916b2c9c48a6431e586739190,129,12,18,12039,,,0,"Saharaclient tests for tempest

Change-Id: I3d85f5afac1c001d4236bcf6864dae50c975e849
implements bp: saharaclient-tests-in-tempest
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/67/130767/17 && git format-patch -1 --stdout FETCH_HEAD,"['saharaclient/tests/tempest/scenario/data_processing/client_tests/__init__.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_plugins.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_clusters.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_node_group_templates.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/base.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_image_registry.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_job_binary_internals.py', 'saharaclient/tests/tempest/scenario/data_processing/__init__.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_data_sources.py', 'saharaclient/tests/tempest/scenario/data_processing/config.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_jobs.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_job_binaries.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_job_executions.py', 'saharaclient/tests/tempest/scenario/data_processing/client_tests/test_cluster_templates.py']",14,7463d9e7709ac3852baf3b3ddc1f24fb3104e61c,bp/saharaclient-tests-in-tempest,"from tempest.scenario.data_processing.client_tests import base from tempest.common.utils import data_utils class ClusterTemplateTest(base.BaseDataProcessingTest): def _check_create_cluster_template(self, template_name=None): ng_template_name = data_utils.rand_name('sahara-ng-template') ng_template = self.create_node_group_template(ng_template_name, **self.worker_template) full_cluster_template = self.cluster_template.copy() full_cluster_template['node_groups'] = [ { 'name': 'master-node', 'flavor_id': self.flavor_ref, 'node_processes': ['namenode'], 'count': 1 }, { 'name': 'worker-node', 'node_group_template_id': ng_template.id, 'count': 3 }] if not template_name: # generate random name if it's not specified template_name = data_utils.rand_name('sahara-cluster-template') # create cluster template resp_body = self.create_cluster_template(template_name, **full_cluster_template) # check that template created successfully self.assertEqual(template_name, resp_body.name) self.assertDictContainsSubset(self.cluster_template, resp_body.__dict__) return resp_body.id, template_name def _check_cluster_template_list(self, *template_info): # check for cluster template in list template_list = self.data_processing_client.cluster_templates.list() templates_info = [(template.id, template.name) for template in template_list] self.assertIn(template_info, templates_info) def _check_cluster_template_get(self, template_id, template_name): # check cluster template fetch by id template = self.data_processing_client.cluster_templates.get( template_id) self.assertEqual(template_name, template.name) self.assertDictContainsSubset(self.cluster_template, template.__dict__) def _check_cluster_template_delete(self, template_id): # delete cluster template by id self.data_processing_client.cluster_templates.delete( template_id) # check that cluster template really deleted templates = self.data_processing_client.cluster_templates.list() self.assertNotIn(template_id, [template.id for template in templates]) def test_cluster_templates(self): template_id, template_name = self._check_create_cluster_template() self._check_cluster_template_list(template_id, template_name) self._check_cluster_template_get(template_id, template_name) self._check_cluster_template_delete(template_id) ",,928,0
openstack%2Fheat~master~I37e209042048cb4409fcd27fcf9587b594f3129b,openstack/heat,master,I37e209042048cb4409fcd27fcf9587b594f3129b,Prevent showing 'show' too early,MERGED,2014-12-10 16:43:38.000000000,2014-12-11 09:14:28.000000000,2014-12-11 09:14:27.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-10 16:43:38.000000000', 'files': ['heat/engine/api.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f6986b6097b827e2a4d2da6a1a26391830587cad', 'message': ""Prevent showing 'show' too early\n\nThe logic in format_resource_attributes was succeptible to a failure\nwhen resource that has 'show' attribute and is early IN_PROGRESS has\nthat attribute not populated yet, returning an empty string instead.\n\nThat might happen when asking for resource-show soon enough after\nstack-create, and that is what test_server_cfn_init in\nheat_integrationtests effectively does.\n\nChange-Id: I37e209042048cb4409fcd27fcf9587b594f3129b\nCloses-Bug: #1401107\n""}]",0,140766,f6986b6097b827e2a4d2da6a1a26391830587cad,15,6,1,9542,,,0,"Prevent showing 'show' too early

The logic in format_resource_attributes was succeptible to a failure
when resource that has 'show' attribute and is early IN_PROGRESS has
that attribute not populated yet, returning an empty string instead.

That might happen when asking for resource-show soon enough after
stack-create, and that is what test_server_cfn_init in
heat_integrationtests effectively does.

Change-Id: I37e209042048cb4409fcd27fcf9587b594f3129b
Closes-Bug: #1401107
",git fetch https://review.opendev.org/openstack/heat refs/changes/66/140766/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/api.py'],1,f6986b6097b827e2a4d2da6a1a26391830587cad,bug/1401107,"import collections show_attr = resolver['show'] if isinstance(show_attr, collections.Mapping): resolver = show_attr", resolver = resolver['show'],5,1
openstack%2Fironic-inspector~master~I8963c844f7bd2faef10115db56c5dc595d0c9643,openstack/ironic-inspector,master,I8963c844f7bd2faef10115db56c5dc595d0c9643,Require manual power on if ipmi_setup_credentials is set in Node.extra,MERGED,2014-12-10 12:11:38.000000000,2014-12-11 09:04:14.000000000,2014-12-11 09:04:14.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-10 12:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e994c3d69fa2d7497f00dd40178406e0b092bc5b', 'message': ""Require manual power on if ipmi_setup_credentials is set in Node.extra\n\nDon't request power on and don't validate power interface.\n\nChange-Id: I8963c844f7bd2faef10115db56c5dc595d0c9643\nImplements: blueprint setup-ipmi-credentials\n""}, {'number': 2, 'created': '2014-12-10 14:13:30.000000000', 'files': ['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/discover.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/8ffae3734607ae65ceb6c4b8c967467273bfe194', 'message': ""Require manual power on if ipmi_setup_credentials is set in Node.extra\n\nDon't request Ironic to power on the node and don't validate power interface.\n\nChange-Id: I8963c844f7bd2faef10115db56c5dc595d0c9643\nImplements: blueprint setup-ipmi-credentials\n""}]",1,140656,8ffae3734607ae65ceb6c4b8c967467273bfe194,13,3,2,10239,,,0,"Require manual power on if ipmi_setup_credentials is set in Node.extra

Don't request Ironic to power on the node and don't validate power interface.

Change-Id: I8963c844f7bd2faef10115db56c5dc595d0c9643
Implements: blueprint setup-ipmi-credentials
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/56/140656/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/discover.py']",2,e994c3d69fa2d7497f00dd40178406e0b092bc5b,bp/setup-ipmi-credentials,"from ironic_discoverd import conf if not node.extra.get('ipmi_setup_credentials'): validation = ironic.node.validate(node.uuid) if not validation.power['result']: LOG.error('Failed validation of power interface for node %s, ' 'reason: %s', node.uuid, validation.power['reason']) raise utils.DiscoveryFailed( 'Failed validation of power interface for node %s' % node.uuid) if not node.extra.get('ipmi_setup_credentials'): try: ironic.node.set_power_state(node.uuid, 'reboot') except Exception as exc: LOG.error('Failed to power on node %s, check it\'s power ' 'management configuration:\n%s', node.uuid, exc) else: LOG.info('Discovery environment is ready for node %s, ' 'manual power on is required within %d seconds', node.uuid, conf.getint('discoverd', 'timeout'))"," validation = ironic.node.validate(node.uuid) if not validation.power['result']: LOG.error('Failed validation of power interface for node %s, ' 'reason: %s', node.uuid, validation.power['reason']) raise utils.DiscoveryFailed('Failed validation of power interface for ' 'node %s' % node.uuid) try: ironic.node.set_power_state(node.uuid, 'reboot') except Exception as exc: LOG.error('Failed to power on node %s, check it\'s power ' 'management configuration:\n%s', node.uuid, exc)",35,12
openstack%2Ftempest~master~I728edf0165ba47b6f8930f2fb3d08bd29cfbb317,openstack/tempest,master,I728edf0165ba47b6f8930f2fb3d08bd29cfbb317,Adds scenario for IPv6 addresses,MERGED,2014-08-06 16:04:52.000000000,2014-12-11 09:00:01.000000000,2014-12-11 08:59:59.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6524}, {'_account_id': 6537}, {'_account_id': 6579}, {'_account_id': 6685}, {'_account_id': 6695}, {'_account_id': 7350}, {'_account_id': 8576}, {'_account_id': 8623}, {'_account_id': 9008}, {'_account_id': 9194}, {'_account_id': 9656}, {'_account_id': 10118}, {'_account_id': 10257}, {'_account_id': 10385}, {'_account_id': 10969}]","[{'number': 1, 'created': '2014-08-06 16:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/33aae5633f8cfdf86ba51b8d29aa7774a1e884f5', 'message': 'Allows choosing ip_version for ScenarioTest based tests\n\nEliminates hard-code which makes all ScenarioTest based tests creating default IPv4 subnet. Implements possibility to switch the test from ip_version=4 (still the default) to ip_version=6\n\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 2, 'created': '2014-08-07 13:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1648a602c73a7369851392b1d1d90b9b31007950', 'message': 'Allows choosing ip_version for ScenarioTest based tests\n\nEliminates hard-code which makes all ScenarioTest based tests creating default IPv4 subnet. Implements possibility to switch the test from ip_version=4 (still the default) to ip_version=6\n\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 3, 'created': '2014-08-08 08:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8ea3d7927170a47d03a8cdddf7584d2a9952eec7', 'message': 'Allows choosing ip_version for ScenarioTest based tests\n\nEliminates hard-code which makes all ScenarioTest based tests creating default IPv4 subnet. Implements possibility to switch the test from ip_version=4 (still the default) to ip_version=6\n\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 4, 'created': '2014-08-19 10:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e4fe6033b0abc1c53e80ff66d9d0be175f1f8f8a', 'message': 'Allows choosing ip_version for scenario tests\n\nEliminates hard-code which makes all ScenarioTest based tests\ncreating default IPv4 subnet.\nImplements possibility to switch the test from ip_version=4\n(still the default) to ip_version=6\n\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 5, 'created': '2014-08-19 12:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c2b458334b0d1b78a06c48df2c19ddbe9ca10009', 'message': 'Allows choosing ip_version for scenario tests\n\nEliminates hard-code which makes all ScenarioTest based tests\ncreating default IPv4 subnet.\nImplements possibility to switch the test from ip_version=4\n(still the default) to ip_version=6\n\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 6, 'created': '2014-11-24 18:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d1885855bf9361aa788b1557c21ba30badf57746', 'message': 'Add scenario test related to the way\n IPv6 addressed assigned to vNIC.\n\nEliminate hardcoded IPv4 subnet creation.\nFix problem with creating FIP for port with few\n addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 7, 'created': '2014-11-25 13:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c69c13b6db5b724302ec2dc1042fe7adfa40216', 'message': 'Add scenario test related to the way\n IPv6 addressed assigned to vNIC\n\nEliminate hardcoded IPv4 subnet creation.\nFix problem with creating FIP for port with few\n addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 8, 'created': '2014-11-25 13:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cd5a7c93f92e021eb178f183846552a53b1fb762', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 9, 'created': '2014-11-25 13:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7f2128173cc965a86a1d40d64f9e7a335874d727', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 10, 'created': '2014-11-25 15:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab9e97edeb71fc44b9bfbaebc53e783d8d5baeca', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 11, 'created': '2014-11-26 12:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9d9dffd6b1b757ad3d724838752e1e699f80f018', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 12, 'created': '2014-11-26 13:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45033cfb36b75fde96d7e02f9a3af0dd2b203ca9', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 13, 'created': '2014-11-26 14:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c64399cead6e2b088defea2f3ec581c1980cb7bf', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 14, 'created': '2014-11-27 10:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/34383db866850da91e2ac4aea0e2cd9dfe8a1d0d', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 15, 'created': '2014-11-27 13:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6219be77b1a80180348c32889853a291931860de', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 16, 'created': '2014-11-27 15:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c804a783b8e62761eb797c8b80b8811005f8090d', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 17, 'created': '2014-11-27 16:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae840394df70ef6b2b3fe52d7fc2bd0117f5e497', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 18, 'created': '2014-11-27 16:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2d6c2bd2f7545a08637f84832dd8f7472050b529', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 19, 'created': '2014-11-28 10:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3aaca22f689162abfba194e72aaed8c929d18f7c', 'message': 'Adds scenario for IPv6 addresses\n\n* Check the way how  IPv6 addresses assigned to vNIC\n* Eliminate hardcoded IPv4 subnet creation.\n* Fix problem with creating FIP for port with few addresses.\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 20, 'created': '2014-12-01 13:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/46bf2d3419e1eea1f5135d5d867b9046e3a6bced', 'message': 'Adds scenario for IPv6 addresses\n\n* Checks the way how  IPv6 addresses assigned to vNIC\n* Eliminates hardcoded IPv4 subnet creation.\n* Fixes problem with creating FIP for port with few addresses.\n* Adds ping6 to remote_client\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}, {'number': 21, 'created': '2014-12-01 15:16:22.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/common/utils/linux/remote_client.py', 'tempest/scenario/test_network_v6.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/14113579e8d78a49cbe576959d25b49c199bafb6', 'message': 'Adds scenario for IPv6 addresses\n\n* Checks the way how  IPv6 addresses assigned to vNIC\n* Eliminates hardcoded IPv4 subnet creation.\n* Fixes problem with creating FIP for port with few addresses.\n* Adds ping6 to remote_client\n\nPartially implements: blueprint ipv6-api-testing-parity\nChange-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317\n'}]",121,112336,14113579e8d78a49cbe576959d25b49c199bafb6,140,19,21,12632,,,0,"Adds scenario for IPv6 addresses

* Checks the way how  IPv6 addresses assigned to vNIC
* Eliminates hardcoded IPv4 subnet creation.
* Fixes problem with creating FIP for port with few addresses.
* Adds ping6 to remote_client

Partially implements: blueprint ipv6-api-testing-parity
Change-Id: I728edf0165ba47b6f8930f2fb3d08bd29cfbb317
",git fetch https://review.opendev.org/openstack/tempest refs/changes/36/112336/20 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/isolated_creds.py', 'tempest/scenario/manager.py']",2,33aae5633f8cfdf86ba51b8d29aa7774a1e884f5,bp/ipv6-api-testing-parity," cls.network_resources.setdefault('ip_version', cls._ip_version) _ip_version = 4 if self._ip_version == 6: tenant_cidr = netaddr.IPNetwork(CONF.network.tenant_network_v6_cidr) network_prefix = CONF.network.tenant_network_v6_mask_bits else: tenant_cidr = netaddr.IPNetwork(CONF.network.tenant_network_cidr) network_prefix = CONF.network.tenant_network_mask_bits for subnet_cidr in tenant_cidr.subnet(network_prefix): ip_version=self._ip_version,"," tenant_cidr = netaddr.IPNetwork(CONF.network.tenant_network_cidr) for subnet_cidr in tenant_cidr.subnet( CONF.network.tenant_network_mask_bits): ip_version=4,",21,10
openstack%2Fmistral~master~Icd4aa1a546893b815c01bea23880cde139df2d1b,openstack/mistral,master,Icd4aa1a546893b815c01bea23880cde139df2d1b,Redesigning engine to move all remote calls from transactions,MERGED,2014-11-26 09:47:26.000000000,2014-12-11 08:57:09.000000000,2014-12-11 08:57:08.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6923}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10104}]","[{'number': 1, 'created': '2014-11-26 09:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d18e11bcda6a5d434f7eb50e5d8373c6eed18273', 'message': 'Redesigning engine to move remove all remove calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have transactional and non-transactional parts\n\nTODO:\n* Fix failing tests\n* Add more tests\n* Think about better design to solve this task\n\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\nCloses-Bug: #1395679\n'}, {'number': 2, 'created': '2014-11-26 09:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/14267d8d1a620c674ec4038124694fdac676779a', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have transactional and non-transactional parts\n\nTODO:\n* Fix failing tests\n* Add more tests\n* Think about better design to solve this task\n\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\nCloses-Bug: #1395679\n'}, {'number': 3, 'created': '2014-12-01 07:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8d4745c09de9be88556ef4bd1339c69182d417bc', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have transactional and non-transactional parts\n\nTODO:\n* Fix failing tests\n* Add more tests\n* Think about better design to solve this task\n\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\nCloses-Bug: #1395679\n'}, {'number': 4, 'created': '2014-12-01 08:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/411255f87859c4132fd6f54ce4c06221d6b2e96b', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\nCloses-Bug: #1395679\n'}, {'number': 5, 'created': '2014-12-02 10:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f091b6cffd3c6a5d222a474902ac920577eae9c4', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\nCloses-Bug: #1395679\n'}, {'number': 6, 'created': '2014-12-02 10:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/605e926a4acc477badd1ed6b4884b6079eb3baa9', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\nCloses-Bug: #1395679\n'}, {'number': 7, 'created': '2014-12-09 10:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7c82df6402afdbd9ca145d74d55fe0d4ba4b0b7d', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nCloses-Bug: #1395679\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\n'}, {'number': 8, 'created': '2014-12-09 11:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5afbf09e4eea965bc486abc73226307e9ce9de24', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nCloses-Bug: #1395679\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\n'}, {'number': 9, 'created': '2014-12-09 11:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/413aa4dd033c6ad44ed988515338498940ff9a98', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nCloses-Bug: #1395679\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\n'}, {'number': 10, 'created': '2014-12-09 12:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2dfc5d22291cc5de9458137bee03b946b2022634', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nCloses-Bug: #1395679\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\n'}, {'number': 11, 'created': '2014-12-11 05:22:51.000000000', 'files': ['mistral/engine1/commands.py', 'mistral/utils/inspect_utils.py', 'mistral/tests/unit/engine1/test_race_condition.py', 'mistral/services/action_manager.py', 'mistral/tests/unit/engine1/test_dataflow.py', 'mistral/workflow/base.py', 'mistral/tests/unit/engine1/test_direct_workflow.py', 'mistral/workflow/direct_workflow.py', 'mistral/engine1/default_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/9da521b841430ba10f22c03386273e562a21d13a', 'message': 'Redesigning engine to move all remote calls from transactions\n\n* Fixes engine race condition between start_workflow and on_task_result methods\n* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")\n\nCloses-Bug: #1395679\nChange-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b\n'}]",3,137313,9da521b841430ba10f22c03386273e562a21d13a,42,8,11,8731,,,0,"Redesigning engine to move all remote calls from transactions

* Fixes engine race condition between start_workflow and on_task_result methods
* Engine commands now have local and remote parts (in fact, ""in tx"" and ""non tx"")

Closes-Bug: #1395679
Change-Id: Icd4aa1a546893b815c01bea23880cde139df2d1b
",git fetch https://review.opendev.org/openstack/mistral refs/changes/13/137313/7 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine1/commands.py', 'mistral/engine1/default_engine.py']",2,d18e11bcda6a5d434f7eb50e5d8373c6eed18273,bug/1395679," go_on = self._run_commands_in_tx(cmds, exec_db, wf_handler) if go_on: self._run_commands_outside_tx(cmds, exec_db, wf_handler) go_on = self._run_commands_in_tx(cmds, exec_db, wf_handler) if go_on: self._run_commands_outside_tx(cmds, exec_db, wf_handler) self._check_subworkflow_completion(exec_db) go_on = self._run_commands_in_tx(cmds, exec_db, wf_handler) if go_on: self._run_commands_outside_tx(cmds, exec_db, wf_handler) def _run_commands_in_tx(cmds, exec_db, wf_handler, cause_task_db=None): if not cmd.run_in_tx(exec_db, wf_handler, cause_task_db): return False return True @staticmethod def _run_commands_outside_tx(cmds, exec_db, wf_handler, cause_task_db=None): if not cmds: return for cmd in cmds: if not cmd.run_outside_tx(exec_db, wf_handler, cause_task_db): return False return True cmd = commands.RunTask(task_spec, task_db)\ cmd.run_in_tx(exec_db, wf_handler) cmd.run_outside_tx(exec_db, wf_handler)"," self._run_commands(cmds, exec_db, wf_handler) self._run_commands(cmds, exec_db, wf_handler, task_db) self._check_subworkflow_completion(exec_db) self._run_commands(cmds, exec_db, wf_handler) def _run_commands(cmds, exec_db, wf_handler, cause_task_db=None): if not cmd.run(exec_db, wf_handler, cause_task_db): break commands.RunTask(task_spec, task_db).run(exec_db, wf_handler)",67,20
openstack%2Ftacker-specs~master~I71e941e2a639641a662a163c682eb86d51de42fb,openstack/tacker-specs,master,I71e941e2a639641a662a163c682eb86d51de42fb,Stop using intersphinx,MERGED,2014-09-13 07:55:42.000000000,2014-12-11 08:55:57.000000000,2014-12-11 08:55:57.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 9375}]","[{'number': 1, 'created': '2014-09-13 07:55:42.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/326052a2d05fd757d07e81b7400a90d0df742157', 'message': ""Stop using intersphinx\n\nRemove intersphinx from the docs build as it triggers network calls that\noccasionally fail, and we don't really use intersphinx (links other\nsphinx documents out on the internet)\n\nThis also removes the requirement for internet access during docs build.\n\nThis can cause docs jobs to fail if the project errors out on\nwarnings.\n\nChange-Id: I71e941e2a639641a662a163c682eb86d51de42fb\nRelated-Bug: #1368910\n""}]",0,121327,326052a2d05fd757d07e81b7400a90d0df742157,6,4,1,6547,,,0,"Stop using intersphinx

Remove intersphinx from the docs build as it triggers network calls that
occasionally fail, and we don't really use intersphinx (links other
sphinx documents out on the internet)

This also removes the requirement for internet access during docs build.

This can cause docs jobs to fail if the project errors out on
warnings.

Change-Id: I71e941e2a639641a662a163c682eb86d51de42fb
Related-Bug: #1368910
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/27/121327/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,326052a2d05fd757d07e81b7400a90d0df742157,bug/1368910,," 'sphinx.ext.intersphinx',",0,1
openstack%2Fopenstack-ansible~master~I3a3122a810c92a2e7efd95a0d9e7df93fdc3b149,openstack/openstack-ansible,master,I3a3122a810c92a2e7efd95a0d9e7df93fdc3b149,Removed unused and unneeded RAX tools,MERGED,2014-12-11 04:27:09.000000000,2014-12-11 08:48:00.000000000,2014-12-11 08:47:59.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 14119}]","[{'number': 1, 'created': '2014-12-11 04:27:09.000000000', 'files': ['tools/install.py', 'tools/README.md'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9bfe84200141783e95ac8deeb889a82bb1776da8', 'message': 'Removed unused and unneeded RAX tools\n\nThis was a tool that was developed to simplify the deployment process.\nSadly this is unused, unneeded and can be removed.\n\nStarts to Implement: rackspace-namesake\n\nChange-Id: I3a3122a810c92a2e7efd95a0d9e7df93fdc3b149\n'}]",0,140917,9bfe84200141783e95ac8deeb889a82bb1776da8,9,5,1,7353,,,0,"Removed unused and unneeded RAX tools

This was a tool that was developed to simplify the deployment process.
Sadly this is unused, unneeded and can be removed.

Starts to Implement: rackspace-namesake

Change-Id: I3a3122a810c92a2e7efd95a0d9e7df93fdc3b149
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/17/140917/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/install.py', 'tools/README.md']",2,9bfe84200141783e95ac8deeb889a82bb1776da8,,,# Ansible-LXC-RPC Tools ## install.py Installs or updates an Ansible-LXC-RPC installation. Does not install or verify pre-requisites. It is (intended to be) 100% idempotent and appears to be so. Can be used for production or testing environments. ### Usage ``` Usage: install.py [OPTIONS] Options: --haproxy / --no-haproxy Should we install Haproxy? Defaults to no. --galera / --no-galera Should we install Galera? Defaults to no. --rabbit / --no-rabbit Should we install RabbitMQ? Defaults to no. --retries INTEGER Number of retries to attempt on an Ansible playbook before giving up. --help Show this message and exit. ``` Please note that the --haproxy option is for development/testing environments only. Our haproxy installation is __NOT__ intended for production use. ,0,322
openstack%2Ffuel-web~master~I2d97a3a09d29f05dcc060b14907e202f3aeb35d1,openstack/fuel-web,master,I2d97a3a09d29f05dcc060b14907e202f3aeb35d1,Correction of the devops.rst,MERGED,2014-10-02 14:19:07.000000000,2014-12-11 08:40:23.000000000,2014-12-11 08:40:23.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8392}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9546}, {'_account_id': 9788}, {'_account_id': 9977}, {'_account_id': 10068}, {'_account_id': 11090}, {'_account_id': 12817}, {'_account_id': 13344}, {'_account_id': 13917}, {'_account_id': 13948}]","[{'number': 1, 'created': '2014-10-02 14:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/839f1449758d1268e82e4d1a8397373394ec8b0a', 'message': 'Corrected the doc/devops.rst\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 2, 'created': '2014-10-06 10:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/df412b0be6468e2408006b4315cc3298c869fe33', 'message': 'Second correctinon of the doc/devops.rst\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 3, 'created': '2014-10-06 13:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7c70d9830df5a7b4d8c5ff4d68c9f4ee6fea6e13', 'message': 'The correction of the doc/devops.rst\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 4, 'created': '2014-10-07 08:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd8d53b441c845d68fda3a11c385c78975e0c9be', 'message': 'The correction of the doc/devops.rst\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 5, 'created': '2014-10-22 08:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8582f4fd2e884ba3b76d2ef7c006cc5a55312459', 'message': 'The correction of the doc/devops.rst\n\n1. Make more understandable the installation from packages and in virtual environment.\n2. Add the package repository.\n3. Add Ubuntu 12.04 and 14.04 support.\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 6, 'created': '2014-12-02 15:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b3a14e451b2f252778ae979863e08a410d5bb193', 'message': 'The correction of the doc/devops.rst\n\n1. Make more understandable the installation from packages and in\nvirtual environment.\n2. Add the package repository.\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 7, 'created': '2014-12-02 15:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b7e5da9759c7dc1a70fc9dce0754ef7518cd7991', 'message': 'The correction of the doc/devops.rst\n\n1. Make more understandable the installation from packages and in\nvirtual environment.\n2. Add the package repository.\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 8, 'created': '2014-12-02 15:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5bb332e8fb439581d48b056a07fbdf1553823740', 'message': 'The correction of the doc/devops.rst\n\n1. Make more understandable the installation from packages and in\nvirtual environment.\n2. Add the package repository.\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 9, 'created': '2014-12-02 16:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/44b1cdaafb44767e7048494f918c2242584f9728', 'message': 'The correction of the doc/devops.rst\n\n1. Make more understandable the installation from packages and in\nvirtual environment.\n2. Add the package repository.\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 10, 'created': '2014-12-03 08:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/31a423ea4c78c472210efd3def9bad42fe94a60f', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 11, 'created': '2014-12-03 13:40:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/37dec31b0f2cda1102d2e27f17bf23648dc7f9e1', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 12, 'created': '2014-12-03 15:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3741b2e8b3f89dae91e9dd03ee1c372c2783f719', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 13, 'created': '2014-12-03 15:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0ff53f33795aec3d7ea2ffa28bddf86d99ae3d41', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 14, 'created': '2014-12-03 16:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e55cf2586bd0ce5cc8ab9728a805088d2a6b5f16', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 15, 'created': '2014-12-03 16:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8bd412c619434a267f2d0f399c02bae8457f75f6', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}, {'number': 16, 'created': '2014-12-03 19:01:41.000000000', 'files': ['docs/devops.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f36ca374edbe57842ce553b414b56697d1f91109', 'message': 'Correction of the devops.rst\n\n1. Determine common steps for all approaches and put them into as\npre installation requirements\n2. Add the package repository to the installation from packages approach\n3. Add some corrections and remove useless items\n\nChange-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1\nCloses-Bug: 1376275\n'}]",18,125648,f36ca374edbe57842ce553b414b56697d1f91109,105,17,16,13343,,,0,"Correction of the devops.rst

1. Determine common steps for all approaches and put them into as
pre installation requirements
2. Add the package repository to the installation from packages approach
3. Add some corrections and remove useless items

Change-Id: I2d97a3a09d29f05dcc060b14907e202f3aeb35d1
Closes-Bug: 1376275
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/48/125648/10 && git format-patch -1 --stdout FETCH_HEAD,['docs/devops.rst'],1,839f1449758d1268e82e4d1a8397373394ec8b0a,bug/1376275, sudo apt-get install git \ postgresql \ postgresql-server-dev-all \ libyaml-dev \ libffi-dev \ python-dev \ python-virtualenv virtualenv --system-site-packages <path>/devops-venv sudo sed -ir 's/peer/trust/' /etc/postgresql/<version.number>/main/pg_hba.conf . <path>/devops-venv/bin/activate, sudo apt-get install postgresql \ python-psycopg2 \ python-ipaddr \ python-paramiko \ python-django \ git \ python-xmlbuilder \ python-libvirt \ python-django-southDevops Installation from packages --------------------------------- Install dependencies first :: sudo apt-get install postgresql \ python-psycopg2 \ python-ipaddr \ python-libvirt \ python-paramiko \ python-django \ git \ python-xmlbuilder \ python-libvirt \ python-django-south then clone fuel-devops repo and run setup.py :: git clone git://github.com/stackforge/fuel-devops.git cd fuel-devops python ./setup.py install First let's install packages required for that way :: apt-get install postgresql-server-dev-all python-libvirt python-dev python-django virtualenv --system-site-packages devops-venv sudo sed -ir 's/peer/trust/' /etc/postgresql/9.1/main/pg_hba.conf . devops-venv/bin/activate,10,38
openstack%2Ftricircle~master~Iaafc366166aca9a4565e23f67fa2194ecff5d07d,openstack/tricircle,master,Iaafc366166aca9a4565e23f67fa2194ecff5d07d,port list pagination patch for l2-proxy,MERGED,2014-12-11 08:24:32.000000000,2014-12-11 08:36:42.000000000,2014-12-11 08:36:42.000000000,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2014-12-11 08:24:32.000000000', 'files': ['neutronproxy/l2proxy/neutron/plugins/l2_proxy/common/config.py', 'neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/feb554ceb8fb53eaab7ef992cbee78804ecbdb3c', 'message': 'port list pagination patch for l2-proxy\n\nChange-Id: Iaafc366166aca9a4565e23f67fa2194ecff5d07d\n'}]",1,140975,feb554ceb8fb53eaab7ef992cbee78804ecbdb3c,6,2,1,9778,,,0,"port list pagination patch for l2-proxy

Change-Id: Iaafc366166aca9a4565e23f67fa2194ecff5d07d
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/75/140975/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py', 'neutronproxy/l2proxy/neutron/plugins/l2_proxy/common/config.py']",2,feb554ceb8fb53eaab7ef992cbee78804ecbdb3c,," cfg.IntOpt('pagination_limit', default=-1, help=_(""list ports pagination limit, default value is -1,"" ""means no pagination"")),",,65,15
openstack%2Ftaskflow~master~Ia146ec6541ee96aa6a78fa659267d2a69e3b9e97,openstack/taskflow,master,Ia146ec6541ee96aa6a78fa659267d2a69e3b9e97,Remove the base postfix for engine abstract base class,MERGED,2014-12-11 07:05:38.000000000,2014-12-11 08:34:00.000000000,2014-12-11 08:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-11 07:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3d8b240fff3378139e847bf9e48afbd379e63d52', 'message': ""Remove the base postfix for engine abstract base class\n\nRemove the non-standard pattern of calling the engine\nbase class EngineBase; since it's already obvious that\nits a base class by it existing in the base engine\nmodule.\n\nChange-Id: Ia146ec6541ee96aa6a78fa659267d2a69e3b9e97\n""}, {'number': 2, 'created': '2014-12-11 07:25:17.000000000', 'files': ['taskflow/engines/base.py', 'taskflow/engines/action_engine/engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/79ff9e7ea7fbb5c9bd022dd341eb28b68738d074', 'message': ""Remove the base postfix for engine abstract base class\n\nRemove the non-standard pattern of calling the engine\nbase class EngineBase; since it's already obvious that\nits a base class by it existing in the base engine\nmodule.\n\nChange-Id: Ia146ec6541ee96aa6a78fa659267d2a69e3b9e97\n""}]",0,140936,79ff9e7ea7fbb5c9bd022dd341eb28b68738d074,7,2,2,1297,,,0,"Remove the base postfix for engine abstract base class

Remove the non-standard pattern of calling the engine
base class EngineBase; since it's already obvious that
its a base class by it existing in the base engine
module.

Change-Id: Ia146ec6541ee96aa6a78fa659267d2a69e3b9e97
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/36/140936/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/engines/base.py']",2,3d8b240fff3378139e847bf9e48afbd379e63d52,less-base-prefix,class Engine(object):,class EngineBase(object):,2,2
openstack%2Ftaskflow~master~I353cb7289c84c06f9712391e84294bed513dca78,openstack/taskflow,master,I353cb7289c84c06f9712391e84294bed513dca78,Avoid popping while another entity is iterating,MERGED,2014-12-11 07:18:47.000000000,2014-12-11 08:33:53.000000000,2014-12-11 08:33:52.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-11 07:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ad89ae57b25792e3a4cf5262799dd64dcbaabc8f', 'message': ""Avoid popping while another entity is iterating\n\nTo avoid 'dictionary changed size during iteration' style\nof errors ensure that we acquire the job lock/condition\nbefore popping so that we do not affect another entity that\nis currently iterating over the job dictionary.\n\nChange-Id: I353cb7289c84c06f9712391e84294bed513dca78\n""}, {'number': 2, 'created': '2014-12-11 07:21:47.000000000', 'files': ['taskflow/jobs/backends/impl_zookeeper.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/880f7d28b95d01d3de36e4b8ac61768cd4310a59', 'message': ""Avoid popping while another entity is iterating\n\nTo avoid 'dictionary changed size during iteration' style\nof errors ensure that we acquire the job lock/condition\nbefore popping so that we do not affect another entity that\nis currently iterating over the job dictionary.\n\nChange-Id: I353cb7289c84c06f9712391e84294bed513dca78\n""}]",0,140946,880f7d28b95d01d3de36e4b8ac61768cd4310a59,8,2,2,1297,,,0,"Avoid popping while another entity is iterating

To avoid 'dictionary changed size during iteration' style
of errors ensure that we acquire the job lock/condition
before popping so that we do not affect another entity that
is currently iterating over the job dictionary.

Change-Id: I353cb7289c84c06f9712391e84294bed513dca78
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/46/140946/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/jobs/backends/impl_zookeeper.py'],1,ad89ae57b25792e3a4cf5262799dd64dcbaabc8f,fixed-job-pop," if path not in self._known_jobs: return with self._job_cond: job = self._known_jobs.pop(path, None) if job is not None: LOG.debug(""Removed job that was at path '%s'"", path) removals = [] removals.append(path) with self._job_cond: for path in removals: self._remove_job(path)"," LOG.debug(""Removing job that was at path: %s"", path) job = self._known_jobs.pop(path, None) if job is not None: self._remove_job(path)",10,3
openstack%2Ftempest~master~Ic554abb0342288f9226cc358dc930cc150d098a2,openstack/tempest,master,Ic554abb0342288f9226cc358dc930cc150d098a2,Handle pagination keys in lister response,MERGED,2014-12-03 12:47:53.000000000,2014-12-11 08:32:42.000000000,2014-12-11 08:32:41.000000000,"[{'_account_id': 3}, {'_account_id': 5174}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7141}, {'_account_id': 8298}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-03 12:47:53.000000000', 'files': ['tempest/services/network/json/network_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b1670c63d9b2e7932c9a2cc9581b5561006d170', 'message': 'Handle pagination keys in lister response\n\nRight now, NetworkClientJSON.deserialize_list() returns the\nfirst key-value pair from the lister response.\n\nBut the lister response might differ when pagination is enabled\nwith pagination_max_limit set to some value. There will be one\nadditional key-value pair like {resource}s-links: {href:, rel: ..},\nwhich deserialize_list() does not handle\n\nThis patch attempts to fix this bug\n\nChange-Id: Ic554abb0342288f9226cc358dc930cc150d098a2\nCloses-bug: #1398811\n'}]",0,138706,2b1670c63d9b2e7932c9a2cc9581b5561006d170,15,10,1,8298,,,0,"Handle pagination keys in lister response

Right now, NetworkClientJSON.deserialize_list() returns the
first key-value pair from the lister response.

But the lister response might differ when pagination is enabled
with pagination_max_limit set to some value. There will be one
additional key-value pair like {resource}s-links: {href:, rel: ..},
which deserialize_list() does not handle

This patch attempts to fix this bug

Change-Id: Ic554abb0342288f9226cc358dc930cc150d098a2
Closes-bug: #1398811
",git fetch https://review.opendev.org/openstack/tempest refs/changes/06/138706/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/network/json/network_client.py'],1,2b1670c63d9b2e7932c9a2cc9581b5561006d170,bug/1398811," # {'resources': [ res1, res2] } => when pagination disabled # {'resources': [..], 'resources_links': {}} => if pagination enabled pagination_suffix = ""_links"" for k in res.keys(): if k[-len(pagination_suffix):] == pagination_suffix: continue return res[k]"," # {'resources': [ res1, res2] } return res[res.keys()[0]]",7,2
openstack%2Fproject-config~master~Id7ffd9e0e897f5ddad253511dc6085b1b9becb89,openstack/project-config,master,Id7ffd9e0e897f5ddad253511dc6085b1b9becb89,Create compass-install project,ABANDONED,2014-12-11 04:01:39.000000000,2014-12-11 08:32:21.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-11 04:01:39.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/28643fe2ad13225b8bb2664df6e66f4d0ac0df15', 'message': 'Create compass-install project\n\nCreate compass-install project to manage installation scripts,\ndocker files and CI scripts for Compass.\n\nChange-Id: Id7ffd9e0e897f5ddad253511dc6085b1b9becb89\n'}]",0,140912,28643fe2ad13225b8bb2664df6e66f4d0ac0df15,4,2,1,6671,,,0,"Create compass-install project

Create compass-install project to manage installation scripts,
docker files and CI scripts for Compass.

Change-Id: Id7ffd9e0e897f5ddad253511dc6085b1b9becb89
",git fetch https://review.opendev.org/openstack/project-config refs/changes/12/140912/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,28643fe2ad13225b8bb2664df6e66f4d0ac0df15,create_compass-install_project, - name: stackforge/compass-install template: - name: merge-check - name: noop-jobs ,,11,0
openstack%2Ftaskflow~master~Ie7adab6aeff344c91151b4df6a55e5adb9d8333a,openstack/taskflow,master,Ie7adab6aeff344c91151b4df6a55e5adb9d8333a,Updated from global requirements,MERGED,2014-12-11 07:20:45.000000000,2014-12-11 08:23:04.000000000,2014-12-11 08:23:03.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-11 07:20:45.000000000', 'files': ['requirements-py2.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a908124c6e3233c7083d429e9cf76eaa30781772', 'message': 'Updated from global requirements\n\nChange-Id: Ie7adab6aeff344c91151b4df6a55e5adb9d8333a\n'}]",0,140961,a908124c6e3233c7083d429e9cf76eaa30781772,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ie7adab6aeff344c91151b4df6a55e5adb9d8333a
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/61/140961/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-py2.txt', 'requirements-py3.txt']",2,a908124c6e3233c7083d429e9cf76eaa30781772,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,2,2
openstack%2Fhorizon~master~Idb8c12559636d3a2efd4787ac478bab33bc98434,openstack/horizon,master,Idb8c12559636d3a2efd4787ac478bab33bc98434,Imported Translations from Transifex,MERGED,2014-12-11 06:03:41.000000000,2014-12-11 07:56:45.000000000,2014-12-11 07:56:44.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-12-11 06:03:41.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6550862314c148f85abc2eef55ff9c25c65f0ce7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Idb8c12559636d3a2efd4787ac478bab33bc98434\n'}]",0,140928,6550862314c148f85abc2eef55ff9c25c65f0ce7,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Idb8c12559636d3a2efd4787ac478bab33bc98434
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/140928/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,6550862314c148f85abc2eef55ff9c25c65f0ce7,transifex/translations,"""POT-Creation-Date: 2014-12-10 22:10-0600\n"" ""PO-Revision-Date: 2014-12-11 00:12+0000\n""#: dashboards/project/instances/workflows/create_instance.py:743#: dashboards/project/instances/workflows/create_instance.py:753#: dashboards/project/instances/workflows/create_instance.py:696#: dashboards/project/instances/workflows/create_instance.py:620#: dashboards/project/instances/workflows/create_instance.py:839#: dashboards/project/instances/workflows/create_instance.py:739#: dashboards/project/instances/workflows/create_instance.py:841#: dashboards/project/instances/workflows/create_instance.py:858#: dashboards/project/instances/workflows/create_instance.py:838#: dashboards/project/instances/workflows/create_instance.py:700#: dashboards/project/instances/workflows/create_instance.py:702#: dashboards/project/instances/workflows/create_instance.py:724#: dashboards/project/instances/workflows/create_instance.py:726#: dashboards/project/instances/workflows/create_instance.py:840#: dashboards/project/instances/workflows/create_instance.py:785#: dashboards/project/instances/workflows/create_instance.py:803#: dashboards/project/instances/workflows/create_instance.py:804#: dashboards/project/instances/workflows/create_instance.py:813#: dashboards/project/instances/workflows/resize_instance.py:89#: dashboards/project/instances/workflows/resize_instance.py:77msgid ""Select Script Source"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:619#: dashboards/project/instances/workflows/create_instance.py:623#: dashboards/project/instances/workflows/create_instance.py:628#: dashboards/project/instances/workflows/create_instance.py:632 #: dashboards/project/instances/workflows/create_instance.py:637#: dashboards/project/instances/workflows/create_instance.py:641 #: dashboards/project/instances/workflows/create_instance.py:646#: dashboards/project/instances/workflows/create_instance.py:673#: dashboards/project/instances/workflows/create_instance.py:681#: dashboards/project/instances/workflows/create_instance.py:708#: dashboards/project/instances/workflows/create_instance.py:711#: dashboards/project/instances/workflows/create_instance.py:786#: dashboards/project/instances/workflows/create_instance.py:790#: dashboards/project/instances/workflows/create_instance.py:791#: dashboards/project/instances/workflows/create_instance.py:817#: dashboards/project/instances/workflows/create_instance.py:855#: dashboards/project/instances/workflows/create_instance.py:915#: dashboards/project/instances/workflows/resize_instance.py:90#: dashboards/project/instances/workflows/resize_instance.py:91#: dashboards/project/instances/workflows/resize_instance.py:92","""POT-Creation-Date: 2014-12-09 21:09-0600\n"" ""PO-Revision-Date: 2014-12-09 09:39+0000\n""#: dashboards/project/instances/workflows/create_instance.py:741#: dashboards/project/instances/workflows/create_instance.py:751#: dashboards/project/instances/workflows/create_instance.py:694#: dashboards/project/instances/workflows/create_instance.py:619#: dashboards/project/instances/workflows/create_instance.py:837#: dashboards/project/instances/workflows/create_instance.py:737#: dashboards/project/instances/workflows/create_instance.py:839#: dashboards/project/instances/workflows/create_instance.py:856#: dashboards/project/instances/workflows/create_instance.py:836#: dashboards/project/instances/workflows/create_instance.py:698#: dashboards/project/instances/workflows/create_instance.py:700#: dashboards/project/instances/workflows/create_instance.py:722#: dashboards/project/instances/workflows/create_instance.py:724#: dashboards/project/instances/workflows/create_instance.py:838#: dashboards/project/instances/workflows/create_instance.py:783#: dashboards/project/instances/workflows/create_instance.py:801#: dashboards/project/instances/workflows/create_instance.py:802#: dashboards/project/instances/workflows/create_instance.py:811#: dashboards/project/instances/workflows/resize_instance.py:88#: dashboards/project/instances/workflows/resize_instance.py:76#: dashboards/project/instances/workflows/create_instance.py:622#: dashboards/project/instances/workflows/create_instance.py:626#: dashboards/project/instances/workflows/create_instance.py:630 #: dashboards/project/instances/workflows/create_instance.py:635#: dashboards/project/instances/workflows/create_instance.py:639 #: dashboards/project/instances/workflows/create_instance.py:644#: dashboards/project/instances/workflows/create_instance.py:671#: dashboards/project/instances/workflows/create_instance.py:679#: dashboards/project/instances/workflows/create_instance.py:706#: dashboards/project/instances/workflows/create_instance.py:709#: dashboards/project/instances/workflows/create_instance.py:784#: dashboards/project/instances/workflows/create_instance.py:788#: dashboards/project/instances/workflows/create_instance.py:789#: dashboards/project/instances/workflows/create_instance.py:815#: dashboards/project/instances/workflows/create_instance.py:853#: dashboards/project/instances/workflows/create_instance.py:913#: dashboards/project/instances/workflows/resize_instance.py:89#: dashboards/project/instances/workflows/resize_instance.py:90#: dashboards/project/instances/workflows/resize_instance.py:91",778,710
openstack%2Fzaqar~master~Id37889c37953fc14cc9ddc749d2f2e265707e044,openstack/zaqar,master,Id37889c37953fc14cc9ddc749d2f2e265707e044,Remove the outdated openstack common modules,MERGED,2014-11-12 05:47:37.000000000,2014-12-11 07:26:40.000000000,2014-12-11 07:26:39.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 7488}]","[{'number': 1, 'created': '2014-11-12 05:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e64e34d90b684f32ef44dd18fcc31c7d59eff047', 'message': 'Remove the outdated openstack common modules\n\nsome of openstack common modules are out of date and do not\nexist in the oslo-incubator\n\nChange-Id: Id37889c37953fc14cc9ddc749d2f2e265707e044\n'}, {'number': 2, 'created': '2014-11-17 02:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/86cb62762e1cd0fc8434f6743fc8fd8660cfdc86', 'message': 'Remove the outdated openstack common modules\n\nsome of openstack common modules are out of date and do not\nexist in the oslo-incubator\n\nChange-Id: Id37889c37953fc14cc9ddc749d2f2e265707e044\n'}, {'number': 3, 'created': '2014-11-18 08:08:19.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c8afcffbda37e1b93d0c59d2d193a99390fa0f32', 'message': 'Remove the outdated openstack common modules\n\nsome of openstack common modules are out of date and do not\nexist in the oslo-incubator\n\nChange-Id: Id37889c37953fc14cc9ddc749d2f2e265707e044\n'}]",0,133886,c8afcffbda37e1b93d0c59d2d193a99390fa0f32,13,4,3,7488,,,0,"Remove the outdated openstack common modules

some of openstack common modules are out of date and do not
exist in the oslo-incubator

Change-Id: Id37889c37953fc14cc9ddc749d2f2e265707e044
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/86/133886/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,e64e34d90b684f32ef44dd18fcc31c7d59eff047,refactor/remove_outdated_modules,module=local,module=config.generator module=excutilsmodule=gettextutils module=importutils module=jsonutilsmodule=setup module=strutils module=timeutils module=version,1,9
openstack%2Fopenstack-manuals~master~I30a33b3d70c5aa504ab82f8eea94ba72a53dd427,openstack/openstack-manuals,master,I30a33b3d70c5aa504ab82f8eea94ba72a53dd427,Imported Translations from Transifex,MERGED,2014-12-11 06:12:24.000000000,2014-12-11 07:26:33.000000000,2014-12-11 07:26:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-11 06:12:24.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/ja.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5844361dc280b1dd4be4793b3f7cef59f2e7111d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I30a33b3d70c5aa504ab82f8eea94ba72a53dd427\n'}]",0,140931,5844361dc280b1dd4be4793b3f7cef59f2e7111d,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I30a33b3d70c5aa504ab82f8eea94ba72a53dd427
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/31/140931/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/ja.po', 'doc/image-guide/locale/ja.po']",3,5844361dc280b1dd4be4793b3f7cef59f2e7111d,transifex/translations,"""POT-Creation-Date: 2014-12-11 05:08+0000\n"" ""PO-Revision-Date: 2014-12-11 05:40+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""msgstr ""Fedora <link href=\""https://getfedora.org/ja/cloud/download/\""/> <systemitem class=\""process\"">cloud-init</systemitem>  <systemitem class=\""username\"">fedora</systemitem> <placeholder-1/>""","""POT-Creation-Date: 2014-12-10 04:44+0000\n"" ""PO-Revision-Date: 2014-12-10 04:41+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"",18,18
openstack%2Fhorizon~master~If298e04952a29acbe3e8bd89e54065525ae5f30c,openstack/horizon,master,If298e04952a29acbe3e8bd89e54065525ae5f30c,No delete volume action for volume with snapshots,MERGED,2014-11-21 17:18:10.000000000,2014-12-11 07:11:55.000000000,2014-12-11 07:11:53.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6637}, {'_account_id': 7012}, {'_account_id': 7665}, {'_account_id': 9981}, {'_account_id': 10881}, {'_account_id': 11096}, {'_account_id': 11880}, {'_account_id': 13325}, {'_account_id': 14151}]","[{'number': 1, 'created': '2014-11-21 17:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4faf6768bba2b1e5422a66f41b6c2785536e3c15', 'message': 'No delete volume action for volume with snapshots\n\nCurrent a volume with snapshots still has the ""Delete Volume"" menu action.\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 2, 'created': '2014-11-21 19:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/de21634a279f60bbcdc47b2d065f8225aa6d44b1', 'message': 'No delete volume action for volume with snapshots\n\nCurrent a volume with snapshots still has the ""Delete Volume"" menu action.\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 3, 'created': '2014-11-22 03:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1cc313e7c082be15f2c8a70359824bb5ebe03014', 'message': 'No delete volume action for volume with snapshots\n\nCurrent a volume with snapshots still has the ""Delete Volume"" menu action.\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 4, 'created': '2014-11-22 04:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1c9e0f2735f4822217c6f61b66b1d37fad2f3f9a', 'message': 'No delete volume action for volume with snapshots\n\nCurrent a volume with snapshots still has the ""Delete Volume"" menu action.\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 5, 'created': '2014-12-01 23:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e37495fceb88ea7a8fec41081c2a263ff80652d0', 'message': 'No delete volume action for volume with snapshots\n\nCurrently a volume with snapshots still has the ""Delete Volume"" menu\naction.\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots. The main purpose of this change is to be consistent\nwith the existing behavior when the volume is not in a deletable state.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 6, 'created': '2014-12-01 23:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d7296e3f17b89cfb659da17ac427efcdfd37ee2a', 'message': 'No delete volume action for volume with snapshots\n\nCurrently a volume with snapshots still has the ""Delete Volume"" menu\naction.\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots. The main purpose of this change is to be consistent\nwith the existing behavior when the volume is not in a deletable state.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 7, 'created': '2014-12-09 02:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e2b25d974712bc6aa29f338010520d7696e6557e', 'message': 'No delete volume action for volume with snapshots\n\nCurrently a volume with snapshots still has the ""Delete Volume"" menu\naction.\n\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots. The main purpose of this change is to be consistent\nwith the existing behavior when the volume is not in a deletable state.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 8, 'created': '2014-12-09 18:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5af9b9e8cea20742a4176cfe94e3f558a771b85a', 'message': 'No delete volume action for volume with snapshots\n\nCurrently a volume with snapshots still has the ""Delete Volume"" menu\naction.\n\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots. The main purpose of this change is to be consistent\nwith the existing behavior when the volume is not in a deletable state.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}, {'number': 9, 'created': '2014-12-11 03:15:24.000000000', 'files': ['openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/project/volumes/test.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f0870fb594cf1676ad3d91c3205eb7004168f755', 'message': 'No delete volume action for volume with snapshots\n\nCurrently a volume with snapshots still has the ""Delete Volume"" menu\naction.\n\nThis fix will not allow the ""Delete Volume"" menu action for a volume\nthat has snapshots. The main purpose of this change is to be consistent\nwith the existing behavior when the volume is not in a deletable state.\n\nCloses-Bug: #1394015\nChange-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c\n'}]",26,136431,f0870fb594cf1676ad3d91c3205eb7004168f755,73,12,9,11880,,,0,"No delete volume action for volume with snapshots

Currently a volume with snapshots still has the ""Delete Volume"" menu
action.

This fix will not allow the ""Delete Volume"" menu action for a volume
that has snapshots. The main purpose of this change is to be consistent
with the existing behavior when the volume is not in a deletable state.

Closes-Bug: #1394015
Change-Id: If298e04952a29acbe3e8bd89e54065525ae5f30c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/31/136431/9 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/volumes/tests.py', 'openstack_dashboard/dashboards/project/volumes/test.py', 'openstack_dashboard/dashboards/project/volumes/volumes/tables.py']",3,4faf6768bba2b1e5422a66f41b6c2785536e3c15,bug/1394015," snapshots = [] if volume: if volume.status in DELETABLE_STATES: opts = {'volume_id': volume.id} try: snapshots = \ cinder.volume_snapshot_list(request, search_opts=opts) except Exception: exceptions.handle( request, _('Unable to retrieve snapshot list')) return not snapshots else: return False", if volume: return volume.status in DELETABLE_STATES,60,5
openstack%2Frequirements~master~Icfddc58933288576e7832bfc2bb1902c4f8b5cbc,openstack/requirements,master,Icfddc58933288576e7832bfc2bb1902c4f8b5cbc,Bump up oslo.utils to 1.1.0,MERGED,2014-12-10 05:22:22.000000000,2014-12-11 07:11:40.000000000,2014-12-11 07:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 7680}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-12-10 05:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/78c367463b965916f992e4a6ea8ea23d0d199c2a', 'message': 'Bump up oslo.utils to 1.1.0\n\nOslo.utils was recently released with version 1.1.0\n\nThat release contains some code that was extracted\nfrom taskflow to provide general functionality to\nother projects. So to allow taskflow to remove that\ncode from its own project we need to bump this up\nto a version that includes that code.\n\nChange-Id: Icfddc58933288576e7832bfc2bb1902c4f8b5cbc\n'}, {'number': 2, 'created': '2014-12-10 20:36:06.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/cc7770e1354fc2e5c1b283d476f1f32ca2da5775', 'message': 'Bump up oslo.utils to 1.1.0\n\nOslo.utils was recently released with version 1.1.0\n\nThat release contains some code that was extracted\nfrom taskflow to provide general functionality to\nother projects. So to allow taskflow to remove that\ncode from its own project we need to bump this up\nto a version that includes that code.\n\nChange-Id: Icfddc58933288576e7832bfc2bb1902c4f8b5cbc\n'}]",0,140573,cc7770e1354fc2e5c1b283d476f1f32ca2da5775,19,5,2,1297,,,0,"Bump up oslo.utils to 1.1.0

Oslo.utils was recently released with version 1.1.0

That release contains some code that was extracted
from taskflow to provide general functionality to
other projects. So to allow taskflow to remove that
code from its own project we need to bump this up
to a version that includes that code.

Change-Id: Icfddc58933288576e7832bfc2bb1902c4f8b5cbc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/73/140573/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,78c367463b965916f992e4a6ea8ea23d0d199c2a,,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Frequirements~master~I577ffa40db7087d5f78ccbd9ad59b1e8e7470403,openstack/requirements,master,I577ffa40db7087d5f78ccbd9ad59b1e8e7470403,Move retrying dependency to version 1.2.3,ABANDONED,2014-12-08 17:46:26.000000000,2014-12-11 05:54:19.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6873}, {'_account_id': 7491}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-12-08 17:46:26.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/283459023032b734c51d56c80f9fd4d0edea3f34', 'message': 'Move retrying dependency to version 1.2.3\n\nIn oslo.concurrent lockutils.py, Retrying is initialized with\nstop_func parameter. This parameter is introduced by retrying\n1.2.3. The object init operation will fail when running with\nretrying 1.2.2 code.\n\nChange-Id: I577ffa40db7087d5f78ccbd9ad59b1e8e7470403\nPartial-Bug: 1400384\n'}]",0,140098,283459023032b734c51d56c80f9fd4d0edea3f34,7,5,1,8574,,,0,"Move retrying dependency to version 1.2.3

In oslo.concurrent lockutils.py, Retrying is initialized with
stop_func parameter. This parameter is introduced by retrying
1.2.3. The object init operation will fail when running with
retrying 1.2.2 code.

Change-Id: I577ffa40db7087d5f78ccbd9ad59b1e8e7470403
Partial-Bug: 1400384
",git fetch https://review.opendev.org/openstack/requirements refs/changes/98/140098/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,283459023032b734c51d56c80f9fd4d0edea3f34,bug/1400384,"retrying>=1.2.3,!=1.3.0 # Apache-2.0","retrying>=1.2.2,!=1.3.0 # Apache-2.0",1,1
openstack%2Fopenstack-manuals~master~I451b21c43147ea73a68676f537cb24919f25e13c,openstack/openstack-manuals,master,I451b21c43147ea73a68676f537cb24919f25e13c,Fix typo: uplodating to uploading,MERGED,2014-12-11 03:03:54.000000000,2014-12-11 05:08:06.000000000,2014-12-11 05:08:05.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10897}]","[{'number': 1, 'created': '2014-12-11 03:03:54.000000000', 'files': ['doc/install-guide/section_trove-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f86b4d6e6d0f8e84d7682edf489ab361a4aa456f', 'message': 'Fix typo: uplodating to uploading\n\nChange-Id: I451b21c43147ea73a68676f537cb24919f25e13c\nCloses-Bug: 1401363\n'}]",0,140904,f86b4d6e6d0f8e84d7682edf489ab361a4aa456f,7,3,1,10497,,,0,"Fix typo: uplodating to uploading

Change-Id: I451b21c43147ea73a68676f537cb24919f25e13c
Closes-Bug: 1401363
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/04/140904/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_trove-install.xml'],1,f86b4d6e6d0f8e84d7682edf489ab361a4aa456f,bug/1401363, <para>Example for uploading rules for MySQL datastore:</para>, <para>Example for uplodating rules for MySQL datastore:</para>,1,1
openstack%2Ftaskflow~master~I2909722156df7bc9321e651c123b5996ac0ffabf,openstack/taskflow,master,I2909722156df7bc9321e651c123b5996ac0ffabf,Move reaction functions to be instance methods,ABANDONED,2014-12-11 04:26:15.000000000,2014-12-11 04:33:34.000000000,,[],"[{'number': 1, 'created': '2014-12-11 04:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/544b01303f1f78f53da4e945150102cc6012d4c3', 'message': 'Move reaction functions to be instance methods\n\nTo avoid creating a number of new functions everytime this\nscope is entered we can just associate the functions with the\nclass instance instead, which will avoid recreating these on\nevery call to build.\n\nChange-Id: I2909722156df7bc9321e651c123b5996ac0ffabf\n'}, {'number': 2, 'created': '2014-12-11 04:28:39.000000000', 'files': ['taskflow/engines/action_engine/runner.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d4fc146c8aa3c14f3bd4c7fdd43100e22b03b878', 'message': 'Move reaction functions to be instance methods\n\nTo avoid creating a number of new functions everytime this\nscope is entered we can just associate the functions with the\nclass instance instead, which will avoid recreating these on\nevery call to build.\n\nChange-Id: I2909722156df7bc9321e651c123b5996ac0ffabf\n'}]",0,140916,d4fc146c8aa3c14f3bd4c7fdd43100e22b03b878,3,0,2,1297,,,0,"Move reaction functions to be instance methods

To avoid creating a number of new functions everytime this
scope is entered we can just associate the functions with the
class instance instead, which will avoid recreating these on
every call to build.

Change-Id: I2909722156df7bc9321e651c123b5996ac0ffabf
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/16/140916/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/runner.py'],1,544b01303f1f78f53da4e945150102cc6012d4c3,," # Machine reactions... def _resume(self, old_state, new_state, event, memory): memory.next_nodes.update(self._completer.resume()) memory.next_nodes.update(self._analyzer.get_next_nodes()) return 'schedule' def _game_over(self, old_state, new_state, event, memory): if memory.failures: return 'failed' if self._analyzer.get_next_nodes(): return 'suspended' elif self._analyzer.is_success(): return 'success' else: return 'reverted' def _schedule(self, old_state, new_state, event, memory): if self.runnable() and memory.next_nodes: not_done, failures = self._scheduler.schedule(memory.next_nodes) if not_done: memory.not_done.update(not_done) if failures: memory.failures.extend(failures) memory.next_nodes.clear() return 'wait' def _wait(self, old_state, new_state, event, memory, timeout): # TODO(harlowja): maybe we should start doing 'yield from' this # call sometime in the future, or equivalent that will work in # py2 and py3. if memory.not_done: done, not_done = self._waiter.wait_for_any(memory.not_done, timeout=timeout) memory.done.update(done) memory.not_done = not_done return 'analyze' def _analyze(self, old_state, new_state, event, memory): next_nodes = set() while memory.done: fut = memory.done.pop() node = fut.atom try: event, result = fut.result() retain = self._completer.complete(node, event, result) if retain and isinstance(result, failure.Failure): memory.failures.append(result) except Exception: memory.failures.append(failure.Failure()) else: try: more_nodes = self._analyzer.get_next_nodes(node) except Exception: memory.failures.append(failure.Failure()) else: next_nodes.update(more_nodes) if self.runnable() and next_nodes and not memory.failures: memory.next_nodes.update(next_nodes) return 'schedule' elif memory.not_done: return 'wait' else: return 'finished' m.add_reaction(_GAME_OVER, 'finished', self._game_over, memory) m.add_reaction(st.ANALYZING, 'analyze', self._analyze, memory) m.add_reaction(st.RESUMING, 'start', self._resume, memory) m.add_reaction(st.SCHEDULING, 'schedule', self._schedule, memory) m.add_reaction(st.WAITING, 'wait', self._wait, memory, timeout)"," def resume(old_state, new_state, event): memory.next_nodes.update(self._completer.resume()) memory.next_nodes.update(self._analyzer.get_next_nodes()) return 'schedule' def game_over(old_state, new_state, event): if memory.failures: return 'failed' if self._analyzer.get_next_nodes(): return 'suspended' elif self._analyzer.is_success(): return 'success' else: return 'reverted' def schedule(old_state, new_state, event): if self.runnable() and memory.next_nodes: not_done, failures = self._scheduler.schedule( memory.next_nodes) if not_done: memory.not_done.update(not_done) if failures: memory.failures.extend(failures) memory.next_nodes.clear() return 'wait' def wait(old_state, new_state, event): # TODO(harlowja): maybe we should start doing 'yield from' this # call sometime in the future, or equivalent that will work in # py2 and py3. if memory.not_done: done, not_done = self._waiter.wait_for_any(memory.not_done, timeout) memory.done.update(done) memory.not_done = not_done return 'analyze' def analyze(old_state, new_state, event): next_nodes = set() while memory.done: fut = memory.done.pop() node = fut.atom try: event, result = fut.result() retain = self._completer.complete(node, event, result) if retain and isinstance(result, failure.Failure): memory.failures.append(result) except Exception: memory.failures.append(failure.Failure()) else: try: more_nodes = self._analyzer.get_next_nodes(node) except Exception: memory.failures.append(failure.Failure()) else: next_nodes.update(more_nodes) if self.runnable() and next_nodes and not memory.failures: memory.next_nodes.update(next_nodes) return 'schedule' elif memory.not_done: return 'wait' else: return 'finished' m.add_reaction(_GAME_OVER, 'finished', game_over) m.add_reaction(st.ANALYZING, 'analyze', analyze) m.add_reaction(st.RESUMING, 'start', resume) m.add_reaction(st.SCHEDULING, 'schedule', schedule) m.add_reaction(st.WAITING, 'wait', wait)",70,69
openstack%2Ftaskflow~master~I6cb027bab5c32bc4a24be683aec88f397c0cd707,openstack/taskflow,master,I6cb027bab5c32bc4a24be683aec88f397c0cd707,Ensure message gets processed correctly,MERGED,2014-12-11 03:03:33.000000000,2014-12-11 04:27:42.000000000,2014-12-11 04:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-11 03:03:33.000000000', 'files': ['taskflow/logging.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f1457a02aea3e32bffa3339f395597a38871b891', 'message': 'Ensure message gets processed correctly\n\nMake sure that we call the local log() function and not\nthe adapted loggers log function to ensure that we pick\nup the adapters potentially existing extra values.\n\nChange-Id: I6cb027bab5c32bc4a24be683aec88f397c0cd707\n'}]",0,140903,f1457a02aea3e32bffa3339f395597a38871b891,6,2,1,1297,,,0,"Ensure message gets processed correctly

Make sure that we call the local log() function and not
the adapted loggers log function to ensure that we pick
up the adapters potentially existing extra values.

Change-Id: I6cb027bab5c32bc4a24be683aec88f397c0cd707
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/03/140903/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/logging.py'],1,f1457a02aea3e32bffa3339f395597a38871b891,," self.log(BLATHER, msg, *args, **kwargs)"," self.logger.log(BLATHER, msg, *args, **kwargs)",1,1
openstack%2Fbarbican~master~I54f36c5a19488c4af5dfa67550b3d822922b4bb9,openstack/barbican,master,I54f36c5a19488c4af5dfa67550b3d822922b4bb9,Replace 'tenants' for 'projects' in documentation,MERGED,2014-12-10 13:40:38.000000000,2014-12-11 04:17:52.000000000,2014-12-11 04:17:51.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-10 13:40:38.000000000', 'files': ['docs/src/docbkx/ck-devguide.xml', 'docs/src/docbkx/ck-gettingstarted.xml', 'docs/src/wadl/Barbican.wadl'], 'web_link': 'https://opendev.org/openstack/barbican/commit/347a3258338fdefbe6b63ffa32956fdff2de449e', 'message': ""Replace 'tenants' for 'projects' in documentation\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: I54f36c5a19488c4af5dfa67550b3d822922b4bb9\n""}]",0,140679,347a3258338fdefbe6b63ffa32956fdff2de449e,9,13,1,10873,,,0,"Replace 'tenants' for 'projects' in documentation

Partially implements: blueprint replace-concept-of-tenants-for-projects

Change-Id: I54f36c5a19488c4af5dfa67550b3d822922b4bb9
",git fetch https://review.opendev.org/openstack/barbican refs/changes/79/140679/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/src/docbkx/ck-devguide.xml', 'docs/src/docbkx/ck-gettingstarted.xml', 'docs/src/wadl/Barbican.wadl']",3,347a3258338fdefbe6b63ffa32956fdff2de449e,bp/replace-concept-of-tenants-for-projects," <doc>This parameter specifies the project ID of the client <para role=""shortdesc"">This method retrieves all secrets for a given project.</para> <para>This method lists all the secrets for a project.</para> project. </doc> datastore for the specified project.</doc> <para role=""shortdesc"">This method retrieves all orders for a given project.</para> <para>This method lists all orders for a specified project. Performing a GET on the secrets resource with no UUID retrieves a batch of the most recent orders per the requesting project."," <doc>This parameter specifies the tenant ID of the client <para role=""shortdesc"">This method retrieves all secrets for a given tenant.</para> <para>This method lists all the secrets for a tenant.</para> tenant. </doc> datastore for the specified tenant.</doc> <para role=""shortdesc"">This method retrieves all orders for a given tenant.</para> <para>This method lists all orders for a specified tenant. Performing a GET on the secrets resource with no UUID retrieves a batch of the most recent orders per the requesting tenant. ",13,13
openstack%2Fpython-heatclient~master~I1ace9268b09e6fc0d0c0ff02ce1f2e31940d961d,openstack/python-heatclient,master,I1ace9268b09e6fc0d0c0ff02ce1f2e31940d961d,Curl statements to include globoff for IPv6 URLs,MERGED,2014-11-21 13:14:17.000000000,2014-12-11 04:09:05.000000000,2014-12-11 04:09:04.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 9542}, {'_account_id': 10257}, {'_account_id': 10267}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-11-21 13:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/f0212044dbd9d6f45346f6ec6e8d4aca20bfd566', 'message': 'Curl statements to include globoff for IPv6 URLs\n\npython-heatclient displays curl statements for debugging/troubleshooting\npurposes. For IPv6 URLs, curl requires --globoff to be passed in the\narguments. Since heatclient does not use curl directly, this patch\ndisplays the curl commands with globoff option which works for both\nIPv4 and IPv6 URLs.\nFix adapted from python-novaclient Ib7099e8e3bbc15f29bbaa1db37ef21e78a74e7bc\n\nCloses-Bug: #1228744\nChange-Id: I1ace9268b09e6fc0d0c0ff02ce1f2e31940d961d\n'}, {'number': 2, 'created': '2014-11-24 06:52:24.000000000', 'files': ['heatclient/common/http.py', 'heatclient/tests/test_common_http.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0d69f021d961c0458d93bcbecdfbe5e53434cf0c', 'message': 'Curl statements to include globoff for IPv6 URLs\n\npython-heatclient displays curl statements for debugging/troubleshooting\npurposes. For IPv6 URLs, curl requires --globoff to be passed in the\narguments. Since heatclient does not use curl directly, this patch\ndisplays the curl commands with globoff option which works for both\nIPv4 and IPv6 URLs.\nFix adapted from python-novaclient Ib7099e8e3bbc15f29bbaa1db37ef21e78a74e7bc\n\nCloses-Bug: #1228744\nChange-Id: I1ace9268b09e6fc0d0c0ff02ce1f2e31940d961d\n'}]",0,136332,0d69f021d961c0458d93bcbecdfbe5e53434cf0c,29,9,2,10257,,,0,"Curl statements to include globoff for IPv6 URLs

python-heatclient displays curl statements for debugging/troubleshooting
purposes. For IPv6 URLs, curl requires --globoff to be passed in the
arguments. Since heatclient does not use curl directly, this patch
displays the curl commands with globoff option which works for both
IPv4 and IPv6 URLs.
Fix adapted from python-novaclient Ib7099e8e3bbc15f29bbaa1db37ef21e78a74e7bc

Closes-Bug: #1228744
Change-Id: I1ace9268b09e6fc0d0c0ff02ce1f2e31940d961d
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/32/136332/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/common/http.py', 'heatclient/openstack/common/apiclient/client.py', 'heatclient/tests/test_common_http.py']",3,f0212044dbd9d6f45346f6ec6e8d4aca20bfd566,bug/1228744," ""curl -g -i -X GET -H 'key: value' --key TEST_KEY "" u""curl -g -i -X GET -H 'Key: foo' http://somewhere"""," ""curl -i -X GET -H 'key: value' --key TEST_KEY "" u""curl -i -X GET -H 'Key: foo' http://somewhere""",4,4
openstack%2Fhorizon~master~I239aa2df055d5158ded2fd2ea8a27779764b2f8d,openstack/horizon,master,I239aa2df055d5158ded2fd2ea8a27779764b2f8d,Updated from global requirements,MERGED,2014-12-10 17:39:51.000000000,2014-12-11 04:07:26.000000000,2014-12-11 04:07:24.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-12-10 17:39:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c9414f5615ccca2b0b4378a68f4852171e451b36', 'message': 'Updated from global requirements\n\nChange-Id: I239aa2df055d5158ded2fd2ea8a27779764b2f8d\n'}]",0,140784,c9414f5615ccca2b0b4378a68f4852171e451b36,11,6,1,11131,,,0,"Updated from global requirements

Change-Id: I239aa2df055d5158ded2fd2ea8a27779764b2f8d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/84/140784/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c9414f5615ccca2b0b4378a68f4852171e451b36,openstack/requirements,"XStatic-Font-Awesome>=4.2.0 # SIL OFL 1.1 License, MIT License","XStatic-Font-Awesome>=4.1.0 # SIL OFL 1.1 License, MIT License",1,1
openstack%2Fheat-templates~master~I9b0685abc074525461c57df1d1d9afdf9d3bdd73,openstack/heat-templates,master,I9b0685abc074525461c57df1d1d9afdf9d3bdd73,Fix file exists asserts,MERGED,2014-12-11 00:57:13.000000000,2014-12-11 03:35:42.000000000,2014-12-11 03:35:41.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-12-11 00:57:13.000000000', 'files': ['tests/software_config/test_heat_config.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/dc84c21e5fb85604d39fd7fcca56b0bc995fc46d', 'message': 'Fix file exists asserts\n\nassertTrue should have been assertThat\n\nChange-Id: I9b0685abc074525461c57df1d1d9afdf9d3bdd73\n'}]",0,140885,dc84c21e5fb85604d39fd7fcca56b0bc995fc46d,7,3,1,4571,,,0,"Fix file exists asserts

assertTrue should have been assertThat

Change-Id: I9b0685abc074525461c57df1d1d9afdf9d3bdd73
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/85/140885/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/software_config/test_heat_config.py'],1,dc84c21e5fb85604d39fd7fcca56b0bc995fc46d,heat-config-kubelet," self.assertThat(hook_path, matchers.FileExists()) self.assertThat(stdin_path, matchers.FileExists()) self.assertThat(stdout_path, matchers.FileExists())"," self.assertTrue(hook_path, matchers.FileExists()) self.assertTrue(stdin_path, matchers.FileExists()) self.assertTrue(stdout_path, matchers.FileExists())",3,3
openstack%2Ftaskflow~master~I828211403bd02bfd6777b10cdcfe58fb0637a52c,openstack/taskflow,master,I828211403bd02bfd6777b10cdcfe58fb0637a52c,Add and use a new simple helper logging module,MERGED,2014-09-21 17:45:22.000000000,2014-12-11 03:13:44.000000000,2014-12-11 03:13:43.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2243}, {'_account_id': 10263}]","[{'number': 1, 'created': '2014-09-21 17:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2d79182167ca90bd536d174f2410847d2ec66460', 'message': 'Add a helper logging module\n\nTo add a new logging SUBDEBUG level and easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information or very verbose runtime\nactivities start to add a new logging module that can be\nused to get logging adapters back that can output at this\nnew level.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 2, 'created': '2014-09-21 18:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3a0075ef667c8ff9d46e916fd43cccec99d0bfc8', 'message': 'Add and use a new helper logging module\n\nTo add a new logging SUBDEBUG level and easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information or very verbose runtime\nactivities start to add a new logging module that can be\nused to get logging adapters back that can output at this\nnew level.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 3, 'created': '2014-09-21 21:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/69f7434f8ca662cb44f6c317be584b3bb36e66dd', 'message': 'Add and use a new helper logging module\n\nTo add a new logging SUBDEBUG level and easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information or very verbose runtime\nactivities start to add a new logging module that can be\nused to get logging adapters back that can output at this\nnew level.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 4, 'created': '2014-09-21 22:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7f9f83207a04603080f589e893371568977988d6', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging SUBDEBUG level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information...\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 5, 'created': '2014-09-26 21:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6bf952c7d81c7d9d1d7231afba7178b1e4e1ad07', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging SUBDEBUG level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information...\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 6, 'created': '2014-10-22 06:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/734720e0860d6d3a22eb569a5a3e93b9d294f2d2', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging SUBDEBUG level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information...\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 7, 'created': '2014-10-22 07:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/40bebe1fa97c2c35f1c16f5acb22304bfb7db4b3', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging SUBDEBUG level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information...\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 8, 'created': '2014-10-22 15:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ec66b7d5e2aee303f95ab9be1f60e795f68d35ef', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging SUBDEBUG level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information...\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 9, 'created': '2014-10-22 15:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5d7f11a02c7ae9964384bc4a8fc7dd8fcf871068', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information...\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 10, 'created': '2014-10-26 00:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c10779d8a859b0d6ca4d212b0442d641f03a7229', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 11, 'created': '2014-11-19 19:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b40a53d9962c914f3789d3c37a215d72ba5b4276', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 12, 'created': '2014-11-19 21:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/258ff33176b38be7406fd334f65d009d82bc919d', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 13, 'created': '2014-12-08 20:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6f9ccd195386ceb515b6e54823df8d00e1c016ef', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 14, 'created': '2014-12-08 22:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/368635693830d5294df158b2ed07ab757fcec71d', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 15, 'created': '2014-12-08 23:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fcf9870bfd8f35d9fbb59abbaede233ef860734f', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}, {'number': 16, 'created': '2014-12-09 06:09:26.000000000', 'files': ['taskflow/engines/worker_based/server.py', 'taskflow/engines/action_engine/actions/retry.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/atom.py', 'taskflow/persistence/backends/impl_sqlalchemy.py', 'taskflow/engines/action_engine/runner.py', 'taskflow/engines/worker_based/dispatcher.py', 'taskflow/jobs/backends/__init__.py', 'taskflow/storage.py', 'taskflow/test.py', 'taskflow/persistence/backends/impl_zookeeper.py', 'taskflow/persistence/backends/impl_memory.py', 'taskflow/listeners/logging.py', 'taskflow/engines/helpers.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/engines/worker_based/worker.py', 'taskflow/conductors/single_threaded.py', 'taskflow/utils/persistence_utils.py', 'taskflow/engines/worker_based/proxy.py', 'taskflow/persistence/logbook.py', 'taskflow/listeners/timing.py', 'taskflow/engines/action_engine/actions/task.py', 'taskflow/listeners/base.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/task.py', 'taskflow/utils/lock_utils.py', 'taskflow/persistence/backends/impl_dir.py', 'taskflow/engines/action_engine/scopes.py', 'taskflow/logging.py', 'taskflow/engines/action_engine/compiler.py', 'taskflow/retry.py', 'taskflow/persistence/backends/__init__.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/14431bc0769673fe5a70182189e2d4038a804cd8', 'message': 'Add and use a new simple helper logging module\n\nAdd a new logging BLATHER level to easily allow its\nusage for messages that are below the normal DEBUG level\nsuch as compilation information and scope lookup info\nwhich can be very verbose in logs if always enabled.\n\nChange-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c\n'}]",0,123007,14431bc0769673fe5a70182189e2d4038a804cd8,45,4,16,1297,,,0,"Add and use a new simple helper logging module

Add a new logging BLATHER level to easily allow its
usage for messages that are below the normal DEBUG level
such as compilation information and scope lookup info
which can be very verbose in logs if always enabled.

Change-Id: I828211403bd02bfd6777b10cdcfe58fb0637a52c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/07/123007/16 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/logging.py'],1,2d79182167ca90bd536d174f2410847d2ec66460,logger-helper,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import absolute_import import logging # Add a SUBDEBUG level, this matches the multiprocessing utils.py module that # declares a similar level, this level is for information that is even lower # level than regular debug and gives out so much runtime information that it # is only useful by low-level users... SUBDEBUG = 5 logging.addLevelName(SUBDEBUG, 'SUBDEBUG') # Copy over attributes to make it easy to use this module CRITICAL = logging.CRITICAL DEBUG = logging.DEBUG ERROR = logging.ERROR FATAL = logging.FATAL NOTSET = logging.NOTSET WARN = logging.WARN WARNING = logging.WARNING class _SubDebugLoggerAdapter(logging.LoggerAdapter): def subdebug(self, *args, **kwargs): self.logger.log(SUBDEBUG, *args, **kwargs) def getLogger(name='taskflow', extra=None): return _SubDebugLoggerAdapter(logging.getLogger(name=name), extra=extra) ",,44,0
openstack%2Fironic~stable%2Ficehouse~Ie80ea287ce24b2ecca02463061bac77c1fe78735,openstack/ironic,stable/icehouse,Ie80ea287ce24b2ecca02463061bac77c1fe78735,Updated from global requirements,MERGED,2014-11-26 20:48:05.000000000,2014-12-11 02:48:04.000000000,2014-12-11 02:48:03.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-11-26 20:48:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/070730e5fcadf232db47105f5057dab172dee623', 'message': 'Updated from global requirements\n\nChange-Id: Ie80ea287ce24b2ecca02463061bac77c1fe78735\n'}]",0,137470,070730e5fcadf232db47105f5057dab172dee623,12,7,1,11131,,,0,"Updated from global requirements

Change-Id: Ie80ea287ce24b2ecca02463061bac77c1fe78735
",git fetch https://review.opendev.org/openstack/ironic refs/changes/70/137470/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,070730e5fcadf232db47105f5057dab172dee623,openstack/requirements,"python-neutronclient>=2.3.4,<2.4 python-glanceclient>=0.9.0,!=0.14.0,<0.15 python-keystoneclient>=0.7.0,<0.12 stevedore>=0.14,<1.2oslo.config>=1.2.0,<1.5 oslo.rootwrap<1.4","python-neutronclient>=2.3.4,<3 python-glanceclient>=0.9.0,!=0.14.0 python-keystoneclient>=0.7.0 stevedore>=0.14oslo.config>=1.2.0 oslo.rootwrap",6,6
openstack%2Fironic~master~I4b8a4ee5fce8f3d0e47e111fa16e03de603c5038,openstack/ironic,master,I4b8a4ee5fce8f3d0e47e111fa16e03de603c5038,Updated from global requirements,MERGED,2014-12-10 17:30:49.000000000,2014-12-11 02:31:44.000000000,2014-12-11 02:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10343}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-10 17:30:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/98a0542c5857a26063851157974f3fbc82bfb3f7', 'message': 'Updated from global requirements\n\nChange-Id: I4b8a4ee5fce8f3d0e47e111fa16e03de603c5038\n'}]",0,140779,98a0542c5857a26063851157974f3fbc82bfb3f7,14,4,1,11131,,,0,"Updated from global requirements

Change-Id: I4b8a4ee5fce8f3d0e47e111fa16e03de603c5038
",git fetch https://review.opendev.org/openstack/ironic refs/changes/79/140779/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,98a0542c5857a26063851157974f3fbc82bfb3f7,openstack/requirements,"retrying>=1.2.3,!=1.3.0 # Apache-2.0","retrying>=1.2.2,!=1.3.0 # Apache-2.0",1,1
openstack%2Fironic~master~I2220f685c862832f73b28157355e11c7b49ce29b,openstack/ironic,master,I2220f685c862832f73b28157355e11c7b49ce29b,Update dev quick-start for devstack,MERGED,2014-12-08 19:24:22.000000000,2014-12-11 02:31:21.000000000,2014-12-11 02:31:21.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-08 19:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b765a036741a220498c6260810da441784f9ea4d', 'message': ""Update dev quick-start for devstack\n\nThe devstack section of the developer's quick-start documentation is\nupdated:\n1. replaces the https://devstack.org link (doesn't work) with\n   http://docs.openstack.org/developer/devstack/\n2. clarifies how to configure usage of the PXE or agent driver\n\nChange-Id: I2220f685c862832f73b28157355e11c7b49ce29b\nCloses-Bug: #1400461\n""}, {'number': 2, 'created': '2014-12-10 21:15:06.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/97ab88d818f659d0a0be3c79962dd6edfd2ff35e', 'message': ""Update dev quick-start for devstack\n\nThe devstack section of the developer's quick-start documentation is\nupdated:\n1. replaces the https://devstack.org link (doesn't work) with\n   http://docs.openstack.org/developer/devstack/\n2. clarifies how to configure usage of the PXE or agent driver\n\nChange-Id: I2220f685c862832f73b28157355e11c7b49ce29b\nCloses-Bug: #1400461\n""}]",0,140124,97ab88d818f659d0a0be3c79962dd6edfd2ff35e,13,4,2,6618,,,0,"Update dev quick-start for devstack

The devstack section of the developer's quick-start documentation is
updated:
1. replaces the https://devstack.org link (doesn't work) with
   http://docs.openstack.org/developer/devstack/
2. clarifies how to configure usage of the PXE or agent driver

Change-Id: I2220f685c862832f73b28157355e11c7b49ce29b
Closes-Bug: #1400461
",git fetch https://review.opendev.org/openstack/ironic refs/changes/24/140124/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,b765a036741a220498c6260810da441784f9ea4d,bug/1400461," http://docs.openstack.org/developer/devstack/or the agent driver, not both. The default is the PXE driver.::If running with the agent driver (instead of PXE driver), add these additional settings to localrc::"," https://devstack.orgor the agent driver, not both.::If running with the agent driver::",4,3
openstack%2Fmonasca-api~master~I3f470969177350becef38379c8754e311e7a5a8e,openstack/monasca-api,master,I3f470969177350becef38379c8754e311e7a5a8e,Add requirements,MERGED,2014-12-10 21:42:31.000000000,2014-12-11 02:18:38.000000000,2014-12-11 02:18:38.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-12-10 21:42:31.000000000', 'files': ['ref-impl-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/c47a6db94418fc0da38f7a0f21b1ed921867a95a', 'message': 'Add requirements\n\npeewee\nvoluptuous\n\nChange-Id: I3f470969177350becef38379c8754e311e7a5a8e\n'}]",0,140842,c47a6db94418fc0da38f7a0f21b1ed921867a95a,6,2,1,12512,,,0,"Add requirements

peewee
voluptuous

Change-Id: I3f470969177350becef38379c8754e311e7a5a8e
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/42/140842/1 && git format-patch -1 --stdout FETCH_HEAD,['ref-impl-requirements.txt'],1,c47a6db94418fc0da38f7a0f21b1ed921867a95a,,peewee>=2.3.3voluptuous>=0.8.5,,2,0
openstack%2Fneutron~master~I3529fe4146c50c940f41eb26d0b5efc5870b3af9,openstack/neutron,master,I3529fe4146c50c940f41eb26d0b5efc5870b3af9,Move classes out of l3_agent.py,MERGED,2014-10-22 18:24:53.000000000,2014-12-11 02:00:43.000000000,2014-12-11 02:00:42.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-22 18:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c5d059bde5e37d332896b1fa0c15c7240a9e1e6', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 2, 'created': '2014-10-22 19:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5845820c6cf1c18c7568ff0cdec7ee071431991f', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 3, 'created': '2014-10-28 17:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab3cfc41717cb3c1625a3d42d8e08f867f63d285', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 4, 'created': '2014-11-20 15:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09e58dbe70398e21c0601d529e73a92228fe0c71', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 5, 'created': '2014-11-20 16:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5d4affb1a07a9e1ab0f5900c298c2f814b38c1c', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 6, 'created': '2014-11-20 21:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24b2158751add15448be0dc1ba0c44d9dbc23144', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 7, 'created': '2014-11-23 10:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf665752e62bd116f1c90de69f6d8e25aa10944e', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 8, 'created': '2014-11-26 14:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/170d1ae8ef97ce64410260942301fdf114e560ec', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 9, 'created': '2014-11-26 16:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4bc52cc4ed3c98b02a6f2146a450d0f915a9fe47', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 10, 'created': '2014-12-01 21:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/96da4dae8d2a484d85bd8f2a1c11db7b4e561363', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 11, 'created': '2014-12-01 22:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b0b9ce62c1e490d90cec9e9aa6b8d7359f7f1da', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 12, 'created': '2014-12-02 00:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8362b71032323a295bd5df8556f2a31f50ed436e', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 13, 'created': '2014-12-08 17:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/820341d774878f24ba807366d146182fac99e636', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 14, 'created': '2014-12-09 00:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/80fe70b79d4f48cbf74c6d0e3ee899b0571a830f', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 15, 'created': '2014-12-09 22:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d52d959e902d1b9908c61c5285b510d7b20f9b97', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 16, 'created': '2014-12-10 17:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a01105652663d0bc510015eaadfa21f06f541b6', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 17, 'created': '2014-12-10 19:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c705dc9d02743c6cb7b45ad8c871985cb3c1742a', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}, {'number': 18, 'created': '2014-12-10 22:22:05.000000000', 'files': ['neutron/agent/l3/link_local_allocator.py', 'neutron/tests/unit/test_router_processing_queue.py', 'neutron/tests/common/agents/l3_agent.py', 'neutron/agent/l3/router_info.py', 'neutron/agent/l3/ha.py', 'neutron/agent/netns_cleanup_util.py', 'neutron/agent/l3/__init__.py', 'neutron/tests/unit/test_l3_dvr.py', 'neutron/agent/l3/agent.py', 'neutron/agent/l3/router_processing_queue.py', 'neutron/agent/ovs_cleanup_util.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7c5306360a052201e0d91019ebc5a1062808241', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9\n""}]",11,130300,d7c5306360a052201e0d91019ebc5a1062808241,382,43,18,7448,,,0,"Move classes out of l3_agent.py

The file l3_agent.py has become too large.  This patch is a simple
pure refactor to move some of the functionality in to other files
where things aren't too tangled up.  There is no functional change
with this patch and I avoided gratuitous other fixups in this patch in
order to make it easier to review.

I plan to follow up on the new l3_dvr and l3_agent_router modules with
more restructuring in the near future.

Partially-Implements: bp restructure-l3-agent

Change-Id: I3529fe4146c50c940f41eb26d0b5efc5870b3af9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/130300/18 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_router_processing_queue.py', 'neutron/services/firewall/agents/varmour/varmour_router.py', 'neutron/agent/l3_agent.py', 'neutron/agent/l3_dvr.py', 'neutron/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/test_l3_dvr.py', 'neutron/agent/router_processing_queue.py', 'neutron/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/agent/l3_agent_router.py', 'neutron/tests/unit/services/firewall/agents/varmour/test_varmour_router.py']",12,5c5d059bde5e37d332896b1fa0c15c7240a9e1e6,bp/restructure-l3-agent,"from neutron.agent import l3_agent_router ri = l3_agent_router.RouterInfo(router['id'], self.conf.root_helper, router=router)","from neutron.agent import l3_agent ri = l3_agent.RouterInfo(router['id'], self.conf.root_helper, router=router)",631,528
openstack%2Fnova~stable%2Fjuno~I1dcee9181fd0ef293628b30766112f00792796ab,openstack/nova,stable/juno,I1dcee9181fd0ef293628b30766112f00792796ab,Fix live migration api stuck when migrate to old nova node,MERGED,2014-12-03 11:23:52.000000000,2014-12-11 01:57:36.000000000,2014-12-11 01:57:32.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 10118}]","[{'number': 1, 'created': '2014-12-03 11:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/832c51f1c798df9bff8fd0b27e35a56302fb9ecf', 'message': ""Fix live migration api stuck when migrate to old nova node\n\nCommit bc45c56f102cdef58840e02b609a89f5278e8cce disable instance\nlive migration between different verison node. If the two nodes\nwith different rpc version, will raise exception\nLiveMigrationWithOldNovaNotSafe. But this exception didn't catch\nas expected exception, that make the instance status stuck at\nmigrating. This patch add LiveMigrationWithOldNovaNotSafe as\nexpected exception.\n\nConflicts:\n        nova/tests/unit/api/openstack/compute/contrib/test_admin_actions.py\n        nova/tests/unit/api/openstack/compute/contrib/test_migrate_server.py\n        nova/tests/unit/conductor/test_conductor.py\n\nChange-Id: I1dcee9181fd0ef293628b30766112f00792796ab\nCloses-Bug: #1377644\n""}, {'number': 2, 'created': '2014-12-03 12:42:08.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_admin_actions.py', 'nova/api/openstack/compute/plugins/v3/migrate_server.py', 'nova/tests/api/openstack/compute/contrib/test_migrate_server.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py', 'nova/api/openstack/compute/contrib/admin_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/46fa995212399d906d3f8dcc0b44ffffe87c49a1', 'message': ""Fix live migration api stuck when migrate to old nova node\n\nCommit bc45c56f102cdef58840e02b609a89f5278e8cce disable instance\nlive migration between different verison node. If the two nodes\nwith different rpc version, will raise exception\nLiveMigrationWithOldNovaNotSafe. But this exception didn't catch\nas expected exception, that make the instance status stuck at\nmigrating. This patch add LiveMigrationWithOldNovaNotSafe as\nexpected exception.\n\nConflicts:\n        nova/tests/unit/api/openstack/compute/contrib/test_admin_actions.py\n        nova/tests/unit/api/openstack/compute/contrib/test_migrate_server.py\n        nova/tests/unit/conductor/test_conductor.py\n\nChange-Id: I1dcee9181fd0ef293628b30766112f00792796ab\nCloses-Bug: #1377644\n""}]",0,138685,46fa995212399d906d3f8dcc0b44ffffe87c49a1,18,6,2,5754,,,0,"Fix live migration api stuck when migrate to old nova node

Commit bc45c56f102cdef58840e02b609a89f5278e8cce disable instance
live migration between different verison node. If the two nodes
with different rpc version, will raise exception
LiveMigrationWithOldNovaNotSafe. But this exception didn't catch
as expected exception, that make the instance status stuck at
migrating. This patch add LiveMigrationWithOldNovaNotSafe as
expected exception.

Conflicts:
        nova/tests/unit/api/openstack/compute/contrib/test_admin_actions.py
        nova/tests/unit/api/openstack/compute/contrib/test_migrate_server.py
        nova/tests/unit/conductor/test_conductor.py

Change-Id: I1dcee9181fd0ef293628b30766112f00792796ab
Closes-Bug: #1377644
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/138685/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/migrate_server.py', 'nova/tests/api/openstack/compute/contrib/test_admin_actions.py', 'nova/tests/api/openstack/compute/contrib/test_migrate_server.py', 'nova/tests/conductor/test_conductor.py', 'nova/conductor/manager.py', 'nova/api/openstack/compute/contrib/admin_actions.py']",6,832c51f1c798df9bff8fd0b27e35a56302fb9ecf,(detached," exception.MigrationPreCheckError, exception.LiveMigrationWithOldNovaNotSafe) as ex:", exception.MigrationPreCheckError) as ex:,21,4
openstack%2Fproject-config~master~I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080,openstack/project-config,master,I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080,Adds experimental job for testing Nova V2.1 API,MERGED,2014-12-04 04:41:30.000000000,2014-12-11 01:12:31.000000000,2014-12-11 01:12:30.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5196}, {'_account_id': 5441}, {'_account_id': 6133}, {'_account_id': 6167}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-12-04 04:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8faeadb8990a61767ebad5249f44200b88abd53d', 'message': ""Adds experimental job for testing Nova V2.1 API\n\nNow Nova contains both v2 and v2.1 APIs as its REST API, and we are\ntesting v2 API only on the gate. To test v2.1 API also, this patch\nadd a new experimental job 'tempest-dsvm-nova-v21-full'.\n\nThis job is added-\n\t- As experimental\n\t- For non Icehouse/Juno branch\n\t- Run in Nova, Tempest & Tempest-lib\n\nDevstack-gate patch - I29e2245e5b2be9bf57ba74a0fe00f335d1b170ec\n\nChange-Id: I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080\n""}, {'number': 2, 'created': '2014-12-04 04:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/de26466b11d5502263c6227e87d701bf6b495a5e', 'message': ""Adds experimental job for testing Nova V2.1 API\n\nNow Nova contains both v2 and v2.1 APIs as its REST API, and we are\ntesting v2 API only on the gate. To test v2.1 API also, this patch\nadd a new experimental job 'tempest-dsvm-nova-v21-full'.\n\nThis job is added-\n\t- As experimental\n\t- For non Icehouse/Juno branch\n\t- Run in Nova, Tempest & Tempest-lib\n\nDevstack-gate patch - I29e2245e5b2be9bf57ba74a0fe00f335d1b170ec\n\nChange-Id: I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080\n""}, {'number': 3, 'created': '2014-12-04 06:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a6517615bc4c95b12c95944977adc3a95091c619', 'message': ""Adds experimental job for testing Nova V2.1 API\n\nNow Nova contains both v2 and v2.1 APIs as its REST API, and we are\ntesting v2 API only on the gate. To test v2.1 API also, this patch\nadd a new experimental job 'tempest-dsvm-nova-v21-full'.\n\nThis job is added-\n\t- As experimental\n\t- For non Icehouse/Juno branch\n\t- Run in Nova, Tempest & Tempest-lib\n\nDevstack-gate patch - I29e2245e5b2be9bf57ba74a0fe00f335d1b170ec\n\nChange-Id: I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080\n""}, {'number': 4, 'created': '2014-12-04 08:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bcf7ec26bac1af2426bad350b703384ef41e6a73', 'message': ""Adds experimental job for testing Nova V2.1 API\n\nNow Nova contains both v2 and v2.1 APIs as its REST API, and we are\ntesting v2 API only on the gate. To test v2.1 API also, this patch\nadd a new experimental job 'tempest-dsvm-nova-v21-full'.\n\nThis job is added-\n - As experimental\n - For non Icehouse/Juno branch\n - Run in Nova, Tempest & Tempest-lib\n\nDepends-On: I29e2245e5b2be9bf57ba74a0fe00f335d1b170ec\n\nChange-Id: I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080\n""}, {'number': 5, 'created': '2014-12-09 23:49:42.000000000', 'files': ['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cd7ee65939b5b41855c7e4c73e81630f70b195d3', 'message': ""Adds experimental job for testing Nova V2.1 API\n\nNow Nova contains both v2 and v2.1 APIs as its REST API, and we are\ntesting v2 API only on the gate. To test v2.1 API also, this patch\nadd a new experimental job 'tempest-dsvm-nova-v21-full'.\n\nThis job is added-\n - As experimental\n - For non Icehouse/Juno branch\n - Run in Nova, Tempest & Tempest-lib\n\nDepends-On: I29e2245e5b2be9bf57ba74a0fe00f335d1b170ec\n\nChange-Id: I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080\n""}]",4,138951,cd7ee65939b5b41855c7e4c73e81630f70b195d3,27,10,5,8556,,,0,"Adds experimental job for testing Nova V2.1 API

Now Nova contains both v2 and v2.1 APIs as its REST API, and we are
testing v2 API only on the gate. To test v2.1 API also, this patch
add a new experimental job 'tempest-dsvm-nova-v21-full'.

This job is added-
 - As experimental
 - For non Icehouse/Juno branch
 - Run in Nova, Tempest & Tempest-lib

Depends-On: I29e2245e5b2be9bf57ba74a0fe00f335d1b170ec

Change-Id: I72e4ceda9d7e880cd7abfcfdd090d0dc16a2e080
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/138951/3 && git format-patch -1 --stdout FETCH_HEAD,"['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,8faeadb8990a61767ebad5249f44200b88abd53d,(detached," name: '{pipeline}-tempest-dsvm-nova-v21-full{branch-designator}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=120 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_FULL=1 export DEVSTACK_GATE_NOVA_REPLACE_V2_ENDPOINT_WITH_V21_API=1 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export OVERRIDE_TEMPEST_PROJECT_BRANCH=master cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template:",,37,0
openstack%2Fpython-barbicanclient~master~If4984d30b552a1eccf5ab927559584dfeebc9593,openstack/python-barbicanclient,master,If4984d30b552a1eccf5ab927559584dfeebc9593,Replace trivial docstring instances of tenant,MERGED,2014-12-10 12:23:31.000000000,2014-12-11 00:47:17.000000000,2014-12-11 00:47:17.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-10 12:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/ee3629ef5113179b979b1ce446dc2b8a8b6e27f0', 'message': ""Replace trivial docstring instances of tenant\n\nThe only changes that made sense to do in the client were three\ninstances of the word tenant in some doc-strings. So they were changed.\nOther than those, the occurrences of 'tenant' in the codebase relate to\nkeystone's v2.0 API.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: If4984d30b552a1eccf5ab927559584dfeebc9593\n""}, {'number': 2, 'created': '2014-12-10 12:24:25.000000000', 'files': ['barbicanclient/containers.py', 'barbicanclient/orders.py', 'barbicanclient/secrets.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/83f09dc8e8a1317a2a9b8942924250fe72ab9071', 'message': ""Replace trivial docstring instances of tenant\n\nThe only changes that made sense to do in the client were three\ninstances of the word tenant in some doc-strings. So they were\nchanged. Other than those, the occurrences of 'tenant' in the\ncodebase relate to keystone's v2.0 API.\n\nPartially implements: blueprint replace-concept-of-tenants-for-projects\n\nChange-Id: If4984d30b552a1eccf5ab927559584dfeebc9593\n""}]",0,140658,83f09dc8e8a1317a2a9b8942924250fe72ab9071,9,13,2,10873,,,0,"Replace trivial docstring instances of tenant

The only changes that made sense to do in the client were three
instances of the word tenant in some doc-strings. So they were
changed. Other than those, the occurrences of 'tenant' in the
codebase relate to keystone's v2.0 API.

Partially implements: blueprint replace-concept-of-tenants-for-projects

Change-Id: If4984d30b552a1eccf5ab927559584dfeebc9593
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/58/140658/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/containers.py', 'barbicanclient/orders.py', 'barbicanclient/secrets.py']",3,ee3629ef5113179b979b1ce446dc2b8a8b6e27f0,bp/replace-concept-of-tenants-for-projects, List all Secrets for the project, List all Secrets for the tenant,3,3
openstack%2Fsolum~master~I498722b89363bce9bec37a0cf1d70b0719f3ebcf,openstack/solum,master,I498722b89363bce9bec37a0cf1d70b0719f3ebcf,Added a python app example,MERGED,2014-12-09 05:08:30.000000000,2014-12-11 00:46:56.000000000,2014-12-11 00:46:55.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-12-09 05:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/df328e1eb825cb06d5412a9a17523549a49b4b2e', 'message': 'Added a python app example\n\nChange-Id: I498722b89363bce9bec37a0cf1d70b0719f3ebcf\n'}, {'number': 2, 'created': '2014-12-09 21:21:05.000000000', 'files': ['examples/plans/py.yaml'], 'web_link': 'https://opendev.org/openstack/solum/commit/535bd613492fb241e8be9ffaa58caec63a3425b0', 'message': 'Added a python app example\n\nChange-Id: I498722b89363bce9bec37a0cf1d70b0719f3ebcf\n'}]",0,140231,535bd613492fb241e8be9ffaa58caec63a3425b0,9,3,2,6662,,,0,"Added a python app example

Change-Id: I498722b89363bce9bec37a0cf1d70b0719f3ebcf
",git fetch https://review.opendev.org/openstack/solum refs/changes/31/140231/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/plans/py.yaml'],1,df328e1eb825cb06d5412a9a17523549a49b4b2e,plan-ex,version: 1 name: cherrypy description: python web app artifacts: - name: web artifact_type: heroku content: href: https://github.com/jamesyli/cherrypy-helloworld.git language_pack: auto ,,9,0
openstack%2Fproject-config~master~Id3f7c23b05baee5e99d24e42e2e327a690970fb3,openstack/project-config,master,Id3f7c23b05baee5e99d24e42e2e327a690970fb3,Stop using networking-l2gw group,MERGED,2014-12-10 23:40:24.000000000,2014-12-11 00:43:38.000000000,2014-12-11 00:43:38.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-12-10 23:40:24.000000000', 'files': ['gerrit/acls/stackforge/networking-l2gw.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/dfbaa0b96636dae42944059d171a5e149abf6ee9', 'message': 'Stop using networking-l2gw group\n\nThere was one last instance of the networking-l2gw group in the gerrit\nACLs. Change it to the -core group.\n\nChange-Id: Id3f7c23b05baee5e99d24e42e2e327a690970fb3\n'}]",0,140867,dfbaa0b96636dae42944059d171a5e149abf6ee9,8,4,1,4146,,,0,"Stop using networking-l2gw group

There was one last instance of the networking-l2gw group in the gerrit
ACLs. Change it to the -core group.

Change-Id: Id3f7c23b05baee5e99d24e42e2e327a690970fb3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/140867/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/stackforge/networking-l2gw.config'],1,dfbaa0b96636dae42944059d171a5e149abf6ee9,fix-l2gw,abandon = group networking-l2gw-core,abandon = group networking-l2gw,1,1
openstack%2Foslo.db~master~Iba8139cbfe181f7f7e32bf0bf9c2fe8fb4a2f908,openstack/oslo.db,master,Iba8139cbfe181f7f7e32bf0bf9c2fe8fb4a2f908,Provide better details for execution failure,ABANDONED,2014-09-15 06:46:12.000000000,2014-12-11 00:42:32.000000000,,"[{'_account_id': 3}, {'_account_id': 7536}, {'_account_id': 7787}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-09-15 06:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/ca6521e61090e0059bd97009b8915bf2d2215bfd', 'message': 'Provide better details for execution failure\n\nInclude the message from the original sqlalchemy.exc.OperationalError\nexception when the exception is converted to a DBConnectionError. This\nis in response to the current message being very misleading when\ndropping a Postgres database with other active connections. [1]\n\n1. http://lists.openstack.org/pipermail/openstack-dev/2014-September/045851.html\n\nChange-Id: Iba8139cbfe181f7f7e32bf0bf9c2fe8fb4a2f908\n'}, {'number': 2, 'created': '2014-10-02 10:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/57ca7d39ae4f8420574003153ed95c7a66794c50', 'message': 'Provide better details for execution failure\n\nInclude the message from the original sqlalchemy.exc.OperationalError\nexception when the exception is converted to a DBConnectionError. This\nis in response to the current message being very misleading when\ndropping a Postgres database with other active connections. [1]\n\n1. http://lists.openstack.org/pipermail/openstack-dev/2014-September/045851.html\n\nChange-Id: Iba8139cbfe181f7f7e32bf0bf9c2fe8fb4a2f908\n'}, {'number': 3, 'created': '2014-10-19 09:22:44.000000000', 'files': ['oslo/db/sqlalchemy/provision.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/51c98bba0653042eb18c7aa9a157925c322dc813', 'message': 'Provide better details for execution failure\n\nInclude the message from the original sqlalchemy.exc.OperationalError\nexception when the exception is converted to a DBConnectionError. This\nis in response to the current message being very misleading when\ndropping a Postgres database with other active connections. [1]\n\n1. http://lists.openstack.org/pipermail/openstack-dev/2014-September/045851.html\n\nChange-Id: Iba8139cbfe181f7f7e32bf0bf9c2fe8fb4a2f908\n'}]",0,121452,51c98bba0653042eb18c7aa9a157925c322dc813,14,4,3,7787,,,0,"Provide better details for execution failure

Include the message from the original sqlalchemy.exc.OperationalError
exception when the exception is converted to a DBConnectionError. This
is in response to the current message being very misleading when
dropping a Postgres database with other active connections. [1]

1. http://lists.openstack.org/pipermail/openstack-dev/2014-September/045851.html

Change-Id: Iba8139cbfe181f7f7e32bf0bf9c2fe8fb4a2f908
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/52/121452/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/db/sqlalchemy/provision.py'],1,ca6521e61090e0059bd97009b8915bf2d2215bfd,bettererror," except sqlalchemy.exc.OperationalError as e: msg = ('Failed to execute statement against database %(url)s. ' 'Details: %(error)s') raise exc.DBConnectionError(msg % {'url': engine.url, 'error': e.message})", except sqlalchemy.exc.OperationalError: msg = ('%s does not match database admin ' 'credentials or database does not exist.') raise exc.DBConnectionError(msg % engine.url),5,4
openstack%2Fbarbican~master~I81c581639639fac612319ef2f02a3b8e37d9047c,openstack/barbican,master,I81c581639639fac612319ef2f02a3b8e37d9047c,Make flake8 ignore *.egg,MERGED,2014-12-10 05:37:55.000000000,2014-12-11 00:36:45.000000000,2014-12-11 00:36:44.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-10 05:37:55.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/barbican/commit/90717c0eba59d8a54d237946e806c0860e66777f', 'message': 'Make flake8 ignore *.egg\n\npbr runs can leave *.egg directories around in the root directory.\nPrevent our pep8 test from inspecting these (and failing).\n\nChange-Id: I81c581639639fac612319ef2f02a3b8e37d9047c\n'}]",0,140578,90717c0eba59d8a54d237946e806c0860e66777f,8,4,1,10035,,,0,"Make flake8 ignore *.egg

pbr runs can leave *.egg directories around in the root directory.
Prevent our pep8 test from inspecting these (and failing).

Change-Id: I81c581639639fac612319ef2f02a3b8e37d9047c
",git fetch https://review.opendev.org/openstack/barbican refs/changes/78/140578/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,90717c0eba59d8a54d237946e806c0860e66777f,feature/tox-ignore-eggs," functionaltests,*alembic_migrations/versions,*docs/target,*.egg"," functionaltests,*alembic_migrations/versions,*docs/target",1,1
openstack%2Fneutron~master~I5dd26def685bcc643e35badc23885afc6240ae94,openstack/neutron,master,I5dd26def685bcc643e35badc23885afc6240ae94,"Services split, pass 2",MERGED,2014-12-09 22:58:59.000000000,2014-12-11 00:27:02.000000000,2014-12-10 22:14:54.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6951}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-09 22:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1b812a78af0a6330f29172607f39d0f85487c5d3', 'message': 'Add thin service plugin shims\n\nPost services-split, existing neutron.conf configurations may contain\nreferences to in-tree plugin classes.  Add thin shims so that those configs\nwill continue to work.\n\nChange-Id: I5dd26def685bcc643e35badc23885afc6240ae94\n'}, {'number': 2, 'created': '2014-12-10 00:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88f5895b083fcafb0fc068d85818879ec119ca9c', 'message': 'Add thin service plugin shims\n\nPost services-split, existing neutron.conf configurations may contain\nreferences to in-tree plugin classes.  Add thin shims so that those configs\nwill continue to work.\n\nChange-Id: I5dd26def685bcc643e35badc23885afc6240ae94\n'}, {'number': 3, 'created': '2014-12-10 04:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/059109db30f6c1796b9575f0ae65374f99be44d8', 'message': 'Add thin service plugin shims\n\nPost services-split, existing neutron.conf configurations may contain\nreferences to in-tree plugin classes.  Add thin shims so that those configs\nwill continue to work.\n\nChange-Id: I5dd26def685bcc643e35badc23885afc6240ae94\n'}, {'number': 4, 'created': '2014-12-10 07:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/00ffa34845a74c522c791fefc6fce83425b7a299', 'message': 'Services split, pass 2\n\n- Nuke more services code, killing some refs in vmware plugin\n- Vmware plugin foreign key relationships are temporary disabled\n- Vmware unit tests are temporarily disabled\n- Remove router insertion test, as its only user is going away\n- Add thin service plugin shims\n\nPost services-split, existing neutron.conf configurations may contain\nreferences to in-tree plugin classes.  Add thin shims so that those configs\nwill continue to work.\n\nChange-Id: I5dd26def685bcc643e35badc23885afc6240ae94\n'}, {'number': 5, 'created': '2014-12-10 15:01:47.000000000', 'files': ['neutron/plugins/vmware/dbexts/vcns_models.py', 'neutron/services/loadbalancer/constants.py', 'neutron/tests/unit/services/vpn/test_plugin_shim.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/db/firewall/firewall_db.py', 'neutron/services/loadbalancer/drivers/embrane/__init__.py', 'neutron/services/loadbalancer/drivers/embrane/constants.py', 'neutron/tests/unit/test_routerserviceinsertion.py.skip', 'neutron/db/vpn/vpn_db.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/db/test_migration.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/vpn/__init__.py', 'neutron/tests/unit/vmware/skip_this_dir__init__.py', 'neutron/services/loadbalancer/drivers/embrane/agent/__init__.py', 'neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/tests/unit/vmware/vshield/test_firewall_driver.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_loadbalancer_driver.py', 'neutron/services/loadbalancer/drivers/embrane/agent/lb_operations.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/services/loadbalancer/drivers/embrane/config.py', 'neutron/services/loadbalancer/drivers/embrane/models.py', 'neutron/services/loadbalancer/drivers/__init__.py', 'neutron/tests/unit/services/firewall/test_plugin_shim.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/db/migration/models/head.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'etc/neutron.conf', 'neutron/services/loadbalancer/drivers/embrane/poller.py', 'neutron/services/loadbalancer/agent_scheduler.py', 'neutron/db/firewall/__init__.py', 'neutron/services/vpn/service_drivers/cisco_csr_db.py', 'neutron/services/loadbalancer/drivers/embrane/db.py', 'neutron/services/loadbalancer/drivers/embrane/driver.py', 'neutron/db/vpn/vpn_validator.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/services/loadbalancer/test_plugin_shim.py', 'tox.ini', 'neutron/db/loadbalancer/__init__.py', 'neutron/services/loadbalancer/drivers/embrane/README', 'neutron/services/loadbalancer/drivers/embrane/agent/dispatcher.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec5fb4327e0dc56843b05d696d287b6348bb3e55', 'message': 'Services split, pass 2\n\n- Nuke more services code, killing some refs in vmware plugin\n- Vmware plugin foreign key relationships are temporary disabled\n- Vmware unit tests are temporarily disabled\n- Remove router insertion test, as its only user is going away\n- Add thin service plugin shims\n- Temporarily disable model sync test\n\nPost services-split, existing neutron.conf configurations may contain\nreferences to in-tree plugin classes.  Add thin shims so that those configs\nwill continue to work.\n\nChange-Id: I5dd26def685bcc643e35badc23885afc6240ae94\n'}]",2,140515,ec5fb4327e0dc56843b05d696d287b6348bb3e55,98,25,5,10980,,,0,"Services split, pass 2

- Nuke more services code, killing some refs in vmware plugin
- Vmware plugin foreign key relationships are temporary disabled
- Vmware unit tests are temporarily disabled
- Remove router insertion test, as its only user is going away
- Add thin service plugin shims
- Temporarily disable model sync test

Post services-split, existing neutron.conf configurations may contain
references to in-tree plugin classes.  Add thin shims so that those configs
will continue to work.

Change-Id: I5dd26def685bcc643e35badc23885afc6240ae94
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/140515/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/firewall/fwaas_plugin.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/services/vpn/test_plugin_shim.py', 'neutron/tests/unit/services/loadbalancer/test_plugin_shim.py', 'neutron/tests/unit/services/firewall/test_plugin_shim.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/services/vpn/__init__.py']",7,1b812a78af0a6330f29172607f39d0f85487c5d3,services-split-shims,,,165,0
openstack%2Fkeystonemiddleware~master~I4929f256d1bbffae909ebb4c08e994c16a4164b5,openstack/keystonemiddleware,master,I4929f256d1bbffae909ebb4c08e994c16a4164b5,Use newer requests-mock syntax,MERGED,2014-11-19 00:22:49.000000000,2014-12-11 00:16:39.000000000,2014-12-11 00:16:38.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 9101}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-11-19 00:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/01725990fd072670016eb496b58f7b8e53a26179', 'message': ""Use newer requests-mock syntax\n\nYou can specify mocks in requests-mock using the method name as the\nfunction rather than having to repeat strings throughout code. This\nmakes it less likely you'll make a simple mistake and looks cleaner.\n\nChange-Id: I4929f256d1bbffae909ebb4c08e994c16a4164b5\n""}, {'number': 2, 'created': '2014-11-21 01:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f27fdad3a8fca27411a9c64a4f13c462ba33aaaf', 'message': ""Use newer requests-mock syntax\n\nYou can specify mocks in requests-mock using the method name as the\nfunction rather than having to repeat strings throughout code. This\nmakes it less likely you'll make a simple mistake and looks cleaner.\n\nChange-Id: I4929f256d1bbffae909ebb4c08e994c16a4164b5\n""}, {'number': 3, 'created': '2014-12-09 22:36:28.000000000', 'files': ['keystonemiddleware/tests/test_auth_token_middleware.py', 'keystonemiddleware/tests/test_s3_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/e619105327ffe002eb114d4d19e5f964a0ee2ab6', 'message': ""Use newer requests-mock syntax\n\nYou can specify mocks in requests-mock using the method name as the\nfunction rather than having to repeat strings throughout code. This\nmakes it less likely you'll make a simple mistake and looks cleaner.\n\nChange-Id: I4929f256d1bbffae909ebb4c08e994c16a4164b5\n""}]",0,135468,e619105327ffe002eb114d4d19e5f964a0ee2ab6,30,6,3,7191,,,0,"Use newer requests-mock syntax

You can specify mocks in requests-mock using the method name as the
function rather than having to repeat strings throughout code. This
makes it less likely you'll make a simple mistake and looks cleaner.

Change-Id: I4929f256d1bbffae909ebb4c08e994c16a4164b5
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/68/135468/3 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/test_auth_token_middleware.py'],1,01725990fd072670016eb496b58f7b8e53a26179,rm_syntax," self.requests.get(""%s/"" % BASE_URI, json=VERSION_LIST_v2, status_code=300) self.requests.post(""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.get(url, text=token_response) self.requests.get('%s/v2.0/tokens/revoked' % BASE_URI, json={}) self.requests.get(invalid_uri, status_code=404) self.requests.get(invalid_uri, status_code=404) self.requests.get(service_url, json=VERSION_LIST_v3, status_code=300) self.requests.get('%s%s' % (BASE_URI, self.ca_path), status_code=404) self.requests.get('%s%s' % (BASE_URI, self.signing_path), status_code=404) self.requests.get(url, text=data) self.requests.get(url, text=data) self.requests.get(ca_url, text='FAKECA') self.requests.get(signing_url, text='FAKECERT') self.requests.get(ca_url, text='FAKECA') self.requests.get(signing_url, text='FAKECERT') self.requests.get('%s/' % BASE_URI, json=VERSION_LIST_v2, status_code=300) self.requests.post('%s/v2.0/tokens' % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.get('%s/v2.0/tokens/revoked' % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST) self.requests.get(url, text=text) self.requests.get(url, text=network_error_response) self.requests.get(BASE_URI, json=VERSION_LIST_v3, status_code=300) self.requests.post('%s/v2.0/tokens' % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.get(url, text=text) self.requests.get(BASE_URI, json=VERSION_LIST_v3, status_code=300) self.requests.post('%s/v2.0/tokens' % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.get('%s/v2.0/tokens/revoked' % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST) self.requests.get('%s/v3/auth/tokens' % BASE_URI, text=self.token_response) self.requests.get('%s/' % BASE_URI, json=VERSION_LIST_v2, status_code=300) self.requests.post('%s/v2.0/tokens' % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.get('%s/v2.0/tokens/revoked' % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST, status_code=200) self.requests.get('%s/v2.0/tokens/%s' % (BASE_URI, token), text=self.examples.JSON_TOKEN_RESPONSES[token]) self.requests.get(invalid_uri, text='', status_code=404) self.requests.get(BASE_URI, json=VERSION_LIST_v3, status_code=300) self.requests.post('%s/v2.0/tokens' % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.get('%s/v2.0/tokens/revoked' % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST) self.requests.get('%s/v3/auth/tokens' % BASE_URI, text=self.token_response) self.requests.post(base_uri + '/v2.0/tokens', json=token)"," self.requests.register_uri('GET', ""%s/"" % BASE_URI, json=VERSION_LIST_v2, status_code=300) self.requests.register_uri('POST', ""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.register_uri('GET', url, text=token_response) self.requests.register_uri('GET', ""%s/v2.0/tokens/revoked"" % BASE_URI, json={}) self.requests.register_uri('GET', invalid_uri, status_code=404) self.requests.register_uri('GET', invalid_uri, status_code=404) self.requests.register_uri('GET', service_url, json=VERSION_LIST_v3, status_code=300) self.requests.register_uri('GET', ""%s%s"" % (BASE_URI, self.ca_path), status_code=404) self.requests.register_uri('GET', ""%s%s"" % (BASE_URI, self.signing_path), status_code=404) self.requests.register_uri('GET', url, text=data) self.requests.register_uri('GET', url, text=data) self.requests.register_uri('GET', ca_url, text='FAKECA') self.requests.register_uri('GET', signing_url, text='FAKECERT') self.requests.register_uri('GET', ca_url, text='FAKECA') self.requests.register_uri('GET', signing_url, text='FAKECERT') self.requests.register_uri('GET', ""%s/"" % BASE_URI, json=VERSION_LIST_v2, status_code=300) self.requests.register_uri('POST', ""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.register_uri('GET', ""%s/v2.0/tokens/revoked"" % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST) self.requests.register_uri('GET', url, text=text) self.requests.register_uri('GET', url, text=network_error_response) self.requests.register_uri('GET', BASE_URI, json=VERSION_LIST_v3, status_code=300) self.requests.register_uri('POST', ""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.register_uri('GET', url, text=text) self.requests.register_uri('GET', BASE_URI, json=VERSION_LIST_v3, status_code=300) self.requests.register_uri('POST', ""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.register_uri('GET', ""%s/v2.0/tokens/revoked"" % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST) self.requests.register_uri('GET', ""%s/v3/auth/tokens"" % BASE_URI, text=self.token_response) self.requests.register_uri('GET', ""%s/"" % BASE_URI, json=VERSION_LIST_v2, status_code=300) self.requests.register_uri('POST', ""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.register_uri('GET', ""%s/v2.0/tokens/revoked"" % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST, status_code=200) self.requests.register_uri( 'GET', ""%s/v2.0/tokens/%s"" % (BASE_URI, token), text=self.examples.JSON_TOKEN_RESPONSES[token]) self.requests.register_uri('GET', invalid_uri, text="""", status_code=404) self.requests.register_uri('GET', ""%s"" % BASE_URI, json=VERSION_LIST_v3, status_code=300) self.requests.register_uri('POST', ""%s/v2.0/tokens"" % BASE_URI, text=FAKE_ADMIN_TOKEN) self.requests.register_uri('GET', ""%s/v2.0/tokens/revoked"" % BASE_URI, text=self.examples.SIGNED_REVOCATION_LIST) self.requests.register_uri('GET', ""%s/v3/auth/tokens"" % BASE_URI, text=self.token_response) self.requests.register_uri('POST', base_uri + '/v2.0/tokens', json=token)",66,96
openstack%2Fheat~master~Ib3a561c01a32bf6a118f06cf244632aa8c8a3922,openstack/heat,master,Ib3a561c01a32bf6a118f06cf244632aa8c8a3922,Add proper unit tests for group Tags,MERGED,2014-12-09 06:16:28.000000000,2014-12-11 00:10:53.000000000,2014-12-11 00:10:52.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-12-09 06:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/77468a2c19f101e030754594b7e15e29132c0647', 'message': 'Add proper unit tests for group Tags\n\nChange-Id: Ib3a561c01a32bf6a118f06cf244632aa8c8a3922\n'}, {'number': 2, 'created': '2014-12-10 08:02:20.000000000', 'files': ['heat/tests/test_server_tags.py', 'heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c0dee4c0f410b1ab17b58fe17f9d1d71a1932c10', 'message': 'Add proper unit tests for group Tags\n\nPart of blueprint decouple-nested\nChange-Id: Ib3a561c01a32bf6a118f06cf244632aa8c8a3922\n'}]",1,140243,c0dee4c0f410b1ab17b58fe17f9d1d71a1932c10,14,4,2,4715,,,0,"Add proper unit tests for group Tags

Part of blueprint decouple-nested
Change-Id: Ib3a561c01a32bf6a118f06cf244632aa8c8a3922
",git fetch https://review.opendev.org/openstack/heat refs/changes/43/140243/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_server_tags.py', 'heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/test_instance_group.py']",3,77468a2c19f101e030754594b7e15e29132c0647,bug/1360292," def test_tags_default(self): expected = [{'Value': u'asg', 'Key': 'metering.groupname'}] self.assertEqual(expected, self.instance_group._tags()) def test_tags_with_extra(self): self.instance_group.properties.data['Tags'] = [ {'Key': 'fee', 'Value': 'foo'}] expected = [{'Key': 'fee', 'Value': 'foo'}, {'Value': u'asg', 'Key': 'metering.groupname'}] self.assertEqual(expected, self.instance_group._tags()) def test_tags_with_metering(self): self.instance_group.properties.data['Tags'] = [ {'Key': 'metering.fee', 'Value': 'foo'}] expected = [{'Key': 'metering.fee', 'Value': 'foo'}] self.assertEqual(expected, self.instance_group._tags()) ",,54,184
openstack%2Fheat~master~I46c18a5545658a3a10c9eb3e9a6d1511bbe7a518,openstack/heat,master,I46c18a5545658a3a10c9eb3e9a6d1511bbe7a518,Add some unit tests for the instance group,MERGED,2014-12-04 11:57:49.000000000,2014-12-11 00:10:43.000000000,2014-12-11 00:10:42.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-12-04 11:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/537ac4aedf3ec1f5ae909d4b5fcd947ac8e91b7a', 'message': 'Add some unit tests for the instance group\n\nChange-Id: I46c18a5545658a3a10c9eb3e9a6d1511bbe7a518\n'}, {'number': 2, 'created': '2014-12-09 06:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d97354dfbd2bdcd1053903d875b3eaae8e6bb03f', 'message': 'Add some unit tests for the instance group\n\nChange-Id: I46c18a5545658a3a10c9eb3e9a6d1511bbe7a518\n'}, {'number': 3, 'created': '2014-12-10 08:02:20.000000000', 'files': ['heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a7ebb7c1b71df0277d836bb74613b0015cb0322e', 'message': 'Add some unit tests for the instance group\n\nPart of blueprint decouple-nested\nChange-Id: I46c18a5545658a3a10c9eb3e9a6d1511bbe7a518\n'}]",3,139029,a7ebb7c1b71df0277d836bb74613b0015cb0322e,26,8,3,4715,,,0,"Add some unit tests for the instance group

Part of blueprint decouple-nested
Change-Id: I46c18a5545658a3a10c9eb3e9a6d1511bbe7a518
",git fetch https://review.opendev.org/openstack/heat refs/changes/29/139029/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_instance_group.py'],1,537ac4aedf3ec1f5ae909d4b5fcd947ac8e91b7a,bug/1360292,"from heat.common import grouputils class TestInstanceGroup(common.HeatTestCase): def setUp(self): super(TestInstanceGroup, self).setUp() t = template_format.parse(inline_templates.as_template) stack = utils.parse_stack(t, params=inline_templates.as_params) defn = rsrc_defn.ResourceDefinition( 'asg', 'OS::Heat::InstanceGroup', {'Size': 2, 'AvailabilityZones': ['zoneb'], 'LaunchConfigurationName': 'config'}) self.instance_group = instgrp.InstanceGroup('asg', defn, stack) def test_child_template(self): self.instance_group._create_template = mock.Mock(return_value='tpl') self.assertEqual('tpl', self.instance_group.child_template()) self.instance_group._create_template.assert_called_once_with(2) def test_child_params(self): expected = {'parameters': {}, 'resource_registry': { 'OS::Heat::ScaledResource': 'AWS::EC2::Instance'}} self.assertEqual(expected, self.instance_group.child_params()) self.assertEqual(expected, self.instance_group._environment()) def test_tags_default(self): expected = [{'Value': u'asg', 'Key': 'metering.groupname'}] self.assertEqual(expected, self.instance_group._tags()) def test_tags_with_extra(self): self.instance_group.properties.data['Tags'] = [ {'Key': 'fee', 'Value': 'foo'}] expected = [{'Key': 'fee', 'Value': 'foo'}, {'Value': u'asg', 'Key': 'metering.groupname'}] self.assertEqual(expected, self.instance_group._tags()) def test_tags_with_metering(self): self.instance_group.properties.data['Tags'] = [ {'Key': 'metering.fee', 'Value': 'foo'}] expected = [{'Key': 'metering.fee', 'Value': 'foo'}] self.assertEqual(expected, self.instance_group._tags()) def test_validate_launch_conf(self): props = self.instance_group.properties.data props['LaunchConfigurationName'] = 'urg_i_cant_spell' creator = scheduler.TaskRunner(self.instance_group.create) props = self.instance_group.properties.data props['LaunchConfigurationName'] = 'JobServerConfig' creator = scheduler.TaskRunner(self.instance_group.create) self.assertIn('(JobServerConfig) reference can not be', def test_handle_delete(self): self.instance_group.delete_nested = mock.Mock(return_value=None) self.instance_group.handle_delete() self.instance_group.delete_nested.assert_called_once_with() def test_attributes(self): mock_members = self.patchobject(grouputils, 'get_members') instances = [] for ip_ex in six.moves.range(1, 4): inst = mock.Mock() inst.FnGetAtt.return_value = '2.1.3.%d' % ip_ex instances.append(inst) mock_members.return_value = instances res = self.instance_group._resolve_attribute('InstanceList') self.assertEqual('2.1.3.1,2.1.3.2,2.1.3.3', res)"," def test_validate_launch_conf(self): t = template_format.parse(ig_template) properties = t['Resources']['JobServerGroup']['Properties'] properties['LaunchConfigurationName'] = 'urg_i_cant_spell' stack = utils.parse_stack(t) rsrc = stack['JobServerGroup'] creator = scheduler.TaskRunner(rsrc.create) t = template_format.parse(ig_template) properties = t['Resources']['JobServerGroup']['Properties'] properties['LaunchConfigurationName'] = 'JobServerConfig' stack = utils.parse_stack(t) rsrc = stack['JobServerGroup'] creator = scheduler.TaskRunner(rsrc.create) self.assertIn('(JobServerConfig) requires a reference to the', class TestChildTemplate(common.HeatTestCase): def setUp(self): super(TestChildTemplate, self).setUp() t = template_format.parse(inline_templates.as_template) stack = utils.parse_stack(t, params=inline_templates.as_params) defn = rsrc_defn.ResourceDefinition('ig', 'OS::Heat::InstanceGroup', {'Size': 2, 'LaunchConfigurationName': 'foo'}) self.instance_group = instgrp.InstanceGroup('ig', defn, stack) def test_child_template(self): self.instance_group._create_template = mock.Mock(return_value='tpl') self.assertEqual('tpl', self.instance_group.child_template()) self.instance_group._create_template.assert_called_once_with(2) def test_child_params(self): self.instance_group._environment = mock.Mock(return_value='env') self.assertEqual('env', self.instance_group.child_params())",66,34
openstack%2Fhorizon~master~If71cdd793723a2777356da773ae12deb68eb55e2,openstack/horizon,master,If71cdd793723a2777356da773ae12deb68eb55e2,removing mandatory mark for post_creation tab,MERGED,2014-12-02 09:29:38.000000000,2014-12-11 00:10:31.000000000,2014-12-11 00:10:30.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 6635}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10442}, {'_account_id': 12030}, {'_account_id': 12355}, {'_account_id': 12826}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-12-02 09:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7132bc6b71888f19ef85e4a55c15088511a53f1a', 'message': 'removing mandatory mark for post_creation tab\n\nIn launch instance form the post creation tab\nhaving the * symbol, which means the the script\ndata is mandatory. but this is optional field.\n\nso removing the the * symbol from the\npost-creation tab.\n\nChange-Id: If71cdd793723a2777356da773ae12deb68eb55e2\nCloses-Bug: #1396501\n'}, {'number': 2, 'created': '2014-12-10 10:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/78065734596c16a3d84d5fbbc993c3b2232a58be', 'message': 'removing mandatory mark for post_creation tab\n\nIn launch instance form the post creation tab\nhaving the * symbol, which means the the script\ndata is mandatory. but this is optional field.\n\nso removing the the * symbol from the\npost-creation tab.\n\nChange-Id: If71cdd793723a2777356da773ae12deb68eb55e2\nCloses-Bug: #1396501\n'}, {'number': 3, 'created': '2014-12-10 11:57:56.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/db33f9f944eed44171bbe744c88d8985275af26b', 'message': 'removing mandatory mark for post_creation tab\n\nIn launch instance form the post creation tab\nhaving the * symbol, which means the the script\ndata is mandatory. but this is optional field.\n\nso removing the the * symbol from the\npost-creation tab.\n\nChange-Id: If71cdd793723a2777356da773ae12deb68eb55e2\nCloses-Bug: #1396501\n'}]",3,138290,db33f9f944eed44171bbe744c88d8985275af26b,27,11,3,10442,,,0,"removing mandatory mark for post_creation tab

In launch instance form the post creation tab
having the * symbol, which means the the script
data is mandatory. but this is optional field.

so removing the the * symbol from the
post-creation tab.

Change-Id: If71cdd793723a2777356da773ae12deb68eb55e2
Closes-Bug: #1396501
",git fetch https://review.opendev.org/openstack/horizon refs/changes/90/138290/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py'],1,7132bc6b71888f19ef85e4a55c15088511a53f1a,bug/1396501," widget=forms.Select(attrs=attributes), required=False)", widget=forms.Select(attrs=attributes)),2,1
openstack%2Fpython-keystoneclient~master~I036c4a49f58e4412c6cfb477b56b31b7b965c2fb,openstack/python-keystoneclient,master,I036c4a49f58e4412c6cfb477b56b31b7b965c2fb,Add missing user-id option to generic.Password,MERGED,2014-11-04 07:08:32.000000000,2014-12-11 00:08:18.000000000,2014-12-11 00:08:17.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 7191}, {'_account_id': 9101}, {'_account_id': 11022}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-11-04 07:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1c6c5ba6ee401e23a7ddb5e525a68e333a81d65e', 'message': 'auth.identity.generic.password misses user-id option\n\nChange-Id: I036c4a49f58e4412c6cfb477b56b31b7b965c2fb\n'}, {'number': 2, 'created': '2014-11-26 01:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6bb48e9e7cfaa135634cca9964f49236493e66a0', 'message': 'add missing user-id option to auth.identity.generic.password\n\nChange-Id: I036c4a49f58e4412c6cfb477b56b31b7b965c2fb\n'}, {'number': 3, 'created': '2014-12-04 00:30:16.000000000', 'files': ['keystoneclient/auth/identity/generic/password.py', 'keystoneclient/tests/auth/test_password.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/bf0f39fbfa680bbef685eabdf052a607d0859e62', 'message': 'Add missing user-id option to generic.Password\n\nThe user_id field is available when constructing the plugin from python\nhowever the option is not listed in the get_options list.\n\nChange-Id: I036c4a49f58e4412c6cfb477b56b31b7b965c2fb\n'}]",6,132626,bf0f39fbfa680bbef685eabdf052a607d0859e62,27,8,3,9101,,,0,"Add missing user-id option to generic.Password

The user_id field is available when constructing the plugin from python
however the option is not listed in the get_options list.

Change-Id: I036c4a49f58e4412c6cfb477b56b31b7b965c2fb
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/26/132626/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/auth/identity/generic/password.py'],1,1c6c5ba6ee401e23a7ddb5e525a68e333a81d65e,bug/1388954," cfg.StrOpt('user-id', help='User ID'),",,1,0
openstack%2Fpython-keystoneclient~master~Id54f353d8b125807a8fc33b4bca8854605e3febb,openstack/python-keystoneclient,master,Id54f353d8b125807a8fc33b4bca8854605e3febb,duplicate auth-url option returned by BaseGenericPlugin,MERGED,2014-11-04 11:04:58.000000000,2014-12-11 00:07:54.000000000,2014-12-11 00:07:53.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-11-04 11:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/833e6ce96ea7f521b0cfe5c74a1b2dee56c4c6bc', 'message': 'duplicate auth-url option returned by BaseGenericPlugin\n\nThe free function get_options() should only return the options that\nthe object itself needs.\n\nChange-Id: Id54f353d8b125807a8fc33b4bca8854605e3febb\nCloses-Bug: #1388954\n'}, {'number': 2, 'created': '2014-12-04 00:30:16.000000000', 'files': ['keystoneclient/auth/identity/generic/base.py', 'keystoneclient/tests/auth/test_password.py', 'keystoneclient/tests/auth/test_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b7da6d0e8449355fa7652523ee5ad0b36b298399', 'message': 'duplicate auth-url option returned by BaseGenericPlugin\n\nThe free function get_options() should only return the options that\nthe object itself needs.\n\nChange-Id: Id54f353d8b125807a8fc33b4bca8854605e3febb\nCloses-Bug: #1388954\n'}]",6,132652,b7da6d0e8449355fa7652523ee5ad0b36b298399,28,9,2,9101,,,0,"duplicate auth-url option returned by BaseGenericPlugin

The free function get_options() should only return the options that
the object itself needs.

Change-Id: Id54f353d8b125807a8fc33b4bca8854605e3febb
Closes-Bug: #1388954
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/52/132652/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/auth/identity/generic/base.py'],1,833e6ce96ea7f521b0cfe5c74a1b2dee56c4c6bc,bug/1388954, return [, return base.get_options() + [,1,1
openstack%2Fhorizon~master~I28a1a71f362045769083b90e15a6ad9ee19d090a,openstack/horizon,master,I28a1a71f362045769083b90e15a6ad9ee19d090a,"With angular hz module, use strict & avoid globals",MERGED,2014-08-07 18:52:36.000000000,2014-12-11 00:06:40.000000000,2014-12-11 00:06:39.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7509}, {'_account_id': 7976}, {'_account_id': 8040}, {'_account_id': 9048}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 11881}, {'_account_id': 11902}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-08-07 18:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5ea85358d608e6003b64494aec719a5faecaaec6', 'message': 'In angular/horizon.js, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\n'}, {'number': 2, 'created': '2014-08-07 18:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ae37c053b9fab223cb13e77c5ae61ad0c48cea7d', 'message': 'In angular/horizon.js, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 3, 'created': '2014-08-08 15:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/249a2f8b4c5ab652df8864f63fe65b3c623addac', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 4, 'created': '2014-09-26 18:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b43d5f8bd2491055e74aa733bb1f9d4e5e2424c3', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 5, 'created': '2014-10-06 03:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ccd8f086fe17dadb153a2a3cf576383dbbc901cf', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 6, 'created': '2014-10-15 16:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2fa1be0e7c5e369b53149a2a2c78551d4a65ea4f', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 7, 'created': '2014-11-11 19:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5447449b5e7e22690078d0a7e7793382d02fbffc', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 8, 'created': '2014-11-13 03:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8ad5f08c0c5263d4e6898cf98bdfddce845764dc', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}, {'number': 9, 'created': '2014-12-09 20:40:55.000000000', 'files': ['horizon/templates/horizon/_conf.html', 'horizon/static/horizon/js/angular/directives/forms.js', 'horizon/static/horizon/js/horizon.images.js', 'horizon/static/horizon/js/angular/controllers/metadata-widget-controller.js', 'horizon/static/horizon/js/angular/controllers/dummy.js', 'horizon/static/horizon/js/angular/horizon.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/21d878531a97a6e1a9c3e09bc2a73bfe89014cc9', 'message': 'With angular hz module, use strict & avoid globals\n\nChange-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a\nCloses-Bug: 1354120\n'}]",4,112654,21d878531a97a6e1a9c3e09bc2a73bfe89014cc9,61,14,9,11902,,,0,"With angular hz module, use strict & avoid globals

Change-Id: I28a1a71f362045769083b90e15a6ad9ee19d090a
Closes-Bug: 1354120
",git fetch https://review.opendev.org/openstack/horizon refs/changes/54/112654/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/angular/horizon.js'],1,5ea85358d608e6003b64494aec719a5faecaaec6,bug/1354120,"/*global angularModuleExtension*/ var horizonApp; (function () { 'use strict'; var horizon_dependencies = ['hz.conf', 'hz.utils', 'ngCookies']; var dependencies = horizon_dependencies.concat(angularModuleExtension); horizonApp = angular.module('hz', dependencies) .config(['$interpolateProvider', '$httpProvider', function ($interpolateProvider, $httpProvider) { $interpolateProvider.startSymbol('{$'); $interpolateProvider.endSymbol('$}'); $httpProvider.defaults.xsrfHeaderName = 'X-CSRFToken'; $httpProvider.defaults.xsrfCookieName = 'csrftoken'; }]) .run(['hzConfig', 'hzUtils', '$cookieStore', function (hzConfig, hzUtils, $cookieStore) { //expose the configuration for horizon legacy variable horizon.conf = hzConfig; horizon.utils = hzUtils; angular.extend(horizon.cookies = {}, $cookieStore); horizon.cookies.put = function (key, value) { //cookies are updated at the end of current $eval, so for the horizon //namespace we need to wrap it in a $apply function. angular.element('body').scope().$apply(function () { $cookieStore.put(key, value); }); }; }]); }());","var horizon_dependencies = ['hz.conf', 'hz.utils', 'ngCookies']; dependencies = horizon_dependencies.concat(angularModuleExtension); var horizonApp = angular.module('hz', dependencies) .config(['$interpolateProvider', '$httpProvider', function ($interpolateProvider, $httpProvider) { $interpolateProvider.startSymbol('{$'); $interpolateProvider.endSymbol('$}'); $httpProvider.defaults.xsrfHeaderName = 'X-CSRFToken'; $httpProvider.defaults.xsrfCookieName = 'csrftoken'; }]) .run(['hzConfig', 'hzUtils', '$cookieStore', function (hzConfig, hzUtils, $cookieStore) { //expose the configuration for horizon legacy variable horizon.conf = hzConfig; horizon.utils = hzUtils; angular.extend(horizon.cookies = {}, $cookieStore); horizon.cookies.put = function (key, value) { //cookies are updated at the end of current $eval, so for the horizon //namespace we need to wrap it in a $apply function. angular.element('body').scope().$apply(function () { $cookieStore.put(key, value); }); }; }]); ",30,24
openstack%2Fbarbican-specs~master~Icc98221869c9290139344a754534e5d79d55cd3d,openstack/barbican-specs,master,Icc98221869c9290139344a754534e5d79d55cd3d,Add Cert API Spec.,MERGED,2014-11-19 02:50:59.000000000,2014-12-11 00:05:59.000000000,2014-12-11 00:05:58.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10035}, {'_account_id': 10273}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 11716}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-11-19 02:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/757034577a07f9db807d60451bb12b0cc05b715b', 'message': 'Add Cert API Spec.\n\nThis spec details a proposal for a common cert API that uses CMC\nrequests as a common API mechanism, similar to RFC 7030.\n\nChange-Id: Icc98221869c9290139344a754534e5d79d55cd3d\n'}, {'number': 2, 'created': '2014-12-02 18:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/dad4ba92b93823d139f86c433696fa1b0109fba3', 'message': 'Add Cert API Spec.\n\nThis spec details a proposal for a common cert API that uses CMC\nrequests as a common API mechanism, similar to RFC 7030.\n\nChange-Id: Icc98221869c9290139344a754534e5d79d55cd3d\n'}, {'number': 3, 'created': '2014-12-03 16:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/52b45065a2dd73ca5ecf2c171a241050608312dd', 'message': 'Add Cert API Spec.\n\nThis spec details a proposal for a common cert API that uses CMC\nrequests as a common API mechanism, similar to RFC 7030.\n\nChange-Id: Icc98221869c9290139344a754534e5d79d55cd3d\n'}, {'number': 4, 'created': '2014-12-05 16:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/b4990a3acf78f1a496be48ecb9d280ed5de524d7', 'message': 'Add Cert API Spec.\n\nThis spec details a proposal for a common cert API that uses CMC\nrequests as a common API mechanism, similar to RFC 7030.\n\nChange-Id: Icc98221869c9290139344a754534e5d79d55cd3d\n'}, {'number': 5, 'created': '2014-12-08 15:48:41.000000000', 'files': ['specs/kilo/certificate-order-api.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/8835ba8872ed2dd1c74b925d2a21a0e8169c8be0', 'message': 'Add Cert API Spec.\n\nThis spec details a proposal for a common cert API that uses CMC\nrequests as a common API mechanism, similar to RFC 7030.\n\nChange-Id: Icc98221869c9290139344a754534e5d79d55cd3d\n'}]",49,135490,8835ba8872ed2dd1c74b925d2a21a0e8169c8be0,42,19,5,9914,,,0,"Add Cert API Spec.

This spec details a proposal for a common cert API that uses CMC
requests as a common API mechanism, similar to RFC 7030.

Change-Id: Icc98221869c9290139344a754534e5d79d55cd3d
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/90/135490/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/cert_api.rst'],1,757034577a07f9db807d60451bb12b0cc05b715b,bp/certificate-order-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================= Common Certificate API ======================= https://blueprints.launchpad.net/barbican/+spec/api-orders-add-more-types Problem Description =================== We currently have a mechanism for enrolling a certificate request by creating a new order, and passing parameters in the metadata of the order. Currently, the parameters in the metadata are passed through to the CA plugin unchanged. This means that - as long as the parameters passed in match the parameters expected by a particular back-end, then a certificate request can be created for that back-end. This diminishes the power of the abstraction though. A client should not have to know which CA is served by the Barbican server. Rather, a client should be able to request a certificate through a common API, which should be supported by all known certificate plugins. The trick is to define an interface/metadata parameters that would be supported by most CA's. An attempt was made to do this in [1]. Recently, it was suggested to use RFC 7030, as a standards-based approach for a common API. RFC7030 basically proposes an HTTP interface for submitting CMC (RFC 5272) requests, and receiving the relevant responses. RFC 7030 is too different from the current Orders interface and functionality for us to consider adding for Kilo. On the other hand, CMC requests - both simple and full - have been standards for some time now, and are supported by most of not all Certificate Authorities. This makes them an ideal candidate for a common set of parameters supported by multiple back-end CA's. Ideally, the CMC request could be passed intact from barbican core through the plugin to the backend CA. Proposed Change =============== We will continue to use the Orders resource to enroll certificate requests, and the order metadata to contain the request parameters. Order requests can look like this: Option 1: Order using simple CMC (PKCS10):: { ""type"": ""certificate"", ""meta"": { ""ca"": ""CA identifier (optional)"", ""request-type"": ""simple-cmc"", ""request-data"": ""base64 encoded simple CMC request (PKCS10)"" } } Option 2: Order using full CMC (PKCS7):: { ""type"": ""certificate"", ""meta"": { ""ca"": ""CA identifier (optional)"", ""request-type"": ""full-cmc"", ""request-data"": ""base64 encoded full CMC request (PKCS7)"" } } Option 3: Order using keys already stored in Barbican:: { ""type"": ""certificate"", ""meta"": { ""ca"": ""CA identifier (optional)"", ""request-type"": ""generated"", ""public_key_ref"": ""barbican UUID for public key"", ""subject_dn"": ""subject DN (RFC1485)"" ""extensions"": ""DER encoded ASN.1 value for extensions"" } } Extensions data defined by the following in RFC 5280: Extensions ::= SEQUENCE SIZE (1..MAX) OF Extension Extension ::= SEQUENCE { extnID OBJECT IDENTIFIER, critical BOOLEAN DEFAULT FALSE, extnValue OCTET STRING -- contains the DER encoding of an ASN.1 value -- corresponding to the extension type identified -- by extnID } Order 4: Orders using parameters for a specific CA. This is already supported:: { ""type"": ""certificate"", ""meta"": { ""ca"": ""CA identifier (optional)"", ""request-type"": ""custom"", ""ca_specific_parameter1"": ""value"", ""ca_specific_parameter2"": ""value2"", ... } } In the Barbican server, logic will need to be added to differentiate between these different request types. For backward compatibility, if request-type is not provided, then we will assume that it is ""custom"". On the server, we can add the following logic: * For Orders 1 and 2, we may be able to validate whether the request-data is valid PKCS10/ PKCS7. * For Order 3, we should retrieve the relevant public key, create a PKCS10 request using the public key, subject DN and extensions data. Submit to backend as a simple CMC request. * For Orders 1,2,3, submit to plugin through new CertPlugin API calls: issue_simple_cmc_request(), issue_full_cmc_request(). * Plugins will interact with the back-end CA, which presumably will return PKCS7 full CMC responses. We have two options here: * Let the plugin interpret the response and set the internal state accordingly. * Have the plugin return the CMC Response to barbican-core, most likely through the ResultDTO. The CMC response contains a CMCStatus field with values:: CMCStatus ::= INTEGER { success (0), -- reserved (1), failed (2), pending (3), noSupport (4), confirmRequired (5), popRequired (6), partial (7) } In the case of success, we could retrieve the certs and intermediates. In the case of pending/partial, barbican-core would need to extract the relevant Query Pending control/ pendInfo data and store it in the order metadata. When the retry task is executed, the CMCRequest (with the Query Pending data) would be resubmitted. In the other cases, we would extract the relevant error data, and set this accordingly. I would suggest that barbican-core handle this processing so that plugins not need to implement this. We could look at how the libest folks handle this processing in their server/client code. * Orders of type 4 are already supported by the existing code. * Encryption in the CMC Response (TBD) * Renewing certs (TBD) Alternatives ------------ Instead of supporting CMC, we could try to define a common API with a basic set of parameters for different profiles of certificates. This is the approach started in [1]. This is simpler, but seems a little arbitrary. Using CMC is likely to be supported by most CA's because it is standards-based. Also, there are likely to be existing clients that already do CMC. The simpler mechanism is also limited, having no support for encryption or POP. Ultimately, I think we would need to evolve to support something like CMC. Data model impact ----------------- We may need to add addtional data in the order_metadata, but this should not result in database changes. REST API impact --------------- See above in proposed changes. Security impact --------------- None Notifications & Audit Impact ---------------------------- None, other than additional audit changes needed. Other end user impact --------------------- There will need to be changes in either barbican-client or certmonger to support the new API. Performance Impact ------------------ There will be some addtional processing that will need to be done to parse the CMCRequest. These changes are not covered in the spec. Other deployer impact --------------------- None. Developer impact ---------------- Plugin developers will need to support two new methods: issue_simple_cmc_request() and issue_full_cmc_request(). Implementation ============== Assignee(s) Primary assignee: alee akoneru chellygel woodster Work Items ---------- * Modify API code to parse the new Order parameters and pass the data to lower levels. * Add code to validate CMC request data. * Add code to certificate_manger.py to send the requests to the plugins and retrieve the response. * Add code to certificate_manager.py to parse and handle CMC Response, including handling pending certs and retries. * Add client code. Dependencies ============ None Testing ======= More unit and functional tests will be needed. Documentation Impact ==================== Docs would need to be changed to reflect this API. References ========== [1] https://review.openstack.org/#/c/129695/3/specs/kilo/add-certificate-type-to-order-resource.rst,cm ",,274,0
openstack%2Fhorizon~master~I514f83088931bfa2a4838ceb13d46b9973fd6778,openstack/horizon,master,I514f83088931bfa2a4838ceb13d46b9973fd6778,"Add ""login as admin"" for integration tests",MERGED,2014-12-10 09:23:07.000000000,2014-12-10 23:51:18.000000000,2014-12-10 23:51:16.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 8577}, {'_account_id': 9981}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-12-10 09:23:07.000000000', 'files': ['openstack_dashboard/test/integration_tests/helpers.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a026b2d5547b324118e56ac1460f16fe57d26d6f', 'message': 'Add ""login as admin"" for integration tests\n\nAdd class AdminTestCase for login as admin.\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: I514f83088931bfa2a4838ceb13d46b9973fd6778\n'}]",0,140618,a026b2d5547b324118e56ac1460f16fe57d26d6f,10,6,1,12355,,,0,"Add ""login as admin"" for integration tests

Add class AdminTestCase for login as admin.

Partially implements blueprint: selenium-integration-testing

Change-Id: I514f83088931bfa2a4838ceb13d46b9973fd6778
",git fetch https://review.opendev.org/openstack/horizon refs/changes/18/140618/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/helpers.py'],1,a026b2d5547b324118e56ac1460f16fe57d26d6f,bp/selenium-integration-testing," class AdminTestCase(BaseTestCase): def setUp(self): super(AdminTestCase, self).setUp() self.login_pg = loginpage.LoginPage(self.driver, self.conf) self.login_pg.go_to_login_page() self.home_pg = self.login_pg.login( user=self.conf.identity.admin_username, password=self.conf.identity.admin_password) def tearDown(self): self.home_pg.log_out() super(AdminTestCase, self).tearDown()",,14,0
openstack%2Fneutron~master~I6d1ede1c66e7b62c68449224f274417a5d66c12f,openstack/neutron,master,I6d1ede1c66e7b62c68449224f274417a5d66c12f,Prettify tox output for functional tests,MERGED,2014-12-10 18:15:41.000000000,2014-12-10 23:46:43.000000000,2014-12-10 21:32:26.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-10 18:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/59348ed1340a39920f223c00d28ace7237a1d660', 'message': 'Prettify tox output for functional tests\n\nChange I6a079ad introduced some magic to enable showing test output\nas the test run. Do the same for *-functional tests too.\n\nChange-Id: I6d1ede1c66e7b62c68449224f274417a5d66c12f\n'}, {'number': 2, 'created': '2014-12-10 18:37:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/05044203245bee6dd09378c6d8c7b4d74678e37b', 'message': 'Prettify tox output for functional tests\n\nChange I6a079ad introduced some magic to enable showing test output\nas the test run. Do the same for *-functional tests too, by reusing\nthe default testenv\n\nChange-Id: I6d1ede1c66e7b62c68449224f274417a5d66c12f\n'}]",0,140793,05044203245bee6dd09378c6d8c7b4d74678e37b,35,21,2,748,,,0,"Prettify tox output for functional tests

Change I6a079ad introduced some magic to enable showing test output
as the test run. Do the same for *-functional tests too, by reusing
the default testenv

Change-Id: I6d1ede1c66e7b62c68449224f274417a5d66c12f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/140793/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,59348ed1340a39920f223c00d28ace7237a1d660,prettify-tox-functional,whitelist_externals = sh sh tools/pretty_tox.sh '{posargs}'whitelist_externals = sh sh tools/pretty_tox.sh '{posargs}', python -m neutron.openstack.common.lockutils python setup.py testr --slowest --testr-args='{posargs}' python -m neutron.openstack.common.lockutils python setup.py testr --slowest --testr-args='{posargs}',4,2
openstack%2Fkeystonemiddleware~master~I2bada31881c5de54c3af6d47e3f6412358edc582,openstack/keystonemiddleware,master,I2bada31881c5de54c3af6d47e3f6412358edc582,Add a test to ensure the version check error,MERGED,2014-12-05 04:06:53.000000000,2014-12-10 23:37:38.000000000,2014-12-10 23:37:38.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 9101}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-12-05 04:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/b0c9af90aa35808c3281f71790b06c9dd5084cb3', 'message': 'Add a test to ensure the version check error\n\nThis section of code was untested. We should enforce the behaviour to\nhandle changes in this area.\n\nChange-Id: I2bada31881c5de54c3af6d47e3f6412358edc582\n'}, {'number': 2, 'created': '2014-12-05 05:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c821c22b60199de4fa91dd78f5d71005222e0645', 'message': ""Add a test to ensure the version check error\n\n_LC wasn't imported with the other log translation methods. This section\nof code was untested. We should enforce the behaviour to handle changes\nin this area.\n\nChange-Id: I2bada31881c5de54c3af6d47e3f6412358edc582\n""}, {'number': 3, 'created': '2014-12-08 04:17:13.000000000', 'files': ['keystonemiddleware/auth_token.py', 'keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6ed9ec4194a233c4da8ea45e0687e9108aa6863c', 'message': ""Add a test to ensure the version check error\n\n_LC wasn't imported with the other log translation methods. This section\nof code was untested. We should enforce the behaviour to handle changes\nin this area.\n\nChange-Id: I2bada31881c5de54c3af6d47e3f6412358edc582\n""}]",2,139512,6ed9ec4194a233c4da8ea45e0687e9108aa6863c,13,5,3,7191,,,0,"Add a test to ensure the version check error

_LC wasn't imported with the other log translation methods. This section
of code was untested. We should enforce the behaviour to handle changes
in this area.

Change-Id: I2bada31881c5de54c3af6d47e3f6412358edc582
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/12/139512/2 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/test_auth_token_middleware.py'],1,b0c9af90aa35808c3281f71790b06c9dd5084cb3,bug/1372142,"class OtherTests(BaseAuthTokenMiddlewareTest): def setUp(self): super(OtherTests, self).setUp() self.logger = self.useFixture(fixtures.FakeLogger()) def test_unknown_server_versions(self): versions = fixture.DiscoveryList(v2=False, v3_id='v4', href=BASE_URI) self.set_middleware() self.requests.get(""%s/"" % BASE_URI, json=versions, status_code=300) req = webob.Request.blank('/') req.headers['X-Auth-Token'] = uuid.uuid4().hex self.middleware(req.environ, self.start_fake_response) self.assertEqual(401, self.response_status) self.assertIn('versions [v3.0, v2.0]', self.logger.output) ",,20,0
openstack%2Fdevstack-gate~master~I6044b27718de730286adcb69b2b1e1a2ab95e1fd,openstack/devstack-gate,master,I6044b27718de730286adcb69b2b1e1a2ab95e1fd,"Temporarily disable testing lbaas, fwaas, and vpnaas",MERGED,2014-12-08 22:23:08.000000000,2014-12-10 23:26:52.000000000,2014-12-09 21:04:15.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1923}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 8871}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-08 22:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c44d3f5b4f874cf7ad34ed32308db0e50acc665f', 'message': 'Temporarily disable testing lbaas, fwaas, and vpnaas\n\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n'}, {'number': 2, 'created': '2014-12-08 22:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fa2ca11277065ab497c86f1c7a5d89df72252638', 'message': 'Temporarily disable testing lbaas, fwaas, and vpnaas\n\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n'}, {'number': 3, 'created': '2014-12-08 23:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/211ca3758fa325c241ff8bea5fc13b29d90b88e5', 'message': 'Temporarily disable testing lbaas, fwaas, and vpnaas\n\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n'}, {'number': 4, 'created': '2014-12-09 00:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0941cf1ec4193f3366c6a1a15ca3f8d39e2b70c6', 'message': 'Temporarily disable testing lbaas, fwaas, and vpnaas\n\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n'}, {'number': 5, 'created': '2014-12-09 15:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/4ea579d8631fcbd29a563586ac97a505858b3a76', 'message': ""Temporarily disable testing lbaas, fwaas, and vpnaas\n\nAs part of the migration of the advanced services out of the neutron repo\nthe testing in tempest needs to be disabled, otherwise the removal patch\nin neutron will not be able to land. This is just \n\nThis patch passes the necessary configuration to devstack and tempest to\ndisable the advanced services from being started and also telling tempest\nthat the features aren't enabled. (which skips the tests) For setting the\nenabled extensions in tempest this patch hard codes the extension list.\nThis is technically incorrect because this list isn't consistent between\nbranches, however since test-matrix.py doesn't support specifying\nextensions yet, as a short-term temporary workaround it should be fine.\n\n\nRelated-Bug: #1400370\nCo-Authored-By: Matthew Treinish <mtreinish@kortar.org>\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n""}, {'number': 6, 'created': '2014-12-09 17:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5abe9d65b8420f03c8763e5e08889b5cfca4ade7', 'message': ""Temporarily disable testing lbaas, fwaas, and vpnaas\n\nAs part of the migration of the advanced services out of the neutron repo\nthe testing in tempest needs to be disabled, otherwise the removal patch\nin neutron will not be able to land. This is just\n\nThis patch passes the necessary configuration to devstack and tempest to\ndisable the advanced services from being started and also telling tempest\nthat the features aren't enabled. (which skips the tests) For setting the\nenabled extensions in tempest this patch hard codes the extension list.\nThis is technically incorrect because this list isn't consistent between\nbranches, however since test-matrix.py doesn't support specifying\nextensions yet, as a short-term temporary workaround it should be fine.\n\nRelated-Bug: #1400370\nCo-Authored-By: Matthew Treinish <mtreinish@kortar.org>\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n""}, {'number': 7, 'created': '2014-12-09 17:54:24.000000000', 'files': ['features.yaml', 'test-features.sh', 'devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5358740468554afcf4fbef0aa16b6f76bf68cae9', 'message': ""Temporarily disable testing lbaas, fwaas, and vpnaas\n\nAs part of the migration of the advanced services out of the neutron repo\nthe testing in tempest needs to be disabled, otherwise the removal patch\nin neutron will not be able to land. This is just a temporary workaround\nto enable forward progress on the repo split, and should be reverted once\nthat is complete.\n\nThis patch passes the necessary configuration to devstack and tempest to\ndisable the advanced services from being started and also telling tempest\nthat the features aren't enabled. (which skips the tests) For setting the\nenabled extensions in tempest this patch hard codes the extension list.\nThis is technically incorrect because this list isn't consistent between\nbranches, however since test-matrix.py doesn't support specifying\nextensions yet, as a short-term temporary workaround it should be fine.\n\nRelated-Bug: #1400370\nCo-Authored-By: Matthew Treinish <mtreinish@kortar.org>\nChange-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd\n""}]",0,140164,5358740468554afcf4fbef0aa16b6f76bf68cae9,29,10,7,10980,,,0,"Temporarily disable testing lbaas, fwaas, and vpnaas

As part of the migration of the advanced services out of the neutron repo
the testing in tempest needs to be disabled, otherwise the removal patch
in neutron will not be able to land. This is just a temporary workaround
to enable forward progress on the repo split, and should be reverted once
that is complete.

This patch passes the necessary configuration to devstack and tempest to
disable the advanced services from being started and also telling tempest
that the features aren't enabled. (which skips the tests) For setting the
enabled extensions in tempest this patch hard codes the extension list.
This is technically incorrect because this list isn't consistent between
branches, however since test-matrix.py doesn't support specifying
extensions yet, as a short-term temporary workaround it should be fine.

Related-Bug: #1400370
Co-Authored-By: Matthew Treinish <mtreinish@kortar.org>
Change-Id: I6044b27718de730286adcb69b2b1e1a2ab95e1fd
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/64/140164/7 && git format-patch -1 --stdout FETCH_HEAD,"['features.yaml', 'test-features.sh']",2,c44d3f5b4f874cf7ad34ed32308db0e50acc665f,bug/1400370,"TEMPEST_NEUTRON_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,heat,h-api,h-api-cfn,h-api-cw,h-eng,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,trove,tr-api,tr-tmgr,tr-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,sahara"" TEMPEST_HEAT_SLOW_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,heat,h-api,h-api-cfn,h-api-cw,h-eng,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,trove,tr-api,tr-tmgr,tr-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,sahara""","TEMPEST_NEUTRON_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,heat,h-api,h-api-cfn,h-api-cw,h-eng,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,trove,tr-api,tr-tmgr,tr-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-vpn,q-fwaas,q-metering,sahara"" TEMPEST_HEAT_SLOW_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,heat,h-api,h-api-cfn,h-api-cw,h-eng,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,trove,tr-api,tr-tmgr,tr-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-vpn,q-fwaas,q-metering,sahara""",3,3
openstack%2Fpython-heatclient~master~Ifc912b31fe2f71d5267827321b8de0420ad62903,openstack/python-heatclient,master,Ifc912b31fe2f71d5267827321b8de0420ad62903,Initial setup for i18n support,MERGED,2014-11-28 18:26:07.000000000,2014-12-10 23:24:14.000000000,2014-12-10 23:24:14.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-11-28 18:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e0eb17cb1b5d43f2687cbcffe8207e1da140d15d', 'message': 'Initial setup for i18n support\n\nChange-Id: Ifc912b31fe2f71d5267827321b8de0420ad62903\nRelated-Bug: #1269930\n'}, {'number': 2, 'created': '2014-11-28 19:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2bc07707eda87ba2b18c8c8546ac8e31627f1b1f', 'message': 'Initial setup for i18n support\n\nChange-Id: Ifc912b31fe2f71d5267827321b8de0420ad62903\nRelated-Bug: #1269930\n'}, {'number': 3, 'created': '2014-12-01 12:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/5a2a4d8899ffc51dc4783a7da0b2c57e3cf53933', 'message': 'Initial setup for i18n support\n\nChange-Id: Ifc912b31fe2f71d5267827321b8de0420ad62903\nRelated-Bug: #1269930\n'}, {'number': 4, 'created': '2014-12-03 10:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d459d6dc5ad138834cbe24787f2060c76541e30d', 'message': 'Initial setup for i18n support\n\nChange-Id: Ifc912b31fe2f71d5267827321b8de0420ad62903\nPartial-Bug: #1269930\n'}, {'number': 5, 'created': '2014-12-10 10:32:21.000000000', 'files': ['requirements.txt', 'babel.cfg', 'python-heatclient/locale/python-heatclient.pot', 'setup.cfg', 'tox.ini', 'MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/802ed10fde0755641c0aa8b1dce40cb2a6a6c4f1', 'message': 'Initial setup for i18n support\n\nChange-Id: Ifc912b31fe2f71d5267827321b8de0420ad62903\nPartial-Bug: #1269930\n'}]",0,137842,802ed10fde0755641c0aa8b1dce40cb2a6a6c4f1,16,4,5,13323,,,0,"Initial setup for i18n support

Change-Id: Ifc912b31fe2f71d5267827321b8de0420ad62903
Partial-Bug: #1269930
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/42/137842/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'babel.cfg', 'python-heatclient/locale/python-heatclient.pot', 'setup.cfg', 'heatclient/i18n.py', 'MANIFEST.in']",6,e0eb17cb1b5d43f2687cbcffe8207e1da140d15d,bug/1269930,include babel.cfgrecursive-include python-heatclient *.po *.pot,,50,0
openstack%2Fpython-heatclient~master~I3366e00fdda025693c3151755528ec18d190ed23,openstack/python-heatclient,master,I3366e00fdda025693c3151755528ec18d190ed23,Show the creation_time for stack snapshot list,MERGED,2014-12-05 01:56:29.000000000,2014-12-10 23:24:03.000000000,2014-12-10 23:24:02.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 7634}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-05 01:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/f0db85637db03a469ed5ae39b860ef3adc588d22', 'message': 'Show the creation_time for stack snapshot list\n\nShow the creation_time information for stack snapshot\nlist.\n\nChange-Id: I3366e00fdda025693c3151755528ec18d190ed23\nCloses-Bug: #1399500\n'}, {'number': 2, 'created': '2014-12-05 02:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/7e6227dfdd778646be641ae45df4c5db1d5d7a61', 'message': 'Show the creation_time for stack snapshot list\n\nShow the creation_time information for stack snapshot\nlist.\n\nChange-Id: I3366e00fdda025693c3151755528ec18d190ed23\nCloses-Bug: #1399500\n'}, {'number': 3, 'created': '2014-12-05 03:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0354afac0aa49ab2bb07ac1fbd76a08358489843', 'message': 'Show the creation_time for stack snapshot list\n\nShow the creation_time information for stack snapshot\nlist.\n\nChange-Id: I3366e00fdda025693c3151755528ec18d190ed23\nCloses-Bug: #1399500\n'}, {'number': 4, 'created': '2014-12-10 03:48:31.000000000', 'files': ['heatclient/tests/test_shell.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/5bb854e91ee3c3bf18a83464a95c6b57c39c1048', 'message': 'Show the creation_time for stack snapshot list\n\nShow the creation_time information for stack snapshot\nlist.\n\nChange-Id: I3366e00fdda025693c3151755528ec18d190ed23\nCloses-Bug: #1399500\n'}]",0,139300,5bb854e91ee3c3bf18a83464a95c6b57c39c1048,15,8,4,8289,,,0,"Show the creation_time for stack snapshot list

Show the creation_time information for stack snapshot
list.

Change-Id: I3366e00fdda025693c3151755528ec18d190ed23
Closes-Bug: #1399500
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/00/139300/4 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_shell.py', 'heatclient/v1/shell.py']",2,f0db85637db03a469ed5ae39b860ef3adc588d22,bug/1399500," import pdb pdb.set_trace() fields = ['id', 'name', 'status', 'status_reason', 'data', 'creation_time'] 'creation_time': lambda x: x['creation_time'],"," fields = ['id', 'name', 'status', 'status_reason', 'data']",9,2
openstack%2Fpython-heatclient~master~Ia1f27102f31a42e7b58008a9b4886cde293308c6,openstack/python-heatclient,master,Ia1f27102f31a42e7b58008a9b4886cde293308c6,Add support for parameter_defaults in environment,MERGED,2014-11-19 18:44:20.000000000,2014-12-10 23:20:41.000000000,2014-12-10 23:20:40.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-11-19 18:44:20.000000000', 'files': ['heatclient/tests/test_environment_format.py', 'heatclient/common/environment_format.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ae39ab240f32626cd6e2f3c7c265645ff82d38ae', 'message': 'Add support for parameter_defaults in environment\n\nhttps://review.openstack.org/#/c/131337/ adds support for a new\nsection ""parameter_defaults"" in the environment, so support it\nin the client\n\nblueprint env-nested-usability\n\nChange-Id: Ia1f27102f31a42e7b58008a9b4886cde293308c6\n'}]",0,135693,ae39ab240f32626cd6e2f3c7c265645ff82d38ae,14,4,1,4328,,,0,"Add support for parameter_defaults in environment

https://review.openstack.org/#/c/131337/ adds support for a new
section ""parameter_defaults"" in the environment, so support it
in the client

blueprint env-nested-usability

Change-Id: Ia1f27102f31a42e7b58008a9b4886cde293308c6
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/93/135693/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/test_environment_format.py', 'heatclient/common/environment_format.py']",2,ae39ab240f32626cd6e2f3c7c265645ff82d38ae,bp/env-nested-usability,"SECTIONS = (PARAMETER_DEFAULTS, PARAMETERS, RESOURCE_REGISTRY) = \ ('parameter_defaults', 'parameters', 'resource_registry')","SECTIONS = (PARAMETERS, RESOURCE_REGISTRY) = \ ('parameters', 'resource_registry')",3,2
openstack%2Fironic-python-agent~master~I40fa4b8d889ce08fa20f7b0841b5abf122499676,openstack/ironic-python-agent,master,I40fa4b8d889ce08fa20f7b0841b5abf122499676,Do not log configdrive contents ever,MERGED,2014-12-10 20:14:06.000000000,2014-12-10 23:09:51.000000000,2014-12-10 23:06:48.000000000,"[{'_account_id': 3}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10380}, {'_account_id': 14228}]","[{'number': 1, 'created': '2014-12-10 20:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/291b636e5fd896b9adec1ad8937cc85d8b788e39', 'message': ""Do not log configdrive contents at INFO.\n\nCurrently this logline contains the full, base64'd configdrive. This\nchanges it to log the file it came from instead.\n\nChange-Id: I40fa4b8d889ce08fa20f7b0841b5abf122499676\nCloses-bug: 1401244\n""}, {'number': 2, 'created': '2014-12-10 20:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/aaeaf4293bf34a133c3983b98188f8de9b9278c5', 'message': ""Do not log configdrive contents ever.\n\nCurrently this logline contains the full, base64'd configdrive. This\nchanges it to log the file it came from instead.\n\nChange-Id: I40fa4b8d889ce08fa20f7b0841b5abf122499676\nCloses-bug: 1401244""}, {'number': 3, 'created': '2014-12-10 22:06:00.000000000', 'files': ['ironic_python_agent/extensions/standby.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/86d4b41709548cb304ab9cc0b627b39449eef121', 'message': ""Do not log configdrive contents ever\n\nCurrently this logline contains the full, base64'd configdrive. This\nchanges it to log the file it came from instead.\n\nChange-Id: I40fa4b8d889ce08fa20f7b0841b5abf122499676\nCloses-bug: 1401244\n""}]",0,140830,86d4b41709548cb304ab9cc0b627b39449eef121,14,5,3,10342,,,0,"Do not log configdrive contents ever

Currently this logline contains the full, base64'd configdrive. This
changes it to log the file it came from instead.

Change-Id: I40fa4b8d889ce08fa20f7b0841b5abf122499676
Closes-bug: 1401244
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/30/140830/3 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/extensions/standby.py'],1,291b636e5fd896b9adec1ad8937cc85d8b788e39,bug/1401244," filename,"," configdrive,",1,1
openstack%2Fproject-config~master~I6379456ca901afd7e55eb441de9e403f517a2094,openstack/project-config,master,I6379456ca901afd7e55eb441de9e403f517a2094,Fix ACL groups for networking L2GW,MERGED,2014-12-09 18:30:39.000000000,2014-12-10 22:32:17.000000000,2014-12-10 22:32:16.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-09 18:30:39.000000000', 'files': ['gerrit/acls/stackforge/networking-l2gw.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/47ace31a1fcdd2a38ae98e41b5028fc28f60ef8e', 'message': 'Fix ACL groups for networking L2GW\n\nFix the ACL so that we have -core and -release groups as usual.\n\nChange-Id: I6379456ca901afd7e55eb441de9e403f517a2094\n'}]",3,140426,47ace31a1fcdd2a38ae98e41b5028fc28f60ef8e,13,5,1,6547,,,0,"Fix ACL groups for networking L2GW

Fix the ACL so that we have -core and -release groups as usual.

Change-Id: I6379456ca901afd7e55eb441de9e403f517a2094
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/140426/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/stackforge/networking-l2gw.config'],1,47ace31a1fcdd2a38ae98e41b5028fc28f60ef8e,fix-networking-L2GW,label-Code-Review = -2..+2 group networking-l2gw-core label-Workflow = -1..+1 group networking-l2gw-corepushSignedTag = group networking-l2gw-release,label-Code-Review = -2..+2 group networking-l2gw label-Workflow = -1..+1 group networking-l2gwpushSignedTag = group networking-l2gw,3,3
openstack%2Fhorizon~master~I8a993b07e395a3274bfaba0310566ebe49ed2eee,openstack/horizon,master,I8a993b07e395a3274bfaba0310566ebe49ed2eee,HORI-3246 Hide Identity Dashboard for keystone v3,ABANDONED,2014-12-10 21:08:12.000000000,2014-12-10 22:08:00.000000000,,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 11098}]","[{'number': 1, 'created': '2014-12-10 21:08:12.000000000', 'files': ['openstack_dashboard/templatetags/context_selection.py', 'openstack_dashboard/dashboards/identity/dashboard.py', 'openstack_dashboard/enabled/_25_identity.py', 'openstack_dashboard/templates/_header.html', 'openstack_dashboard/templates/context_selection/_menu_footer.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/968e2826609fd7d185d3db62eafa2a46610de178', 'message': 'HORI-3246 Hide Identity Dashboard for keystone v3\n\nIf Keystone v3 is configured, hide the Identity dashboard and panels\n\nChange-Id: I8a993b07e395a3274bfaba0310566ebe49ed2eee\nJIRA:HORI-3246\n'}]",0,140837,968e2826609fd7d185d3db62eafa2a46610de178,5,3,1,11098,,,0,"HORI-3246 Hide Identity Dashboard for keystone v3

If Keystone v3 is configured, hide the Identity dashboard and panels

Change-Id: I8a993b07e395a3274bfaba0310566ebe49ed2eee
JIRA:HORI-3246
",git fetch https://review.opendev.org/openstack/horizon refs/changes/37/140837/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/templatetags/context_selection.py', 'openstack_dashboard/dashboards/identity/dashboard.py', 'openstack_dashboard/enabled/_25_identity.py', 'openstack_dashboard/templates/_header.html', 'openstack_dashboard/templates/context_selection/_menu_footer.html']",5,968e2826609fd7d185d3db62eafa2a46610de178,bug/HORI-3246,"{% load branding i18n %} {% load url from future %} {% if legacy_keystone %} <div class=""footer""> <a href=""{% url 'horizon:identity:projects:index' %}"">{% trans ""More Projects"" %}</a> </div> {% endif %} ",,31,9
openstack%2Fdiskimage-builder~master~Ia30d266dafe22313ba26efa8c188f679801b4109,openstack/diskimage-builder,master,Ia30d266dafe22313ba26efa8c188f679801b4109,Rename yaml_path to installs_path,ABANDONED,2014-12-10 16:27:07.000000000,2014-12-10 21:58:31.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-12-10 16:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b78939c68fb90b7a9cad51b306dc78f9669c8403', 'message': ""Rename yaml_path to installs_path\n\nyaml_path can actually contain the path to a json or native file as\nwell as yaml. That's unclear to read, so change it to be more general.\n\nChange-Id: Ia30d266dafe22313ba26efa8c188f679801b4109\n""}, {'number': 2, 'created': '2014-12-10 16:56:11.000000000', 'files': ['elements/package-installs/bin/package-installs-v2'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c7c4ce6189d3dec23e0ac7e146d7fb8edf1c1b23', 'message': ""Rename yaml_path to installs_path\n\nyaml_path can actually contain the path to a json or native file as\nwell as yaml. That's unclear to read, so change it to be more general.\n\nChange-Id: Ia30d266dafe22313ba26efa8c188f679801b4109\n""}]",0,140761,c7c4ce6189d3dec23e0ac7e146d7fb8edf1c1b23,6,2,2,2,,,0,"Rename yaml_path to installs_path

yaml_path can actually contain the path to a json or native file as
well as yaml. That's unclear to read, so change it to be more general.

Change-Id: Ia30d266dafe22313ba26efa8c188f679801b4109
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/61/140761/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/package-installs/bin/package-installs-v2'],1,b78939c68fb90b7a9cad51b306dc78f9669c8403,," for installs_path in os.listdir(self.path): full_path = os.path.join(self.path, installs_path) yield (installs_path[:-5], pi)"," for yaml_path in os.listdir(self.path): full_path = os.path.join(self.path, yaml_path) yield (yaml_path[:-5], pi)",3,3
openstack%2Fdiskimage-builder~master~I4d6bddee3721d93e9a6c00bd4cad77a80651be4c,openstack/diskimage-builder,master,I4d6bddee3721d93e9a6c00bd4cad77a80651be4c,Don't make YAML required,ABANDONED,2014-12-10 16:27:07.000000000,2014-12-10 21:58:18.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-12-10 16:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b09c615a1f09369f4b7b6ba76f7a245e2fd8c436', 'message': ""Don't make YAML required\n\npython-yaml actually has something like 80 dependencies in a base\nCentOS, which means that requiring it to be present for the tool to run\nputs a content burden on the images themselves. Instead, only import\nyaml functionality if the user uses a yaml file.\n\nChange-Id: I4d6bddee3721d93e9a6c00bd4cad77a80651be4c\n""}, {'number': 2, 'created': '2014-12-10 16:55:50.000000000', 'files': ['elements/package-installs/extra-data.d/11-create-package-installs-dir', 'elements/package-installs/bin/package-installs-v2'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/aa3f860db5bfa9b4d1c8a2f2496ecf0ea9ad6c85', 'message': ""Don't make YAML required\n\npython-yaml actually has something like 80 dependencies in a base\nCentOS, which means that requiring it to be present for the tool to run\nputs a content burden on the images themselves. Instead, only import\nyaml functionality if the user uses a yaml file.\n\nChange-Id: I4d6bddee3721d93e9a6c00bd4cad77a80651be4c\n""}]",2,140760,aa3f860db5bfa9b4d1c8a2f2496ecf0ea9ad6c85,7,3,2,2,,,0,"Don't make YAML required

python-yaml actually has something like 80 dependencies in a base
CentOS, which means that requiring it to be present for the tool to run
puts a content burden on the images themselves. Instead, only import
yaml functionality if the user uses a yaml file.

Change-Id: I4d6bddee3721d93e9a6c00bd4cad77a80651be4c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/60/140760/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/package-installs/bin/package-installs-v2'],1,b09c615a1f09369f4b7b6ba76f7a245e2fd8c436,,"try: from yaml import load as yaml_load except ImportError: yaml_load = None if yaml_load is None: print( ""YAML file %s but PyYAML is not installed in the image"" % path) sys.exit(1)",from yaml import load as yaml_load ,8,2
openstack%2Foslo.vmware~master~Icce4f5f2c18590596157a9634bb51f43f225ac29,openstack/oslo.vmware,master,Icce4f5f2c18590596157a9634bb51f43f225ac29,Updated from global requirements,MERGED,2014-12-08 08:58:05.000000000,2014-12-10 21:57:51.000000000,2014-12-10 21:57:51.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 7575}, {'_account_id': 9008}, {'_account_id': 9149}]","[{'number': 1, 'created': '2014-12-08 08:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/250ce77a5138a89209526b9ca3aaa84ac714908d', 'message': 'Updated from global requirements\n\nChange-Id: Icce4f5f2c18590596157a9634bb51f43f225ac29\n'}, {'number': 2, 'created': '2014-12-09 14:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/f053b8eacf94f9fdb4fa1132b352f58f4801dcf8', 'message': 'Updated from global requirements\n\nChange-Id: Icce4f5f2c18590596157a9634bb51f43f225ac29\n'}, {'number': 3, 'created': '2014-12-10 17:03:13.000000000', 'files': ['requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/e70a05782e2cfb6ff2fbb7582b955bcf9e6df4cd', 'message': 'Updated from global requirements\n\nChange-Id: Icce4f5f2c18590596157a9634bb51f43f225ac29\n'}]",0,139945,e70a05782e2cfb6ff2fbb7582b955bcf9e6df4cd,13,6,3,11131,,,0,"Updated from global requirements

Change-Id: Icce4f5f2c18590596157a9634bb51f43f225ac29
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/45/139945/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,250ce77a5138a89209526b9ca3aaa84ac714908d,openstack/requirements,urllib3>=1.8.3,urllib3>=1.7.1,2,2
openstack%2Fneutron-fwaas~master~I78593f89427d69d8d659f55ee26a5204c42daaec,openstack/neutron-fwaas,master,I78593f89427d69d8d659f55ee26a5204c42daaec,Init of separate alembic chain,MERGED,2014-12-10 00:47:38.000000000,2014-12-10 21:48:37.000000000,2014-12-10 21:48:36.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 11822}]","[{'number': 1, 'created': '2014-12-10 00:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/95243d13ec9fc1556505b659bed3299c2628fefb', 'message': 'Init of separate alembic chain\n\nChange-Id: I78593f89427d69d8d659f55ee26a5204c42daaec\n'}, {'number': 2, 'created': '2014-12-10 06:07:18.000000000', 'files': ['neutron_fwaas/db/migration/alembic_migrations/script.py.mako', 'neutron_fwaas/db/migration/__init__.py', 'neutron_fwaas/db/alembic.ini', 'neutron_fwaas/db/migration/alembic_migrations/README', 'neutron_fwaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_fwaas/db/migration/alembic_migrations/env.py', 'neutron_fwaas/db/migration/alembic_migrations/versions/start_neutron_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/152ce96a82b0cd528500101aaa17bb21b0097b74', 'message': 'Init of separate alembic chain\n\nChange-Id: I78593f89427d69d8d659f55ee26a5204c42daaec\n'}]",2,140545,152ce96a82b0cd528500101aaa17bb21b0097b74,13,5,2,6951,,,0,"Init of separate alembic chain

Change-Id: I78593f89427d69d8d659f55ee26a5204c42daaec
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/45/140545/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/db/migration/alembic_migrations/script.py.mako', 'neutron_fwaas/db/migration/__init__.py', 'neutron_fwaas/db/alembic.ini', 'neutron_fwaas/db/migration/alembic_migrations/README', 'neutron_fwaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_fwaas/db/migration/alembic_migrations/env.py', 'neutron_fwaas/db/migration/alembic_migrations/versions/start_neutron_fwaas.py']",7,95243d13ec9fc1556505b659bed3299c2628fefb,,"# Copyright 2014 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""start neutron-fwaas chain Revision ID: start_neutron_fwaas Revises: None Create Date: 2014-12-09 18:42:08.262632 """""" # revision identifiers, used by Alembic. revision = 'start_neutron_fwaas' down_revision = None def upgrade(): pass def downgrade(): pass ",,204,0
openstack%2Fcue~master~I4178c358b80d649a9ca92c336dd4b9a835edf8f0,openstack/cue,master,I4178c358b80d649a9ca92c336dd4b9a835edf8f0,Add 'status' field to Version so that API discovery works,MERGED,2014-12-10 09:25:58.000000000,2014-12-10 21:47:51.000000000,2014-12-10 21:47:50.000000000,"[{'_account_id': 3}, {'_account_id': 1925}]","[{'number': 1, 'created': '2014-12-10 09:25:58.000000000', 'files': ['cue/api/controllers/root.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/0ee75a588909c09ed45932e29556b950f1933cb5', 'message': ""Add 'status' field to Version so that API discovery works\n\nChange-Id: I4178c358b80d649a9ca92c336dd4b9a835edf8f0\n""}]",0,140619,0ee75a588909c09ed45932e29556b950f1933cb5,6,2,1,395,,,0,"Add 'status' field to Version so that API discovery works

Change-Id: I4178c358b80d649a9ca92c336dd4b9a835edf8f0
",git fetch https://review.opendev.org/openstack/cue refs/changes/19/140619/1 && git format-patch -1 --stdout FETCH_HEAD,['cue/api/controllers/root.py'],1,0ee75a588909c09ed45932e29556b950f1933cb5,add-stable-version," status = wtypes.text ""The status of this version"" def convert(self, id, status): version.status = status root.versions = [Version.convert('v1', 'STABLE')] root.default_version = Version.convert('v1', 'STABLE')"," def convert(self, id): root.versions = [Version.convert('v1')] root.default_version = Version.convert('v1')",7,3
openstack%2Ftripleo-specs~master~I8720156b785263b54ad96d2e47ebe79703298640,openstack/tripleo-specs,master,I8720156b785263b54ad96d2e47ebe79703298640,WIP: Environment definition and use,ABANDONED,2014-06-06 07:25:23.000000000,2014-12-10 21:32:13.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 4190}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-06-06 07:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/209f92c4b08c60055c7240f6003811ee4f27b4b6', 'message': 'Add multiple-environment-support spec\n\nWhile working on I1b10abda0209f1c58c6c2612542d8a6cd42628e8 I came to\nunderstand that the rules for naming VMs inside a numbered environment\nwere labyrinthine and confusing. As a result, I created\n3a0d4315aa3e7d5281db827f01b681d7d8c3128d which simplifies the rules\nsomewhat.\n\nHowever, both changes had much discussion which I believe was caused\nby the fact that the behaviour in question was not specified anywhere\nbut had merely grown over time without deep consideration of how\nthings interacted.\n\nThis change is intended to codify (and perhaps simplify) existing\nbehaviour.\n\nChange-Id: I8720156b785263b54ad96d2e47ebe79703298640\n'}, {'number': 2, 'created': '2014-06-16 10:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/ac77f8e8cd315c38aabf58778e4aaa4b917864ef', 'message': 'Define what an environment is and how to use one\n\nWhile working on I1b10abda0209f1c58c6c2612542d8a6cd42628e8 I came to\nunderstand that the rules for naming VMs inside a numbered environment\nwere labyrinthine and confusing. As a result, I created\n3a0d4315aa3e7d5281db827f01b681d7d8c3128d which simplifies the rules\nsomewhat.\n\nHowever, both changes had much discussion which I believe was caused\nby the fact that the behaviour in question was not specified anywhere\nbut had merely grown over time without deep consideration of how\nthings interacted.\n\nThis change is intended to codify (and perhaps simplify) existing\nbehaviour.\n\nChange-Id: I8720156b785263b54ad96d2e47ebe79703298640\n'}, {'number': 3, 'created': '2014-06-16 10:18:05.000000000', 'files': ['specs/juno/environment-definition.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/fe0e25b62837578f7e6ed5b13b1a7a99d658fdad', 'message': 'WIP: Environment definition and use\n\nWhile working on I1b10abda0209f1c58c6c2612542d8a6cd42628e8 I came to\nunderstand that the rules for naming VMs inside a numbered environment\nwere labyrinthine and confusing. As a result, I created\n3a0d4315aa3e7d5281db827f01b681d7d8c3128d which simplifies the rules\nsomewhat.\n\nHowever, both changes had much discussion which I believe was caused\nby the fact that the behaviour in question was not specified anywhere\nbut had merely grown over time without deep consideration of how\nthings interacted.\n\nThis change is intended to codify (and perhaps simplify) existing\nbehaviour.\n\nChange-Id: I8720156b785263b54ad96d2e47ebe79703298640\n'}]",2,98314,fe0e25b62837578f7e6ed5b13b1a7a99d658fdad,14,4,3,9453,,,0,"WIP: Environment definition and use

While working on I1b10abda0209f1c58c6c2612542d8a6cd42628e8 I came to
understand that the rules for naming VMs inside a numbered environment
were labyrinthine and confusing. As a result, I created
3a0d4315aa3e7d5281db827f01b681d7d8c3128d which simplifies the rules
somewhat.

However, both changes had much discussion which I believe was caused
by the fact that the behaviour in question was not specified anywhere
but had merely grown over time without deep consideration of how
things interacted.

This change is intended to codify (and perhaps simplify) existing
behaviour.

Change-Id: I8720156b785263b54ad96d2e47ebe79703298640
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/14/98314/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/multiple-environment-support.rst'],1,209f92c4b08c60055c7240f6003811ee4f27b4b6,env-definition,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Multiple environment support ============================ https://blueprints.launchpad.net/tripleo/+spec/multiple-environment-support Several TripleO tools include support for multiple environments, but standards around eg naming of machines within environments have not been rigorously defined. This has led to the code which names these machines needing to recreate convoluted logic in several places - including odd details such as needing to know whether or not the environment was passed a specific physical bridge at the time it was created in order to be able to figure out which VM names would bee created. This spec aims to define:: * What information is required in order to create an environment * How that information is evaluated to name machines, bridges, and so on. Problem Description =================== A detailed description of the problem: * For a new feature this might be use cases. Ensure you are clear about the actors in each use case: End User vs Deployer * For a major reworking of something existing it would describe the problems in that feature that are being addressed. Proposed Change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? Alternatives ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Other End User Impact --------------------- Are there ways a user will interact with this feature? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A small change in a utility function or a commonly used decorator can have a large impacts on performance. Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in tripleo, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Tripleo (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Please discuss how the change will be tested. Is this untestable in CI given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs? Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,197,0
openstack%2Fgrenade~master~Ib7560bb4f19d4593b5958b1f94a462c09a23cee7,openstack/grenade,master,Ib7560bb4f19d4593b5958b1f94a462c09a23cee7,Remove call to inexistent unfubar_testtools function,MERGED,2014-12-10 17:24:43.000000000,2014-12-10 21:17:49.000000000,2014-12-10 21:17:49.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}]","[{'number': 1, 'created': '2014-12-10 17:24:43.000000000', 'files': ['upgrade-infra'], 'web_link': 'https://opendev.org/openstack/grenade/commit/40f30d3d51a5cd53d9c34b11adc598ba5675fe50', 'message': ""Remove call to inexistent unfubar_testtools function\n\nThe function was removed here I5554514dd862a2004454daf295abbcf9cf9f2bfb\nand since icehouse is not target in grenade job the call it's no longer needed\nhere we can remove it - wasn't causing any big issue besides a 'command\nnot found' but at least closes a bug.\n\nChange-Id: Ib7560bb4f19d4593b5958b1f94a462c09a23cee7\nCloses-bug: #1356178\n""}]",0,140776,40f30d3d51a5cd53d9c34b11adc598ba5675fe50,7,3,1,5174,,,0,"Remove call to inexistent unfubar_testtools function

The function was removed here I5554514dd862a2004454daf295abbcf9cf9f2bfb
and since icehouse is not target in grenade job the call it's no longer needed
here we can remove it - wasn't causing any big issue besides a 'command
not found' but at least closes a bug.

Change-Id: Ib7560bb4f19d4593b5958b1f94a462c09a23cee7
Closes-bug: #1356178
",git fetch https://review.opendev.org/openstack/grenade refs/changes/76/140776/1 && git format-patch -1 --stdout FETCH_HEAD,['upgrade-infra'],1,40f30d3d51a5cd53d9c34b11adc598ba5675fe50,bug/1356178,,unfubar_setuptools ,0,2
openstack%2Fheat~master~I4ad9c7ae54e3f04224b780ecb24d0827951d18da,openstack/heat,master,I4ad9c7ae54e3f04224b780ecb24d0827951d18da,Deprecate HARestarter resource type,MERGED,2014-09-16 12:22:51.000000000,2014-12-10 21:07:19.000000000,2014-12-10 21:07:18.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6460}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 8328}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-09-16 12:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1f85a8bb4e1f7da402e4d95bf89bc6ae541ac672', 'message': 'Deprecate HARestarter resource type\n\nTime to die.\n\nChange-Id: I4ad9c7ae54e3f04224b780ecb24d0827951d18da\n'}, {'number': 2, 'created': '2014-09-26 17:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a56ec55eb23903bebce3f6cbd8827613b2685609', 'message': ""Deprecate HARestarter resource type\n\nThis was basically a failed experiment in High Availability. Amongst other\nthings - for example it is perpetually causing users to misunderstand how\nit works - it relies on the paradigm of a resource just being a place to\nstick code that can then go and perform operations on the stack itself\nwhich are not defined in Heat's lifecycle model, rather than purely as a\nrepresentation of some real OpenStack resource. We later realised that this\nwas the cause of many of our worst headaches. It's one obstacle to moving\nto a convergence architecture - where resources will be isolated from one\nanother - that will actually provide a decent solution to the HA problem.\n\nHARestarter is an architectural dead-end, and we need to communicate that\nmuch more clearly to users along what it actually can and cannot do.\n\nChange-Id: I4ad9c7ae54e3f04224b780ecb24d0827951d18da\n""}, {'number': 3, 'created': '2014-11-14 16:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0ab04433a819625c2ab48ed543d9d3d49212225c', 'message': ""Deprecate HARestarter resource type\n\nThis was basically a failed experiment in High Availability. Amongst other\nthings - for example it is perpetually causing users to misunderstand how\nit works - it relies on the paradigm of a resource just being a place to\nstick code that can then go and perform operations on the stack itself\nwhich are not defined in Heat's lifecycle model, rather than purely as a\nrepresentation of some real OpenStack resource. We later realised that this\nwas the cause of many of our worst headaches. Convergence will be a far\nsuperior solution to the problems that HARestart was designed to solve.\n\nHARestarter is an architectural dead-end, and we need to communicate that\nmuch more clearly to users along what it actually can and cannot do.\n\nChange-Id: I4ad9c7ae54e3f04224b780ecb24d0827951d18da\n""}, {'number': 4, 'created': '2014-12-10 00:27:42.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/59456e34f0822ce3912cd22d34a72f4bcf4a62d2', 'message': ""Deprecate HARestarter resource type\n\nThis was basically a failed experiment in High Availability. Amongst other\nthings - for example it is perpetually causing users to misunderstand how\nit works - it relies on the paradigm of a resource just being a place to\nstick code that can then go and perform operations on the stack itself\nwhich are not defined in Heat's lifecycle model, rather than purely as a\nrepresentation of some real OpenStack resource. We later realised that this\nwas the cause of many of our worst headaches. Convergence will be a far\nsuperior solution to the problems that HARestart was designed to solve.\n\nHARestarter is an architectural dead-end, and we need to communicate that\nmuch more clearly to users along what it actually can and cannot do.\n\nChange-Id: I4ad9c7ae54e3f04224b780ecb24d0827951d18da\n""}]",8,121824,59456e34f0822ce3912cd22d34a72f4bcf4a62d2,54,15,4,4257,,,0,"Deprecate HARestarter resource type

This was basically a failed experiment in High Availability. Amongst other
things - for example it is perpetually causing users to misunderstand how
it works - it relies on the paradigm of a resource just being a place to
stick code that can then go and perform operations on the stack itself
which are not defined in Heat's lifecycle model, rather than purely as a
representation of some real OpenStack resource. We later realised that this
was the cause of many of our worst headaches. Convergence will be a far
superior solution to the problems that HARestart was designed to solve.

HARestarter is an architectural dead-end, and we need to communicate that
much more clearly to users along what it actually can and cannot do.

Change-Id: I4ad9c7ae54e3f04224b780ecb24d0827951d18da
",git fetch https://review.opendev.org/openstack/heat refs/changes/24/121824/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/instance.py'],1,1f85a8bb4e1f7da402e4d95bf89bc6ae541ac672,,"from heat.engine import support support_status = support.SupportStatus( support.DEPRECATED, _('The HARestarter resource type is deprecated and will be removed in ' 'a future release of Heat. Note that HARestarter does *not* ' 'actually restart servers - it deletes and then recreates them. It ' 'also does the same to all dependent resources, and may therefore ' 'exhibit unexpected and undesirable behaviour. Avoid at any cost.') ) ",,11,0
openstack%2Ftrove~master~I14b43966d4e7f047a5859bd4a463f2838f03b01f,openstack/trove,master,I14b43966d4e7f047a5859bd4a463f2838f03b01f,Fix trove resize-volume resize2fs error,MERGED,2014-12-09 21:51:05.000000000,2014-12-10 21:07:10.000000000,2014-12-10 21:07:09.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7634}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 10725}, {'_account_id': 11783}, {'_account_id': 13355}, {'_account_id': 14009}]","[{'number': 1, 'created': '2014-12-09 21:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0bd4c35ef6aeb2e9360c5901cf0e01b5736ffea8', 'message': 'Fix trove resize-volume resize2fs error\n\ntrove resize-volume works by calling the e2fsck and resize2fs commands.\nWhen resize2fs detect errors in the volume, it will abort with an\nerror: ""Please run \'e2fsck -f /dev/vdb\' first"".\n\nThe e2fsck command is currently called with the -n flag, meaning not to fix\nany volume errors, which cause the subsequent resize2fs command to fail.\nAs a result, the trove instance being resized remain stuck in the\nRESIZE status.\n\nThis patch reverts the e2fsck -n flag back to the -p flag, which enables\nauto correction of volume errors, thus allowing resize2fs to complete\nthe resize-volume operation.\n\nChange-Id: I14b43966d4e7f047a5859bd4a463f2838f03b01f\nCloses-Bug: #1391639\n'}, {'number': 2, 'created': '2014-12-09 21:59:15.000000000', 'files': ['trove/guestagent/volume.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/a13112599dd20e890d8d70babb0015052796aa09', 'message': 'Fix trove resize-volume resize2fs error\n\ntrove resize-volume works by calling the e2fsck and resize2fs\ncommands. When resize2fs detect errors in the volume, it will\nabort with an error: ""Please run \'e2fsck -f /dev/vdb\' first"".\n\nThe e2fsck command is currently called with the -n flag, meaning\nnot to fix any volume errors, which cause the subsequent resize2fs\ncommand to fail. As a result, the trove instance being resized\nremain stuck in the RESIZE status.\n\nThis patch reverts the e2fsck -n flag back to the -p flag, which\nenables auto correction of volume errors, thus allowing resize2fs\nto complete the resize-volume operation.\n\nChange-Id: I14b43966d4e7f047a5859bd4a463f2838f03b01f\nCloses-Bug: #1391639\n'}]",0,140488,a13112599dd20e890d8d70babb0015052796aa09,15,9,2,10266,,,0,"Fix trove resize-volume resize2fs error

trove resize-volume works by calling the e2fsck and resize2fs
commands. When resize2fs detect errors in the volume, it will
abort with an error: ""Please run 'e2fsck -f /dev/vdb' first"".

The e2fsck command is currently called with the -n flag, meaning
not to fix any volume errors, which cause the subsequent resize2fs
command to fail. As a result, the trove instance being resized
remain stuck in the RESIZE status.

This patch reverts the e2fsck -n flag back to the -p flag, which
enables auto correction of volume errors, thus allowing resize2fs
to complete the resize-volume operation.

Change-Id: I14b43966d4e7f047a5859bd4a463f2838f03b01f
Closes-Bug: #1391639
",git fetch https://review.opendev.org/openstack/trove refs/changes/88/140488/2 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/volume.py'],1,0bd4c35ef6aeb2e9360c5901cf0e01b5736ffea8,bug/1391639," utils.execute(""e2fsck"", ""-f"", ""-p"", self.device_path,"," utils.execute(""e2fsck"", ""-f"", ""-n"", self.device_path,",1,1
openstack%2Fpython-troveclient~master~I250777890a1f5240c5f14290cf02eb5a7b34b434,openstack/python-troveclient,master,I250777890a1f5240c5f14290cf02eb5a7b34b434,Remove RAX-specific auth in troveclient,MERGED,2014-01-25 02:57:24.000000000,2014-12-10 21:07:03.000000000,2014-12-10 21:07:02.000000000,"[{'_account_id': 3}, {'_account_id': 739}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 6162}, {'_account_id': 6268}, {'_account_id': 7051}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-01-25 02:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/205f8aeeacbe81b658100e4ff8b9b0014c2660e1', 'message': 'Remove RAX-specific auth in troveclient\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 2, 'created': '2014-03-22 04:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/be04c3c7bc812edb67ab8e7641f64b7ee33aa3e7', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 3, 'created': '2014-03-22 04:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/bdf61bd077b8fe252451821f9c316bd59556d379', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 4, 'created': '2014-03-22 04:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/7b47b90711e7fed93648a217a92d08dc719a75be', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 5, 'created': '2014-03-23 03:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d9af9145e418dff75544edf514110d86a40bc363', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 6, 'created': '2014-04-22 03:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/ee91938aa6835e28ab20d766cb258e831cebe1b0', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 7, 'created': '2014-04-22 15:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/db372070bacea5013b21ac386ced5b16a08310bd', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 8, 'created': '2014-05-30 09:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/f457803fcf0686e89dd8b535cd524fbbdaba8960', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 9, 'created': '2014-06-10 08:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/e34b46bdf2295fde2e73037912dd5508bf685c41', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 10, 'created': '2014-06-10 23:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/010c3deb8c38ef30714a0562f5487898f37a2605', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 11, 'created': '2014-10-30 21:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/512ee2488a8a350f4c99e2480ebf5790a79a7c79', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 12, 'created': '2014-11-13 21:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/c47911d184a7c57c04ca424b259e6b6adfdea329', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 13, 'created': '2014-12-05 22:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/284c66e668b39570ce63aea1828b640dff0981d8', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 14, 'created': '2014-12-05 22:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/252d52aba1f91f3d47520fd608fc8b307176392e', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}, {'number': 15, 'created': '2014-12-09 19:34:11.000000000', 'files': ['troveclient/client.py', 'troveclient/tests/test_shell.py', 'troveclient/shell.py', 'troveclient/auth_plugin.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/cd58da52134069f94e7efb82685882d5d3aa122f', 'message': 'Remove RAX-specific auth in troveclient\n\nAuthor: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>\nCo-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>\nCo-Authored-By: Craig Vyvial <cp16net@gmail.com>\n\nChange-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434\nCloses-Bug: #966329\n'}]",3,69081,cd58da52134069f94e7efb82685882d5d3aa122f,102,12,15,7051,,,0,"Remove RAX-specific auth in troveclient

Author: Swapnil Kulkarni <swapnilkulkarni2608@gmail.com>
Co-Authored-By: Nikhil Manchanda <SlickNik@gmail.com>
Co-Authored-By: Craig Vyvial <cp16net@gmail.com>

Change-Id: I250777890a1f5240c5f14290cf02eb5a7b34b434
Closes-Bug: #966329
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/81/69081/4 && git format-patch -1 --stdout FETCH_HEAD,['troveclient/client.py'],1,205f8aeeacbe81b658100e4ff8b9b0014c2660e1,bug/966329, auth_url = self._v2_auth(auth_url),"import os if ""TROVE_RAX_AUTH"" in os.environ: auth_url = self._rax_auth(auth_url) else: auth_url = self._v2_auth(auth_url) def _rax_auth(self, url): """"""Authenticate against the Rackspace auth service."""""" body = {""auth"": { ""RAX-KSKEY:apiKeyCredentials"": { ""username"": self.user, ""apiKey"": self.password, ""tenantName"": self.projectid}}} self._authenticate(url, body) ",1,15
openstack%2Frally~master~Id5d404a4e17e1e50cd0b6783384b864c81015713,openstack/rally,master,Id5d404a4e17e1e50cd0b6783384b864c81015713,Fix the world (heat role was remove from devstack),MERGED,2014-12-10 19:07:11.000000000,2014-12-10 20:56:35.000000000,2014-12-10 20:56:34.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6589}]","[{'number': 1, 'created': '2014-12-10 19:07:11.000000000', 'files': ['rally/benchmark/scenarios/heat/stacks.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8e50821fe32b936437960c4f13008369dd014d2e', 'message': 'Fix the world (heat role was remove from devstack)\n\nThis patch removes ""roles"" context from heat scenarios\ncause they are not used now\n\nChange-Id: Id5d404a4e17e1e50cd0b6783384b864c81015713\n'}]",0,140810,8e50821fe32b936437960c4f13008369dd014d2e,7,3,1,6172,,,0,"Fix the world (heat role was remove from devstack)

This patch removes ""roles"" context from heat scenarios
cause they are not used now

Change-Id: Id5d404a4e17e1e50cd0b6783384b864c81015713
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/140810/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/scenarios/heat/stacks.py'],1,8e50821fe32b936437960c4f13008369dd014d2e,fix_world," @base.scenario(context={""cleanup"": [""heat""]}) @base.scenario(context={""cleanup"": [""heat""]})"," @base.scenario(context={""cleanup"": [""heat""], ""roles"": [""heat_stack_owner""]}) @base.scenario(context={""cleanup"": [""heat""], ""roles"": [""heat_stack_owner""]})",2,4
openstack%2Fmonasca-api~master~I59cd53f934237a76545975361c2d41415e17fa05,openstack/monasca-api,master,I59cd53f934237a76545975361c2d41415e17fa05,implementation specific requirement files,MERGED,2014-12-09 14:15:14.000000000,2014-12-10 20:56:29.000000000,2014-12-10 20:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 2419}]","[{'number': 1, 'created': '2014-12-09 14:15:14.000000000', 'files': ['requirements.txt', 'ref-impl-requirements.txt', 'es-impl-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/89383b08be5fe6de12228a3361564f225dfc6cad', 'message': ""implementation specific requirement files\n\ncurrent requirements.txt file lists all the dependency files\nwhich will install libraries which are not needed if one choose\nto use a different implementation. For example, one can use\nv2 reference implementation or elastic search implementation.\nnot having separate files, one will install many libraries.\nFor elastic search implementation, one will not wish to install\ninfluxdb dependencies. But without separate requirement files,\nit won't be possible to do that. With this change, one can\nsimply use implementation specific requirement file to\naccomplish that. To install v2 reference implementation, simply\nrun this command:\n   pip install -r requirements.txt -r ref-impl-requirements.txt\n\nTo install elastic search implementation, simply run this command:\n   pip install -r requirements.txt -r es-impl-requirements.txt\n\nChange-Id: I59cd53f934237a76545975361c2d41415e17fa05\n""}]",0,140338,89383b08be5fe6de12228a3361564f225dfc6cad,6,2,1,2860,,,0,"implementation specific requirement files

current requirements.txt file lists all the dependency files
which will install libraries which are not needed if one choose
to use a different implementation. For example, one can use
v2 reference implementation or elastic search implementation.
not having separate files, one will install many libraries.
For elastic search implementation, one will not wish to install
influxdb dependencies. But without separate requirement files,
it won't be possible to do that. With this change, one can
simply use implementation specific requirement file to
accomplish that. To install v2 reference implementation, simply
run this command:
   pip install -r requirements.txt -r ref-impl-requirements.txt

To install elastic search implementation, simply run this command:
   pip install -r requirements.txt -r es-impl-requirements.txt

Change-Id: I59cd53f934237a76545975361c2d41415e17fa05
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/38/140338/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'ref-impl-requirements.txt', 'es-impl-requirements.txt']",3,89383b08be5fe6de12228a3361564f225dfc6cad,,"# The order of packages is significant, because pip processes them in the order # of appearance. Changing the order has an impact on the overall integration # process, please pay attention to order them correctly. # # This is the dependency file for elasticsearch implementation which based on # elasticsearch, all elasticsearch related dependencies should be listed here. requests>=1.1 ",,42,4
openstack%2Fproject-config~master~I50aec2be3ae7c2d0ec552eb9aac0ad2828f61dab,openstack/project-config,master,I50aec2be3ae7c2d0ec552eb9aac0ad2828f61dab,"Revert ""Use more strict regex for sahara tags acl""",MERGED,2014-12-10 20:25:02.000000000,2014-12-10 20:49:16.000000000,2014-12-10 20:49:15.000000000,"[{'_account_id': 3}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-10 20:25:02.000000000', 'files': ['gerrit/acls/openstack/sahara.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/07453ae7a880632fcbbbf725ee404e67a74095fe', 'message': 'Revert ""Use more strict regex for sahara tags acl""\n\nThis reverts commit be96ca4214a58ad8fc23fdaf4da0874976dd4985.\n\nEmbedding square brackets in a Gerrit ACL section heading is\nsyntactically invalid.\n\nChange-Id: I50aec2be3ae7c2d0ec552eb9aac0ad2828f61dab\n'}]",0,140831,07453ae7a880632fcbbbf725ee404e67a74095fe,6,2,1,5263,,,0,"Revert ""Use more strict regex for sahara tags acl""

This reverts commit be96ca4214a58ad8fc23fdaf4da0874976dd4985.

Embedding square brackets in a Gerrit ACL section heading is
syntactically invalid.

Change-Id: I50aec2be3ae7c2d0ec552eb9aac0ad2828f61dab
",git fetch https://review.opendev.org/openstack/project-config refs/changes/31/140831/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/sahara.config'],1,07453ae7a880632fcbbbf725ee404e67a74095fe,sahara-acl,"[access ""^refs/tags/2014.1.*""]","[access ""^refs/tags/2014\.1\.[0-9]+[.0-9]*""]",1,1
openstack%2Fmonasca-notification~master~I2e545153aae114b9d0fa86f7202a8cac35e3120d,openstack/monasca-notification,master,I2e545153aae114b9d0fa86f7202a8cac35e3120d,Added test coverage for email and webhook notification,MERGED,2014-12-10 00:08:57.000000000,2014-12-10 20:39:05.000000000,2014-12-10 20:39:04.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 11094}]","[{'number': 1, 'created': '2014-12-10 00:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/1aca3c3d1173391a6bf11b94c87efcd891afd93f', 'message': 'Added test coverage for email and webhook notification.\n\nFixed expression in exception trap\n\nChange-Id: I2e545153aae114b9d0fa86f7202a8cac35e3120d\n'}, {'number': 2, 'created': '2014-12-10 17:22:35.000000000', 'files': ['monasca_notification/processors/notification_processor.py', 'tests/test_notification_processor.py'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/a2271ba7c82d40ee2b00d72b3b1df7fe57841d3c', 'message': 'Added test coverage for email and webhook notification\n\nFixed expression in exception trap\n\nChange-Id: I2e545153aae114b9d0fa86f7202a8cac35e3120d\n'}]",0,140533,a2271ba7c82d40ee2b00d72b3b1df7fe57841d3c,9,3,2,14273,,,0,"Added test coverage for email and webhook notification

Fixed expression in exception trap

Change-Id: I2e545153aae114b9d0fa86f7202a8cac35e3120d
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/33/140533/2 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_notification/processors/notification_processor.py', 'tests/test_notification_processor.py']",2,1aca3c3d1173391a6bf11b94c87efcd891afd93f,,"class smtpStub(object): def __init__(self, log_queue): self.queue = log_queue def sendmail(self, from_addr, to_addr, msg): self.queue.put(""%s %s %s"" % (from_addr, to_addr, msg)) class requestsResponse(object): def __init__(self, status): self.status_code = status self.http_func = self._http_post_200 @mock.patch('monasca_notification.processors.notification_processor.requests') def _start_processor(self, mock_log, mock_smtp, mock_requests): mock_requests.post = self.http_func mock_smtp.SMTP = self._smtpStub self.mock_requests = mock_requests def _smtpStub(self, *arg, **kwargs): return smtpStub(self.log_queue) def _http_post_200(self, url, data, headers): self.log_queue.put(""%s %s %s"" % (url, data, headers)) r = requestsResponse(200) return r def _http_post_404(self, url, data, headers): r = requestsResponse(404) return r def _http_post_exception(self, url, data, headers): # generate error foobar def test_email_notification_single_host(self): """"""Email with single host """""" metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('email', 0, 1, 'email notification', 'me@here.com', alarm_dict) self.notification_queue.put([notification]) self._start_processor() log_msg = self.log_queue.get(timeout=3) self.processor.terminate() self.assertRegexpMatches(log_msg, ""From: hpcs.mon@hp.com"") self.assertRegexpMatches(log_msg, ""To: me@here.com"") self.assertRegexpMatches(log_msg, ""Content-Type: text/plain"") self.assertRegexpMatches(log_msg, ""Alarm .test Alarm."") self.assertRegexpMatches(log_msg, ""On host .foo1."") self.assertTrue(self.log_queue.empty()) def test_email_notification_multiple_hosts(self): """"""Email with multiple hosts """""" metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('email', 0, 1, 'email notification', 'me@here.com', alarm_dict) self.notification_queue.put([notification]) self._start_processor() log_msg = self.log_queue.get(timeout=3) self.processor.terminate() self.assertRegexpMatches(log_msg, ""From: hpcs.mon@hp.com"") self.assertRegexpMatches(log_msg, ""To: me@here.com"") self.assertRegexpMatches(log_msg, ""Content-Type: text/plain"") self.assertRegexpMatches(log_msg, ""Alarm .test Alarm."") self.assertNotRegexpMatches(log_msg, ""foo1"") self.assertNotRegexpMatches(log_msg, ""foo2"") self.assertTrue(self.log_queue.empty()) def test_webhook_good_http_response(self): """"""webhook """""" self.http_func = self._http_post_200 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('webhook', 0, 1, 'email notification', 'me@here.com', alarm_dict) self.notification_queue.put([notification]) self._start_processor() log_msg = self.log_queue.get(timeout=3) self.processor.terminate() self.assertRegexpMatches(log_msg, ""me@here.com"") self.assertRegexpMatches(log_msg, ""alarm_id.: .test Alarm"") self.assertRegexpMatches(log_msg, ""content-type.: .application/json"") self.assertTrue(self.log_queue.empty()) def test_webhook_bad_http_response(self): """"""webhook """""" self.http_func = self._http_post_404 metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('webhook', 0, 1, 'email notification', 'me@here.com', alarm_dict) self.notification_queue.put([notification]) self._start_processor() log_msg = self.log_queue.get(timeout=3) self.processor.terminate() self.assertNotRegexpMatches(log_msg, ""alarm_id.: .test Alarm"") self.assertNotRegexpMatches(log_msg, ""content-type.: .application/json"") self.assertRegexpMatches(log_msg, ""HTTP code 404"") self.assertRegexpMatches(log_msg, ""post on URL me@here.com"") self.assertTrue(self.log_queue.empty()) def test_webhook_exception_on_http_response(self): """"""webhook """""" self.http_func = self._http_post_exception metrics = [] metric_data = {'dimensions': {'hostname': 'foo1', 'service': 'bar1'}} metrics.append(metric_data) metric_data = {'dimensions': {'hostname': 'foo2', 'service': 'bar2'}} metrics.append(metric_data) alarm_dict = {""tenantId"": ""0"", ""alarmId"": ""0"", ""alarmName"": ""test Alarm"", ""oldState"": ""OK"", ""newState"": ""ALARM"", ""stateChangeReason"": ""I am alarming!"", ""timestamp"": time.time(), ""metrics"": metrics} notification = Notification('webhook', 0, 1, 'email notification', 'me@here.com', alarm_dict) self.notification_queue.put([notification]) self._start_processor() log_msg = self.log_queue.get(timeout=3) self.processor.terminate() self.assertNotRegexpMatches(log_msg, ""alarm_id.: .test Alarm"") self.assertNotRegexpMatches(log_msg, ""content-type.: .application/json"") self.assertRegexpMatches(log_msg, ""Error trying to post on URL me@here.com"") self.assertTrue(self.log_queue.empty())"," def _start_processor(self, mock_log, mock_smtp):",211,2
openstack%2Fmurano~master~I073dcf42729297b954407a1ef3938f315d301856,openstack/murano,master,I073dcf42729297b954407a1ef3938f315d301856,Fix logging message,ABANDONED,2014-12-10 18:47:37.000000000,2014-12-10 20:36:27.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8127}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-12-10 18:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f95f5d4fe4a716a27d77013af6502094b783f4a1', 'message': 'Fix logging message\n\nChange-Id: I073dcf42729297b954407a1ef3938f315d301856\nCloses-bug: #1401214\n'}, {'number': 2, 'created': '2014-12-10 18:52:19.000000000', 'files': ['murano/common/engine.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/8956049202a0f8ce7329b6ea7455963c34994dc5', 'message': 'Fix logging message\n\nChange-Id: I073dcf42729297b954407a1ef3938f315d301856\nCloses-bug: #1401214\n'}]",2,140804,8956049202a0f8ce7329b6ea7455963c34994dc5,9,10,2,7225,,,0,"Fix logging message

Change-Id: I073dcf42729297b954407a1ef3938f315d301856
Closes-bug: #1401214
",git fetch https://review.opendev.org/openstack/murano refs/changes/04/140804/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/common/engine.py'],1,f95f5d4fe4a716a27d77013af6502094b783f4a1,bug/1401214, LOG.info('Starting processing task: {task_desc}').format( task_desc=anyjson.dumps(s_task)), LOG.info(_('Starting processing task: {task_desc}').format( task_desc=anyjson.dumps(s_task))),2,2
openstack%2Fgrenade~master~I4d1ec41bac5a05241069963d1bcd2df4070f5ea2,openstack/grenade,master,I4d1ec41bac5a05241069963d1bcd2df4070f5ea2,Remove use of GRENADE_PHASE,MERGED,2014-11-19 01:46:20.000000000,2014-12-10 20:32:09.000000000,2014-12-10 20:32:08.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-11-19 01:46:20.000000000', 'files': ['devstack.localrc.base', 'README.rst', 'devstack.localrc.target'], 'web_link': 'https://opendev.org/openstack/grenade/commit/b7ae1b46602e34d53b5489ba9e0a7cb73d6ea418', 'message': 'Remove use of GRENADE_PHASE\n\nRecently, devstack-gate accidentally stopped setting these values and\nthere appeared to be no fallout.  Looking closer, they appear to be\nno longer used by Grenade.  This removes them from sample localrcs\nand docs.\n\nChange-Id: I4d1ec41bac5a05241069963d1bcd2df4070f5ea2\n'}]",0,135479,b7ae1b46602e34d53b5489ba9e0a7cb73d6ea418,10,5,1,1420,,,0,"Remove use of GRENADE_PHASE

Recently, devstack-gate accidentally stopped setting these values and
there appeared to be no fallout.  Looking closer, they appear to be
no longer used by Grenade.  This removes them from sample localrcs
and docs.

Change-Id: I4d1ec41bac5a05241069963d1bcd2df4070f5ea2
",git fetch https://review.opendev.org/openstack/grenade refs/changes/79/135479/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack.localrc.base', 'README.rst', 'devstack.localrc.target']",3,b7ae1b46602e34d53b5489ba9e0a7cb73d6ea418,phase_out_phase,,GRENADE_PHASE=target,0,13
openstack%2Fnova~master~Ia584dba66affb86787e3069df19bd17b89cb5c49,openstack/nova,master,Ia584dba66affb86787e3069df19bd17b89cb5c49,Compute: Catch binding failed exception while init host,MERGED,2014-10-17 08:06:39.000000000,2014-12-10 20:30:27.000000000,2014-12-10 20:30:24.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 1653}, {'_account_id': 1678}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2835}, {'_account_id': 4468}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 8247}, {'_account_id': 8430}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-10-17 08:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf54c5fd3c95b3b0f7e25849dd15a0e305859cd1', 'message': 'Compute: Catch exception while init instance\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance,\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nSo we need to handle all exceptions while init\ninstances to solve this problem.\nAlso some unnecessary try-except after this change\nis removed in this commit.\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\nCloses-bug: #1324041\n'}, {'number': 2, 'created': '2014-10-17 10:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a01d71ad1f0597eabf07b259a2a79dc184e57335', 'message': 'Compute: Catch exception while init instance\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance,\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nSo we need to handle all exceptions while init\ninstances to solve this problem.\nAlso some unnecessary try-except after this change\nis removed in this commit.\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\nCloses-bug: #1324041\n'}, {'number': 3, 'created': '2014-10-20 06:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f29425cbc03d5a5ada4358de4892665283a19be', 'message': 'Compute: Catch exception while init instance\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance,\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nSo we need to handle all exceptions while init\ninstances to solve this problem.\nAlso some unnecessary try-except after this change\nis removed in this commit.\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\nCloses-bug: #1324041\n'}, {'number': 4, 'created': '2014-10-20 08:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/850ed7e8e7dc61d08b54d3606e804761fd037dfa', 'message': 'Compute: Catch exception while init instance\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance,\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nSo we need to handle all exceptions while init\ninstances to solve this problem.\nAlso some unnecessary try-except after this change\nis removed in this commit.\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\nCloses-bug: #1324041\n'}, {'number': 5, 'created': '2014-10-21 01:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d2aca2dfdacf8e1af20d7dcfcd706557793ff4c', 'message': 'Compute: Catch exception while init instance\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance,\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nSo we need to handle all exceptions while init\ninstances to solve this problem.\nAlso some unnecessary try-except after this change\nis removed in this commit.\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\nCloses-bug: #1324041\n'}, {'number': 6, 'created': '2014-10-21 08:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7d377774573118c2d6a7ca296e8b7f03f131ca5', 'message': 'Compute: Catch exception while init instance\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance,\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nSo we need to handle all exceptions while init\ninstances to solve this problem.\nAlso some unnecessary try-except after this change\nis removed in this commit.\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\nCloses-bug: #1324041\n'}, {'number': 7, 'created': '2014-10-22 02:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/781ebf25ec2937cb6bc76b92b843bef8bff65ddd', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs),\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nThe commit catches the NovaException during\nplug_vifs and set instance to error state,\nthen the compute process can be started normally\neven if this exception is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 8, 'created': '2014-10-23 07:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7149e61ed314b7175041ddc0367d517c3becda36', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs),\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nThe commit catches the NovaException during\nplug_vifs and set instance to error state,\nthen the compute process can be started normally\neven if this exception is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 9, 'created': '2014-10-23 07:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6db395fac6a44606d3e15b9d831b94e3729de9d', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs),\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nThe commit catches the NovaException during\nplug_vifs and set instance to error state,\nthen the compute process can be started normally\neven if this exception is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 10, 'created': '2014-10-24 01:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15340af34e81fecde1371ac12197ff0c05907b38', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs),\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nThe commit catches the NovaException during\nplug_vifs and set instance to error state,\nthen the compute process can be started normally\neven if this exception is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 11, 'created': '2014-10-27 07:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcf756c4e3d0e61f6fa038828179ade335f958a1', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs),\nthen the compute process exits unexpectedly\nbecause of this unhandled exception.\nThe commit catches the NovaException during\nplug_vifs and set instance to error state,\nthen the compute process can be started normally\neven if this exception is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 12, 'created': '2014-10-30 02:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd7030d63b107491540a418415f64104d6486665', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\n\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 13, 'created': '2014-10-30 02:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5abb68c5c794886b3b3a918cc5a44f9837a30be9', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\n\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 14, 'created': '2014-10-30 05:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ec3b071b013b3a45abbaf698622fa285a5fa803', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\n\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 15, 'created': '2014-11-13 05:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/474bbb51def648afea0d390a247be34bf762e882', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\n\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 16, 'created': '2014-12-01 05:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0c93cc8d832017a508c7d81818db3e43831d2e4', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\n\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 17, 'created': '2014-12-02 01:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80e61e5f4eeb270523697ad1d6f9a04454e39590', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\n\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 18, 'created': '2014-12-02 06:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9f8ff61ed59d4b0c9f4a511e85ed616a4b82b3d', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}, {'number': 19, 'created': '2014-12-04 01:31:55.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/ironic/driver.py', 'nova/exception.py', 'nova/virt/libvirt/vif.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/16ac50b1e760b7d20b840763b271a497b66ad5a5', 'message': 'Compute: Catch binding failed exception while init host\n\nWhile compute starts it will init all instances,\nif an exception is raised from one instance\n(e.g NovaException during plug_vifs), then the\ncompute process exits unexpectedly because of\nthis unhandled exception.\nThis commit changes the NovaException to more\nappropriate VirtualInterfacePlugException and\ncatches it during init host, as well as the\ninstance is set to error state, with this change\nthe compute process can be started normally even\nif this VirtualInterfacePlugException is raised.\n\nCloses-bug: #1324041\n\nChange-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49\n'}]",21,129158,16ac50b1e760b7d20b840763b271a497b66ad5a5,153,21,19,4468,,,0,"Compute: Catch binding failed exception while init host

While compute starts it will init all instances,
if an exception is raised from one instance
(e.g NovaException during plug_vifs), then the
compute process exits unexpectedly because of
this unhandled exception.
This commit changes the NovaException to more
appropriate VirtualInterfacePlugException and
catches it during init host, as well as the
instance is set to error state, with this change
the compute process can be started normally even
if this VirtualInterfacePlugException is raised.

Closes-bug: #1324041

Change-Id: Ia584dba66affb86787e3069df19bd17b89cb5c49
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/129158/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,cf54c5fd3c95b3b0f7e25849dd15a0e305859cd1,bug/1324041," LOG.debug(""Complete a partial deleted instance"", instance=instance) self._complete_partial_deletion(context, instance) self._post_interrupted_snapshot_cleanup(context, instance) LOG.info(_('Service started deleting the instance during ' 'the previous run, but did not finish. Restarting ' 'the deletion now.'), instance=instance) instance.obj_load_attr('metadata') instance.obj_load_attr('system_metadata') bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( context, instance.uuid) # FIXME(comstud): This needs fixed. We should be creating # reservations and updating quotas, because quotas # wouldn't have been updated for this instance since it is # still in DELETING. See bug 1296414. # # Create a dummy quota object for now. quotas = objects.Quotas.from_reservations( context, None, instance=instance) self._delete_instance(context, instance, bdms, quotas) LOG.debug(""Instance in transitional state %s at start-up "" ""retrying stop request"", instance['task_state'], instance=instance) self.stop_instance(context, instance) LOG.debug(""Instance in transitional state %s at start-up "" ""retrying start request"", instance['task_state'], instance=instance) self.start_instance(context, instance) LOG.info(_('Instance found in resize migrating state during ' LOG.debug(_('Instance found in migrating state during startup. ' 'Resetting task_state'), instance=instance) except Exception as ex: self._set_instance_error_state(context, instance) LOG.error(_(""Init instance failed, %s"") % ex, instance=instance)"," try: self._complete_partial_deletion(context, instance) except Exception: # we don't want that an exception blocks the init_host msg = _LE('Failed to complete a deletion') LOG.exception(msg, instance=instance) return try: self._post_interrupted_snapshot_cleanup(context, instance) except Exception: # we don't want that an exception blocks the init_host msg = _LE('Failed to cleanup snapshot.') LOG.exception(msg, instance=instance) try: LOG.info(_('Service started deleting the instance during ' 'the previous run, but did not finish. Restarting ' 'the deletion now.'), instance=instance) instance.obj_load_attr('metadata') instance.obj_load_attr('system_metadata') bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( context, instance.uuid) # FIXME(comstud): This needs fixed. We should be creating # reservations and updating quotas, because quotas # wouldn't have been updated for this instance since it is # still in DELETING. See bug 1296414. # # Create a dummy quota object for now. quotas = objects.Quotas.from_reservations( context, None, instance=instance) self._delete_instance(context, instance, bdms, quotas) except Exception: # we don't want that an exception blocks the init_host msg = _LE('Failed to complete a deletion') LOG.exception(msg, instance=instance) self._set_instance_error_state(context, instance) return try: LOG.debug(""Instance in transitional state %s at start-up "" ""retrying stop request"", instance['task_state'], instance=instance) self.stop_instance(context, instance) except Exception: # we don't want that an exception blocks the init_host msg = _LE('Failed to stop instance') LOG.exception(msg, instance=instance) return try: LOG.debug(""Instance in transitional state %s at start-up "" ""retrying start request"", instance['task_state'], instance=instance) self.start_instance(context, instance) except Exception: # we don't want that an exception blocks the init_host msg = _LE('Failed to start instance') LOG.exception(msg, instance=instance) return LOG.info(_('Instance found in migrating state during ' except Exception: # NOTE(vish): The instance failed to resume, so we set the # instance to error and attempt to continue. LOG.warning(_('Failed to resume instance'), instance=instance) self._set_instance_error_state(context, instance)",35,62
openstack%2Fnova~master~I49511f608291b66642ced00a3c13833e18fab3d7,openstack/nova,master,I49511f608291b66642ced00a3c13833e18fab3d7,Don't modify columns_to_join formal parameter in _manual_join_columns,MERGED,2014-11-18 04:14:04.000000000,2014-12-10 20:29:58.000000000,2014-12-10 20:29:55.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-18 04:14:04.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c8b4882cf1d32a0a668fe4e8d1476b1956223d4f', 'message': ""Don't modify columns_to_join formal parameter in _manual_join_columns\n\nThe _manual_join_columns method was modifying the columns_to_join list\npassed to it which, if not copied by the original caller, can introduce\nbugs in the calling code if the original columns_to_join list is re-used\nlater, e.g. making nova objects with an expected_attrs list that has\nbeen mutated by the DB API call.\n\nThis change makes a copy of the original list and passes back the new\nlist for the DB API methods to use, and adds some documentation to\nhopefully clarify intent and usage.\n\nA test is added to demonstrate the expected behavior of the utility\nmethod.\n\nCloses-Bug: #1393491\n\nChange-Id: I49511f608291b66642ced00a3c13833e18fab3d7\n""}]",0,135160,c8b4882cf1d32a0a668fe4e8d1476b1956223d4f,16,9,1,6873,,,0,"Don't modify columns_to_join formal parameter in _manual_join_columns

The _manual_join_columns method was modifying the columns_to_join list
passed to it which, if not copied by the original caller, can introduce
bugs in the calling code if the original columns_to_join list is re-used
later, e.g. making nova objects with an expected_attrs list that has
been mutated by the DB API call.

This change makes a copy of the original list and passes back the new
list for the DB API methods to use, and adds some documentation to
hopefully clarify intent and usage.

A test is added to demonstrate the expected behavior of the utility
method.

Closes-Bug: #1393491

Change-Id: I49511f608291b66642ced00a3c13833e18fab3d7
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/135160/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,c8b4882cf1d32a0a668fe4e8d1476b1956223d4f,bug/1393491," """"""Separate manually joined columns from columns_to_join If columns_to_join contains 'metadata', 'system_metadata', or 'pci_devices' those columns are removed from columns_to_join and added to a manual_joins list to be used with the _instances_fill_metadata method. The columns_to_join formal parameter is copied and not modified, the return tuple has the modified columns_to_join list to be used with joinedload in a model query. :param:columns_to_join: List of columns to join in a model query. :return: tuple of (manual_joins, columns_to_join) """""" columns_to_join_new = copy.copy(columns_to_join) for column in ('metadata', 'system_metadata', 'pci_devices'): if column in columns_to_join_new: columns_to_join_new.remove(column) return manual_joins, columns_to_join_new columns_to_join_new = ['info_cache', 'security_groups'] manual_joins, columns_to_join_new = ( _manual_join_columns(columns_to_join)) for column in columns_to_join_new: columns_to_join_new = ['info_cache', 'security_groups'] manual_joins, columns_to_join_new = ( _manual_join_columns(columns_to_join)) for column in columns_to_join_new: columns_to_join_new = ['info_cache', 'security_groups'] manual_joins, columns_to_join_new = ( _manual_join_columns(columns_to_join)) for column in columns_to_join_new:"," for column in ('metadata', 'system_metadata', 'pci_devices'): if column in columns_to_join: columns_to_join.remove(column) return manual_joins, columns_to_join columns_to_join = ['info_cache', 'security_groups'] manual_joins, columns_to_join = _manual_join_columns(columns_to_join) for column in columns_to_join: columns_to_join = ['info_cache', 'security_groups'] manual_joins, columns_to_join = _manual_join_columns(columns_to_join) for column in columns_to_join: columns_to_join = ['info_cache', 'security_groups'] manual_joins, columns_to_join = _manual_join_columns(columns_to_join) for column in columns_to_join:",42,12
openstack%2Fheat~master~Ie8239823b448cc95fdcce3afe27523cb960863d6,openstack/heat,master,Ie8239823b448cc95fdcce3afe27523cb960863d6,Remove Python 2.6 classifier,MERGED,2014-11-25 15:57:12.000000000,2014-12-10 20:29:44.000000000,2014-12-10 20:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2874}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 11600}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-25 15:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aba42c4f2173f5cf85b593dd55eb709d648fe4a2', 'message': 'Remove Python 2.6 classifier\n\nHeat does not support Python 2.6 anymore starting with Kilo and might\nnot work correctly with it, so remove the classifier.\n\nChange-Id: Ie8239823b448cc95fdcce3afe27523cb960863d6\n'}, {'number': 2, 'created': '2014-11-25 16:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/46c151abad47e6827ffe3757c339e8bea426bfb3', 'message': 'Remove Python 2.6 classifier\n\nHeat does not support Python 2.6 anymore starting with Kilo and might\nnot work correctly with it, so remove the classifier.\n\nChange-Id: Ie8239823b448cc95fdcce3afe27523cb960863d6\n'}, {'number': 3, 'created': '2014-11-25 16:02:08.000000000', 'files': ['heat/tests/testing-overview.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/e0f773ee5e4adfc66e6651f2de5824caa43a163f', 'message': 'Remove Python 2.6 classifier\n\nHeat does not support Python 2.6 anymore starting with Kilo and might\nnot work correctly with it, so remove the classifier.\n\nChange-Id: Ie8239823b448cc95fdcce3afe27523cb960863d6\n'}]",2,137115,e0f773ee5e4adfc66e6651f2de5824caa43a163f,20,12,3,1669,,,0,"Remove Python 2.6 classifier

Heat does not support Python 2.6 anymore starting with Kilo and might
not work correctly with it, so remove the classifier.

Change-Id: Ie8239823b448cc95fdcce3afe27523cb960863d6
",git fetch https://review.opendev.org/openstack/heat refs/changes/15/137115/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,aba42c4f2173f5cf85b593dd55eb709d648fe4a2,jd/py26,, Programming Language :: Python :: 2.6,0,1
openstack%2Fnova~master~Ife0b3f35ec6bd0d3c0052d2a8c0f314638a07ca3,openstack/nova,master,Ife0b3f35ec6bd0d3c0052d2a8c0f314638a07ca3,Share server access ips tests between V2 & V2.1,MERGED,2014-11-28 08:15:43.000000000,2014-12-10 20:29:19.000000000,2014-12-10 20:29:15.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-11-28 08:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d4d89abdb32a6a0bd353958509c05194aa57ae3', 'message': 'Share server access ips tests between V2 & V2.1\n\nAs server access ips should behave same in V2 and V2.1,\naccess ips tests can be shared among V2 & V2.1 to cleanup\nduplicated test code.\n\nThis patch share those tests between V2 & V2.1\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ife0b3f35ec6bd0d3c0052d2a8c0f314638a07ca3\n'}, {'number': 2, 'created': '2014-12-05 04:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/752eafe2ea7189429c9bf4533502ac3129b07dbe', 'message': 'Share server access ips tests between V2 & V2.1\n\nAs server access ips should behave same in V2 and V2.1,\naccess ips tests can be shared among V2 & V2.1 to cleanup\nduplicated test code.\n\nThis patch share those tests between V2 & V2.1\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ife0b3f35ec6bd0d3c0052d2a8c0f314638a07ca3\n'}, {'number': 3, 'created': '2014-12-05 04:24:00.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_access_ips.py', 'nova/tests/unit/api/openstack/compute/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fec400ac1d91fe2f74ac7b16e5329865e581b009', 'message': 'Share server access ips tests between V2 & V2.1\n\nAs server access ips should behave same in V2 and V2.1,\naccess ips tests can be shared among V2 & V2.1 to cleanup\nduplicated test code.\n\nThis patch share those tests between V2 & V2.1\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ife0b3f35ec6bd0d3c0052d2a8c0f314638a07ca3\n'}]",4,137738,fec400ac1d91fe2f74ac7b16e5329865e581b009,24,10,3,8556,,,0,"Share server access ips tests between V2 & V2.1

As server access ips should behave same in V2 and V2.1,
access ips tests can be shared among V2 & V2.1 to cleanup
duplicated test code.

This patch share those tests between V2 & V2.1

Partially implements blueprint v2-on-v3-api

Change-Id: Ife0b3f35ec6bd0d3c0052d2a8c0f314638a07ca3
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/137738/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_access_ips.py', 'nova/tests/unit/api/openstack/compute/test_servers.py']",2,0d4d89abdb32a6a0bd353958509c05194aa57ae3,bp/v2-on-v3-api,," def test_update_server_access_ipv4(self): body = {'server': {'accessIPv4': '0.0.0.0'}} req = self._get_request(body, {'access_ipv4': '0.0.0.0'}) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv4'], '0.0.0.0') def test_update_server_access_ipv4_bad_format(self): body = {'server': {'accessIPv4': 'bad_format'}} req = self._get_request(body, {'access_ipv4': '0.0.0.0'}) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_access_ipv4_none(self): body = {'server': {'accessIPv4': None}} req = self._get_request(body, {'access_ipv4': '0.0.0.0'}) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv4'], '') def test_update_server_access_ipv4_blank(self): body = {'server': {'accessIPv4': ''}} req = self._get_request(body, {'access_ipv4': '0.0.0.0'}) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv4'], '') def test_update_server_access_ipv6(self): body = {'server': {'accessIPv6': 'beef::0123'}} req = self._get_request(body, {'access_ipv6': 'beef::0123'}) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv6'], 'beef::123') def test_update_server_access_ipv6_bad_format(self): body = {'server': {'accessIPv6': 'bad_format'}} req = self._get_request(body, {'access_ipv6': 'beef::0123'}) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, FAKE_UUID, body) def test_update_server_access_ipv6_none(self): body = {'server': {'accessIPv6': None}} req = self._get_request(body, {'access_ipv6': 'beef::0123'}) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv6'], '') def test_update_server_access_ipv6_blank(self): body = {'server': {'accessIPv6': ''}} req = self._get_request(body, {'access_ipv6': 'beef::0123'}) res_dict = self.controller.update(req, FAKE_UUID, body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['accessIPv6'], '') def test_rebuild_instance_with_access_ipv4_bad_format(self): # proper local hrefs must start with 'http://localhost/v2/' self.body['rebuild']['accessIPv4'] = 'bad_format' self.body['rebuild']['accessIPv6'] = 'fead::1234' self.body['rebuild']['metadata']['hello'] = 'world' self.req.body = jsonutils.dumps(self.body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller._action_rebuild, self.req, FAKE_UUID, self.body) def test_rebuild_instance_with_access_ipv6_bad_format(self): # proper local hrefs must start with 'http://localhost/v2/' self.body['rebuild']['accessIPv4'] = '1.2.3.4' self.body['rebuild']['accessIPv6'] = 'bad_format' self.body['rebuild']['metadata']['hello'] = 'world' self.req.body = jsonutils.dumps(self.body) self.req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller._action_rebuild, self.req, FAKE_UUID, self.body) def test_create_instance_with_access_ip(self): self.body['server']['accessIPv4'] = '1.2.3.4' self.body['server']['accessIPv6'] = 'fead::1234' self.req.body = jsonutils.dumps(self.body) res = self.controller.create(self.req, self.body).obj server = res['server'] self._check_admin_pass_len(server) self.assertEqual(FAKE_UUID, server['id']) def test_create_instance_with_access_ip_pass_disabled(self): # test with admin passwords disabled See lp bug 921814 self.flags(enable_instance_password=False) self.body['server']['accessIPv4'] = '1.2.3.4' self.body['server']['accessIPv6'] = 'fead::1234' self.req.body = jsonutils.dumps(self.body) res = self.controller.create(self.req, self.body).obj server = res['server'] self._check_admin_pass_missing(server) self.assertEqual(FAKE_UUID, server['id']) def test_create_instance_bad_format_access_ip_v4(self): self.body['server']['accessIPv4'] = 'bad_format' self.body['server']['accessIPv6'] = 'fead::1234' self.req.body = jsonutils.dumps(self.body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, self.req, self.body) def test_create_instance_bad_format_access_ip_v6(self): self.body['server']['accessIPv4'] = '1.2.3.4' self.body['server']['accessIPv6'] = 'bad_format' self.req.body = jsonutils.dumps(self.body) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, self.req, self.body) ",69,131
openstack%2Fnova~master~Ia8c6a0144e43134667636db9ba862b26f265a433,openstack/nova,master,Ia8c6a0144e43134667636db9ba862b26f265a433,Modify v21 alias name for compatible with v2,MERGED,2014-12-08 09:15:08.000000000,2014-12-10 20:28:51.000000000,2014-12-10 20:28:48.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-12-08 09:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93ebd2182ee934a2d25381802718e0d8ad5c2720', 'message': 'Modify v21 alias name for compatible with v2\n\nThis patch change some of the alias name to compatible with v2.\nso the extension info output will be as same with v2.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ia8c6a0144e43134667636db9ba862b26f265a433\n'}, {'number': 2, 'created': '2014-12-08 09:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f280a409db8b2a68b776f62a347ca34c791d285', 'message': 'Modify v21 alias name for compatible with v2\n\nThis patch changes some of the alias names to be compatible with v2.\nso the extension info output will be as same with v2.\n consoles -> os-consoles\n flavor-extra-specs -> os-flavor-extra-specs\n flavor-manage -> os-flavor-manage\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ia8c6a0144e43134667636db9ba862b26f265a433\n'}, {'number': 3, 'created': '2014-12-09 03:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c97b1ceb6ffd1b7dfcf414ae466acbfc1a21f4ac', 'message': 'Modify v21 alias name for compatible with v2\n\nThis patch changes some of the alias names to be compatible with v2.\nso the extension info output will be as same with v2.\n consoles -> os-consoles\n flavor-extra-specs -> os-flavor-extra-specs\n flavor-manage -> os-flavor-manage\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ia8c6a0144e43134667636db9ba862b26f265a433\n'}, {'number': 4, 'created': '2014-12-09 05:00:51.000000000', 'files': ['nova/api/openstack/__init__.py', 'nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/tests/unit/fake_policy.py', 'nova/api/openstack/compute/plugins/v3/consoles.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'doc/v3/api_samples/all_extensions/extensions-list-resp.json', 'etc/nova/policy.json', 'nova/tests/functional/v3/api_samples/all_extensions/extensions-list-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/001d702e90a806ec07d37128d9ece89dc3b1bb21', 'message': 'Modify v21 alias name for compatible with v2\n\nThis patch changes some of the alias names to be compatible with v2.\nso the extension info output will be as same with v2.\n consoles -> os-consoles\n flavor-extra-specs -> os-flavor-extra-specs\n flavor-manage -> os-flavor-manage\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ia8c6a0144e43134667636db9ba862b26f265a433\n'}]",7,139948,001d702e90a806ec07d37128d9ece89dc3b1bb21,30,13,4,12175,,,0,"Modify v21 alias name for compatible with v2

This patch changes some of the alias names to be compatible with v2.
so the extension info output will be as same with v2.
 consoles -> os-consoles
 flavor-extra-specs -> os-flavor-extra-specs
 flavor-manage -> os-flavor-manage

Partially implements blueprint v2-on-v3-api

Change-Id: Ia8c6a0144e43134667636db9ba862b26f265a433
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/139948/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/flavors_extraspecs.py', 'nova/tests/unit/fake_policy.py', 'nova/api/openstack/compute/plugins/v3/consoles.py', 'nova/api/openstack/compute/plugins/v3/flavor_manage.py', 'doc/v3/api_samples/all_extensions/extensions-list-resp.json', 'etc/nova/policy.json', 'nova/tests/functional/v3/api_samples/all_extensions/extensions-list-resp.json.tpl']",7,93ebd2182ee934a2d25381802718e0d8ad5c2720,bp/v2-on-v3-api," ""alias"": ""os-consoles"", ""alias"": ""os-flavor-extra-specs"", ""alias"": ""os-flavor-manage"","," ""alias"": ""consoles"", ""alias"": ""flavor-extra-specs"", ""alias"": ""flavor-manage"",",32,26
openstack%2Fkeystone~master~I20275ff462aa41b0c1e9dfc6dff4a306f6a92539,openstack/keystone,master,I20275ff462aa41b0c1e9dfc6dff4a306f6a92539,Fix inherited user role test docstring,MERGED,2014-12-10 14:53:10.000000000,2014-12-10 20:27:23.000000000,2014-12-10 20:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5707}]","[{'number': 1, 'created': '2014-12-10 14:53:10.000000000', 'files': ['keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/71c9bf5fed53aba7e1b06ce2dd72963188e35d02', 'message': 'Fix inherited user role test docstring\n\nThe docstring first line was describing a inherited group role\ntest instead of a inherited user role test.\n\nChange-Id: I20275ff462aa41b0c1e9dfc6dff4a306f6a92539\n'}]",0,140705,71c9bf5fed53aba7e1b06ce2dd72963188e35d02,7,3,1,11022,,,0,"Fix inherited user role test docstring

The docstring first line was describing a inherited group role
test instead of a inherited user role test.

Change-Id: I20275ff462aa41b0c1e9dfc6dff4a306f6a92539
",git fetch https://review.opendev.org/openstack/keystone refs/changes/05/140705/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_backend.py'],1,71c9bf5fed53aba7e1b06ce2dd72963188e35d02,bp/hierarchical-multitenancy," """"""Test inherited user roles."," """"""Test inherited group roles.",1,1
openstack%2Fnova~master~I72cb8dd044f7ac094287bad7df9167b8e77a4b5b,openstack/nova,master,I72cb8dd044f7ac094287bad7df9167b8e77a4b5b,Check for floating IP pool in nova-network,MERGED,2014-09-10 21:28:34.000000000,2014-12-10 20:26:58.000000000,2014-12-10 20:26:55.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10612}, {'_account_id': 12175}, {'_account_id': 13409}]","[{'number': 1, 'created': '2014-09-10 21:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd65b22606281141ae71205b6ecba5ada2346b43', 'message': ""Check for floating IP pool in nova-network\n\nThere are no checks in nova-network to see if a specified\nfloating IP pool exists or not before attempting to allocate\nan IP address. If a pool does not exist, nova throws an\nunrelated error - 'No more floating ips available'. The\nfollowing patch adds a check for the existence of the IP pool\nand throws a FloatingIpPoolNotFound if it is not found.\n\nChange-Id: I72cb8dd044f7ac094287bad7df9167b8e77a4b5b\nRelated-Bug: #1355623\n""}, {'number': 2, 'created': '2014-10-20 20:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a593e68f4dd04fa8e5a798826da248a59bca00f8', 'message': ""Check for floating IP pool in nova-network\n\nThere are no checks in nova-network to see if a specified\nfloating IP pool exists or not before attempting to allocate\nan IP address. If a pool does not exist, nova throws an\nunrelated error - 'No more floating ips available'. The\nfollowing patch adds a check for the existence of the IP pool\nand throws a FloatingIpPoolNotFound if it is not found.\n\nChange-Id: I72cb8dd044f7ac094287bad7df9167b8e77a4b5b\nRelated-Bug: #1355623\n""}, {'number': 3, 'created': '2014-11-13 19:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14cadf99bd2069719b97b2cad9de943ccee38de8', 'message': ""Check for floating IP pool in nova-network\n\nThere are no checks in nova-network to see if a specified\nfloating IP pool exists or not before attempting to allocate\nan IP address. If a pool does not exist, nova throws an\nunrelated error - 'No more floating ips available'. The\nfollowing patch adds a check for the existence of the IP pool\nand throws a FloatingIpPoolNotFound if it is not found.\n\nChange-Id: I72cb8dd044f7ac094287bad7df9167b8e77a4b5b\nRelated-Bug: #1355623\n""}, {'number': 4, 'created': '2014-12-05 15:29:13.000000000', 'files': ['nova/tests/unit/test_quota.py', 'nova/tests/unit/api/ec2/test_cloud.py', 'nova/tests/unit/network/test_manager.py', 'nova/network/floating_ips.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b13be2cd56a22cf3b66f4b19c3f07b25652670b2', 'message': ""Check for floating IP pool in nova-network\n\nThere are no checks in nova-network to see if a specified\nfloating IP pool exists or not before attempting to allocate\nan IP address. If a pool does not exist, nova throws an\nunrelated error - 'No more floating ips available'. The\nfollowing patch adds a check for the existence of the IP pool\nand throws a FloatingIpPoolNotFound if it is not found.\n\nChange-Id: I72cb8dd044f7ac094287bad7df9167b8e77a4b5b\nRelated-Bug: #1355623\n""}]",2,120587,b13be2cd56a22cf3b66f4b19c3f07b25652670b2,45,13,4,8247,,,0,"Check for floating IP pool in nova-network

There are no checks in nova-network to see if a specified
floating IP pool exists or not before attempting to allocate
an IP address. If a pool does not exist, nova throws an
unrelated error - 'No more floating ips available'. The
following patch adds a check for the existence of the IP pool
and throws a FloatingIpPoolNotFound if it is not found.

Change-Id: I72cb8dd044f7ac094287bad7df9167b8e77a4b5b
Related-Bug: #1355623
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/120587/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/ec2/test_cloud.py', 'nova/tests/test_quota.py', 'nova/tests/network/test_manager.py', 'nova/network/floating_ips.py']",4,dd65b22606281141ae71205b6ecba5ada2346b43,bug/1355623," def _floating_ip_pool_exists(self, context, name): """"""Returns true if the specified floating ip pool exists. Otherwise, returns false. """""" pools = [pool.get('name') for pool in self.get_floating_ip_pools(context)] if name in pools: return True return False if not self._floating_ip_pool_exists(context, pool): raise exception.FloatingIpPoolNotFound() ",,35,1
openstack%2Fnova~master~I150bd95da65263981608dd9a033232bd142e737f,openstack/nova,master,I150bd95da65263981608dd9a033232bd142e737f,Only load necessary instance info for use in sync power state,MERGED,2014-09-11 13:12:45.000000000,2014-12-10 20:26:18.000000000,2014-12-10 20:26:13.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 8531}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-11 13:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd4270d010d1189d91ec7fa6bf9b9cd0e603df38', 'message': 'Only load necessary instance info for use in sync power state\n\nDuring sync power state, instance is refreshed from the db. If the\ninstance gets deleted, this can result in InstanceInfoCacheNotFound\nbeing thrown due to info_cache being loaded and therefore refreshed.\n\nSync power state does not make use of any extra instance attrs, so\nthis problem can be avoided by not loading any extra attrs in the\nfirst place.\n\nTwo callers of _sync_instance_power_state() are updated to not load\nextra attrs. 1) The periodic sync and 2) the lifecycle event handler.\n\nChange-Id: I150bd95da65263981608dd9a033232bd142e737f\nCloses-Bug: #1367845\n'}, {'number': 2, 'created': '2014-11-12 09:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88e8140a67b6a197d3b135710c28337a17089b2d', 'message': 'Only load necessary instance info for use in sync power state\n\nDuring sync power state, instance is refreshed from the db. If the\ninstance gets deleted, this can result in InstanceInfoCacheNotFound\nbeing thrown due to info_cache being loaded and therefore refreshed.\n\nSync power state does not make use of any extra instance attrs, so\nthis problem can be avoided by not loading any extra attrs in the\nfirst place.\n\nTwo callers of _sync_instance_power_state() are updated to not load\nextra attrs. 1) The periodic sync and 2) the lifecycle event handler.\n\nChange-Id: I150bd95da65263981608dd9a033232bd142e737f\nCloses-Bug: #1367845\n'}, {'number': 3, 'created': '2014-11-12 10:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9acf1c63bd6d14326337f1a8f197176b66a61fd', 'message': 'Only load necessary instance info for use in sync power state\n\nDuring sync power state, instance is refreshed from the db. If the\ninstance gets deleted, this can result in InstanceInfoCacheNotFound\nbeing thrown due to info_cache being loaded and therefore refreshed.\n\nSync power state does not make use of any extra instance attrs, so\nthis problem can be avoided by not loading any extra attrs in the\nfirst place.\n\nTwo callers of _sync_instance_power_state() are updated to not load\nextra attrs. 1) The periodic sync and 2) the lifecycle event handler.\n\nChange-Id: I150bd95da65263981608dd9a033232bd142e737f\nCloses-Bug: #1367845\n'}, {'number': 4, 'created': '2014-11-13 07:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58729c0210ba1006bb26d017372943c62da2764d', 'message': 'Only load necessary instance info for use in sync power state\n\nDuring sync power state, instance is refreshed from the db. If the\ninstance gets deleted, this can result in InstanceInfoCacheNotFound\nbeing thrown due to info_cache being loaded and therefore refreshed.\n\nSync power state does not make use of any extra instance attrs, so\nthis problem can be avoided by not loading any extra attrs in the\nfirst place.\n\nTwo callers of _sync_instance_power_state() are updated to not load\nextra attrs. 1) The periodic sync and 2) the lifecycle event handler.\n\nChange-Id: I150bd95da65263981608dd9a033232bd142e737f\nCloses-Bug: #1367845\n'}, {'number': 5, 'created': '2014-11-14 16:21:07.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_compute_xen.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/43c8cff8252ff38eb2fca88c44193049afb711ee', 'message': 'Only load necessary instance info for use in sync power state\n\nDuring sync power state, instance is refreshed from the db. If the\ninstance gets deleted, this can result in InstanceInfoCacheNotFound\nbeing thrown due to info_cache being loaded and therefore refreshed.\n\nSync power state does not make use of any extra instance attrs, so\nthis problem can be avoided by not loading any extra attrs in the\nfirst place.\n\nTwo callers of _sync_instance_power_state() are updated to not load\nextra attrs. 1) The periodic sync and 2) the lifecycle event handler.\n\nChange-Id: I150bd95da65263981608dd9a033232bd142e737f\nCloses-Bug: #1367845\n'}]",2,120784,43c8cff8252ff38eb2fca88c44193049afb711ee,57,13,5,6450,,,0,"Only load necessary instance info for use in sync power state

During sync power state, instance is refreshed from the db. If the
instance gets deleted, this can result in InstanceInfoCacheNotFound
being thrown due to info_cache being loaded and therefore refreshed.

Sync power state does not make use of any extra instance attrs, so
this problem can be avoided by not loading any extra attrs in the
first place.

Two callers of _sync_instance_power_state() are updated to not load
extra attrs. 1) The periodic sync and 2) the lifecycle event handler.

Change-Id: I150bd95da65263981608dd9a033232bd142e737f
Closes-Bug: #1367845
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/120784/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_xen.py', 'nova/compute/manager.py']",2,bd4270d010d1189d91ec7fa6bf9b9cd0e603df38,bug/1367845," event.get_instance_uuid(), expected_attrs=[]) db_instances = objects.InstanceList.get_by_host(context, self.host, expected_attrs=[], use_slave=True)"," event.get_instance_uuid()) db_instances = objects.InstanceList.get_by_host(context, self.host, use_slave=True)",7,5
openstack%2Fnova~master~I03d2ea7935040b656c4a32de219d018f0ab89161,openstack/nova,master,I03d2ea7935040b656c4a32de219d018f0ab89161,VMware: remove flag in tests indicating VC is supported,MERGED,2014-10-08 05:56:26.000000000,2014-12-10 20:25:39.000000000,2014-12-10 20:25:35.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-08 05:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26275dbb29503c1da770c1eb45a1ad8ebeefe603', 'message': 'VMware: remove flag in tests indicating VC is supported\n\nThe ESX driver is no longer supported so this code is no longer\nneeded.\n\nChange-Id: I03d2ea7935040b656c4a32de219d018f0ab89161\n'}, {'number': 2, 'created': '2014-10-15 05:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f29a2309df7c7583b9c50f6b430a54c8521e69d', 'message': 'VMware: remove flag in tests indicating VC is supported\n\nThe ESX driver is no longer supported so this code is no longer\nneeded.\n\nChange-Id: I03d2ea7935040b656c4a32de219d018f0ab89161\n'}, {'number': 3, 'created': '2014-10-21 06:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03dfdfe9da4a9a979e6373c4bc3286e001fc41f8', 'message': 'VMware: remove flag in tests indicating VC is supported\n\nThe ESX driver is no longer supported so this code is no longer\nneeded.\n\nChange-Id: I03d2ea7935040b656c4a32de219d018f0ab89161\n'}, {'number': 4, 'created': '2014-12-08 14:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a1fce74dfd59674c7419ee0b5a4bc1b29ed8014', 'message': 'VMware: remove flag in tests indicating VC is supported\n\nThe ESX driver is no longer supported so this code is no longer\nneeded.\n\nChange-Id: I03d2ea7935040b656c4a32de219d018f0ab89161\n'}, {'number': 5, 'created': '2014-12-09 09:47:29.000000000', 'files': ['nova/tests/unit/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/88b01866b59e72e4dfe1561442834d3bf861b471', 'message': 'VMware: remove flag in tests indicating VC is supported\n\nThe ESX driver is no longer supported so this code is no longer\nneeded.\n\nChange-Id: I03d2ea7935040b656c4a32de219d018f0ab89161\n'}]",0,126802,88b01866b59e72e4dfe1561442834d3bf861b471,42,10,5,1653,,,0,"VMware: remove flag in tests indicating VC is supported

The ESX driver is no longer supported so this code is no longer
needed.

Change-Id: I03d2ea7935040b656c4a32de219d018f0ab89161
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/126802/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/vmwareapi/test_driver_api.py'],1,26275dbb29503c1da770c1eb45a1ad8ebeefe603,remove-vc-support," def _spawn_attach_volume_vmdk(self, set_image_ref=True): self.mox.StubOutWithMock(volumeops.VMwareVolumeOps, '_get_res_pool_of_vm') volumeops.VMwareVolumeOps._get_res_pool_of_vm( mox.IgnoreArg()).AndReturn('fake_res_pool') self.mox.StubOutWithMock(volumeops.VMwareVolumeOps, '_relocate_vmdk_volume') volumeops.VMwareVolumeOps._relocate_vmdk_volume(mox.IgnoreArg(), 'fake_res_pool', mox.IgnoreArg()) self._spawn_attach_volume_vmdk() self._spawn_attach_volume_vmdk(set_image_ref=False)"," def _spawn_attach_volume_vmdk(self, set_image_ref=True, vc_support=False): if vc_support: self.mox.StubOutWithMock(volumeops.VMwareVolumeOps, '_get_res_pool_of_vm') volumeops.VMwareVolumeOps._get_res_pool_of_vm( mox.IgnoreArg()).AndReturn('fake_res_pool') self.mox.StubOutWithMock(volumeops.VMwareVolumeOps, '_relocate_vmdk_volume') volumeops.VMwareVolumeOps._relocate_vmdk_volume(mox.IgnoreArg(), 'fake_res_pool', mox.IgnoreArg()) self._spawn_attach_volume_vmdk(vc_support=True) self._spawn_attach_volume_vmdk(set_image_ref=False, vc_support=True)",11,12
openstack%2Fdevstack-gate~master~I0b7e81b2b73f90db1debe50d707e77fcf7994774,openstack/devstack-gate,master,I0b7e81b2b73f90db1debe50d707e77fcf7994774,Add os-net-config to the list of packages we clone,MERGED,2014-11-24 16:30:08.000000000,2014-12-10 20:24:35.000000000,2014-12-10 20:24:34.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-11-24 16:30:08.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/cb2dc59568c386a7b0a7f82279d157d31849e241', 'message': ""Add os-net-config to the list of packages we clone\n\nWithout this, changes such as Idac59e571a72cc8d5693f811ec0121273b891d0f\ncan't pass as there's no os-net-config git checkout to apply the change to.\n\nChange-Id: I0b7e81b2b73f90db1debe50d707e77fcf7994774\n""}]",0,136811,cb2dc59568c386a7b0a7f82279d157d31849e241,14,7,1,9453,,,0,"Add os-net-config to the list of packages we clone

Without this, changes such as Idac59e571a72cc8d5693f811ec0121273b891d0f
can't pass as there's no os-net-config git checkout to apply the change to.

Change-Id: I0b7e81b2b73f90db1debe50d707e77fcf7994774
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/11/136811/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,cb2dc59568c386a7b0a7f82279d157d31849e241,,"PROJECTS=""openstack/os-net-config $PROJECTS""",,1,0
openstack%2Fneutron-fwaas~master~I8c104155c409600e7ca8ac48bfb0919aaf864510,openstack/neutron-fwaas,master,I8c104155c409600e7ca8ac48bfb0919aaf864510,Delete accidentally committed egg files,MERGED,2014-12-10 18:52:26.000000000,2014-12-10 19:51:44.000000000,2014-12-10 19:51:43.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}]","[{'number': 1, 'created': '2014-12-10 18:52:26.000000000', 'files': ['neutron_fwaas.egg-info/dependency_links.txt', 'neutron_fwaas.egg-info/PKG-INFO', 'neutron_fwaas.egg-info/requires.txt', 'neutron_fwaas.egg-info/SOURCES.txt', 'neutron_fwaas.egg-info/top_level.txt', 'neutron_fwaas.egg-info/not-zip-safe'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/049ac09740eed7d5c5b5114e8d8e9bb2dfb591aa', 'message': 'Delete accidentally committed egg files\n\nChange-Id: I8c104155c409600e7ca8ac48bfb0919aaf864510\n'}]",0,140807,049ac09740eed7d5c5b5114e8d8e9bb2dfb591aa,7,3,1,10980,,,0,"Delete accidentally committed egg files

Change-Id: I8c104155c409600e7ca8ac48bfb0919aaf864510
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/07/140807/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas.egg-info/PKG-INFO', 'neutron_fwaas.egg-info/dependency_links.txt', 'neutron_fwaas.egg-info/requires.txt', 'neutron_fwaas.egg-info/SOURCES.txt', 'neutron_fwaas.egg-info/top_level.txt', 'neutron_fwaas.egg-info/not-zip-safe']",6,049ac09740eed7d5c5b5114e8d8e9bb2dfb591aa,nuke_egg_files,, ,0,84
openstack%2Fcongress~master~If1dd859a53731e643ff098422b271f8520db1a1d,openstack/congress,master,If1dd859a53731e643ff098422b271f8520db1a1d,Persist policies to database,ABANDONED,2014-11-13 17:51:40.000000000,2014-12-10 19:47:06.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-11-13 17:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/93e390277a2ca50ac15719d061488fdcc242cacf', 'message': 'WIP: Persist policies to database\n\nChange-Id: If1dd859a53731e643ff098422b271f8520db1a1d\n'}, {'number': 2, 'created': '2014-11-20 17:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/78032f7bc6ea08c1a0a0ffd14e5bbd9794881fbc', 'message': 'Persist policies to database\n\nChange-Id: If1dd859a53731e643ff098422b271f8520db1a1d\n'}, {'number': 3, 'created': '2014-11-21 00:06:43.000000000', 'files': ['congress/policy/tests/test_runtime.py', 'congress/tests/test_congress.py', 'congress/harness.py', 'congress/policy/tests/test_nonrecur.py', 'congress/policy/tests/test_materialized.py', 'congress/api/policy_model.py', 'congress/api/error_codes.py', 'congress/db/db_policy_rules.py', 'congress/policy/tests/test_compiler.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/f7ec1de6ea9972b5a2db7b884b554dbe00cbf244', 'message': 'Persist policies to database\n\nChange-Id: If1dd859a53731e643ff098422b271f8520db1a1d\n'}]",13,134312,f7ec1de6ea9972b5a2db7b884b554dbe00cbf244,15,4,3,8215,,,0,"Persist policies to database

Change-Id: If1dd859a53731e643ff098422b271f8520db1a1d
",git fetch https://review.opendev.org/openstack/congress refs/changes/12/134312/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/test_congress.py', 'congress/harness.py', 'congress/api/policy_model.py', 'congress/api/error_codes.py', 'congress/db/db_policy_rules.py']",5,93e390277a2ca50ac15719d061488fdcc242cacf,multipolicy,"class Policy(model_base.BASE, model_base.HasId, model_base.HasAudit): __tablename__ = 'policy' name = sa.Column(sa.Text(), nullable=False, primary_key=True) abbreviation = sa.Column(sa.Text(), nullable=False) description = sa.Column(sa.Text(), nullable=False) owner = sa.Column(sa.Text(), nullable=False) def __init__(self, id_, abbreviation, description, owner, deleted=False): self.id = id_ self.abbreviation = abbreviation self.description = description self.owner = owner self.deleted = deleted def add_policy(id_, abbreviation, description, owner, deleted=False, session=None): session = session or db.get_session() with session.begin(subtransactions=True): policy = Policy(id_, abbreviation, description, owner, deleted) session.add(policy) return policy def delete_policy(id, session=None): session = session or db.get_session() return session.query(Policy).filter_by(id=id).soft_delete() def update_policy(id, new_keyvalues, session=None): session = session or db.get_session() policy = (session.query(Policy). filter_by(id=id). filter_by(deleted=0). one()) policy.update(new_keyvalues) def get_policy(id, session=None): session = session or db.get_session() try: return (session.query(Policy). filter_by(id=id). filter_by(deleted=0). one()) except db_exc.NoResultFound: pass def get_policies(session=None): session = session or db.get_session() return (session.query(Policy). filter_by(deleted=0). all()) ",,85,16
openstack%2Fproject-config~master~I76fcea1e2965795ebb99f2b7d649cf9a53908f09,openstack/project-config,master,I76fcea1e2965795ebb99f2b7d649cf9a53908f09,Support running script against local changes,MERGED,2014-12-03 12:59:10.000000000,2014-12-10 19:46:51.000000000,2014-12-10 19:46:50.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-03 12:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1ece9e0a3386ae9109cf5911027c5358cffb4147', 'message': ""Support running script against local changes\n\nSome projects do not strictly enforce requirements changes and\ndevelopers in those project need a way to see how far away they\nare from the global requirements. So we need a way to run this\nscript to figure out which of those items in global requirements\nthey would like to update in their projects.\n\nAdding a --local optional flag and defaulting the branch to 'master'\nseems to support both existing usecases in gate and the local\nuse case as detailed above\n\nChange-Id: I76fcea1e2965795ebb99f2b7d649cf9a53908f09\n""}, {'number': 2, 'created': '2014-12-03 13:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/24c412e7f5190cbb4849272220c7cda392dfe79c', 'message': ""Support running script against local changes\n\nSome projects do not strictly enforce requirements changes and\ndevelopers in those project need a way to see how far away they\nare from the global requirements. So we need a way to run this\nscript to figure out which of those items in global requirements\nthey would like to update in their projects.\n\nAdding a --local optional flag and defaulting the branch to 'master'\nseems to support both existing usecases in gate and the local\nuse case as detailed above\n\nChange-Id: I76fcea1e2965795ebb99f2b7d649cf9a53908f09\n""}, {'number': 3, 'created': '2014-12-03 14:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/527dce0446f202f1dbcccc672d071e8d5ebe888b', 'message': ""Support running script against local changes\n\nSome projects do not strictly enforce requirements changes and\ndevelopers in those project need a way to see how far away they\nare from the global requirements. So we need a way to run this\nscript to figure out which of those items in global requirements\nthey would like to update in their projects.\n\nAdding a --local optional flag and defaulting the branch to 'master'\nseems to support both existing usecases in gate and the local\nuse case as detailed above\n\nChange-Id: I76fcea1e2965795ebb99f2b7d649cf9a53908f09\n""}, {'number': 4, 'created': '2014-12-07 02:05:56.000000000', 'files': ['jenkins/scripts/project-requirements-change.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/291b578f6becbb370cc0f8579e19ee9470550abf', 'message': ""Support running script against local changes\n\nSome projects do not strictly enforce requirements changes and\ndevelopers in those project need a way to see how far away they\nare from the global requirements. So we need a way to run this\nscript to figure out which of those items in global requirements\nthey would like to update in their projects.\n\nAdding a --local optional flag and defaulting the branch to 'master'\nseems to support both existing usecases in gate and the local\nuse case as detailed above\n\nChange-Id: I76fcea1e2965795ebb99f2b7d649cf9a53908f09\n""}]",0,138710,291b578f6becbb370cc0f8579e19ee9470550abf,19,5,4,5638,,,0,"Support running script against local changes

Some projects do not strictly enforce requirements changes and
developers in those project need a way to see how far away they
are from the global requirements. So we need a way to run this
script to figure out which of those items in global requirements
they would like to update in their projects.

Adding a --local optional flag and defaulting the branch to 'master'
seems to support both existing usecases in gate and the local
use case as detailed above

Change-Id: I76fcea1e2965795ebb99f2b7d649cf9a53908f09
",git fetch https://review.opendev.org/openstack/project-config refs/changes/10/138710/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/project-requirements-change.py'],1,1ece9e0a3386ae9109cf5911027c5358cffb4147,,"import argparsedef grab_args(): """"""Grab and return arguments"""""" parser = argparse.ArgumentParser( description=""Check if project requirements have changed"" ) parser.add_argument('--local', action='store_true', help='check local changes (not yet in git)') parser.add_argument('branch', nargs='?', default='master', help='target branch for diffs') return parser.parse_args() def main(): args = grab_args() print ""using parser %s"" % args branch = args.branch if not args.local: # build a list of requirements already in the target branch, # so that we can create a diff and identify what's being changed run_command(""git remote update"") run_command(""git checkout remotes/origin/%s"" % branch) branch_reqs.read_all_requirements() # switch back to the proposed change now run_command(""git checkout %s"" % head)","def main(): branch = sys.argv[1] # build a list of requirements already in the target branch, # so that we can create a diff and identify what's being changed run_command(""git remote update"") run_command(""git checkout remotes/origin/%s"" % branch) branch_reqs.read_all_requirements() # switch back to the proposed change now run_command(""git checkout %s"" % head)",25,8
openstack%2Fdiskimage-builder~master~Ic3d3565423b0ae090896d99fd3bf1145eca6303d,openstack/diskimage-builder,master,Ic3d3565423b0ae090896d99fd3bf1145eca6303d,Add some speedups to dpkg,MERGED,2014-11-24 02:28:43.000000000,2014-12-10 19:45:35.000000000,2014-12-10 19:45:34.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 8532}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-11-24 02:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7955857890ccb444e68f887a6386e68ded35290d', 'message': 'Add some speedups to dpkg\n\nThe docker build folks obsess about image size and speed a bit. Grab a\nfew of their optimizations from their debootstrap build process and\napply them to ours.\n\nChange-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d\n'}, {'number': 2, 'created': '2014-11-24 14:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1a1d318ef78dcbedea855757e7bf44706b790347', 'message': 'Add some speedups to dpkg\n\nThe docker build folks obsess about image size and speed a bit. Grab a\nfew of their optimizations from their debootstrap build process and\napply them to ours.\n\nChange-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d\n'}, {'number': 3, 'created': '2014-11-24 22:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c631b6d5373215729d9bc2d8feaa441befad2ff7', 'message': 'Add some speedups to dpkg\n\nThe docker build folks obsess about image size and speed a bit. Grab a\nfew of their optimizations from their debootstrap build process and\napply them to ours.\n\nChange-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d\n'}, {'number': 4, 'created': '2014-11-28 16:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c343c7e42e19582b6c4b1e1f97385666f845f82e', 'message': 'Add some speedups to dpkg\n\nThe docker build folks obsess about image size and speed a bit. Grab a\nfew of their optimizations from their debootstrap build process and\napply them to ours.\n\nChange-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d\n'}, {'number': 5, 'created': '2014-12-08 22:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7c4fcd7ae58dae548d7843ceb654c3d26ee69afc', 'message': 'Add some speedups to dpkg\n\nThe docker build folks obsess about image size and speed a bit. Grab a\nfew of their optimizations from their debootstrap build process and\napply them to ours.\n\nChange-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d\n'}, {'number': 6, 'created': '2014-12-10 14:53:22.000000000', 'files': ['elements/dpkg/root.d/99-trim-dpkg', 'elements/dpkg/cleanup.d/60-untrim-dpkg'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6be5c396d172bd3decf321fdd5c2f317aae8d066', 'message': 'Add some speedups to dpkg\n\nThe docker build folks obsess about image size and speed a bit. Grab a\nfew of their optimizations from their debootstrap build process and\napply them to ours.\n\nChange-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d\n'}]",1,136660,6be5c396d172bd3decf321fdd5c2f317aae8d066,28,6,6,2,,,0,"Add some speedups to dpkg

The docker build folks obsess about image size and speed a bit. Grab a
few of their optimizations from their debootstrap build process and
apply them to ours.

Change-Id: Ic3d3565423b0ae090896d99fd3bf1145eca6303d
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/60/136660/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/dpkg/root.d/99-trim-dpkg', 'elements/dpkg/cleanup.d/60-untrim-dpkg']",2,7955857890ccb444e68f887a6386e68ded35290d,,"#!/bin/bash set -eu set -o pipefail [ -n ""$TARGET_ROOT"" ] sudo rm $TARGET_ROOT/etc/dpkg/dpkg.cfg.d/02apt-speedup sudo rm $TARGET_ROOT/etc/apt/apt.conf.d/no-cache sudo rm $TARGET_ROOT/etc/apt/apt.conf.d/no-languages ",,31,0
openstack%2Ftrove~master~I77535f6798f202f51f04b94ee9271b139b5c6b78,openstack/trove,master,I77535f6798f202f51f04b94ee9271b139b5c6b78,Obsolete oslo-incubator modules - unused modules,MERGED,2014-10-17 15:00:22.000000000,2014-12-10 19:42:59.000000000,2014-12-10 19:42:58.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6159}, {'_account_id': 6268}, {'_account_id': 7092}, {'_account_id': 7796}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9746}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10266}, {'_account_id': 10295}, {'_account_id': 10725}, {'_account_id': 12673}]","[{'number': 1, 'created': '2014-10-17 15:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/500832799d0e32ee35353ef346345e3aea65c41e', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: trove-retire-unused-modules\nPartial-Bug: #1380789\n'}, {'number': 2, 'created': '2014-10-17 19:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c4f512f0f32f077faeb4505f66f22690a5bef6fd', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-modules\nPartial-Bug: #1380789'}, {'number': 3, 'created': '2014-10-17 20:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e0074afd899f5536a775b5e707a3107444f9ac21', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-modules\nPartial-Bug: #1380789\n'}, {'number': 4, 'created': '2014-10-20 16:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dbeb887903fd80ddb622f7fcb06a5497bba39237', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-modules\nPartial-Bug: #1380789\n'}, {'number': 5, 'created': '2014-10-20 16:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/47cc87b95cb5fc6b33c20f2f90152d140ee4ced9', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 6, 'created': '2014-10-20 21:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/71fa6183cb9689318031547949f3145f61f094df', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 7, 'created': '2014-11-05 08:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/929483132fca15475f59f52f8de3350dc35cd02e', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-trove-modules\nPartial-Bug: #1380789\n'}, {'number': 8, 'created': '2014-11-10 12:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9cf8a28689d4b427570ecd04ea310d5679e77042', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-oslo-incubator-modules\nPartial-Bug: #1380789'}, {'number': 9, 'created': '2014-12-04 16:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/02703d2caaa31b9f8091821579bf97dda7a58e42', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-oslo-incubator-modules\nPartial-Bug: #1380789'}, {'number': 10, 'created': '2014-12-09 17:37:47.000000000', 'files': ['trove/openstack/common/testutils.py', 'trove/openstack/common/lockutils.py', 'trove/openstack/common/iniparser.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/trove/commit/b480b8769b9bada07c3050fd42fd7534c01e9f6e', 'message': 'Obsolete oslo-incubator modules - unused modules\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules.\n\nThis commit handles obsolete oslo-incubator modules that are not used\nin Trove but are referenced in openstack-common.conf\n\nThe change here is to remove them from openstack-common.conf and\ndelete them from trove/openstack/common.\n\nWhile excutils, network_utils and strutils are deleted from\nopenstack-common.conf the files are retained because of dependencies\nwithin oslo-incubator.\n\nChange-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78\nBlueprint: retire-unused-oslo-incubator-modules\nPartial-Bug: #1380789\n'}]",0,129292,b480b8769b9bada07c3050fd42fd7534c01e9f6e,66,21,10,9664,,,0,"Obsolete oslo-incubator modules - unused modules

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules.

This commit handles obsolete oslo-incubator modules that are not used
in Trove but are referenced in openstack-common.conf

The change here is to remove them from openstack-common.conf and
delete them from trove/openstack/common.

While excutils, network_utils and strutils are deleted from
openstack-common.conf the files are retained because of dependencies
within oslo-incubator.

Change-Id: I77535f6798f202f51f04b94ee9271b139b5c6b78
Blueprint: retire-unused-oslo-incubator-modules
Partial-Bug: #1380789
",git fetch https://review.opendev.org/openstack/trove refs/changes/92/129292/9 && git format-patch -1 --stdout FETCH_HEAD,"['trove/openstack/common/testutils.py', 'trove/openstack/common/iniparser.py', 'openstack-common.conf']",3,500832799d0e32ee35353ef346345e3aea65c41e,bugs/bug-1380789-unused-modules,,module=iniparsermodule=testutils,0,200
openstack%2Fmonasca-api~master~I47cb5eb6fe06314d29b2b0d972b06f54fe9fe98f,openstack/monasca-api,master,I47cb5eb6fe06314d29b2b0d972b06f54fe9fe98f,Move tenant id to front for serie name,MERGED,2014-12-10 14:48:56.000000000,2014-12-10 19:38:25.000000000,2014-12-10 19:38:24.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-10 14:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/45d708eaaf063ccc1eabd82860e639e64604d7c9', 'message': 'Move tenant id to front for serie name\n\nMake serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: I47cb5eb6fe06314d29b2b0d972b06f54fe9fe98f\n'}, {'number': 2, 'created': '2014-12-10 15:02:13.000000000', 'files': ['monasca/v2/reference/metrics.py', 'monasca/common/repositories/influxdb/metrics_repository.py', 'monasca/common/repositories/metrics_repository.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/45a0da48cb85a746a27d3e5601e121e805ee4ab5', 'message': 'Move tenant id to front for serie name\n\nMake serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: I47cb5eb6fe06314d29b2b0d972b06f54fe9fe98f\n'}]",0,140702,45a0da48cb85a746a27d3e5601e121e805ee4ab5,8,4,2,12512,,,0,"Move tenant id to front for serie name

Make serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...

Change-Id: I47cb5eb6fe06314d29b2b0d972b06f54fe9fe98f
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/02/140702/2 && git format-patch -1 --stdout FETCH_HEAD,"['monasca/v2/reference/metrics.py', 'monasca/common/repositories/influxdb/metrics_repository.py', 'monasca/common/repositories/metrics_repository.py']",3,45d708eaaf063ccc1eabd82860e639e64604d7c9,," def list_metrics(self, tenant_id, region, name, dimensions): def measurement_list(self, tenant_id, region, name, dimensions, start_timestamp, def metrics_statistics(self, tenant_id, region, name, dimensions, start_timestamp, end_timestamp, statistics, period):"," def list_metrics(self, tenant_id, name, dimensions): def measurement_list(self, tenant_id, name, dimensions, start_timestamp, def metrics_statistics(self, tenant_id, name, dimensions, start_timestamp, end_timestamp, statistics, period):",69,39
openstack%2Fmonasca-persister~master~I1f8efbabe34548c080ccb932fc58e4f1e517042c,openstack/monasca-persister,master,I1f8efbabe34548c080ccb932fc58e4f1e517042c,Move tenant id and region to front of serie name,MERGED,2014-12-09 22:06:38.000000000,2014-12-10 19:37:59.000000000,2014-12-10 19:37:59.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-09 22:06:38.000000000', 'files': ['monasca_persister/persister.py'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/150dbb190f1a9b4f9c895a4c9a7206d62b315d04', 'message': 'Move tenant id and region to front of serie name\n\nMake serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: I1f8efbabe34548c080ccb932fc58e4f1e517042c\n'}]",0,140494,150dbb190f1a9b4f9c895a4c9a7206d62b315d04,7,4,1,12512,,,0,"Move tenant id and region to front of serie name

Make serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...

Change-Id: I1f8efbabe34548c080ccb932fc58e4f1e517042c
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/94/140494/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_persister/persister.py'],1,150dbb190f1a9b4f9c895a4c9a7206d62b315d04,," urllib.quote(tenant_id.encode('utf8'), safe='') + '?' + urllib.quote(region.encode('utf8'), safe='') + '&' + urllib.quote(metric_name.encode('utf8'), safe=''))"," urllib.quote(metric_name.encode('utf8'), safe='') + '?' + urllib.quote( tenant_id.encode('utf8'), safe='') + '&' + urllib.quote( region.encode('utf8'), safe=''))",5,4
openstack%2Fneutron-vpnaas~master~Id31eef8a4ed712c347c81c9987465e7566ba9bf3,openstack/neutron-vpnaas,master,Id31eef8a4ed712c347c81c9987465e7566ba9bf3,Remove erroneously commited egg files,MERGED,2014-12-10 18:51:45.000000000,2014-12-10 19:36:40.000000000,2014-12-10 19:36:39.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 18:51:45.000000000', 'files': ['neutron_vpnaas.egg-info/top_level.txt', 'neutron_vpnaas.egg-info/PKG-INFO', 'neutron_vpnaas.egg-info/entry_points.txt', 'neutron_vpnaas.egg-info/SOURCES.txt', 'neutron_vpnaas.egg-info/dependency_links.txt', 'neutron_vpnaas.egg-info/not-zip-safe', 'neutron_vpnaas.egg-info/requires.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/d1ee6923425eca52f400a2de23d1541f16568c2b', 'message': 'Remove erroneously commited egg files\n\nChange-Id: Id31eef8a4ed712c347c81c9987465e7566ba9bf3\n'}]",0,140806,d1ee6923425eca52f400a2de23d1541f16568c2b,7,3,1,10980,,,0,"Remove erroneously commited egg files

Change-Id: Id31eef8a4ed712c347c81c9987465e7566ba9bf3
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/06/140806/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas.egg-info/top_level.txt', 'neutron_vpnaas.egg-info/PKG-INFO', 'neutron_vpnaas.egg-info/entry_points.txt', 'neutron_vpnaas.egg-info/SOURCES.txt', 'neutron_vpnaas.egg-info/dependency_links.txt', 'neutron_vpnaas.egg-info/not-zip-safe', 'neutron_vpnaas.egg-info/requires.txt']",7,d1ee6923425eca52f400a2de23d1541f16568c2b,nuke_egg_files,,"pbr>=0.6,!=0.7,<1.0 Paste PasteDeploy>=1.5.0 Routes>=1.12.3,!=2.0 anyjson>=0.3.3 argparse eventlet>=0.15.2 greenlet>=0.3.2 httplib2>=0.7.5 requests>=2.2.0,!=2.4.0 iso8601>=0.1.9 jsonrpclib Jinja2>=2.6 # BSD License3 clause keystonemiddleware>=1.0.0 netaddr>=0.7.12 python-neutronclient>=2.3.6,<3 SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99 WebOb>=1.2.3 python-keystoneclient>=0.11.1 alembic>=0.6.4 six>=1.7.0 stevedore>=1.1.0 # Apache-2.0 oslo.config>=1.4.0 # Apache-2.0 oslo.db>=1.1.0 # Apache-2.0 oslo.i18n>=1.0.0 # Apache-2.0 oslo.messaging>=1.4.0,!=1.5.0 oslo.middleware>=0.1.0 # Apache-2.0 oslo.rootwrap>=1.3.0 oslo.serialization>=1.0.0 # Apache-2.0 oslo.utils>=1.0.0 # Apache-2.0 python-novaclient>=2.18.0 neutron ",0,87
openstack%2Fneutron-lbaas~master~Ibad5c00fb5d88b53e43c8d359d3a484e3540165a,openstack/neutron-lbaas,master,Ibad5c00fb5d88b53e43c8d359d3a484e3540165a,WIP -  passes pycharm; fails tox,ABANDONED,2014-12-09 19:12:35.000000000,2014-12-10 19:34:22.000000000,,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-09 19:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/feed900367855412c69d289a8040eec9380e8a33', 'message': 'WIP - service insertion\n\nChange-Id: Ibad5c00fb5d88b53e43c8d359d3a484e3540165a\n'}, {'number': 2, 'created': '2014-12-10 00:52:56.000000000', 'files': ['neutron_lbaas/tests/unit/test_routerserviceinsertion.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/8a17f13f9c717d50c10006007c43f502880cc035', 'message': 'WIP -  passes pycharm; fails tox\n\nChange-Id: Ibad5c00fb5d88b53e43c8d359d3a484e3540165a\n'}]",0,140438,8a17f13f9c717d50c10006007c43f502880cc035,7,3,2,10850,,,0,"WIP -  passes pycharm; fails tox

Change-Id: Ibad5c00fb5d88b53e43c8d359d3a484e3540165a
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/38/140438/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/tests/unit/test_routerserviceinsertion.py'],1,feed900367855412c69d289a8040eec9380e8a33,,"# Copyright 2013 VMware, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg import webob.exc as webexc import neutron from neutron.api import extensions from neutron.api.v2 import attributes from neutron.api.v2 import router from neutron.common import config from neutron import context as q_context from neutron.db import db_base_plugin_v2 from neutron.db import l3_db from neutron.db.loadbalancer import loadbalancer_db as lb_db from neutron.db import routedserviceinsertion_db as rsi_db from neutron.db import routerservicetype_db as rst_db from neutron.db import servicetype_db as st_db from neutron.extensions import routedserviceinsertion as rsi from neutron.extensions import routerservicetype as rst from neutron.plugins.common import constants from neutron.tests.unit import test_api_v2 from neutron.tests.unit import testlib_api from neutron.tests.unit import testlib_plugin from neutron import wsgi _uuid = test_api_v2._uuid _get_path = test_api_v2._get_path extensions_path = ':'.join(neutron.extensions.__path__) class RouterServiceInsertionTestPlugin( rst_db.RouterServiceTypeDbMixin, rsi_db.RoutedServiceInsertionDbMixin, st_db.ServiceTypeManager, lb_db.LoadBalancerPluginDb, l3_db.L3_NAT_db_mixin, db_base_plugin_v2.NeutronDbPluginV2): supported_extension_aliases = [ ""router"", ""router-service-type"", ""routed-service-insertion"", ""service-type"", ""lbaas"" ] def create_router(self, context, router): with context.session.begin(subtransactions=True): r = super(RouterServiceInsertionTestPlugin, self).create_router( context, router) service_type_id = router['router'].get(rst.SERVICE_TYPE_ID) if service_type_id is not None: r[rst.SERVICE_TYPE_ID] = service_type_id self._process_create_router_service_type_id( context, r) return r def get_router(self, context, id, fields=None): with context.session.begin(subtransactions=True): r = super(RouterServiceInsertionTestPlugin, self).get_router( context, id, fields) rsbind = self._get_router_service_type_id_binding(context, id) if rsbind: r[rst.SERVICE_TYPE_ID] = rsbind['service_type_id'] return r def delete_router(self, context, id): with context.session.begin(subtransactions=True): super(RouterServiceInsertionTestPlugin, self).delete_router( context, id) rsbind = self._get_router_service_type_id_binding(context, id) if rsbind: raise Exception('Router service-type binding is not deleted') def create_resource(self, res, context, resource, model): with context.session.begin(subtransactions=True): method_name = ""create_{0}"".format(res) method = getattr(super(RouterServiceInsertionTestPlugin, self), method_name) o = method(context, resource) router_id = resource[res].get(rsi.ROUTER_ID) if router_id is not None: o[rsi.ROUTER_ID] = router_id self._process_create_resource_router_id( context, o, model) return o def get_resource(self, res, context, id, fields, model): method_name = ""get_{0}"".format(res) method = getattr(super(RouterServiceInsertionTestPlugin, self), method_name) o = method(context, id, fields) if fields is None or rsi.ROUTER_ID in fields: rsbind = self._get_resource_router_id_binding( context, model, id) if rsbind: o[rsi.ROUTER_ID] = rsbind['router_id'] return o def delete_resource(self, res, context, id, model): method_name = ""delete_{0}"".format(res) with context.session.begin(subtransactions=True): method = getattr(super(RouterServiceInsertionTestPlugin, self), method_name) method(context, id) self._delete_resource_router_id_binding(context, id, model) if self._get_resource_router_id_binding(context, model, id): raise Exception(""{0}-router binding is not deleted"".format(res)) def create_pool(self, context, pool): return self.create_resource('pool', context, pool, lb_db.Pool) def get_pool(self, context, id, fields=None): return self.get_resource('pool', context, id, fields, lb_db.Pool) def delete_pool(self, context, id): return self.delete_resource('pool', context, id, lb_db.Pool) def create_health_monitor(self, context, health_monitor): return self.create_resource('health_monitor', context, health_monitor, lb_db.HealthMonitor) def get_health_monitor(self, context, id, fields=None): return self.get_resource('health_monitor', context, id, fields, lb_db.HealthMonitor) def delete_health_monitor(self, context, id): return self.delete_resource('health_monitor', context, id, lb_db.HealthMonitor) def create_vip(self, context, vip): return self.create_resource('vip', context, vip, lb_db.Vip) def get_vip(self, context, id, fields=None): return self.get_resource( 'vip', context, id, fields, lb_db.Vip) def delete_vip(self, context, id): return self.delete_resource('vip', context, id, lb_db.Vip) def stats(self, context, pool_id): pass class RouterServiceInsertionTestCase(testlib_api.SqlTestCase, testlib_plugin.PluginSetupHelper): def setUp(self): super(RouterServiceInsertionTestCase, self).setUp() plugin = ( ""neutron.tests.unit.test_routerserviceinsertion."" ""RouterServiceInsertionTestPlugin"" ) # point config file to: neutron/tests/etc/neutron.conf.test self.config_parse() #just stubbing core plugin with LoadBalancer plugin self.setup_coreplugin(plugin) cfg.CONF.set_override('service_plugins', []) cfg.CONF.set_override('quota_router', -1, group='QUOTAS') # Ensure existing ExtensionManager is not used ext_mgr = extensions.PluginAwareExtensionManager( extensions_path, {constants.LOADBALANCER: RouterServiceInsertionTestPlugin()} ) extensions.PluginAwareExtensionManager._instance = ext_mgr router.APIRouter() app = config.load_paste_app('extensions_test_app') self._api = extensions.ExtensionMiddleware(app, ext_mgr=ext_mgr) self._tenant_id = ""8c70909f-b081-452d-872b-df48e6c355d1"" self._service_type_id = _uuid() self._setup_core_resources() # FIXME (markmcclain): The test setup makes it difficult to add core # via the api. In the interim we'll create directly using the plugin with # the side effect of polluting the fixture database until tearDown. def tearDown(self): self.api = None super(RouterServiceInsertionTestCase, self).tearDown() def _setup_core_resources(self): core_plugin = neutron.manager.NeutronManager.get_plugin() self._network = core_plugin.create_network( q_context.get_admin_context(), { 'network': { 'tenant_id': self._tenant_id, 'name': 'test net', 'admin_state_up': True, 'shared': False, } } ) self._subnet = core_plugin.create_subnet( q_context.get_admin_context(), { 'subnet': { 'network_id': self._network['id'], 'name': 'test subnet', 'cidr': '192.168.1.0/24', 'ip_version': 4, 'gateway_ip': '192.168.1.1', 'allocation_pools': attributes.ATTR_NOT_SPECIFIED, 'dns_nameservers': attributes.ATTR_NOT_SPECIFIED, 'host_routes': attributes.ATTR_NOT_SPECIFIED, 'enable_dhcp': True, } } ) self._subnet_id = self._subnet['id'] def _do_request(self, method, path, data=None, params=None, action=None): content_type = 'application/json' body = None if data is not None: # empty dict is valid body = wsgi.Serializer().serialize(data, content_type) req = testlib_api.create_request( path, body, content_type, method, query_string=params) res = req.get_response(self._api) if res.status_code >= 400: raise webexc.HTTPClientError(detail=res.body, code=res.status_code) if res.status_code != webexc.HTTPNoContent.code: return res.json def _router_create(self, service_type_id=None): data = { ""router"": { ""tenant_id"": self._tenant_id, ""name"": ""test"", ""admin_state_up"": True, ""service_type_id"": service_type_id, } } res = self._do_request('POST', _get_path('routers'), data) return res['router'] def test_router_create_no_service_type_id(self): router = self._router_create() self.assertIsNone(router.get('service_type_id')) def test_router_create_with_service_type_id(self): router = self._router_create(self._service_type_id) self.assertEqual(router['service_type_id'], self._service_type_id) def test_router_get(self): router = self._router_create(self._service_type_id) res = self._do_request('GET', _get_path('routers/{0}'.format(router['id']))) self.assertEqual(res['router']['service_type_id'], self._service_type_id) def _test_router_update(self, update_service_type_id): router = self._router_create(self._service_type_id) router_id = router['id'] new_name = _uuid() data = { ""router"": { ""name"": new_name, ""admin_state_up"": router['admin_state_up'], } } if update_service_type_id: data[""router""][""service_type_id""] = _uuid() with testlib_api.ExpectedException( webexc.HTTPClientError) as ctx_manager: res = self._do_request( 'PUT', _get_path('routers/{0}'.format(router_id)), data) self.assertEqual(ctx_manager.exception.code, 400) else: res = self._do_request( 'PUT', _get_path('routers/{0}'.format(router_id)), data) res = self._do_request( 'GET', _get_path('routers/{0}'.format(router['id']))) self.assertEqual(res['router']['name'], new_name) def test_router_update_with_service_type_id(self): self._test_router_update(True) def test_router_update_without_service_type_id(self): self._test_router_update(False) def test_router_delete(self): router = self._router_create(self._service_type_id) self._do_request( 'DELETE', _get_path('routers/{0}'.format(router['id']))) def _test_lb_setup(self): router = self._router_create(self._service_type_id) self._router_id = router['id'] def _test_pool_setup(self): self._test_lb_setup() def _test_health_monitor_setup(self): self._test_lb_setup() def _test_vip_setup(self): self._test_pool_setup() pool = self._pool_create(self._router_id) self._pool_id = pool['id'] def _create_resource(self, res, data): resp = self._do_request('POST', _get_path('lb/{0}s'.format(res)), data) return resp[res] def _pool_create(self, router_id=None): data = { ""pool"": { ""tenant_id"": self._tenant_id, ""name"": ""test"", ""protocol"": ""HTTP"", ""subnet_id"": self._subnet_id, ""lb_method"": ""ROUND_ROBIN"", ""router_id"": router_id } } return self._create_resource('pool', data) def _pool_update_attrs(self, pool): uattr = {} fields = [ 'name', 'description', 'lb_method', 'health_monitors', 'admin_state_up' ] for field in fields: uattr[field] = pool[field] return uattr def _health_monitor_create(self, router_id=None): data = { ""health_monitor"": { ""tenant_id"": self._tenant_id, ""type"": ""HTTP"", ""delay"": 1, ""timeout"": 1, ""max_retries"": 1, ""router_id"": router_id } } return self._create_resource('health_monitor', data) def _health_monitor_update_attrs(self, hm): uattr = {} fields = ['delay', 'timeout', 'max_retries'] for field in fields: uattr[field] = hm[field] return uattr def _vip_create(self, router_id=None): data = { ""vip"": { ""tenant_id"": self._tenant_id, ""name"": ""test"", ""protocol"": ""HTTP"", ""protocol_port"": 80, ""subnet_id"": self._subnet_id, ""pool_id"": self._pool_id, ""address"": ""192.168.1.102"", ""connection_limit"": 100, ""admin_state_up"": True, ""router_id"": router_id } } return self._create_resource('vip', data) def _vip_update_attrs(self, vip): uattr = {} fields = [ 'name', 'description', 'pool_id', 'connection_limit', 'admin_state_up' ] for field in fields: uattr[field] = vip[field] return uattr def _test_resource_create(self, res): getattr(self, ""_test_{0}_setup"".format(res))() obj = getattr(self, ""_{0}_create"".format(res))(self._router_id) self.assertEqual(obj['router_id'], self._router_id) def _test_resource_update(self, res, update_router_id, update_attr, update_value): getattr(self, ""_test_{0}_setup"".format(res))() obj = getattr(self, ""_{0}_create"".format(res))(self._router_id) uattrs = getattr(self, ""_{0}_update_attrs"".format(res))(obj) uattrs[update_attr] = update_value data = {res: uattrs} if update_router_id: uattrs['router_id'] = self._router_id with testlib_api.ExpectedException( webexc.HTTPClientError) as ctx_manager: self._do_request( 'PUT', _get_path('lb/{0}s/{1}'.format(res, obj['id'])), data) self.assertEqual(ctx_manager.exception.code, 400) else: self._do_request( 'PUT', _get_path('lb/{0}s/{1}'.format(res, obj['id'])), data) updated = self._do_request( 'GET', _get_path('lb/{0}s/{1}'.format(res, obj['id']))) self.assertEqual(updated[res][update_attr], update_value) def _test_resource_delete(self, res, with_router_id): getattr(self, ""_test_{0}_setup"".format(res))() func = getattr(self, ""_{0}_create"".format(res)) if with_router_id: obj = func(self._router_id) else: obj = func() self._do_request( 'DELETE', _get_path('lb/{0}s/{1}'.format(res, obj['id']))) def test_pool_create(self): self._test_resource_create('pool') def test_pool_update_with_router_id(self): self._test_resource_update('pool', True, 'name', _uuid()) def test_pool_update_without_router_id(self): self._test_resource_update('pool', False, 'name', _uuid()) def test_pool_delete_with_router_id(self): self._test_resource_delete('pool', True) def test_pool_delete_without_router_id(self): self._test_resource_delete('pool', False) def test_health_monitor_create(self): self._test_resource_create('health_monitor') def test_health_monitor_update_with_router_id(self): self._test_resource_update('health_monitor', True, 'timeout', 2) def test_health_monitor_update_without_router_id(self): self._test_resource_update('health_monitor', False, 'timeout', 2) def test_health_monitor_delete_with_router_id(self): self._test_resource_delete('health_monitor', True) def test_health_monitor_delete_without_router_id(self): self._test_resource_delete('health_monitor', False) def test_vip_create(self): self._test_resource_create('vip') def test_vip_update_with_router_id(self): self._test_resource_update('vip', True, 'name', _uuid()) def test_vip_update_without_router_id(self): self._test_resource_update('vip', False, 'name', _uuid()) def test_vip_delete_with_router_id(self): self._test_resource_delete('vip', True) def test_vip_delete_without_router_id(self): self._test_resource_delete('vip', False) ",,487,0
openstack%2Fglance-specs~master~I47d13439709ed895925fea27962350de60fcf381,openstack/glance-specs,master,I47d13439709ed895925fea27962350de60fcf381,Spec for Swift Store to use Multiple Container,MERGED,2014-09-26 21:59:20.000000000,2014-12-10 19:19:48.000000000,2014-12-10 19:19:47.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 7665}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8959}, {'_account_id': 11642}, {'_account_id': 11864}]","[{'number': 1, 'created': '2014-09-26 21:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/8aaca8913fe1275f2d8a96d7744ef013713ce84c', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 2, 'created': '2014-09-26 22:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/665f3751c58de19c52ac2e21ccef15df06bc262c', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 3, 'created': '2014-09-29 15:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/b53d996680f45716a426436532a50d7aeaba9b56', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 4, 'created': '2014-10-03 15:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/8d3b46b89b3ad51fcf20189372be850a1fa2f125', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 5, 'created': '2014-10-08 20:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/4871715bc758a84b9794a387664433cef1582e12', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 6, 'created': '2014-10-14 19:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/b41460de1f647df40796767ed578d602b6d257af', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 7, 'created': '2014-10-22 20:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/32d41d97876f343f1cfb42af68792b0b0d6a4815', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 8, 'created': '2014-10-22 20:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/c5e2bba232445a16099d2dafee2bb8852a136b0a', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 9, 'created': '2014-10-24 17:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/f999b7eeac0b42123004a1f1b1b5352af9499f5c', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 10, 'created': '2014-10-28 15:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/71dec43f9106a670a04ea7fc9054fe089979d14d', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 11, 'created': '2014-10-30 15:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/f321c1ace313147f5d10a0a6ad8328bd1b26ad58', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}, {'number': 12, 'created': '2014-11-25 18:36:44.000000000', 'files': ['specs/kilo/swift-store-multiple-containers.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/2e3f65883aefce3783701ab92d24f46947aa8228', 'message': 'Spec for Swift Store to use Multiple Container\n\nThis spec focuses on using multiple containers in glance swift store\n\nCorresponding blueprint is below:\nhttps://blueprints.launchpad.net/glance/+spec/swift-store-multiple-containers\n\nChange-Id: I47d13439709ed895925fea27962350de60fcf381\n'}]",63,124522,2e3f65883aefce3783701ab92d24f46947aa8228,84,11,12,8158,,,0,"Spec for Swift Store to use Multiple Container

This spec focuses on using multiple containers in glance swift store

Corresponding blueprint is below:
https://blueprints.launchpad.net/glance/+spec/swift-store-multiple-containers

Change-Id: I47d13439709ed895925fea27962350de60fcf381
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/22/124522/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/swift-store-multiple-containers.rst'],1,8aaca8913fe1275f2d8a96d7744ef013713ce84c,bp/is,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Glance Swift Store to use Multiple Containers for Storing Images ========================================== Glance, when configured to use Swift store in Single Tenant Mode, stores images in one container as indicated by the configuration option, swift_store_container. This approach of storing images in ONE container is subject to performance bottleneck. Storing images in one container is prone to Swift rate-limiting on containers . Swift is equipped with container rate-limiting that can throttle concurrent POST, PUT and DELETE operations in a single container. This becomes a serious issue in a large scale deployments especially when coupled with smaller segment sizes. Problem description =================== Swift is known to be capable of throttling incoming traffic[1]. The very fact that swift can throttle write operations on containers presents a performance bottleneck and hence large scale deployments need an alternative to get around Swift throttling. When container rate-limiting is enabled for a Swift cluster, it throttles concurrent POST, PUT and DELETE requests after a certain configurable rate. This directly translates to a limit on concurrent image creation and deletion operations for Glance before experiencing performance degradation. Proposed change =============== To reduce/overcome the performance bottleneck, we propose the use of multiple containers for storing images in Single Tenant Mode (this change will not affect Multi Tenant Mode because that setup stores each image in its own container). This leads to increased concurrency of image creation and deletion operations. There are four major aspects to this change: - Container Selection - determining what container an image should go into - Container Creation - creating the new containers - Re-distribution of Existing Images - moving images from old to new containers - Database Migration - updating image locations as per new containers **1) Container Selection:** This change proposes to select containers based on image uuid. Images will be stored in multiple containers in order to avoid throttling during multiple simultaneous uploads. The first N characters of the image UUID (where N is a configurable integer between 1 and 32 with the default value of 2) will be used to determine which container the image will be uploaded to. With the default value of the first two characters used, this gives 16*16=256 unique containers. At N=1, the smallest valid value for this configuration, 16 containers will be created and used for storing images. The containers will be named after the value set for swift_store_container with the first N chars of the image UUID as the suffix. The number of containers can be easily increased or decreased by changing N in the configuration. However, a new set of containers will be created with every change to this configuration. Images created after a configuration change will go into new containers while older images remain in their previous containers. The older images do not need to necessarily be moved into new containers as their locations would still point to the existing older container they are stored in. However, if one wishes to move the older images to new containers, they may do so by re-distributing the images, which is described later in this section. **2) Container Creation:** Glance ships with a configuration option to dynamically create the container, if it doesn't exist already at the time of uploading image data to Swift. This is indicated by configuration option, swift_store_create_container_on_put. If dynamic container creation is enabled, Glance would automatically create each container when the appropriate container for that image is not found. However, if the config option for dynamic container creation is disabled, image uploads would fail if the appropriate containers are not created manually by the deployer. This behavior is consistent with how Glance currently handles missing containers if the config option to create them is not enabled. **3) Re-distribution of Existing Images:** This spec will not provide code or scripts migrate existing images since lazy loading is an existing effective method of distributing new images. However, if one wants to migrate images here is the process: Once the use of multiple containers is enabled or the number of containers is changed, all previously created images would remain in the older container(s). If desired, older images can be moved to new containers appropriately. This can be achieved as a separate batch job that can be run as and when desired. Subject to the number of older images, redistributing images may involve significant movement of data in the Swift cluster. Hence, it would be helpful to achieve this in phases and in a non-intrusive fashion. Once the images are re-distributed, their image locations need to be updated as well. **4) Database Migration:** If images are re-distributed by operator choice, image location of each re-distributed image must be updated to reflect the new container name. This requires a db migration to replace the old container name in the location with the new container name as per the image id. This migration can go hand-in-hand with re-distribution. **Scope of this spec:** Of the four aspects discussed above, this specification would only addresses container creation and selection while leaving re-distribution and the required db migrations out, which can be implemented as another concerted effort. Alternatives ------------ 1) Instead of using image id as the basis for container selection, one can use other basis like tenant id, which would keep all images belonging to a certain tenant in the same container. While there are may be many other bases possible, using image id provides an easier way to correlate an image to its container. 2) An alternative to creating containers could be to allow the API to create all the required containers while it boots up. This requires the API to know all possible containers before hand, which may or may not be possible depending upon the container selection basis chosen. This places a certain limitation on the kind of bases one may opt for. Hence, going with dynamic container creation will eliminate this limitation as both container selection and creation could be dynamic. Also, dynamic container creation is in-line with current Glance behavior. Data model impact ----------------- New containers will be created and used for storing images. However, this does not have any impact on the Glance image data model itself. **Database migrations**: No database migrations are required. The code supporting multiple containers would only affect the uploading of new images, determining which container they belong to based on uuid. For existing images (those uploaded before support for multiple containers), the image already contains a valid location in its metadata. Essentially, new containers will be populated by lazy loading: When an image is uploading, it will first check through a HEAD request if the appropriate container exists for that image based on its UUID, and if the container does not exist then the container will be created immediately with a PUT request. This image will then be the first image stored in that particular container. REST API impact --------------- None Security impact --------------- Given the scope of this spec, where image data is not being re-distributed among new containers and no migrations are being run, there is minimal to no security impact introduced. Notifications impact -------------------- This change only impacts the image location property among all the image properties. And, since image location is not included in notifications, there should be no impact to Glance notifications. Other end user impact --------------------- As image location is not accessible to either the end-user or from Glance client, there should be no end-user impact. Performance Impact ------------------ The use of multiple containers will reduce throttling when multiple images are uploaded simultaneously. This leads to increased concurrency of image creation and deletion operations in large scale deployments. Container selection would take place for every image upload request and thus adds an extra operation to the current set of operations to upload image data. However, selecting a container would be a simple substring operation to fetch the first few characters of an image id. The time incurred in determining the container would be significantly smaller than the time incurred to upload image data. Overall, the performance impact of container selection should be very minimal. Container creation is a conditional operation that would take place only when the container is not present already. This would occur once for each combination of N characters as specified in the configuration. For example, the default configuration option is that the first 2 characters of the image UUID are used to select an appropriate container, leading to a total of 256 containers which should be optimal for mid size deployments. We found that in a large scale deployment, 4096 containers would be preferred over 256 containers if smaller segment sizes were chosen. The time incurred in creating a new container is significantly smaller than the time incurred in upload image data. Hence, the overall performance impact in image uploads should be minimal. Other deployer impact --------------------- This change would begin taking effect upon enabling multiple containers in a configuration. When enabled, new images would be uploaded to new containers, while existing images would remain in their previously assigned container. This change is forwards and backwards compatible, such that the deployer can choose to enable or disable multiple containers at any time and images will still upload and download correctly. Deployers should note that if their deployment limits the total number of containers per account, the seed for the total number of containers should be set such that this limit is not hit. New configuration options in *glance-api.conf* **swift_store_use_multiple_containers** - default = False - A boolean value that determines if single-tenant store should use multiple containers for storing images. Used only when swift_store_multi_tenant is disabled. **swift_store_multiple_containers_seed** - default = 2 - An integer value between 1 and 32 representing the number of characters used from the image UUID to determine which container the image will be placed. Used only when swift_store_use_multiple_containers is enabled. The total number of containers that will be used is equal to 16^N, or 16^2=256 by default. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: hemanth-makkapati Other contributors: ben-roble Work Items ---------- 1) Implement new config options in Swift store driver 2) Implement container selection in Swift store driver 3) Implement unit, functional, and integration tests 4) Change glance-api sample conf in glance repo Points to note: - All code changes would be limited to glance_store module. - Image download code wouldn't require any changes. - Both manifest and segments would go into the same container. Dependencies ============ None Testing ======= No tempest tests needed Documentation Impact ==================== * Document new configuration options References ========== [1] http://docs.openstack.org/developer/swift/ratelimit.html#configuration ",,290,0
openstack%2Fdevstack~master~Ia097ac9a76b3242ed6e62b11ca64c7ac7680b97c,openstack/devstack,master,Ia097ac9a76b3242ed6e62b11ca64c7ac7680b97c,Remove heat_stack_owner role,MERGED,2014-12-04 10:46:09.000000000,2014-12-10 18:52:01.000000000,2014-12-09 18:56:32.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 6172}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-04 10:46:09.000000000', 'files': ['lib/heat'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8b469c1c5e36047a9e5a80e040f137957bdb8d66', 'message': 'Remove heat_stack_owner role\n\nSince https://review.openstack.org/#/c/128509/ heat no longer requires\nthe ""heat_stack_owner"" role by default, as we now delegate all roles\nvia the trust.  So remove the now unnecessary role creation and assignment\nfrom lib/heat.\n\nChange-Id: Ia097ac9a76b3242ed6e62b11ca64c7ac7680b97c\n'}]",0,139009,8b469c1c5e36047a9e5a80e040f137957bdb8d66,14,7,1,4328,,,0,"Remove heat_stack_owner role

Since https://review.openstack.org/#/c/128509/ heat no longer requires
the ""heat_stack_owner"" role by default, as we now delegate all roles
via the trust.  So remove the now unnecessary role creation and assignment
from lib/heat.

Change-Id: Ia097ac9a76b3242ed6e62b11ca64c7ac7680b97c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/09/139009/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/heat'],1,8b469c1c5e36047a9e5a80e040f137957bdb8d66,heat_no_stack_owner,," # heat_stack_owner role is given to users who create Heat stacks, # it's the default role used by heat to delegate to the heat service # user (for performing deferred operations via trusts), see heat.conf local heat_owner_role=$(get_or_create_role ""heat_stack_owner"") # Give the role to the demo and admin users so they can create stacks # in either of the projects created by devstack get_or_add_user_role $heat_owner_role demo demo get_or_add_user_role $heat_owner_role admin demo get_or_add_user_role $heat_owner_role admin admin",0,11
openstack%2Fcliff~master~If880bc3e3a62e8c0b70f4985d81d99ffc35f761e,openstack/cliff,master,If880bc3e3a62e8c0b70f4985d81d99ffc35f761e,Update cmd2 version to prevent `which` errors,ABANDONED,2014-12-09 20:55:09.000000000,2014-12-10 18:45:30.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 8736}, {'_account_id': 10068}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-09 20:55:09.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cliff/commit/a9431812c09a24931af7363ee5df6c93b8ef0b7f', 'message': ""Update cmd2 version to prevent `which` errors\n\nWhen the `which` executable is missing, cmd2 will throw exceptions that\nbubble up to consumers of cliff's API.\n\nThis change updates cmd2 to a newer version that fixes this behavior.\n\nChange-Id: If880bc3e3a62e8c0b70f4985d81d99ffc35f761e\nCloses-Bug: #1379055\n""}]",0,140474,a9431812c09a24931af7363ee5df6c93b8ef0b7f,6,5,1,12892,,,0,"Update cmd2 version to prevent `which` errors

When the `which` executable is missing, cmd2 will throw exceptions that
bubble up to consumers of cliff's API.

This change updates cmd2 to a newer version that fixes this behavior.

Change-Id: If880bc3e3a62e8c0b70f4985d81d99ffc35f761e
Closes-Bug: #1379055
",git fetch https://review.opendev.org/openstack/cliff refs/changes/74/140474/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a9431812c09a24931af7363ee5df6c93b8ef0b7f,bug/1379055,cmd2>=0.6.8,cmd2>=0.6.7,1,1
openstack%2Foslo.utils~master~Ib891154d187728c3bc7181736e4859352bb98241,openstack/oslo.utils,master,Ib891154d187728c3bc7181736e4859352bb98241,Add deprecation + reflection auto documentation,ABANDONED,2014-12-08 19:46:15.000000000,2014-12-10 18:34:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-08 19:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/f71d443df32dd8b93b8ca23cb6904417c6ed3267', 'message': 'Add deprecation + reflection auto documentation\n\nChange-Id: Ib891154d187728c3bc7181736e4859352bb98241\n'}, {'number': 2, 'created': '2014-12-08 22:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/bf5ed57a16c1301b66e178891d1251a6bcd170ef', 'message': 'Add deprecation + reflection auto documentation\n\nChange-Id: Ib891154d187728c3bc7181736e4859352bb98241\n'}, {'number': 3, 'created': '2014-12-08 22:41:02.000000000', 'files': ['doc/source/api/deprecation.rst', 'doc/source/api/reflection.rst', 'oslo/utils/reflection.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/9077c134a16dcd24c737be0d64073296485d6fd2', 'message': 'Add deprecation + reflection auto documentation\n\nChange-Id: Ib891154d187728c3bc7181736e4859352bb98241\n'}]",0,140129,9077c134a16dcd24c737be0d64073296485d6fd2,6,1,3,1297,,,0,"Add deprecation + reflection auto documentation

Change-Id: Ib891154d187728c3bc7181736e4859352bb98241
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/29/140129/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/api/deprecation.rst', 'doc/source/api/reflection.rst']",2,f71d443df32dd8b93b8ca23cb6904417c6ed3267,,============ reflection ============ .. automodule:: oslo.utils.reflection :members: ,,12,0
openstack%2Fnova~master~I1437b2a7d5a62615b0099114ed1b5b1110f56de2,openstack/nova,master,I1437b2a7d5a62615b0099114ed1b5b1110f56de2,libvirt: Fixes live migration for volume backed instances,MERGED,2014-11-17 20:41:55.000000000,2014-12-10 18:25:29.000000000,2014-12-10 16:32:06.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2243}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 6802}, {'_account_id': 7746}, {'_account_id': 8802}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13630}]","[{'number': 1, 'created': '2014-11-17 20:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4306144eb68b130c103734fdd34fc63aab97ca1b', 'message': 'Fixes live migration for volume backed instances\n\nLive migration fails for volume backed instances in LibvirtDriver\nbecause _is_shared_block_storage() incorrectly identifies volume\nbacked disks as local. This is fixed by passing the block_device_info\nparameter to get_instance_disk_info, which allows for correct\nfiltering of volume backed disks.\n\nChange-Id: I1437b2a7d5a62615b0099114ed1b5b1110f56de2\nCloses-bug: 1392773\n'}, {'number': 2, 'created': '2014-11-17 20:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71438fcdcf2791559aa8f4d37f6650bf4e8be899', 'message': 'Fixes live migration for volume backed instances\n\nLive migration fails for volume backed instances in LibvirtDriver\nbecause _is_shared_block_storage() incorrectly identifies volume\nbacked disks as local. This is fixed by passing the block_device_info\nparameter to get_instance_disk_info, which allows for correct\nfiltering of volume backed disks.\n\nChange-Id: I1437b2a7d5a62615b0099114ed1b5b1110f56de2\nCloses-bug: 1392773\n'}, {'number': 3, 'created': '2014-12-01 17:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14f361bee70778ee627ff5d05a93c8ab458b860a', 'message': 'Fixes live migration for volume backed instances\n\nLive migration fails for volume backed instances in LibvirtDriver\nbecause _is_shared_block_storage() incorrectly identifies volume\nbacked disks as local. This is fixed by passing the block_device_info\nparameter to get_instance_disk_info, which allows for correct\nfiltering of volume backed disks.\n\nChange-Id: I1437b2a7d5a62615b0099114ed1b5b1110f56de2\nCloses-bug: 1392773\n'}, {'number': 4, 'created': '2014-12-02 19:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28e7ca2f8504aa7554697fc8937c5c3fd0ffd89b', 'message': 'Fixes live migration for volume backed instances\n\nLive migration fails for volume backed instances in LibvirtDriver\nbecause _is_shared_block_storage() incorrectly identifies volume\nbacked disks as local. This is fixed by passing the block_device_info\nparameter to get_instance_disk_info, which allows for correct\nfiltering of volume backed disks.\n\nChange-Id: I1437b2a7d5a62615b0099114ed1b5b1110f56de2\nCloses-bug: 1392773\n'}, {'number': 5, 'created': '2014-12-08 17:02:54.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ad7e17e19b9809306b0b96ae7aa9cdfda91fcbb', 'message': 'libvirt: Fixes live migration for volume backed instances\n\nLive migration fails for volume backed instances in LibvirtDriver\nbecause _is_shared_block_storage() incorrectly identifies volume\nbacked disks as local. This is fixed by passing the block_device_info\nparameter to get_instance_disk_info, which allows for correct\nfiltering of volume backed disks.\n\nChange-Id: I1437b2a7d5a62615b0099114ed1b5b1110f56de2\nCloses-bug: 1392773\n'}]",12,135074,6ad7e17e19b9809306b0b96ae7aa9cdfda91fcbb,63,15,5,7746,,,0,"libvirt: Fixes live migration for volume backed instances

Live migration fails for volume backed instances in LibvirtDriver
because _is_shared_block_storage() incorrectly identifies volume
backed disks as local. This is fixed by passing the block_device_info
parameter to get_instance_disk_info, which allows for correct
filtering of volume backed disks.

Change-Id: I1437b2a7d5a62615b0099114ed1b5b1110f56de2
Closes-bug: 1392773
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/135074/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,4306144eb68b130c103734fdd34fc63aab97ca1b,bug/1392773," self._is_shared_block_storage(instance, dest_check_data, block_device_info)}) def _is_shared_block_storage(self, instance, dest_check_data, block_device_info): self.get_instance_disk_info(instance['name'], block_device_info)))):"," self._is_shared_block_storage(instance, dest_check_data)}) def _is_shared_block_storage(self, instance, dest_check_data): self.get_instance_disk_info(instance['name'])))):",6,3
openstack%2Fneutron-vpnaas~master~Ib3280c1678038e7d8000c4a9f5fef093cf6b5f6d,openstack/neutron-vpnaas,master,Ib3280c1678038e7d8000c4a9f5fef093cf6b5f6d,Move classes out of l3_agent.py,ABANDONED,2014-12-10 17:49:37.000000000,2014-12-10 18:25:07.000000000,,"[{'_account_id': 4694}, {'_account_id': 6659}, {'_account_id': 7448}]","[{'number': 1, 'created': '2014-12-10 17:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/c805031ccac41db7ec6eb0b9a583bb054cb1b06a', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: Ib3280c1678038e7d8000c4a9f5fef093cf6b5f6d\nRelates-to: https://review.openstack.org/#/c/130300/\n""}, {'number': 2, 'created': '2014-12-10 18:06:44.000000000', 'files': ['neutron_vpnaas/tests.skip/unit/services/vpn/test_vpn_agent.py', 'neutron_vpnaas/services/vpn/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b39def41d6606bcfdbe27903ac9f277695178e15', 'message': ""Move classes out of l3_agent.py\n\nThe file l3_agent.py has become too large.  This patch is a simple\npure refactor to move some of the functionality in to other files\nwhere things aren't too tangled up.  There is no functional change\nwith this patch and I avoided gratuitous other fixups in this patch in\norder to make it easier to review.\n\nI plan to follow up on the new l3_dvr and l3_agent_router modules with\nmore restructuring in the near future.\n\nPartially-Implements: bp restructure-l3-agent\n\nChange-Id: Ib3280c1678038e7d8000c4a9f5fef093cf6b5f6d\nRelates-to: https://review.openstack.org/#/c/130300/\n""}]",0,140788,b39def41d6606bcfdbe27903ac9f277695178e15,3,3,2,1131,,,0,"Move classes out of l3_agent.py

The file l3_agent.py has become too large.  This patch is a simple
pure refactor to move some of the functionality in to other files
where things aren't too tangled up.  There is no functional change
with this patch and I avoided gratuitous other fixups in this patch in
order to make it easier to review.

I plan to follow up on the new l3_dvr and l3_agent_router modules with
more restructuring in the near future.

Partially-Implements: bp restructure-l3-agent

Change-Id: Ib3280c1678038e7d8000c4a9f5fef093cf6b5f6d
Relates-to: https://review.openstack.org/#/c/130300/
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/88/140788/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests.skip/unit/services/vpn/test_vpn_agent.py', 'neutron_vpnaas/services/vpn/agent.py']",2,c805031ccac41db7ec6eb0b9a583bb054cb1b06a,bp/restructure-l3-agent,from neutron.agent.l3 import agentclass VPNAgent(agent.L3NATAgentWithStateReport): agent.main(,from neutron.agent import l3_agentclass VPNAgent(l3_agent.L3NATAgentWithStateReport): l3_agent.main(,14,14
openstack%2Fnova~master~I23ccad0460f38db5314180fda865153bd8784c01,openstack/nova,master,I23ccad0460f38db5314180fda865153bd8784c01,Remove unused db.api.fixed_ip_get_by_address_detailed,MERGED,2014-11-13 16:01:17.000000000,2014-12-10 18:21:26.000000000,2014-12-10 16:33:08.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-13 16:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/144f31296fd3a71a7c3964378d0d23f46404a1e4', 'message': 'Remove unused db.api.fixed_up_get_by_address_detailed\n\nChange-Id: I23ccad0460f38db5314180fda865153bd8784c01\n'}, {'number': 2, 'created': '2014-12-08 16:05:25.000000000', 'files': ['nova/tests/functional/v3/test_fixed_ips.py', 'nova/tests/functional/test_api_samples.py', 'nova/tests/unit/api/openstack/compute/contrib/test_fixed_ips.py', 'nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e6700bbc74056d72ea0f2256c79fdb1414cf0a5f', 'message': 'Remove unused db.api.fixed_ip_get_by_address_detailed\n\nChange-Id: I23ccad0460f38db5314180fda865153bd8784c01\n'}]",2,134271,e6700bbc74056d72ea0f2256c79fdb1414cf0a5f,28,12,2,9555,,,0,"Remove unused db.api.fixed_ip_get_by_address_detailed

Change-Id: I23ccad0460f38db5314180fda865153bd8784c01
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/134271/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_fixed_ips.py', 'nova/tests/unit/integrated/v3/test_fixed_ips.py', 'nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py', 'nova/tests/unit/integrated/test_api_samples.py']",6,144f31296fd3a71a7c3964378d0d23f46404a1e4,db/prune_api,," def fake_fixed_ip_get_by_address_detailed(context, address): network = {'id': 1, 'cidr': ""192.168.1.0/24""} host = {'host': ""host"", 'hostname': 'openstack'} for fixed_ip in fake_fixed_ips: if fixed_ip['address'] == address: return (fixed_ip, network, host) raise exception.FixedIpNotFoundForAddress(address=address) self.stubs.Set(db, ""fixed_ip_get_by_address_detailed"", fake_fixed_ip_get_by_address_detailed)",0,111
openstack%2Fopenstack-ansible~master~Ifaa0fa5719f79180610b4a63d590ca8bc681f87d,openstack/openstack-ansible,master,Ifaa0fa5719f79180610b4a63d590ca8bc681f87d,Changed the container interaction process,MERGED,2014-12-04 23:26:16.000000000,2014-12-10 18:18:41.000000000,2014-12-10 18:18:41.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-04 23:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/08bfea644d08a00dcb246db11033ae28cf4d096b', 'message': 'Changed the container interaction process\n\nThis changes the way that containers are interacted with. With this\nchange, container actions are deletgated to the host instead of looping\nthrough the hacky mess that we were doing. This change will make it\nso that the entire container process is faster.\n\nChange-Id: Ifaa0fa5719f79180610b4a63d590ca8bc681f87d\n'}, {'number': 2, 'created': '2014-12-05 02:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c948d0b38994c1a3e7e89165dad92c8bdaf20e4a', 'message': 'Changed the container interaction process\n\nThis changes the way that containers are interacted with. With this\nchange, container actions are deletgated to the host instead of looping\nthrough the hacky mess that we were doing. This change will make it\nso that the entire container process is faster.\n\nChange-Id: Ifaa0fa5719f79180610b4a63d590ca8bc681f87d\n'}, {'number': 3, 'created': '2014-12-08 15:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a7e900276dafe447ee3bcca8451ac0a7e8252624', 'message': 'Changed the container interaction process\n\nThis changes the way that containers are interacted with. With this\nchange, container actions are deletgated to the host instead of looping\nthrough the hacky mess that we were doing. This change will make it\nso that the entire container process is faster.\n\nThis also removes the needs for the ""/openstack/monitoring"" directory which\nwas held over cruft from long ago. This should address the race condition\nwhen delegating to a host and the monitoring directory attempts to be created\nat the same time on the same host.\n\nChange-Id: Ifaa0fa5719f79180610b4a63d590ca8bc681f87d\n'}, {'number': 4, 'created': '2014-12-09 22:16:43.000000000', 'files': ['rpc_deployment/roles/container_destroy/tasks/main.yml', 'rpc_deployment/playbooks/setup/destroy-containers.yml', 'rpc_deployment/roles/container_create/tasks/main.yml', 'rpc_deployment/roles/container_setup/tasks/container_setup.yml', 'rpc_deployment/roles/container_setup/tasks/main.yml', 'rpc_deployment/library/lxc', 'rpc_deployment/roles/container_restart/tasks/main.yml', 'rpc_deployment/playbooks/setup/containers-setup.yml', 'rpc_deployment/vars/config_vars/container_interfaces.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fea671ec1692617d0c64c8b3d27df530bf58c004', 'message': 'Changed the container interaction process\n\nThis changes the way that containers are interacted with. With this\nchange, container actions are deletgated to the host instead of looping\nthrough the hacky mess that we were doing. This change will make it\nso that the entire container process is faster.\n\nThis also removes the needs for the ""/openstack/monitoring"" directory which\nwas held over cruft from long ago. This should address the race condition\nwhen delegating to a host and the monitoring directory attempts to be created\nat the same time on the same host.\n\nCloses-Bug: #1399427\nChange-Id: Ifaa0fa5719f79180610b4a63d590ca8bc681f87d\n'}]",0,139264,fea671ec1692617d0c64c8b3d27df530bf58c004,22,6,4,7353,,,0,"Changed the container interaction process

This changes the way that containers are interacted with. With this
change, container actions are deletgated to the host instead of looping
through the hacky mess that we were doing. This change will make it
so that the entire container process is faster.

This also removes the needs for the ""/openstack/monitoring"" directory which
was held over cruft from long ago. This should address the race condition
when delegating to a host and the monitoring directory attempts to be created
at the same time on the same host.

Closes-Bug: #1399427
Change-Id: Ifaa0fa5719f79180610b4a63d590ca8bc681f87d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/64/139264/4 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/roles/container_destroy/tasks/main.yml', 'rpc_deployment/playbooks/setup/destroy-containers.yml', 'rpc_deployment/roles/container_create/tasks/main.yml', 'rpc_deployment/roles/container_setup/tasks/container_setup.yml', 'rpc_deployment/roles/container_setup/tasks/main.yml', 'rpc_deployment/library/lxc', 'rpc_deployment/roles/container_restart/tasks/main.yml', 'rpc_deployment/playbooks/setup/containers-setup.yml', 'rpc_deployment/vars/config_vars/container_interfaces.yml']",9,08bfea644d08a00dcb246db11033ae28cf4d096b,bug/1399427,default_interfaces: | # LXC interface # Load any additional configs auto {{ container_network['container_interface'] }} iface {{ container_network['container_interface'] }} inet static address {{ container_address }} netmask {{ container_network['container_netmask']|default(container_netmask) }},container_interface: | auto {{ hostvars[item]['container_network']['container_interface'] }} iface {{ hostvars[item]['container_network']['container_interface'] }} inet static address {{ hostvars[item]['container_address'] }} netmask {{ hostvars[item]['container_network']['container_netmask']|default(hostvars[item]['container_netmask']) }},61,122
openstack%2Fnova-specs~master~I777cc98a10d82c0e3e28b8324aeaf56e7ff4c160,openstack/nova-specs,master,I777cc98a10d82c0e3e28b8324aeaf56e7ff4c160,cleanup: api-microversions spec,MERGED,2014-12-01 13:49:24.000000000,2014-12-10 18:14:17.000000000,2014-12-10 18:14:16.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5292}, {'_account_id': 5441}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-12-01 13:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/97246880398a45ffb6572e0bbe6b28b6bb4204bc', 'message': 'cleanup: api-microversions spec\n\nThe spec was using some unsuported formatting:\n\n* A list\n** This is not how to indent to the next level\n    * This is\n\nAlso, dropped the link to semver.org from the references as\nwe have decided to pursue an approach which does not use\nthat.\n\nChange-Id: I777cc98a10d82c0e3e28b8324aeaf56e7ff4c160\n'}, {'number': 2, 'created': '2014-12-01 13:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6f494f35eae180e288196df12c07ea9b7fc62ca0', 'message': 'cleanup: api-microversions spec\n\nThe spec was using some unsupported formatting:\n\n* A list\n** This is not how to indent to the next level\n    * This is\n\nAlso, dropped the link to semver.org from the references as\nwe have decided to pursue an approach which does not use\nthat.\n\nChange-Id: I777cc98a10d82c0e3e28b8324aeaf56e7ff4c160\n'}, {'number': 3, 'created': '2014-12-10 10:42:15.000000000', 'files': ['specs/kilo/approved/api-microversions.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c7c16f33a5a4d6be750b7f5c8229b86717b71145', 'message': 'cleanup: api-microversions spec\n\nThe spec was using some unsupported formatting:\n\n* A list\n** This is not how to indent to the next level\n    * This is\n\nAlso, dropped the link to semver.org from the references as\nwe have decided to pursue an approach which does not use\nthat.\n\nChange-Id: I777cc98a10d82c0e3e28b8324aeaf56e7ff4c160\n'}]",0,138065,c7c16f33a5a4d6be750b7f5c8229b86717b71145,16,5,3,9420,,,0,"cleanup: api-microversions spec

The spec was using some unsupported formatting:

* A list
** This is not how to indent to the next level
    * This is

Also, dropped the link to semver.org from the references as
we have decided to pursue an approach which does not use
that.

Change-Id: I777cc98a10d82c0e3e28b8324aeaf56e7ff4c160
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/65/138065/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/api-microversions.rst'],1,97246880398a45ffb6572e0bbe6b28b6bb4204bc,, * Easy to see in the code that you are about to break API compatibility. * Make it easy to make backwards compatible changes * Make it possible to make backwards incompatible changes * Minimise code duplication to minimise maintenance overhead,** Easy to see in the code that you are about to break API compatibility. ** Make it easy to make backwards compatible changes ** Make it possible to make backwards incompatible changes ** Minimise code duplication to minimise maintenance overhead* Semver http://semver.org * Links to mailing list or IRC discussions ,4,8
openstack%2Fironic-specs~master~I78de2fe97b7385a26693d22beb6c0c956a579b65,openstack/ironic-specs,master,I78de2fe97b7385a26693d22beb6c0c956a579b65,fix the filename for hardware-capabilities.rst,MERGED,2014-12-09 06:22:02.000000000,2014-12-10 18:14:00.000000000,2014-12-10 18:14:00.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 7882}]","[{'number': 1, 'created': '2014-12-09 06:22:02.000000000', 'files': ['specs/backlog/exposing-hardware-capabilities.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6aceb0802a9336235f949ddea3d5b6dcfe991a77', 'message': 'fix the filename for hardware-capabilities.rst\n\nThis spec file name did not match the blueprint title, and so the file\nis being renamed.\n\nChange-Id: I78de2fe97b7385a26693d22beb6c0c956a579b65\n'}]",0,140252,6aceb0802a9336235f949ddea3d5b6dcfe991a77,9,5,1,2889,,,0,"fix the filename for hardware-capabilities.rst

This spec file name did not match the blueprint title, and so the file
is being renamed.

Change-Id: I78de2fe97b7385a26693d22beb6c0c956a579b65
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/52/140252/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/exposing-hardware-capabilities.rst'],1,6aceb0802a9336235f949ddea3d5b6dcfe991a77,bp/title,,,0,0
openstack%2Fironic-specs~master~Ib94aa83a1611cd9528086bf97670abb32cfcce8d,openstack/ironic-specs,master,Ib94aa83a1611cd9528086bf97670abb32cfcce8d,Set blueprint link for drivers capabilities spec,MERGED,2014-12-09 08:26:21.000000000,2014-12-10 18:13:47.000000000,2014-12-10 18:13:46.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6618}]","[{'number': 1, 'created': '2014-12-09 08:26:21.000000000', 'files': ['specs/backlog/driver-capabilities.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2d2b51409bce1e879ef5e95028f4d252a35e1533', 'message': 'Set blueprint link for drivers capabilities spec\n\nChange-Id: Ib94aa83a1611cd9528086bf97670abb32cfcce8d\n'}]",0,140267,2d2b51409bce1e879ef5e95028f4d252a35e1533,8,4,1,10239,,,0,"Set blueprint link for drivers capabilities spec

Change-Id: Ib94aa83a1611cd9528086bf97670abb32cfcce8d
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/67/140267/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/driver-capabilities.rst'],1,2d2b51409bce1e879ef5e95028f4d252a35e1533,bp/link,https://blueprints.launchpad.net/ironic/+spec/driver-capabilities ,,2,0
openstack%2Ffuel-library~stable%2F6.0~Ib53038bc53846d14a6c7bf028c7b4e78eef56255,openstack/fuel-library,stable/6.0,Ib53038bc53846d14a6c7bf028c7b4e78eef56255,Use augeas instead of sysctl::value,MERGED,2014-12-10 14:41:32.000000000,2014-12-10 18:08:04.000000000,2014-12-10 18:08:04.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-12-10 14:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/17089195ed1014957b6b2bf497e982977c6d2eb6', 'message': ""Use augeas instead of sysctl::value\n\nWe don't actually need to execute 'sysctl -w' for\nnet.bridge.bridge-nf-call* sysctl keys since this can cause\npuppet errors if puppet tries to apply sysctl::value before bridge\nkernel module is loaded.\n\nSo we just need to make sure those sysctl keys are configured\nproperly in /etc/sysctl.conf file. When bridge kernel module is\nloaded by libvirt, it will set them to correct values itself.\n\nCloses-bug: #1401100\nChange-Id: Ib53038bc53846d14a6c7bf028c7b4e78eef56255\n""}, {'number': 2, 'created': '2014-12-10 15:17:42.000000000', 'files': ['deployment/puppet/openstack/manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b9cbfd233520e7f94ec35b018b4f2b799fa8dee7', 'message': ""Use augeas instead of sysctl::value\n\nWe don't actually need to execute 'sysctl -w' for\nnet.bridge.bridge-nf-call* sysctl keys since this can cause\npuppet errors if puppet tries to apply sysctl::value before bridge\nkernel module is loaded.\n\nSo we just need to make sure those sysctl keys are configured\nproperly in /etc/sysctl.conf file. When bridge kernel module is\nloaded by libvirt, it will set them to correct values itself.\n\nCloses-bug: #1401100\nChange-Id: Ib53038bc53846d14a6c7bf028c7b4e78eef56255\n""}]",0,140699,b9cbfd233520e7f94ec35b018b4f2b799fa8dee7,15,4,2,9387,,,0,"Use augeas instead of sysctl::value

We don't actually need to execute 'sysctl -w' for
net.bridge.bridge-nf-call* sysctl keys since this can cause
puppet errors if puppet tries to apply sysctl::value before bridge
kernel module is loaded.

So we just need to make sure those sysctl keys are configured
properly in /etc/sysctl.conf file. When bridge kernel module is
loaded by libvirt, it will set them to correct values itself.

Closes-bug: #1401100
Change-Id: Ib53038bc53846d14a6c7bf028c7b4e78eef56255
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/99/140699/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/compute.pp'],1,17089195ed1014957b6b2bf497e982977c6d2eb6,," augeas { 'sysctl-net.bridge.bridge-nf-call-arptables': context => '/files/etc/sysctl.conf', onlyif => ""get net.bridge.bridge-nf-call-arptables != '1'"", changes => ""set net.bridge.bridge-nf-call-arptables '1'"", before => Service['libvirt'], } augeas { 'sysctl-net.bridge.bridge-nf-call-iptables': context => '/files/etc/sysctl.conf', onlyif => ""get net.bridge.bridge-nf-call-iptables != '1'"", changes => ""set net.bridge.bridge-nf-call-iptables '1'"", before => Service['libvirt'], } augeas { 'sysctl-net.bridge.bridge-nf-call-ip6tables': context => '/files/etc/sysctl.conf', onlyif => ""get net.bridge.bridge-nf-call-ip6tables != '1'"", changes => ""set net.bridge.bridge-nf-call-ip6tables '1'"", before => Service['libvirt'], } "," sysctl::value { 'net.bridge.bridge-nf-call-arptables': value => '1', require => Service['libvirt'], } sysctl::value { 'net.bridge.bridge-nf-call-iptables': value => '1', require => Service['libvirt'], } sysctl::value { 'net.bridge.bridge-nf-call-ip6tables': value => '1', require => Service['libvirt'], }",16,9
openstack%2Fneutron-fwaas~master~Ibbca9ad8d2d6c3078bd94439b11d2af0d1450a03,openstack/neutron-fwaas,master,Ibbca9ad8d2d6c3078bd94439b11d2af0d1450a03,Fix python path to neutron_fwaas module,MERGED,2014-12-10 16:08:25.000000000,2014-12-10 18:04:29.000000000,2014-12-10 18:04:28.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 16:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/3a7d0f26508d2c9a284124af2d98883661dafb0d', 'message': 'Fix python path to neutron_fwaas module\n\nChange-Id: Ibbca9ad8d2d6c3078bd94439b11d2af0d1450a03\n'}, {'number': 2, 'created': '2014-12-10 16:34:03.000000000', 'files': ['neutron_fwaas/services/firewall/agents/varmour/varmour_router.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/4a885ed2aaf05ad48a071804bfbf8722766da193', 'message': 'Fix python path to neutron_fwaas module\n\nChange-Id: Ibbca9ad8d2d6c3078bd94439b11d2af0d1450a03\n'}]",0,140751,4a885ed2aaf05ad48a071804bfbf8722766da193,11,3,2,10980,,,0,"Fix python path to neutron_fwaas module

Change-Id: Ibbca9ad8d2d6c3078bd94439b11d2af0d1450a03
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/51/140751/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/services/firewall/agents/varmour/varmour_router.py'],1,3a7d0f26508d2c9a284124af2d98883661dafb0d,fix_python_neutron_path, manager='neutron_fwaas.services.firewall.agents.varmour.varmour_router.', manager='neutron.services.firewall.agents.varmour.varmour_router.',1,1
openstack%2Ffuel-library~master~Ib53038bc53846d14a6c7bf028c7b4e78eef56255,openstack/fuel-library,master,Ib53038bc53846d14a6c7bf028c7b4e78eef56255,Use augeas instead of sysctl::value,MERGED,2014-12-10 14:37:25.000000000,2014-12-10 17:28:22.000000000,2014-12-10 17:28:21.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 13343}, {'_account_id': 13344}]","[{'number': 1, 'created': '2014-12-10 14:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aa530aee6ea17e420decc908d1d35a9eec695299', 'message': ""Use augeas instead of sysctl::value\n\nWe don't actually need to execute 'sysctl -w' for\nnet.bridge.bridge-nf-call* sysctl keys since this can cause\npuppet errors if puppet tries to apply sysctl::value before bridge\nkernel module is loaded.\n\nSo we just need to make sure those sysctl keys are configured\nproperly in /etc/sysctl.conf file. When bridge kernel module is\nloaded by libvirt, it will set them to correct values itself.\n\nCloses-bug: #1401100\nChange-Id: Ib53038bc53846d14a6c7bf028c7b4e78eef56255\n""}, {'number': 2, 'created': '2014-12-10 15:16:33.000000000', 'files': ['deployment/puppet/openstack/manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/231b61ae14786211b5773959f95e6fbddecb3e27', 'message': ""Use augeas instead of sysctl::value\n\nWe don't actually need to execute 'sysctl -w' for\nnet.bridge.bridge-nf-call* sysctl keys since this can cause\npuppet errors if puppet tries to apply sysctl::value before bridge\nkernel module is loaded.\n\nSo we just need to make sure those sysctl keys are configured\nproperly in /etc/sysctl.conf file. When bridge kernel module is\nloaded by libvirt, it will set them to correct values itself.\n\nCloses-bug: #1401100\nChange-Id: Ib53038bc53846d14a6c7bf028c7b4e78eef56255\n""}]",3,140697,231b61ae14786211b5773959f95e6fbddecb3e27,24,7,2,9387,,,0,"Use augeas instead of sysctl::value

We don't actually need to execute 'sysctl -w' for
net.bridge.bridge-nf-call* sysctl keys since this can cause
puppet errors if puppet tries to apply sysctl::value before bridge
kernel module is loaded.

So we just need to make sure those sysctl keys are configured
properly in /etc/sysctl.conf file. When bridge kernel module is
loaded by libvirt, it will set them to correct values itself.

Closes-bug: #1401100
Change-Id: Ib53038bc53846d14a6c7bf028c7b4e78eef56255
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/97/140697/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/compute.pp'],1,aa530aee6ea17e420decc908d1d35a9eec695299,bug/1401100," augeas { 'sysctl-net.bridge.bridge-nf-call-arptables': context => '/files/etc/sysctl.conf', onlyif => ""get net.bridge.bridge-nf-call-arptables != '1'"", changes => ""set net.bridge.bridge-nf-call-arptables '1'"", before => Service['libvirt'], } augeas { 'sysctl-net.bridge.bridge-nf-call-iptables': context => '/files/etc/sysctl.conf', onlyif => ""get net.bridge.bridge-nf-call-iptables != '1'"", changes => ""set net.bridge.bridge-nf-call-iptables '1'"", before => Service['libvirt'], } augeas { 'sysctl-net.bridge.bridge-nf-call-ip6tables': context => '/files/etc/sysctl.conf', onlyif => ""get net.bridge.bridge-nf-call-ip6tables != '1'"", changes => ""set net.bridge.bridge-nf-call-ip6tables '1'"", before => Service['libvirt'], } "," sysctl::value { 'net.bridge.bridge-nf-call-arptables': value => '1', require => Service['libvirt'], } sysctl::value { 'net.bridge.bridge-nf-call-iptables': value => '1', require => Service['libvirt'], } sysctl::value { 'net.bridge.bridge-nf-call-ip6tables': value => '1', require => Service['libvirt'], }",16,9
openstack%2Frequirements~master~I28c3da234443dbb87dab4020c3b286114f68859d,openstack/requirements,master,I28c3da234443dbb87dab4020c3b286114f68859d,Add nova-docker to tracked project list,MERGED,2014-09-17 18:53:12.000000000,2014-12-10 17:27:34.000000000,2014-12-10 17:27:34.000000000,"[{'_account_id': 3}, {'_account_id': 159}, {'_account_id': 308}, {'_account_id': 2750}, {'_account_id': 4395}, {'_account_id': 6786}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-09-17 18:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/001f6b21836efe46cf44652a0d26aa1438e1fd1e', 'message': 'Add nova-docker to tracked project list\n\nChange-Id: I28c3da234443dbb87dab4020c3b286114f68859d\n'}, {'number': 2, 'created': '2014-09-19 22:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fd73b97c105dfe6cf358c3be78e1cdbf8169d9e0', 'message': 'Add nova-docker to tracked project list\n\nChange-Id: I28c3da234443dbb87dab4020c3b286114f68859d\n'}, {'number': 3, 'created': '2014-12-05 23:15:10.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0508c8870580c7ecb74c29953aaabfd8587a4b85', 'message': 'Add nova-docker to tracked project list\n\nChange-Id: I28c3da234443dbb87dab4020c3b286114f68859d\n'}]",0,122221,0508c8870580c7ecb74c29953aaabfd8587a4b85,23,7,3,4395,,,0,"Add nova-docker to tracked project list

Change-Id: I28c3da234443dbb87dab4020c3b286114f68859d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/122221/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,001f6b21836efe46cf44652a0d26aa1438e1fd1e,,stackforge/nova-docker,,1,0
openstack%2Frequirements~master~I3d546965bd301deeb0eb20406af3818aa61d15cf,openstack/requirements,master,I3d546965bd301deeb0eb20406af3818aa61d15cf,Update xstatic-font-awesome to 4.2.0,MERGED,2014-12-04 21:31:49.000000000,2014-12-10 17:27:32.000000000,2014-12-10 17:27:31.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6786}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-12-04 21:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4a9f63e032d805a3b86af81803ad3fef2f7bb85f', 'message': 'Update xstatic-font-awesome to 4.2.0\n\nThe updated version contains the alias fa-remove, this\nfixes the missing delete icon in horizon.\n\nChange-Id: I3d546965bd301deeb0eb20406af3818aa61d15cf\n'}, {'number': 2, 'created': '2014-12-05 18:20:18.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fdceb99d954287ad8fc1cd049719c8d697eee416', 'message': 'Update xstatic-font-awesome to 4.2.0\n\nThe updated version contains the alias fa-remove, this\nfixes the missing delete icon in horizon.\n\nChange-Id: I3d546965bd301deeb0eb20406af3818aa61d15cf\n'}]",0,139207,fdceb99d954287ad8fc1cd049719c8d697eee416,10,4,2,1941,,,0,"Update xstatic-font-awesome to 4.2.0

The updated version contains the alias fa-remove, this
fixes the missing delete icon in horizon.

Change-Id: I3d546965bd301deeb0eb20406af3818aa61d15cf
",git fetch https://review.opendev.org/openstack/requirements refs/changes/07/139207/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,4a9f63e032d805a3b86af81803ad3fef2f7bb85f,,"xstatic-font-awesome>=4.2.0 # SIL OFL 1.1 License, MIT License","xstatic-font-awesome>=4.1.0 # SIL OFL 1.1 License, MIT License",1,1
openstack%2Frequirements~master~Ieb1539ca4efaf1e95e1eb1462f801228f7750490,openstack/requirements,master,Ieb1539ca4efaf1e95e1eb1462f801228f7750490,Bump the minimum required version of retrying,MERGED,2014-12-08 16:47:57.000000000,2014-12-10 17:27:29.000000000,2014-12-10 17:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2592}, {'_account_id': 7491}, {'_account_id': 7680}, {'_account_id': 12826}]","[{'number': 1, 'created': '2014-12-08 16:47:57.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0d2c2d63ea613890f80d58bd5b2c29959024251f', 'message': 'Bump the minimum required version of retrying\n\noslo.concurrency master actually uses one of 1.2.3 features\n(custom stop functions).\n\nChange-Id: Ieb1539ca4efaf1e95e1eb1462f801228f7750490\n'}]",0,140074,0d2c2d63ea613890f80d58bd5b2c29959024251f,10,6,1,6849,,,0,"Bump the minimum required version of retrying

oslo.concurrency master actually uses one of 1.2.3 features
(custom stop functions).

Change-Id: Ieb1539ca4efaf1e95e1eb1462f801228f7750490
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/140074/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,0d2c2d63ea613890f80d58bd5b2c29959024251f,,"retrying>=1.2.3,!=1.3.0 # Apache-2.0","retrying>=1.2.2,!=1.3.0 # Apache-2.0",1,1
openstack%2Freviewstats~master~I18d3ea0749421cb106caf03b9001b9d790694aad,openstack/reviewstats,master,I18d3ea0749421cb106caf03b9001b9d790694aad,Add tripleo stackforge projects,ABANDONED,2014-12-01 06:43:42.000000000,2014-12-10 17:25:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 6488}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-01 06:43:42.000000000', 'files': ['projects/tripleo.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/3153b8970365eb925770e6ab484a43675f1ee10f', 'message': 'Add tripleo stackforge projects\n\nChange-Id: I18d3ea0749421cb106caf03b9001b9d790694aad\n'}]",0,138005,3153b8970365eb925770e6ab484a43675f1ee10f,7,4,1,9453,,,0,"Add tripleo stackforge projects

Change-Id: I18d3ea0749421cb106caf03b9001b9d790694aad
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/05/138005/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/tripleo.json'],1,3153b8970365eb925770e6ab484a43675f1ee10f,," ""openstack/tuskar"", ""stackforge/prep_source_repos"", ""stackforge/tripleo-ansible"""," ""openstack/tuskar""",3,1
openstack%2Fpuppet-neutron~stable%2Fjuno~I415001419474dd8d242fe238bbf88b5c45c9f3e9,openstack/puppet-neutron,stable/juno,I415001419474dd8d242fe238bbf88b5c45c9f3e9,Fix l3_ha enablement,MERGED,2014-12-10 16:11:58.000000000,2014-12-10 17:15:10.000000000,2014-12-10 17:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2014-12-10 16:11:58.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c3dc52023dfdf7649080c1b5bc5eae3b43991db1', 'message': 'Fix l3_ha enablement\n\nThe L3 HA feature needs to be enabled using ""l3_ha=True"" instead of\n""ha_enabled=true"".\n\nChange-Id: I415001419474dd8d242fe238bbf88b5c45c9f3e9\n(cherry picked from commit 05eb42aae94253dfd5ffc37dfc665ac3e2631ccd)\n'}]",0,140757,c3dc52023dfdf7649080c1b5bc5eae3b43991db1,7,3,1,13294,,,0,"Fix l3_ha enablement

The L3 HA feature needs to be enabled using ""l3_ha=True"" instead of
""ha_enabled=true"".

Change-Id: I415001419474dd8d242fe238bbf88b5c45c9f3e9
(cherry picked from commit 05eb42aae94253dfd5ffc37dfc665ac3e2631ccd)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/57/140757/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_server_spec.rb', 'manifests/server.pp']",2,c3dc52023dfdf7649080c1b5bc5eae3b43991db1,, 'DEFAULT/l3_ha': value => true;, 'DEFAULT/ha_enabled': value => true;,2,2
openstack%2Fbarbican~master~I3a64c05fdc21dd3e07852aa750ea4c099564da65,openstack/barbican,master,I3a64c05fdc21dd3e07852aa750ea4c099564da65,Changing ModelBase.save to correct updated time,MERGED,2014-12-09 18:18:28.000000000,2014-12-10 17:15:01.000000000,2014-12-10 17:15:00.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 10670}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-12-09 18:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/db2563ae44640a3126c15248f8608254fa316d1e', 'message': 'Changing ModelBase.save to correct updated time\n\nThis change modifies the updated_at time property for new ModelBase\nobjects. When the save method is called for a new object that does not yet\nhave an id assigned, the created_at and updated_at times are set to the\nsame value.\n\nChanges\n* modified ModelBase.save method for new objects\n\nChange-Id: I3a64c05fdc21dd3e07852aa750ea4c099564da65\nCloses-Bug: #1382188\n'}, {'number': 2, 'created': '2014-12-10 15:10:21.000000000', 'files': ['barbican/model/models.py', 'barbican/tests/model/test_models.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/d163550914bb78f4e0bc8c316d79dfd50f9a47f6', 'message': 'Changing ModelBase.save to correct updated time\n\nThis change modifies the updated_at time property for new ModelBase\nobjects. When the save method is called for a new object that does not yet\nhave an id assigned, the created_at and updated_at times are set to the\nsame value.\n\nChanges\n* modified ModelBase.save method for new objects\n* adding a test to confirm new secrets have the same created_at and\n  updated_at times\n\nChange-Id: I3a64c05fdc21dd3e07852aa750ea4c099564da65\nCloses-Bug: #1382188\n'}]",3,140423,d163550914bb78f4e0bc8c316d79dfd50f9a47f6,15,7,2,10670,,,0,"Changing ModelBase.save to correct updated time

This change modifies the updated_at time property for new ModelBase
objects. When the save method is called for a new object that does not yet
have an id assigned, the created_at and updated_at times are set to the
same value.

Changes
* modified ModelBase.save method for new objects
* adding a test to confirm new secrets have the same created_at and
  updated_at times

Change-Id: I3a64c05fdc21dd3e07852aa750ea4c099564da65
Closes-Bug: #1382188
",git fetch https://review.opendev.org/openstack/barbican refs/changes/23/140423/2 && git format-patch -1 --stdout FETCH_HEAD,['barbican/model/models.py'],1,db2563ae44640a3126c15248f8608254fa316d1e,bug/1382188, # if model is being created ensure that created/updated are the same if self.id is None: self.created_at = timeutils.utcnow() self.updated_at = self.created_at,,4,0
openstack%2Ffuel-library~stable%2F6.0~Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a,openstack/fuel-library,stable/6.0,Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a,Create keystone admin user before micro flavor,MERGED,2014-12-09 22:46:15.000000000,2014-12-10 17:09:53.000000000,2014-12-10 17:09:52.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-09 22:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1ad6ad87acd2948ce86ee4af418fb10f5738b3e9', 'message': 'Create keystone admin user before micro flavor\n\nCreate keystone admin user so that you have\nrights to create m1.micro flavor\n\nChange-Id: Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a\nCloses-bug: #1400910\n'}, {'number': 2, 'created': '2014-12-10 12:15:19.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3d21d96df33b2a9ed00d0ea69752a85152254847', 'message': 'Create keystone admin user before micro flavor\n\nCreate keystone admin user so that you have\nrights to create m1.micro flavor\n\nChange-Id: Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a\nCloses-bug: #1400910\n'}]",0,140509,3d21d96df33b2a9ed00d0ea69752a85152254847,21,7,2,8786,,,0,"Create keystone admin user before micro flavor

Create keystone admin user so that you have
rights to create m1.micro flavor

Change-Id: Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a
Closes-bug: #1400910
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/09/140509/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",2,1ad6ad87acd2948ce86ee4af418fb10f5738b3e9,, Keystone::Roles::Admin <||> -> Exec<| title=='create-m1.micro-flavor' |> ,,5,0
openstack%2Fmagnetodb-specs~master~I7b0a5509fe45434e115d170b06a218661903c3b9,openstack/magnetodb-specs,master,I7b0a5509fe45434e115d170b06a218661903c3b9,"Adds table uuid in create, describe, delete table response bodies",MERGED,2014-11-26 11:23:57.000000000,2014-12-10 17:05:41.000000000,2014-12-10 17:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}]","[{'number': 1, 'created': '2014-11-26 11:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/8abd0e5a40147e77f1fad6b72702a1d3068cbac9', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 2, 'created': '2014-11-26 11:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/255e0e4681ac664f48f330a17df0d148a5ed2355', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 3, 'created': '2014-11-26 11:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/74691e83b09f9114508430b4188878e1a115a4b0', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 4, 'created': '2014-11-26 11:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/da4297a13a847bec1150fdd7624e4b76876964f8', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 5, 'created': '2014-11-27 12:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/63b3bf4bd3f81f1a4ddb4ae8f5844bac5cc8bad1', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 6, 'created': '2014-11-27 13:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/f34609fab223496eed6eca213d9b981365e899b8', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 7, 'created': '2014-11-27 14:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/f5c0607609a9edfa64bc03093c2d52612673028f', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 8, 'created': '2014-11-27 14:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/2160b38021711182bf35974eaae6a1147d0b635c', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 9, 'created': '2014-11-27 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/856b28fbcdbcc5ec4f7d0344cae64befbafbdcf7', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 10, 'created': '2014-11-27 14:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/58d3fad01dd3c522490e71ea26bbc3e5debdb494', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 11, 'created': '2014-12-04 13:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/188f34a14d1209a03004b7ca29767b4176fa97e4', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 12, 'created': '2014-12-04 15:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/3c281dc3abc7218fc521e106b8b2ffecbf864a89', 'message': 'Adds table uuid in uri specification\n\nbp: table-uuid-in-uri\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 13, 'created': '2014-12-10 14:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/d4380fa20f2b94c299f9caaa1dc540daa7c9bc62', 'message': 'Adds table uuid in create, describe, delete table response bodies\n\nbp: table-uuid\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 14, 'created': '2014-12-10 14:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/1474c4587ec9b4fbd63728a568abddd4247f1462', 'message': 'Adds table uuid in create, describe, delete table response bodies\n\nbp: table-uuid\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}, {'number': 15, 'created': '2014-12-10 14:49:40.000000000', 'files': ['specs/kilo/approved/table-uuid.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/f6f1b1666605f3385a0ff8f827fd7cdfb2422b13', 'message': 'Adds table uuid in create, describe, delete table response bodies\n\nbp: table-uuid\nChange-Id: I7b0a5509fe45434e115d170b06a218661903c3b9\n'}]",28,137336,f6f1b1666605f3385a0ff8f827fd7cdfb2422b13,47,5,15,8863,,,0,"Adds table uuid in create, describe, delete table response bodies

bp: table-uuid
Change-Id: I7b0a5509fe45434e115d170b06a218661903c3b9
",git fetch https://review.opendev.org/openstack/magnetodb-specs refs/changes/36/137336/11 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/uuid-in-uri.rst'],1,8abd0e5a40147e77f1fad6b72702a1d3068cbac9,bp/table-uuid,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================== Add UUID in uri ======================== Launchpad: table-uuid-in-uri_ .. _table-uuid-in-uri: https://blueprints.launchpad.net/magnetodb/+spec/table-uuid-in-uri Implement table resource lookup by UUID, not only name :: Problem description =================== --------- Use Cases --------- UUID is used as an intristic identifier of table. We need to expose in for Ceilometer purposes. Resource lookup by UUID is closer for OpenStack and defines resource unambiguously. Proposed change =============== 1. Add primary table lookup by UUID in any uri, that contains table name or UUID 2. List table response will contain table UUID 3. Describe table will contatin table UUID ------------ Alternatives ------------ ----------------- Data model impact ----------------- No data is stored or cached. --------------- REST API impact --------------- Table name in any request except 'create table' can be substituted by table UUID. Additionally 'list table' and 'describe table' responses will contain table UUID. URL for the resource ```````````````````` v1/{tenant_id}/data/tables/{table_uuid|table_name} Response Syntax ``````````````` List table: :: { ""last_evaluated_table_name"": ""string"", ""tables"": [ { ""rel"": ""string"", ""href"": ""url"", ""uuid"": ""string"" } ] } Describe table: :: { ""table"": { ""attribute_definitions"": [ { ""attribute_name"": ""string"", ""attribute_type"": ""string"" } ], ""creation_datetime"": ""number"", ""item_count"": ""number"", ""key_schema"": [ { ""attribute_name"": ""string"", ""key_type"": ""string"" } ], ""local_secondary_indexes"": [ { ""index_name"": ""string"", ""index_size_bytes"": ""number"", ""item_count"": ""number"", ""key_schema"": [ { ""attribute_name"": ""string"", ""key_type"": ""string"" } ], ""projection"": { ""non_key_attributes"": [ ""string"" ], ""projection_type"": ""string"" } } ], ""links"": [ { ""href"": ""url"", ""rel"": ""self"" } ], ""uuid"": ""string"", ""table_name"": ""string"", ""table_size_bytes"": ""number"", ""table_status"": ""string"" } } --------------- Security impact --------------- None -------------------- Notifications impact -------------------- None --------------------- Other end user impact --------------------- None ------------------ Performance Impact ------------------ None --------------------- Other deployer impact --------------------- None ---------------- Developer impact ---------------- None Implementation ============== None ----------- Assignee(s) ----------- Primary assignee: <aostapenko> Other contributors: <None> ---------- Work Items ---------- 1. Update interface for data and monitoring API. 2. Update documentation. Dependencies ============ None Testing ======= None Documentation Impact ==================== * Updated API section should be added to documentation_. .. _documentation: http://magnetodb.readthedocs.org/en/latest/api_reference.html References ========== ",,221,0
openstack%2Fcongress~master~I988645efabbdb415c2072160c1cab5eabbcdf8f2,openstack/congress,master,I988645efabbdb415c2072160c1cab5eabbcdf8f2,Add code pointers to docs,MERGED,2014-12-09 22:32:35.000000000,2014-12-10 17:05:35.000000000,2014-12-10 17:05:34.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-09 22:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/7395fc1e77f647a9d09a3c7a07c705ddc8260ca5', 'message': 'Add code pointers to docs\n\nPreviously, our documentation was intended for end-users.  It did\nnot have any docs pointing developers to different points in the\ncodebase.\n\nThis change adds a Code Overview section to the docs.\n\nChange-Id: I988645efabbdb415c2072160c1cab5eabbcdf8f2\n'}, {'number': 2, 'created': '2014-12-09 22:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/300311cfcc8105e615fb617992bda27635f0fdfa', 'message': 'Add code pointers to docs\n\nPreviously, our documentation was intended for end-users.  It did\nnot have any docs pointing developers to different points in the\ncodebase.\n\nThis change adds a Code Overview section to the docs.\n\nChange-Id: I988645efabbdb415c2072160c1cab5eabbcdf8f2\n'}, {'number': 3, 'created': '2014-12-10 15:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/655ffbeb7844fe84784585605ea9baf2a251f29e', 'message': 'Add code pointers to docs\n\nPreviously, our documentation was intended for end-users.  It did\nnot have any docs pointing developers to different points in the\ncodebase.\n\nThis change adds a Code Overview section to the docs.\n\nChange-Id: I988645efabbdb415c2072160c1cab5eabbcdf8f2\n'}, {'number': 4, 'created': '2014-12-10 15:58:09.000000000', 'files': ['doc/source/index.rst', 'doc/source/codeoverview.rst'], 'web_link': 'https://opendev.org/openstack/congress/commit/36cb4786a8c0ebee357f2219b81f0345be000a4b', 'message': 'Add code pointers to docs\n\nPreviously, our documentation was intended for end-users.  It did\nnot have any docs pointing developers to different points in the\ncodebase.\n\nThis change adds a Code Overview section to the docs.\n\nChange-Id: I988645efabbdb415c2072160c1cab5eabbcdf8f2\n'}]",8,140506,36cb4786a8c0ebee357f2219b81f0345be000a4b,15,4,4,8215,,,0,"Add code pointers to docs

Previously, our documentation was intended for end-users.  It did
not have any docs pointing developers to different points in the
codebase.

This change adds a Code Overview section to the docs.

Change-Id: I988645efabbdb415c2072160c1cab5eabbcdf8f2
",git fetch https://review.opendev.org/openstack/congress refs/changes/06/140506/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/codeoverview.rst']",2,7395fc1e77f647a9d09a3c7a07c705ddc8260ca5,devdocs," .. include:: aliases.rst .. _codeoverview: ============== Code Overview ============== This page gives a brief overview of the code the Congress implementation. 1. External information ======================= The main source of information is the Congress wiki. There are two separate codebases that implement Congress: the server and the python-client. * wiki: https://wiki.openstack.org/wiki/Congress * server: https://github.com/stackforge/congress * client: https://github.com/stackforge/python-congressclient The structure of the client code is the same as that for other recent OpenStack python clients. The bulk of the Congress code is contained within the server. The remainder of this page describes the layout of the server code. 2. Server directory structure =============================== Here are the most important components of the code, described by how they are laid out in the repository. * ``congress/harness.py``: analogous to ""main()"" in C++. * ``congress/policy``: policy engine (datalog interpreter, monitoring, enforcement) * ``congress/datasources``: datasource drivers: thin wrappers/adapters for integrating services like Nova, Neutron * ``congress/dse``: message bus that the policy engine and datasources use to communicate * ``congress/api``: API data models (entry points into the system from the API) * ``contrib``: code for integrating into other services, e.g. devstack, horizon, tempest 3. Policy Engine ==================== First is a description of the files and folders in congress/policy. * ``congress/policy/Congress.g``: Antlr3 grammar defining the syntax of policies. ``make`` uses Congress.g to generate CongressLexer.py and CongressParser.py, which are used to convert strings into Python datastructures. * ``congress/policy/compile.py``: * Convert policy strings into Python datastructures that represent those strings. * Includes datastructures for individual policy statements. * Also includes additional syntax checks that are not handled by the grammar. * ``congress/policy/runtime.py``: * Policy datastructures * Reasoning algorithms * Toplevel class for policy engine: Runtime * ``congress/policy/unify.py``: unification routines used at the heart of the policy reasoning algorithms. * ``congress/policy/dsepolicy.py``: code that implements the Runtime class as a member of the DSE message bus. Handles publishing/subscribing to the tables exported by the datasources. Second is a brief overview of the fundamental datastructures used to represent individual policy statements. * ``congress/policy/compile.py:Rule``: represents a single rule of the form ``head1, ..., headn :- body1, ..., bodym``. Each headi and bodyi are Literals. * ``congress/policy/compile.py:Literal``: represents a possibly negated atom of the form ``[not] table(arg1, ..., argn)``. Each argi is a term. * ``congress/policy/compile.py:Term``: represents an argument to a Literal. Is either a Variable or an ObjectConstant. * ``congress/policy/compile.py:ObjectConstant``: special kind of Term that represents a fixed string or number. * ``congress/policy/compile.py:Variable``: special kind of Term that is a placeholder used in a rule to represent an ObjectConstant. Third is an overview of the datastructures used to represent entire policies. There are several different kinds of policies that you can choose from when creating a new policy. Each makes different tradeoffs in terms of time/space or in terms of the kind of policy statements that are permitted. Internally these are called 'theories'. * ``congress/policy/runtime.py:NonrecursiveRuleTheory``: represents an arbitrary collection of rules (without recursion). No precomputation of table contents is performed. Small memory footprint, but query time can be large. (A Prolog implementation of rules.) This is the default datastructure used when creating a new policy. * ``congress/policy/runtime.py:MaterializedViewTheory``: represents an arbitrary collection of rules (even allows recursion). Contents of all tables are computed and stored each time policy changes. Large memory footprint, but query time is small when asking for the contents of any table. Not actively maintained. * ``congress/policy/runtime.py:Database``: represents a collection of non-negated Literals without variables, e.g. ``p(1, ""alice"")``. A standard DB table. Last we give a list of the top-level entry points to the Runtime class, which is basically the top-level class for the policy engine. * ``create_policy``, ``delete_policy``: implement multiple policies * ``select``: ask for the answer to a standard database query (e.g. the contents of a table) for a specified policy * ``insert``, ``delete``: insert or delete a single policy statement into a specified policy * ``update``: batch of inserts/deletes into multiple policies * ``simulate``: apply a sequence of updates (temporarily), answer a query, and roll-back the updates. ",,123,0
openstack%2Fneutron-vpnaas~master~I39626727a1b17faa938aa418924958e1ac60d56e,openstack/neutron-vpnaas,master,I39626727a1b17faa938aa418924958e1ac60d56e,Fix python neutron path for neutron_vpnaas,MERGED,2014-12-10 16:10:49.000000000,2014-12-10 17:05:28.000000000,2014-12-10 17:05:28.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6659}]","[{'number': 1, 'created': '2014-12-10 16:10:49.000000000', 'files': ['neutron_vpnaas/services/vpn/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/ae09404af1ca45631cf103c1aebe794c46e3731c', 'message': 'Fix python neutron path for neutron_vpnaas\n\nChange-Id: I39626727a1b17faa938aa418924958e1ac60d56e\n'}]",0,140756,ae09404af1ca45631cf103c1aebe794c46e3731c,7,3,1,10980,,,0,"Fix python neutron path for neutron_vpnaas

Change-Id: I39626727a1b17faa938aa418924958e1ac60d56e
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/56/140756/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/services/vpn/agent.py'],1,ae09404af1ca45631cf103c1aebe794c46e3731c,fix_neutron_python_path, default=['neutron_vpnaas.services.vpn.device_drivers.' manager='neutron_vpnaas.services.vpn.agent.VPNAgent'), default=['neutron.services.vpn.device_drivers.' manager='neutron.services.vpn.agent.VPNAgent'),2,2
openstack%2Fneutron-lbaas~master~I758109051dfe245dafbf484ea85d842b655f519d,openstack/neutron-lbaas,master,I758109051dfe245dafbf484ea85d842b655f519d,Fix python neutron paths for neutron_lbaas,MERGED,2014-12-10 16:09:46.000000000,2014-12-10 17:05:26.000000000,2014-12-10 17:05:26.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6951}, {'_account_id': 10850}]","[{'number': 1, 'created': '2014-12-10 16:09:46.000000000', 'files': ['neutron_lbaas/services/loadbalancer/drivers/embrane/poller.py', 'neutron_lbaas/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/agent/agent_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/972873d232090b9dae063fd3592447c00b2b74e9', 'message': 'Fix python neutron paths for neutron_lbaas\n\nChange-Id: I758109051dfe245dafbf484ea85d842b655f519d\n'}]",0,140753,972873d232090b9dae063fd3592447c00b2b74e9,8,4,1,10980,,,0,"Fix python neutron paths for neutron_lbaas

Change-Id: I758109051dfe245dafbf484ea85d842b655f519d
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/53/140753/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/drivers/embrane/poller.py', 'neutron_lbaas/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/agent/agent_manager.py']",3,972873d232090b9dae063fd3592447c00b2b74e9,fix_python_neutron_paths, default=['neutron_lbaas.services.loadbalancer.drivers', default=['neutron.services.loadbalancer.drivers',3,3
openstack%2Fneutron-fwaas~master~I934cea427b9ea941e446c04e6e8754676769a4fb,openstack/neutron-fwaas,master,I934cea427b9ea941e446c04e6e8754676769a4fb,Fix python path in ini file,MERGED,2014-12-10 04:37:53.000000000,2014-12-10 17:05:20.000000000,2014-12-10 17:05:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}]","[{'number': 1, 'created': '2014-12-10 04:37:53.000000000', 'files': ['etc/fwaas_driver.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/9f1f6cf5d9a222a6bccfc9df9ba62df0c6e39136', 'message': 'Fix python path in ini file\n\nChange-Id: I934cea427b9ea941e446c04e6e8754676769a4fb\n'}]",0,140568,9f1f6cf5d9a222a6bccfc9df9ba62df0c6e39136,8,3,1,10980,,,0,"Fix python path in ini file

Change-Id: I934cea427b9ea941e446c04e6e8754676769a4fb
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/68/140568/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/fwaas_driver.ini'],1,9f1f6cf5d9a222a6bccfc9df9ba62df0c6e39136,fix_ini_path,#driver = neutron_fwaas.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver,#driver = neutron.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver,1,1
openstack%2Foslo.vmware~master~I6c155370dbd01fe4748d5137bdf288e8d3e1a67e,openstack/oslo.vmware,master,I6c155370dbd01fe4748d5137bdf288e8d3e1a67e,Add pbr to installation requirements,MERGED,2014-10-24 13:36:14.000000000,2014-12-10 16:54:33.000000000,2014-12-10 16:54:30.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9008}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-10-24 13:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/e451dfba8fb89da26d4f867447fa445a3ef35dd9', 'message': 'Add pbr to installation requirements\n\nAdd pbr to the list of installation requirements so that it is installed\nvia pip before this library is installed, instead of with easy_install.\nThis avoids issues like Bug #1384919, and ensures that projects that use\nthis library as a dependency are properly installed.\n\nChange-Id: I6c155370dbd01fe4748d5137bdf288e8d3e1a67e\n'}, {'number': 2, 'created': '2014-12-01 22:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/f5e704172e6fd7265d2b9b935c698cc87ce4de2d', 'message': 'Add pbr to installation requirements\n\nAdd pbr to the list of installation requirements so that it is installed\nvia pip before this library is installed, instead of with easy_install.\nThis avoids issues like Bug #1384919, and ensures that projects that use\nthis library as a dependency are properly installed.\n\nChange-Id: I6c155370dbd01fe4748d5137bdf288e8d3e1a67e\n'}, {'number': 3, 'created': '2014-12-10 15:28:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/24681faec25aa59da24ed35a2fc3d4202df2f33e', 'message': 'Add pbr to installation requirements\n\nAdd pbr to the list of installation requirements so that it is installed\nvia pip before this library is installed, instead of with easy_install.\nThis avoids issues like Bug #1384919, and ensures that projects that use\nthis library as a dependency are properly installed.\n\nChange-Id: I6c155370dbd01fe4748d5137bdf288e8d3e1a67e\n'}]",2,130790,24681faec25aa59da24ed35a2fc3d4202df2f33e,21,7,3,2472,,,0,"Add pbr to installation requirements

Add pbr to the list of installation requirements so that it is installed
via pip before this library is installed, instead of with easy_install.
This avoids issues like Bug #1384919, and ensures that projects that use
this library as a dependency are properly installed.

Change-Id: I6c155370dbd01fe4748d5137bdf288e8d3e1a67e
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/90/130790/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e451dfba8fb89da26d4f867447fa445a3ef35dd9,bug/1384919,"pbr>=0.6,!=0.7,<1.0 ",,2,0
openstack%2Foslo.messaging~master~Ice80ffc6cbc39919eac4bc0809992daea51b5922,openstack/oslo.messaging,master,Ice80ffc6cbc39919eac4bc0809992daea51b5922,Warns user if thread monkeypatch is not done,MERGED,2014-12-10 08:49:40.000000000,2014-12-10 16:54:22.000000000,2014-12-10 16:54:22.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 10725}]","[{'number': 1, 'created': '2014-12-10 08:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/072de88516dfd4b25ff021e572cfb00bb1d3b290', 'message': 'Warns user if thread monkeypatch is not done\n\nThis change warns the user that it does have monkeypatched the\noslo.messaging library correclty.\n\nChange-Id: Ice80ffc6cbc39919eac4bc0809992daea51b5922\nCloses-bug: #1288878\n'}, {'number': 2, 'created': '2014-12-10 10:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6baef6f9c871b5789312bab60c84285de0fb6ebc', 'message': 'Warns user if thread monkeypatch is not done\n\nThis change warns the user that it does have monkeypatched the\noslo.messaging library correclty.\n\nChange-Id: Ice80ffc6cbc39919eac4bc0809992daea51b5922\nCloses-bug: #1288878\n'}, {'number': 3, 'created': '2014-12-10 15:03:47.000000000', 'files': ['oslo/messaging/rpc/server.py', 'oslo/messaging/_executors/impl_eventlet.py', 'doc/source/notification_listener.rst', 'oslo/messaging/notify/listener.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d3e6ea17881bdeefcebccbff691b9084315f2393', 'message': 'Warns user if thread monkeypatch is not done\n\nThis change warns the user that it does have monkeypatched the\noslo.messaging library correclty.\n\nChange-Id: Ice80ffc6cbc39919eac4bc0809992daea51b5922\nCloses-bug: #1288878\n'}]",11,140610,d3e6ea17881bdeefcebccbff691b9084315f2393,17,7,3,2813,,,0,"Warns user if thread monkeypatch is not done

This change warns the user that it does have monkeypatched the
oslo.messaging library correclty.

Change-Id: Ice80ffc6cbc39919eac4bc0809992daea51b5922
Closes-bug: #1288878
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/10/140610/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/rpc/server.py', 'oslo/messaging/_executors/impl_eventlet.py', 'doc/source/notification_listener.rst', 'oslo/messaging/notify/listener.py']",4,072de88516dfd4b25ff021e572cfb00bb1d3b290,bug/1288878," If the eventlet executor is used, the threading and time library need to be monkeypatched. ",,23,0
openstack%2Foslo.db~master~Icb1d6324b58feed515e4eb885715cbf2195768cf,openstack/oslo.db,master,Icb1d6324b58feed515e4eb885715cbf2195768cf,Fix TestConnectionUtils to py3x compatibility,MERGED,2014-12-09 10:24:57.000000000,2014-12-10 16:54:16.000000000,2014-12-10 16:54:14.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-12-09 10:24:57.000000000', 'files': ['tests/sqlalchemy/test_utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/4c939b38eb1328094e4b73eec0955ba7c2f2e67d', 'message': 'Fix TestConnectionUtils to py3x compatibility\n\nTests in TestConnectionUtils class depends on database and DB connector,\nso the simplest way to run them with python 3.X is to use same database\nand connector for the both python versions. PostgreSQL and psycopg2 are\nlooks good for this.\n\nReplaced ``mysql`` to ``postgresql`` in TestConnectionUtils.\n\nChange-Id: Icb1d6324b58feed515e4eb885715cbf2195768cf\n'}]",0,140291,4c939b38eb1328094e4b73eec0955ba7c2f2e67d,10,5,1,7491,,,0,"Fix TestConnectionUtils to py3x compatibility

Tests in TestConnectionUtils class depends on database and DB connector,
so the simplest way to run them with python 3.X is to use same database
and connector for the both python versions. PostgreSQL and psycopg2 are
looks good for this.

Replaced ``mysql`` to ``postgresql`` in TestConnectionUtils.

Change-Id: Icb1d6324b58feed515e4eb885715cbf2195768cf
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/91/140291/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/sqlalchemy/test_utils.py'],1,4c939b38eb1328094e4b73eec0955ba7c2f2e67d,py3-mysql-psql," self.full_credentials = {'backend': 'postgresql', self.connect_string = 'postgresql://dude:pass@localhost/test' error_msg = ""The postgresql backend is unavailable: %s\n"" % err ""The postgresql backend is unavailable: %s"" % err, ""The postgresql backend is unavailable: Can't import "" self.assertEqual(connect_string, 'postgresql://dude:pass@myhost/test')"," self.full_credentials = {'backend': 'mysql', self.connect_string = 'mysql://dude:pass@localhost/test' error_msg = ""The mysql backend is unavailable: %s\n"" % err ""The mysql backend is unavailable: %s"" % err, ""The mysql backend is unavailable: Can't import "" self.assertEqual(connect_string, 'mysql://dude:pass@myhost/test')",6,6
openstack%2Fneutron~master~I65b40fe52c2c6f4bae88e125bd1ee501aaa24114,openstack/neutron,master,I65b40fe52c2c6f4bae88e125bd1ee501aaa24114,Refactor test_migration,MERGED,2014-11-18 08:02:49.000000000,2014-12-10 16:54:02.000000000,2014-12-10 16:54:00.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-11-18 08:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/349344bc917b6f7d836bf6b673cdb24a61959303', 'message': 'Refactor test_migration\n\ntest_migration contains some methods like overriding compare_server_default\nand compare_foreign_keys that was added directly in ModelsMigrationsSync\nclass in oslo.db only in 1.1.0.\n\nAlso as now migrations refactoring is fully finished, there is no\nneed to have separate classes for each plugin.\n\nCloses-bug: #1393691\n\nChange-Id: I65b40fe52c2c6f4bae88e125bd1ee501aaa24114\n'}, {'number': 2, 'created': '2014-12-02 13:40:24.000000000', 'files': ['neutron/tests/unit/db/test_migration.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd0417d000b0e8f0ff52b5f0d7ca9eb4029071a3', 'message': 'Refactor test_migration\n\ntest_migration contains some methods like overriding compare_server_default\nand compare_foreign_keys that was added directly in ModelsMigrationsSync\nclass in oslo.db only in 1.1.0.\n\nAlso as now migrations refactoring is fully finished, there is no\nneed to have separate classes for each plugin.\n\nCloses-bug: #1393691\n\nChange-Id: I65b40fe52c2c6f4bae88e125bd1ee501aaa24114\n'}]",0,135188,fd0417d000b0e8f0ff52b5f0d7ca9eb4029071a3,60,27,2,7249,,,0,"Refactor test_migration

test_migration contains some methods like overriding compare_server_default
and compare_foreign_keys that was added directly in ModelsMigrationsSync
class in oslo.db only in 1.1.0.

Also as now migrations refactoring is fully finished, there is no
need to have separate classes for each plugin.

Closes-bug: #1393691

Change-Id: I65b40fe52c2c6f4bae88e125bd1ee501aaa24114
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/135188/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/db/test_migration.py'],1,349344bc917b6f7d836bf6b673cdb24a61959303,bug/1393691,"CORE_PLUGIN = 'neutron.plugins.ml2.plugin.Ml2Plugin' core_plugin=CORE_PLUGIN) diff2 = self.check_foreign_keys(self.get_metadata(), self.get_engine()) pass pass","import collectionsfrom oslo.db.sqlalchemy import utilsimport sqlalchemy.sql.expression as expr import testscenariosCORE_PLUGINS = _discover_plugins('neutron.core_plugins') core_plugin=self.core_plugin) def compare_server_default(self, ctxt, ins_col, meta_col, insp_def, meta_def, rendered_meta_def): return self._compare_server_default(ctxt.bind, meta_col, insp_def, meta_def) # TODO(akamyshnikova):remove _compare_server_default methods when it # appears in oslo.db(version>1.0.0) @utils.DialectFunctionDispatcher.dispatch_for_dialect(""*"") def _compare_server_default(bind, meta_col, insp_def, meta_def): pass @_compare_server_default.dispatch_for('mysql') def _compare_server_default(bind, meta_col, insp_def, meta_def): if isinstance(meta_col.type, sqlalchemy.Boolean): if meta_def is None or insp_def is None: return meta_def != insp_def return not ( isinstance(meta_def.arg, expr.True_) and insp_def == ""'1'"" or isinstance(meta_def.arg, expr.False_) and insp_def == ""'0'"" ) if isinstance(meta_col.type, sqlalchemy.Integer): if meta_def is None or insp_def is None: return meta_def != insp_def return meta_def.arg == insp_def @_compare_server_default.dispatch_for('postgresql') def _compare_server_default(bind, meta_col, insp_def, meta_def): if isinstance(meta_col.type, sqlalchemy.Enum): if meta_def is None or insp_def is None: return meta_def != insp_def return insp_def != ""'%s'::%s"" % (meta_def.arg, meta_col.type.name) elif isinstance(meta_col.type, sqlalchemy.String): if meta_def is None or insp_def is None: return meta_def != insp_def return insp_def != ""'%s'::character varying"" % meta_def.arg diff2 = self.compare_foreign_keys(self.get_metadata(), self.get_engine()) FKInfo = collections.namedtuple('FKInfo', ['constrained_columns', 'referred_table', 'referred_columns']) def compare_foreign_keys(self, metadata, bind): """"""Compare foreign keys between model and db table. Returns a list that contains information about: * should be a new key added or removed existing, * name of that key, * source table, * referred table, * constrained columns, * referred columns Output:: [('drop_key', 'testtbl_fk_check_fkey', 'testtbl', fk_info(constrained_columns=(u'fk_check',), referred_table=u'table', referred_columns=(u'fk_check',)))] """""" diff = [] insp = sqlalchemy.engine.reflection.Inspector.from_engine(bind) # Get all tables from db db_tables = insp.get_table_names() # Get all tables from models model_tables = metadata.tables for table in db_tables: if table not in model_tables: continue # Get all necessary information about key of current table from db fk_db = dict((self._get_fk_info_from_db(i), i['name']) for i in insp.get_foreign_keys(table)) fk_db_set = set(fk_db.keys()) # Get all necessary information about key of current table from # models fk_models = dict((self._get_fk_info_from_model(fk), fk) for fk in model_tables[table].foreign_keys) fk_models_set = set(fk_models.keys()) for key in (fk_db_set - fk_models_set): diff.append(('drop_key', fk_db[key], table, key)) LOG.info((""Detected removed foreign key %(fk)r on "" ""table %(table)r""), {'fk': fk_db[key], 'table': table}) for key in (fk_models_set - fk_db_set): diff.append(('add_key', fk_models[key], key)) LOG.info(( ""Detected added foreign key for column %(fk)r on table "" ""%(table)r""), {'fk': fk_models[key].column.name, 'table': table}) return diff def _get_fk_info_from_db(self, fk): return self.FKInfo(tuple(fk['constrained_columns']), fk['referred_table'], tuple(fk['referred_columns'])) def _get_fk_info_from_model(self, fk): return self.FKInfo((fk.parent.name,), fk.column.table.name, (fk.column.name,)) load_tests = testscenarios.load_tests_apply_scenarios _scenarios = [] for plugin in CORE_PLUGINS: plugin_name = plugin.split('.')[-1] class_name = plugin_name _scenarios.append((class_name, {'core_plugin': plugin})) scenarios = _scenarios scenarios = _scenarios",6,121
openstack%2Frequirements~master~I259fb3bd68d6727c3768b00d284fd40ddc4c85b7,openstack/requirements,master,I259fb3bd68d6727c3768b00d284fd40ddc4c85b7,Upgrade oslo.vmware>=0.7.0,MERGED,2014-11-23 09:32:45.000000000,2014-12-10 16:53:50.000000000,2014-12-10 16:53:50.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 5638}, {'_account_id': 9317}]","[{'number': 1, 'created': '2014-11-23 09:32:45.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0ec4255ba941f502369395c93fc4a410e24f4a5d', 'message': 'Upgrade oslo.vmware>=0.7.0\n\nThis release includes several bug fixes\n(https://launchpad.net/oslo.vmware/+milestone/0.7.0) as well as many other\nchanges:\n\n1661a0a Updated from global requirements\n33f6002 Imported Translations from Transifex\n8b1f97b Do not log when reraising an exception\n575fd70 Imported Translations from Transifex\n0b7ff54 Updated from global requirements\n8ed3d53 Add unit test for VC 5.1 web fault handling\n776c20d Fix to get exception detail with vCenter 5.1\n62d0ba7 Download image API to bypass vCenter\n6aa427d Updated from global requirements\n84a39fb Updated from global requirements\ne25af91 Enable the PBM WSDL to be updated\n9f6f2a3 Support building wheels (PEP-427)\n73d1160 Fixup autoindex.rst only if it exists\n42eab0c Supress error logs when exception is thrown\n2350257 Fix handling of fault details\n7591589 Fix UnboundLocalError during WebFault handling\n89d0131 Use faultstring attribute in suds.WebFault.fault\n54455f2 Imported Translations from Transifex\n95e84eb Fix the log message for progress\n264e428 Add API to get the entity inventory path\nee4d9c0 VimExceptions need to support i18n objects\ndf59368 Switch to using oslo.utils\ne55e677 Use custom transport adapter for file URLs\n1c2987b getText can be called only when doc is not None\ndef85dd Updated from global requirements\n80057e4 Add unit test for suds cache expiration\na3e493a Add a memory based shared cache\n6a72bf1 Updated from global requirements\n4bd0b4c VMware: Enable vCenter SSL certificate validation\n\nFor more details, please see the git log history below or\nhttp://git.openstack.org/cgit/openstack/oslo.vmware/log/\n\nChange-Id: I259fb3bd68d6727c3768b00d284fd40ddc4c85b7\n'}]",0,136614,0ec4255ba941f502369395c93fc4a410e24f4a5d,10,6,1,1653,,,0,"Upgrade oslo.vmware>=0.7.0

This release includes several bug fixes
(https://launchpad.net/oslo.vmware/+milestone/0.7.0) as well as many other
changes:

1661a0a Updated from global requirements
33f6002 Imported Translations from Transifex
8b1f97b Do not log when reraising an exception
575fd70 Imported Translations from Transifex
0b7ff54 Updated from global requirements
8ed3d53 Add unit test for VC 5.1 web fault handling
776c20d Fix to get exception detail with vCenter 5.1
62d0ba7 Download image API to bypass vCenter
6aa427d Updated from global requirements
84a39fb Updated from global requirements
e25af91 Enable the PBM WSDL to be updated
9f6f2a3 Support building wheels (PEP-427)
73d1160 Fixup autoindex.rst only if it exists
42eab0c Supress error logs when exception is thrown
2350257 Fix handling of fault details
7591589 Fix UnboundLocalError during WebFault handling
89d0131 Use faultstring attribute in suds.WebFault.fault
54455f2 Imported Translations from Transifex
95e84eb Fix the log message for progress
264e428 Add API to get the entity inventory path
ee4d9c0 VimExceptions need to support i18n objects
df59368 Switch to using oslo.utils
e55e677 Use custom transport adapter for file URLs
1c2987b getText can be called only when doc is not None
def85dd Updated from global requirements
80057e4 Add unit test for suds cache expiration
a3e493a Add a memory based shared cache
6a72bf1 Updated from global requirements
4bd0b4c VMware: Enable vCenter SSL certificate validation

For more details, please see the git log history below or
http://git.openstack.org/cgit/openstack/oslo.vmware/log/

Change-Id: I259fb3bd68d6727c3768b00d284fd40ddc4c85b7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/14/136614/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,0ec4255ba941f502369395c93fc4a410e24f4a5d,,oslo.vmware>=0.7.0 # Apache-2.0,oslo.vmware>=0.6.0 # Apache-2.0,1,1
openstack%2Ffuel-main~stable%2F6.0~I092397e000efa922ce0bed85644bcbfe44b3c221,openstack/fuel-main,stable/6.0,I092397e000efa922ce0bed85644bcbfe44b3c221,Add missed during merge method,MERGED,2014-12-10 16:00:01.000000000,2014-12-10 16:53:43.000000000,2014-12-10 16:53:42.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-12-10 16:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7dd41ba264ed9bf2a45af3e785c3a6919a43df8d', 'message': 'Add missed during merge method\n\nChange-Id: I092397e000efa922ce0bed85644bcbfe44b3c221\n'}, {'number': 2, 'created': '2014-12-10 16:01:23.000000000', 'files': ['fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3a9af663a546ce3f12b05f516c9890d2af904b3e', 'message': 'Add missed during merge method\n\nChange-Id: I092397e000efa922ce0bed85644bcbfe44b3c221\n'}]",0,140744,3a9af663a546ce3f12b05f516c9890d2af904b3e,13,5,2,6719,,,0,"Add missed during merge method

Change-Id: I092397e000efa922ce0bed85644bcbfe44b3c221
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/44/140744/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/checkers.py'],1,7dd41ba264ed9bf2a45af3e785c3a6919a43df8d,fix_plugins," @logwrap def install_plugin_check_code( remote, plugin, exit_code=0): cmd = ""cd /var && fuel plugins --install {0} "".format(plugin) chan, stdin, stderr, stdout = remote.execute_async(cmd) logger.debug('Try to read status code from chain...') assert_equal( chan.recv_exit_status(), exit_code, 'Install script fails with next message {0}'.format(''.join(stderr)))",,10,0
openstack%2Ffuel-library~stable%2F6.0~I4bd59f233273374545953f16c7843488148096d6,openstack/fuel-library,stable/6.0,I4bd59f233273374545953f16c7843488148096d6,new option manage_password for keystone_user,MERGED,2014-12-10 11:59:19.000000000,2014-12-10 16:42:52.000000000,2014-12-10 15:08:13.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-10 11:59:19.000000000', 'files': ['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb', 'deployment/puppet/keystone/spec/unit/provider/keystone_user/keystone_spec.rb', 'deployment/puppet/keystone/lib/puppet/type/keystone_user.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1f401c323b565886d13e7d1a1bc0be479e2a42bc', 'message': ""new option manage_password for keystone_user\n\nAdds a new option manage_password, which defaults\nto 'True' for all keystone_user objects, that\nhas the effect of enforcing the password of a given\nkeystone_user. If this is disabled, the user may change\nhis or her password at a later time and not be reset\nby the keystone Puppet module.\n\nChange-Id: I4bd59f233273374545953f16c7843488148096d6\nCloses-Bug: #1400701\n""}]",0,140654,1f401c323b565886d13e7d1a1bc0be479e2a42bc,16,8,1,8786,,,0,"new option manage_password for keystone_user

Adds a new option manage_password, which defaults
to 'True' for all keystone_user objects, that
has the effect of enforcing the password of a given
keystone_user. If this is disabled, the user may change
his or her password at a later time and not be reset
by the keystone Puppet module.

Change-Id: I4bd59f233273374545953f16c7843488148096d6
Closes-Bug: #1400701
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/54/140654/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb', 'deployment/puppet/keystone/spec/unit/provider/keystone_user/keystone_spec.rb', 'deployment/puppet/keystone/lib/puppet/type/keystone_user.rb']",3,1f401c323b565886d13e7d1a1bc0be479e2a42bc,," newproperty(:manage_password) do newvalues(/(t|T)rue/, /(f|F)alse/) defaultto('True') munge do |value| value.to_s.capitalize end end ",,52,6
openstack%2Fapi-sig~master~I75162da8a1632e31ca5885de4c6d5be7280b16cc,openstack/api-sig,master,I75162da8a1632e31ca5885de4c6d5be7280b16cc,Clarify 201 Created,MERGED,2014-11-06 16:26:35.000000000,2014-12-10 16:38:18.000000000,2014-12-10 16:38:17.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7}, {'_account_id': 161}, {'_account_id': 170}, {'_account_id': 261}, {'_account_id': 1112}, {'_account_id': 5046}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 6486}, {'_account_id': 6773}, {'_account_id': 8505}, {'_account_id': 8556}, {'_account_id': 10161}, {'_account_id': 10670}, {'_account_id': 11126}, {'_account_id': 11564}, {'_account_id': 12000}, {'_account_id': 12606}, {'_account_id': 12807}, {'_account_id': 14046}]","[{'number': 1, 'created': '2014-11-06 16:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-sig/commit/97e4fabb8eaf116b8c7749d5c04df47dfa7ee179', 'message': 'Clarify 201 Created\n\nChange-Id: I75162da8a1632e31ca5885de4c6d5be7280b16cc\n'}, {'number': 2, 'created': '2014-11-06 16:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-sig/commit/bdb70d25db9dbcbf0799650e3a0b06d6430886d3', 'message': 'Clarify 201 Created\n\nChange-Id: I75162da8a1632e31ca5885de4c6d5be7280b16cc\n'}, {'number': 3, 'created': '2014-11-06 16:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-sig/commit/bef2e92e57171123843e5cacdfd8f96180564740', 'message': 'Clarify 201 Created\n\nChange-Id: I75162da8a1632e31ca5885de4c6d5be7280b16cc\n'}, {'number': 4, 'created': '2014-11-26 21:25:52.000000000', 'files': ['guidelines/http.rst'], 'web_link': 'https://opendev.org/openstack/api-sig/commit/0a281244b109be43db5658bfb79ee307afb5ec6e', 'message': 'Clarify 201 Created\n\nChange-Id: I75162da8a1632e31ca5885de4c6d5be7280b16cc\n'}]",18,133087,0a281244b109be43db5658bfb79ee307afb5ec6e,50,22,4,1112,,,0,"Clarify 201 Created

Change-Id: I75162da8a1632e31ca5885de4c6d5be7280b16cc
",git fetch https://review.opendev.org/openstack/api-sig refs/changes/87/133087/4 && git format-patch -1 --stdout FETCH_HEAD,['guidelines/http.rst'],1,97e4fabb8eaf116b8c7749d5c04df47dfa7ee179,201-header-and-body,2xx Success Codes ~~~~~~~~~~~~~~~~~ * Synchronous resource creation * Must return 201 * Must return a representation of the resource in the body,"Success Codes ~~~~~~~~~~~~~ * If the API call creates a resource on a server, the return code should be **201 Created**.",5,4
openstack%2Fsahara~master~I07fb9af96166272913321d6c2140e567c02a3a37,openstack/sahara,master,I07fb9af96166272913321d6c2140e567c02a3a37,"Removed _i18n module, it is not used directly",MERGED,2014-12-04 18:42:05.000000000,2014-12-10 16:38:04.000000000,2014-12-10 16:38:03.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-04 18:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c534c56f33c17cf90daacd17d9b08e77f45ef098', 'message': 'Removed _i18n module, it is not used directly\n\nChange-Id: I07fb9af96166272913321d6c2140e567c02a3a37\n'}, {'number': 2, 'created': '2014-12-04 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/65777357c36ecb5e4bd0a67db8c47f8adeb35a58', 'message': 'Removed _i18n module, it is not used directly\n\nChange-Id: I07fb9af96166272913321d6c2140e567c02a3a37\n'}, {'number': 3, 'created': '2014-12-05 17:53:18.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/sahara/commit/cb101e9e3e793cb664a0f96fdb8bdfe4fee06188', 'message': 'Removed _i18n module, it is not used directly\n\nChange-Id: I07fb9af96166272913321d6c2140e567c02a3a37\n'}]",3,139146,cb101e9e3e793cb664a0f96fdb8bdfe4fee06188,23,7,3,7555,,,0,"Removed _i18n module, it is not used directly

Change-Id: I07fb9af96166272913321d6c2140e567c02a3a37
",git fetch https://review.opendev.org/openstack/sahara refs/changes/46/139146/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,c534c56f33c17cf90daacd17d9b08e77f45ef098,,,module=_i18n,0,1
openstack%2Fdevstack~stable%2Ficehouse~I14b4301f9211529e5ff6fe56f65392c1d198a18a,openstack/devstack,stable/icehouse,I14b4301f9211529e5ff6fe56f65392c1d198a18a,Hard code icehouse service extension lists,MERGED,2014-12-08 17:02:19.000000000,2014-12-10 16:37:54.000000000,2014-12-10 16:37:54.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10016}]","[{'number': 1, 'created': '2014-12-08 17:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40374260e35a54e92c43da7e46aede772ddb8dcf', 'message': ""Hard code icehouse service extension lists\n\nThis commit adds the hard coded service extension lists for icehouse\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the icehouse\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I14b4301f9211529e5ff6fe56f65392c1d198a18a\n""}, {'number': 2, 'created': '2014-12-08 17:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0c4d85b5cddeccef0cee84e5e426d3faddc6660d', 'message': ""Hard code icehouse service extension lists\n\nThis commit adds the hard coded service extension lists for icehouse\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the icehouse\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I14b4301f9211529e5ff6fe56f65392c1d198a18a\n""}, {'number': 3, 'created': '2014-12-08 19:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9b0bee588673f6ae5ee36d97f7b6c44e060b59f8', 'message': ""Hard code icehouse service extension lists\n\nThis commit adds the hard coded service extension lists for icehouse\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the icehouse\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I14b4301f9211529e5ff6fe56f65392c1d198a18a\n""}, {'number': 4, 'created': '2014-12-08 21:56:58.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9ad198337d7e0e6f9d334e416508eb9d8d4f0921', 'message': ""Hard code icehouse service extension lists\n\nThis commit adds the hard coded service extension lists for icehouse\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the icehouse\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I14b4301f9211529e5ff6fe56f65392c1d198a18a\n""}]",0,140078,9ad198337d7e0e6f9d334e416508eb9d8d4f0921,19,8,4,5196,,,0,"Hard code icehouse service extension lists

This commit adds the hard coded service extension lists for icehouse
in the tempest config files. To enable gating with tempest master on
all supported branches the extension list has to be explicit on stable
branches to ensure we don't attempt to run tests for new extensions on
stable branch services. This commit adds these lists for the icehouse
branch.

Implements blueprint branchless-tempest-extensions

Change-Id: I14b4301f9211529e5ff6fe56f65392c1d198a18a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/78/140078/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,40374260e35a54e92c43da7e46aede772ddb8dcf,bp/branchless-tempest-extensions," iniset $TEMPEST_CONFIG compute-feature-enabled api_extensions ${COMPUTE_API_EXTENSIONS:-""AdminActions, Agents, Aggregates, AssistedVolumeSnapshots, AttachInterfaces, AvailabilityZone, BareMetalExtStatus, BareMetalNodes, BlockDeviceMappingV2Boot, CellCapacities, Cells, Certificates, Cloudpipe, CloudpipeUpdate, ConfigDrive, ConsoleAuthTokens, ConsoleOutput, Consoles, Createserverext, DeferredDelete, DiskConfig, Evacuate, ExtendedAvailabilityZone, ExtendedFloatingIps, ExtendedHypervisors, ExtendedIps, ExtendedIpsMac, ExtendedQuotas, ExtendedServerAttributes, ExtendedServices, ExtendedServicesDelete, ExtendedStatus, ExtendedVIFNet, ExtendedVolumes, FixedIPs, FlavorAccess, FlavorDisabled, FlavorExtraData, FlavorExtraSpecs, FlavorManage, FlavorRxtx, FlavorSwap, FloatingIpDns, FloatingIpPools, FloatingIps, FloatingIpsBulk, Fping, HideServerAddresses, Hosts, Hypervisors, ImageSize, InstanceActions, Keypairs, Migrations, Multinic, MultipleCreate, NetworkAssociationSupport, Networks, OSInstanceUsageAuditLog, OSTenantNetworks, PreserveEphemeralOnRebuild, QuotaClasses, Quotas, Rescue, SchedulerHints, SecurityGroupDefaultRules, SecurityGroups, ServerDiagnostics, ServerExternalEvents, ServerGroups, ServerPassword, ServerStartStop, ServerUsage, Services, Shelve, SimpleTenantUsage, UsedLimits, UsedLimitsForAdmin, UserData, UserQuotas, VirtualInterfaces, VolumeAttachmentUpdate, Volumes""} iniset $TEMPEST_CONFIG volume-feature-enabled api_extensions ${VOLUME_API_EXTENSIONS:-""AdminActions, AvailabilityZones, Backups, CreateVolumeExtension, ExtendedServices, ExtendedSnapshotAttributes, Hosts, Qos_specs_manage, QuotaClasses, Quotas, SchedulerHints, Services, SnapshotActions, TypesExtraSpecs, TypesManage, UsedLimits, VolumeActions, VolumeEncryptionMetadata, VolumeHostAttribute, VolumeImageMetadata, VolumeManage, VolumeMigStatusAttribute, VolumeTenantAttribute, VolumeTransfer, VolumeTypeEncryption, VolumeUnmanage""} iniset $TEMPEST_CONFIG network-feature-enabled api_extensions ${NETWORK_API_EXTENSIONS:-""agent, allowed-address-pairs, binding, dhcp_agent_scheduler, ext-gw-mode, external-net, extra_dhcp_opt, extraroute, fwaas, l3_agent_scheduler, lbaas, lbaas_agent_scheduler, metering, multi-provider, provider, quotas, router, security-group, service-type, vpnaas}"" # Object Storage iniset $TEMPEST_CONFIG object-storage-feature-enabled discoverable_apis ${OBJECT_STORAGE_API_EXTENSIONS:-""account_quotas, bulk_delete, bulk_upload, container_quotas, container_sync, crossdomain, formpost, keystoneauth, ratelimit, slo, staticweb, tempauth, tempurl""}"," iniset $TEMPEST_CONFIG network-feature-enabled api_extensions ""${NETWORK_API_EXTENSIONS:-all}""",5,1
openstack%2Fneutron~master~I87bde8be831ee7f005886671be3fbd7999bc51be,openstack/neutron,master,I87bde8be831ee7f005886671be3fbd7999bc51be,IT IS A TEST,ABANDONED,2014-11-21 12:04:29.000000000,2014-12-10 16:36:31.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-11-21 12:04:29.000000000', 'files': ['neutron/tests/unit/db/test_ipam.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf47809afbb31c00724e3856a45155a11fdcad32', 'message': 'IT IS A TEST\n\nChange-Id: I87bde8be831ee7f005886671be3fbd7999bc51be\n'}]",1,136313,cf47809afbb31c00724e3856a45155a11fdcad32,21,18,1,6788,,,0,"IT IS A TEST

Change-Id: I87bde8be831ee7f005886671be3fbd7999bc51be
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/136313/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/db/test_ipam.py'],1,cf47809afbb31c00724e3856a45155a11fdcad32,db-test,"# Copyright 2014 SUSE Linux Products GmbH # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import random from sqlalchemy.orm import sessionmaker import eventlet from oslo.config import cfg from oslo.db.sqlalchemy import session from oslo.db.sqlalchemy import test_base from neutron.api.v2 import attributes from neutron.common import constants from neutron.common import exceptions as n_exc from neutron import context from neutron.db import api as db_api from neutron.db import db_base_plugin_v2 as base_plugin from neutron.db import model_base from neutron.db import models_v2 def get_admin_test_context(db_url, read_deleted=""no"", load_admin_roles=True): ctx = context.Context(user_id=None, tenant_id=None, is_admin=True, read_deleted=read_deleted, load_admin_roles=load_admin_roles, overwrite=False) facade = session.EngineFacade(db_url) ctx._session = facade.get_session( autocommit=False, expire_on_commit=True) return ctx class IpamTestCase(object): def configure_test(self): # cfg.CONF.set_override('connection', self.engine.url, group='database') model_base.BASEV2.metadata.create_all(self.engine) self.plugin = base_plugin.NeutronDbPluginV2() self.cxt = get_admin_test_context(self.engine.url) # self.cxt._session = session.EngineFacade(self.engine.url).get_session( # autocommit=False, expire_on_commit=True) cfg.CONF.set_override('notify_nova_on_port_status_changes', False) self.tenant_id = 'test_tenant' self.network_id = 'test_net_id' self.subnet_id = 'test_sub_id' self.port_id = 'test_p_id' self._create_network() self._create_subnet() def resultset_to_dicts(self, resultset, keys): dicts = [] for item in resultset: item_dict = dict((x, item[x]) for x in keys) dicts.append(item_dict) return dicts def assert_ip_alloc_matches(self, expected, resultset): keys = ['port_id', 'ip_address', 'subnet_id', 'network_id'] actual = self.resultset_to_dicts(resultset, keys) self.assertEqual(expected, actual) def assert_ip_avail_range_matches(self, expected, resultset): keys = ['first_ip', 'last_ip'] actual = self.resultset_to_dicts(resultset, keys) self.assertEqual(expected, actual) def assert_ip_alloc_pool_matches(self, expected, resultset): keys = ['first_ip', 'last_ip', 'subnet_id'] actual = self.resultset_to_dicts(resultset, keys) self.assertEqual(expected, actual) def query_db_and_assert_ip_alloc_matches(self, expected): ip_alloc = self.cxt.session.query(models_v2.IPAllocation).all() self.assert_ip_alloc_matches(expected, ip_alloc) def query_db_and_assert_ip_avail_range_matches(self, expected): ip_avail_range = self.cxt.session.query( models_v2.IPAvailabilityRange).all() self.assert_ip_avail_range_matches(expected, ip_avail_range) def query_db_and_assert_alloc_pool_matches(self, expected): ip_alloc_pool = self.cxt.session.query( models_v2.IPAllocationPool).all() self.assert_ip_alloc_pool_matches(expected, ip_alloc_pool) def _create_network(self): network = {'tenant_id': self.tenant_id, 'id': self.network_id, 'name': 'test-net', 'admin_state_up': True, 'shared': False, 'status': constants.NET_STATUS_ACTIVE} return self.plugin.create_network(self.cxt, {'network': network}) def _create_subnet(self): subnet = {'tenant_id': self.tenant_id, 'id': self.subnet_id, 'name': 'test_sub', 'network_id': self.network_id, 'ip_version': 4, 'cidr': '10.10.10.0/29', 'enable_dhcp': False, 'gateway_ip': '10.10.10.1', 'shared': False, 'allocation_pools': attributes.ATTR_NOT_SPECIFIED, 'dns_nameservers': attributes.ATTR_NOT_SPECIFIED, 'host_routes': attributes.ATTR_NOT_SPECIFIED} return self.plugin.create_subnet(self.cxt, {'subnet': subnet}) def _create_port(self, port_id, fixed_ips=None): port_fixed_ips = (fixed_ips if fixed_ips else attributes.ATTR_NOT_SPECIFIED) port = {'tenant_id': self.tenant_id, 'name': 'test_port', 'id': port_id, 'network_id': self.network_id, 'mac_address': '%d.02.01.00.%d' % (random.randint(10, 99), random.randint(10, 99)), 'admin_state_up': True, 'status': constants.PORT_STATUS_ACTIVE, 'device_id': 'test_dev_id', 'device_owner': 'compute', 'fixed_ips': port_fixed_ips} self.plugin.create_port(self.cxt, {'port': port}) port_db = self.plugin.get_port(self.cxt, port_id) if fixed_ips is None: port['fixed_ips'] = port_db['fixed_ips'] self.assertEqual(port, port_db) def test_allocate_fixed_ip(self): fixed_ip = [{'ip_address': ""10.10.10.3"", 'subnet_id': self.subnet_id}] self._create_port(self.port_id, fixed_ip) ip_alloc_expected = [{'port_id': self.port_id, 'ip_address': fixed_ip[0].get('ip_address'), 'subnet_id': self.subnet_id, 'network_id': self.network_id}] ip_avail_ranges_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.2'}, {'first_ip': '10.10.10.4', 'last_ip': '10.10.10.6'}] ip_alloc_pool_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.6', 'subnet_id': self.subnet_id}] self.query_db_and_assert_ip_alloc_matches(ip_alloc_expected) self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) def test_allocate_first_available_ip(self): self._create_port(self.port_id) ip_alloc_expected = [{'port_id': self.port_id, 'ip_address': '10.10.10.2', 'subnet_id': self.subnet_id, 'network_id': self.network_id}] ip_avail_ranges_expected = [{'first_ip': '10.10.10.3', 'last_ip': '10.10.10.6'}] ip_alloc_pool_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.6', 'subnet_id': self.subnet_id}] self.query_db_and_assert_ip_alloc_matches(ip_alloc_expected) self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) def test_allocate_fixed_ips_concurrently(self): p1_fixed_ip = [{'ip_address': ""10.10.10.3"", 'subnet_id': self.subnet_id}] p2_fixed_ip = [{'ip_address': ""10.10.10.5"", 'subnet_id': self.subnet_id}] self.port2_id = 'test_p_id_2' self._create_port(self.port_id, p1_fixed_ip) eventlet.spawn( self._create_port, self.port2_id, p2_fixed_ip).wait() ip_alloc_expected = [{'port_id': self.port_id, 'ip_address': '10.10.10.3', 'subnet_id': self.subnet_id, 'network_id': self.network_id}, {'port_id': self.port2_id, 'ip_address': '10.10.10.5', 'subnet_id': self.subnet_id, 'network_id': self.network_id}] ip_avail_ranges_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.2'}, {'first_ip': '10.10.10.4', 'last_ip': '10.10.10.4'}, {'first_ip': '10.10.10.6', 'last_ip': '10.10.10.6'}] ip_alloc_pool_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.6', 'subnet_id': self.subnet_id}] self.query_db_and_assert_ip_alloc_matches(ip_alloc_expected) self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) def test_allocate_ip_exausted_pool(self): # available from .2 up tp .6 -> 5 for i in range(1, 6): self._create_port(self.port_id + str(i)) ip_avail_ranges_expected = [] ip_alloc_pool_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.6', 'subnet_id': self.subnet_id}] self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) # Create another port self.assertRaises(n_exc.IpAddressGenerationFailure, self._create_port, self.port_id) def test_rebuild_availability_range(self): for i in range(1, 6): self._create_port(self.port_id + str(i)) ip_avail_ranges_expected = [] ip_alloc_pool_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.6', 'subnet_id': self.subnet_id}] self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) # Delete some ports, this will free the first two IPs for i in range(1, 3): self.plugin.delete_port(self.cxt, self.port_id + str(i)) # Create another port, this will trigger the rebuilding of the # availability ranges self._create_port(self.port_id) ip_avail_ranges_expected = [{'first_ip': '10.10.10.3', 'last_ip': '10.10.10.3'}] ip_alloc = self.cxt.session.query(models_v2.IPAllocation).all() self.assertEqual(4, len(ip_alloc)) self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) def test_rebuild_availability_range_concurrent_port_operations(self): for i in range(1, 4): self._create_port(self.port_id + str(i)) def create_ports(): for i in range(4, 6): self._create_port(self.port_id + str(i)) eventlet.spawn(create_ports).wait() ip_avail_ranges_expected = [] ip_alloc_pool_expected = [{'first_ip': '10.10.10.2', 'last_ip': '10.10.10.6', 'subnet_id': self.subnet_id}] self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) # Delete some ports, this will free the first two IPs for i in range(1, 3): self.plugin.delete_port(self.cxt, self.port_id + str(i)) # Create another port concurrently, this will trigger the # rebuilding of the availability ranges eventlet.spawn(self._create_port, self.port_id).wait() ip_avail_ranges_expected = [{'first_ip': '10.10.10.3', 'last_ip': '10.10.10.3'}] ip_alloc = self.cxt.session.query(models_v2.IPAllocation).all() self.assertEqual(4, len(ip_alloc)) self.query_db_and_assert_alloc_pool_matches(ip_alloc_pool_expected) self.query_db_and_assert_ip_avail_range_matches( ip_avail_ranges_expected) class TestIpamMySql(test_base.MySQLOpportunisticTestCase, IpamTestCase): def setUp(self): super(TestIpamMySql, self).setUp() # TestContext._session = sessionmaker(self.engine)() super(TestIpamMySql, self).configure_test() def tearDown(self): # db_api._FACADE = None # cfg.CONF.clear_override('connection', group='database') super(TestIpamMySql, self).tearDown() class TestIpamPsql(test_base.PostgreSQLOpportunisticTestCase, IpamTestCase): def setUp(self): super(TestIpamPsql, self).setUp() super(TestIpamPsql, self).configure_test() def tearDown(self): # db_api._FACADE = None # cfg.CONF.clear_override('connection', group='database') super(TestIpamPsql, self).tearDown() ",,312,0
openstack%2Ffuel-web~master~I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d,openstack/fuel-web,master,I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d,Fixed regex for vCenter host,MERGED,2014-12-08 16:54:17.000000000,2014-12-10 16:36:23.000000000,2014-12-10 16:36:22.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 13516}]","[{'number': 1, 'created': '2014-12-08 16:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a4f41ba7cd70df3daf248cffa48d49fc0b3156cd', 'message': 'Fixed regex for vCenter host\n\nFixed regex for vCenter IP to allow use hostnames too\nFixed fields descriptions for vCenter IP\n\nDocimpact\ncloses-bug: #1370753\n\nChange-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d\n'}, {'number': 2, 'created': '2014-12-09 10:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0249af7280f5603f014175fc2ea92bdf75214b07', 'message': 'Fixed regex for vCenter host\n\nFixed regex for vCenter IP to allow use hostnames too\nFixed fields descriptions for vCenter IP\n\nDocimpact\ncloses-bug: #1370753\n\nChange-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d\n'}, {'number': 3, 'created': '2014-12-09 11:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/df51a8c188a1d43dc79b9c4fbbab9f84d1dcb0ec', 'message': 'Fixed regex for vCenter host\n\nFixed regex for vCenter IP to allow use hostnames too\nFixed fields descriptions for vCenter IP\n\nDocimpact\ncloses-bug: #1370753\n\nChange-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d\n'}, {'number': 4, 'created': '2014-12-09 15:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e016dab1fff126b72a2c83b08cfb8ced1dcbd162', 'message': 'Fixed regex for vCenter host\n\nFixed regex for vCenter IP to allow use hostnames too\nFixed fields descriptions for vCenter IP\n\nDocimpact\ncloses-bug: #1370753\n\nChange-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d\n'}, {'number': 5, 'created': '2014-12-09 15:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7a4a03883f788ed2edee3cbfa90518fc673e4c64', 'message': 'Fixed regex for vCenter host\n\nFixed regex for vCenter IP to allow use hostnames too\nFixed fields descriptions for vCenter IP\n\nDocimpact\ncloses-bug: #1370753\n\nChange-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d\n'}, {'number': 6, 'created': '2014-12-10 12:29:59.000000000', 'files': ['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4ed4ff42cd2b80b1141bdd7640779efe0a2ca2b9', 'message': 'Fixed regex for vCenter host\n\nFixed regex for vCenter IP to allow use hostnames too\nFixed fields descriptions for vCenter IP\n\nDocimpact\ncloses-bug: #1370753\n\nChange-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d\n'}]",11,140076,4ed4ff42cd2b80b1141bdd7640779efe0a2ca2b9,47,11,6,12139,,,0,"Fixed regex for vCenter host

Fixed regex for vCenter IP to allow use hostnames too
Fixed fields descriptions for vCenter IP

Docimpact
closes-bug: #1370753

Change-Id: I79dbd28f9880b0c0a9d918fa1d86876aec2ec38d
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/76/140076/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml']",2,a4f41ba7cd70df3daf248cffa48d49fc0b3156cd,fix_vcenter_hostname," label: ""vCenter Hostname or IP"" description: ""Hostname or IP Address of vCenter"" source: &ipv4_or_hostname_regex '^(([\d]|[1-9][\d]|1[\d]{2}|2[0-4][\d]|25[0-5])\.){3}([\d]|[1-9][\d]|1[\d]{2}|2[0-4][\d]|25[0-5])$|^(([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\-]*[a-zA-Z0-9])\.)*([A-Za-z0-9]|[A-Za-z0-9][A-Za-z0-9\-]*[A-Za-z0-9])$' error: 'Specify valid Hostname or IPv4 address' label: ""vCenter/ESXi Hostname or IP"" description: ""Hostname or IP Address of vCenter/ESXi"" source: *ipv4_or_hostname_regex error: 'Specify valid Hostname or IPv4 address' source: *ipv4_or_hostname_regex"," label: ""vCenter IP"" description: ""IP Address of vCenter"" source: &ipv4_regex '^(([\d]|[1-9][\d]|1[\d]{2}|2[0-4][\d]|25[0-5])\.){3}([\d]|[1-9][\d]|1[\d]{2}|2[0-4][\d]|25[0-5])$' error: 'Specify valid IPv4 address' label: ""vCenter/ESXi IP"" description: ""IP Address of vCenter/ESXi"" source: *ipv4_regex error: 'Specify valid IPv4 address' source: *ipv4_regex",12,12
openstack%2Foslo-incubator~master~Id0469b31a51ee6482d8b7bcca7664854d705c102,openstack/oslo-incubator,master,Id0469b31a51ee6482d8b7bcca7664854d705c102,Delete graduated concurrency files,MERGED,2014-09-19 17:09:31.000000000,2014-12-10 16:34:19.000000000,2014-12-10 16:34:18.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-09-19 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7bf715cd7eb90ae077810f64a9057ea4a14e9f87', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 2, 'created': '2014-09-23 19:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/804a88ef4e3c6ef5e469d7293b2d99792d357948', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 3, 'created': '2014-09-25 13:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/db96ace2f607ce1ffe0ff6cf3fced2d4f08b2318', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 4, 'created': '2014-12-05 18:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9c058ccdbe538d7d73f6f74a2463b6d856ae9694', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 5, 'created': '2014-12-05 18:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f5b1620b1c2a716727a5e40c3e9f17b9ca5b614e', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 6, 'created': '2014-12-05 18:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/88c25ee327441a7b5e906ec7270854850c9a4723', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 7, 'created': '2014-12-05 20:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e8184f28f12ccd1054412ac729d09b5cce7447f7', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}, {'number': 8, 'created': '2014-12-08 10:15:27.000000000', 'files': ['tests/unit/test_processutils.py', 'openstack/common/fixture/lockutils.py', 'tests/unit/test_policy.py', 'openstack/common/lockutils.py', 'tests/unit/test_lockutils_eventlet.py', 'openstack/common/processutils.py', 'requirements.txt', 'openstack/common/cache/_backends/memory.py', 'MAINTAINERS', 'tools/run_tests_common.sh', 'tests/unit/test_lockutils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8b833185e378fa221d81c3e3ff37b644ea4fb49e', 'message': 'Delete graduated concurrency files\n\nPer the new process, we will not be keeping graduated files around\non the master branch of incubator.\n\nCo-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>\nChange-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102\nCloses-Bug: 1371697\n'}]",7,122796,8b833185e378fa221d81c3e3ff37b644ea4fb49e,35,6,8,6928,,,0,"Delete graduated concurrency files

Per the new process, we will not be keeping graduated files around
on the master branch of incubator.

Co-Authored-By: Ihar Hrachyshka <ihrachys@redhat.com>
Change-Id: Id0469b31a51ee6482d8b7bcca7664854d705c102
Closes-Bug: 1371697
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/96/122796/8 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_processutils.py', 'openstack/common/fixture/lockutils.py', 'openstack/common/processutils.py', 'openstack/common/lockutils.py', 'tests/unit/test_lockutils.py']",5,7bf715cd7eb90ae077810f64a9057ea4a14e9f87,bug/1371697,,"# Copyright 2011 Justin Santa Barbara # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import errno import fcntl import multiprocessing import os import shutil import sys import tempfile import threading import time from oslo.config import cfg from oslotest import base as test_base import six from six import moves from openstack.common.fixture import config from openstack.common.fixture import lockutils as fixtures from openstack.common import lockutils class LockTestCase(test_base.BaseTestCase): def setUp(self): super(LockTestCase, self).setUp() self.config = self.useFixture(config.Config()).config def test_synchronized_wrapped_function_metadata(self): @lockutils.synchronized('whatever', 'test-') def foo(): """"""Bar."""""" pass self.assertEqual(foo.__doc__, 'Bar.', ""Wrapped function's docstring "" ""got lost"") self.assertEqual(foo.__name__, 'foo', ""Wrapped function's name "" ""got mangled"") def test_lock_acquire_release_file_lock(self): lock_dir = tempfile.mkdtemp() lock_file = os.path.join(lock_dir, 'lock') lock = lockutils._FcntlLock(lock_file) def try_lock(): lock.release() # child co-owns it before fork try: my_lock = lockutils._FcntlLock(lock_file) my_lock.lockfile = open(lock_file, 'w') my_lock.trylock() my_lock.unlock() os._exit(1) except IOError: os._exit(0) def attempt_acquire(count): children = [] for i in range(count): child = multiprocessing.Process(target=try_lock) child.start() children.append(child) exit_codes = [] for child in children: child.join() exit_codes.append(child.exitcode) return sum(exit_codes) self.assertTrue(lock.acquire()) try: acquired_children = attempt_acquire(10) self.assertEqual(0, acquired_children) finally: lock.release() try: acquired_children = attempt_acquire(5) self.assertNotEqual(0, acquired_children) finally: try: shutil.rmtree(lock_dir) except IOError: pass def test_lock_internally(self): """"""We can lock across multiple threads."""""" saved_sem_num = len(lockutils._semaphores) seen_threads = list() def f(_id): with lockutils.lock('testlock2', 'test-', external=False): for x in range(10): seen_threads.append(_id) threads = [] for i in range(10): thread = threading.Thread(target=f, args=(i,)) threads.append(thread) thread.start() for thread in threads: thread.join() self.assertEqual(len(seen_threads), 100) # Looking at the seen threads, split it into chunks of 10, and verify # that the last 9 match the first in each chunk. for i in range(10): for j in range(9): self.assertEqual(seen_threads[i * 10], seen_threads[i * 10 + 1 + j]) self.assertEqual(saved_sem_num, len(lockutils._semaphores), ""Semaphore leak detected"") def test_nested_synchronized_external_works(self): """"""We can nest external syncs."""""" tempdir = tempfile.mkdtemp() try: self.config(lock_path=tempdir) sentinel = object() @lockutils.synchronized('testlock1', 'test-', external=True) def outer_lock(): @lockutils.synchronized('testlock2', 'test-', external=True) def inner_lock(): return sentinel return inner_lock() self.assertEqual(sentinel, outer_lock()) finally: if os.path.exists(tempdir): shutil.rmtree(tempdir) def _do_test_lock_externally(self): """"""We can lock across multiple processes."""""" def lock_files(handles_dir): with lockutils.lock('external', 'test-', external=True): # Open some files we can use for locking handles = [] for n in range(50): path = os.path.join(handles_dir, ('file-%s' % n)) handles.append(open(path, 'w')) # Loop over all the handles and try locking the file # without blocking, keep a count of how many files we # were able to lock and then unlock. If the lock fails # we get an IOError and bail out with bad exit code count = 0 for handle in handles: try: fcntl.flock(handle, fcntl.LOCK_EX | fcntl.LOCK_NB) count += 1 fcntl.flock(handle, fcntl.LOCK_UN) except IOError: os._exit(2) finally: handle.close() # Check if we were able to open all files self.assertEqual(50, count) handles_dir = tempfile.mkdtemp() try: children = [] for n in range(50): pid = os.fork() if pid: children.append(pid) else: try: lock_files(handles_dir) finally: os._exit(0) for child in children: (pid, status) = os.waitpid(child, 0) if pid: self.assertEqual(0, status) finally: if os.path.exists(handles_dir): shutil.rmtree(handles_dir, ignore_errors=True) def test_lock_externally(self): lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) try: self._do_test_lock_externally() finally: if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_lock_externally_lock_dir_not_exist(self): lock_dir = tempfile.mkdtemp() os.rmdir(lock_dir) self.config(lock_path=lock_dir) try: self._do_test_lock_externally() finally: if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_synchronized_with_prefix(self): lock_name = 'mylock' lock_pfix = 'mypfix-' foo = lockutils.synchronized_with_prefix(lock_pfix) @foo(lock_name, external=True) def bar(dirpath, pfix, name): return True lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) self.assertTrue(bar(lock_dir, lock_pfix, lock_name)) def test_synchronized_without_prefix(self): lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) @lockutils.synchronized('lock', external=True) def test_without_prefix(): # We can't check much pass try: test_without_prefix() finally: if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_synchronized_prefix_without_hypen(self): lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) @lockutils.synchronized('lock', 'hypen', True) def test_without_hypen(): # We can't check much pass try: test_without_hypen() finally: if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_contextlock(self): lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) try: # Note(flaper87): Lock is not external, which means # a semaphore will be yielded with lockutils.lock(""test"") as sem: if six.PY2: self.assertTrue(isinstance(sem, threading._Semaphore)) else: self.assertTrue(isinstance(sem, threading.Semaphore)) # NOTE(flaper87): Lock is external so an InterProcessLock # will be yielded. with lockutils.lock(""test2"", external=True) as lock: self.assertTrue(lock.exists()) with lockutils.lock(""test1"", external=True) as lock1: self.assertTrue(isinstance(lock1, lockutils.InterProcessLock)) finally: if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_contextlock_unlocks(self): lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) sem = None try: with lockutils.lock(""test"") as sem: if six.PY2: self.assertTrue(isinstance(sem, threading._Semaphore)) else: self.assertTrue(isinstance(sem, threading.Semaphore)) with lockutils.lock(""test2"", external=True) as lock: self.assertTrue(lock.exists()) # NOTE(flaper87): Lock should be free with lockutils.lock(""test2"", external=True) as lock: self.assertTrue(lock.exists()) # NOTE(flaper87): Lock should be free # but semaphore should already exist. with lockutils.lock(""test"") as sem2: self.assertEqual(sem, sem2) finally: if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_remove_lock_external_file(self): lock_name = 'mylock' lock_pfix = 'mypfix-remove-lock-test-' lock_dir = tempfile.mkdtemp() self.config(lock_path=lock_dir) lockutils.remove_external_lock_file(lock_name, lock_pfix) for ent in os.listdir(lock_dir): self.assertRaises(OSError, ent.startswith, lock_pfix) if os.path.exists(lock_dir): shutil.rmtree(lock_dir, ignore_errors=True) def test_no_slash_in_b64(self): # base64(sha1(foobar)) has a slash in it with lockutils.lock(""foobar""): pass class BrokenLock(lockutils._FileLock): def __init__(self, name, errno_code): super(BrokenLock, self).__init__(name) self.errno_code = errno_code def unlock(self): pass def trylock(self): err = IOError() err.errno = self.errno_code raise err class FileBasedLockingTestCase(test_base.BaseTestCase): def setUp(self): super(FileBasedLockingTestCase, self).setUp() self.lock_dir = tempfile.mkdtemp() def test_lock_file_exists(self): lock_file = os.path.join(self.lock_dir, 'lock-file') @lockutils.synchronized('lock-file', external=True, lock_path=self.lock_dir) def foo(): self.assertTrue(os.path.exists(lock_file)) foo() def test_bad_acquire(self): lock_file = os.path.join(self.lock_dir, 'lock') lock = BrokenLock(lock_file, errno.EBUSY) self.assertRaises(threading.ThreadError, lock.acquire) def test_interprocess_lock(self): lock_file = os.path.join(self.lock_dir, 'processlock') pid = os.fork() if pid: # Make sure the child grabs the lock first start = time.time() while not os.path.exists(lock_file): if time.time() - start > 5: self.fail('Timed out waiting for child to grab lock') time.sleep(0) lock1 = lockutils.InterProcessLock('foo') lock1.lockfile = open(lock_file, 'w') self.assertRaises(IOError, lock1.trylock) else: try: lock2 = lockutils.InterProcessLock('foo') lock2.lockfile = open(lock_file, 'w') lock2.trylock() finally: # NOTE(bnemec): This is racy, but I don't want to add any # synchronization primitives that might mask a problem # with the one we're trying to test here. time.sleep(.5) os._exit(0) def test_interthread_external_lock(self): call_list = [] @lockutils.synchronized('foo', external=True, lock_path=self.lock_dir) def foo(param): """"""Simulate a long-running threaded operation."""""" call_list.append(param) # NOTE(bnemec): This is racy, but I don't want to add any # synchronization primitives that might mask a problem # with the one we're trying to test here. time.sleep(.5) call_list.append(param) def other(param): foo(param) thread = threading.Thread(target=other, args=('other',)) thread.start() # Make sure the other thread grabs the lock start = time.time() while not os.path.exists(os.path.join(self.lock_dir, 'foo')): if time.time() - start > 5: self.fail('Timed out waiting for thread to grab lock') time.sleep(0) thread1 = threading.Thread(target=other, args=('main',)) thread1.start() thread1.join() thread.join() self.assertEqual(call_list, ['other', 'other', 'main', 'main']) class LockutilsModuleTestCase(test_base.BaseTestCase): def setUp(self): super(LockutilsModuleTestCase, self).setUp() self.old_env = os.environ.get('OSLO_LOCK_PATH') def tearDown(self): if self.old_env is None: del os.environ['OSLO_LOCK_PATH'] else: os.environ['OSLO_LOCK_PATH'] = self.old_env super(LockutilsModuleTestCase, self).tearDown() def _lock_path_conf_test(self, lock_dir): cfg.CONF.unregister_opts(lockutils.util_opts) lockutils_ = moves.reload_module(lockutils) with lockutils_.lock('test-lock', external=True): if not os.path.exists(lock_dir): os._exit(2) if not os.path.exists(os.path.join(lock_dir, 'test-lock')): os._exit(3) def test_main(self): script = '\n'.join([ 'import os', 'lock_path = os.environ.get(""OSLO_LOCK_PATH"")', 'assert lock_path is not None', 'assert os.path.isdir(lock_path)', ]) argv = ['', sys.executable, '-c', script] retval = lockutils.main(argv) self.assertEqual(retval, 0, ""Bad OSLO_LOCK_PATH has been set"") class TestLockFixture(test_base.BaseTestCase): def setUp(self): super(TestLockFixture, self).setUp() self.config = self.useFixture(config.Config()).config self.tempdir = tempfile.mkdtemp() def _check_in_lock(self): self.assertTrue(self.lock.exists()) def tearDown(self): self._check_in_lock() super(TestLockFixture, self).tearDown() def test_lock_fixture(self): # Setup lock fixture to test that teardown is inside the lock self.config(lock_path=self.tempdir) fixture = fixtures.LockFixture('test-lock') self.useFixture(fixture) self.lock = fixture.lock ",0,1539
openstack%2Fdevstack~master~I263bcf04668953f414a4ef18cb98c1c373e142ad,openstack/devstack,master,I263bcf04668953f414a4ef18cb98c1c373e142ad,Tempest: configure exact set of extensions to test,MERGED,2014-10-06 22:06:27.000000000,2014-12-10 16:33:29.000000000,2014-12-10 16:33:28.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 1653}, {'_account_id': 5196}, {'_account_id': 7118}, {'_account_id': 7930}, {'_account_id': 8859}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-06 22:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5062cef18877aa43d0212a8330ee7b13eb19ec88', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}, {'number': 2, 'created': '2014-10-09 12:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/46c46df236ad4ce0e9c9e41e249fb24034fa7e28', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}, {'number': 3, 'created': '2014-10-16 20:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d0d70892c3e458522d3a404ceb672e4333977efa', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}, {'number': 4, 'created': '2014-10-16 20:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1b99e879f42b4fa14a31efc22ae5506c2108f655', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}, {'number': 5, 'created': '2014-12-03 16:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5d46019be88ff7cf6ab57e0a986f7b59a64cfb53', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}, {'number': 6, 'created': '2014-12-03 18:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/029980502949ebffb00b4edddbe5a2fcc5aa237d', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}, {'number': 7, 'created': '2014-12-09 16:54:18.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/33e8ee20a4ad087f5538e813eace1ca23243e2c5', 'message': 'Tempest: configure exact set of extensions to test\n\nSo far devstack configures tempest either for testing all extensions\nor a specific subset. It does not allow users for specifying a set\nof extensions which should not be exercised.\n\nThis patch adds this support. To this aim, the tempest configuration\nprocess will scan API endpoints for active extensions using the\nverify_tempest_config.py tool, and then will remove those extensions\nwhich have been explicitly disabled by the user.\n\nIf an explicit subset of extensions to enable is passed to devstack,\ntempest will use this subset, rather than the list of active\nextensions.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad\n'}]",11,126422,33e8ee20a4ad087f5538e813eace1ca23243e2c5,46,11,7,261,,,0,"Tempest: configure exact set of extensions to test

So far devstack configures tempest either for testing all extensions
or a specific subset. It does not allow users for specifying a set
of extensions which should not be exercised.

This patch adds this support. To this aim, the tempest configuration
process will scan API endpoints for active extensions using the
verify_tempest_config.py tool, and then will remove those extensions
which have been explicitly disabled by the user.

If an explicit subset of extensions to enable is passed to devstack,
tempest will use this subset, rather than the list of active
extensions.

Implements blueprint branchless-tempest-extensions

Change-Id: I263bcf04668953f414a4ef18cb98c1c373e142ad
",git fetch https://review.opendev.org/openstack/devstack refs/changes/22/126422/6 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,5062cef18877aa43d0212a8330ee7b13eb19ec88,bp/branchless-tempest-extensions,"# remove_disabled_extension - removes disabled extensions from the list of extensions # to test for a given service function remove_disabled_extensions { local extensions_list=$1 shift local disabled_exts=$* OLDIFS=$IFS local IFS=, disabled_exts_array=($disabled_exts) IFS=$OLDIFS for ext_to_remove in ${disabled_exts_array[@]} do extensions_list=${extensions_list/$ext_to_remove"",""} done echo $extensions_list } # Run verify_tempest_config -ur to retrieve enabled extensions on API endpoints tmp_cfg_file=$(mktemp) $TEMPEST_DIR/tempest/cmd/verify_tempest_config.py -uro $tmp_cfg_file compute_api_extensions=${COMPUTE_API_EXTENSIONS:-$(iniget $tmp_cfg_file compute-feature-enabled api_extensions | tr -d "" "")} network_api_extensions=${NETWORK_API_EXTENSIONS:-$(iniget $tmp_cfg_file network-feature-enabled api_extensions | tr -d "" "")} object_storage_api_extensions=${OBJECT_STORAGE_API_EXTENSIONS:-$(iniget $tmp_cfg_file object-storage-feature-enabled discoverable_apis | tr -d "" "")} volume_api_extensions=${VOLUME_API_EXTENSIONS:-$(iniget $tmp_cfg_file volume-feature-enabled api_extensions | tr -d "" "")} # Remove disabled extensions, if any compute_api_extensions=$(remove_disabled_extensions $compute_api_extensions $DISABLE_COMPUTE_API_EXTENSIONS) network_api_extensions=$(remove_disabled_extensions $network_api_extensions $DISABLE_NETWORK_API_EXTENSIONS) object_storage_api_extensions=$(remove_disabled_extensions $object_storage_api_extensions $DISABLE_STORAGE_API_EXTENSIONS) volume_api_extensions=$(remove_disabled_extensions $volume_api_extensions $DISABLE_VOLUME_API_EXTENSIONS) iniset $TEMPEST_CONFIG compute-feature-enabled api_extensions $compute_api_extensions iniset $TEMPEST_CONFIG network-feature-enabled api_extensions $network_api_extensions iniset $TEMPEST_CONFIG object-storage-feature-enabled discoverable_apis $object_storage_api_extensions iniset $TEMPEST_CONFIG volume-feature-enabled api_extensions $volume_api_extensions"," iniset $TEMPEST_CONFIG compute-feature-enabled api_extensions ${COMPUTE_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG compute-feature-disabled api_extensions ${DISABLE_COMPUTE_API_EXTENSIONS} iniset $TEMPEST_CONFIG network-feature-enabled api_extensions ${NETWORK_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG network-feature-disabled api_extensions ${DISABLE_NETWORK_API_EXTENSIONS} iniset $TEMPEST_CONFIG object-storage-feature-enabled discoverable_apis ${OBJECT_STORAGE_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG object-storage-feature-disabled discoverable_apis ${OBJECT_STORAGE_DISABLE_API_EXTENSIONS} iniset $TEMPEST_CONFIG volume-feature-enabled api_extensions ${VOLUME_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG volume-feature-disabled api_extensions ${DISABLE_VOLUME_API_EXTENSIONS}",35,8
openstack%2Fneutron~master~I796a059292e26c4df75c54f095d9e20e99187c98,openstack/neutron,master,I796a059292e26c4df75c54f095d9e20e99187c98,Use comments rather than no-op string statements,MERGED,2014-10-21 04:56:34.000000000,2014-12-10 16:31:52.000000000,2014-12-10 16:31:50.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9305}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 12612}, {'_account_id': 13426}, {'_account_id': 13635}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-21 04:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f706c3c879717282c283e207dcae572290604ba9', 'message': 'Use comments rather than no-op string statements\n\nThis change replaces a few no-op string statements with regular\ncomments.  While there was no harm in the previous use of strings for\ncomments, this allows us to re-enable the corresponding pylint check\nwhich may catch genuinely unintended cases.\n\nChange-Id: I796a059292e26c4df75c54f095d9e20e99187c98\n'}, {'number': 2, 'created': '2014-12-08 21:40:52.000000000', 'files': ['neutron/plugins/ml2/drivers/freescale/config.py', 'neutron/plugins/midonet/plugin.py', 'neutron/plugins/nec/db/models.py', 'neutron/plugins/ml2/drivers/arista/config.py', '.pylintrc', 'neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/hacking/checks.py', 'neutron/plugins/cisco/network_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd5b3646c1a231b46da0eff5bbbb5d3f2949ba50', 'message': 'Use comments rather than no-op string statements\n\nThis change replaces a few no-op string statements with regular\ncomments.  While there was no harm in the previous use of strings for\ncomments, this allows us to re-enable the corresponding pylint check\nwhich may catch genuinely unintended cases.\n\nChange-Id: I796a059292e26c4df75c54f095d9e20e99187c98\n'}]",3,129786,cd5b3646c1a231b46da0eff5bbbb5d3f2949ba50,83,40,2,11279,,,0,"Use comments rather than no-op string statements

This change replaces a few no-op string statements with regular
comments.  While there was no harm in the previous use of strings for
comments, this allows us to re-enable the corresponding pylint check
which may catch genuinely unintended cases.

Change-Id: I796a059292e26c4df75c54f095d9e20e99187c98
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/129786/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/midonet/plugin.py', 'neutron/plugins/nec/db/models.py', 'neutron/plugins/ml2/drivers/arista/config.py', '.pylintrc', 'neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/hacking/checks.py', 'neutron/plugins/cisco/network_plugin.py']",7,f706c3c879717282c283e207dcae572290604ba9,pointless-string-statement, # # Extension API implementation #," """""" Extension API implementation """"""",26,30
openstack%2Ffuel-web~master~I2c38fef2c4ad61db1097edf1903dff1badc546a3,openstack/fuel-web,master,I2c38fef2c4ad61db1097edf1903dff1badc546a3,Fixes Ceph node addition in vCenter env,MERGED,2014-12-10 14:11:47.000000000,2014-12-10 16:22:58.000000000,2014-12-10 16:22:58.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 12139}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-10 14:11:47.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/47286d8d11bc196308ef0a82fe070c4d33e2b26e', 'message': 'Fixes Ceph node addition in vCenter env\n\nCloses-Bug: #1401111\n\nChange-Id: I2c38fef2c4ad61db1097edf1903dff1badc546a3\n'}]",0,140688,47286d8d11bc196308ef0a82fe070c4d33e2b26e,11,7,1,8766,,,0,"Fixes Ceph node addition in vCenter env

Closes-Bug: #1401111

Change-Id: I2c38fef2c4ad61db1097edf1903dff1badc546a3
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/88/140688/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,47286d8d11bc196308ef0a82fe070c4d33e2b26e,bug/1401111," - condition: ""settings:common.libvirt_type.value == 'vcenter' and settings:storage.images_ceph.value == false"" message: ""Ceph RBD for images should be enabled in settings."""," - condition: ""settings:common.libvirt_type.value == 'vcenter'"" message: ""Ceph cannot be used with vCenter""",2,2
openstack%2Fdesignate~master~I98eed46a8dd9918ba36c97fe40619ec42136c723,openstack/designate,master,I98eed46a8dd9918ba36c97fe40619ec42136c723,Added designate-dashboard code to contrib/designate-dashboard,MERGED,2014-11-26 22:12:39.000000000,2014-12-10 16:17:28.000000000,2014-12-10 16:17:27.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 14229}]","[{'number': 1, 'created': '2014-11-26 22:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2ec8228fe039115d5c0bb6d57b325d56ab55f1ff', 'message': 'Added designate-dashboard code to contrib/designate-dashboard\n\nAdded to devstack as well.\n\nChange-Id: I98eed46a8dd9918ba36c97fe40619ec42136c723\n'}, {'number': 2, 'created': '2014-11-26 23:18:25.000000000', 'files': ['contrib/designate-dashboard/doc/source/conf.py', 'contrib/designate-dashboard/designatedashboard/dashboards/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/update_record.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/forms.py', 'contrib/designate-dashboard/designatedashboard/tests/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_create_record.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/tests.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_update_domain.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/views.py', 'contrib/designate-dashboard/test', 'contrib/designate-dashboard/README.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/index.html', 'contrib/designate-dashboard/tox.ini', 'contrib/designate-dashboard/openstack-common.conf', 'contrib/designate-dashboard/MANIFEST.in', 'contrib/designate-dashboard/designatedashboard/tests/base.py', 'contrib/designate-dashboard/test-requirements.txt', 'contrib/designate-dashboard/doc/source/installation.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/create_record.html', 'contrib/designate-dashboard/LICENSE', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/urls.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/tables.py', 'contrib/designate-dashboard/enabled/_70_dns_add_group.py', 'contrib/devstack/lib/designate', 'tox.ini', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/records.html', 'contrib/designate-dashboard/babel.cfg', 'contrib/designate-dashboard/designatedashboard/tests/settings.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/update_domain.html', 'contrib/designate-dashboard/doc/source/readme.rst', 'contrib/designate-dashboard/designatedashboard/api/designate.py', 'contrib/designate-dashboard/designatedashboard/__init__.py', 'contrib/designate-dashboard/requirements.txt', 'contrib/designate-dashboard/doc/source/usage.rst', 'contrib/vagrant/localrc', 'contrib/designate-dashboard/setup.py', 'contrib/designate-dashboard/designatedashboard/api/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/panel.py', 'contrib/designate-dashboard/designatedashboard/exceptions.py', 'contrib/designate-dashboard/HACKING.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/create_domain.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_create_domain.html', 'contrib/designate-dashboard/setup.cfg', 'contrib/designate-dashboard/designatedashboard/tests/.secret_key_store', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/__init__.py', 'contrib/designate-dashboard/CONTRIBUTING.rst', 'contrib/designate-dashboard/doc/source/index.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_update_record.html', 'contrib/designate-dashboard/doc/source/contributing.rst', 'contrib/designate-dashboard/designatedashboard/tests/test_designatedashboard.py', 'contrib/designate-dashboard/enabled/_71_dns_project.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/46a50e06b8fb82c9d48732cd985b5149e03e0334', 'message': 'Added designate-dashboard code to contrib/designate-dashboard\n\nAdded to devstack as well.\n\nChange-Id: I98eed46a8dd9918ba36c97fe40619ec42136c723\n'}]",9,137480,46a50e06b8fb82c9d48732cd985b5149e03e0334,12,4,2,8099,,,0,"Added designate-dashboard code to contrib/designate-dashboard

Added to devstack as well.

Change-Id: I98eed46a8dd9918ba36c97fe40619ec42136c723
",git fetch https://review.opendev.org/openstack/designate refs/changes/80/137480/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/designate-dashboard/doc/source/conf.py', 'contrib/designate-dashboard/designatedashboard/dashboards/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/update_record.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/forms.py', 'contrib/designate-dashboard/designatedashboard/tests/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_create_record.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/tests.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_update_domain.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/views.py', 'contrib/designate-dashboard/test', 'contrib/designate-dashboard/README.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/index.html', 'contrib/designate-dashboard/tox.ini', 'contrib/designate-dashboard/openstack-common.conf', 'contrib/designate-dashboard/MANIFEST.in', 'contrib/designate-dashboard/designatedashboard/tests/base.py', 'contrib/designate-dashboard/test-requirements.txt', 'contrib/designate-dashboard/doc/source/installation.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/create_record.html', 'contrib/designate-dashboard/LICENSE', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/urls.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/tables.py', 'contrib/designate-dashboard/enabled/_70_dns_add_group.py', 'contrib/devstack/lib/designate', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/records.html', 'contrib/designate-dashboard/babel.cfg', 'contrib/designate-dashboard/designatedashboard/tests/settings.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/update_domain.html', 'contrib/designate-dashboard/doc/source/readme.rst', 'contrib/designate-dashboard/designatedashboard/api/designate.py', 'contrib/designate-dashboard/designatedashboard/__init__.py', 'contrib/designate-dashboard/requirements.txt', 'contrib/designate-dashboard/doc/source/usage.rst', 'contrib/vagrant/localrc', 'contrib/designate-dashboard/setup.py', 'contrib/designate-dashboard/designatedashboard/api/__init__.py', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/panel.py', 'contrib/designate-dashboard/designatedashboard/exceptions.py', 'contrib/designate-dashboard/HACKING.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/create_domain.html', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_create_domain.html', 'contrib/designate-dashboard/setup.cfg', 'contrib/designate-dashboard/designatedashboard/tests/.secret_key_store', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/__init__.py', 'contrib/designate-dashboard/CONTRIBUTING.rst', 'contrib/designate-dashboard/doc/source/index.rst', 'contrib/designate-dashboard/designatedashboard/dashboards/project/dns_domains/templates/dns_domains/_update_record.html', 'contrib/designate-dashboard/doc/source/contributing.rst', 'contrib/designate-dashboard/designatedashboard/tests/test_designatedashboard.py', 'contrib/designate-dashboard/enabled/_71_dns_project.py']",51,2ec8228fe039115d5c0bb6d57b325d56ab55f1ff,,"# Copyright 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. PANEL = 'domains' # The name of the panel to be added to HORIZON_CONFIG. Required. PANEL = 'domains' # The name of the dashboard the PANEL associated with. Required. PANEL_DASHBOARD = 'project' # The name of the panel group the PANEL is associated with. PANEL_GROUP = 'dns' # Python panel class of the PANEL to be added. ADD_PANEL = ( 'designatedashboard.dashboards.project.dns_domains.panel.DNSDomains') ",,2984,0
openstack%2Fpuppet-neutron~master~I415001419474dd8d242fe238bbf88b5c45c9f3e9,openstack/puppet-neutron,master,I415001419474dd8d242fe238bbf88b5c45c9f3e9,Fix l3_ha enablement,MERGED,2014-12-10 14:55:35.000000000,2014-12-10 16:11:58.000000000,2014-12-10 16:09:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-10 14:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b29c771eb39ad0236417c063d1f769f8d6cca6f7', 'message': 'Fix l3_ha enablement\n\nThe L3 HA feature needs to be enabled using ""l3_ha=True"" instead of\n""ha_enabled=true"".\n\nChange-Id: I415001419474dd8d242fe238bbf88b5c45c9f3e9\n'}, {'number': 2, 'created': '2014-12-10 15:08:52.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/05eb42aae94253dfd5ffc37dfc665ac3e2631ccd', 'message': 'Fix l3_ha enablement\n\nThe L3 HA feature needs to be enabled using ""l3_ha=True"" instead of\n""ha_enabled=true"".\n\nChange-Id: I415001419474dd8d242fe238bbf88b5c45c9f3e9\n'}]",0,140707,05eb42aae94253dfd5ffc37dfc665ac3e2631ccd,11,4,2,13294,,,0,"Fix l3_ha enablement

The L3 HA feature needs to be enabled using ""l3_ha=True"" instead of
""ha_enabled=true"".

Change-Id: I415001419474dd8d242fe238bbf88b5c45c9f3e9
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/07/140707/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_server_spec.rb', 'manifests/server.pp']",2,b29c771eb39ad0236417c063d1f769f8d6cca6f7,jpena/l3ha, 'DEFAULT/l3_ha': value => true;, 'DEFAULT/ha_enabled': value => true;,2,2
openstack%2Fcongress~master~Ic1256f8e8e4ec265186de175039d05cf7f83efbb,openstack/congress,master,Ic1256f8e8e4ec265186de175039d05cf7f83efbb,Log exception in runtime.update,MERGED,2014-12-04 01:10:29.000000000,2014-12-10 16:11:55.000000000,2014-12-10 16:11:54.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-04 01:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/72599b622f0d0243a3896f0756167182740e0b2d', 'message': 'Log exception in runtime.update\n\nChange-Id: Ic1256f8e8e4ec265186de175039d05cf7f83efbb\n'}, {'number': 2, 'created': '2014-12-04 01:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/193597ef509d53c6b001623c05d6f13e73d1efcb', 'message': 'Log exception in runtime.update\n\nChange-Id: Ic1256f8e8e4ec265186de175039d05cf7f83efbb\n'}, {'number': 3, 'created': '2014-12-04 18:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/316f36046d9f19a454ca1ed0109a8ecca103d1a7', 'message': 'Log exception in runtime.update\n\nChange-Id: Ic1256f8e8e4ec265186de175039d05cf7f83efbb\n'}, {'number': 4, 'created': '2014-12-04 21:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/364cd212e3f8a6efffb7a99cfd872bb1ec657b4c', 'message': 'Log exception in runtime.update\n\nChange-Id: Ic1256f8e8e4ec265186de175039d05cf7f83efbb\n'}, {'number': 5, 'created': '2014-12-10 00:05:07.000000000', 'files': ['congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/1fa42b09dcd4e0ae654d60184f199d490b1d8f88', 'message': 'Log exception in runtime.update\n\nChange-Id: Ic1256f8e8e4ec265186de175039d05cf7f83efbb\n'}]",5,138917,1fa42b09dcd4e0ae654d60184f199d490b1d8f88,36,5,5,12875,,,0,"Log exception in runtime.update

Change-Id: Ic1256f8e8e4ec265186de175039d05cf7f83efbb
",git fetch https://review.opendev.org/openstack/congress refs/changes/17/138917/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/policy/runtime.py'],1,72599b622f0d0243a3896f0756167182740e0b2d,," try: for event in events: formula = compile.reorder_for_safety(event.formula) if event.insert: if self.insert_actual(formula): changes.append(event) else: if self.delete_actual(formula): changes.append(event) except Exception as e: self.last_error = e LOG.exception(""runtime caught an exception"") ", for event in events: formula = compile.reorder_for_safety(event.formula) if event.insert: if self.insert_actual(formula): changes.append(event) else: if self.delete_actual(formula): changes.append(event),13,8
openstack%2Fcongress~master~I317f97b41deca2d5da9fc0690a8f81117afb62af,openstack/congress,master,I317f97b41deca2d5da9fc0690a8f81117afb62af,Add validation for val-col LIST,MERGED,2014-12-05 00:55:18.000000000,2014-12-10 16:09:33.000000000,2014-12-10 16:09:32.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-05 00:55:18.000000000', 'files': ['congress/tests/datasources/test_datasource_driver.py', 'congress/datasources/datasource_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/fb5173d234262db5d5ecdfef2bff433045b74d02', 'message': 'Add validation for val-col LIST\n\nval-col is a required field for lists so we should validate that it is present.\n\nCloses-bug: 1399493\n\nChange-Id: I317f97b41deca2d5da9fc0690a8f81117afb62af\n'}]",3,139291,fb5173d234262db5d5ecdfef2bff433045b74d02,12,6,1,4395,,,0,"Add validation for val-col LIST

val-col is a required field for lists so we should validate that it is present.

Closes-bug: 1399493

Change-Id: I317f97b41deca2d5da9fc0690a8f81117afb62af
",git fetch https://review.opendev.org/openstack/congress refs/changes/91/139291/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/datasources/test_datasource_driver.py', 'congress/datasources/datasource_driver.py']",2,fb5173d234262db5d5ecdfef2bff433045b74d02,bug/1399493," if self.VAL_COL not in translator: raise exception.InvalidParamException( ""Param (%s) must be in translator"" % self.VAL_COL) ", # NOTE(arosen): this method is a duplicate of _validate_vdict_type # revist and see if we should refactor this out..,12,2
openstack%2Fcongress~master~I45d352572d7ea1396b9c989e909ac91cf4b9e882,openstack/congress,master,I45d352572d7ea1396b9c989e909ac91cf4b9e882,Add validation for key-col/val-col VDICT,MERGED,2014-12-05 00:40:04.000000000,2014-12-10 16:09:30.000000000,2014-12-10 16:09:29.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-05 00:40:04.000000000', 'files': ['congress/tests/datasources/test_datasource_driver.py', 'congress/datasources/datasource_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/d1cee0a2051f0e5454f442d5a60b8fad86764403', 'message': 'Add validation for key-col/val-col VDICT\n\nThis are required fields so we should validate that they are present.\n\nCloses-bug: 1399489\n\nChange-Id: I45d352572d7ea1396b9c989e909ac91cf4b9e882\n'}]",3,139288,d1cee0a2051f0e5454f442d5a60b8fad86764403,10,6,1,4395,,,0,"Add validation for key-col/val-col VDICT

This are required fields so we should validate that they are present.

Closes-bug: 1399489

Change-Id: I45d352572d7ea1396b9c989e909ac91cf4b9e882
",git fetch https://review.opendev.org/openstack/congress refs/changes/88/139288/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/datasources/test_datasource_driver.py', 'congress/datasources/datasource_driver.py']",2,d1cee0a2051f0e5454f442d5a60b8fad86764403,bug/1399489," if self.KEY_COL not in translator: raise exception.InvalidParamException( ""Param (%s) must be in translator"" % self.KEY_COL) if self.VAL_COL not in translator: raise exception.InvalidParamException( ""Param (%s) must be in translator"" % self.VAL_COL) ",,25,0
openstack%2Fcongress~master~I9a6915d4662c6d7a169aeea70f12591b4290bf9f,openstack/congress,master,I9a6915d4662c6d7a169aeea70f12591b4290bf9f,Fix wildcard for editors,MERGED,2014-12-10 03:06:31.000000000,2014-12-10 16:09:17.000000000,2014-12-10 16:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-10 03:06:31.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/congress/commit/d8598783d3a638c9400a9b6e1d522753c97e9c51', 'message': 'Fix wildcard for editors\n\nThis patch fixes the wild card for editors as .swl and .swm files\nare not ignored.\n\nChange-Id: I9a6915d4662c6d7a169aeea70f12591b4290bf9f\n'}]",0,140562,d8598783d3a638c9400a9b6e1d522753c97e9c51,16,5,1,4395,,,0,"Fix wildcard for editors

This patch fixes the wild card for editors as .swl and .swm files
are not ignored.

Change-Id: I9a6915d4662c6d7a169aeea70f12591b4290bf9f
",git fetch https://review.opendev.org/openstack/congress refs/changes/62/140562/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,d8598783d3a638c9400a9b6e1d522753c97e9c51,,.*.sw?,.*.swp *.swo *.swn,1,3
openstack%2Fpython-congressclient~master~I1a09d18df7fa0dcce9f29c96d1dce6184f890fd5,openstack/python-congressclient,master,I1a09d18df7fa0dcce9f29c96d1dce6184f890fd5,Update NEWS file with date that 1.0.1 was released,MERGED,2014-12-10 08:28:49.000000000,2014-12-10 16:08:01.000000000,2014-12-10 16:08:00.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 9253}]","[{'number': 1, 'created': '2014-12-10 08:28:49.000000000', 'files': ['NEWS'], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/9cf55d82c6069a50317d1286912dfbda856fd45f', 'message': 'Update NEWS file with date that 1.0.1 was released\n\n$ git show 1.0.1\ntag 1.0.1\nTagger: Aaron Rosen <aaronorosen@gmail.com>\nDate:   Fri Dec 5 10:39:59 2014 -0800\n\n1.0.1 Release!\n\nChange-Id: I1a09d18df7fa0dcce9f29c96d1dce6184f890fd5\n'}]",0,140607,9cf55d82c6069a50317d1286912dfbda856fd45f,6,3,1,4395,,,0,"Update NEWS file with date that 1.0.1 was released

$ git show 1.0.1
tag 1.0.1
Tagger: Aaron Rosen <aaronorosen@gmail.com>
Date:   Fri Dec 5 10:39:59 2014 -0800

1.0.1 Release!

Change-Id: I1a09d18df7fa0dcce9f29c96d1dce6184f890fd5
",git fetch https://review.opendev.org/openstack/python-congressclient refs/changes/07/140607/1 && git format-patch -1 --stdout FETCH_HEAD,['NEWS'],1,9cf55d82c6069a50317d1286912dfbda856fd45f,,1.0.1 - 2014-12-05,1.0.1 - XXXX-XX-XX,1,1
openstack%2Fnova~master~I376a2a9e567baa568bd8d9e5c853fca4ece1d4df,openstack/nova,master,I376a2a9e567baa568bd8d9e5c853fca4ece1d4df,libvirt: Add shutdownFlags support,ABANDONED,2014-10-22 09:11:35.000000000,2014-12-10 16:02:07.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5387}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-22 09:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13016250ed1e8b157256e88d820f75d193c2bb60', 'message': 'libvirt: Add shutdownFlags support\n\nAdds a new flag, `shutdownFlags`, which gives operators the ability to specify\nwhich shutdown methods they want to use on the guest.\n\nThis also allows us to fail-fast if the chosen method is not supported, rather\nthan have to wait for the timeout.\n\nDocImpact\nCloses-Bug: 1384127\n\nChange-Id: I376a2a9e567baa568bd8d9e5c853fca4ece1d4df\n'}, {'number': 2, 'created': '2014-11-21 22:39:41.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/db0c872e47245a4bd21e13fe6aa6b99ed9d07392', 'message': 'libvirt: Add shutdownFlags support\n\nAdds a new flag, `shutdownFlags`, which gives operators the ability to specify\nwhich shutdown methods they want to use on the guest.\n\nThis also allows us to fail-fast if the chosen method is not supported, rather\nthan have to wait for the timeout.\n\nDocImpact\nCloses-Bug: 1384127\n\nChange-Id: I376a2a9e567baa568bd8d9e5c853fca4ece1d4df\n'}]",5,130168,db0c872e47245a4bd21e13fe6aa6b99ed9d07392,21,10,2,475,,,0,"libvirt: Add shutdownFlags support

Adds a new flag, `shutdownFlags`, which gives operators the ability to specify
which shutdown methods they want to use on the guest.

This also allows us to fail-fast if the chosen method is not supported, rather
than have to wait for the timeout.

DocImpact
Closes-Bug: 1384127

Change-Id: I376a2a9e567baa568bd8d9e5c853fca4ece1d4df
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/130168/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/tests/virt/libvirt/test_driver.py']",3,13016250ed1e8b157256e88d820f75d193c2bb60,bug/1384127," mock_domain.shutdownFlags(fakelibvirt.VIR_DOMAIN_SHUTDOWN_DEFAULT) mock_domain.shutdownFlags(fakelibvirt.VIR_DOMAIN_SHUTDOWN_DEFAULT) mock_domain.shutdownFlags(fakelibvirt.VIR_DOMAIN_SHUTDOWN_DEFAULT)\ .AndRaise(libvirt.libvirtError('Err')) def count_shutdowns(flags): mock_domain.shutdownFlags(fakelibvirt.VIR_DOMAIN_SHUTDOWN_DEFAULT)\ .WithSideEffects(count_shutdowns) mock_domain.shutdownFlags(fakelibvirt.VIR_DOMAIN_SHUTDOWN_DEFAULT)\ .WithSideEffects(count_shutdowns) (fakelibvirt.VIR_DOMAIN_SHUTDOWN,) + info_tuple) def test_clean_shutdown_unsupported_fail_fast(self): def shutdownFlags(flags): raise fakelibvirt.make_libvirtError( libvirt.libvirtError, 'foo', error_code=fakelibvirt.VIR_ERR_OPERATION_UNSUPPORTED) info_tuple = ('fake', 'fake', 'fake', 'also_fake') # Mock domain mock_domain = self.mox.CreateMock(libvirt.virDomain) mock_domain.info().AndReturn( (libvirt_driver.VIR_DOMAIN_RUNNING,) + info_tuple) mock_domain.shutdownFlags(fakelibvirt.VIR_DOMAIN_SHUTDOWN_DEFAULT)\ .WithSideEffects(shutdownFlags) self.mox.ReplayAll() def fake_lookup_by_name(instance_name): return mock_domain def fake_create_domain(**kwargs): self.reboot_create_called = True conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} self.stubs.Set(conn, '_lookup_by_name', fake_lookup_by_name) self.stubs.Set(conn, '_create_domain', fake_create_domain) result = conn._clean_shutdown(instance, 10, 3) self.assertEqual(False, result) "," mock_domain.shutdown() mock_domain.shutdown() mock_domain.shutdown().AndRaise(libvirt.libvirtError('Err')) def count_shutdowns(): mock_domain.shutdown().WithSideEffects(count_shutdowns) mock_domain.shutdown().WithSideEffects(count_shutdowns) (libvirt_driver.VIR_DOMAIN_SHUTDOWN,) + info_tuple)",87,11
openstack%2Fnova~master~Iefdd23554e59098f4c4280df1327dc6c8b769732,openstack/nova,master,Iefdd23554e59098f4c4280df1327dc6c8b769732,libvirt: Adding NoopMounter for LVM backed images.,ABANDONED,2014-10-22 08:54:45.000000000,2014-12-10 16:01:58.000000000,,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5387}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-22 08:54:45.000000000', 'files': ['nova/tests/virt/libvirt/test_imagebackend.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/disk/mount/test_api.py', 'nova/tests/virt/test_virt.py', 'nova/virt/disk/mount/api.py', 'nova/virt/disk/mount/noop.py', 'nova/virt/disk/api.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c4b1fd32225469556510a67429e76211c2dc7173', 'message': ""libvirt: Adding NoopMounter for LVM backed images.\n\nLVM backed images are already available as block devices\nand thus do not need to be mounted to nbd or loopback\ndevices. So, that step is skipped and the LVM device is\nmounted directly to the instance's rootfs directory.\n\nChange-Id: Iefdd23554e59098f4c4280df1327dc6c8b769732\nCloses-bug: 1287754\n""}]",3,130163,c4b1fd32225469556510a67429e76211c2dc7173,14,9,1,475,,,0,"libvirt: Adding NoopMounter for LVM backed images.

LVM backed images are already available as block devices
and thus do not need to be mounted to nbd or loopback
devices. So, that step is skipped and the LVM device is
mounted directly to the instance's rootfs directory.

Change-Id: Iefdd23554e59098f4c4280df1327dc6c8b769732
Closes-bug: 1287754
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/130163/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/libvirt/test_imagebackend.py', 'nova/virt/libvirt/driver.py', 'nova/tests/virt/disk/mount/test_api.py', 'nova/tests/virt/test_virt.py', 'nova/virt/disk/mount/api.py', 'nova/virt/disk/mount/noop.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/disk/api.py', 'nova/virt/libvirt/imagebackend.py']",9,c4b1fd32225469556510a67429e76211c2dc7173,bug/1287754, noop_mount = False noop_mount = True ,,274,18
openstack%2Fdevstack~master~I046ae22d59a99ef86da786c4d5db870814ce159f,openstack/devstack,master,I046ae22d59a99ef86da786c4d5db870814ce159f,Fix MySQL password on Ubuntu,ABANDONED,2014-08-18 20:46:11.000000000,2014-12-10 16:01:48.000000000,,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 7118}, {'_account_id': 7175}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-18 20:46:11.000000000', 'files': ['lib/databases/mysql'], 'web_link': 'https://opendev.org/openstack/devstack/commit/002c2b72b4d42496b6da0e11b39ee627ab01733c', 'message': ""Fix MySQL password on Ubuntu\n\nUbuntu relies on debconf to set the MySQL server password when the MySQL\npackage is installed. (This is done to avoid the password prompt during\ninstall).\n\nThis works the first time `./stack.sh` is run.\n\nOn subsequent runs, however, the package will already be installed, so the new\npassword won't be set.\n\nThe proposed work around is to uninstall/reinstall mysql-server on each run.\n\nChange-Id: I046ae22d59a99ef86da786c4d5db870814ce159f\nCloses-Bug: 1358485\n""}]",2,115103,002c2b72b4d42496b6da0e11b39ee627ab01733c,15,5,1,475,,,0,"Fix MySQL password on Ubuntu

Ubuntu relies on debconf to set the MySQL server password when the MySQL
package is installed. (This is done to avoid the password prompt during
install).

This works the first time `./stack.sh` is run.

On subsequent runs, however, the package will already be installed, so the new
password won't be set.

The proposed work around is to uninstall/reinstall mysql-server on each run.

Change-Id: I046ae22d59a99ef86da786c4d5db870814ce159f
Closes-Bug: 1358485
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/115103/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/databases/mysql'],1,002c2b72b4d42496b6da0e11b39ee627ab01733c,bug/1358485, # We need to reinstall each time so that the password is set anew uninstall_package mysql-server-5.5 ,,3,0
openstack%2Fmonasca-ui~master~I38dad97b6dbd09b57f8b175151b4ea77581ca351,openstack/monasca-ui,master,I38dad97b6dbd09b57f8b175151b4ea77581ca351,Add support for non-default WSGIScriptAlias,MERGED,2014-12-10 14:53:34.000000000,2014-12-10 16:00:41.000000000,2014-12-10 16:00:41.000000000,"[{'_account_id': 3}, {'_account_id': 6230}, {'_account_id': 6650}, {'_account_id': 11155}, {'_account_id': 12108}]","[{'number': 1, 'created': '2014-12-10 14:53:34.000000000', 'files': ['monitoring/static/monitoring/js/controllers.js'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/6240b46af3ed69ae908d895cc8d6502f7d12a739', 'message': ""Add support for non-default WSGIScriptAlias\n\nIn our horizon deployment, we set WSGIScriptAlias to /horizon,\nso the hard-coded link of /monitoring/status doesn't work.\n\nChange-Id: I38dad97b6dbd09b57f8b175151b4ea77581ca351\n""}]",0,140706,6240b46af3ed69ae908d895cc8d6502f7d12a739,8,5,1,8126,,,0,"Add support for non-default WSGIScriptAlias

In our horizon deployment, we set WSGIScriptAlias to /horizon,
so the hard-coded link of /monitoring/status doesn't work.

Change-Id: I38dad97b6dbd09b57f8b175151b4ea77581ca351
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/06/140706/1 && git format-patch -1 --stdout FETCH_HEAD,['monitoring/static/monitoring/js/controllers.js'],1,6240b46af3ed69ae908d895cc8d6502f7d12a739,feature/support_custom_wsgi_alias," .controller('monitoringController', function ($scope, $http, $timeout, $location) { $scope.fetchStatus = function() { $http({method: 'GET', url: $location.absUrl().concat('status')}).} "," .controller('monitoringController', function ($scope, $http, $timeout) { $scope.fetchStatus = function() { $http({method: 'GET', url: '/monitoring/status'}).}",3,3
openstack%2Fmonasca-persister~master~I78c1b98dd4b7f532ebaebf971aa14524638ba45a,openstack/monasca-persister,master,I78c1b98dd4b7f532ebaebf971aa14524638ba45a,Move tenant id to the front of the serie name,MERGED,2014-12-09 21:17:32.000000000,2014-12-10 16:00:34.000000000,2014-12-10 16:00:34.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-09 21:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/8505130742e4dad58fde2a4c7d948d0431248ad0', 'message': 'Make serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: I78c1b98dd4b7f532ebaebf971aa14524638ba45a\n'}, {'number': 2, 'created': '2014-12-09 21:26:53.000000000', 'files': ['src/main/java/monasca/persister/repository/InfluxDBMetricRepository.java'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/88bb2006628fac6264bab71bb5b053191e70e55a', 'message': 'Move tenant id to the front of the serie name\n\nMake serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: I78c1b98dd4b7f532ebaebf971aa14524638ba45a\n'}]",0,140479,88bb2006628fac6264bab71bb5b053191e70e55a,11,4,2,12512,,,0,"Move tenant id to the front of the serie name

Make serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...

Change-Id: I78c1b98dd4b7f532ebaebf971aa14524638ba45a
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/79/140479/1 && git format-patch -1 --stdout FETCH_HEAD,['src/main/java/monasca/persister/repository/InfluxDBMetricRepository.java'],1,8505130742e4dad58fde2a4c7d948d0431248ad0,," serieNameBuilder.append(""?""); serieNameBuilder.append(""&""); logger.debug(""Adding name to serie name: {}"", def.name); serieNameBuilder.append(urlEncodeUTF8(def.name));"," logger.debug(""Adding name to serie name: {}"", def.name); serieNameBuilder.append(urlEncodeUTF8(def.name)); serieNameBuilder.append(""?""); serieNameBuilder.append(""&"");",5,5
openstack%2Fmonasca-api~master~Icbe292109962bb68e02a1b3f44a5765f9d902410,openstack/monasca-api,master,Icbe292109962bb68e02a1b3f44a5765f9d902410,Move tenant id to front for serie name,MERGED,2014-12-09 21:31:35.000000000,2014-12-10 16:00:28.000000000,2014-12-10 16:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 8126}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-09 21:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/4e3ca1fdf12eba540b4f2f4dbe9f49f135b547f1', 'message': 'Move tenant id to front for serie name\n\nMake serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: Icbe292109962bb68e02a1b3f44a5765f9d902410\n'}, {'number': 2, 'created': '2014-12-09 22:26:36.000000000', 'files': ['src/main/java/monasca/api/infrastructure/persistence/influxdb/Utils.java', 'src/main/java/monasca/api/infrastructure/persistence/influxdb/MeasurementInfluxDbRepositoryImpl.java', 'src/main/java/monasca/api/infrastructure/persistence/influxdb/MetricDefinitionInfluxDbRepositoryImpl.java', 'src/main/java/monasca/api/infrastructure/persistence/influxdb/StatisticInfluxDbRepositoryImpl.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/80b7c8474477f6376d491b3122c18eee91ccbd14', 'message': 'Move tenant id to front for serie name\n\nMake serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...\n\nChange-Id: Icbe292109962bb68e02a1b3f44a5765f9d902410\n'}]",0,140483,80b7c8474477f6376d491b3122c18eee91ccbd14,11,5,2,12512,,,0,"Move tenant id to front for serie name

Make serie name tenantId?region&metricName&dimName1=dimValue1&dimName2=dimValue2...

Change-Id: Icbe292109962bb68e02a1b3f44a5765f9d902410
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/83/140483/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/main/java/monasca/api/infrastructure/persistence/influxdb/Utils.java', 'src/main/java/monasca/api/infrastructure/persistence/influxdb/MeasurementInfluxDbRepositoryImpl.java', 'src/main/java/monasca/api/infrastructure/persistence/influxdb/MetricDefinitionInfluxDbRepositoryImpl.java', 'src/main/java/monasca/api/infrastructure/persistence/influxdb/StatisticInfluxDbRepositoryImpl.java']",4,4e3ca1fdf12eba540b4f2f4dbe9f49f135b547f1,," String serieNameRegex = buildSerieNameRegex(tenantId, config.region, name, dimensions);"," String serieNameRegex = buildSerieNameRegex(tenantId, name, dimensions);",10,10
openstack%2Fcongress~master~I8411d81a96e2eaf8b5c6f9c0f5c21a71df83b7db,openstack/congress,master,I8411d81a96e2eaf8b5c6f9c0f5c21a71df83b7db,Fix style problem,ABANDONED,2014-12-09 22:32:35.000000000,2014-12-10 15:59:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-09 22:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/620503cbc0d0066a65942fcc9819846f2ba2a038', 'message': 'Fix style problem\n\nSomehow style guideline H307 fails, meaning that the codebase does not\npass the pep8 checks.\n\nThis change fixes the problem.\n\nChange-Id: I8411d81a96e2eaf8b5c6f9c0f5c21a71df83b7db\n'}, {'number': 2, 'created': '2014-12-10 15:55:38.000000000', 'files': ['contrib/horizon/congress.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/6264fca2a3171f9e85c85845d37b6dfddc925f45', 'message': 'Fix style problem\n\nSomehow style guideline H307 fails, meaning that the codebase does not\npass the pep8 checks.\n\nThis change fixes the problem.\n\nChange-Id: I8411d81a96e2eaf8b5c6f9c0f5c21a71df83b7db\n'}]",0,140505,6264fca2a3171f9e85c85845d37b6dfddc925f45,8,3,2,8215,,,0,"Fix style problem

Somehow style guideline H307 fails, meaning that the codebase does not
pass the pep8 checks.

This change fixes the problem.

Change-Id: I8411d81a96e2eaf8b5c6f9c0f5c21a71df83b7db
",git fetch https://review.opendev.org/openstack/congress refs/changes/05/140505/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/horizon/congress.py'],1,620503cbc0d0066a65942fcc9819846f2ba2a038,devdocs,from congressclient.v1 import client as congress_client ,from congressclient.v1 import client as congress_client,2,1
openstack%2Fcinder~master~Ifd9d647175a840939bf01fa3bcecfa6384965e3b,openstack/cinder,master,Ifd9d647175a840939bf01fa3bcecfa6384965e3b,Implementing the use of _Lx/i18n markers,MERGED,2014-12-04 09:22:49.000000000,2014-12-10 15:45:28.000000000,2014-12-09 11:50:14.000000000,"[{'_account_id': 3}, {'_account_id': 842}, {'_account_id': 1207}, {'_account_id': 4355}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12716}, {'_account_id': 12779}, {'_account_id': 13636}]","[{'number': 1, 'created': '2014-12-04 09:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8541dc984c4bcc961a056b88386e93ca7dfd51d6', 'message': 'Implementing the use of _Lx/i18n markers\n\nPlacing the _Lx markers back into the code. No other cleaner solution has\nhas been implemented. Patches will be submitted in a series of sub\ndirectories and in a fashion that is manageable.\neighth commit of this kind\nThis is the last run through to pick up the ones that were missed\n\nChange-Id: Ifd9d647175a840939bf01fa3bcecfa6384965e3b\nCloses-Bug: #1384312\n'}, {'number': 2, 'created': '2014-12-09 08:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/60030c5a139f0affd839bb1fef948699d1c7ed33', 'message': 'Implementing the use of _Lx/i18n markers\n\nPlacing the _Lx markers back into the code. No other cleaner solution has\nhas been implemented. Patches will be submitted in a series of sub\ndirectories and in a fashion that is manageable.\neighth commit of this kind\nThis is the last run through to pick up the ones that were missed\n\nChange-Id: Ifd9d647175a840939bf01fa3bcecfa6384965e3b\nCloses-Bug: #1384312\n'}, {'number': 3, 'created': '2014-12-09 10:03:39.000000000', 'files': ['cinder/volume/drivers/nimble.py', 'cinder/volume/drivers/hitachi/hbsd_fc.py', 'cinder/volume/drivers/hitachi/hbsd_horcm.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/db/sqlalchemy/api.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_driver.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/volume/drivers/prophetstor/dplcommon.py', 'cinder/tests/integrated/api/client.py', 'cinder/consistencygroup/api.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/volume/drivers/zadara.py', 'cinder/volume/drivers/smbfs.py', 'cinder/transfer/api.py', 'cinder/volume/drivers/fusionio/ioControl.py', 'cinder/volume/drivers/emc/emc_vmax_iscsi.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/volume/drivers/fujitsu_eternus_dx_common.py', 'cinder/volume/drivers/zfssa/restclient.py', 'cinder/volume/utils.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/common/sqlalchemyutils.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/volume/api.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/utils.py', 'cinder/keymgr/barbican.py', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/san/san.py', 'cinder/openstack/common/request_utils.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/keymgr/conf_key_mgr.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/hitachi/hbsd_common.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/volume/drivers/hitachi/hbsd_snm2.py', 'cinder/tests/fake_driver.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/extensions.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/api/__init__.py', 'cinder/volume/drivers/emc/xtremio.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/api/openstack/wsgi.py', 'cinder/utils.py', 'cinder/volume/drivers/huawei/huawei_t.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ad858c9c9522eac8b653b633c04669b39bc2b5c', 'message': 'Implementing the use of _Lx/i18n markers\n\nPlacing the _Lx markers back into the code. No other cleaner solution has\nhas been implemented. Patches will be submitted in a series of sub\ndirectories and in a fashion that is manageable.\neighth commit of this kind\nThis is the last run through to pick up the ones that were missed\n\nChange-Id: Ifd9d647175a840939bf01fa3bcecfa6384965e3b\nCloses-Bug: #1384312\n'}]",2,138997,9ad858c9c9522eac8b653b633c04669b39bc2b5c,33,15,3,12716,,,0,"Implementing the use of _Lx/i18n markers

Placing the _Lx markers back into the code. No other cleaner solution has
has been implemented. Patches will be submitted in a series of sub
directories and in a fashion that is manageable.
eighth commit of this kind
This is the last run through to pick up the ones that were missed

Change-Id: Ifd9d647175a840939bf01fa3bcecfa6384965e3b
Closes-Bug: #1384312
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/138997/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/nimble.py', 'cinder/volume/drivers/hitachi/hbsd_fc.py', 'cinder/volume/drivers/hitachi/hbsd_horcm.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/db/sqlalchemy/api.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_driver.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/volume/drivers/prophetstor/dplcommon.py', 'cinder/tests/integrated/api/client.py', 'cinder/consistencygroup/api.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/volume/drivers/zadara.py', 'cinder/volume/drivers/smbfs.py', 'cinder/transfer/api.py', 'cinder/volume/drivers/fusionio/ioControl.py', 'cinder/volume/drivers/emc/emc_vmax_iscsi.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/volume/drivers/fujitsu_eternus_dx_common.py', 'cinder/volume/drivers/zfssa/restclient.py', 'cinder/volume/utils.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/common/sqlalchemyutils.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/volume/api.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/utils.py', 'cinder/keymgr/barbican.py', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/san/san.py', 'cinder/openstack/common/request_utils.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/keymgr/conf_key_mgr.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/tests/test_fujitsu.py', 'cinder/volume/drivers/hitachi/hbsd_common.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/volume/drivers/hitachi/hbsd_snm2.py', 'cinder/tests/fake_driver.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/extensions.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/api/__init__.py', 'cinder/volume/drivers/emc/xtremio.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/api/openstack/wsgi.py', 'cinder/utils.py', 'cinder/volume/drivers/huawei/huawei_t.py']",63,8541dc984c4bcc961a056b88386e93ca7dfd51d6,bug/1384312,"from cinder.i18n import _, _LW LOG.warn(_LW('_remove_iscsi_port: iSCSI port was not found ' 'on host %(hostid)s.') % {'hostid': hostid}) LOG.warn(_LW('_remove_fc_ports: FC port was not found ' 'on host %(hostid)s.') % {'hostid': hostid})",from cinder.i18n import _ LOG.warn(_('_remove_iscsi_port: iSCSI port was not found ' 'on host %(hostid)s.') % {'hostid': hostid}) LOG.warn(_('_remove_fc_ports: FC port was not found ' 'on host %(hostid)s.') % {'hostid': hostid}),457,435
openstack%2Fmanila~master~I3c38a2dbc9575a81c83e64180cd37916abe68334,openstack/manila,master,I3c38a2dbc9575a81c83e64180cd37916abe68334,Update EMC Manila driver framework using stevedore,MERGED,2014-12-08 10:12:23.000000000,2014-12-10 15:34:32.000000000,2014-12-10 15:34:31.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 11637}]","[{'number': 1, 'created': '2014-12-08 10:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/803f067580b3d08a35e1823d93200a0e3326183b', 'message': 'EMC Manila framework update for Kilo\n\nAlternative way of registering plugin in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 2, 'created': '2014-12-08 10:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ca3d8bba76f072d84c7a8fdd0211c6a274a98779', 'message': 'EMC Manila framework update for Kilo\n\nAlternative way of registering plugin in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 3, 'created': '2014-12-08 10:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a96b7af04928d6a3525746d7159c8e42e192fbd0', 'message': 'EMC Manila framework update for Kilo\n\nAlternative way of registering plugins in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 4, 'created': '2014-12-09 00:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0385bc067b9c528cada5e3fdad09e35ec78f499f', 'message': 'Update EMC Manila driver framework using stevedore\n\nAlternative way of registering plugins in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 5, 'created': '2014-12-09 01:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8f24b7711dc1c88a0c3c22f5d1ff97affdf60c3f', 'message': 'EMC Manila framework update for Kilo\n\nAlternative way of registering plugin in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 6, 'created': '2014-12-09 01:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a4febb81505ca62da5cb325615c8e167adf7a330', 'message': 'Update EMC Manila driver framework using stevedore\n\nAlternative way of registering plugin in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 7, 'created': '2014-12-10 06:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/42ef16c17a9c7c49ce179057c5c3ff45af4d9fe3', 'message': 'Update EMC Manila driver framework using stevedore\n\nAlternative way of registering plugin in EMC Manila driver framework\nusing the module *stevedore*.\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 8, 'created': '2014-12-10 06:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/deeab6a146e89d30da9c088a1ef8b076f6370e81', 'message': 'Update EMC Manila driver framework using stevedore\n\nAlternative way of registering plugin in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 9, 'created': '2014-12-10 09:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/103c694966c6c2e7499f76aa6862298228519b26', 'message': 'Update EMC Manila driver framework using stevedore\n\nAlternative way of registering plugins in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 10, 'created': '2014-12-10 10:01:53.000000000', 'files': ['manila/share/drivers/emc/plugin_manager.py', 'manila/share/drivers/emc/driver.py', 'manila/share/drivers/emc/plugins/registry.py', 'manila/tests/share/drivers/emc/test_emc_vnx.py', 'manila/share/drivers/emc/plugins/vnx/connection.py', 'manila/tests/share/drivers/emc/test_driver.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/manila/commit/e8709c8005a8d83626675e3c7298ada7d06468db', 'message': 'Update EMC Manila driver framework using stevedore\n\nAlternative way of registering plugins in EMC Manila driver framework\nusing the module *stevedore*.\n\nChange-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}]",13,139963,e8709c8005a8d83626675e3c7298ada7d06468db,30,4,10,11637,,,0,"Update EMC Manila driver framework using stevedore

Alternative way of registering plugins in EMC Manila driver framework
using the module *stevedore*.

Change-Id: I3c38a2dbc9575a81c83e64180cd37916abe68334
Implements: blueprint register-emc-manila-plugin-with-stevedore
",git fetch https://review.opendev.org/openstack/manila refs/changes/63/139963/9 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/emc/driver.py', 'manila/share/drivers/emc/plugins/registry.py', 'manila/tests/share/drivers/emc/test_emc_vnx.py', 'manila/share/drivers/emc/plugins/vnx/connection.py', 'manila/tests/share/drivers/emc/test_driver.py', 'setup.cfg']",6,803f067580b3d08a35e1823d93200a0e3326183b,bp/register-emc-manila-plugin-with-stevedore,manila.share.drivers.emc.plugins = vnx = manila.share.drivers.emc.plugins.vnx.connection:VNXStorageConnection,,59,84
openstack%2Fmanila~master~Idd0e8cbb7ecdaf2e57017863b57f699710db7082,openstack/manila,master,Idd0e8cbb7ecdaf2e57017863b57f699710db7082,Alternative way to import emc.plugins.registry,MERGED,2014-12-10 05:32:55.000000000,2014-12-10 15:33:15.000000000,2014-12-10 15:33:14.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 11637}]","[{'number': 1, 'created': '2014-12-10 05:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/33424623692601a0508301a43160003398329ac9', 'message': 'Alternative way to import emc.plugins.registry\n\nAlternative way to import emc.plugins.registry and fix the related pep8 issues.\n\nChange-Id: Idd0e8cbb7ecdaf2e57017863b57f699710db7082\n'}, {'number': 2, 'created': '2014-12-10 06:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b855a44346b38c25a9dd4a9e6b8df434a6568e42', 'message': 'Alternative way to import emc.plugins.registry\n\nAlternative way to import emc.plugins.registry and fix the related pep8 issues.\n\nChange-Id: Idd0e8cbb7ecdaf2e57017863b57f699710db7082\nImplements: blueprint register-emc-manila-plugin-with-stevedore\n'}, {'number': 3, 'created': '2014-12-10 09:51:21.000000000', 'files': ['manila/share/drivers/emc/plugins/vnx/connection.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/5433fdafc76468307068e0082b67c0f75741f120', 'message': 'Alternative way to import emc.plugins.registry\n\nAlternative way to import emc.plugins.registry and fix the related pep8 issues.\n\nChange-Id: Idd0e8cbb7ecdaf2e57017863b57f699710db7082\n'}]",2,140576,5433fdafc76468307068e0082b67c0f75741f120,13,4,3,11637,,,0,"Alternative way to import emc.plugins.registry

Alternative way to import emc.plugins.registry and fix the related pep8 issues.

Change-Id: Idd0e8cbb7ecdaf2e57017863b57f699710db7082
",git fetch https://review.opendev.org/openstack/manila refs/changes/76/140576/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/emc/plugins/vnx/connection.py'],1,33424623692601a0508301a43160003398329ac9,emc/fix-pep8-issue,"from manila.share.drivers.emc.plugins import registry raise exception.InvalidShare( raise exception.InvalidShare( raise exception.InvalidShare( raise exception.InvalidShare( raise exception.InvalidShareAccess(reason) raise exception.InvalidShare( raise exception.InvalidShareAccess(reason) raise exception.InvalidParameterValue(err=message) raise exception.InvalidParameterValue(err=message) raise exception.InvalidParameterValue(err=message) raise exception.InvalidParameterValue(err=message)registry.register_storage_backend(""vnx"", VNXStorageConnection)","import manila.share.drivers.emc.plugins.registry raise manila.exception.InvalidShare( raise manila.exception.InvalidShare( raise manila.exception.InvalidShare( raise manila.exception.InvalidShare( raise manila.exception.InvalidShareAccess(reason) raise manila.exception.InvalidShare( raise manila.exception.InvalidShareAccess(reason) raise manila.exception.InvalidParameterValue(err=message) raise manila.exception.InvalidParameterValue(err=message) raise manila.exception.InvalidParameterValue(err=message) raise manila.exception.InvalidParameterValue(err=message)manila.share.drivers.emc.plugins.registry.register_storage_backend( ""vnx"", VNXStorageConnection)",13,14
openstack%2Fmanila~master~I96923bd345fc5129963c77dfce3555e7284eb836,openstack/manila,master,I96923bd345fc5129963c77dfce3555e7284eb836,Fix wrong mock assertions in unit tests,MERGED,2014-12-08 19:03:29.000000000,2014-12-10 15:31:38.000000000,2014-12-10 15:31:38.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}]","[{'number': 1, 'created': '2014-12-08 19:03:29.000000000', 'files': ['manila/tests/network/neutron/test_neutron_api.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/tests/share/drivers/test_glusterfs.py', 'manila/tests/test_utils.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/network/linux/test_interface.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ab37c79a7e3527ee022cb7a6703c16aa0803e33a', 'message': 'Fix wrong mock assertions in unit tests\n\n\'mock\' objects don\'t have method ""assert_called_once"", but this is called in\nfollowing unit test suites:\n\nmanila/tests/network/linux/test_interface.py\nmanila/tests/network/neutron/test_neutron_api.py\nmanila/tests/test_share_generic.py\nmanila/tests/test_service_instance.py\nmanila/tests/test_share_glusterfs.py\nmanila/tests/test_utils.py\n\nMake unit tests call proper assertion methods.\n\nChange-Id: I96923bd345fc5129963c77dfce3555e7284eb836\nCloses-Bug: #1330391\n'}]",0,140116,ab37c79a7e3527ee022cb7a6703c16aa0803e33a,8,4,1,8851,,,0,"Fix wrong mock assertions in unit tests

'mock' objects don't have method ""assert_called_once"", but this is called in
following unit test suites:

manila/tests/network/linux/test_interface.py
manila/tests/network/neutron/test_neutron_api.py
manila/tests/test_share_generic.py
manila/tests/test_service_instance.py
manila/tests/test_share_glusterfs.py
manila/tests/test_utils.py

Make unit tests call proper assertion methods.

Change-Id: I96923bd345fc5129963c77dfce3555e7284eb836
Closes-Bug: #1330391
",git fetch https://review.opendev.org/openstack/manila refs/changes/16/140116/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/network/neutron/test_neutron_api.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/tests/share/drivers/test_glusterfs.py', 'manila/tests/test_utils.py', 'manila/tests/share/drivers/test_generic.py', 'manila/tests/network/linux/test_interface.py']",6,ab37c79a7e3527ee022cb7a6703c16aa0803e33a,bug/1330391, self.assertTrue(log.called), log.assert_called_once() ,199,171
openstack%2Fsahara-image-elements~master~I2b070423eff71be760b737ed1bbf7c18f32aada8,openstack/sahara-image-elements,master,I2b070423eff71be760b737ed1bbf7c18f32aada8,Make bashate checks as part of pep8 checks,MERGED,2014-12-07 10:17:22.000000000,2014-12-10 15:25:32.000000000,2014-12-10 15:25:32.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-07 10:17:22.000000000', 'files': ['tools/run_bashate.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/091330418b859dc359be9d3e44cedb7c6679ab9f', 'message': 'Make bashate checks as part of pep8 checks\n\nChange-Id: I2b070423eff71be760b737ed1bbf7c18f32aada8\n'}]",0,139856,091330418b859dc359be9d3e44cedb7c6679ab9f,15,9,1,7710,,,0,"Make bashate checks as part of pep8 checks

Change-Id: I2b070423eff71be760b737ed1bbf7c18f32aada8
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/56/139856/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/run_bashate.sh', 'tox.ini']",2,091330418b859dc359be9d3e44cedb7c6679ab9f,bashate-pep8,commands = flake8 {posargs} {toxinidir}/tools/run_bashate.sh,commands = flake8 {posargs},6,1
openstack%2Ffuel-library~stable%2F6.0~I16a2c1fae2cc7916a9afc9847fcd03b20f431258,openstack/fuel-library,stable/6.0,I16a2c1fae2cc7916a9afc9847fcd03b20f431258,unmanage password for admin keystone user in nailgun,MERGED,2014-12-10 11:59:08.000000000,2014-12-10 15:22:30.000000000,2014-12-10 15:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-10 11:59:08.000000000', 'files': ['deployment/puppet/nailgun/examples/keystone-only.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f30886db9c2ae9d47596cbd6907bc36ccc530f6a', 'message': ""unmanage password for admin keystone user in nailgun\n\nSetting keystone_user 'admin' to be unmanaged allows\na user to change his or her password to another password\nand expect it to remain in tact after reapplying puppet\nduring a Fuel Master upgrade scenario.\n\nChange-Id: I16a2c1fae2cc7916a9afc9847fcd03b20f431258\nCloses-Bug: #1400701\n""}]",0,140653,f30886db9c2ae9d47596cbd6907bc36ccc530f6a,14,8,1,8786,,,0,"unmanage password for admin keystone user in nailgun

Setting keystone_user 'admin' to be unmanaged allows
a user to change his or her password to another password
and expect it to remain in tact after reapplying puppet
during a Fuel Master upgrade scenario.

Change-Id: I16a2c1fae2cc7916a9afc9847fcd03b20f431258
Closes-Bug: #1400701
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/53/140653/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/examples/keystone-only.pp'],1,f30886db9c2ae9d47596cbd6907bc36ccc530f6a,," ensure => present, password => $::fuel_settings['FUEL_ACCESS']['password'], enabled => 'True', tenant => 'admin', manage_password => 'False',"," ensure => present, password => $::fuel_settings['FUEL_ACCESS']['password'], enabled => 'True', tenant => 'admin',",5,4
openstack%2Ffuel-library~master~Ia5e9339074d9993b84217079013f2708baeb6eb7,openstack/fuel-library,master,Ia5e9339074d9993b84217079013f2708baeb6eb7,Change IP for zabbix memcache check,MERGED,2014-11-13 13:39:55.000000000,2014-12-10 15:13:11.000000000,2014-12-10 15:13:10.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10489}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 11849}, {'_account_id': 13343}]","[{'number': 1, 'created': '2014-11-13 13:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0b6fc55564c6060c8384813009efac9b4d0f6de9', 'message': ""Change IP for zabbix memcache check\n\nChange IP from 127.0.0.1 to node's public IP\nfor zabbix memcache net.tcp.service check\n\nChange-Id: Ia5e9339074d9993b84217079013f2708baeb6eb7\nCloses-Bug: 1387116\n""}, {'number': 2, 'created': '2014-11-17 11:37:07.000000000', 'files': ['deployment/puppet/zabbix/files/import/Template_App_Memcache.xml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bf8f68902a57bcc9d91cf7d40d950c7cf188ad9f', 'message': ""Change IP for zabbix memcache check\n\nChange IP from 127.0.0.1 to node's public IP\nfor zabbix memcache net.tcp.service check\n\nChange-Id: Ia5e9339074d9993b84217079013f2708baeb6eb7\nCloses-Bug: 1387116\n""}]",0,134209,bf8f68902a57bcc9d91cf7d40d950c7cf188ad9f,26,9,2,13344,,,0,"Change IP for zabbix memcache check

Change IP from 127.0.0.1 to node's public IP
for zabbix memcache net.tcp.service check

Change-Id: Ia5e9339074d9993b84217079013f2708baeb6eb7
Closes-Bug: 1387116
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/09/134209/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/zabbix/files/import/Template_App_Memcache.xml'],1,0b6fc55564c6060c8384813009efac9b4d0f6de9,bug/1387116," <key>net.tcp.service[tcp,{IPADDRESS},11211]</key> <expression>{Template App Memcache:net.tcp.service[tcp,{IPADDRESS},11211].last(0)}=0</expression>"," <key>net.tcp.service[tcp,,11211]</key> <expression>{Template App Memcache:net.tcp.service[tcp,,11211].last(0)}=0</expression>",2,2
openstack%2Ffuel-docs~stable%2F6.0~I358e9ae4c384e13e61c1986d24e44b8c1accd1ab,openstack/fuel-docs,stable/6.0,I358e9ae4c384e13e61c1986d24e44b8c1accd1ab,Updated docs for Sahara,ABANDONED,2014-12-10 14:49:36.000000000,2014-12-10 15:10:46.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-10 14:49:36.000000000', 'files': ['pages/operations/sahara/7700-prepare-to-test.rst', 'pages/operations/sahara/7600-security-groups.rst', 'pages/user-guide/7000-sahara-install.rst', 'pages/operations/sahara/7600-ports.rst', 'pages/terminology/s/sahara.rst', 'pages/operations/7000-sahara.rst', 'pages/terminology/s/security-groups.rst', 'pages/planning-guide/7000-sahara-plan.rst', 'pages/operations/sahara/7750-test-details.rst', 'pages/operations/sahara/7760-sahara-images.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e854cf36330f4952d7686a9bf4eeaea651555ab2', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ab\n'}]",0,140703,e854cf36330f4952d7686a9bf4eeaea651555ab2,5,2,1,7132,,,0,"Updated docs for Sahara

The update is targeted for MOS 6.0

Change-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ab
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/03/140703/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/sahara/7700-prepare-to-test.rst', 'pages/operations/sahara/7600-security-groups.rst', 'pages/user-guide/7000-sahara-install.rst', 'pages/operations/sahara/7600-ports.rst', 'pages/terminology/s/sahara.rst', 'pages/operations/7000-sahara.rst', 'pages/terminology/s/security-groups.rst', 'pages/planning-guide/7000-sahara-plan.rst', 'pages/operations/sahara/7750-test-details.rst', 'pages/operations/sahara/7760-sahara-images.rst']",10,e854cf36330f4952d7686a9bf4eeaea651555ab2,master, .. _sahara-images: Sahara Images ------------- +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Plugin Name | Version | Operating System | Username | Link | Size | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 1.2.1 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 1.2.1 | Fedora 20 | cloud-user | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-fedora-20.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 1.2.1 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 2.4.1 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-2.4.1-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 2.4.1 | Fedora 20 | cloud-user | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-2.4.1-fedora-20.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 2.4.1 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-2.4.1-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | HDP | 1.3.2 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-hdp-1.3.2-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | HDP | 2.0.6 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-hdp-2.0.6-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | CDH | 5 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-cdh-5-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | CDH | 5 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-cdh-5-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Spark | 1.0.0 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-spark-1.0.0-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ .. note:: You can find MD5 checksum of an image by adding .md5 suffix to the image url. For example MD5 for Vanilla 1.2.1 ubuntu image is available at `http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-ubuntu-14.04.qcow2.md5`_,,87,159
openstack%2Ffuel-library~stable%2F6.0~I049bd99b9474204ff498863095beb8eecc641aee,openstack/fuel-library,stable/6.0,I049bd99b9474204ff498863095beb8eecc641aee,Fix keystone password update for users,MERGED,2014-12-10 11:58:36.000000000,2014-12-10 15:08:28.000000000,2014-12-10 15:08:28.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-10 11:58:36.000000000', 'files': ['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2841834b7edbc18afeb9bf604c38b7bc0a58f231', 'message': 'Fix keystone password update for users\n\nkeystone-client changed its error message when an invalid\npassword is specified. The logic is updated so that puppet\ncan update passwords for users.\n\nBackport of I090f7e2ee62ee189f37921c091fe51b6d587cd74\n\nChange-Id: I049bd99b9474204ff498863095beb8eecc641aee\nPartial-Bug: #1400701\n'}]",0,140652,2841834b7edbc18afeb9bf604c38b7bc0a58f231,15,10,1,8786,,,0,"Fix keystone password update for users

keystone-client changed its error message when an invalid
password is specified. The logic is updated so that puppet
can update passwords for users.

Backport of I090f7e2ee62ee189f37921c091fe51b6d587cd74

Change-Id: I049bd99b9474204ff498863095beb8eecc641aee
Partial-Bug: #1400701
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/52/140652/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb'],1,2841834b7edbc18afeb9bf604c38b7bc0a58f231,, return nil if e.message =~ /Not Authorized/ or e.message =~ /HTTP 401/, return nil if e.message =~ /Not Authorized/,1,1
openstack%2Ffuel-library~master~I16a2c1fae2cc7916a9afc9847fcd03b20f431258,openstack/fuel-library,master,I16a2c1fae2cc7916a9afc9847fcd03b20f431258,unmanage password for admin keystone user in nailgun,MERGED,2014-12-10 11:38:00.000000000,2014-12-10 15:07:53.000000000,2014-12-10 15:07:53.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-10 11:38:00.000000000', 'files': ['deployment/puppet/nailgun/examples/keystone-only.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b51da0684f4f0c2ac7f6f343dc3e603c1d8e708b', 'message': ""unmanage password for admin keystone user in nailgun\n\nSetting keystone_user 'admin' to be unmanaged allows\na user to change his or her password to another password\nand expect it to remain in tact after reapplying puppet\nduring a Fuel Master upgrade scenario.\n\nChange-Id: I16a2c1fae2cc7916a9afc9847fcd03b20f431258\nCloses-Bug: #1400701\n""}]",0,140649,b51da0684f4f0c2ac7f6f343dc3e603c1d8e708b,18,9,1,7195,,,0,"unmanage password for admin keystone user in nailgun

Setting keystone_user 'admin' to be unmanaged allows
a user to change his or her password to another password
and expect it to remain in tact after reapplying puppet
during a Fuel Master upgrade scenario.

Change-Id: I16a2c1fae2cc7916a9afc9847fcd03b20f431258
Closes-Bug: #1400701
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/49/140649/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/examples/keystone-only.pp'],1,b51da0684f4f0c2ac7f6f343dc3e603c1d8e708b,keystone-unmanage-pw," ensure => present, password => $::fuel_settings['FUEL_ACCESS']['password'], enabled => 'True', tenant => 'admin', manage_password => 'False',"," ensure => present, password => $::fuel_settings['FUEL_ACCESS']['password'], enabled => 'True', tenant => 'admin',",5,4
openstack%2Ffuel-library~master~I4bd59f233273374545953f16c7843488148096d6,openstack/fuel-library,master,I4bd59f233273374545953f16c7843488148096d6,new option manage_password for keystone_user,MERGED,2014-12-10 11:35:45.000000000,2014-12-10 15:07:41.000000000,2014-12-10 15:07:41.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-10 11:35:45.000000000', 'files': ['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb', 'deployment/puppet/keystone/spec/unit/provider/keystone_user/keystone_spec.rb', 'deployment/puppet/keystone/lib/puppet/type/keystone_user.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fca8ef014c8daecb7a122f66c6a92e194cd57405', 'message': ""new option manage_password for keystone_user\n\nAdds a new option manage_password, which defaults\nto 'True' for all keystone_user objects, that\nhas the effect of enforcing the password of a given\nkeystone_user. If this is disabled, the user may change\nhis or her password at a later time and not be reset\nby the keystone Puppet module.\n\nChange-Id: I4bd59f233273374545953f16c7843488148096d6\nCloses-Bug: #1400701\n""}]",0,140648,fca8ef014c8daecb7a122f66c6a92e194cd57405,19,8,1,7195,,,0,"new option manage_password for keystone_user

Adds a new option manage_password, which defaults
to 'True' for all keystone_user objects, that
has the effect of enforcing the password of a given
keystone_user. If this is disabled, the user may change
his or her password at a later time and not be reset
by the keystone Puppet module.

Change-Id: I4bd59f233273374545953f16c7843488148096d6
Closes-Bug: #1400701
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/48/140648/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb', 'deployment/puppet/keystone/spec/unit/provider/keystone_user/keystone_spec.rb', 'deployment/puppet/keystone/lib/puppet/type/keystone_user.rb']",3,fca8ef014c8daecb7a122f66c6a92e194cd57405,keystone-unmanage-pw," newproperty(:manage_password) do newvalues(/(t|T)rue/, /(f|F)alse/) defaultto('True') munge do |value| value.to_s.capitalize end end ",,52,6
openstack%2Fapi-site~master~I82d3a4412698143be86dc61ec5b555942110305f,openstack/api-site,master,I82d3a4412698143be86dc61ec5b555942110305f,Fix wrong param description in Neutron API v2,MERGED,2014-12-09 09:07:05.000000000,2014-12-10 15:03:50.000000000,2014-12-10 15:03:49.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 10897}]","[{'number': 1, 'created': '2014-12-09 09:07:05.000000000', 'files': ['api-ref/src/wadls/netconn-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/1ab7585b70004b9cea31abf05fb0f55b7fd11e34', 'message': 'Fix wrong param description in Neutron API v2\n\nThe description of param ""admin_state_up"" in Neutron API v2 Ports chapter\nshould be corrected from ""The administrative status of the router"" to\n""The administrative status of the port"".\n\nChange-Id: I82d3a4412698143be86dc61ec5b555942110305f\nCloses-bug: 1400630\n'}]",0,140276,1ab7585b70004b9cea31abf05fb0f55b7fd11e34,8,4,1,4894,,,0,"Fix wrong param description in Neutron API v2

The description of param ""admin_state_up"" in Neutron API v2 Ports chapter
should be corrected from ""The administrative status of the router"" to
""The administrative status of the port"".

Change-Id: I82d3a4412698143be86dc61ec5b555942110305f
Closes-bug: 1400630
",git fetch https://review.opendev.org/openstack/api-site refs/changes/76/140276/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/netconn-api/src/common.ent'],1,1ab7585b70004b9cea31abf05fb0f55b7fd11e34,bug/1400630," <para>The administrative state of the port, which is up (<code>true</code>) or <para>The administrative status of the port, which is up (<code>true</code>) or down (<code>false</code>).</para></wadl:doc>"," <para>The administrative state of the router, which is up (<code>true</code>) or <para>The administrative status of the router, which is up (<code>true</code>) or down (<code>false</code>).</para></wadl:doc>",2,2
openstack%2Fmurano~master~I3764d6516b629022dff43f905efd532e8725e387,openstack/murano,master,I3764d6516b629022dff43f905efd532e8725e387,Change the package 'description' field type,MERGED,2014-11-06 17:52:07.000000000,2014-12-10 15:01:57.000000000,2014-12-10 15:01:55.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-11-06 17:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/83c8f50492da1fafc2669e2c6d246ffc65fe0915', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 2, 'created': '2014-11-10 15:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/72122c7fb97617b6337beb08725648a9050f462c', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 3, 'created': '2014-12-05 17:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/dec7a35482ee8cd44ffab17daf66806a8adc3fcb', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 4, 'created': '2014-12-08 12:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/82b540e98aa5ea58fc09321a74e94f3f9f36acd2', 'message': ""\\Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 5, 'created': '2014-12-08 12:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/e9b5f07b7785eca90ca4288181afde43e147367f', 'message': ""\\Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 6, 'created': '2014-12-08 12:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8fda70b940b09331fa1468ed03427fe265599162', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064""}, {'number': 7, 'created': '2014-12-08 13:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bb4c1ba281bffa381d4f97c36c5eae04de319420', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 8, 'created': '2014-12-08 14:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ddd1bfd7e9aee230f06be65027568d0a5b42765f', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}, {'number': 9, 'created': '2014-12-10 09:35:56.000000000', 'files': ['murano/db/migration/alembic_migrations/versions/004_change_package_desc_type.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/dd3fd29ee0de23cbae3c56f4595a03d68364053c', 'message': ""Change the package 'description' field type\n\nType of 'description' field must be Sql Text because description\nof apps could easily be longer than 512 characters\n\nChange-Id: I3764d6516b629022dff43f905efd532e8725e387\nCloses-Bug: 1379064\n""}]",0,133101,dd3fd29ee0de23cbae3c56f4595a03d68364053c,48,7,9,13149,,,0,"Change the package 'description' field type

Type of 'description' field must be Sql Text because description
of apps could easily be longer than 512 characters

Change-Id: I3764d6516b629022dff43f905efd532e8725e387
Closes-Bug: 1379064
",git fetch https://review.opendev.org/openstack/murano refs/changes/01/133101/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/db/models.py', 'murano/db/migration/alembic_migrations/versions/001_inital_version.py']",2,83c8f50492da1fafc2669e2c6d246ffc65fe0915,bug/1379064," sa.Column('description', sa.Text(), nullable=False),"," sa.Column('description', sa.String(length=512), nullable=False),",2,2
openstack%2Ffuel-library~master~Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a,openstack/fuel-library,master,Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a,Create keystone admin user before micro flavor,MERGED,2014-12-09 22:45:55.000000000,2014-12-10 14:54:45.000000000,2014-12-10 14:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-09 22:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e3f804d1f353fa0e0d50039a81a3ce8dd9a69300', 'message': 'Create keystone admin user before micro flavor\n\nCreate keystone admin user so that you have\nrights to create m1.micro flavor\n\nChange-Id: Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a\nCloses-bug: #1400910\n'}, {'number': 2, 'created': '2014-12-10 12:14:54.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3e2287ed0ae10070288830ef352860c9d9bccc8e', 'message': 'Create keystone admin user before micro flavor\n\nCreate keystone admin user so that you have\nrights to create m1.micro flavor\n\nChange-Id: Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a\nCloses-bug: #1400910\n'}]",0,140508,3e2287ed0ae10070288830ef352860c9d9bccc8e,21,7,2,8786,,,0,"Create keystone admin user before micro flavor

Create keystone admin user so that you have
rights to create m1.micro flavor

Change-Id: Ie4eeac635c7684be7b705d8fe4d4d145cd47d29a
Closes-bug: #1400910
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/08/140508/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",2,e3f804d1f353fa0e0d50039a81a3ce8dd9a69300,bug/1400910, Keystone::Roles::Admin <||> -> Exec<| title=='create-m1.micro-flavor' |> ,,5,0
openstack%2Fpuppet-neutron~master~I8a0e703231c312b80c1749174f666242d1399ab5,openstack/puppet-neutron,master,I8a0e703231c312b80c1749174f666242d1399ab5,Add 'state_path' and 'lock_path' for Neutron::Server,MERGED,2014-11-21 13:17:12.000000000,2014-12-10 14:54:20.000000000,2014-12-10 14:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-11-21 13:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a47b1008d43ffbb19b18f7b5cd24c6ee049aa1f2', 'message': ""Add 'state_path' and 'lock_path' for Neutron::Server\n\nCloses-bug: #1384123\n\nChange-Id: I8a0e703231c312b80c1749174f666242d1399ab5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}, {'number': 2, 'created': '2014-11-24 08:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8c0676a7a0f8126e7e91723082fa1f85aeeb6896', 'message': ""Add 'state_path' and 'lock_path' for Neutron::Server\n\nCloses-bug: #1384123\n\nChange-Id: I8a0e703231c312b80c1749174f666242d1399ab5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}, {'number': 3, 'created': '2014-11-24 10:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8dabc979b24c688f7aec18e4deb11a6e88883a98', 'message': ""Add 'state_path' and 'lock_path' for Neutron::Server\n\nCloses-bug: #1384123\n\nChange-Id: I8a0e703231c312b80c1749174f666242d1399ab5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}, {'number': 4, 'created': '2014-11-26 08:41:49.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/094d71fc724bfe770400cc5a071070b372ef6252', 'message': ""Add 'state_path' and 'lock_path' for Neutron::Server\n\nCloses-bug: #1384123\n\nChange-Id: I8a0e703231c312b80c1749174f666242d1399ab5\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",3,136333,094d71fc724bfe770400cc5a071070b372ef6252,19,5,4,6926,,,0,"Add 'state_path' and 'lock_path' for Neutron::Server

Closes-bug: #1384123

Change-Id: I8a0e703231c312b80c1749174f666242d1399ab5
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/33/136333/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agents/dhcp.pp', 'spec/classes/neutron_server_spec.rb', 'manifests/server.pp']",3,a47b1008d43ffbb19b18f7b5cd24c6ee049aa1f2,fix1384123,"# [*state_path*] # (optional) Where to store dnsmasq state files. This directory must be # writable by the user executing the agent. Defaults to '/var/lib/neutron'. # # [*lock_path*] # (optional) Where to store dnsmasq lock files. This directory must be # writable by the user executing the agent. Defaults to '/var/lib/neutron/lock'. # $state_path = '/var/lib/neutron', $lock_path = ""${state_path}/lock"", 'DEFAULT/state_path': value => $state_path; 'DEFAULT/lock_path': value => $lock_path;",,18,0
openstack%2Fnova~master~Ib1b97452bc5e777c66c4d368f71156dbe1e116b7,openstack/nova,master,Ib1b97452bc5e777c66c4d368f71156dbe1e116b7,Set vm state error when raising unexpected exception in live migrate,MERGED,2014-11-07 15:36:46.000000000,2014-12-10 14:46:42.000000000,2014-12-10 14:46:39.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6896}, {'_account_id': 7579}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 12909}]","[{'number': 1, 'created': '2014-11-07 15:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92350eea8490a4718e56dfd5d936591b54174000', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 2, 'created': '2014-11-08 01:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33ce9c7e0d4e47b47a7008813ee52ef238aa7ad5', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 3, 'created': '2014-11-08 01:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5704ce36cf0d715f27b0b9dcf25c2dad333c471a', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 4, 'created': '2014-11-08 03:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/907511d99072205d861d9dd275c4b3c3d34c45d2', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 5, 'created': '2014-11-13 10:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6699272feca3f9796894543d2ca43c2070667b3', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 6, 'created': '2014-11-21 02:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e65ad3ec921759c3691e8feb00f81f1b95163f31', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 7, 'created': '2014-11-26 04:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79603d08ede723772f5e4b56a773621ae430f7e7', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 8, 'created': '2014-11-26 04:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d16713e16ea3de5a776eb9ad87ba70fe1dbbc20', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status.\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\n'}, {'number': 9, 'created': '2014-11-28 02:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d31a5b7aa014519f3c093a197b6feda3b80c212', 'message': 'Set vm state back when raising unexpected exception in live migrate\n\nThe instance stuck at migrating status when unexpected exception.\nWhatever the error happened when live migration in conductor, the\nvm actually is not broken, so the vm status should set back to\norignal status.\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\nPartial-Bug: 1397153\n'}, {'number': 10, 'created': '2014-11-28 06:49:25.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/40a37269c52977a718e91012cfd4580b2e31ec65', 'message': 'Set vm state error when raising unexpected exception in live migrate\n\nThe instance stuck at migrating task_state when unexpected exception.\nThis is confuse for user, this patch set the vm_state to error.\n\nChange-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7\nPartial-Bug: 1397153\n'}]",9,133268,40a37269c52977a718e91012cfd4580b2e31ec65,83,15,10,5754,,,0,"Set vm state error when raising unexpected exception in live migrate

The instance stuck at migrating task_state when unexpected exception.
This is confuse for user, this patch set the vm_state to error.

Change-Id: Ib1b97452bc5e777c66c4d368f71156dbe1e116b7
Partial-Bug: 1397153
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/133268/6 && git format-patch -1 --stdout FETCH_HEAD,['nova/conductor/manager.py'],1,92350eea8490a4718e56dfd5d936591b54174000,bug/1397153," request_spec = {'instance_properties': { 'uuid': instance['uuid'], }, } scheduler_utils.set_vm_state_and_notify(context, 'compute_task', 'migrate_server', dict(vm_state=instance['vm_state'], task_state=None, expected_task_state=task_states.MIGRATING,), ex, request_spec, self.db)",,9,0
openstack%2Fmanila~master~I8f79724dacb3dd7efc75dc459529a0c3185f999f,openstack/manila,master,I8f79724dacb3dd7efc75dc459529a0c3185f999f,Release network resources properly,MERGED,2014-12-05 17:43:29.000000000,2014-12-10 14:43:13.000000000,2014-12-10 14:43:12.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-12-05 17:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/51d03c94e69ec55c5ecc98c8e893908416bd6cd7', 'message': 'Release network resources properly\n\nIf we try to create share with backend that uses share-server,\nits network resources won\'t be released because of improper param provided.\nMethod ""deallocate_network"" of module ""neutron_network_plugin"" expects\n""share_server"" as second param but ""share_network"" is provided indeed.\n\nChange-Id: I8f79724dacb3dd7efc75dc459529a0c3185f999f\nCloses-Bug: #1399732\n'}, {'number': 2, 'created': '2014-12-06 10:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/787598bf04ea3700684e9a80e56c50c96d4c05f9', 'message': 'Release network resources properly\n\nIf we try to create share with backend that uses share-server,\nits network resources won\'t be released because of improper param provided.\nMethod ""deallocate_network"" of module ""neutron_network_plugin"" expects\n""share_server"" as second param but ""share_network"" is provided indeed.\n\nMake it be called only when share_server deleted and errored after network\nresources provided and with proper params.\n\nChange-Id: I8f79724dacb3dd7efc75dc459529a0c3185f999f\nCloses-Bug: #1399732\n'}, {'number': 3, 'created': '2014-12-06 11:04:04.000000000', 'files': ['manila/network/__init__.py', 'manila/tests/fake_driver.py', 'manila/share/manager.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/tests/share/test_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8b083605fbe0aa4e70e900e76520784c39c06515', 'message': 'Release network resources properly\n\nIf we try to create share with backend that uses share-server,\nits network resources won\'t be released because of improper param provided.\nMethod ""deallocate_network"" of module ""neutron_network_plugin"" expects\n""share_server"" as second param but ""share_network"" is provided indeed.\n\nMake it be called only when share_server deleted and errored after network\nresources provided and with proper params.\n\nChange-Id: I8f79724dacb3dd7efc75dc459529a0c3185f999f\nCloses-Bug: #1399732\n'}]",2,139690,8b083605fbe0aa4e70e900e76520784c39c06515,16,7,3,8851,,,0,"Release network resources properly

If we try to create share with backend that uses share-server,
its network resources won't be released because of improper param provided.
Method ""deallocate_network"" of module ""neutron_network_plugin"" expects
""share_server"" as second param but ""share_network"" is provided indeed.

Make it be called only when share_server deleted and errored after network
resources provided and with proper params.

Change-Id: I8f79724dacb3dd7efc75dc459529a0c3185f999f
Closes-Bug: #1399732
",git fetch https://review.opendev.org/openstack/manila refs/changes/90/139690/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/network/__init__.py', 'manila/share/manager.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/tests/share/test_manager.py']",4,51d03c94e69ec55c5ecc98c8e893908416bd6cd7,bug/1399732," assert_called_once_with(context, share_server['id']) assert_called_once_with(context, share_server['id']) assert_called_once_with(context, share_server['id'])"," assert_called_once_with(context, share_network) assert_called_once_with(context, share_network) assert_called_once_with(context, share_network)",13,12
openstack%2Frelease-tools~master~Idba1f042ffb836ac782f50d91802b2a6f4ff44c1,openstack/release-tools,master,Idba1f042ffb836ac782f50d91802b2a6f4ff44c1,spec2bp v2 -- support in-review specs,MERGED,2014-07-18 15:18:48.000000000,2014-12-10 14:42:54.000000000,2014-12-10 14:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 105}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 2889}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-07-18 15:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/ae2c90d3618afb3ac936ccc69a3a392dd003f177', 'message': 'spec2bp v2 -- support inreview specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --inreview to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can set the spec URL\n  on cgit manually to work around the issue\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awsome-spec.rst is still under review, but you would like to\nadd the my-awesome-spec blueprint to juno-2 (marked Blocked):\n./spec2bp.py nova my-awsome-spec --inreview --milestone=juno-2\n\nmy-awsome-spec is now approved. You want to flip all the approval bits,\nbut also change its priority to High:\n./spec2bp.py nova my-awsome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}, {'number': 2, 'created': '2014-07-30 14:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/bcf33849880c35a55ecf31d4b675fe6f3ee65f4f', 'message': 'spec2bp v2 -- support in-review specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --in-review to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can set the spec URL\n  on cgit manually to work around the issue\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awesome-spec.rst is still under review, but you would like to\nadd the my-awesome-spec blueprint to juno-2 (marked Blocked):\n./spec2bp.py nova my-awesome-spec --in-review --milestone=juno-2\n\nmy-awesome-spec is now approved. You want to flip all the approval bits,\nbut also change its priority to High:\n./spec2bp.py nova my-awesome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}, {'number': 3, 'created': '2014-08-27 16:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/d79821dbbd7f2f31d30a5f0dd4fa9d881dfe7bb4', 'message': 'spec2bp v2 -- support in-review specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --in-review to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can set the spec URL\n  on cgit manually to work around the issue\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awesome-spec.rst is still under review, but you would like to\nadd the my-awesome-spec blueprint to juno-2 (marked Blocked):\n./spec2bp.py nova my-awesome-spec --in-review --milestone=juno-2\n\nmy-awesome-spec is now approved. You want to flip all the approval bits,\nbut also change its priority to High:\n./spec2bp.py nova my-awesome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}, {'number': 4, 'created': '2014-10-08 12:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/5c6142b586163818c33782a12c579d2851c0bce7', 'message': 'spec2bp v2 -- support in-review specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --in-review to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can set the spec URL\n  on cgit manually to work around the issue\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awesome-spec.rst is still under review, but you would like to\nadd the my-awesome-spec blueprint to juno-2 (marked Blocked):\n./spec2bp.py nova my-awesome-spec --in-review --milestone=juno-2\n\nmy-awesome-spec is now approved. You want to flip all the approval bits,\nbut also change its priority to High:\n./spec2bp.py nova my-awesome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}, {'number': 5, 'created': '2014-11-20 15:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/b3200a57f89016216685386c001fed0d40f5a77d', 'message': 'spec2bp v2 -- support in-review specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --in-review to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can set the spec URL\n  on cgit manually to work around the issue\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awesome-spec.rst is still under review, but you would like to\nadd the my-awesome-spec blueprint to juno-2 (marked Blocked):\n./spec2bp.py nova my-awesome-spec --in-review --milestone=juno-2\n\nmy-awesome-spec is now approved. You want to flip all the approval bits,\nbut also change its priority to High:\n./spec2bp.py nova my-awesome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}, {'number': 6, 'created': '2014-11-26 13:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/5a07160b1c9698ecd4e70d5877cdb4c4bd24bc1d', 'message': 'spec2bp v2 -- support in-review specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --in-review to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can set the spec URL\n  on cgit manually to work around the issue\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awesome-spec.rst is still under review, but you would like to\nadd the my-awesome-spec blueprint to juno-2 (marked Blocked):\n./spec2bp.py nova my-awesome-spec --in-review --milestone=juno-2\n\nmy-awesome-spec is now approved. You want to flip all the approval bits,\nbut also change its priority to High:\n./spec2bp.py nova my-awesome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}, {'number': 7, 'created': '2014-12-08 11:09:57.000000000', 'files': ['README.rst', 'spec2bp.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/df2041e4ac6d44c68e2a0ddca567efd25431a27c', 'message': 'spec2bp v2 -- support in-review specs\n\nNew version of spec2bp:\n\n- takes the project and blueprint name as arguments, instead of a file\n- supports not-yet-approved specs (use --in-review to set them ""Blocked"")\n- sets series goal as well as milestone targets\n- if the BP and approved spec names don\'t match, you can use --specpath\n  to specify the spec location\n- if --specpath is not provided, but the blueprint URL looks like it\n  points to a spec document, spec2bp will infer path from that instead\n- if milestone or priority are already set, the --milestone and\n  --priority parameters are optional (current values will be kept if\n  parameter is omitted)\n- spec2bp will recognize projects from the oslo projectgroup and use\n  oslo-specs for those\n\nExample usage:\n\nGlance\'s super-spec.rst was approved and you want to add it to juno-2,\nwith Medium priority:\n\n./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium\n\nNova\'s my-awesome-spec.rst is still under review, but you would like\nto add the my-awesome-spec blueprint to juno-2 (marked Blocked). Since\nit\'s located in a non-standard path, we specify it using --specpath\nparameter:\n\n./spec2bp.py nova --specpath=specs/kilo/approved/my-awesome-spec.rst\n  --in-review --milestone=juno-2\n\nmy-awesome-spec is now approved. You want to flip all the approval\nbits, but also change its priority to High. There is no need to pass\n--specpath again, spec2bp will infer it from the blueprint URL field:\n\n./spec2bp.py nova my-awesome-spec --priority=High\n\nChange-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1\n'}]",4,108041,df2041e4ac6d44c68e2a0ddca567efd25431a27c,32,7,7,308,,,0,"spec2bp v2 -- support in-review specs

New version of spec2bp:

- takes the project and blueprint name as arguments, instead of a file
- supports not-yet-approved specs (use --in-review to set them ""Blocked"")
- sets series goal as well as milestone targets
- if the BP and approved spec names don't match, you can use --specpath
  to specify the spec location
- if --specpath is not provided, but the blueprint URL looks like it
  points to a spec document, spec2bp will infer path from that instead
- if milestone or priority are already set, the --milestone and
  --priority parameters are optional (current values will be kept if
  parameter is omitted)
- spec2bp will recognize projects from the oslo projectgroup and use
  oslo-specs for those

Example usage:

Glance's super-spec.rst was approved and you want to add it to juno-2,
with Medium priority:

./spec2bp.py glance super-spec --milestone=juno-2 --priority=Medium

Nova's my-awesome-spec.rst is still under review, but you would like
to add the my-awesome-spec blueprint to juno-2 (marked Blocked). Since
it's located in a non-standard path, we specify it using --specpath
parameter:

./spec2bp.py nova --specpath=specs/kilo/approved/my-awesome-spec.rst
  --in-review --milestone=juno-2

my-awesome-spec is now approved. You want to flip all the approval
bits, but also change its priority to High. There is no need to pass
--specpath again, spec2bp will infer it from the blueprint URL field:

./spec2bp.py nova my-awesome-spec --priority=High

Change-Id: Idba1f042ffb836ac782f50d91802b2a6f4ff44c1
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/41/108041/1 && git format-patch -1 --stdout FETCH_HEAD,['spec2bp.py'],1,ae2c90d3618afb3ac936ccc69a3a392dd003f177,bp/name,"parser.add_argument('project', help='project name') parser.add_argument('blueprint', help='blueprint name') parser.add_argument('--inreview', action='store_true', help='spec is still under review, mark as Blocked') parser.add_argument('--milestone', help='which milestone to target the BP to') parser.add_argument(""--priority"", choices=['Essential', 'High', 'Medium', 'Low'], help='priority to set (default is keep, or set Low)')project = launchpad.projects[args.project] if not project: parser.error(""%s project does not exist in Launchpad"" % args.project)bp = project.getSpecification(name=args.blueprint) if not bp: parser.error(""Blueprint %s not found for project %s"" % (args.blueprint, args.project)) # If no milestone is set on blueprint, we must have a milestone argument if not bp.milestone and not args.milestone: parser.error(""Blueprint has no milestone, so you must specify one to set "" ""using the --milestone argument"") # Validate milestone if provided if args.milestone: milestone = project.getMilestone(name=args.milestone) if not milestone: parser.error(""%s milestone does not exist in LP"" % args.milestone) if not milestone.is_active: parser.error(""%s is no longer an active milestone"" % args.milestone) else: milestone = bp.milestone # Calculate likely spec location path = None if bp.specification_url: m = re.match(r""(.*git.openstack.org.*/\w+-specs)/(.+)/(.+).rst"", bp.specification_url) if m is not None: # This looks like a valid spec link, so we'll use that # but make sure we look at plain specs docs if m.group(2).startswith(""plain/""): path = m.group(2)[6:] else: path = m.group(2) site = m.group(1) spec = m.group(3) if not path: site = ""http://git.openstack.org/cgit/openstack/%s-specs"" % args.project path = ""specs/%s"" % milestone.series_target.name spec = args.blueprint url = ""%s/plain/%s/%s.rst"" % (site, path, spec) # Set blueprints fields if args.inreview: # Check if the spec is not already approved try: r = requests.get(url) if r.status_code == 200 and r.text: parser.error(""The spec you want to set --inreview seems to "" ""have been approved already!"") except requests.exceptions.RequestException as exc: pass bp.definition_status = 'Review' bp.implementation_status = 'Blocked' else: # Check that spec was approved (merged in specs repository) # Also use this to validate spec link URL try: r = requests.get(url) if r.status_code != 200 or not r.text: parser.error("""""" Can't find the spec corresponding to the blueprint in cgit. There are multiple possible causes for that. The spec may not be approved yet. If you just wanted to set fields on unapproved BP, don't forget the --inreview parameter. The spec may also point to some non-standard URL (not specs/series/bpname.rst). In that case, you can workaround the issue by setting the spec URL in the blueprint itself."""""") except requests.exceptions.RequestException as exc: parser.exit(1, ""Error trying to confirm spec is valid"") # Set approver, definition status, spec URL, priority and milestone bp.definition_status = 'Approved' bp.specification_url = url if bp.implementation_status == 'Blocked': bp.implementation_status = 'Unknown' if bp.priority == 'Undefined': bp.priority = args.priority or 'Low' if bp.milestone != milestone: bp.milestone = milestone bp.lp_save() bp.proposeGoal(goal=milestone.series_target) else: bp.lp_save()","import osparser.add_argument('specfile', help='spec file (in a -specs git repo)') parser.add_argument('milestone', help='which milestone to target the BP to')parser.add_argument(""--priority"", default='Low', choices=['Essential', 'High', 'Medium', 'Low'], help='which priority to set (default is Low)')# Validate specfile m = re.match(r"".*/(\w+)-specs/(.+)/(.+).rst"", os.path.abspath(args.specfile)) if m is None: parser.error(""%s has not a recognized spec pattern"" % args.specfile) projname = m.group(1) repoloc = ""openstack/%s-specs/plain/%s"" % (projname, m.group(2)) bpname = m.group(3) # Check that spec was approved (merged in specs repository) # Also use this to validate spec link URL cgit = ""http://git.openstack.org/cgit"" specurl = ""%s/%s/%s.rst"" % (cgit, repoloc, bpname) try: r = requests.get(specurl) if r.status_code != 200 or not r.text: parser.error(""No such confirmed spec in %s-specs"" % projname) except requests.exceptions.RequestException as exc: parser.exit(1, ""Error trying to confirm spec is valid"") project = launchpad.projects[projname] if not project: parser.error(""%s project does not exist in Launchpad"" % projname) # Validate milestone milestone = project.getMilestone(name=args.milestone) if not milestone: parser.error(""%s milestone does not exist in Launchpad"" % args.milestone) if not milestone.is_active: parser.error(""%s is no longer an active milestone"" % args.milestone)bp = project.getSpecification(name=bpname) if not bp: parser.exit(1, ""Blueprint %s not found for project %s"" % (bpname, projname)) # Set approver, definition status, spec URL, priority and milestonebp.definition_status = 'Approved' bp.specification_url = specurl bp.priority = args.priority bp.milestone = milestone bp.lp_save()",97,43
openstack%2Fpython-ceilometerclient~master~If6c1fa05044e65ec1e72a3e5f63e6db826469a2d,openstack/python-ceilometerclient,master,If6c1fa05044e65ec1e72a3e5f63e6db826469a2d,Make methods static where it's possible,MERGED,2014-12-10 10:19:04.000000000,2014-12-10 14:42:02.000000000,2014-12-10 14:42:01.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-10 10:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/435d3a2ac0d62b6a20bf50cabdf5128abc1476b3', 'message': ""Make methods static where it's possible\n\nChange-Id: If6c1fa05044e65ec1e72a3e5f63e6db826469a2d\n""}, {'number': 2, 'created': '2014-12-10 12:25:15.000000000', 'files': ['ceilometerclient/shell.py', 'ceilometerclient/v2/statistics.py', 'ceilometerclient/tests/fakes.py', 'ceilometerclient/tests/test_client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/ce8c06d413d52e3e392eca3f311fc2d3334c05a2', 'message': ""Make methods static where it's possible\n\nChange-Id: If6c1fa05044e65ec1e72a3e5f63e6db826469a2d\n""}]",0,140632,ce8c06d413d52e3e392eca3f311fc2d3334c05a2,15,4,2,3012,,,0,"Make methods static where it's possible

Change-Id: If6c1fa05044e65ec1e72a3e5f63e6db826469a2d
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/32/140632/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/shell.py', 'ceilometerclient/v2/statistics.py', 'ceilometerclient/tests/fakes.py', 'ceilometerclient/tests/test_client.py']",4,435d3a2ac0d62b6a20bf50cabdf5128abc1476b3,code-style-fixes," @staticmethod def create_client(env, api_version=2, endpoint=None, exclude=[]):"," def create_client(self, env, api_version=2, endpoint=None, exclude=[]):",10,5
openstack%2Fglance~master~I84511ab1ee600e618985448dfbfbdc26cb130370,openstack/glance,master,I84511ab1ee600e618985448dfbfbdc26cb130370,Update glance.openstack.common.policy and cleanup,MERGED,2014-10-13 10:08:33.000000000,2014-12-10 14:34:36.000000000,2014-12-10 14:34:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6493}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 8759}, {'_account_id': 9303}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-10-13 10:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f2403da3a11c3460683aa68ed74185fb80e092e5', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-10-16 03:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/15c6554ba21f9281fcb36a080abe34609224161b', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 3, 'created': '2014-10-21 09:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3c83b30881b88b484302d696d805dea50a068c23', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 4, 'created': '2014-11-18 07:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/67e64c45c8fe3af0417fa467e422ed3e293f0669', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nCloses-bug: #1288178\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 5, 'created': '2014-11-24 15:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5752297046bcd1884ed1e12cf0886de4c28d65f5', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nCloses-bug: #1288178\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 6, 'created': '2014-11-25 08:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b5cd55a8500c8dce6ea24bb86be0e95aa053f3bc', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nCloses-bug: #1288178\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 7, 'created': '2014-11-26 06:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ce975a265916cb802bf208986c9333d5ca2cc2e1', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\nCloses-bug: #1288178\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 8, 'created': '2014-11-26 08:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/81fa17902c8cc1757b536cabfdbe0cbab36d4b3a', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\ndocImpact\n\nCloses-bug: #1288178\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}, {'number': 9, 'created': '2014-11-27 13:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ab8d5c2adaf1c2f6e17a93f68615974425c64b91', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\ndocImpact\n\nCloses-bug: #1288178\nPartial-bug: #1381870\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 10, 'created': '2014-12-01 07:09:54.000000000', 'files': ['glance/tests/functional/v2/test_images.py', 'glance/openstack/common/policy.py', 'glance/tests/functional/db/base.py', 'glance/opts.py', 'glance/tests/functional/db/test_registry.py', 'etc/glance-cache.conf', 'glance/tests/unit/test_opts.py', 'glance/tests/unit/v2/test_image_members_resource.py', 'glance/api/policy.py', 'glance/tests/functional/db/test_simple.py', 'etc/glance-api.conf', 'glance/tests/functional/__init__.py', 'glance/tests/unit/base.py', 'etc/glance-scrubber.conf', 'glance/openstack/common/jsonutils.py', 'openstack-common.conf', 'glance/openstack/common/strutils.py', 'glance/tests/etc/policy.json', 'etc/glance-registry.conf', 'glance/tests/functional/db/test_sqlalchemy.py', 'glance/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/bdc4951d29ce803891bee85f993e9a01893827e6', 'message': 'Update glance.openstack.common.policy and cleanup\n\n1. Sync glance.openstack.common.policy up to latest\nversion from oslo-inc.\n\n2. Clean useless modules which depended by policy\nmodule and pinned gettextutils module there. For\nlatter one, we are going to use glance.i18n instead.\n * jsonutils\n * strutils\n\ndocImpact\n\nCloses-bug: #1288178\nCloses-bug: #1387973\nPartial-bug: #1381870\nChange-Id: I84511ab1ee600e618985448dfbfbdc26cb130370\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",7,127923,bdc4951d29ce803891bee85f993e9a01893827e6,47,11,10,6549,,,0,"Update glance.openstack.common.policy and cleanup

1. Sync glance.openstack.common.policy up to latest
version from oslo-inc.

2. Clean useless modules which depended by policy
module and pinned gettextutils module there. For
latter one, we are going to use glance.i18n instead.
 * jsonutils
 * strutils

docImpact

Closes-bug: #1288178
Closes-bug: #1387973
Partial-bug: #1381870
Change-Id: I84511ab1ee600e618985448dfbfbdc26cb130370
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/23/127923/10 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v2/test_images.py', 'glance/openstack/common/policy.py', 'glance/tests/functional/db/base.py', 'glance/opts.py', 'glance/tests/functional/db/test_registry.py', 'etc/glance-cache.conf', 'glance/tests/unit/test_opts.py', 'glance/tests/unit/v2/test_image_members_resource.py', 'glance/api/policy.py', 'glance/tests/functional/db/test_simple.py', 'etc/glance-api.conf', 'glance/tests/functional/__init__.py', 'glance/tests/unit/base.py', 'etc/glance-scrubber.conf', 'glance/openstack/common/jsonutils.py', 'openstack-common.conf', 'glance/openstack/common/strutils.py', 'glance/tests/etc/policy.json', 'etc/glance-registry.conf', 'glance/tests/functional/db/test_sqlalchemy.py', 'glance/tests/utils.py']",21,f2403da3a11c3460683aa68ed74185fb80e092e5,,"from glance.common import utils self.conf_dir = os.path.join(self.test_dir, 'etc') utils.safe_mkdirs(self.conf_dir) self.set_policy() def set_policy(self): conf_file = ""policy.json"" self.policy_file = self._copy_data_file(conf_file, self.conf_dir) self.config(policy_file=self.policy_file) ",,521,753
openstack%2Fnova~master~I562888d7f4afebc96245bacb1dec9410472d88db,openstack/nova,master,I562888d7f4afebc96245bacb1dec9410472d88db,Generate API sample files from API schemas,ABANDONED,2014-02-06 07:10:36.000000000,2014-12-10 14:16:45.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-02-06 07:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85f8d6b239b7ba2189dc8293fd87e5b20e91f0e7', 'message': ""Generate API sample docs from API schema\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nThis tools generates API sample files under doc/v3/api_samples\nfrom the API schemas. By generating API sample files from API\nschemas, it is easy to synchronize the files to API changes.\n\nJSONSchema defines 'description' attribute, and the attribute\nis not used for the validation. This tool requires:\n  * the http method of each API with the 'http-method: ' prefix\n  * the sample of each API parameter with the 'sample: ' prefix\non API schemas. This patch adds the above description of keypairs\nas a sample.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n""}, {'number': 2, 'created': '2014-02-06 09:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bf377f6f3a1208f4392fa903ed1271d5df353d6', 'message': ""Generate API sample docs from API schema\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nThis tools generates API sample files under doc/v3/api_samples\nfrom the API schemas. By generating API sample files from API\nschemas, it is easy to synchronize the files to API changes.\n\nJSONSchema defines 'description' attribute, and the attribute\nis not used for the validation. This tool requires:\n  * the http method of each API with the 'http-method: ' prefix\n  * the sample of each API parameter with the 'sample: ' prefix\non API schemas. This patch adds the above description of keypairs\nas a sample.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n""}, {'number': 3, 'created': '2014-02-12 05:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06fb0836520340d9ad1ed1930db1ec71e7a194db', 'message': ""Generate API sample docs from API schema\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nThis tools generates API sample files under doc/v3/api_samples\nfrom the API schemas. By generating API sample files from API\nschemas, it is easy to synchronize the files to API changes.\n\nJSONSchema defines 'description' attribute, and the attribute\nis not used for the validation. This tool requires:\n  * the http method of each API with 'http-method'\n  * the sample of each API parameter with 'sample'\nin 'description' attribute of each API schema.\nThis patch adds the above description of keypairs as a sample.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n""}, {'number': 4, 'created': '2014-02-12 19:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2b9802deebc51b5fbd53809a0c4fcf51da7739c', 'message': ""Generate API sample docs from API schema\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nThis tools generates API sample files under doc/v3/api_samples\nfrom the API schemas. By generating API sample files from API\nschemas, it is easy to synchronize the files to API changes.\n\nJSONSchema defines 'description' attribute, and the attribute\nis not used for the validation. This tool requires:\n  * the http method of each API with 'http-method'\n  * the sample of each API parameter with 'sample'\nin 'description' attribute of each API schema.\nThis patch adds the above description of keypairs as a sample.\n\nimplements blueprint generate-api-sample-from-api-schema\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n""}, {'number': 5, 'created': '2014-02-13 14:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6db4b6db5a03e461a9b27981bc74c8e76035fce8', 'message': 'Generate API sample files from API schemas\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nNow API sample files are generated from template files under\nnova/tests/integrated/v3/api_samples.\n\nThis patch adds the feature which generates API sample files\nfrom the API schemas instead of template files. We don\'t need\nto create a request template file when adding a new API and\nthe following command generates API sample files:\n\n $ export GENERATE_SAMPLES=yes\n $ ./run_tests.sh\n\nThe \'subs\' argument of a new method _do_post_with_schema() is\nfor specifying the sample data with the API parameter name.\nFor example, we need to specify {\'name\': \'keypair-foo\'} as the\nargument when generating API sample file of \'name\' API parameter\nwith \'keypair-foo\' data.\n\nThis patch applies this feature to ""create keypairs"" API as a sample.\n\nimplements blueprint generate-api-sample-from-api-schema\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n'}, {'number': 6, 'created': '2014-11-14 01:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7820a39974efe4fc86939023a80ce8acc4a792ea', 'message': 'Generate API sample files from API schemas\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nNow API sample files are generated from template files under\nnova/tests/unit/integrated/v3/api_samples.\n\nThis patch adds the feature which generates API sample files\nfrom the API schemas instead of template files. We don\'t need\nto create a request template file when adding a new API and\nthe following command generates API sample files:\n\n $ export GENERATE_SAMPLES=yes\n $ ./run_tests.sh\n\nThe \'subs\' argument of a new method _do_post_with_schema() is\nfor specifying the sample data with the API parameter name.\nFor example, we need to specify {\'name\': \'keypair-foo\'} as the\nargument when generating API sample file of \'name\' API parameter\nwith \'keypair-foo\' data.\n\nThis patch applies this feature to ""create keypairs"" API as a sample.\n\nPartially implements blueprint generate-api-sample-from-api-schema\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n'}, {'number': 7, 'created': '2014-11-14 04:09:42.000000000', 'files': ['nova/tests/unit/integrated/api_samples_test_base.py', 'nova/tests/unit/integrated/v3/api_samples/keypairs/keypairs-post-req.json.tpl', 'nova/tests/unit/integrated/v3/test_keypairs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/405b60ab0fe78ac4ee673a357e0fdd4397e83ae9', 'message': 'Generate API sample files from API schemas\n\nAPI schemas has been defined with JSONSchema since v3 API,\nand Nova validates its API parameters by referring them.\nNow API sample files are generated from template files under\nnova/tests/unit/integrated/v3/api_samples.\n\nThis patch adds the feature which generates API sample files\nfrom the API schemas instead of template files. We don\'t need\nto create a request template file when adding a new API and\nthe following command generates API sample files:\n\n $ export GENERATE_SAMPLES=yes\n $ ./run_tests.sh\n\nThe \'subs\' argument of a new method _do_post_with_schema() is\nfor specifying the sample data with the API parameter name.\nFor example, we need to specify {\'name\': \'keypair-foo\'} as the\nargument when generating API sample file of \'name\' API parameter\nwith \'keypair-foo\' data.\n\nThis patch applies this feature to ""create keypairs"" API as a sample.\n\nPartially implements blueprint generate-api-sample-from-api-schema\n\nChange-Id: I562888d7f4afebc96245bacb1dec9410472d88db\n'}]",0,71465,405b60ab0fe78ac4ee673a357e0fdd4397e83ae9,53,9,7,6167,,,0,"Generate API sample files from API schemas

API schemas has been defined with JSONSchema since v3 API,
and Nova validates its API parameters by referring them.
Now API sample files are generated from template files under
nova/tests/unit/integrated/v3/api_samples.

This patch adds the feature which generates API sample files
from the API schemas instead of template files. We don't need
to create a request template file when adding a new API and
the following command generates API sample files:

 $ export GENERATE_SAMPLES=yes
 $ ./run_tests.sh

The 'subs' argument of a new method _do_post_with_schema() is
for specifying the sample data with the API parameter name.
For example, we need to specify {'name': 'keypair-foo'} as the
argument when generating API sample file of 'name' API parameter
with 'keypair-foo' data.

This patch applies this feature to ""create keypairs"" API as a sample.

Partially implements blueprint generate-api-sample-from-api-schema

Change-Id: I562888d7f4afebc96245bacb1dec9410472d88db
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/71465/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/schemas/v3/keypairs.py', 'tools/generate_api_samples.py']",2,85f8d6b239b7ba2189dc8293fd87e5b20e91f0e7,bp/generate-api-sample-from-api-schema,"#!/usr/bin/env python # Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Tool for generating API sample files from API schemas. TBD """""" import json from nova.api.openstack.compute.schemas.v3 import keypairs def main(): usage = """""" Tool for generating API sample files from API schemas. Usage: %prog"""""" APISampleGenerator('keypairs', keypairs.create).generate() class APISampleGenerator(object): def __init__(self, name, schema): self.name = name self.schema = schema self.http_method = None def generate(self): print 'Creating API sample file of %s ...' % self.name, sample_dict = {} self.parse_properties(self.schema, sample_dict) if not self.http_method: print 'failed' return self.remove_empty_properties(sample_dict) self.write_api_sample_file(sample_dict) print 'done' def parse_properties(self, data, sample_dict): description = data.get('description') if description and 'http-method: ' in description: self.http_method = description.split('http-method: ')[1].lower() properties = data.get('properties') if properties: for key, value in properties.iteritems(): description = value.get('description') if description and 'sample: ' in description: sample = description.split('sample: ')[1] sample_dict[key] = sample continue sample_dict[key] = {} self.parse_properties(value, sample_dict[key]) def remove_empty_properties(self, sample_dict): if not isinstance(sample_dict, dict): return keys = sample_dict.keys() for key in keys: if sample_dict[key] == {}: del sample_dict[key] continue self.remove_empty_properties(sample_dict[key]) def write_api_sample_file(self, sample_dict): path = 'doc/v3/api_samples/%(name)s/%(name)s-%(method)s-req.json' % { 'name': self.name, 'method': self.http_method} contents = json.dumps(sample_dict, indent=4) with open(path, 'w') as f: f.write(contents) if __name__ == ""__main__"": main() ",,96,2
openstack%2Fceilometer~master~I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f,openstack/ceilometer,master,I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f,"Make compute discovery pollster-based, not agent-level",MERGED,2014-10-09 10:14:32.000000000,2014-12-10 14:15:24.000000000,2014-12-10 14:15:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 12927}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-10-09 10:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fa437834b848651837f6fe1602925a186c32f7ea', 'message': 'Make compute discovery pollster-based, not agent-level\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f\n'}, {'number': 2, 'created': '2014-11-07 13:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/11db7dcb5b589f3693c382cbfb9cb8d31efb5786', 'message': 'Make compute discovery pollster-based, not agent-level\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f\n'}, {'number': 3, 'created': '2014-11-26 14:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b9dd31a76d89088c4c50eb10340a3e5c9abcc6f6', 'message': 'Make compute discovery pollster-based, not agent-level\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f\n'}, {'number': 4, 'created': '2014-12-02 10:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/49b61aa4b63cca6fc130c3ebbe9f84611ff05d0f', 'message': 'Make compute discovery pollster-based, not agent-level\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f'}, {'number': 5, 'created': '2014-12-04 16:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2b1a82bc9f582f90e5df9abba8bfb1fedc29855b', 'message': 'Make compute discovery pollster-based, not agent-level\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f\n'}, {'number': 6, 'created': '2014-12-05 16:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b94aacba307fb978bbb1561b60e012dcdbd9a2dd', 'message': 'Make compute discovery pollster-based, not agent-level\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f\n'}, {'number': 7, 'created': '2014-12-09 11:48:18.000000000', 'files': ['ceilometer/tests/agentbase.py', 'ceilometer/compute/manager.py', 'ceilometer/agent.py', 'ceilometer/compute/plugin.py', 'ceilometer/tests/compute/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/633c3db1e87b7bc886dbe470092e4b0e4aea7137', 'message': 'Make compute discovery pollster-based, not agent-level\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f\n'}]",13,127185,633c3db1e87b7bc886dbe470092e4b0e4aea7137,43,13,7,3012,,,0,"Make compute discovery pollster-based, not agent-level

Partially-Implements-Blueprint: merge-compute-central-agents

Change-Id: I02c9a12b0fcd55a7d59688853f3c08e505b4bf3f
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/127185/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/manager.py', 'ceilometer/compute/plugin.py', 'ceilometer/tests/compute/test_manager.py']",3,fa437834b848651837f6fe1602925a186c32f7ea,merge-compute-and-central-agents," """"""Test that compute manager loads some pollsters. There is no need to test how does compute manager setups pollstering process, as it's actually the same that is done by base manager tests. """"""","from oslotest import mockpatch from ceilometer import agentfrom ceilometer import nova_client from ceilometer.tests import agentbase class TestRunTasks(agentbase.BaseAgentManagerTestCase): def _fake_instance(self, name, state): instance = mock.MagicMock() instance.name = name setattr(instance, 'OS-EXT-STS:vm_state', state) return instance def _raise_exception(self): raise Exception @staticmethod def create_manager(): return manager.AgentManager() @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def setUp(self): self.source_resources = False super(TestRunTasks, self).setUp() # Set up a fake instance value to be returned by # instance_get_all_by_host() so when the manager gets the list # of instances to poll we can control the results. self.instances = [self._fake_instance('doing', 'active'), self._fake_instance('resting', 'paused')] stillborn_instance = self._fake_instance('stillborn', 'error') self.useFixture(mockpatch.PatchObject( nova_client.Client, 'instance_get_all_by_host', side_effect=lambda *x: self.instances + [stillborn_instance])) def test_setup_polling_tasks(self): super(TestRunTasks, self).test_setup_polling_tasks() self.assertEqual(self.Pollster.samples[0][1], self.instances) def test_interval_exception_isolation(self): super(TestRunTasks, self).test_interval_exception_isolation() self.assertEqual(1, len(self.PollsterException.samples)) self.assertEqual(1, len(self.PollsterExceptionAnother.samples)) def test_manager_exception_persistency(self): super(TestRunTasks, self).test_manager_exception_persistency() with mock.patch.object(nova_client.Client, 'instance_get_all_by_host', side_effect=lambda *x: self._raise_exception()): mgr = manager.AgentManager() polling_task = agent.PollingTask(mgr) polling_task.poll_and_publish() def test_local_instances_default_agent_discovery(self): self.setup_pipeline() self.assertEqual(self.mgr.default_discovery, ['local_instances']) polling_tasks = self.mgr.setup_polling_tasks() self.mgr.interval_task(polling_tasks.get(60)) self._verify_discovery_params([]) self.assertEqual(set(self.Pollster.resources), set(self.instances))",7,66
openstack%2Fceilometer~master~Ic3ade312efa89edd01d2ee5ae31d341805b11f79,openstack/ceilometer,master,Ic3ade312efa89edd01d2ee5ae31d341805b11f79,Standardize timestamp fields of ceilometer API,MERGED,2014-10-16 09:05:06.000000000,2014-12-10 14:15:15.000000000,2014-12-10 14:15:14.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7049}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 10987}, {'_account_id': 11758}]","[{'number': 1, 'created': '2014-10-16 09:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7568b1135b1efe94de9de6b572949be4a3b4c498', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 2, 'created': '2014-10-16 09:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8c859aef499c29cb2a5a5da60aa77181d5a0c972', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 3, 'created': '2014-10-16 09:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/923689fad04337bda58238322e33550df38cd235', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 4, 'created': '2014-10-17 07:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/412f0a163ac9db32da13efa32320c809bd7f3de2', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 5, 'created': '2014-10-17 07:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a7a21e633807a074f671786063774dd8b0bdab20', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 6, 'created': '2014-10-27 01:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a47a9cabc030c4218b7b172b305d8cf373b13855', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 7, 'created': '2014-12-05 00:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/258d7332cc4150858e1c790361d971c49241de33', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardize the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time releted fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user input unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 8, 'created': '2014-12-05 00:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/97668a8aea98ce864135f0d43323e8fecc608306', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardizes the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time related fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user specifies unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}, {'number': 9, 'created': '2014-12-05 13:59:14.000000000', 'files': ['ceilometer/tests/api/v2/test_compute_duration_by_resource_scenarios.py', 'ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/tests/api/v2/test_query.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/__init__.py', 'ceilometer/tests/api/v2/test_alarm_scenarios.py', 'ceilometer/event/storage/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/33065c16f6b7ffb1f3595a10559b395542e7e30d', 'message': 'Standardize timestamp fields of ceilometer API\n\nFor currently, the timestamp in query fields is not unified, this\npatch standardizes the usage of timestamp query fileds:\n\n- unify the time query filed in API to *timestamp* supported only.\n- unify the time related fileds of filters to start_timestamp and\n  end_timestamp to simplify the process logic.\n- improve the _query_to_kwargs method to give explicit presentation\n  if user specifies unsupported query fields.\n\nChange-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79\nCloses-bug: #1295104\nCloses-bug: #1291171\n'}]",32,128856,33065c16f6b7ffb1f3595a10559b395542e7e30d,39,11,9,8290,,,0,"Standardize timestamp fields of ceilometer API

For currently, the timestamp in query fields is not unified, this
patch standardizes the usage of timestamp query fileds:

- unify the time query filed in API to *timestamp* supported only.
- unify the time related fileds of filters to start_timestamp and
  end_timestamp to simplify the process logic.
- improve the _query_to_kwargs method to give explicit presentation
  if user specifies unsupported query fields.

Change-Id: Ic3ade312efa89edd01d2ee5ae31d341805b11f79
Closes-bug: #1295104
Closes-bug: #1291171
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/56/128856/8 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/api/v2/test_compute_duration_by_resource_scenarios.py', 'ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/tests/api/v2/test_query.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/storage/__init__.py', 'ceilometer/tests/api/v2/test_alarm_scenarios.py', 'ceilometer/event/storage/impl_sqlalchemy.py']",13,7568b1135b1efe94de9de6b572949be4a3b4c498,bug/1291171, start = event_filter.start_timestamp end = event_filter.end_timestamp, start = event_filter.start_time end = event_filter.end_time,176,117
openstack%2Fceilometer~master~I23ec262dc4617af7c270ffc1a4dd17ad9ac69841,openstack/ceilometer,master,I23ec262dc4617af7c270ffc1a4dd17ad9ac69841,Add docs about volume/snapshot measurements,MERGED,2014-12-08 10:56:09.000000000,2014-12-10 14:14:51.000000000,2014-12-10 14:14:50.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-08 10:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a9740c170be2a8609c1a5d56cff6dbaf1dcebc2f', 'message': 'Add docs about volume/snapshot measurements\n\nThis change allows to add information about\nmeasurements of volumes/snapshots.\n\nChange-Id: I23ec262dc4617af7c270ffc1a4dd17ad9ac69841\n'}, {'number': 2, 'created': '2014-12-08 12:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/59cbfd4e5b2466632f821bcfa3d094fc2fdcfdcf', 'message': 'Add docs about volume/snapshot measurements\n\nThis change allows to add information about\nmeasurements of volumes/snapshots.\n\nChange-Id: I23ec262dc4617af7c270ffc1a4dd17ad9ac69841\n'}, {'number': 3, 'created': '2014-12-08 13:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/16191d58dbc166f6d7eb6c63ed5ceeadab0b5239', 'message': 'Add docs about volume/snapshot measurements\n\nThis change adds information about measurements\nof volumes/snapshots.\n\nChange-Id: I23ec262dc4617af7c270ffc1a4dd17ad9ac69841'}, {'number': 4, 'created': '2014-12-09 07:33:27.000000000', 'files': ['doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/61eba5455bebb068868488f14a62e47996341c66', 'message': 'Add docs about volume/snapshot measurements\n\nThis change allows to add information about\nmeasurements of volumes/snapshots.\n\nImplements: blueprint add-new-notifications-types-for-volumes-and-snapshots\nChange-Id: I23ec262dc4617af7c270ffc1a4dd17ad9ac69841\n'}]",6,139969,61eba5455bebb068868488f14a62e47996341c66,26,11,4,13273,,,0,"Add docs about volume/snapshot measurements

This change allows to add information about
measurements of volumes/snapshots.

Implements: blueprint add-new-notifications-types-for-volumes-and-snapshots
Change-Id: I23ec262dc4617af7c270ffc1a4dd17ad9ac69841
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/69/139969/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/measurements.rst'],1,a9740c170be2a8609c1a5d56cff6dbaf1dcebc2f,cinder_notifications,======================== ========== ======== ======== ============ ======================================================= Name Type Unit Resource Origin Note ======================== ========== ======== ======== ============ ======================================================= volume Gauge volume vol ID notification Existence of volume volume.size Gauge GB vol ID notification Size of volume volume.create.(start|end) Delta volume vol ID notification Creation of volume volume.delete.(start|end) Delta volume vol ID notification Deletion of volume volume.update.(start|end) Delta volume vol ID notification Update volume(name or description) volume.resize.(start|end) Delta volume vol ID notification Update volume's size volume.attach.(start|end) Delta volume vol ID notification Attaching volume to instance volume.detach.(start|end) Delta volume vol ID notification Detaching volume from instance snapshot Gauge snapshot snap ID notification Existence of snapshot snapshot.size Gauge GB snap ID notification Size of snapshot's volume snapshot.create.(start|end) Delta snapshot snap ID notification Creation of snapshot snapshot.delete.(start|end) Delta snapshot snap ID notification Deletion of snapshot snapshot.update.(start|end) Delta snapshot snap ID notification Update snapshot(name or description),======================== ========== ======== ======== ============ ======================================================= Name Type Unit Resource Origin Note ======================== ========== ======== ======== ============ ======================================================= volume Gauge volume vol ID notification Existence of volume volume.size Gauge GB vol ID notification Size of volume snapshot Gauge snapshot snap ID notification Existence of snapshot snapshot.size Gauge GB snap ID notification Size of snapshot's volume,16,7
openstack%2Fpython-troveclient~master~I5a76e11d428c63d33f6d2c2021426090ebf8340c,openstack/python-troveclient,master,I5a76e11d428c63d33f6d2c2021426090ebf8340c,Add profiling support to Trove client,MERGED,2014-08-25 15:38:12.000000000,2014-12-10 14:14:46.000000000,2014-12-10 14:14:46.000000000,"[{'_account_id': 3}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6172}, {'_account_id': 6268}, {'_account_id': 6549}, {'_account_id': 7092}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-08-25 15:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/0babba3aabec225f0194ef993ccb28a2f5c0e5ab', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}, {'number': 2, 'created': '2014-08-26 03:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/eef3263a163d7f99c6227048033004908d717a49', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}, {'number': 3, 'created': '2014-09-22 16:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/f7836237eb3fba628d9c9c5a0ce4e12002213c2c', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}, {'number': 4, 'created': '2014-10-08 13:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/ae3e04fc3b54fab0043cf2cf2d5a1dd8d068114c', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 5, 'created': '2014-10-09 16:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/fb2f4a55e7ae83f2945f02755e03ee57acda7e1f', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 6, 'created': '2014-11-17 17:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/a757432c437ee7ce19492081f129fdfce7afc582', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 7, 'created': '2014-11-18 10:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/2dbf7df7ae59d8c5afe99ace1f399685ba7a151b', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 8, 'created': '2014-12-02 11:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/93f10a041e9139d7575b1b587a36708b419cf6a2', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 9, 'created': '2014-12-04 04:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/68aa083f13662ee78d11099880a5b80a0c323bdf', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 10, 'created': '2014-12-04 04:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/cd802ff8106e5ed72e15328f883767f22c53f53d', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 11, 'created': '2014-12-04 10:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/c6109305c98cb372fc3a01dd37e10ccc3bfb686f', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 12, 'created': '2014-12-09 19:41:35.000000000', 'files': ['troveclient/client.py', 'README.rst', 'openstack-common.conf', 'troveclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/1cd92286473d5737cfa19ac4c850519e4ec64c72', 'message': ""Add profiling support to Trove client\n\nTo be able to create profiling traces for Trove, client should be\nable to send special HTTP header that contains trace info.\nThis patch is as well important to be able to make cross project\ntraces. (Typical case horizon calls Trove via python client, if\nprofiler is initialized, Trove client will add extra header, that\nwill be parsed by special osprofiler middleware in Trove api)\nDon't worry no security issue here, trace information is signed\nby HMAC key that is setted in api-paste.ini. So only person that\nknows HMAC key is able to send proper header.\nMain patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I95dccdc9f274661767d2659c18b96da169891f30\nCurrently there are 2 other projects are using osprofiler: Glance &\nCinder, and some others are working in progress.\n\nChange-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}]",8,116654,1cd92286473d5737cfa19ac4c850519e4ec64c72,91,10,12,6549,,,0,"Add profiling support to Trove client

To be able to create profiling traces for Trove, client should be
able to send special HTTP header that contains trace info.
This patch is as well important to be able to make cross project
traces. (Typical case horizon calls Trove via python client, if
profiler is initialized, Trove client will add extra header, that
will be parsed by special osprofiler middleware in Trove api)
Don't worry no security issue here, trace information is signed
by HMAC key that is setted in api-paste.ini. So only person that
knows HMAC key is able to send proper header.
Main patch in Trove is: I580cce8d2b3c4ec9ce625ac09de6f14e1249f6f5

We prepared a common BP in oslo-spec due to integration change is
similar to all projects: I95dccdc9f274661767d2659c18b96da169891f30
Currently there are 2 other projects are using osprofiler: Glance &
Cinder, and some others are working in progress.

Change-Id: I5a76e11d428c63d33f6d2c2021426090ebf8340c
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/54/116654/12 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/client.py', 'troveclient/shell.py']",2,0babba3aabec225f0194ef993ccb28a2f5c0e5ab,,"from troveclient.openstack.common import importutilsosprofiler_profiler = importutils.try_import(""osprofiler.profiler"") if osprofiler_profiler: parser.add_argument('--profile', metavar='HMAC_KEY', help='HMAC key to use for encrypting context ' 'data for performance profiling of operation. ' 'This key should be the value of HMAC key ' 'configured in osprofiler middleware in ' 'trove, it specified in paste configuration ' 'file at /etc/trove/api-paste.ini. ' 'Without key the profiling will not be ' 'triggered even if osprofiler is enabled ' 'on server side.') profile = osprofiler_profiler and options.profile if profile: osprofiler_profiler.init(options.profile) try: args.func(self.cs, args) finally: if profile: trace_id = osprofiler_profiler.get().get_base_id() print(""Trace ID: %s"" % trace_id) print(""To display trace use next command:\n"" ""osprofiler trace show --html %s"" % trace_id)"," args.func(self.cs, args)",32,1
openstack%2Ffuel-main~master~I0d11c23f20a97623efcd670fb499e2a435f44470,openstack/fuel-main,master,I0d11c23f20a97623efcd670fb499e2a435f44470,Add additional wait for galera get synced,MERGED,2014-12-09 09:57:17.000000000,2014-12-10 14:08:37.000000000,2014-12-09 20:28:54.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11090}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-09 09:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0de8b0857bc841017375a1ae8c123990d0e88481', 'message': ""Add additional wait for galera get synced\n\n- After killing mysql and starting mysql daemon again\nwe need to wait until Galera is synced because if it's\nnot synced and we kill mysql on next controller\nGalera will lose its quorum\n\nChange-Id: I0d11c23f20a97623efcd670fb499e2a435f44470\nCloses-Bug: #1400380\n""}, {'number': 2, 'created': '2014-12-09 09:58:31.000000000', 'files': ['fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/87359485d88e857aead80d57841b86bd59fa7d12', 'message': ""Add additional wait for galera get synced\n\n- After killing mysql and starting mysql daemon again\nwe need to wait until Galera is synced because if it's\nnot synced and we kill mysql on next controller\nGalera will lose its quorum\n\nChange-Id: I0d11c23f20a97623efcd670fb499e2a435f44470\nCloses-Bug: #1400380\n""}]",0,140283,87359485d88e857aead80d57841b86bd59fa7d12,15,7,2,10136,,,0,"Add additional wait for galera get synced

- After killing mysql and starting mysql daemon again
we need to wait until Galera is synced because if it's
not synced and we kill mysql on next controller
Galera will lose its quorum

Change-Id: I0d11c23f20a97623efcd670fb499e2a435f44470
Closes-Bug: #1400380
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/83/140283/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/checkers.py'],1,0de8b0857bc841017375a1ae8c123990d0e88481,fixMysqlTest," check_galera_cmd = (""mysql --connect_timeout=5 -sse \""SELECT"" "" VARIABLE_VALUE FROM"" "" information_schema.GLOBAL_STATUS"" "" WHERE VARIABLE_NAME"" "" = 'wsrep_local_state_comment';\"""") try: wait(lambda: ''.join(remote.execute( check_galera_cmd)['stdout']).rstrip() == 'Synced', timeout=600) except TimeoutError: logger.error('galera status is {0}'.format(''.join(remote.execute( check_galera_cmd)['stdout']).rstrip())) raise",,12,0
openstack%2Fzaqar~master~Ia8c0b3057a34413d28dfdef99fc5dbb7100e9c50,openstack/zaqar,master,Ia8c0b3057a34413d28dfdef99fc5dbb7100e9c50,Removes ZMQ directory,MERGED,2014-12-09 15:12:57.000000000,2014-12-10 14:04:09.000000000,2014-12-10 14:04:08.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-12-09 15:12:57.000000000', 'files': ['zaqar/transport/zmq/__init__.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0222159366e74c2b92dcee9a8f69b31e4dc83931', 'message': ""Removes ZMQ directory\n\nThis transport won't be implemented in the near future,\nso it doesn't make sense to keep the directory in the code base.\nThis doesn't mean that the future implementation of a transport\ndriver for ZMQ is discarded.\n\nChange-Id: Ia8c0b3057a34413d28dfdef99fc5dbb7100e9c50\n""}]",0,140359,0222159366e74c2b92dcee9a8f69b31e4dc83931,6,2,1,6413,,,0,"Removes ZMQ directory

This transport won't be implemented in the near future,
so it doesn't make sense to keep the directory in the code base.
This doesn't mean that the future implementation of a transport
driver for ZMQ is discarded.

Change-Id: Ia8c0b3057a34413d28dfdef99fc5dbb7100e9c50
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/59/140359/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/transport/zmq/__init__.py'],1,0222159366e74c2b92dcee9a8f69b31e4dc83931,zmq-removal,,,0,0
openstack%2Fzaqar~master~Iaa62703df426edcae1b1d0987f236106bc53d341,openstack/zaqar,master,Iaa62703df426edcae1b1d0987f236106bc53d341,Imported Translations from Transifex,MERGED,2014-12-09 06:07:45.000000000,2014-12-10 14:04:02.000000000,2014-12-10 14:04:01.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-12-09 06:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/70dd9cf6b7835203b80ec280b65ff3ef3a691f4f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaa62703df426edcae1b1d0987f236106bc53d341\n'}, {'number': 2, 'created': '2014-12-10 06:06:59.000000000', 'files': ['zaqar/locale/zaqar.pot', 'zaqar/locale/pt_BR/LC_MESSAGES/zaqar.po'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c4a1dd614a9c4e58e86776ba72c3c27a9a3775a0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaa62703df426edcae1b1d0987f236106bc53d341\n'}]",0,140240,c4a1dd614a9c4e58e86776ba72c3c27a9a3775a0,8,2,2,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iaa62703df426edcae1b1d0987f236106bc53d341
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/40/140240/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/locale/zaqar.pot', 'zaqar/locale/pt_BR/LC_MESSAGES/zaqar.po']",2,70dd9cf6b7835203b80ec280b65ff3ef3a691f4f,transifex/translations,"""POT-Creation-Date: 2014-12-09 06:07+0000\n""#: zaqar/bootstrap.py:88 msgid """" ""Unreliable's default value will be changed to False in the Kilo release. "" ""Please, make sure your deployments are working in a reliable mode or that"" "" `unreliable` is explicitly set to `True` in your configuration files."" msgstr """" #: zaqar/common/transport/wsgi/helpers.py:45#: zaqar/common/transport/wsgi/helpers.py:65#: zaqar/common/transport/wsgi/helpers.py:72#: zaqar/common/transport/wsgi/helpers.py:130#: zaqar/common/transport/wsgi/helpers.py:131#: zaqar/storage/pipeline.py:30#: zaqar/storage/pipeline.py:77#: zaqar/storage/mongodb/driver.py:79#: zaqar/storage/mongodb/driver.py:84#: zaqar/storage/mongodb/driver.py:97#: zaqar/storage/mongodb/messages.py:563#: zaqar/storage/mongodb/messages.py:607#: zaqar/storage/mongodb/messages.py:621#: zaqar/storage/mongodb/messages.py:681#: zaqar/storage/mongodb/queues.py:171#: zaqar/storage/mongodb/utils.py:290#: zaqar/storage/mongodb/utils.py:296#: zaqar/storage/redis/driver.py:42#: zaqar/storage/redis/driver.py:45#: zaqar/storage/redis/driver.py:88 zaqar/storage/redis/driver.py:118#: zaqar/storage/redis/driver.py:98#: zaqar/storage/redis/driver.py:107#: zaqar/storage/redis/driver.py:123#: zaqar/storage/redis/driver.py:132#: zaqar/storage/redis/driver.py:151#: zaqar/storage/redis/utils.py:178#: zaqar/storage/redis/utils.py:183#: zaqar/storage/sqlalchemy/driver.py:41#: zaqar/transport/validation.py:98#: zaqar/transport/validation.py:102#: zaqar/transport/validation.py:107#: zaqar/transport/validation.py:120#: zaqar/transport/validation.py:132#: zaqar/transport/validation.py:144#: zaqar/transport/validation.py:159#: zaqar/transport/validation.py:168#: zaqar/transport/validation.py:184 zaqar/transport/validation.py:240#: zaqar/transport/validation.py:202#: zaqar/transport/validation.py:208#: zaqar/transport/validation.py:215#: zaqar/transport/validation.py:222#: zaqar/transport/validation.py:249#: zaqar/transport/validation.py:265#: zaqar/transport/wsgi/driver.py:110#: zaqar/transport/wsgi/errors.py:24#: zaqar/transport/wsgi/errors.py:25#: zaqar/transport/wsgi/errors.py:36#: zaqar/transport/wsgi/errors.py:45#: zaqar/transport/wsgi/errors.py:54#: zaqar/transport/wsgi/utils.py:50#: zaqar/transport/wsgi/utils.py:61#: zaqar/transport/wsgi/utils.py:66#: zaqar/transport/wsgi/utils.py:72#: zaqar/transport/wsgi/utils.py:168#: zaqar/transport/wsgi/utils.py:176#: zaqar/transport/wsgi/v1_0/claims.py:77 #: zaqar/transport/wsgi/v1_1/claims.py:97#: zaqar/transport/wsgi/v1_0/claims.py:122 #: zaqar/transport/wsgi/v1_1/claims.py:149#: zaqar/transport/wsgi/v1_0/claims.py:169 #: zaqar/transport/wsgi/v1_1/claims.py:196#: zaqar/transport/wsgi/v1_0/claims.py:187 #: zaqar/transport/wsgi/v1_1/claims.py:214#: zaqar/transport/wsgi/v1_0/messages.py:61 #: zaqar/transport/wsgi/v1_0/messages.py:262 #: zaqar/transport/wsgi/v1_1/messages.py:74 #: zaqar/transport/wsgi/v1_1/messages.py:323#: zaqar/transport/wsgi/v1_0/messages.py:104 #: zaqar/transport/wsgi/v1_1/messages.py:120#: zaqar/transport/wsgi/v1_0/messages.py:168 #: zaqar/transport/wsgi/v1_1/messages.py:195#: zaqar/transport/wsgi/v1_0/messages.py:173 #: zaqar/transport/wsgi/v1_1/messages.py:200#: zaqar/transport/wsgi/v1_0/messages.py:231 #: zaqar/transport/wsgi/v1_1/messages.py:268#: zaqar/transport/wsgi/v1_0/messages.py:279 #: zaqar/transport/wsgi/v1_1/messages.py:343 #: zaqar/transport/wsgi/v1_1/pools.py:197#: zaqar/transport/wsgi/v1_0/messages.py:290 #: zaqar/transport/wsgi/v1_1/messages.py:354#: zaqar/transport/wsgi/v1_0/messages.py:296 #: zaqar/transport/wsgi/v1_1/messages.py:360#: zaqar/transport/wsgi/v1_0/messages.py:302 #: zaqar/transport/wsgi/v1_1/messages.py:366#: zaqar/transport/wsgi/v1_0/messages.py:308 #: zaqar/transport/wsgi/v1_1/messages.py:372#: zaqar/transport/wsgi/v1_0/metadata.py:54 #: zaqar/transport/wsgi/v1_1/queues.py:55#: zaqar/transport/wsgi/v1_0/metadata.py:91#: zaqar/transport/wsgi/v1_0/queues.py:47 #: zaqar/transport/wsgi/v1_1/queues.py:90#: zaqar/transport/wsgi/v1_0/queues.py:76 #: zaqar/transport/wsgi/v1_1/queues.py:105#: zaqar/transport/wsgi/v1_0/queues.py:111 #: zaqar/transport/wsgi/v1_1/queues.py:141#: zaqar/transport/wsgi/v1_0/stats.py:63 zaqar/transport/wsgi/v1_1/stats.py:72#: zaqar/transport/wsgi/v1_1/flavors.py:159#: zaqar/transport/wsgi/v1_1/flavors.py:162#: zaqar/transport/wsgi/v1_1/health.py:37#: zaqar/transport/wsgi/v1_1/messages.py:166#: zaqar/transport/wsgi/v1_1/messages.py:286#: zaqar/transport/wsgi/v1_1/pools.py:198","""POT-Creation-Date: 2014-11-13 06:07+0000\n""#: zaqar/common/transport/wsgi/helpers.py:44#: zaqar/common/transport/wsgi/helpers.py:64#: zaqar/common/transport/wsgi/helpers.py:71#: zaqar/common/transport/wsgi/helpers.py:129#: zaqar/common/transport/wsgi/helpers.py:130#: zaqar/queues/bootstrap.py:89 msgid """" ""Unreliable's default value will be changed to False in the Kilo release. "" ""Please, make sure your deployments are working in a reliable mode or that"" "" `unreliable` is explicitly set to `True` in your configuration files."" msgstr """" #: zaqar/queues/storage/pipeline.py:30#: zaqar/queues/storage/pipeline.py:77#: zaqar/queues/storage/mongodb/driver.py:79#: zaqar/queues/storage/mongodb/driver.py:84#: zaqar/queues/storage/mongodb/driver.py:97#: zaqar/queues/storage/mongodb/messages.py:556#: zaqar/queues/storage/mongodb/messages.py:600#: zaqar/queues/storage/mongodb/messages.py:614#: zaqar/queues/storage/mongodb/messages.py:674#: zaqar/queues/storage/mongodb/queues.py:171#: zaqar/queues/storage/mongodb/utils.py:290#: zaqar/queues/storage/mongodb/utils.py:296#: zaqar/queues/storage/redis/driver.py:42#: zaqar/queues/storage/redis/driver.py:45#: zaqar/queues/storage/redis/driver.py:88 #: zaqar/queues/storage/redis/driver.py:118#: zaqar/queues/storage/redis/driver.py:98#: zaqar/queues/storage/redis/driver.py:107#: zaqar/queues/storage/redis/driver.py:123#: zaqar/queues/storage/redis/driver.py:132#: zaqar/queues/storage/redis/driver.py:151#: zaqar/queues/storage/redis/utils.py:178#: zaqar/queues/storage/redis/utils.py:183#: zaqar/queues/storage/sqlalchemy/driver.py:41#: zaqar/queues/transport/validation.py:98#: zaqar/queues/transport/validation.py:102#: zaqar/queues/transport/validation.py:107#: zaqar/queues/transport/validation.py:120#: zaqar/queues/transport/validation.py:132#: zaqar/queues/transport/validation.py:144#: zaqar/queues/transport/validation.py:159#: zaqar/queues/transport/validation.py:168#: zaqar/queues/transport/validation.py:184 #: zaqar/queues/transport/validation.py:240#: zaqar/queues/transport/validation.py:202#: zaqar/queues/transport/validation.py:208#: zaqar/queues/transport/validation.py:215#: zaqar/queues/transport/validation.py:222#: zaqar/queues/transport/validation.py:249#: zaqar/queues/transport/validation.py:265#: zaqar/queues/transport/wsgi/driver.py:106#: zaqar/queues/transport/wsgi/errors.py:24#: zaqar/queues/transport/wsgi/errors.py:25#: zaqar/queues/transport/wsgi/errors.py:36#: zaqar/queues/transport/wsgi/errors.py:45#: zaqar/queues/transport/wsgi/errors.py:54#: zaqar/queues/transport/wsgi/utils.py:50#: zaqar/queues/transport/wsgi/utils.py:61#: zaqar/queues/transport/wsgi/utils.py:66#: zaqar/queues/transport/wsgi/utils.py:72#: zaqar/queues/transport/wsgi/utils.py:168#: zaqar/queues/transport/wsgi/utils.py:176#: zaqar/queues/transport/wsgi/v1_0/claims.py:77 #: zaqar/queues/transport/wsgi/v1_1/claims.py:97#: zaqar/queues/transport/wsgi/v1_0/claims.py:122 #: zaqar/queues/transport/wsgi/v1_1/claims.py:149#: zaqar/queues/transport/wsgi/v1_0/claims.py:169 #: zaqar/queues/transport/wsgi/v1_1/claims.py:196#: zaqar/queues/transport/wsgi/v1_0/claims.py:187 #: zaqar/queues/transport/wsgi/v1_1/claims.py:214#: zaqar/queues/transport/wsgi/v1_0/messages.py:61 #: zaqar/queues/transport/wsgi/v1_0/messages.py:262 #: zaqar/queues/transport/wsgi/v1_1/messages.py:74 #: zaqar/queues/transport/wsgi/v1_1/messages.py:323#: zaqar/queues/transport/wsgi/v1_0/messages.py:104 #: zaqar/queues/transport/wsgi/v1_1/messages.py:120#: zaqar/queues/transport/wsgi/v1_0/messages.py:168 #: zaqar/queues/transport/wsgi/v1_1/messages.py:195#: zaqar/queues/transport/wsgi/v1_0/messages.py:173 #: zaqar/queues/transport/wsgi/v1_1/messages.py:200#: zaqar/queues/transport/wsgi/v1_0/messages.py:231 #: zaqar/queues/transport/wsgi/v1_1/messages.py:268#: zaqar/queues/transport/wsgi/v1_0/messages.py:279 #: zaqar/queues/transport/wsgi/v1_1/messages.py:343 #: zaqar/queues/transport/wsgi/v1_1/pools.py:197#: zaqar/queues/transport/wsgi/v1_0/messages.py:290 #: zaqar/queues/transport/wsgi/v1_1/messages.py:354#: zaqar/queues/transport/wsgi/v1_0/messages.py:296 #: zaqar/queues/transport/wsgi/v1_1/messages.py:360#: zaqar/queues/transport/wsgi/v1_0/messages.py:302 #: zaqar/queues/transport/wsgi/v1_1/messages.py:366#: zaqar/queues/transport/wsgi/v1_0/messages.py:308 #: zaqar/queues/transport/wsgi/v1_1/messages.py:372#: zaqar/queues/transport/wsgi/v1_0/metadata.py:54 #: zaqar/queues/transport/wsgi/v1_1/queues.py:55#: zaqar/queues/transport/wsgi/v1_0/metadata.py:91#: zaqar/queues/transport/wsgi/v1_0/queues.py:48 #: zaqar/queues/transport/wsgi/v1_1/queues.py:90#: zaqar/queues/transport/wsgi/v1_0/queues.py:77 #: zaqar/queues/transport/wsgi/v1_1/queues.py:105#: zaqar/queues/transport/wsgi/v1_0/queues.py:113 #: zaqar/queues/transport/wsgi/v1_1/queues.py:141#: zaqar/queues/transport/wsgi/v1_0/stats.py:63 #: zaqar/queues/transport/wsgi/v1_1/stats.py:72#: zaqar/queues/transport/wsgi/v1_1/flavors.py:159#: zaqar/queues/transport/wsgi/v1_1/flavors.py:162#: zaqar/queues/transport/wsgi/v1_1/health.py:37#: zaqar/queues/transport/wsgi/v1_1/messages.py:166#: zaqar/queues/transport/wsgi/v1_1/messages.py:286#: zaqar/queues/transport/wsgi/v1_1/pools.py:198",221,227
openstack%2Ffuel-main~master~I3c021f6aa6ccab02a902a6968cad2bb926cc634a,openstack/fuel-main,master,I3c021f6aa6ccab02a902a6968cad2bb926cc634a,Add cinder role deploy for bvt test,ABANDONED,2014-10-28 11:16:12.000000000,2014-12-10 14:02:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-28 11:16:12.000000000', 'files': ['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/84ef16344b644c8adac73761e6f91457d14a7bc5', 'message': 'Add cinder role deploy for bvt test\n\nTo be sure that cinder is deployed\nwithout error, add cinder role deployment\nto the bvt tests in ha mode\n\nChange-Id: I3c021f6aa6ccab02a902a6968cad2bb926cc634a\n'}]",0,131392,84ef16344b644c8adac73761e6f91457d14a7bc5,7,3,1,6719,,,0,"Add cinder role deploy for bvt test

To be sure that cinder is deployed
without error, add cinder role deployment
to the bvt tests in ha mode

Change-Id: I3c021f6aa6ccab02a902a6968cad2bb926cc634a
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/92/131392/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_neutron.py']",2,84ef16344b644c8adac73761e6f91457d14a7bc5,add_cinder_deploy," 2. Add 3 nodes with controller role and cinder role 'slave-01': ['controller', 'cinder'], 'slave-02': ['controller', 'cinder'], 'slave-03': ['controller', 'cinder'],"," 2. Add 3 nodes with controller role 'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller'],",9,9
openstack%2Ffuel-main~stable%2F6.0~Ib19864d777f0439cd2ba172a8a9bd14abe09a201,openstack/fuel-main,stable/6.0,Ib19864d777f0439cd2ba172a8a9bd14abe09a201,Add base tests for plugins,MERGED,2014-12-10 13:37:14.000000000,2014-12-10 14:00:28.000000000,2014-12-10 14:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-10 13:37:14.000000000', 'files': ['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_example/__init__.py', 'fuelweb_test/tests/plugins/__init__.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/tests/plugins/plugin_lbaas/__init__.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py', 'fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/__init__.py', 'fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2bd6ced3fe406f33120fe0d4817103287e8460ad', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}]",0,140678,2bd6ced3fe406f33120fe0d4817103287e8460ad,9,4,1,6719,,,0,"Add base tests for plugins

Add test for lbaas plugin:
For each plugin test variable PLUGIN_PATH should be exported

I.* deploy master node
  * upload plugin on it using path expoerted in PLUGIN_PATH var
  * install plugin
  * enable it
  * deploy cluster with  neutron
  * check that lbaas agent is running
  * create pool/vip
  * assert that vip in Active state
  * run OSTF
By default neutron vlan is used, if we need gre here
variable NEUTRON_SEGMENT_TYPE should be exported with gre value

II. * Deploy neutron with lbaas
    * Reset cluster and add node
    * redeploy and check lbaas

Add template for plugin_example
* deploy neutron simple with example plugin
* deploy ha nova with example plugin
* deploy ha neutron with example plugin
  add nodes, re-deploy cluster
  verify that plugin works on added nodes

III. glusterfs plugin
Deploy simple
  * Deploy simple anv with plugin
  * verify plugin health

Deploy HA:
 * Deploy ha env with plugin
 * Verify health
 * add 2 nodes
 * Re-deploy env
 * verify health
By default nova net is used, to get neutron
Variable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.
Also here we should export GLUSTER_CLUSTER_ENDPOINT in
format like ip:/volume1/subvolume

Change-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/78/140678/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_example/__init__.py', 'fuelweb_test/tests/plugins/__init__.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/tests/plugins/plugin_lbaas/__init__.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py', 'fuelweb_test/helpers/checkers.py', 'fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/__init__.py']",11,2bd6ced3fe406f33120fe0d4817103287e8460ad,,__author__ = 'tleontovich' ,,846,1
openstack%2Fdesignate~master~Ib0bab379d95d1b94ae9dd4dbbbcee606d9e34f42,openstack/designate,master,Ib0bab379d95d1b94ae9dd4dbbbcee606d9e34f42,Switch to oslo.context and sync from incubator,MERGED,2014-12-09 19:57:12.000000000,2014-12-10 13:58:56.000000000,2014-12-10 13:58:55.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-09 19:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e356ae5dee37cad66226348ab80a69fd09af5122', 'message': 'Switch to oslo.context and sync from incubator\n\nChange-Id: Ib0bab379d95d1b94ae9dd4dbbbcee606d9e34f42\n'}, {'number': 2, 'created': '2014-12-09 20:54:36.000000000', 'files': ['designate/openstack/common/context.py', 'designate/openstack/common/_i18n.py', 'designate/openstack/deprecated/xmlutils.py', 'designate/context.py', 'designate/openstack/deprecated/wsgi.py', 'designate/openstack/common/policy.py', 'designate/openstack/common/threadgroup.py', 'requirements.txt', 'designate/openstack/common/eventlet_backdoor.py', 'designate/openstack/common/sslutils.py', 'openstack-common.conf', 'designate/openstack/common/fileutils.py', 'designate/openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/dc88f8f3b77c49b992ef02c11b9da29932fd46d3', 'message': 'Switch to oslo.context and sync from incubator\n\nChange-Id: Ib0bab379d95d1b94ae9dd4dbbbcee606d9e34f42\n'}]",1,140460,dc88f8f3b77c49b992ef02c11b9da29932fd46d3,10,3,2,395,,,0,"Switch to oslo.context and sync from incubator

Change-Id: Ib0bab379d95d1b94ae9dd4dbbbcee606d9e34f42
",git fetch https://review.opendev.org/openstack/designate refs/changes/60/140460/2 && git format-patch -1 --stdout FETCH_HEAD,"['designate/openstack/common/context.py', 'designate/openstack/common/_i18n.py', 'designate/openstack/deprecated/xmlutils.py', 'designate/context.py', 'designate/openstack/deprecated/wsgi.py', 'designate/openstack/common/policy.py', 'designate/openstack/common/threadgroup.py', 'requirements.txt', 'designate/openstack/common/eventlet_backdoor.py', 'designate/openstack/common/sslutils.py', 'openstack-common.conf', 'designate/openstack/common/fileutils.py', 'designate/openstack/common/log.py']",13,e356ae5dee37cad66226348ab80a69fd09af5122,oslo_context,"import copy def list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(common_cli_opts)), (None, copy.deepcopy(logging_cli_opts)), (None, copy.deepcopy(generic_log_opts)), (None, copy.deepcopy(log_opts)), ] handler = importutils.import_object( ""oslo.messaging.notify.log_handler.PublishErrorsHandler"", logging.ERROR) syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility)"," try: handler = importutils.import_object( ""designate.openstack.common.log_handler.PublishErrorsHandler"", logging.ERROR) except ImportError: handler = importutils.import_object( ""oslo.messaging.notify.log_handler.PublishErrorsHandler"", logging.ERROR) syslog = RFCSysLogHandler(facility=facility) else: syslog = logging.handlers.SysLogHandler(facility=facility)",146,204
openstack%2Fzaqar~stable%2Fjuno~I2e4c372b6877710bc08d6cc2d604ef89118d1e69,openstack/zaqar,stable/juno,I2e4c372b6877710bc08d6cc2d604ef89118d1e69,Updated from global requirements,MERGED,2014-11-27 10:38:50.000000000,2014-12-10 13:55:25.000000000,2014-12-10 13:55:24.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1955}, {'_account_id': 6159}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-11-27 10:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/424b3170639336b4528843739c79255796b83325', 'message': 'Updated from global requirements\n\nChange-Id: I2e4c372b6877710bc08d6cc2d604ef89118d1e69\n'}, {'number': 2, 'created': '2014-12-03 21:03:39.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5755694df48cd80c6ad705fd1777a5a6100f69d5', 'message': 'Updated from global requirements\n\nChange-Id: I2e4c372b6877710bc08d6cc2d604ef89118d1e69\n'}]",0,137591,5755694df48cd80c6ad705fd1777a5a6100f69d5,13,5,2,11131,,,0,"Updated from global requirements

Change-Id: I2e4c372b6877710bc08d6cc2d604ef89118d1e69
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/91/137591/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'requirements-py3.txt', 'test-requirements-py3.txt']",4,424b3170639336b4528843739c79255796b83325,openstack/requirements,"testtools>=0.9.34,!=1.4.0",testtools>=0.9.34,12,12
openstack%2Fdesignate~master~Iee4290ea681a6295e4c8787b5362f61720dfa911,openstack/designate,master,Iee4290ea681a6295e4c8787b5362f61720dfa911,rename oslo.concurrency to oslo_concurrency,MERGED,2014-12-06 04:18:20.000000000,2014-12-10 13:55:04.000000000,2014-12-10 13:55:03.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-06 04:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/62547ebc07f03298f315a30b6b36b44f083c901a', 'message': 'rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nChange-Id: Iee4290ea681a6295e4c8787b5362f61720dfa911\n'}, {'number': 2, 'created': '2014-12-06 10:08:19.000000000', 'files': ['designate/central/service.py', 'designate/utils.py', 'designate/backend/impl_bind9.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/e8645863db140b7a5457f579645a1e3ed350520a', 'message': 'rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nChange-Id: Iee4290ea681a6295e4c8787b5362f61720dfa911\nCloses-Bug: #1398656\n'}]",0,139781,e8645863db140b7a5457f579645a1e3ed350520a,10,4,2,6676,,,0,"rename oslo.concurrency to oslo_concurrency

oslo.concurrency-0.3.0 has moved its path to oslo_concurrency,
the old path oslo.concurrency can still work but is deprecated now.

Change-Id: Iee4290ea681a6295e4c8787b5362f61720dfa911
Closes-Bug: #1398656
",git fetch https://review.opendev.org/openstack/designate refs/changes/81/139781/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/central/service.py', 'designate/utils.py', 'designate/backend/impl_bind9.py']",3,62547ebc07f03298f315a30b6b36b44f083c901a,bug/1398656,from oslo_concurrency import lockutils,from oslo.concurrency import lockutils,3,3
openstack%2Foslo-specs~master~I7a25e00f1fb3ad6f043527502f1fa1b9385b0d3e,openstack/oslo-specs,master,I7a25e00f1fb3ad6f043527502f1fa1b9385b0d3e,Restore app-agnostic-logging-parameters spec,MERGED,2014-11-03 12:10:16.000000000,2014-12-10 13:47:08.000000000,2014-12-10 13:47:07.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-11-03 12:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/3a1fe4baa1fe859ac3469b81afece7213fb5fa0e', 'message': 'Restore app-agnostic-logging-parameters spec\n\nChange-Id: I7a25e00f1fb3ad6f043527502f1fa1b9385b0d3e\n'}, {'number': 2, 'created': '2014-11-03 12:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/347f23ced2736ac3c0b5415af819755f5704bbda', 'message': 'Restore app-agnostic-logging-parameters spec\n\nbp/app-agnostic-logging-parameters spec\n\nChange-Id: I7a25e00f1fb3ad6f043527502f1fa1b9385b0d3e\n'}, {'number': 3, 'created': '2014-11-19 16:40:19.000000000', 'files': ['specs/kilo/app-agnostic-logging-parameters.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/35ebb89c60b32fcfc2cb77276c32db1b287c6c2a', 'message': 'Restore app-agnostic-logging-parameters spec\n\nbp/app-agnostic-logging-parameters spec\n\nChange-Id: I7a25e00f1fb3ad6f043527502f1fa1b9385b0d3e\n'}]",3,132551,35ebb89c60b32fcfc2cb77276c32db1b287c6c2a,14,3,3,2472,,,0,"Restore app-agnostic-logging-parameters spec

bp/app-agnostic-logging-parameters spec

Change-Id: I7a25e00f1fb3ad6f043527502f1fa1b9385b0d3e
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/51/132551/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/app-agnostic-logging-parameters.rst'],1,3a1fe4baa1fe859ac3469b81afece7213fb5fa0e,bp/app-agnostic-logging-parameters,"=================================================================== Provide application-agnostic logging parameters in format strings =================================================================== https://blueprints.launchpad.net/oslo.log/+spec/app-agnostic-logging-parameters We still have some nova-specific names in the default logging format string, and we want to eliminate those to make oslo.log more generally useful across projects. Problem description =================== The default ``logging_context_format_string`` and ``logging_default_format_string`` option values include ``%(instance)s``, which is not useful in all projects. We should do something like what we did with ""user_identity"" and provide a generic name, which the projects can fill in with their desired value. Proposed change =============== Make :class:`RequestContext` from :mod:`openstack.common.context` into an abstract base class for other applications to use for their own application-specific request contexts. In the new base class, define some abstract properties with generic names like ``user_identity``, ``resource_id``, etc. that the subclass can override. Change the default for the logging format strings to refer to these generic names. Add a new method to the base class to return values useful for logging. We cannot use the existing :meth:`to_dict` because we expect the logging values to contain generated properties not used for things like reconstructing the context when it passes through RPC calls. :: def get_logging_values(self): """"""Return a dict containing values for logging using this context. """""" values = self.to_dict() values.update({ 'user_identity': self.user_identity, 'resource_id': self.resource_id, }) return values Remove the other functions in the :mod:`context` module for creating and testing contexts. The applications all have their own version of these functions and the versions provided in :mod:`context` are not useful when subclasses of :class:`RequestContext` are used. Update the logging code to use :meth:`get_logging_values` instead of :meth:`to_dict`. Alternatives ------------ We had previously talked about removing this module entirely, but given changes to logging to make the user identity parameters log consistently across projects, I think making it a useful base class is a better approach. Impact on Existing APIs ----------------------- Existing context classes will be updated to be subclasses of the base class, which may allow us to save some repeated code in the constructor. Security impact --------------- When we talk about logging and contexts together we typically worry about exposing secret details. I don't think any of these proposed changes expose any information beyond what we are exposing already. Performance Impact ------------------ Possibly a slight impact creating :class:`RequestContext` instances in the application. If an app sees that as a problem, they could opt to simply copy the base class API into their local class rather than using a subclass, but it would be up to them to keep up with API changes at that point. I don't think this is a significant performance issue. Configuration Impact -------------------- The defaults for the configuration options might change, but the *output* should be the same and the old values will still work as well as they did before. Developer Impact ---------------- The idea is for the other projects to define their context as a subclass of the :class:`RequestContext` in Oslo, implementing or overriding private methods or properties in order to meet the API needed by the logging module. Implementation ============== Assignee(s) ----------- Primary assignee: Doug Hellmann (doug-hellmann) Other contributors: None Milestones ---------- Target Milestone for completion: Kilo-2 Work Items ---------- 1. Remove unused functions from :mod:`context`. 2. Add new :meth:`get_logging_values` to :class:`RequestContext`. 3. Add abstract properties to :class:`RequestContext`. 4. Update default format strings in :mod:`log`. 5. Update :mod:`log` to use :meth:`get_logging_values`. Incubation ========== N/A Adoption -------- N/A Library ------- N/A Anticipated API Stabilization ----------------------------- I expect :meth:`get_logging_values` to be stable. We may add more generated properties to :class:`RequestContext` over time, but we will have to add those as normal properties (not abstract) to provide backwards compatibility. Documentation Impact ==================== The defaults for the config options will need to be updated in any documentation generated from the option definitions. Dependencies ============ None References ========== * Discussion at the juno summit: https://etherpad.openstack.org/p/juno-oslo-release-plan * Mailing list thread that mentions the domain support in Oslo's context as a potential issue for nova: http://lists.openstack.org/pipermail/openstack-dev/2014-February/027634.html .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,179,0
openstack%2Frequirements~master~I0cf50e0497ba64147ea0c237104be2304c95487c,openstack/requirements,master,I0cf50e0497ba64147ea0c237104be2304c95487c,Explicitly state which projects can add requirements,ABANDONED,2014-10-22 15:17:12.000000000,2014-12-10 13:43:22.000000000,,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6786}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-10-22 15:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/946bca0ee8784181ee36e6a9cebbc61802fb3c5a', 'message': 'Explicitly state which projects can add requirements\n\nChange-Id: I0cf50e0497ba64147ea0c237104be2304c95487c\n'}, {'number': 2, 'created': '2014-10-27 12:48:33.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/requirements/commit/13b226dfa84a5937fe5ed718b6a4016d5eed1409', 'message': 'Explicitly state which projects can add requirements\n\nChange-Id: I0cf50e0497ba64147ea0c237104be2304c95487c\n'}]",5,130245,13b226dfa84a5937fe5ed718b6a4016d5eed1409,18,8,2,2472,,,0,"Explicitly state which projects can add requirements

Change-Id: I0cf50e0497ba64147ea0c237104be2304c95487c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/45/130245/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,946bca0ee8784181ee36e6a9cebbc61802fb3c5a,allow-all-projects," All OpenStack projects, regardless of status, may add entries to ``global-requirements.txt`` for dependencies if the project is going to run integration tests under a devstack-configured environment. We want everyone testing with the same requirements, and any project that wants to test in a fully configured environment needs to have their dependencies in the global list. ",,7,0
openstack%2Fspecs-cookiecutter~master~Ib4f84efab8b3af3ddd47d38d63a91362612bd655,openstack/specs-cookiecutter,master,Ib4f84efab8b3af3ddd47d38d63a91362612bd655,Add RSS feed,MERGED,2014-09-10 19:34:37.000000000,2014-12-10 13:42:53.000000000,2014-12-10 13:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-09-10 19:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/specs-cookiecutter/commit/9e0b63a62a00465f39e088fd27a1d154831075d4', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nDo not include the template in the toctree so it will not be included in\nthe RSS feed.\n\nUse the doc build date to produce the copyright string instead of using\na hard-coded value.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}, {'number': 2, 'created': '2014-09-10 20:08:04.000000000', 'files': ['{{cookiecutter.repo_name}}/doc/source/conf.py', '{{cookiecutter.repo_name}}/doc/source/index.rst', '{{cookiecutter.repo_name}}/requirements.txt'], 'web_link': 'https://opendev.org/openstack/specs-cookiecutter/commit/d8f004af753ec9c00ca2579577a9965cce6c53ff', 'message': 'Add RSS feed\n\nPublish an RSS feed of the changes to the specs repository to make the\nspecs more discoverable.\n\nDo not include the template in the toctree so it will not be included in\nthe RSS feed.\n\nUse the doc build date to produce the copyright string instead of using\na hard-coded value.\n\nChange-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655\n'}]",0,120560,d8f004af753ec9c00ca2579577a9965cce6c53ff,9,3,2,2472,,,0,"Add RSS feed

Publish an RSS feed of the changes to the specs repository to make the
specs more discoverable.

Do not include the template in the toctree so it will not be included in
the RSS feed.

Use the doc build date to produce the copyright string instead of using
a hard-coded value.

Change-Id: Ib4f84efab8b3af3ddd47d38d63a91362612bd655
",git fetch https://review.opendev.org/openstack/specs-cookiecutter refs/changes/60/120560/1 && git format-patch -1 --stdout FETCH_HEAD,"['{{cookiecutter.repo_name}}/doc/source/conf.py', '{{cookiecutter.repo_name}}/doc/source/index.rst', '{{cookiecutter.repo_name}}/requirements.txt']",3,9e0b63a62a00465f39e088fd27a1d154831075d4,rss-feed,yasfb>=0.5.1,,9,3
openstack%2Foslo.db~stable%2Fjuno~Ia71446bb8c0b248c6310534deb290524e3946987,openstack/oslo.db,stable/juno,Ia71446bb8c0b248c6310534deb290524e3946987,Repair include_object to accommodate new objects,MERGED,2014-11-28 13:11:22.000000000,2014-12-10 13:36:25.000000000,2014-12-10 13:36:25.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1955}, {'_account_id': 6849}, {'_account_id': 11816}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-11-28 13:11:22.000000000', 'files': ['tests/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5a35fb240001657b49bd13771fe5b5edc12276fb', 'message': 'Repair include_object to accommodate new objects\n\nThe tests in tests/sqlalchemy/test_migrations.py which expect\nto see changes in unique constraints fail due to the\nassumption that the ""include_object"" feature of Alembic only\ndeals with the \'table\' and \'column\' constructs.   As Alembic\n0.7.0 has added include_object support for \'index\' and\n\'unique_constraint\', this method should not be limiting\nitself to not include objects that it\'s testing for.\nTests won\'t pass on Alembic 0.7.0 without this patch.\n\nChange-Id: Ia71446bb8c0b248c6310534deb290524e3946987\n(cherry picked from commit 549ba15e3055d269c6323e6b8b6d072925ad0007)\n'}]",0,137781,5a35fb240001657b49bd13771fe5b5edc12276fb,10,6,1,7491,,,0,"Repair include_object to accommodate new objects

The tests in tests/sqlalchemy/test_migrations.py which expect
to see changes in unique constraints fail due to the
assumption that the ""include_object"" feature of Alembic only
deals with the 'table' and 'column' constructs.   As Alembic
0.7.0 has added include_object support for 'index' and
'unique_constraint', this method should not be limiting
itself to not include objects that it's testing for.
Tests won't pass on Alembic 0.7.0 without this patch.

Change-Id: Ia71446bb8c0b248c6310534deb290524e3946987
(cherry picked from commit 549ba15e3055d269c6323e6b8b6d072925ad0007)
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/81/137781/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/sqlalchemy/test_migrations.py'],1,5a35fb240001657b49bd13771fe5b5edc12276fb,(detached," if type_ == 'table': return name == 'testtbl' else: return True self.assertIn('eggs', msg) # test that the unique constraint is added"," return type_ == 'table' and name == 'testtbl' or type_ == 'column' self.assertIn('eggs', msg)",5,2
openstack%2Fcinder~stable%2Ficehouse~I180dc74e4535bfde19f1741cff975f5ec675dd21,openstack/cinder,stable/icehouse,I180dc74e4535bfde19f1741cff975f5ec675dd21,Raise exception if invalid IP is specified,MERGED,2014-12-09 01:12:51.000000000,2014-12-10 13:35:51.000000000,2014-12-10 13:35:49.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 13636}, {'_account_id': 13747}]","[{'number': 1, 'created': '2014-12-09 01:12:51.000000000', 'files': ['cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6aa4bca436430c1448af21edfb34887a63f2e3ff', 'message': 'Raise exception if invalid IP is specified\n\nThis patch ensures that all values specified for the configuration\noption netapp_controller_ips are valid, rather than logging and\ncontinuing with only the valid addresses.\n\nCloses-Bug: 1396718\n\nChange-Id: I180dc74e4535bfde19f1741cff975f5ec675dd21\n(cherry picked from commit 3748994b58e4255958365b0939056cca8c323c9a)\n'}]",0,140195,6aa4bca436430c1448af21edfb34887a63f2e3ff,9,6,1,9186,,,0,"Raise exception if invalid IP is specified

This patch ensures that all values specified for the configuration
option netapp_controller_ips are valid, rather than logging and
continuing with only the valid addresses.

Closes-Bug: 1396718

Change-Id: I180dc74e4535bfde19f1741cff975f5ec675dd21
(cherry picked from commit 3748994b58e4255958365b0939056cca8c323c9a)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/95/140195/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py']",2,6aa4bca436430c1448af21edfb34887a63f2e3ff,bug/1396718," raise exception.NoValidHost( _(""Controller IP '%(host)s' could not be resolved: %(e)s."") % {'host': host, 'e': e})", return None if not ips: msg = _('Controller ips not valid after resolution.') raise exception.NoValidHost(reason=msg),50,4
openstack%2Ffuel-main~master~Ib19864d777f0439cd2ba172a8a9bd14abe09a201,openstack/fuel-main,master,Ib19864d777f0439cd2ba172a8a9bd14abe09a201,Add base tests for plugins,MERGED,2014-11-13 18:25:36.000000000,2014-12-10 13:26:07.000000000,2014-12-10 13:26:06.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 12817}]","[{'number': 1, 'created': '2014-11-13 18:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/17686b1fb27c3a3a12ba146dfdfa1281cec8ece4', 'message': 'WIP: Add base tests for lbaas plugin\n\nAdd test for lbaas plugin:\n* deploy master node\n* upload plugin on it using path expoerted in PLUGIN_PATH var\n* install plugin\n* enable it\n* deploy cluster with  neutron\n* check that lbaas agent is running\n* create pool/vip\n* assert that vip in Active state\n* run OSTF\n\nAdd template for plugin_example\nand glusterfs plugin\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 2, 'created': '2014-11-13 18:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b1aaea1d715a62efcfb2c9af7f614ea6c29577a5', 'message': 'WIP: Add base tests for lbaas plugin\n\nAdd test for lbaas plugin:\n* deploy master node\n* upload plugin on it using path expoerted in PLUGIN_PATH var\n* install plugin\n* enable it\n* deploy cluster with  neutron\n* check that lbaas agent is running\n* create pool/vip\n* assert that vip in Active state\n* run OSTF\n\nAdd template for plugin_example\nand glusterfs plugin\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 3, 'created': '2014-11-17 14:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2a539d5f643b66ce22da1c3bd19570d57c128b9c', 'message': 'WIP: Add base tests for lbaas plugin\n\nAdd test for lbaas plugin:\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutronwith example plugin\n  add nodes\n  verify that plugin works on added nodes\n\nand glusterfs plugin\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 4, 'created': '2014-11-17 14:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0889a115ed6d5cb6ee5d5f9507743f22d77e5b1f', 'message': 'WIP: Add base tests for lbaas plugin\n\nAdd test for lbaas plugin:\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nand glusterfs plugin\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 5, 'created': '2014-11-21 11:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/01fb624f366c831fefe5a4774a6b4faa685819c2', 'message': 'WIP: Add base tests for lbaas plugin\n\nAdd test for lbaas plugin:\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nand glusterfs plugin\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 6, 'created': '2014-11-21 11:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ffbf88084251fa2ecbcc2b462df42f9c968519df', 'message': 'WIP: Add base tests for lbaas plugin\n\nAdd test for lbaas plugin:\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nand glusterfs plugin\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 7, 'created': '2014-11-27 15:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f367445660a3adfa662473ca3b57614f156569d1', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 8, 'created': '2014-11-27 15:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2a8378a016f2a88605e0c8cac624f654319b7f6b', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 9, 'created': '2014-11-28 11:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/164f1370486873e4f654aa0d44cfa42f3fe2d981', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 10, 'created': '2014-11-28 12:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/31ebacebe26f285ffb682a2f369eb1cec999b8c8', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 11, 'created': '2014-12-01 22:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/783e5e8b92bfd2b40a27f3465b7c2035ba1362cf', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}, {'number': 12, 'created': '2014-12-10 11:27:04.000000000', 'files': ['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_example/__init__.py', 'fuelweb_test/tests/plugins/__init__.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/tests/plugins/plugin_lbaas/__init__.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py', 'fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/__init__.py', 'fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/868ea1623635b51116b1823e4e8a600cb65e1570', 'message': 'Add base tests for plugins\n\nAdd test for lbaas plugin:\nFor each plugin test variable PLUGIN_PATH should be exported\n\nI.* deploy master node\n  * upload plugin on it using path expoerted in PLUGIN_PATH var\n  * install plugin\n  * enable it\n  * deploy cluster with  neutron\n  * check that lbaas agent is running\n  * create pool/vip\n  * assert that vip in Active state\n  * run OSTF\nBy default neutron vlan is used, if we need gre here\nvariable NEUTRON_SEGMENT_TYPE should be exported with gre value\n\nII. * Deploy neutron with lbaas\n    * Reset cluster and add node\n    * redeploy and check lbaas\n\nAdd template for plugin_example\n* deploy neutron simple with example plugin\n* deploy ha nova with example plugin\n* deploy ha neutron with example plugin\n  add nodes, re-deploy cluster\n  verify that plugin works on added nodes\n\nIII. glusterfs plugin\nDeploy simple\n  * Deploy simple anv with plugin\n  * verify plugin health\n\nDeploy HA:\n * Deploy ha env with plugin\n * Verify health\n * add 2 nodes\n * Re-deploy env\n * verify health\nBy default nova net is used, to get neutron\nVariable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.\nAlso here we should export GLUSTER_CLUSTER_ENDPOINT in\nformat like ip:/volume1/subvolume\n\nChange-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201\n'}]",0,134321,868ea1623635b51116b1823e4e8a600cb65e1570,56,5,12,6719,,,0,"Add base tests for plugins

Add test for lbaas plugin:
For each plugin test variable PLUGIN_PATH should be exported

I.* deploy master node
  * upload plugin on it using path expoerted in PLUGIN_PATH var
  * install plugin
  * enable it
  * deploy cluster with  neutron
  * check that lbaas agent is running
  * create pool/vip
  * assert that vip in Active state
  * run OSTF
By default neutron vlan is used, if we need gre here
variable NEUTRON_SEGMENT_TYPE should be exported with gre value

II. * Deploy neutron with lbaas
    * Reset cluster and add node
    * redeploy and check lbaas

Add template for plugin_example
* deploy neutron simple with example plugin
* deploy ha nova with example plugin
* deploy ha neutron with example plugin
  add nodes, re-deploy cluster
  verify that plugin works on added nodes

III. glusterfs plugin
Deploy simple
  * Deploy simple anv with plugin
  * verify plugin health

Deploy HA:
 * Deploy ha env with plugin
 * Verify health
 * add 2 nodes
 * Re-deploy env
 * verify health
By default nova net is used, to get neutron
Variable NEUTRON_ENABLE. In this case neutron vlan wiil be deployed.
Also here we should export GLUSTER_CLUSTER_ENDPOINT in
format like ip:/volume1/subvolume

Change-Id: Ib19864d777f0439cd2ba172a8a9bd14abe09a201
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/21/134321/12 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_example/__init__.py', 'fuelweb_test/tests/plugins/__init__.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/tests/plugins/plugin_lbaas/__init__.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py', 'fuelweb_test/helpers/checkers.py', 'fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/__init__.py']",11,17686b1fb27c3a3a12ba146dfdfa1281cec8ece4,test_example_plugin,__author__ = 'tleontovich' ,,617,1
openstack%2Fpuppet-keystone~master~Ib05522d922fecfbd28aa8a8b092b4d3b47172d00,openstack/puppet-keystone,master,Ib05522d922fecfbd28aa8a8b092b4d3b47172d00,crontab: ensure the script is run with bash shell,MERGED,2014-12-09 15:51:19.000000000,2014-12-10 13:15:24.000000000,2014-12-09 23:31:05.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 9500}]","[{'number': 1, 'created': '2014-12-09 15:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/00af5542ee2794854107e0e14b9048bcaf2b0d57', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Keystone user.\nWe can run the crontab by force bash shell usage and avoid running\nissues.\n\nChange-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00\n'}, {'number': 2, 'created': '2014-12-09 18:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/f4c085ea9f6125ccd9e545aa3136f33c5637e7fe', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Keystone user.\nWe can run the crontab by force bash shell usage and avoid running\nissues.\n\nChange-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00\n'}, {'number': 3, 'created': '2014-12-09 18:34:55.000000000', 'files': ['manifests/cron/token_flush.pp', 'spec/classes/keystone_cron_token_flush_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c39fca28e68cbfdcfb64efb91ec9927a9385cdd3', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Keystone user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00\n'}]",3,140378,c39fca28e68cbfdcfb64efb91ec9927a9385cdd3,16,5,3,3153,,,0,"crontab: ensure the script is run with bash shell

Some distros does not provide a default shell for Keystone user.
We can run the crontab by force shell usage and avoid running
issues.

Change-Id: Ib05522d922fecfbd28aa8a8b092b4d3b47172d00
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/78/140378/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/cron/token_flush.pp', 'spec/classes/keystone_cron_token_flush_spec.rb']",2,00af5542ee2794854107e0e14b9048bcaf2b0d57,cron-shell," :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/bash', :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/bash',"," :environment => 'PATH=/bin:/usr/bin:/usr/sbin', :environment => 'PATH=/bin:/usr/bin:/usr/sbin',",3,3
openstack%2Fpuppet-ceilometer~master~I3a4d5c958a4620335d062baecfc362fd758768b6,openstack/puppet-ceilometer,master,I3a4d5c958a4620335d062baecfc362fd758768b6,crontab: ensure the script is run with shell,MERGED,2014-12-09 15:54:37.000000000,2014-12-10 13:14:47.000000000,2014-12-09 23:35:48.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-12-09 15:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/7a8b1a2b5c0a52b3d03b1b46c5a566ba12c81348', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Ceilometer user.\nWe can run the crontab by force bash shell usage and avoid running\nissues.\n\nChange-Id: I3a4d5c958a4620335d062baecfc362fd758768b6\n'}, {'number': 2, 'created': '2014-12-09 18:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/7deec68a20601134f1da1dbf45309f51c187b1bb', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Ceilometer user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: I3a4d5c958a4620335d062baecfc362fd758768b6\n'}, {'number': 3, 'created': '2014-12-09 18:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/ea7ad7408fd97805cf15be5b9681faa0db6340f6', 'message': 'crontab: ensure the script is run with shell\n\nSome distros does not provide a default shell for Ceilometer user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: I3a4d5c958a4620335d062baecfc362fd758768b6\n'}, {'number': 4, 'created': '2014-12-09 18:47:09.000000000', 'files': ['spec/classes/ceilometer_expirer_spec.rb', 'manifests/expirer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a83673c3bae7d560680cb77f2a2cc8c998fac2b7', 'message': 'crontab: ensure the script is run with shell\n\nSome distros does not provide a default shell for Ceilometer user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nCloses-bug: #1400523\nChange-Id: I3a4d5c958a4620335d062baecfc362fd758768b6\n'}]",0,140379,a83673c3bae7d560680cb77f2a2cc8c998fac2b7,13,3,4,3153,,,0,"crontab: ensure the script is run with shell

Some distros does not provide a default shell for Ceilometer user.
We can run the crontab by force shell usage and avoid running
issues.

Closes-bug: #1400523
Change-Id: I3a4d5c958a4620335d062baecfc362fd758768b6
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/79/140379/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_expirer_spec.rb', 'manifests/expirer.pp']",2,7a8b1a2b5c0a52b3d03b1b46c5a566ba12c81348,cron-shell," environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/bash',"," environment => 'PATH=/bin:/usr/bin:/usr/sbin',",2,2
openstack%2Fpuppet-nova~master~Id222c943ac2f0957e1354a739ca42dde1162d1ae,openstack/puppet-nova,master,Id222c943ac2f0957e1354a739ca42dde1162d1ae,crontab: ensure the script is run with shell,MERGED,2014-12-09 15:56:21.000000000,2014-12-10 13:14:11.000000000,2014-12-09 23:36:21.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-12-09 15:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/3d06086314a6e7943d4619d8e029c9822cd12b9d', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Nova user.\nWe can run the crontab by force bash shell usage and avoid running\nissues.\n\nChange-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae\n'}, {'number': 2, 'created': '2014-12-09 18:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/69a5e074a15a670282e4bb6e09ea90a65ddae50d', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Nova user.\nWe can run the crontab by force bash shell usage and avoid running\nissues.\n\nChange-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae\n'}, {'number': 3, 'created': '2014-12-09 18:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c9d1cfb2558bf5056d480256a6fd1fcae76f2f5a', 'message': 'crontab: ensure the script is run with bash shell\n\nSome distros does not provide a default shell for Nova user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae\n'}, {'number': 4, 'created': '2014-12-09 18:38:24.000000000', 'files': ['manifests/cron/archive_deleted_rows.pp', 'spec/classes/nova_cron_archive_deleted_rows_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8897ab59088b89770a6754bee7d94156922e19ee', 'message': 'crontab: ensure the script is run with shell\n\nSome distros does not provide a default shell for Nova user.\nWe can run the crontab by force shell usage and avoid running\nissues.\n\nChange-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae\n'}]",0,140380,8897ab59088b89770a6754bee7d94156922e19ee,12,3,4,3153,,,0,"crontab: ensure the script is run with shell

Some distros does not provide a default shell for Nova user.
We can run the crontab by force shell usage and avoid running
issues.

Change-Id: Id222c943ac2f0957e1354a739ca42dde1162d1ae
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/80/140380/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/cron/archive_deleted_rows.pp', 'spec/classes/nova_cron_archive_deleted_rows_spec.rb']",2,3d06086314a6e7943d4619d8e029c9822cd12b9d,cron-shell," :environment => 'PATH=/bin:/usr/bin:/usr/sbin SHELL=/bin/bash',"," :environment => 'PATH=/bin:/usr/bin:/usr/sbin',",2,2
openstack%2Ffuel-web~master~I2a378601e9a0fdf53a3495e05cb37c24f7431c5c,openstack/fuel-web,master,I2a378601e9a0fdf53a3495e05cb37c24f7431c5c,Added settings validation check before allowing cluster deploy,MERGED,2014-11-27 15:02:01.000000000,2014-12-10 13:11:57.000000000,2014-12-10 13:11:57.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}, {'_account_id': 13516}]","[{'number': 1, 'created': '2014-11-27 15:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c81d85df19e6002800b9825abf55e419d8547fec', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 2, 'created': '2014-11-27 16:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/98e9f7eda4513552e38b87babff81197935d0561', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 3, 'created': '2014-11-28 10:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b8f78d83186c96ab1cfe422470766e0d94f7dea5', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 4, 'created': '2014-11-28 11:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bd07a52d9b362de2b13de2615f51f2103e21131c', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 5, 'created': '2014-11-28 13:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/60f237af4129ff4dd450fd5b7fb1b2e830b321be', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 6, 'created': '2014-12-01 13:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dffea54cd51186b30b6d61a20f83f0b10dab8c10', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 7, 'created': '2014-12-01 13:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/99a3a1856822fb596277dd280681a537dc86ed87', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 8, 'created': '2014-12-10 11:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b8080f7c3f2e75c5d3d284b878f5319a5fc03409', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1381640\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}, {'number': 9, 'created': '2014-12-10 12:03:45.000000000', 'files': ['nailgun/static/js/views/dialogs.jsx', 'nailgun/static/i18n/translation.json'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/67c918c291b67f69048e3832832bf5748baaa3a2', 'message': 'Added settings validation check before allowing cluster deploy\n\nChange-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c\nCloses-bug: #1347682\nCloses-bug: #1370723\nCloses-bug: #1370724\n'}]",14,137658,67c918c291b67f69048e3832832bf5748baaa3a2,70,8,9,9091,,,0,"Added settings validation check before allowing cluster deploy

Change-Id: I2a378601e9a0fdf53a3495e05cb37c24f7431c5c
Closes-bug: #1347682
Closes-bug: #1370723
Closes-bug: #1370724
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/58/137658/8 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/dialogs.jsx', 'nailgun/static/i18n/translation.json']",2,c81d85df19e6002800b9825abf55e419d8547fec,valid_sett_before_deploy," ""compute"": ""Compute nodes are recommended for deployment"", ""settings_invalid"": ""Deployment cannot be started because of invalid settings"""," ""compute"": ""Compute nodes are recommended for deployment""",14,4
openstack%2Ffuel-main~stable%2F5.1~I1d9232e0531f9e8f5c33baa21afb90d7a437a183,openstack/fuel-main,stable/5.1,I1d9232e0531f9e8f5c33baa21afb90d7a437a183,Customize root password and keystone password on admin node.,MERGED,2014-11-28 14:53:41.000000000,2014-12-10 13:06:58.000000000,2014-12-10 13:06:58.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-11-28 14:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f42b0e1ee8ed2b1d6ec0a40be1e82cdfe05163e3', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I1d9232e0531f9e8f5c33baa21afb90d7a437a183\nCloses-Bug: #1381962\n'}, {'number': 2, 'created': '2014-12-05 13:49:13.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/51c068d67892bc0e048690e2a42186886bbddb7d', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I1d9232e0531f9e8f5c33baa21afb90d7a437a183\nCloses-Bug: #1381962\n'}]",0,137800,51c068d67892bc0e048690e2a42186886bbddb7d,15,8,2,11969,,,0,"Customize root password and keystone password on admin node.

- passwords can be customized via environment variables;
- root password changes right after provisioning admin node;
- keystone password changes after deploying admin node.

Change-Id: I1d9232e0531f9e8f5c33baa21afb90d7a437a183
Closes-Bug: #1381962
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/00/137800/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/settings.py']",3,f42b0e1ee8ed2b1d6ec0a40be1e82cdfe05163e3,bug/1381962," SSH_CREDENTIALS = {'login': os.environ.get('ENV_FUEL_LOGIN', 'root'), 'password': os.environ.get('ENV_FUEL_PASSWORD', 'r00tme')}",,31,11
openstack%2Foslo.messaging~master~I674c0def1efb420c293897d49683593a0b10e291,openstack/oslo.messaging,master,I674c0def1efb420c293897d49683593a0b10e291,The executor doesn't need to set the timeout,MERGED,2014-12-08 11:59:27.000000000,2014-12-10 13:05:32.000000000,2014-12-10 13:05:31.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8415}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-12-08 11:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/13136db7e52cfe1d5778387d25fe8560b86bfe51', 'message': ""The executor don't need the set the timeout\n\nIt's up to the driver to set a suitable timeout for polling the broker,\nthis one can be different that the one requested by the driver\ncaller as long as the caller timeout is respected.\n\nThis change also add a new driver listener API, to be able\nto stop it cleanly, specially in case of timeout=None.\n\nCloses bug: #1400268\nCloses bug: #1399257\nChange-Id: I674c0def1efb420c293897d49683593a0b10e291\n""}, {'number': 2, 'created': '2014-12-08 12:00:07.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/base.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_executors/impl_blocking.py', 'oslo/messaging/_executors/impl_eventlet.py', 'tests/executors/test_executor.py', 'oslo/messaging/_drivers/impl_fake.py', 'oslo/messaging/_executors/base.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/15aa5cbda810ef3f757e9e54280fd8216dc9ef7d', 'message': ""The executor doesn't need to set the timeout\n\nIt's up to the driver to set a suitable timeout for polling the broker,\nthis one can be different that the one requested by the driver\ncaller as long as the caller timeout is respected.\n\nThis change also adds a new driver listener API, to be able\nto stop it cleanly, specially in case of timeout=None.\n\nCloses bug: #1400268\nCloses bug: #1399257\nChange-Id: I674c0def1efb420c293897d49683593a0b10e291\n""}]",3,139982,15aa5cbda810ef3f757e9e54280fd8216dc9ef7d,11,6,2,2813,,,0,"The executor doesn't need to set the timeout

It's up to the driver to set a suitable timeout for polling the broker,
this one can be different that the one requested by the driver
caller as long as the caller timeout is respected.

This change also adds a new driver listener API, to be able
to stop it cleanly, specially in case of timeout=None.

Closes bug: #1400268
Closes bug: #1399257
Change-Id: I674c0def1efb420c293897d49683593a0b10e291
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/82/139982/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_qpid.py', 'oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/base.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_executors/impl_blocking.py', 'oslo/messaging/_executors/impl_eventlet.py', 'tests/executors/test_executor.py', 'oslo/messaging/_drivers/impl_fake.py', 'oslo/messaging/_executors/base.py']",9,13136db7e52cfe1d5778387d25fe8560b86bfe51,bug/1400268,,# NOTE(sileht): value choosen according the best practice from kombu # http://kombu.readthedocs.org/en/latest/reference/kombu.common.html#kombu.common.eventloop POLL_TIMEOUT = 1 ,54,34
openstack%2Foslo.messaging~master~I8f267fc8b5a7abc852f0caf84d1e7c2c342ba951,openstack/oslo.messaging,master,I8f267fc8b5a7abc852f0caf84d1e7c2c342ba951,qpid: honor iterconsume timeout,MERGED,2014-12-08 11:59:27.000000000,2014-12-10 13:04:51.000000000,2014-12-10 13:04:49.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-12-08 11:59:27.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/43a9dc1de58df6559be02dc9f9ae3f5eeb12cb7a', 'message': 'qpid: honor iterconsume timeout\n\nThe qpid driver must always honor the timeout passed the iterconsume\nmethod, this change fixes that.\n\nRelated bug: #1400268\nRelated bug: #1399257\n\nChange-Id: I8f267fc8b5a7abc852f0caf84d1e7c2c342ba951\n'}]",3,139981,43a9dc1de58df6559be02dc9f9ae3f5eeb12cb7a,8,5,1,2813,,,0,"qpid: honor iterconsume timeout

The qpid driver must always honor the timeout passed the iterconsume
method, this change fixes that.

Related bug: #1400268
Related bug: #1399257

Change-Id: I8f267fc8b5a7abc852f0caf84d1e7c2c342ba951
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/81/139981/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_qpid.py'],1,43a9dc1de58df6559be02dc9f9ae3f5eeb12cb7a,bug/1400268," timer = rpc_common.DecayingTimer(duration=timeout).start() def _raise_timeout(exc): LOG.debug('Timed out waiting for RPC response: %s', exc) raise rpc_common.Timeout() def _error_callback(exc): timer.check_return(_raise_timeout, exc) LOG.exception(_('Failed to consume message from queue: %s'), exc) poll_timeout = 1 if timeout is None else min(timeout, 1) while True: try: nxt_receiver = self.session.next_receiver( timeout=poll_timeout) except qpid_exceptions.Empty as exc: poll_timeout = timer.check_return(_raise_timeout, exc, maximum=1) else: break LOG.exception(_(""Error processing message. "" ""Skipping it.""))"," def _error_callback(exc): if isinstance(exc, qpid_exceptions.Empty): LOG.debug('Timed out waiting for RPC response: %s', exc) raise rpc_common.Timeout() else: LOG.exception(_('Failed to consume message from queue: %s'), exc) nxt_receiver = self.session.next_receiver(timeout=timeout) LOG.exception(_(""Error processing message. Skipping it.""))",21,8
openstack%2Ffuel-ostf~master~I4f488166223ca6bbd294815e6bff7215ad6009ba,openstack/fuel-ostf,master,I4f488166223ca6bbd294815e6bff7215ad6009ba,Add ceilometer keystone notifications tests to ostf,MERGED,2014-11-07 10:51:39.000000000,2014-12-10 13:03:23.000000000,2014-12-10 13:03:23.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8392}, {'_account_id': 8592}, {'_account_id': 8789}, {'_account_id': 8824}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-11-07 10:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/75a9a54b4b128e914fb1f1398ab6708855bf895f', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\n\nAdded but disabled because not implemented or not works:\nidentity.role_assignment.created, identity.role_assignment.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 2, 'created': '2014-11-12 16:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/2d4f2548622f09a7d9bd4037dc77a7939701c2ee', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\n\nAdded but disabled because not implemented or not works:\nidentity.role_assignment.created, identity.role_assignment.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 3, 'created': '2014-11-12 16:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b6d7a5bfa2da4a20532860be1f74dfc59b6800c4', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 4, 'created': '2014-11-13 14:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/dbbdb363841a7d581fad6304fcc0728801fb1252', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 5, 'created': '2014-11-17 16:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/64df81d5507895ed729c003bc1cf143d8ebf9c31', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 6, 'created': '2014-11-27 15:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/e4196cddc6447a11399d2f3372dde311ca2c8756', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 7, 'created': '2014-12-01 15:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/3e4a4445159bccf81da0e5a28d3d2eaeeed74369', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}, {'number': 8, 'created': '2014-12-01 18:05:26.000000000', 'files': ['fuel_health/tests/platform_tests/test_create_alarm.py', 'fuel_health/nmanager.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/ceilometermanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/9023a565c8ea536c0e5fa5f137f3ad78e89ec92a', 'message': 'Add ceilometer keystone notifications tests to ostf\n\nAdded ceilometer tests for keystone notifications:\nidentity.user.created, identity.user.deleted, identity.user.updated\nidentity.role.created, identity.role.updated, identity.role.deleted\nidentity.project.created, identity.project.updated, identity.project.deleted\nidentity.group.created, identity.group.updated, identity.group.deleted\nidentity.trust.created, identity.trust.deleted\n\nChanged actual duration for ceilometer tests in relation to recent\nchanges in ceilometer\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba\n'}]",11,133199,9023a565c8ea536c0e5fa5f137f3ad78e89ec92a,71,13,8,7126,,,0,"Add ceilometer keystone notifications tests to ostf

Added ceilometer tests for keystone notifications:
identity.user.created, identity.user.deleted, identity.user.updated
identity.role.created, identity.role.updated, identity.role.deleted
identity.project.created, identity.project.updated, identity.project.deleted
identity.group.created, identity.group.updated, identity.group.deleted
identity.trust.created, identity.trust.deleted

Changed actual duration for ceilometer tests in relation to recent
changes in ceilometer

Partially implements: blueprint ceilometer-ostf-notification-tests

Change-Id: I4f488166223ca6bbd294815e6bff7215ad6009ba
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/99/133199/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/platform_tests/test_create_alarm.py', 'fuel_health/nmanager.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/ceilometermanager.py']",4,75a9a54b4b128e914fb1f1398ab6708855bf895f,bp/ceilometer-ostf-notification-tests," cls.objects_for_delete = [] cls.keystone_user_notifications = [ 'identity.user.created', 'identity.user.deleted', 'identity.user.updated'] cls.keystone_role_notifications = [ 'identity.role.created', 'identity.role.updated', 'identity.role.deleted'] cls.keystone_role_assignment_notifications = [ 'identity.role_assignment.created', 'identity.role_assignment.deleted'] cls.keystone_project_notifications = [ 'identity.project.created', 'identity.project.updated', 'identity.project.deleted'] cls.keystone_group_notifications = [ 'identity.group.created', 'identity.group.updated', 'identity.group.deleted'] cls.keystone_trust_notifications = [ 'identity.trust.created', 'identity.trust.deleted'] self.objects_for_delete.append((self.ceilometer_client.alarms.delete, alarm.alarm_id)) return alarm def identity_helper(self): user_pass = rand_name(""ceilo-user-pass"") tenant = self.identity_client.tenants.create(rand_name(""ceilo-tenant"")) self.objects_for_delete.append((self.identity_client.tenants.delete, tenant)) self.identity_client.tenants.update(tenant.id, rand_name(""ceilo-tenant-update"")) user = self.identity_client.users.create(name=rand_name(""ceilo-user""), password=user_pass, tenant_id=tenant.id) self.objects_for_delete.append((self.identity_client.users.delete, user)) self.identity_client.users.update(user, name=rand_name(""ceilo-user-update"")) role = self.identity_v3_client.roles.create(rand_name(""ceilo-role"")) self.identity_v3_client.roles.update(role, user=user, project=tenant) self.objects_for_delete.append((self.identity_client.roles.delete, role)) # role_assignment = self.identity_v3_client.role_assignments.create( # role=role, user=user, project=tenant) # self.objects_for_delete.append( # (self.identity_client.role_assignments.delete, role_assignment)) # trust = self.identity_v3_client.trusts.create( # next(user for user in self.identity_client.users.list() # if user.name == ""admin""), user, [role.name], tenant) # self.objects_for_delete.append((self.identity_v3_client.trusts.delete, # trust)) group = self.identity_v3_client.groups.create(rand_name(""ceilo-group"")) self.objects_for_delete.append((self.identity_v3_client.groups.delete, group)) self.identity_v3_client.groups.update( group, name=rand_name(""ceilo-group-update"")) self.identity_v3_client.groups.delete(group) # self.identity_v3_client.trusts.delete(trust) # self.identity_v3_client.role_assignments.delete(role_assignment) self.identity_client.roles.delete(role) self.identity_client.users.delete(user) self.identity_client.tenants.delete(tenant) return tenant, user, role, group # , trust @staticmethod def cleanup_resources(object_list): for method, resource in object_list: try: method(resource) except Exception: LOG.debug(traceback.format_exc()) cls.cleanup_resources(cls.objects_for_delete)"," cls.alarm_id_list = [] if alarm: self.alarm_id_list.append(alarm.alarm_id) return alarm @classmethod def _clean(cls, items, client): if items: for item in items: try: client.delete(item) except RuntimeError as exc: cls.error_msg.append(exc) LOG.debug(traceback.format_exc()) @classmethod def _clean_alarms(cls): cls._clean(cls.alarm_id_list, cls.ceilometer_client.alarms) try: cls._clean_alarms() except Exception as exc: LOG.debug(exc)",153,32
openstack%2Foslo.messaging~master~I157dab80cdb4afcf9a5f26fa900f96f0696db502,openstack/oslo.messaging,master,I157dab80cdb4afcf9a5f26fa900f96f0696db502,rabbit: more precise iterconsume timeout,MERGED,2014-12-08 11:59:27.000000000,2014-12-10 12:59:35.000000000,2014-12-10 12:59:34.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-12-08 11:59:27.000000000', 'files': ['oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/023b7f44e2ccd77a7e9ee9ee78431a4646c88f13', 'message': 'rabbit: more precise iterconsume timeout\n\nThe iterconsume always set the timeout of kombu to 1 second\neven the requested timeout more precise or < 1 second.\n\nThis change fixes that.\n\nRelated bug: #1400268\nRelated bug: #1399257\n\nChange-Id: I157dab80cdb4afcf9a5f26fa900f96f0696db502\n'}]",1,139980,023b7f44e2ccd77a7e9ee9ee78431a4646c88f13,9,5,1,2813,,,0,"rabbit: more precise iterconsume timeout

The iterconsume always set the timeout of kombu to 1 second
even the requested timeout more precise or < 1 second.

This change fixes that.

Related bug: #1400268
Related bug: #1399257

Change-Id: I157dab80cdb4afcf9a5f26fa900f96f0696db502
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/80/139980/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/amqpdriver.py', 'oslo/messaging/_drivers/impl_rabbit.py', 'oslo/messaging/_drivers/common.py']",3,023b7f44e2ccd77a7e9ee9ee78431a4646c88f13,bug/1400268,"import time class DecayingTimer(object): def __init__(self, duration=None): self._duration = duration self._ends_at = None def start(self): if self._duration is not None: self._ends_at = time.time() + max(0, self._duration) return self def check_return(self, timeout_callback, *args, **kwargs): if self._duration is None: return None if self._ends_at is None: raise RuntimeError(""Can not check/return a timeout from a timer"" "" that has not been started"") maximum = kwargs.pop('maximum', None) left = self._ends_at - time.time() if left <= 0: timeout_callback(*args, **kwargs) return left if maximum is None else min(left, maximum)",,47,41
openstack%2Fmurano~master~I87557ec6cb301ad2277232d8ea3ed6b145ac058d,openstack/murano,master,I87557ec6cb301ad2277232d8ea3ed6b145ac058d,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:57:11.000000000,2014-12-10 12:54:18.000000000,2014-12-10 12:54:16.000000000,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-05 03:57:11.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/3e4e832dce146cc039d4ab1531c830248a81510e', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I87557ec6cb301ad2277232d8ea3ed6b145ac058d\n'}]",0,139476,3e4e832dce146cc039d4ab1531c830248a81510e,17,4,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I87557ec6cb301ad2277232d8ea3ed6b145ac058d
",git fetch https://review.opendev.org/openstack/murano refs/changes/76/139476/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,3e4e832dce146cc039d4ab1531c830248a81510e,infra-manual,* http://docs.openstack.org/infra/manual/developers.html * http://docs.openstack.org/infra/manual/developers.html#development-workflow,* http://wiki.openstack.org/HowToContribute * https://wiki.openstack.org/wiki/GerritWorkflow,2,2
openstack%2Fmurano~master~I80f439fc2667b05a5bcf2091559ae7a332bfcbee,openstack/murano,master,I80f439fc2667b05a5bcf2091559ae7a332bfcbee,Removed outdated init scripts,MERGED,2014-11-29 20:36:30.000000000,2014-12-10 12:54:13.000000000,2014-12-10 12:54:12.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-29 20:36:30.000000000', 'files': ['etc/init.d/murano-api-redhat', 'etc/init.d/README.rst', 'etc/init.d/murano-engine-redhat', 'etc/init.d/murano-api-debian', 'etc/init.d/murano-engine-debian'], 'web_link': 'https://opendev.org/openstack/murano/commit/500ed42c6da8598d38a15a5dd09153add5c30211', 'message': 'Removed outdated init scripts\n\nThese scripts were not supported for a long time. Upstream\ndistributions have their own version of init scripts for Murano.\n\nChange-Id: I80f439fc2667b05a5bcf2091559ae7a332bfcbee\n'}]",0,137921,500ed42c6da8598d38a15a5dd09153add5c30211,10,6,1,7600,,,0,"Removed outdated init scripts

These scripts were not supported for a long time. Upstream
distributions have their own version of init scripts for Murano.

Change-Id: I80f439fc2667b05a5bcf2091559ae7a332bfcbee
",git fetch https://review.opendev.org/openstack/murano refs/changes/21/137921/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/init.d/murano-api-redhat', 'etc/init.d/README.rst', 'etc/init.d/murano-engine-redhat', 'etc/init.d/murano-api-debian', 'etc/init.d/murano-engine-debian']",5,500ed42c6da8598d38a15a5dd09153add5c30211,cleanup,,"#!/bin/sh # Copyright (c) 2014 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # Author: Igor Yozhikov <iyozhikov@mirantis.com> # ### BEGIN INIT INFO # Provides: murano-engine # Required-Start: $network $local_fs $remote_fs $syslog # Required-Stop: $remote_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: OpenStack Murano Engine Server # Description: This startup script launches murano-engine service daemon. ### END INIT INFO PATH=/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/bin DESC=""murano-engine"" NAME=murano-engine DAEMON=$(which murano-engine) PIDFILE=/var/run/murano/$NAME.pid SCRIPTNAME=/etc/init.d/$NAME DAEMONLOG=/var/log/murano/$NAME.log SYSTEM_USER=murano CONFIG_FILE=/etc/murano/murano.conf # Exit if the package is not installed [ -x $DAEMON ] || exit 5 # source function library . /lib/lsb/init-functions do_start() { if [ ! -d ""/var/run/murano"" ]; then mkdir -p /var/run/murano chown -R $SYSTEM_USER /var/run/murano fi start-stop-daemon --start --background --quiet --chuid $SYSTEM_USER:$SYSTEM_USER --make-pidfile --pidfile $PIDFILE --startas $DAEMON --test -- --config-file=$CONFIG_FILE > /dev/null || return 1 start-stop-daemon --start --background --quiet --chuid $SYSTEM_USER:$SYSTEM_USER --make-pidfile --pidfile $PIDFILE --startas $DAEMON -- --config-file=$CONFIG_FILE --log-file=$DAEMONLOG || return 2 } do_stop() { start-stop-daemon --stop --quiet --retry=TERM/30/KILL/5 --pidfile $PIDFILE RETVAL=""$?"" rm -f $PIDFILE return ""$RETVAL"" } case ""$1"" in start) log_daemon_msg ""Starting $DESC"" ""$NAME"" do_start case ""$?"" in 0|1) log_end_msg 0 ;; 2) log_end_msg 1 ;; esac ;; stop) log_daemon_msg ""Stopping $DESC"" ""$NAME"" do_stop case ""$?"" in 0|1) log_end_msg 0 ;; 2) log_end_msg 1 ;; esac ;; status) status_of_proc ""$DAEMON"" ""$NAME"" && exit 0 || exit $? ;; restart|force-reload) log_daemon_msg ""Restarting $DESC"" ""$NAME"" do_stop case ""$?"" in 0|1) do_start case ""$?"" in 0) log_end_msg 0 ;; 1) log_end_msg 1 ;; # Old process is still running *) log_end_msg 1 ;; # Failed to start esac ;; *) # Failed to stop log_end_msg 1 ;; esac ;; *) echo ""Usage: $SCRIPTNAME {start|stop|status|restart|force-reload}"" >&2 exit 3 ;; esac ",0,420
openstack%2Fmurano~master~If1e3ed20172c40344b771627ce20739348b80163,openstack/murano,master,If1e3ed20172c40344b771627ce20739348b80163,Adds aggregate function to MuranoPL (YAQL),MERGED,2014-11-21 09:59:01.000000000,2014-12-10 12:51:18.000000000,2014-12-10 12:51:18.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-21 09:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/702dc89ede5a56d5640811fb915c4ee23a03448b', 'message': ""Adds aggregate function to MuranoPL (YAQL)\n\nAggregate is similar to python's reduce() built-in\n\nChange-Id: If1e3ed20172c40344b771627ce20739348b80163\n""}, {'number': 2, 'created': '2014-11-21 15:19:14.000000000', 'files': ['murano/tests/unit/dsl/meta/TestEngineFunctions.yaml', 'murano/tests/unit/dsl/test_engine_yaql_functions.py', 'murano/engine/system/yaql_functions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/96603bced345e9cce8c79f514d1cc7d8a0121170', 'message': ""Adds aggregate function to MuranoPL (YAQL)\n\nAggregate is similar to python's reduce() built-in\n\nChange-Id: If1e3ed20172c40344b771627ce20739348b80163\n""}]",0,136282,96603bced345e9cce8c79f514d1cc7d8a0121170,14,5,2,7226,,,0,"Adds aggregate function to MuranoPL (YAQL)

Aggregate is similar to python's reduce() built-in

Change-Id: If1e3ed20172c40344b771627ce20739348b80163
",git fetch https://review.opendev.org/openstack/murano refs/changes/82/136282/2 && git format-patch -1 --stdout FETCH_HEAD,"['murano/tests/unit/dsl/meta/TestEngineFunctions.yaml', 'murano/tests/unit/dsl/test_engine_yaql_functions.py', 'murano/engine/system/yaql_functions.py']",3,702dc89ede5a56d5640811fb915c4ee23a03448b,aggregate-function,"@yaql.context.EvalArg('collection', collections.Iterable) def _aggregate(collection, selector): return reduce(selector, collection) @yaql.context.EvalArg('collection', collections.Iterable) def _aggregate_with_seed(collection, selector, seed): return reduce(selector, collection, seed()) context.register_function(_aggregate, 'aggregate') context.register_function(_aggregate_with_seed, 'aggregate')",,40,0
openstack%2Fmurano~master~Ic33f61acfd0de17181690cda9a517717522116cf,openstack/murano,master,Ic33f61acfd0de17181690cda9a517717522116cf,Merged duplicating unit tests for actions,MERGED,2014-10-13 19:23:14.000000000,2014-12-10 12:51:07.000000000,2014-12-10 12:51:05.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-10-13 19:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bf3e8f9de213687348bb0fba92567f1e8e6cd1eb', 'message': 'Merged duplicating unit tests for actions\n\nWe had two almost identical files with unit tests for actions. This\ncommit merges two files into one and puts it in a proper location.\n\nChange-Id: Ic33f61acfd0de17181690cda9a517717522116cf\n'}, {'number': 2, 'created': '2014-11-29 01:22:27.000000000', 'files': ['murano/tests/test_actions.py', 'murano/tests/unit/test_actions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/e8babf5b29961db2f1faac73ea6b2ceb54731efc', 'message': 'Merged duplicating unit tests for actions\n\nWe had two almost identical files with unit tests for actions. This\ncommit merges two files into one and puts it in a proper location.\n\nChange-Id: Ic33f61acfd0de17181690cda9a517717522116cf\n'}]",0,128060,e8babf5b29961db2f1faac73ea6b2ceb54731efc,14,6,2,7600,,,0,"Merged duplicating unit tests for actions

We had two almost identical files with unit tests for actions. This
commit merges two files into one and puts it in a proper location.

Change-Id: Ic33f61acfd0de17181690cda9a517717522116cf
",git fetch https://review.opendev.org/openstack/murano refs/changes/60/128060/2 && git format-patch -1 --stdout FETCH_HEAD,"['murano/tests/test_actions.py', 'murano/tests/unit/test_actions.py']",2,bf3e8f9de213687348bb0fba92567f1e8e6cd1eb,,"from murano.services import actions class TestActionFinder(base.MuranoTestCase): def setUp(self): super(TestActionFinder, self).setUp() def test_simple_root_level_search(self): model = { '?': { 'id': 'id1', '_actions': { 'ad_deploy': { 'enabled': True, 'name': 'deploy' } } } } action = actions.ActionServices.find_action(model, 'ad_deploy') self.assertEqual('deploy', action[1]['name']) def test_recursive_action_search(self): model = { '?': { 'id': 'id1', '_actions': {'ad_deploy': {'enabled': True, 'name': 'deploy'}} }, 'property': { '?': { 'id': 'id2', '_actions': { 'ad_scale': {'enabled': True, 'name': 'scale'} } }, } } action = actions.ActionServices.find_action(model, 'ad_scale') self.assertEqual('scale', action[1]['name'])",,39,135
openstack%2Fnova~master~Ief66e2245179a37eae60bafaf9e8f452d89319a7,openstack/nova,master,Ief66e2245179a37eae60bafaf9e8f452d89319a7,move all conf overrides to conf_fixture,MERGED,2014-12-09 14:11:13.000000000,2014-12-10 12:49:21.000000000,2014-12-10 12:49:18.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 14:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80570fedd9c0d480750e7661f7b63905099b3a09', 'message': 'move all conf overrides to conf_fixture\n\nSome config overrides were in conf_fixture, and some were living in\ntest.py:setUp. If we are globally overriding conf variables we should\ndo it in one place, the fixture.\n\nChange-Id: Ief66e2245179a37eae60bafaf9e8f452d89319a7\n'}, {'number': 2, 'created': '2014-12-09 19:05:59.000000000', 'files': ['nova/test.py', 'nova/tests/unit/conf_fixture.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e8e74ffebb36ea4003c0b525634b9e2586c242a', 'message': 'move all conf overrides to conf_fixture\n\nSome config overrides were in conf_fixture, and some were living in\ntest.py:setUp. If we are globally overriding conf variables we should\ndo it in one place, the fixture.\n\nChange-Id: Ief66e2245179a37eae60bafaf9e8f452d89319a7\n'}]",0,140333,2e8e74ffebb36ea4003c0b525634b9e2586c242a,22,9,2,2750,,,0,"move all conf overrides to conf_fixture

Some config overrides were in conf_fixture, and some were living in
test.py:setUp. If we are globally overriding conf variables we should
do it in one place, the fixture.

Change-Id: Ief66e2245179a37eae60bafaf9e8f452d89319a7
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/140333/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/test.py', 'nova/tests/unit/conf_fixture.py']",2,80570fedd9c0d480750e7661f7b63905099b3a09,fixtures_series," self.conf.set_default('fatal_exception_format_errors', True) self.conf.set_default('enabled', True, 'osapi_v3') self.conf.set_default('force_dhcp_release', False) self.conf.set_default('periodic_enable', False)",,4,4
openstack%2Fnova~master~I0a45dab39745591a55ffc91b31aed8df5179767a,openstack/nova,master,I0a45dab39745591a55ffc91b31aed8df5179767a,move ServiceFixture and TranslationFixture,MERGED,2014-12-09 14:11:13.000000000,2014-12-10 12:48:52.000000000,2014-12-10 12:48:49.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 14:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92b24a87559bff091bdc46eb4b7c86ea8aabe837', 'message': 'move ServiceFixture and TranslationFixture\n\nMove these into the new namespace. No additional testing added at this\npoint.\n\nChange-Id: I0a45dab39745591a55ffc91b31aed8df5179767a\n'}, {'number': 2, 'created': '2014-12-09 19:05:59.000000000', 'files': ['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_test.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a57e8dd6434c906f223b4b29127575e5b112beda', 'message': 'move ServiceFixture and TranslationFixture\n\nMove these into the new namespace. No additional testing added at this\npoint.\n\nChange-Id: I0a45dab39745591a55ffc91b31aed8df5179767a\n'}]",0,140332,a57e8dd6434c906f223b4b29127575e5b112beda,19,9,2,2750,,,0,"move ServiceFixture and TranslationFixture

Move these into the new namespace. No additional testing added at this
point.

Change-Id: I0a45dab39745591a55ffc91b31aed8df5179767a
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/140332/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_test.py']",3,92b24a87559bff091bdc46eb4b7c86ea8aabe837,fixtures_series,from nova.tests import fixtures self.useFixture(fixtures.ServiceFixture('compute')), self.useFixture(test.ServiceFixture('compute')),37,34
openstack%2Fnova~master~I97fdacdf5a6ad2957b0efa1e21ae084d4eb04ab9,openstack/nova,master,I97fdacdf5a6ad2957b0efa1e21ae084d4eb04ab9,extract fixtures from nova.test to nova.test.fixtures,MERGED,2014-12-09 14:11:13.000000000,2014-12-10 12:48:27.000000000,2014-12-10 12:48:24.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 14:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e0a8fd1752ff0091b826f7c7bb2813bd2e40c1a', 'message': ""extract fixtures from nova.test to nova.test.fixtures\n\nStart extracting all the setup code in note.test into fixtures which\nwill let us decompose test setup (and have test base classes that\ndon't setup everything).\n\nThis creates new OutputStreamCapture fixture and StandardLogging\nfixture and unit tests for both of them plus tests for the exiting\nConf fixture.\n\nH305/306 have to be turned off because hacking import rules are broken\nand continue to believe that fixtures is a nova module not the\nabsolute one.\n\nChange-Id: I97fdacdf5a6ad2957b0efa1e21ae084d4eb04ab9\n""}, {'number': 2, 'created': '2014-12-09 19:05:59.000000000', 'files': ['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/f96ec4411ce89606cf52211061003c14306dcfa1', 'message': ""extract fixtures from nova.test to nova.test.fixtures\n\nStart extracting all the setup code in note.test into fixtures which\nwill let us decompose test setup (and have test base classes that\ndon't setup everything).\n\nThis creates new OutputStreamCapture fixture and StandardLogging\nfixture and unit tests for both of them plus tests for the exiting\nConf fixture.\n\nH305/306 have to be turned off because hacking import rules are broken\nand continue to believe that fixtures is a nova module not the\nabsolute one.\n\nChange-Id: I97fdacdf5a6ad2957b0efa1e21ae084d4eb04ab9\n""}]",0,140331,f96ec4411ce89606cf52211061003c14306dcfa1,22,9,2,2750,,,0,"extract fixtures from nova.test to nova.test.fixtures

Start extracting all the setup code in note.test into fixtures which
will let us decompose test setup (and have test base classes that
don't setup everything).

This creates new OutputStreamCapture fixture and StandardLogging
fixture and unit tests for both of them plus tests for the exiting
Conf fixture.

H305/306 have to be turned off because hacking import rules are broken
and continue to believe that fixtures is a nova module not the
absolute one.

Change-Id: I97fdacdf5a6ad2957b0efa1e21ae084d4eb04ab9
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/140331/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py', 'tox.ini']",4,6e0a8fd1752ff0091b826f7c7bb2813bd2e40c1a,fixtures_series,"# H305,H306 Skipped due to inability to handle absolute_import ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H305,H306,H405,H803,H904"," ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H405,H803,H904",262,60
openstack%2Fnova~master~I4cab323fcc7a4e2aab2ca7c36d6b9505b6a05bcb,openstack/nova,master,I4cab323fcc7a4e2aab2ca7c36d6b9505b6a05bcb,Clarify point of setting dirname in load_standard_extensions,MERGED,2014-12-08 15:33:31.000000000,2014-12-10 12:48:06.000000000,2014-12-10 12:48:03.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 15:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06a9fd04667c56c73e93e253005f32d9bcaca410', 'message': ""Remove dead code in load_standard_extensions\n\ndirname[:] doesn't appear to be used for anything so just remove it.\nCloses-Bug: #1399546\n\nChange-Id: I4cab323fcc7a4e2aab2ca7c36d6b9505b6a05bcb\n""}, {'number': 2, 'created': '2014-12-09 19:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25a354646eefb022e3d31ee54010621687e1cc52', 'message': 'Clarify point of setting dirname in load_standard_extensions\n\nChanging dirname to alter how os.walk visits directories is a little\nknown feature, so add a note inline explaining how it works.\n\nThis came up because someone filed a bug saying this block of code was\nconfusing.\n\nCloses-Bug: #1399546\nChange-Id: I4cab323fcc7a4e2aab2ca7c36d6b9505b6a05bcb\n'}, {'number': 3, 'created': '2014-12-09 20:50:31.000000000', 'files': ['nova/api/openstack/extensions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/23eb5555ee1ddc60a6b6e22f8a9713314265b88c', 'message': 'Clarify point of setting dirname in load_standard_extensions\n\nChanging dirname to alter how os.walk visits directories is a little\nknown feature, so add a note inline explaining how it works.\n\nThis came up because someone filed a bug saying this block of code was\nconfusing.\n\nCloses-Bug: #1399546\nChange-Id: I4cab323fcc7a4e2aab2ca7c36d6b9505b6a05bcb\n'}]",1,140028,23eb5555ee1ddc60a6b6e22f8a9713314265b88c,22,9,3,1849,,,0,"Clarify point of setting dirname in load_standard_extensions

Changing dirname to alter how os.walk visits directories is a little
known feature, so add a note inline explaining how it works.

This came up because someone filed a bug saying this block of code was
confusing.

Closes-Bug: #1399546
Change-Id: I4cab323fcc7a4e2aab2ca7c36d6b9505b6a05bcb
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/140028/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/extensions.py'],1,06a9fd04667c56c73e93e253005f32d9bcaca410,bug/1399546, # extension() doesn't exist on it pass," subdirs = [] # extension() doesn't exist on it, so we'll explore # the directory for ourselves subdirs.append(dname) # Update the list of directories we'll explore... dirnames[:] = subdirs ",2,7
openstack%2Fnova~master~I579c0061f03d788c477c5424d4d00ec7a6e721e1,openstack/nova,master,I579c0061f03d788c477c5424d4d00ec7a6e721e1,Adds hacking check for api_version decorator,MERGED,2014-12-02 11:25:28.000000000,2014-12-10 12:47:37.000000000,2014-12-10 12:47:34.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-12-02 11:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9af3822d82b68c1440274fa27ea2b40dcee669cf', 'message': 'Adds hacking check for api_version decorator\n\nBecause of the implementation of this decorator and the controller\'s metaclass,\nthe api_version decorator must be the outermost (ie first) decorator wherever\nit is used. This patch adds a hacking check to ensure that this is the case.\n\nThis decorator is intended to be used on multiple methods with the same name\nwhich offends F811, so \'#noqa\' is needed too. This will be fixed in a separate\npatch.\n\nBad:\n    @some_decorator # noqa  <-- \'# noqa\' to avoid F811\n    @api_version(""2.5"")     <-- Error, needs to be the first decorator\n    def my_api_method...\n\nGood:\n    @api_version(""2.5"") # noqa   <-- this line still needs \'# noqa\' for F811\n    @some_decorator\n    def my_api_method...\n\nChange-Id: I579c0061f03d788c477c5424d4d00ec7a6e721e1\n'}, {'number': 2, 'created': '2014-12-02 13:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56e93c8ccfdbaca4d835f9e655142920072e9d91', 'message': 'Adds hacking check for api_version decorator\n\nBecause of the implementation of this decorator and the controller\'s metaclass,\nthe api_version decorator must be the outermost (ie first) decorator wherever\nit is used. This patch adds a hacking check to ensure that this is the case.\n\nThis decorator is intended to be used on multiple methods with the same name\nwhich offends F811, so \'#noqa\' is needed too. This will be fixed in a separate\npatch.\n\nBad:\n    @some_decorator # noqa  <-- \'# noqa\' to avoid F811\n    @api_version(""2.5"")     <-- Error, needs to be the first decorator\n    def my_api_method...\n\nGood:\n    @api_version(""2.5"") # noqa   <-- this line still needs \'# noqa\' for F811\n    @some_decorator\n    def my_api_method...\n\nChange-Id: I579c0061f03d788c477c5424d4d00ec7a6e721e1\n'}, {'number': 3, 'created': '2014-12-03 09:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfc4385c36f6614e92dacedbe30557f266ce7078', 'message': 'Adds hacking check for api_version decorator\n\nBecause of the implementation of this decorator and the controller\'s metaclass,\nthe api_version decorator must be the outermost (ie first) decorator wherever\nit is used. This patch adds a hacking check to ensure that this is the case.\n\nThis decorator is intended to be used on multiple methods with the same name\nwhich offends F811, so \'#noqa\' is needed too. This will be fixed in a separate\npatch.\n\nBad:\n    @some_decorator # noqa  <-- \'# noqa\' to avoid F811\n    @api_version(""2.5"")     <-- Error, needs to be the first decorator\n    def my_api_method...\n\nGood:\n    @api_version(""2.5"") # noqa   <-- this line still needs \'# noqa\' for F811\n    @some_decorator\n    def my_api_method...\n\nChange-Id: I579c0061f03d788c477c5424d4d00ec7a6e721e1\n'}, {'number': 4, 'created': '2014-12-08 08:35:39.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/hacking/checks.py', 'nova/tests/unit/test_hacking.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/f5c29e98c23ca790f6f869d3cd42a4d5258e7340', 'message': 'Adds hacking check for api_version decorator\n\nBecause of the implementation of this decorator and the controller\'s metaclass,\nthe api_version decorator must be the outermost (ie first) decorator wherever\nit is used. This patch adds a hacking check to ensure that this is the case.\n\nThis decorator is intended to be used on multiple methods with the same name\nwhich offends F811, so \'#noqa\' is needed too. This will be fixed in a separate\npatch.\n\nBad:\n    @some_decorator # noqa  <-- \'# noqa\' to avoid F811\n    @api_version(""2.5"")     <-- Error, needs to be the first decorator\n    def my_api_method...\n\nGood:\n    @api_version(""2.5"") # noqa   <-- this line still needs \'# noqa\' for F811\n    @some_decorator\n    def my_api_method...\n\nChange-Id: I579c0061f03d788c477c5424d4d00ec7a6e721e1\n'}]",2,138319,f5c29e98c23ca790f6f869d3cd42a4d5258e7340,53,14,4,9420,,,0,"Adds hacking check for api_version decorator

Because of the implementation of this decorator and the controller's metaclass,
the api_version decorator must be the outermost (ie first) decorator wherever
it is used. This patch adds a hacking check to ensure that this is the case.

This decorator is intended to be used on multiple methods with the same name
which offends F811, so '#noqa' is needed too. This will be fixed in a separate
patch.

Bad:
    @some_decorator # noqa  <-- '# noqa' to avoid F811
    @api_version(""2.5"")     <-- Error, needs to be the first decorator
    def my_api_method...

Good:
    @api_version(""2.5"") # noqa   <-- this line still needs '# noqa' for F811
    @some_decorator
    def my_api_method...

Change-Id: I579c0061f03d788c477c5424d4d00ec7a6e721e1
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/138319/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/unit/test_hacking.py', 'HACKING.rst']",3,9af3822d82b68c1440274fa27ea2b40dcee669cf,bp/api-microversions,- [N332] Check that the api_version decorator is the first decorator on a method,,20,0
openstack%2Fnova~master~I15129808d0d1271c1223e7ab8d8532f8cb2f7293,openstack/nova,master,I15129808d0d1271c1223e7ab8d8532f8cb2f7293,Doc: minor fixes to unit testing devref,MERGED,2014-11-25 13:51:11.000000000,2014-12-10 12:47:04.000000000,2014-12-10 12:47:00.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9420}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11647}, {'_account_id': 13692}]","[{'number': 1, 'created': '2014-11-25 13:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce326e09502831d374a476068fab21b8d760821d', 'message': 'Doc: minor fixes to unit testing devref\n\nThe unit testing devref had a bit of inconsistent formatting, and a reference\nto HACKING.rst which could have been linkifed.  This patch fixes both of those,\nand additionally the examples have been updated to reflect the recent split\ninto functional and unit tests.\n\nChange-Id: I15129808d0d1271c1223e7ab8d8532f8cb2f7293\n'}, {'number': 2, 'created': '2014-12-09 10:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71f9f22f5a66638be48a94ae311b0abd6f6f5925', 'message': 'Doc: minor fixes to unit testing devref\n\nThe unit testing devref had a bit of inconsistent formatting, and a reference\nto HACKING.rst which could have been linkifed.  This patch fixes both of those,\nand additionally the examples have been updated to reflect the recent split\ninto functional and unit tests.\n\nChange-Id: I15129808d0d1271c1223e7ab8d8532f8cb2f7293\n'}, {'number': 3, 'created': '2014-12-09 12:04:20.000000000', 'files': ['doc/source/devref/unit_tests.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/8654f948da718c504f8dd231bae936b977cf9f94', 'message': 'Doc: minor fixes to unit testing devref\n\nThe unit testing devref had a bit of inconsistent formatting, and a reference\nto HACKING.rst which could have been linkifed.  This patch fixes both of those,\nand additionally the examples have been updated to reflect the recent split\ninto functional and unit tests.\n\nChange-Id: I15129808d0d1271c1223e7ab8d8532f8cb2f7293\n'}]",6,137071,8654f948da718c504f8dd231bae936b977cf9f94,27,12,3,9420,,,0,"Doc: minor fixes to unit testing devref

The unit testing devref had a bit of inconsistent formatting, and a reference
to HACKING.rst which could have been linkifed.  This patch fixes both of those,
and additionally the examples have been updated to reflect the recent split
into functional and unit tests.

Change-Id: I15129808d0d1271c1223e7ab8d8532f8cb2f7293
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/137071/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/unit_tests.rst'],1,ce326e09502831d374a476068fab21b8d760821d,devref_updates,unit testing section of the Testing wiki page`_ and `Nova's HACKING.rst`_To run the style tests::.. _Nova's HACKING.rst: http://git.openstack.org/cgit/openstack/nova/tree/HACKING.rstTo run the tests in the ``nova/tests/unit/scheduler`` directory:: tox -e py27 nova.tests.unit.scheduler To run the tests in the ``nova/tests/unit/virt/libvirt/test_libvirt.py`` file::``nova/tests/unit/virt/libvirt/test_libvirt.py``::``nova/tests/unit/test_utils.py``::,unit testing section of the Testing wiki page`_ and Nova's HACKING.rstTo run the style tests:To run the tests in the ``nova/tests/scheduler`` directory:: tox -e py27 nova.tests.scheduler To run the tests in the ``nova/tests/virt/libvirt/test_libvirt.py`` file::``nova/tests/virt/libvirt/test_libvirt.py``::``nova/tests/test_utils.py``::,8,7
openstack%2Fmurano-dashboard~master~I2856ed84ce5b25de939538997da3498dbacb8306,openstack/murano-dashboard,master,I2856ed84ce5b25de939538997da3498dbacb8306,test ci,ABANDONED,2014-12-03 14:13:35.000000000,2014-12-10 12:45:16.000000000,,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-03 14:13:35.000000000', 'files': ['test.ci'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f23cebc22205fc1a202337a5697daae61adddd0f', 'message': 'test ci\n\nChange-Id: I2856ed84ce5b25de939538997da3498dbacb8306\n'}]",0,138737,f23cebc22205fc1a202337a5697daae61adddd0f,6,3,1,7562,,,0,"test ci

Change-Id: I2856ed84ce5b25de939538997da3498dbacb8306
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/37/138737/1 && git format-patch -1 --stdout FETCH_HEAD,['test.ci'],1,f23cebc22205fc1a202337a5697daae61adddd0f,,,,0,0
openstack%2Fmurano-dashboard~master~I6fc6cf822087cb792bbd649242806a0d7cc47e78,openstack/murano-dashboard,master,I6fc6cf822087cb792bbd649242806a0d7cc47e78,Remove py26 from tox targets,MERGED,2014-12-05 14:33:22.000000000,2014-12-10 12:42:21.000000000,2014-12-10 12:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 10063}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-12-05 14:33:22.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2a52b570c13bea320cb7436b10775010464c7527', 'message': 'Remove py26 from tox targets\n\nOpenStack drops Python 2.6 support in Kilo.\n\nChange-Id: I6fc6cf822087cb792bbd649242806a0d7cc47e78\n'}]",0,139639,2a52b570c13bea320cb7436b10775010464c7527,12,10,1,7549,,,0,"Remove py26 from tox targets

OpenStack drops Python 2.6 support in Kilo.

Change-Id: I6fc6cf822087cb792bbd649242806a0d7cc47e78
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/39/139639/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2a52b570c13bea320cb7436b10775010464c7527,py26-goodbye,"envlist = py27,py33,py34,pep8","envlist = py26,py27,py33,py34,pep8",1,1
openstack%2Ffuel-library~stable%2F5.0~I192ebbd31f83fb264307c1c2f1e17a74cec933b3,openstack/fuel-library,stable/5.0,I192ebbd31f83fb264307c1c2f1e17a74cec933b3,Fix comments in logrotation templates,ABANDONED,2014-11-17 17:37:16.000000000,2014-12-10 12:19:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-11-17 17:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/07c90027cf3c6ca219a3a0e07edb184f710f62c4', 'message': 'Fix comments in logrotation templates\n\nW/o this fix, some log files at Openstack nodes cannot be rotated at the\nhourly schedule and /var/log could end up having no free space while\nwaiting for the next daily based rotation schedule.\n\nCloses-bug: #1393495\n\nChange-Id: I192ebbd31f83fb264307c1c2f1e17a74cec933b3\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-11-17 19:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/366b379386f6aef8342146117f1524c015cce7e7', 'message': 'Fix comments in logrotation templates\n\nW/o this fix, some log files at Openstack nodes cannot be rotated at the\nhourly schedule and /var/log could end up having no free space while\nwaiting for the next daily based rotation schedule\n\nCloses-bug: #1393495\n\nChange-Id: I192ebbd31f83fb264307c1c2f1e17a74cec933b3\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2014-12-03 12:48:23.000000000', 'files': ['deployment/puppet/openstack/templates/20-fuel.conf.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bd0da98b1a30ba5ddceac0bf76ce4548ceda5fd8', 'message': 'Fix comments in logrotation templates\n\nW/o this fix, some log files at Openstack nodes cannot be rotated at the\nhourly schedule and /var/log could end up having no free space while\nwaiting for the next daily based rotation schedule.\n\nCloses-bug: #1393495\n\nChange-Id: I192ebbd31f83fb264307c1c2f1e17a74cec933b3\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,135027,bd0da98b1a30ba5ddceac0bf76ce4548ceda5fd8,19,3,3,6926,,,0,"Fix comments in logrotation templates

W/o this fix, some log files at Openstack nodes cannot be rotated at the
hourly schedule and /var/log could end up having no free space while
waiting for the next daily based rotation schedule.

Closes-bug: #1393495

Change-Id: I192ebbd31f83fb264307c1c2f1e17a74cec933b3
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/135027/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/templates/20-fuel.conf.erb'],1,07c90027cf3c6ca219a3a0e07edb184f710f62c4,,"{ # This file is used for hourly log rotations, use (min)size options here","# This file is used for hourly log rotations, use (min)size options here {",1,1
openstack%2Fzaqar-specs~master~I19aea934526bd6210fdd984f03e43fb484e65741,openstack/zaqar-specs,master,I19aea934526bd6210fdd984f03e43fb484e65741,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:53:05.000000000,2014-12-10 12:18:15.000000000,2014-12-10 12:18:15.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-12-05 03:53:05.000000000', 'files': ['doc/source/contributing.rst', 'CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/0bbd0d5cb22464e42aafca7c5b1f7127825016ad', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I19aea934526bd6210fdd984f03e43fb484e65741\n'}]",0,139405,0bbd0d5cb22464e42aafca7c5b1f7127825016ad,6,2,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I19aea934526bd6210fdd984f03e43fb484e65741
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/05/139405/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'doc/source/contributing.rst']",2,0bbd0d5cb22464e42aafca7c5b1f7127825016ad,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer, start here"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",6,8
openstack%2Fheat~master~I18c6ada4386c0a091ae1d369db91c6a3d6429f34,openstack/heat,master,I18c6ada4386c0a091ae1d369db91c6a3d6429f34,Reduce Server update complexity to below 20,MERGED,2014-11-30 06:45:45.000000000,2014-12-10 12:05:59.000000000,2014-12-10 11:50:05.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-30 06:45:45.000000000', 'files': ['heat/engine/resources/server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4dc2a0af53734a6e2392ada70f8ccbacf4593fc2', 'message': 'Reduce Server update complexity to below 20\n\nOne of the goals to polish Heat code is to make sure the complexity is\nbelow 20.  This patch refactors the Server resource implementation\nregarding its update logic so that it meets this requirement.\n\nThis is a pure code refacto patch, so no test cases are modified.\n\nChange-Id: I18c6ada4386c0a091ae1d369db91c6a3d6429f34\n'}]",3,137931,4dc2a0af53734a6e2392ada70f8ccbacf4593fc2,18,8,1,8246,,,0,"Reduce Server update complexity to below 20

One of the goals to polish Heat code is to make sure the complexity is
below 20.  This patch refactors the Server resource implementation
regarding its update logic so that it meets this requirement.

This is a pure code refacto patch, so no test cases are modified.

Change-Id: I18c6ada4386c0a091ae1d369db91c6a3d6429f34
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/137931/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/server.py'],1,4dc2a0af53734a6e2392ada70f8ccbacf4593fc2,server-reduce-complexity," def _update_flavor(self, server, prop_diff): flavor_update_policy = ( prop_diff.get(self.FLAVOR_UPDATE_POLICY) or self.properties.get(self.FLAVOR_UPDATE_POLICY)) flavor = prop_diff[self.FLAVOR] if flavor_update_policy == 'REPLACE': raise resource.UpdateReplace(self.name) flavor_id = self.client_plugin().get_flavor_id(flavor) if not server: server = self.nova().servers.get(self.resource_id) return scheduler.TaskRunner(self.client_plugin().resize, server, flavor, flavor_id) def _update_image(self, server, prop_diff): image_update_policy = ( prop_diff.get(self.IMAGE_UPDATE_POLICY) or self.properties.get(self.IMAGE_UPDATE_POLICY)) if image_update_policy == 'REPLACE': raise resource.UpdateReplace(self.name) image = prop_diff[self.IMAGE] image_id = self.client_plugin('glance').get_image_id(image) if not server: server = self.nova().servers.get(self.resource_id) preserve_ephemeral = ( image_update_policy == 'REBUILD_PRESERVE_EPHEMERAL') return scheduler.TaskRunner( self.client_plugin().rebuild, server, image_id, preserve_ephemeral=preserve_ephemeral) def _update_networks(self, server, prop_diff): checkers = [] new_networks = prop_diff.get(self.NETWORKS) attach_first_free_port = False if not new_networks: new_networks = [] attach_first_free_port = True old_networks = self.properties.get(self.NETWORKS) if not server: server = self.nova().servers.get(self.resource_id) interfaces = server.interface_list() # if old networks is None, it means that the server got first # free port. so we should detach this interface. if old_networks is None: for iface in interfaces: checker = scheduler.TaskRunner(server.interface_detach, iface.port_id) checkers.append(checker) # if we have any information in networks field, we should: # 1. find similar networks, if they exist # 2. remove these networks from new_networks and old_networks # lists # 3. detach unmatched networks, which were present in old_networks # 4. attach unmatched networks, which were present in new_networks else: # remove not updated networks from old and new networks lists, # also get list these networks not_updated_networks = \ self._get_network_matches(old_networks, new_networks) self.update_networks_matching_iface_port( old_networks + not_updated_networks, interfaces) # according to nova interface-detach command detached port # will be deleted for net in old_networks: checker = scheduler.TaskRunner(server.interface_detach, net.get('port')) checkers.append(checker) # attach section similar for both variants that # were mentioned above for net in new_networks: if net.get('port'): checker = scheduler.TaskRunner(server.interface_attach, net['port'], None, None) checkers.append(checker) elif net.get('network'): checker = scheduler.TaskRunner(server.interface_attach, None, net['network'], net.get('fixed_ip')) checkers.append(checker) # if new_networks is None, we should attach first free port, # according to similar behavior during instance creation if attach_first_free_port: checker = scheduler.TaskRunner(server.interface_attach, None, None, None) checkers.append(checker) return checkers checkers.append(self._update_flavor(server, prop_diff)) checkers.append(self._update_image(server, prop_diff)) checkers.extend(self._update_networks(server, prop_diff))"," flavor_update_policy = ( prop_diff.get(self.FLAVOR_UPDATE_POLICY) or self.properties.get(self.FLAVOR_UPDATE_POLICY)) if flavor_update_policy == 'REPLACE': raise resource.UpdateReplace(self.name) flavor = prop_diff[self.FLAVOR] flavor_id = self.client_plugin().get_flavor_id(flavor) if not server: server = self.nova().servers.get(self.resource_id) checker = scheduler.TaskRunner(self.client_plugin().resize, server, flavor, flavor_id) checkers.append(checker) image_update_policy = ( prop_diff.get(self.IMAGE_UPDATE_POLICY) or self.properties.get(self.IMAGE_UPDATE_POLICY)) if image_update_policy == 'REPLACE': raise resource.UpdateReplace(self.name) image = prop_diff[self.IMAGE] image_id = self.client_plugin('glance').get_image_id(image) if not server: server = self.nova().servers.get(self.resource_id) preserve_ephemeral = ( image_update_policy == 'REBUILD_PRESERVE_EPHEMERAL') checker = scheduler.TaskRunner( self.client_plugin().rebuild, server, image_id, preserve_ephemeral=preserve_ephemeral) checkers.append(checker) new_networks = prop_diff.get(self.NETWORKS) attach_first_free_port = False if not new_networks: new_networks = [] attach_first_free_port = True old_networks = self.properties.get(self.NETWORKS) if not server: server = self.nova().servers.get(self.resource_id) interfaces = server.interface_list() # if old networks is None, it means that the server got first # free port. so we should detach this interface. if old_networks is None: for iface in interfaces: checker = scheduler.TaskRunner(server.interface_detach, iface.port_id) checkers.append(checker) # if we have any information in networks field, we should: # 1. find similar networks, if they exist # 2. remove these networks from new_networks and old_networks # lists # 3. detach unmatched networks, which were present in old_networks # 4. attach unmatched networks, which were present in new_networks else: # remove not updated networks from old and new networks lists, # also get list these networks not_updated_networks = \ self._get_network_matches(old_networks, new_networks) self.update_networks_matching_iface_port( old_networks + not_updated_networks, interfaces) # according to nova interface-detach command detached port # will be deleted for net in old_networks: checker = scheduler.TaskRunner(server.interface_detach, net.get('port')) checkers.append(checker) # attach section similar for both variants that # were mentioned above for net in new_networks: if net.get('port'): checker = scheduler.TaskRunner(server.interface_attach, net['port'], None, None) checkers.append(checker) elif net.get('network'): checker = scheduler.TaskRunner(server.interface_attach, None, net['network'], net.get('fixed_ip')) checkers.append(checker) # if new_networks is None, we should attach first free port, # according to similar behavior during instance creation if attach_first_free_port: checker = scheduler.TaskRunner(server.interface_attach, None, None, None) checkers.append(checker)",101,90
openstack%2Ffuel-library~master~I049bd99b9474204ff498863095beb8eecc641aee,openstack/fuel-library,master,I049bd99b9474204ff498863095beb8eecc641aee,Fix keystone password update for users,MERGED,2014-12-09 17:05:59.000000000,2014-12-10 12:00:16.000000000,2014-12-10 12:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-09 17:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e00c80db34ea18a372b7e9786a8b1b51e27472ca', 'message': 'Fix keystone password update for users\n\nkeystone-client changed its error message when an invalid\npassword is specified. The logic is updated so that puppet\ncan update passwords for users.\n\nBackport of I090f7e2ee62ee189f37921c091fe51b6d587cd74\n\nChange-Id: I049bd99b9474204ff498863095beb8eecc641aee\nCloses-Bug: #1400701\n'}, {'number': 2, 'created': '2014-12-09 20:22:25.000000000', 'files': ['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4a2980191869d3854bddd101093eaa5b02038d11', 'message': 'Fix keystone password update for users\n\nkeystone-client changed its error message when an invalid\npassword is specified. The logic is updated so that puppet\ncan update passwords for users.\n\nBackport of I090f7e2ee62ee189f37921c091fe51b6d587cd74\n\nChange-Id: I049bd99b9474204ff498863095beb8eecc641aee\nPartial-Bug: #1400701'}]",0,140407,4a2980191869d3854bddd101093eaa5b02038d11,22,6,2,7195,,,0,"Fix keystone password update for users

keystone-client changed its error message when an invalid
password is specified. The logic is updated so that puppet
can update passwords for users.

Backport of I090f7e2ee62ee189f37921c091fe51b6d587cd74

Change-Id: I049bd99b9474204ff498863095beb8eecc641aee
Partial-Bug: #1400701",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/07/140407/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/keystone/lib/puppet/provider/keystone_user/keystone.rb'],1,e00c80db34ea18a372b7e9786a8b1b51e27472ca,keystone-pw-update, return nil if e.message =~ /Not Authorized/ or e.message =~ /HTTP 401/, return nil if e.message =~ /Not Authorized/,1,1
openstack%2Fnova~master~I81d1bb4eb4ac7278c02e3e937f74aeadbd20c0f5,openstack/nova,master,I81d1bb4eb4ac7278c02e3e937f74aeadbd20c0f5,Remove support for deprecated header X_ROLE,MERGED,2014-11-12 22:57:22.000000000,2014-12-10 11:59:49.000000000,2014-12-10 11:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 2835}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-12 22:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/814c85f408d583019deff26d3dcc07d806a87112', 'message': 'Remove support for deprecated header X_ROLE\n\nX_ROLE support was deprecated in 2012\n(bc0ba55ae6ce7b9b9bf5c9dd359f9d812ac8d18d) we are overdue in removing\nsupport for it.\n\nChange-Id: I81d1bb4eb4ac7278c02e3e937f74aeadbd20c0f5\n'}, {'number': 2, 'created': '2014-11-13 19:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/097eee5b1643e9e7c80b7785e8bf72b293a694bb', 'message': 'Remove support for deprecated header X_ROLE\n\nX_ROLE support was deprecated in 2012\n(bc0ba55ae6ce7b9b9bf5c9dd359f9d812ac8d18d) we are overdue in removing\nsupport for it.\n\nChange-Id: I81d1bb4eb4ac7278c02e3e937f74aeadbd20c0f5\n'}, {'number': 3, 'created': '2014-12-09 20:38:54.000000000', 'files': ['nova/api/auth.py', 'nova/tests/unit/api/test_auth.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5338cf5426562cd708d74d9c64a50feb2759e6ef', 'message': 'Remove support for deprecated header X_ROLE\n\nX_ROLE support was deprecated in 2012\n(bc0ba55ae6ce7b9b9bf5c9dd359f9d812ac8d18d) we are overdue in removing\nsupport for it.\n\nChange-Id: I81d1bb4eb4ac7278c02e3e937f74aeadbd20c0f5\n'}]",1,134071,5338cf5426562cd708d74d9c64a50feb2759e6ef,29,11,3,1849,,,0,"Remove support for deprecated header X_ROLE

X_ROLE support was deprecated in 2012
(bc0ba55ae6ce7b9b9bf5c9dd359f9d812ac8d18d) we are overdue in removing
support for it.

Change-Id: I81d1bb4eb4ac7278c02e3e937f74aeadbd20c0f5
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/134071/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/auth.py', 'nova/tests/api/test_auth.py']",2,814c85f408d583019deff26d3dcc07d806a87112,deprecated2,," def test_roles(self): # Test that the newer style role header takes precedence. self.request.headers['X_ROLES'] = 'pawn,knight,rook' self.request.headers['X_ROLE'] = 'bad' response = self.request.get_response(self.middleware) self.assertEqual(response.status, '200 Role Match') def test_deprecated_role(self): # Test fallback to older role header. self.request.headers['X_ROLE'] = 'pawn,knight,rook' response = self.request.get_response(self.middleware) self.assertEqual(response.status, '200 Role Match') def test_role_empty(self): self.request.headers['X_ROLE'] = '' response = self.request.get_response(self.middleware) self.assertEqual(response.status, '200 No Roles') ",1,28
openstack%2Fnova~master~I56b3931da7339d2d350a7d1368dd39c7e398d3e6,openstack/nova,master,I56b3931da7339d2d350a7d1368dd39c7e398d3e6,virt: use instance object for attach in block_device,MERGED,2014-10-21 13:55:46.000000000,2014-12-10 11:50:19.000000000,2014-12-10 11:50:16.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-21 13:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c055832d8f41e8401eda3bf60b6503358f797640', 'message': ""virt: use instance object for attach in block_device\n\nIt will be better if we'll use `instance` like object.\n\nChange-Id: I56b3931da7339d2d350a7d1368dd39c7e398d3e6\n""}, {'number': 2, 'created': '2014-11-06 13:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea71b23b0b5e0a1e08777100dafb123018206569', 'message': ""virt: use instance object for attach in block_device\n\nIt will be better if we'll use `instance` like object.\n\nChange-Id: I56b3931da7339d2d350a7d1368dd39c7e398d3e6\n""}, {'number': 3, 'created': '2014-12-09 09:46:54.000000000', 'files': ['nova/tests/unit/virt/test_block_device.py', 'nova/tests/unit/compute/test_compute.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f82aabf76005cae1504a18e9a2dcddb75a33c1f', 'message': ""virt: use instance object for attach in block_device\n\nIt will be better if we'll use `instance` like object.\n\nChange-Id: I56b3931da7339d2d350a7d1368dd39c7e398d3e6\n""}]",0,129912,8f82aabf76005cae1504a18e9a2dcddb75a33c1f,28,9,3,8412,,,0,"virt: use instance object for attach in block_device

It will be better if we'll use `instance` like object.

Change-Id: I56b3931da7339d2d350a7d1368dd39c7e398d3e6
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/129912/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_block_device.py', 'nova/virt/block_device.py']",2,c055832d8f41e8401eda3bf60b6503358f797640,virt-block-device-object," volume_api.attach(context, volume_id, instance.uuid,"," volume_api.attach(context, volume_id, instance['uuid'],",4,2
openstack%2Fnova~master~I8e46d41164e9478b820cad569ba82f25de244620,openstack/nova,master,I8e46d41164e9478b820cad569ba82f25de244620,replace httplib.HTTPSConnection in EC2KeystoneAuth,MERGED,2014-09-26 06:14:04.000000000,2014-12-10 11:49:42.000000000,2014-12-10 11:49:38.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6802}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8574}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11642}]","[{'number': 1, 'created': '2014-09-26 06:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecfbc4806deaecb005a6d7f4e848a01dc2c5021d', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It also adds some config settings related\nto SSL verification: keystone_ec2_keyfile, keystone_ec2_certfile,\nkeystone_ec2_cafile, keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 2, 'created': '2014-10-06 22:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/789ad9cba93bc264ee0e89db5be40b26dece9872', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 3, 'created': '2014-10-07 17:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13d1da918a18bd8d846408b906987e73c6280e8f', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 4, 'created': '2014-10-08 17:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/881eaaf3bdb454e9f1d50340d7b59d0b6057fa01', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 5, 'created': '2014-11-04 11:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5d1df1b3e8a8c66c8351b961b5203bd6c93f4c2', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 6, 'created': '2014-11-05 11:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4895f3c814f9ae00ab7adcc7546f7654a2cf5bfb', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 7, 'created': '2014-11-19 18:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1cc27084f3a6f3ecc78b751a7cc014721ba63a1', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}, {'number': 8, 'created': '2014-12-08 19:21:09.000000000', 'files': ['nova/api/ec2/__init__.py', 'nova/tests/unit/api/ec2/test_middleware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cff14b3763df7515405552b56e96f11765c56c74', 'message': 'replace httplib.HTTPSConnection in EC2KeystoneAuth\n\nhttplib.HTTPSConnection is known to not verify SSL certificates\nin Python 2.x. This change replaces use of httplib.HTTPSConnection\nwith the requests module. It imports config settings related to SSL\nverification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also\nadds one config setting: keystone_ec2_insecure. By default, SSL\nverification is on, but can be disabled by setting:\n\nkeystone_ec2_insecure=true\n\nThis patch is based on the keystone middleware ec2 token patch:\n\nhttps://review.openstack.org/#/c/76476\n\nSecurityImpact\nDocImpact\nCloses-Bug: #1373992\n\nChange-Id: I8e46d41164e9478b820cad569ba82f25de244620\n'}]",35,124296,cff14b3763df7515405552b56e96f11765c56c74,86,16,8,4690,,,0,"replace httplib.HTTPSConnection in EC2KeystoneAuth

httplib.HTTPSConnection is known to not verify SSL certificates
in Python 2.x. This change replaces use of httplib.HTTPSConnection
with the requests module. It imports config settings related to SSL
verification: ssl.key_file, ssl.cert_file, and ssl.ca_file. It also
adds one config setting: keystone_ec2_insecure. By default, SSL
verification is on, but can be disabled by setting:

keystone_ec2_insecure=true

This patch is based on the keystone middleware ec2 token patch:

https://review.openstack.org/#/c/76476

SecurityImpact
DocImpact
Closes-Bug: #1373992

Change-Id: I8e46d41164e9478b820cad569ba82f25de244620
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/124296/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/ec2/__init__.py', 'nova/tests/api/ec2/test_middleware.py']",2,ecfbc4806deaecb005a6d7f4e848a01dc2c5021d,ec2keystoneauth-requests,"import mockimport requests def __init__(self, status_code=400): self.status_code = status_code def json(self): return {} @mock.patch.object(requests, 'post', return_value=FakeResponse()) def test_communication_failure(self, mock_post): mock_post.assert_called_with(CONF.keystone_ec2_url, data=mock.ANY, headers=mock.ANY, verify=mock.ANY, cert=mock.ANY) @mock.patch.object(requests, 'post', return_value=FakeResponse(200)) def test_no_result_data(self, mock_post): mock_post.assert_called_with(CONF.keystone_ec2_url, data=mock.ANY, headers=mock.ANY, verify=mock.ANY, cert=mock.ANY)","from eventlet.green import httplibimport mox def __init__(self, status=400): self.status = status def read(self): return '{}' def test_communication_failure(self): conn = httplib.HTTPConnection('/mock') self.mox.StubOutWithMock(httplib.HTTPConnection, 'request') self.mox.StubOutWithMock(httplib.HTTPConnection, 'getresponse') conn.request('POST', mox.IgnoreArg(), body=mox.IgnoreArg(), headers=mox.IgnoreArg()) resp = FakeResponse() conn.getresponse().AndReturn(resp) self.mox.ReplayAll() def test_no_result_data(self): conn = httplib.HTTPConnection('/mock') self.mox.StubOutWithMock(httplib.HTTPConnection, 'request') self.mox.StubOutWithMock(httplib.HTTPConnection, 'getresponse') self.mox.StubOutWithMock(httplib.HTTPConnection, 'close') conn.request('POST', mox.IgnoreArg(), body=mox.IgnoreArg(), headers=mox.IgnoreArg()) resp = FakeResponse(200) conn.getresponse().AndReturn(resp) conn.close() self.mox.ReplayAll() ",45,45
openstack%2Fnova~master~Idd0f6848ca05e0793506471bb226e2c3530df8be,openstack/nova,master,Idd0f6848ca05e0793506471bb226e2c3530df8be,VMware: clean up unit tests,MERGED,2014-08-31 08:56:18.000000000,2014-12-10 11:49:22.000000000,2014-12-10 11:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-08-31 08:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c676bbb57b0ff517fd9bcaab06c1caa1f1c6486', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 2, 'created': '2014-08-31 11:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0f0cb8aef2f7db5306b7c71d8dc89f1882b876e', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 3, 'created': '2014-09-07 07:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86dc3c888669974ddb70aa4be9e8ddad3465b666', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 4, 'created': '2014-09-08 06:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f295560a056086e9303bd3fd6eb83beb73c05cab', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 5, 'created': '2014-09-14 15:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c927acad9c6bf4311243d98357ccbdaf2d3f2318', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 6, 'created': '2014-09-17 08:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57b49bf6a02629da0a800f2dcd0fbce7ef45ed79', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 7, 'created': '2014-09-21 12:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19def518ef805249f31e701299d483925e2d935f', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 8, 'created': '2014-10-08 05:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55a08820b39a4e128c250d52d7a103c74f266016', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 9, 'created': '2014-10-15 05:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/654f6218e869f150558a5b6c4cb0fcb88ce04eea', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 10, 'created': '2014-10-21 06:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d8053b8bc68a8d5256b15028dddc9ba3c177369', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 11, 'created': '2014-12-08 13:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e531edf62aad6237b6b5ebf4b7ed7d87d1e156a', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}, {'number': 12, 'created': '2014-12-09 07:46:55.000000000', 'files': ['nova/tests/unit/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9cf32b2e37cdb6653917e3e09187148bd7930028', 'message': 'VMware: clean up unit tests\n\nRemove unnecessary test class\n\nThe patch also removes duplicate test methods. These were duplicated\ndue to the fact that there were two drivers (ESX and VC). Now we\nonly have the VC driver.\n\nTrivialFix\n\nChange-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be\n'}]",5,118026,9cf32b2e37cdb6653917e3e09187148bd7930028,109,15,12,1653,,,0,"VMware: clean up unit tests

Remove unnecessary test class

The patch also removes duplicate test methods. These were duplicated
due to the fact that there were two drivers (ESX and VC). Now we
only have the VC driver.

TrivialFix

Change-Id: Idd0f6848ca05e0793506471bb226e2c3530df8be
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/118026/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py']",2,2c676bbb57b0ff517fd9bcaab06c1caa1f1c6486,fix-tests,"import timeclass VMwareAPIVMTestCase(test.NoDBTestCase, test_driver.DriverAPITestHelper): def setUp(self): self.conn = driver.VMwareVCDriver(None, False) self._set_exception_vars() self.node_name = self.conn._resources.keys()[0] self.node_name2 = self.conn._resources.keys()[1] if cluster_name2 in self.node_name2: self.ds = 'ds1' else: self.ds = 'ds2' mock.patch.object(time, 'sleep')","class VMwareAPIVMTestCase(test.NoDBTestCase): def setUp(self, create_connection=True): if create_connection: self.conn = driver.VMwareVCDriver(None, False) self._set_exception_vars() self.node_name = self.conn._resources.keys()[0] self.node_name2 = self.conn._resources.keys()[1] if cluster_name2 in self.node_name2: self.ds = 'ds1' else: self.ds = 'ds2' mock.patch.object(vmops, '_time_sleep_wrapper') class VMwareAPIVCDriverTestCase(VMwareAPIVMTestCase, test_driver.DriverAPITestHelper): def setUp(self): super(VMwareAPIVCDriverTestCase, self).setUp(create_connection=False) cluster_name = 'test_cluster' cluster_name2 = 'test_cluster2' self.flags(cluster_name=[cluster_name, cluster_name2], api_retry_count=1, task_poll_interval=10, datastore_regex='.*', group='vmware') self.flags(vnc_enabled=False, image_cache_subdirectory_name='vmware_base') vmwareapi_fake.reset() self.conn = driver.VMwareVCDriver(None, False) self._set_exception_vars() self.node_name = self.conn._resources.keys()[0] self.node_name2 = self.conn._resources.keys()[1] if cluster_name2 in self.node_name2: self.ds = 'ds1' else: self.ds = 'ds2' self.vnc_host = 'ha-host' def tearDown(self): super(VMwareAPIVCDriverTestCase, self).tearDown() vmwareapi_fake.cleanup() ",14,50
openstack%2Fnova~master~I2d1bbdbd4a391ad3487da905df2e812166a837de,openstack/nova,master,I2d1bbdbd4a391ad3487da905df2e812166a837de,Fix invalid read_deleted value in _validate_unique_server_name(),MERGED,2014-07-23 14:35:57.000000000,2014-12-10 11:49:03.000000000,2014-12-10 11:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-23 14:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/374a0fa5f09bd2b50417b6d88a83fa9bf2f2291b', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 2, 'created': '2014-08-08 17:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14d94155e859dbd8360700e58bc668c1ca057153', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nall values explicitly passed in retain their given value, unless they\nwere explicitly set to None, in which case they are defaulted anyway.\nThis last is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 3, 'created': '2014-10-02 16:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a59003f356b5ac8131f7c80127f87690ca401873', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nall values explicitly passed in retain their given value, unless they\nwere explicitly set to None, in which case they are defaulted anyway.\nThis last is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 4, 'created': '2014-10-02 16:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39b055a1b84a99ca54b9d42bc211d52365a47a44', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nvalues explicitly passed in retain their given value, unless they were\nexplicitly set to None, in which case they are defaulted anyway.  This\nlast is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 5, 'created': '2014-10-06 12:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ddd17d5a88cdfc20babfad5d5f32d379f03317f9', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nvalues explicitly passed in retain their given value, unless they were\nexplicitly set to None, in which case they are defaulted anyway.  This\nlast is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 6, 'created': '2014-10-08 11:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5d8ac651f668a6ba20a9267211a44e90c0dd74a', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nvalues explicitly passed in retain their given value, unless they were\nexplicitly set to None, in which case they are defaulted anyway.  This\nlast is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 7, 'created': '2014-10-08 13:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e35707e92e82c699af1e1810b19092e35e5b9504', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nvalues explicitly passed in retain their given value, unless they were\nexplicitly set to None, in which case they are defaulted anyway.  This\nlast is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}, {'number': 8, 'created': '2014-12-03 14:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c88530f8c943023199a18064ed026834c25403a9', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nvalues explicitly passed in retain their given value, unless they were\nexplicitly set to None, in which case they are defaulted anyway.  This\nlast is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nTidies up type checking of model and base_model.\n\nAdd tests of argument handling.\n\n(Accidentally approved while unit tests are still breaking)\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de""}, {'number': 9, 'created': '2014-12-08 09:28:27.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/13174668298bf7c42b3bcc21051a83b62a7e8a1b', 'message': ""Fix invalid read_deleted value in _validate_unique_server_name()\n\nread_deleted passed to model_query() may have the value 'yes', 'no',\nor 'only', but was being passed the value False. The implementation of\nmodel_query caused this to be ignored, and the value of\ncontext.read_deleted used instead.\n\nThis change cleans up kwarg parsing in model_query to ensure that all\nvalues explicitly passed in retain their given value, unless they were\nexplicitly set to None, in which case they are defaulted anyway.  This\nlast is the expectation of current callers of model_query().\n\nChanges Exception thrown for invalid values to ValueError.\n\nChange-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de\n""}]",21,109006,13174668298bf7c42b3bcc21051a83b62a7e8a1b,103,14,9,9555,,,0,"Fix invalid read_deleted value in _validate_unique_server_name()

read_deleted passed to model_query() may have the value 'yes', 'no',
or 'only', but was being passed the value False. The implementation of
model_query caused this to be ignored, and the value of
context.read_deleted used instead.

This change cleans up kwarg parsing in model_query to ensure that all
values explicitly passed in retain their given value, unless they were
explicitly set to None, in which case they are defaulted anyway.  This
last is the expectation of current callers of model_query().

Changes Exception thrown for invalid values to ValueError.

Change-Id: I2d1bbdbd4a391ad3487da905df2e812166a837de
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/109006/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,374a0fa5f09bd2b50417b6d88a83fa9bf2f2291b,db/invalid_read_deleted, read_deleted='no').\, read_deleted=False).\,1,1
openstack%2Fnova~master~I3ec281dd016ad904e9f323630324e70a002a037d,openstack/nova,master,I3ec281dd016ad904e9f323630324e70a002a037d,move eventlet GREENDNS override to top level,MERGED,2014-12-08 21:17:57.000000000,2014-12-10 11:27:31.000000000,2014-12-10 09:46:47.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 21:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d143a473b9d2c3a7d7a016e55bb6439a9539583', 'message': 'move eventlet GREENDNS override to top level\n\nInstead of working around this in 3 places, only do the import\noverride at the top level. There were comments left by mikal to do\nthis after the pbr switch which is now done.\n\nChange-Id: I3ec281dd016ad904e9f323630324e70a002a037d\n'}, {'number': 2, 'created': '2014-12-08 22:45:12.000000000', 'files': ['nova/__init__.py', 'nova/cmd/__init__.py', 'nova/tests/functional/__init__.py', 'nova/tests/unit/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/18518102cea329ead2c78bb1875705318c5b2afb', 'message': 'move eventlet GREENDNS override to top level\n\nInstead of working around this in 3 places, only do the import\noverride at the top level. There were comments left by mikal to do\nthis after the pbr switch which is now done.\n\nChange-Id: I3ec281dd016ad904e9f323630324e70a002a037d\n'}]",2,140146,18518102cea329ead2c78bb1875705318c5b2afb,38,15,2,2750,,,0,"move eventlet GREENDNS override to top level

Instead of working around this in 3 places, only do the import
override at the top level. There were comments left by mikal to do
this after the pbr switch which is now done.

Change-Id: I3ec281dd016ad904e9f323630324e70a002a037d
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/140146/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/__init__.py', 'nova/cmd/__init__.py', 'nova/tests/functional/__init__.py', 'nova/tests/unit/__init__.py']",4,1d143a473b9d2c3a7d7a016e55bb6439a9539583,fixtures,,"# TODO(mikal): move eventlet imports to nova.__init__ once we move to PBR import os import sys import traceback # NOTE(mikal): All of this is because if dnspython is present in your # environment then eventlet monkeypatches socket.getaddrinfo() with an # implementation which doesn't work for IPv6. What we're checking here is # that the magic environment variable was set when the import happened. # NOTE(dims): Prevent this code from kicking in under docs generation # as it leads to spurious errors/warning. stack = traceback.extract_stack() if ('eventlet' in sys.modules and os.environ.get('EVENTLET_NO_GREENDNS', '').lower() != 'yes' and (len(stack) < 2 or 'sphinx' not in stack[-2][0])): raise ImportError('eventlet imported before nova/cmd/__init__ ' '(env var set to %s)' % os.environ.get('EVENTLET_NO_GREENDNS')) os.environ['EVENTLET_NO_GREENDNS'] = 'yes' ",6,65
openstack%2Ffuel-main~stable%2F6.0~I22dc8659c94138de9e49833316e31f1e3fae295c,openstack/fuel-main,stable/6.0,I22dc8659c94138de9e49833316e31f1e3fae295c,Customize root password and keystone password on admin node.,MERGED,2014-12-10 10:16:51.000000000,2014-12-10 11:23:14.000000000,2014-12-10 11:23:13.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-10 10:16:51.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/79bab82301a6cb1df4305f9e37283a002dd8ba2b', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I22dc8659c94138de9e49833316e31f1e3fae295c\nCloses-Bug: #1381962\n'}]",0,140629,79bab82301a6cb1df4305f9e37283a002dd8ba2b,8,5,1,11969,,,0,"Customize root password and keystone password on admin node.

- passwords can be customized via environment variables;
- root password changes right after provisioning admin node;
- keystone password changes after deploying admin node.

Change-Id: I22dc8659c94138de9e49833316e31f1e3fae295c
Closes-Bug: #1381962
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/29/140629/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/settings.py']",3,79bab82301a6cb1df4305f9e37283a002dd8ba2b,," SSH_CREDENTIALS = { 'login': os.environ.get('ENV_FUEL_LOGIN', 'root'), 'password': os.environ.get('ENV_FUEL_PASSWORD', 'r00tme')}",,56,14
openstack%2Fpython-ceilometerclient~master~I8759dd64637e5150f6744d0989eaa5e584487f5e,openstack/python-ceilometerclient,master,I8759dd64637e5150f6744d0989eaa5e584487f5e,Fix old-style classes declaration,MERGED,2014-12-10 10:20:51.000000000,2014-12-10 11:22:56.000000000,2014-12-10 11:22:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-10 10:20:51.000000000', 'files': ['ceilometerclient/tests/test_utils.py', 'ceilometerclient/tests/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/dd67d3bd259494ac94731aed3d92ac4177c65bf4', 'message': 'Fix old-style classes declaration\n\nChange-Id: I8759dd64637e5150f6744d0989eaa5e584487f5e\n'}]",0,140633,dd67d3bd259494ac94731aed3d92ac4177c65bf4,6,2,1,3012,,,0,"Fix old-style classes declaration

Change-Id: I8759dd64637e5150f6744d0989eaa5e584487f5e
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/33/140633/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/tests/test_utils.py', 'ceilometerclient/tests/fakes.py']",2,dd67d3bd259494ac94731aed3d92ac4177c65bf4,code-style-fixes,class FakeServiceCatalog(object):class FakeKeystone(object):class FakeHTTPResponse(object):,class FakeServiceCatalog():class FakeKeystone():class FakeHTTPResponse():,5,5
openstack%2Ffuel-main~master~I22dc8659c94138de9e49833316e31f1e3fae295c,openstack/fuel-main,master,I22dc8659c94138de9e49833316e31f1e3fae295c,Customize root password and keystone password on admin node.,MERGED,2014-11-26 19:19:04.000000000,2014-12-10 11:21:30.000000000,2014-12-10 11:21:29.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-11-26 19:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/072599459a62469f4fdfd2ce280bf652fe67a53c', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I22dc8659c94138de9e49833316e31f1e3fae295c\nCloses-Bug: #1381962\n'}, {'number': 2, 'created': '2014-11-28 13:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4395336d68c86bc16fc4cd480e254a3a7f50c5ef', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I22dc8659c94138de9e49833316e31f1e3fae295c\nCloses-Bug: #1381962\n'}, {'number': 3, 'created': '2014-12-05 12:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bc45aa8bea7a2e8372f9eb31a356e84e0b65a0ef', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I22dc8659c94138de9e49833316e31f1e3fae295c\nCloses-Bug: #1381962\n'}, {'number': 4, 'created': '2014-12-10 10:16:35.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/183ad8c9de702c0be02f8574321704deee7b3453', 'message': 'Customize root password and keystone password on admin node.\n\n- passwords can be customized via environment variables;\n- root password changes right after provisioning admin node;\n- keystone password changes after deploying admin node.\n\nChange-Id: I22dc8659c94138de9e49833316e31f1e3fae295c\nCloses-Bug: #1381962\n'}]",0,137454,183ad8c9de702c0be02f8574321704deee7b3453,26,9,4,11969,,,0,"Customize root password and keystone password on admin node.

- passwords can be customized via environment variables;
- root password changes right after provisioning admin node;
- keystone password changes after deploying admin node.

Change-Id: I22dc8659c94138de9e49833316e31f1e3fae295c
Closes-Bug: #1381962
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/54/137454/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/settings.py']",3,072599459a62469f4fdfd2ce280bf652fe67a53c,bug/1381962," SSH_CREDENTIALS = { 'login': os.environ.get('ENV_FUEL_LOGIN', 'root'), 'password': os.environ.get('ENV_FUEL_PASSWORD', 'r00tme')}",,32,11
openstack%2Fhorizon~master~I7a7ee75f7aeca7163833d4dd7dd28ad44143cd7b,openstack/horizon,master,I7a7ee75f7aeca7163833d4dd7dd28ad44143cd7b,Fixes Inconsistent usage of Detail / Details,ABANDONED,2014-12-10 09:00:42.000000000,2014-12-10 11:06:20.000000000,,"[{'_account_id': 3}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-12-10 09:00:42.000000000', 'files': ['openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/subnets/workflows.py', 'openstack_dashboard/dashboards/admin/routers/templates/routers/detail.html', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/templates/networks/subnets/detail.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/detail.html', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/admin/networks/templates/networks/subnets/index.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/detail.html', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/resource.html', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/templates/networks/ports/detail.html', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/workflows.py', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d14b73c2f2b53bab31079ecf4a305f07fa072f95', 'message': 'Fixes Inconsistent usage of Detail / Details\n\nThis patch changes all the instances of ""Detail"" to ""Details""\n\nCloses-bug: #1396080\n\nChange-Id: I7a7ee75f7aeca7163833d4dd7dd28ad44143cd7b\n'}]",0,140612,d14b73c2f2b53bab31079ecf4a305f07fa072f95,4,2,1,11599,,,0,"Fixes Inconsistent usage of Detail / Details

This patch changes all the instances of ""Detail"" to ""Details""

Closes-bug: #1396080

Change-Id: I7a7ee75f7aeca7163833d4dd7dd28ad44143cd7b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/140612/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/subnets/workflows.py', 'openstack_dashboard/dashboards/admin/routers/templates/routers/detail.html', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/templates/networks/subnets/detail.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/detail.html', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/admin/networks/templates/networks/subnets/index.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/detail.html', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/resource.html', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/templates/networks/ports/detail.html', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/dashboards/project/networks/workflows.py', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po']",26,d14b73c2f2b53bab31079ecf4a305f07fa072f95,bugs/#1396080_details,"msgid ""Network Details""#: dashboards/admin/routers/templates/routers/detail.html:6msgid ""Subnet Details""msgid ""Port Details""msgid ""Stack Details""msgid ""Resource Details""","msgid ""Network Detail""#: dashboards/admin/routers/templates/routers/detail.html:6 msgid ""Router Detail"" msgstr ""Detalhe de Roteador"" msgid ""Subnet Detail""msgid ""Port Detail""msgid ""Stack Detail""msgid ""Resource Detail""",137,188
openstack%2Fproject-config~master~I9b37d10dffee238d7038dc273508dd7b635a6dd9,openstack/project-config,master,I9b37d10dffee238d7038dc273508dd7b635a6dd9,Use the no-mergepy templates in a TripleO job,ABANDONED,2014-12-04 16:12:47.000000000,2014-12-10 10:56:00.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 4330}, {'_account_id': 6133}]","[{'number': 1, 'created': '2014-12-04 16:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7caed7adbc768b9dce38689a3e4b27852ad99c3a', 'message': ""Add a TripleO job for the non-mergepy templates\n\nWe're looking to switch to these templates and the CI coverage is\nessential for that.\n\nThis change needs to be merged first: I527bfb7f90d75f08982a30d26515740f6cb9f7cf\n\nChange-Id: I9b37d10dffee238d7038dc273508dd7b635a6dd9\n""}, {'number': 2, 'created': '2014-12-09 11:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a78b699dabd21e18d30bcb5804539d779c82e9b3', 'message': ""Use the no-mergepy templates in a TripleO job\n\nWe're looking to switch to these templates as the TripleO default and\nthe CI coverage is an essential first step.\n\nChange-Id: I9b37d10dffee238d7038dc273508dd7b635a6dd9\n""}, {'number': 3, 'created': '2014-12-09 12:13:32.000000000', 'files': ['jenkins/jobs/tripleo.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0e19853d25730ad7968976196ed62531205faf93', 'message': ""Use the no-mergepy templates in a TripleO job\n\nWe're looking to switch to these templates as the TripleO default and\nthe CI coverage is an essential first step.\n\nChange-Id: I9b37d10dffee238d7038dc273508dd7b635a6dd9\n""}]",1,139102,0e19853d25730ad7968976196ed62531205faf93,16,5,3,4330,,,0,"Use the no-mergepy templates in a TripleO job

We're looking to switch to these templates as the TripleO default and
the CI coverage is an essential first step.

Change-Id: I9b37d10dffee238d7038dc273508dd7b635a6dd9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/139102/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/tripleo.yaml', 'zuul/layout.yaml']",2,7caed7adbc768b9dce38689a3e4b27852ad99c3a,nomergepy-tripleo-job, - check-tripleo-ironic-overcloud-nomergepy-f20-nonha - check-tripleo-ironic-overcloud-nomergepy-f20-nonha,,46,0
openstack%2Fheat~master~Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd,openstack/heat,master,Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd,Add OS::Cinder::VolumeType resource,MERGED,2014-10-31 11:17:18.000000000,2014-12-10 10:53:07.000000000,2014-12-10 10:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 8289}, {'_account_id': 8505}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-10-31 11:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fb9ef5c2ace6f49a8154b48bac6b6d32bf6a5132', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}, {'number': 2, 'created': '2014-11-02 03:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5a3534ccaafef9fdba4e0c43161b64a403f4e4e1', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}, {'number': 3, 'created': '2014-11-03 02:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d6b9d2b852cfc5f17825647ba28ebd968dc1bd3', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}, {'number': 4, 'created': '2014-11-13 03:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1567f6a6fdf7d3c3ecfce95756fbcfecd4093464', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}, {'number': 5, 'created': '2014-11-17 09:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d4b6eebeb69f30dfd586202f3948d3700920ad9', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}, {'number': 6, 'created': '2014-11-18 03:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6d42c78422927473e0269d25d7c2842fb6db1742', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}, {'number': 7, 'created': '2014-12-01 03:49:55.000000000', 'files': ['contrib/cinder_volume_type/README.md', 'contrib/cinder_volume_type/cinder_volume_type/tests/test_cinder_volume_type.py', 'contrib/cinder_volume_type/cinder_volume_type/tests/__init__.py', 'contrib/cinder_volume_type/cinder_volume_type/__init__.py', 'contrib/cinder_volume_type/cinder_volume_type/resources/__init__.py', 'contrib/cinder_volume_type/setup.py', 'contrib/cinder_volume_type/cinder_volume_type/resources/cinder_volume_type.py', 'contrib/cinder_volume_type/setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/8b8ab1cdf71089418fe1aedf7de043add614f81c', 'message': 'Add OS::Cinder::VolumeType resource\n\nAdd OS::Cinder::VolumeType resource, implement its\nbasic actions: creation, deletion, updation.\n\nChange-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd\nImplements: blueprint cinder-volume-type\n'}]",10,132214,8b8ab1cdf71089418fe1aedf7de043add614f81c,44,10,7,8289,,,0,"Add OS::Cinder::VolumeType resource

Add OS::Cinder::VolumeType resource, implement its
basic actions: creation, deletion, updation.

Change-Id: Id37f4a0b1c558caa83dbecf7b64f87241ea89cdd
Implements: blueprint cinder-volume-type
",git fetch https://review.opendev.org/openstack/heat refs/changes/14/132214/5 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/cinder_volume_type/README.md', 'contrib/cinder_volume_type/cinder_volume_type/tests/test_cinder_volume_type.py', 'contrib/cinder_volume_type/cinder_volume_type/tests/__init__.py', 'contrib/cinder_volume_type/cinder_volume_type/__init__.py', 'contrib/cinder_volume_type/cinder_volume_type/resources/__init__.py', 'contrib/cinder_volume_type/setup.py', 'contrib/cinder_volume_type/cinder_volume_type/resources/cinder_volume_type.py', 'contrib/cinder_volume_type/setup.cfg']",8,fb9ef5c2ace6f49a8154b48bac6b6d32bf6a5132,bp/cinder-volume-type,[metadata] name = heat-contrib-cinder-volume-type summary = Heat resource for managing cinder volume_types description-file = README.md author = OpenStack author-email = openstack-dev@lists.openstack.org home-page = http://www.openstack.org/ classifier = Environment :: OpenStack Intended Audience :: Information Technology Intended Audience :: System Administrators License :: OSI Approved :: Apache Software License Operating System :: POSIX :: Linux Programming Language :: Python Programming Language :: Python :: 2 Programming Language :: Python :: 2.7 Programming Language :: Python :: 2.6 [files] # Copy to /usr/lib/heat for plugin loading data_files = lib/heat/cinder_volume_type = cinder_volume_type/resources/* [global] setup-hooks = pbr.hooks.setup_hook ,,286,0
openstack%2Fgovernance~master~I581cb37d2627e7a4f2d72fe425547ab98460378c,openstack/governance,master,I581cb37d2627e7a4f2d72fe425547ab98460378c,Completed the gerrit-powered-agenda project split,MERGED,2014-12-08 08:53:31.000000000,2014-12-10 10:51:17.000000000,2014-12-10 10:51:17.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2472}, {'_account_id': 2592}]","[{'number': 1, 'created': '2014-12-08 08:53:31.000000000', 'files': ['reference/programs.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/b623eb7fb76d5b3b81b008a26fc15c8d460e2330', 'message': 'Completed the gerrit-powered-agenda project split\n\nThe gerrit-powered-agenda repository was successfully split into\nyaml2ical (generic code) and irc-meetings (specific config).\n\nChange-Id: I581cb37d2627e7a4f2d72fe425547ab98460378c\n'}]",0,139944,b623eb7fb76d5b3b81b008a26fc15c8d460e2330,11,7,1,308,,,0,"Completed the gerrit-powered-agenda project split

The gerrit-powered-agenda repository was successfully split into
yaml2ical (generic code) and irc-meetings (specific config).

Change-Id: I581cb37d2627e7a4f2d72fe425547ab98460378c
",git fetch https://review.opendev.org/openstack/governance refs/changes/44/139944/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/programs.yaml'],1,b623eb7fb76d5b3b81b008a26fc15c8d460e2330,rename-gpa, - repo: openstack-infra/irc-meetings - repo: openstack-infra/yaml2ical, - repo: openstack-infra/gerrit-powered-agenda,2,1
openstack%2Fgovernance~master~I0e1909e767da1cf696df126450caa6261657c77d,openstack/governance,master,I0e1909e767da1cf696df126450caa6261657c77d,Add Castellan project to Barbican program,MERGED,2014-12-03 22:01:45.000000000,2014-12-10 10:51:05.000000000,2014-12-10 10:51:05.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2472}, {'_account_id': 2592}]","[{'number': 1, 'created': '2014-12-03 22:01:45.000000000', 'files': ['reference/programs.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/e68e9b275490054ef9788b72dc7495dfc9c0621b', 'message': 'Add Castellan project to Barbican program\n\nAfter reviewing a few projects that are starting to integrate with\nBarbican we noticed that a couple of them were defining a Key Manager\nInterface and then implementing the interface using\npython-barbicanclient instead of integrating with Barbican directly.\n\nWe were able to identify a couple of advantages with this pattern.\nNamely that it gives the projects flexibilty to choose an alternative\nKey Manager as needed.  This is helpful during development, for example,\nwhere a simple implementation of the Key Manager Interface can be used\ninstead of having to spin up a Barbican instance.  It would also be\nhelpful in deployments with strict compliance requirements where a Key\nManager with specific certifications is required which would prevent the\nusage of Barbican.\n\nIn order to prevent duplication of efforts, the Barbican team would like\nto provide the generic Key Manager interface, as well as the\npython-barbicanclient implementation of the interface.\n\nWe asked the Oslo team about creating a new oslo library for this\npurpose, but Doug Hellman\'s recommendation was that we create a new\nrepository under the Barbican program since he would prefer that the\nBarbican team be responsible for reviewing changes to the Key Manager\ninterface.\n\nFollowing Doug Hellman\'s recommendation, and after many hours of\nbikeshedding a name for the new repository, the Barbican team agreed on\ncreating a new repository called ""Castellan"" to hold the generic Key\nManager Interface.\n\nWe have requested a new repository in the following CR:\n\nhttps://review.openstack.org/#/c/136140/\n\nAs requested by the Infra team, we\'re also submitting this CR to the\ngovernance repo for review by the TC.\n\nChange-Id: I0e1909e767da1cf696df126450caa6261657c77d\n'}]",0,138875,e68e9b275490054ef9788b72dc7495dfc9c0621b,12,7,1,7973,,,0,"Add Castellan project to Barbican program

After reviewing a few projects that are starting to integrate with
Barbican we noticed that a couple of them were defining a Key Manager
Interface and then implementing the interface using
python-barbicanclient instead of integrating with Barbican directly.

We were able to identify a couple of advantages with this pattern.
Namely that it gives the projects flexibilty to choose an alternative
Key Manager as needed.  This is helpful during development, for example,
where a simple implementation of the Key Manager Interface can be used
instead of having to spin up a Barbican instance.  It would also be
helpful in deployments with strict compliance requirements where a Key
Manager with specific certifications is required which would prevent the
usage of Barbican.

In order to prevent duplication of efforts, the Barbican team would like
to provide the generic Key Manager interface, as well as the
python-barbicanclient implementation of the interface.

We asked the Oslo team about creating a new oslo library for this
purpose, but Doug Hellman's recommendation was that we create a new
repository under the Barbican program since he would prefer that the
Barbican team be responsible for reviewing changes to the Key Manager
interface.

Following Doug Hellman's recommendation, and after many hours of
bikeshedding a name for the new repository, the Barbican team agreed on
creating a new repository called ""Castellan"" to hold the generic Key
Manager Interface.

We have requested a new repository in the following CR:

https://review.openstack.org/#/c/136140/

As requested by the Infra team, we're also submitting this CR to the
governance repo for review by the TC.

Change-Id: I0e1909e767da1cf696df126450caa6261657c77d
",git fetch https://review.opendev.org/openstack/governance refs/changes/75/138875/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/programs.yaml'],1,e68e9b275490054ef9788b72dc7495dfc9c0621b,castellan, - repo: openstack/castellan,,1,0
openstack%2Fgovernance~master~I09fa3f50da0ec272dfd42534835aee895ee4ba5d,openstack/governance,master,I09fa3f50da0ec272dfd42534835aee895ee4ba5d,Add new advanced services repositories for neutron,MERGED,2014-12-02 18:43:38.000000000,2014-12-10 10:49:26.000000000,2014-12-10 10:49:26.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 287}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2889}, {'_account_id': 6437}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-02 18:43:38.000000000', 'files': ['reference/programs.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/75a2e2a90e36b1dbce2d191ff79811c61470ccef', 'message': 'Add new advanced services repositories for neutron\n\nAdding a commit to reference the 3 new service repositories being created\nwhich will host neutron advanced services.\n\nChange-Id: I09fa3f50da0ec272dfd42534835aee895ee4ba5d\n'}]",0,138479,75a2e2a90e36b1dbce2d191ff79811c61470ccef,17,13,1,105,,,0,"Add new advanced services repositories for neutron

Adding a commit to reference the 3 new service repositories being created
which will host neutron advanced services.

Change-Id: I09fa3f50da0ec272dfd42534835aee895ee4ba5d
",git fetch https://review.opendev.org/openstack/governance refs/changes/79/138479/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/programs.yaml'],1,75a2e2a90e36b1dbce2d191ff79811c61470ccef,, - repo: openstack/neutron-fwaas - repo: openstack/neutron-lbaas - repo: openstack/neutron-vpnaas,,3,0
openstack%2Ffuel-web~master~Ib9f45225f6e3c91809ea0dbc47e79b3529b54d3b,openstack/fuel-web,master,Ib9f45225f6e3c91809ea0dbc47e79b3529b54d3b,Do not refresh data on filtering stuff by cluster,MERGED,2014-11-14 10:45:23.000000000,2014-12-10 10:43:18.000000000,2014-12-10 10:43:18.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-11-14 10:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6fb995425a7ad7a88883db9491576b9b49ae6541', 'message': 'Do not refresh data on filtering stuff by cluster\n\nListing nodes of node groups downloads all data from\nNailgun so there is no need to refresh it during the\nfollowing filtering by cluster id.\n\nCloses-bug: #1378963\nChange-Id: Ib9f45225f6e3c91809ea0dbc47e79b3529b54d3b\n'}, {'number': 2, 'created': '2014-11-25 12:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bfd5aeeb6659a3f74f4d0e5d61ae28c43a9d5c54', 'message': 'Do not refresh data on filtering stuff by cluster\n\nListing nodes of node groups downloads all data from\nNailgun so there is no need to refresh it during the\nfollowing filtering by cluster id.\n\nCloses-bug: #1378963\nChange-Id: Ib9f45225f6e3c91809ea0dbc47e79b3529b54d3b\n'}, {'number': 3, 'created': '2014-11-27 10:04:57.000000000', 'files': ['fuelclient/fuelclient/objects/nodegroup.py', 'fuelclient/fuelclient/objects/node.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bc143f2f62900cf1d62193f1a05528b3f23d574f', 'message': 'Do not refresh data on filtering stuff by cluster\n\nListing nodes of node groups downloads all data from\nNailgun so there is no need to refresh it during the\nfollowing filtering by cluster id.\n\nCloses-bug: #1378963\nChange-Id: Ib9f45225f6e3c91809ea0dbc47e79b3529b54d3b\n'}]",4,134498,bc143f2f62900cf1d62193f1a05528b3f23d574f,27,9,3,6623,,,0,"Do not refresh data on filtering stuff by cluster

Listing nodes of node groups downloads all data from
Nailgun so there is no need to refresh it during the
following filtering by cluster id.

Closes-bug: #1378963
Change-Id: Ib9f45225f6e3c91809ea0dbc47e79b3529b54d3b
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/98/134498/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/fuelclient/objects/nodegroup.py', 'fuelclient/fuelclient/objects/node.py']",2,6fb995425a7ad7a88883db9491576b9b49ae6541,bug/1378963," def filter_by_env_id(self, env_id, refresh=False): if refresh: predicate = lambda node: node.env_id == env_id else: predicate = lambda node: node.data['cluster'] == env_id self.collection = filter(predicate, self.collection)"," def filter_by_env_id(self, env_id): self.collection = filter( lambda node: node.env_id == env_id, self.collection )",14,10
openstack%2Fneutron~master~Ic961e4aae939be6a04e74b58227ae972723c1cba,openstack/neutron,master,Ic961e4aae939be6a04e74b58227ae972723c1cba,Allow user to create l3ha router,ABANDONED,2014-12-10 07:58:20.000000000,2014-12-10 10:38:17.000000000,,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10267}, {'_account_id': 10387}, {'_account_id': 14119}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-10 07:58:20.000000000', 'files': ['etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ba54e64161ae414cc55eb1274a752fc57c74841', 'message': 'Allow user to create l3ha router\n\nCurrently the policy.json prevents a regular user from creating an l3ha router.\nThis changes the permissions to match those of the regular create_router perms.\n\nChange-Id: Ic961e4aae939be6a04e74b58227ae972723c1cba\nCloses-Bug: #1401004\nRelated-Bug: #1388716\n'}]",0,140601,0ba54e64161ae414cc55eb1274a752fc57c74841,20,18,1,14119,,,0,"Allow user to create l3ha router

Currently the policy.json prevents a regular user from creating an l3ha router.
This changes the permissions to match those of the regular create_router perms.

Change-Id: Ic961e4aae939be6a04e74b58227ae972723c1cba
Closes-Bug: #1401004
Related-Bug: #1388716
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/140601/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/policy.json'],1,0ba54e64161ae414cc55eb1274a752fc57c74841,bug/1401004," ""create_router:ha"": ""rule:regular_user"", ""get_router:ha"": ""rule:admin_or_owner"", ""update_router:ha"": ""rule:admin_or_owner"","," ""get_router:ha"": ""rule:admin_only"", ""create_router:ha"": ""rule:admin_only"", ""update_router:ha"": ""rule:admin_only"",",3,3
openstack%2Fneutron~master~I050b4f494ccb3c810f2f7f6d75891d3f7b5cea29,openstack/neutron,master,I050b4f494ccb3c810f2f7f6d75891d3f7b5cea29,Allow user to create l3ha router,ABANDONED,2014-12-10 07:56:19.000000000,2014-12-10 10:25:10.000000000,,"[{'_account_id': 5170}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}]","[{'number': 1, 'created': '2014-12-10 07:56:19.000000000', 'files': ['etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6431ee883bc5d1e1ad6209634494bb1a146c657', 'message': 'Allow user to create l3ha router\n\nCurrently the policy.json prevents a regular user from creating an l3ha router.\nThis changes the permissions to match those of the regular create_router perms.\n\nChange-Id: I050b4f494ccb3c810f2f7f6d75891d3f7b5cea29\nRelated-Bug: #1388716\nCloses-Bug: #1401004\n'}]",0,140598,c6431ee883bc5d1e1ad6209634494bb1a146c657,10,8,1,14119,,,0,"Allow user to create l3ha router

Currently the policy.json prevents a regular user from creating an l3ha router.
This changes the permissions to match those of the regular create_router perms.

Change-Id: I050b4f494ccb3c810f2f7f6d75891d3f7b5cea29
Related-Bug: #1388716
Closes-Bug: #1401004
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/140598/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/policy.json'],1,c6431ee883bc5d1e1ad6209634494bb1a146c657,bug/1388716," ""create_router:ha"": ""rule:regular_user"", ""get_router:ha"": ""rule:admin_or_owner"", ""update_router:ha"": ""rule:admin_or_owner"","," ""get_router:ha"": ""rule:admin_only"", ""create_router:ha"": ""rule:admin_only"", ""update_router:ha"": ""rule:admin_only"",",3,3
openstack%2Fheat~master~I4e823206c3a88d27241532d9f393c07208af8b73,openstack/heat,master,I4e823206c3a88d27241532d9f393c07208af8b73,Use kwargs for ResourcePropertyConflict exception,MERGED,2014-11-27 13:42:12.000000000,2014-12-10 10:08:51.000000000,2014-12-10 10:08:50.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 7634}, {'_account_id': 8289}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-27 13:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c0e0f84aef69cc106cb4e7ad2b392ccf5b152273', 'message': 'Use kwargs for ResourcePropertyConflict exception\n\nCurrent approach works correct when error raised in heat-engine,\nbut when oslo-messaging try to send this error to heat-api it calls\nthis Exception again without any arguments. So it leads to empty output\nin message.\nThis patch adds kwargs properties for directly sending parameters to\nparent class and storing them for substitution during re-call in\noslo-messanging.\n\nChange-Id: I4e823206c3a88d27241532d9f393c07208af8b73\nCloses-Bug: #1397002\n'}, {'number': 2, 'created': '2014-12-04 07:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3be72fff97cb9a8ebeab9331b5bd38897f3934ab', 'message': 'Use kwargs for ResourcePropertyConflict exception\n\nCurrent approach works correct when error raised in heat-engine,\nbut when oslo-messaging try to send this error to heat-api it calls\nthis Exception again without any arguments. So it leads to empty output\nin message.\nThis patch adds kwargs properties for directly sending parameters to\nparent class and storing them for substitution during re-call in\noslo-messanging.\n\nChange-Id: I4e823206c3a88d27241532d9f393c07208af8b73\nCloses-Bug: #1397002\n'}, {'number': 3, 'created': '2014-12-10 07:24:04.000000000', 'files': ['heat/api/middleware/fault.py', 'heat/common/exception.py', 'heat/engine/resources/neutron/router.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a4ecd1ed33aad0f1ec8296be28fff69e2affcffe', 'message': 'Use kwargs for ResourcePropertyConflict exception\n\nCurrent approach works correct when error raised in heat-engine,\nbut when oslo-messaging try to send this error to heat-api it calls\nthis Exception again without any arguments. So it leads to empty output\nin message.\nThis patch adds kwargs properties for directly sending parameters to\nparent class and storing them for substitution during re-call in\noslo-messanging.\n\nChange-Id: I4e823206c3a88d27241532d9f393c07208af8b73\nCloses-Bug: #1397002\n'}]",3,137641,a4ecd1ed33aad0f1ec8296be28fff69e2affcffe,24,9,3,6577,,,0,"Use kwargs for ResourcePropertyConflict exception

Current approach works correct when error raised in heat-engine,
but when oslo-messaging try to send this error to heat-api it calls
this Exception again without any arguments. So it leads to empty output
in message.
This patch adds kwargs properties for directly sending parameters to
parent class and storing them for substitution during re-call in
oslo-messanging.

Change-Id: I4e823206c3a88d27241532d9f393c07208af8b73
Closes-Bug: #1397002
",git fetch https://review.opendev.org/openstack/heat refs/changes/41/137641/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/api/middleware/fault.py', 'heat/common/exception.py', 'heat/engine/resources/neutron/router.py']",3,c0e0f84aef69cc106cb4e7ad2b392ccf5b152273,bug/1397002, depr_subnet_key), subnet_key),8,5
openstack%2Fpython-ceilometerclient~master~I7e2ead688ac9fcab0ac6a2479e0eca12af415b07,openstack/python-ceilometerclient,master,I7e2ead688ac9fcab0ac6a2479e0eca12af415b07,sync with oslo and use oslo.i18n,MERGED,2014-10-07 18:01:40.000000000,2014-12-10 10:06:56.000000000,2014-12-10 10:06:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}]","[{'number': 1, 'created': '2014-10-07 18:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/313b6172c2d0a8b984f016eda6efc7425ba0956f', 'message': 'sync with oslo\n\n- remove openstack/common/strutils usage\n- start use of oslo.i18n\n\nsync to Change-Id: I6b720c462b8a562e3276f9e64d723bc36fb5c842\n\nChange-Id: I7e2ead688ac9fcab0ac6a2479e0eca12af415b07\n'}, {'number': 2, 'created': '2014-10-07 18:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/90c2a2c85477d8e9e60aa9f76781d513e8122fa1', 'message': 'sync with oslo\n\n- remove strutils and gettextutils from openstack/common\n- start use of oslo.i18n\n\nsync to Change-Id: I6b720c462b8a562e3276f9e64d723bc36fb5c842\n\nChange-Id: I7e2ead688ac9fcab0ac6a2479e0eca12af415b07\n'}, {'number': 3, 'created': '2014-10-07 18:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/ad265ddf590febfd9a3818f0cd6c3314ff5ef475', 'message': 'sync with oslo and use oslo.i18n\n\n- remove strutils and gettextutils from openstack/common\n- start use of oslo.i18n\n\nsync to Change-Id: I6b720c462b8a562e3276f9e64d723bc36fb5c842\n\nChange-Id: I7e2ead688ac9fcab0ac6a2479e0eca12af415b07\n'}, {'number': 4, 'created': '2014-11-14 09:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/462f54b9a8ccca2e6128608b3a852c8d03b95efa', 'message': 'sync with oslo and use oslo.i18n\n\n- remove strutils and gettextutils from openstack/common\n- start use of oslo.i18n\n\nsync to Change-Id: I6b720c462b8a562e3276f9e64d723bc36fb5c842\n\nChange-Id: I7e2ead688ac9fcab0ac6a2479e0eca12af415b07\n'}, {'number': 5, 'created': '2014-12-05 19:57:40.000000000', 'files': ['ceilometerclient/openstack/common/gettextutils.py', 'requirements.txt', 'ceilometerclient/openstack/common/apiclient/base.py', 'ceilometerclient/openstack/common/apiclient/client.py', 'ceilometerclient/openstack/common/apiclient/exceptions.py', 'ceilometerclient/openstack/common/_i18n.py', 'ceilometerclient/openstack/common/strutils.py', 'ceilometerclient/openstack/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/292e55073a94abd7a51487bfc5e9529c73143a0f', 'message': 'sync with oslo and use oslo.i18n\n\n- remove strutils and gettextutils from openstack/common\n- start use of oslo.i18n\n\nsync to Change-Id: Ia1820495a989f4f84530ab83f2d87d53a9f761df\n\nChange-Id: I7e2ead688ac9fcab0ac6a2479e0eca12af415b07\n'}]",3,126639,292e55073a94abd7a51487bfc5e9529c73143a0f,19,5,5,6537,,,0,"sync with oslo and use oslo.i18n

- remove strutils and gettextutils from openstack/common
- start use of oslo.i18n

sync to Change-Id: Ia1820495a989f4f84530ab83f2d87d53a9f761df

Change-Id: I7e2ead688ac9fcab0ac6a2479e0eca12af415b07
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/39/126639/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'ceilometerclient/openstack/common/apiclient/base.py', 'ceilometerclient/openstack/common/apiclient/client.py', 'ceilometerclient/openstack/common/apiclient/exceptions.py', 'ceilometerclient/openstack/common/_i18n.py', 'ceilometerclient/openstack/common/cliutils.py', 'ceilometerclient/openstack/common/strutils.py']",7,313b6172c2d0a8b984f016eda6efc7425ba0956f,i18n,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" System-level utilities and helper functions. """""" import re import sys import unicodedata import six from ceilometerclient.openstack.common.gettextutils import _ # Used for looking up extensions of text # to their 'multiplied' byte amount BYTE_MULTIPLIERS = { '': 1, 't': 1024 ** 4, 'g': 1024 ** 3, 'm': 1024 ** 2, 'k': 1024, } BYTE_REGEX = re.compile(r'(^-?\d+)(\D*)') TRUE_STRINGS = ('1', 't', 'true', 'on', 'y', 'yes') FALSE_STRINGS = ('0', 'f', 'false', 'off', 'n', 'no') SLUGIFY_STRIP_RE = re.compile(r""[^\w\s-]"") SLUGIFY_HYPHENATE_RE = re.compile(r""[-\s]+"") def int_from_bool_as_string(subject): """"""Interpret a string as a boolean and return either 1 or 0. Any string value in: ('True', 'true', 'On', 'on', '1') is interpreted as a boolean True. Useful for JSON-decoded stuff and config file parsing """""" return bool_from_string(subject) and 1 or 0 def bool_from_string(subject, strict=False): """"""Interpret a string as a boolean. A case-insensitive match is performed such that strings matching 't', 'true', 'on', 'y', 'yes', or '1' are considered True and, when `strict=False`, anything else is considered False. Useful for JSON-decoded stuff and config file parsing. If `strict=True`, unrecognized values, including None, will raise a ValueError which is useful when parsing values passed in from an API call. Strings yielding False are 'f', 'false', 'off', 'n', 'no', or '0'. """""" if not isinstance(subject, six.string_types): subject = str(subject) lowered = subject.strip().lower() if lowered in TRUE_STRINGS: return True elif lowered in FALSE_STRINGS: return False elif strict: acceptable = ', '.join( ""'%s'"" % s for s in sorted(TRUE_STRINGS + FALSE_STRINGS)) msg = _(""Unrecognized value '%(val)s', acceptable values are:"" "" %(acceptable)s"") % {'val': subject, 'acceptable': acceptable} raise ValueError(msg) else: return False def safe_decode(text, incoming=None, errors='strict'): """"""Decodes incoming str using `incoming` if they're not already unicode. :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a unicode `incoming` encoded representation of it. :raises TypeError: If text is not an instance of str """""" if not isinstance(text, six.string_types): raise TypeError(""%s can't be decoded"" % type(text)) if isinstance(text, six.text_type): return text if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) try: return text.decode(incoming, errors) except UnicodeDecodeError: # Note(flaper87) If we get here, it means that # sys.stdin.encoding / sys.getdefaultencoding # didn't return a suitable encoding to decode # text. This happens mostly when global LANG # var is not set correctly and there's no # default encoding. In this case, most likely # python will use ASCII or ANSI encoders as # default encodings but they won't be capable # of decoding non-ASCII characters. # # Also, UTF-8 is being used since it's an ASCII # extension. return text.decode('utf-8', errors) def safe_encode(text, incoming=None, encoding='utf-8', errors='strict'): """"""Encodes incoming str/unicode using `encoding`. If incoming is not specified, text is expected to be encoded with current python's default encoding. (`sys.getdefaultencoding`) :param incoming: Text's current encoding :param encoding: Expected encoding for text (Default UTF-8) :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: text or a bytestring `encoding` encoded representation of it. :raises TypeError: If text is not an instance of str """""" if not isinstance(text, six.string_types): raise TypeError(""%s can't be encoded"" % type(text)) if not incoming: incoming = (sys.stdin.encoding or sys.getdefaultencoding()) if isinstance(text, six.text_type): if six.PY3: return text.encode(encoding, errors).decode(incoming) else: return text.encode(encoding, errors) elif text and encoding != incoming: # Decode text before encoding it with `encoding` text = safe_decode(text, incoming, errors) if six.PY3: return text.encode(encoding, errors).decode(incoming) else: return text.encode(encoding, errors) return text def to_bytes(text, default=0): """"""Converts a string into an integer of bytes. Looks at the last characters of the text to determine what conversion is needed to turn the input text into a byte number. Supports ""B, K(B), M(B), G(B), and T(B)"". (case insensitive) :param text: String input for bytes size conversion. :param default: Default return value when text is blank. """""" match = BYTE_REGEX.search(text) if match: magnitude = int(match.group(1)) mult_key_org = match.group(2) if not mult_key_org: return magnitude elif text: msg = _('Invalid string format: %s') % text raise TypeError(msg) else: return default mult_key = mult_key_org.lower().replace('b', '', 1) multiplier = BYTE_MULTIPLIERS.get(mult_key) if multiplier is None: msg = _('Unknown byte multiplier: %s') % mult_key_org raise TypeError(msg) return magnitude * multiplier def to_slug(value, incoming=None, errors=""strict""): """"""Normalize string. Convert to lowercase, remove non-word characters, and convert spaces to hyphens. Inspired by Django's `slugify` filter. :param value: Text to slugify :param incoming: Text's current encoding :param errors: Errors handling policy. See here for valid values http://docs.python.org/2/library/codecs.html :returns: slugified unicode representation of `value` :raises TypeError: If text is not an instance of str """""" value = safe_decode(value, incoming, errors) # NOTE(aababilov): no need to use safe_(encode|decode) here: # encodings are always ""ascii"", error handling is always ""ignore"" # and types are always known (first: unicode; second: str) value = unicodedata.normalize(""NFKD"", value).encode( ""ascii"", ""ignore"").decode(""ascii"") value = SLUGIFY_STRIP_RE.sub("""", value).strip().lower() return SLUGIFY_HYPHENATE_RE.sub(""-"", value) ",55,235
openstack%2Fcongress-specs~master~I0516a99f117c5eeb76431337cc3872c94b1fb460,openstack/congress-specs,master,I0516a99f117c5eeb76431337cc3872c94b1fb460,Fix capitalization in subtitles,MERGED,2014-12-10 09:05:24.000000000,2014-12-10 09:53:48.000000000,2014-12-10 09:53:48.000000000,"[{'_account_id': 3}, {'_account_id': 4395}]","[{'number': 1, 'created': '2014-12-10 09:05:24.000000000', 'files': ['specs/kilo/add-extract-fn-to-all-translators.rst', 'specs/kilo/support-python3.rst', 'specs/kilo/heat-datasource-driver.rst', 'specs/kilo/swift-datasource-driver.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/673ffb03312575ee025d1ce995e38ef4bff6201b', 'message': 'Fix capitalization in subtitles\n\nChange-Id: I0516a99f117c5eeb76431337cc3872c94b1fb460\n'}]",0,140615,673ffb03312575ee025d1ce995e38ef4bff6201b,6,2,1,7187,,,0,"Fix capitalization in subtitles

Change-Id: I0516a99f117c5eeb76431337cc3872c94b1fb460
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/15/140615/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/kilo/add-extract-fn-to-all-translators.rst', 'specs/kilo/heat-datasource-driver.rst', 'specs/kilo/support-python3.rst', 'specs/kilo/swift-datasource-driver.rst']",4,673ffb03312575ee025d1ce995e38ef4bff6201b,,Policy actionsData sourcesPerformance impactOther deployer impact ---------------------Developer impactWork itemsDocumentation impact,Policy ActionsData SourcesPerformance ImpactOther Deployer Impacts ----------------------Developer ImpactWork ItemsDocumentation Impact,37,37
openstack%2Fmistral~master~I1b08ed28196ff473a7cef47dea058401629979d1,openstack/mistral,master,I1b08ed28196ff473a7cef47dea058401629979d1,"Working on ""join"": making ""one"" join value work (discriminator)",MERGED,2014-12-09 07:17:18.000000000,2014-12-10 09:49:48.000000000,2014-12-10 09:49:48.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-09 07:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/da20dfe9d5bd23fd7287102ef24f0b1468cd2b34', 'message': 'Working on ""join"": making ""one"" join value work (discriminator)\n\nChange-Id: I1b08ed28196ff473a7cef47dea058401629979d1\n'}, {'number': 2, 'created': '2014-12-09 08:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1f59a2a64d4c0237b74253d204c349b058ad32c2', 'message': 'Working on ""join"": making ""one"" join value work (discriminator)\n\nChange-Id: I1b08ed28196ff473a7cef47dea058401629979d1\n'}, {'number': 3, 'created': '2014-12-09 11:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/747b6216b215bf4d8911947dca1a52ea09bed818', 'message': 'Working on ""join"": making ""one"" join value work (discriminator)\n\nChange-Id: I1b08ed28196ff473a7cef47dea058401629979d1\n'}, {'number': 4, 'created': '2014-12-09 12:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5ffed5230ac58c019214243cc899d2ac1190ba32', 'message': 'Working on ""join"": making ""one"" join value work (discriminator)\n\nChange-Id: I1b08ed28196ff473a7cef47dea058401629979d1\n'}, {'number': 5, 'created': '2014-12-10 09:24:17.000000000', 'files': ['mistral/tests/unit/engine1/test_join.py', 'mistral/workflow/direct_workflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/9826579c7dcf3868761a256debc263b2db36c287', 'message': 'Working on ""join"": making ""one"" join value work (discriminator)\n\nChange-Id: I1b08ed28196ff473a7cef47dea058401629979d1\n'}]",0,140256,9826579c7dcf3868761a256debc263b2db36c287,20,5,5,8731,,,0,"Working on ""join"": making ""one"" join value work (discriminator)

Change-Id: I1b08ed28196ff473a7cef47dea058401629979d1
",git fetch https://review.opendev.org/openstack/mistral refs/changes/56/140256/5 && git format-patch -1 --stdout FETCH_HEAD,['mistral/tests/unit/engine1/test_join.py'],1,da20dfe9d5bd23fd7287102ef24f0b1468cd2b34,bug/1395679,"WF_DISCRIMINATOR = """""" --- version: 2.0 wf: type: direct output: result: $.result4 tasks: task1: action: std.noop publish: result1: 1 on-complete: - task4 task2: action: std.noop publish: result2: 2 on-complete: - task4 task3: action: std.noop publish: result3: 3 on-complete: - task4 task4: join: one action: std.echo output=""{$.result1},{$.result2},{$.result3}"" publish: result4: $ """""" def test_discriminator(self): wf_service.create_workflows(WF_DISCRIMINATOR) # Start workflow. exec_db = self.engine.start_workflow('wf', {}) self._await(lambda: self.is_execution_success(exec_db.id)) # Note: We need to reread execution to access related tasks. exec_db = db_api.get_execution(exec_db.id) tasks = exec_db.tasks self.assertEqual(4, len(tasks)) task1 = self._assert_single_item(tasks, name='task1') task2 = self._assert_single_item(tasks, name='task2') task3 = self._assert_single_item(tasks, name='task3') task4 = self._assert_single_item(tasks, name='task4') self.assertEqual(states.SUCCESS, task1.state) self.assertEqual(states.SUCCESS, task2.state) self.assertEqual(states.SUCCESS, task3.state) self.assertEqual(states.SUCCESS, task4.state) result4 = task4.output['result4'] print result4 self.assertIsNotNone(result4) self.assertEqual(2, result4.count('None'))",,70,0
openstack%2Fmistral~master~I8508b62337f2aa3624eae0d385a801286abdf7b6,openstack/mistral,master,I8508b62337f2aa3624eae0d385a801286abdf7b6,"Working on ""join"": allowed value ""one"" for ""join"" property",MERGED,2014-12-09 06:20:52.000000000,2014-12-10 09:49:42.000000000,2014-12-10 09:49:41.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-09 06:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d283314ac30d77013f3684de533a5f5c19157f53', 'message': 'Working on ""join"": allowed value ""one"" for ""join"" property\n\n* Refactored task specification\n* Fixed unit test for task specification\n\nChange-Id: I8508b62337f2aa3624eae0d385a801286abdf7b6\n'}, {'number': 2, 'created': '2014-12-09 07:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e7b93abba683a8a2ee35d8f4cdb4753a1d6bdb4d', 'message': 'Working on ""join"": allowed value ""one"" for ""join"" property\n\n* Refactored task specification\n* Fixed unit test for task specification\n\nChange-Id: I8508b62337f2aa3624eae0d385a801286abdf7b6\n'}, {'number': 3, 'created': '2014-12-09 11:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/709cfbe059f7fc78e1cd21988a60dfbaf06e75c6', 'message': 'Working on ""join"": allowed value ""one"" for ""join"" property\n\n* Refactored task specification\n* Fixed unit test for task specification\n\nChange-Id: I8508b62337f2aa3624eae0d385a801286abdf7b6\n'}, {'number': 4, 'created': '2014-12-09 12:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/534200c303dc851208534dfaaad53185300489ae', 'message': 'Working on ""join"": allowed value ""one"" for ""join"" property\n\n* Refactored task specification\n* Fixed unit test for task specification\n\nChange-Id: I8508b62337f2aa3624eae0d385a801286abdf7b6\n'}, {'number': 5, 'created': '2014-12-10 09:23:36.000000000', 'files': ['mistral/workbook/v2/tasks.py', 'mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/c23699836329da5dd63c727ca4291e84fb433cc4', 'message': 'Working on ""join"": allowed value ""one"" for ""join"" property\n\n* Refactored task specification\n* Fixed unit test for task specification\n\nChange-Id: I8508b62337f2aa3624eae0d385a801286abdf7b6\n'}]",6,140251,c23699836329da5dd63c727ca4291e84fb433cc4,27,5,5,8731,,,0,"Working on ""join"": allowed value ""one"" for ""join"" property

* Refactored task specification
* Fixed unit test for task specification

Change-Id: I8508b62337f2aa3624eae0d385a801286abdf7b6
",git fetch https://review.opendev.org/openstack/mistral refs/changes/51/140251/3 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workbook/v2/tasks.py', 'mistral/tests/unit/workbook/v2/test_dsl_specs_v2.py']",2,d283314ac30d77013f3684de533a5f5c19157f53,bug/1395679," task11: join: one action: std.echo output=""Task 11 echo"" self.assertEqual(9, len(wf2_spec.get_tasks())) task11_spec = wf2_spec.get_tasks().get('task11') self.assertEqual('one', task11_spec.get_join()) "," self.assertEqual(8, len(wf2_spec.get_tasks()))",35,15
openstack%2Fsahara~master~I07485c286a501bff52f8c67ffd0cc841814a5c9c,openstack/sahara,master,I07485c286a501bff52f8c67ffd0cc841814a5c9c,Open all ports for private network for auto SG,MERGED,2014-11-20 18:15:48.000000000,2014-12-10 09:43:52.000000000,2014-12-02 11:34:24.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 12039}, {'_account_id': 13662}, {'_account_id': 13670}]","[{'number': 1, 'created': '2014-11-20 18:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/68c5dcaddaadc674e5ea9c82dab990354714fef3', 'message': '[WIP] Open all ports for private network for auto SG\n\nChange-Id: I07485c286a501bff52f8c67ffd0cc841814a5c9c\n'}, {'number': 2, 'created': '2014-11-21 13:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/13def46fe168f21e104399a668c878b2826dbdd7', 'message': 'Open all ports for private network for auto SG\n\nCloses-bug: #1394988\n\nChange-Id: I07485c286a501bff52f8c67ffd0cc841814a5c9c\n'}, {'number': 3, 'created': '2014-12-01 15:15:42.000000000', 'files': ['sahara/utils/openstack/heat.py', 'sahara/utils/openstack/neutron.py', 'sahara/service/direct_engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7c4ea57548c34a84996ba36fbdf6d63b17bf6cf3', 'message': 'Open all ports for private network for auto SG\n\nCloses-bug: #1394988\n\nChange-Id: I07485c286a501bff52f8c67ffd0cc841814a5c9c\n'}]",4,136083,7c4ea57548c34a84996ba36fbdf6d63b17bf6cf3,68,11,3,7710,,,0,"Open all ports for private network for auto SG

Closes-bug: #1394988

Change-Id: I07485c286a501bff52f8c67ffd0cc841814a5c9c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/83/136083/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/utils/openstack/heat.py', 'sahara/utils/openstack/neutron.py', 'sahara/service/direct_engine.py']",3,68c5dcaddaadc674e5ea9c82dab990354714fef3,bug/1394988,"from sahara.utils.openstack import neutron # open all traffic for private networks if CONF.use_neutron: for cidr in neutron.get_private_network_cidrs(node_group.cluster): for protocol in ['tcp', 'udp']: nova_client.security_group_rules.create( security_group.id, protocol, 1, 65535, cidr) nova_client.security_group_rules.create( security_group.id, 'icmp', -1, 255, cidr) ",,39,4
openstack%2Fhorizon~master~Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49,openstack/horizon,master,Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49,Fixed issue of progress bars in resize instance,MERGED,2014-08-26 23:49:31.000000000,2014-12-10 09:33:23.000000000,2014-12-10 09:33:22.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6825}, {'_account_id': 8871}, {'_account_id': 9382}, {'_account_id': 9576}, {'_account_id': 10295}, {'_account_id': 11880}, {'_account_id': 11881}, {'_account_id': 11941}, {'_account_id': 11973}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-08-26 23:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13c97a45a853e7b2dd6e89c0838955002a081776', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress bars:\n1.it adds 1 instance even there is no new instance to add\n2.it adds the vcpu of the selected flavor when it should use\nthe difference between the old flavor and new flavor\n3. it adds the ram of the selected flavor when it should use\nthe difference of the old flavor and new flavor\n4. when select no falvor, the flavor detail doesn't get updated\n\nadded logics to deal with flavor quota for instance_resize:\n\n1. set a flag resize_instance in resize_instance.py when it passes\ncontext back to _flavors_and_quotas.html\n2. seperate the the instance progress bars with different ids based\non the resize_instance flag\n3. updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram\n4. instance update_amount is always 0 for resize instance case\n5. when nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 2, 'created': '2014-08-27 01:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d0718b44db80ad8ba286c5bc34e645c77fdba67d', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress bars:\n1.it adds 1 instance even there is no new instance to add\n2.it adds the vcpu of the selected flavor when it should use\nthe difference between the old flavor and new flavor\n3. it adds the ram of the selected flavor when it should use\nthe difference of the old flavor and new flavor\n4. when select no falvor, the flavor detail doesn't get updated\n\nadded logics to deal with flavor quota for instance_resize:\n\n1. set a flag resize_instance in resize_instance.py when it passes\ncontext back to _flavors_and_quotas.html\n2. seperate the the instance progress bars with different ids based\non the resize_instance flag\n3. updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram\n4. instance update_amount is always 0 for resize instance case\n5. when nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 3, 'created': '2014-08-27 01:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f7fda4f99a3ae1e798cadb49803f0e3335ce77c5', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress bars:\n1.it adds 1 instance even there is no new instance to add\n2.it adds the vcpu of the selected flavor when it should use\nthe difference between the old flavor and new flavor\n3. it adds the ram of the selected flavor when it should use\nthe difference of the old flavor and new flavor\n4. when select no falvor, the flavor detail doesn't get updated\n\nadded logics to deal with flavor quota for instance_resize:\n\n1. set a flag resize_instance in resize_instance.py when it passes\ncontext back to _flavors_and_quotas.html\n2. seperate the the instance progress bars with different ids based\non the resize_instance flag\n3. updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram\n4. instance update_amount is always 0 for resize instance case\n5. when nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 4, 'created': '2014-08-27 20:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fdca027a13aa6a2051b34f5ecf53c44ab734b597', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 5, 'created': '2014-09-05 19:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e0a05ed1b90a4889ac5dc350a667cb0470e3a148', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change. The default\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 6, 'created': '2014-09-05 19:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/24126bc03256275a6b1869db726f847622b4ad59', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change. The default\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 7, 'created': '2014-09-16 00:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/69968fcc90d162121dc5a6114337b56c40006019', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 8, 'created': '2014-09-19 00:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b75297f7900fab7bbc826f9512a9eb48458ec605', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 9, 'created': '2014-09-23 00:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e48e48f196c2edd5d4493834ee76e8bdbf9e1bb7', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 10, 'created': '2014-09-24 18:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a565213f3c5c5283d62d5404dca1c27d7ed9bbe5', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 11, 'created': '2014-10-01 17:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ab0d3e8b7db9accbae279641921674daf9f9a4cf', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 12, 'created': '2014-10-06 16:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c2d399dfd1f3ddc1fa40f841910cbeb27f902482', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 13, 'created': '2014-10-06 21:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/39eca88fda9bea462d81047138a8c5c69254a373', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 14, 'created': '2014-10-07 18:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/587968633b4d42f2d441e842caff38e64638e014', 'message': 'Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn\'t get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n6. The ""Flavor Details"" at the right size is called ""New Flavor Details""\nto make it more clear.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n'}, {'number': 15, 'created': '2014-10-09 00:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/026e7848ca9fd9d64eadbc5a8be4864d7fa463eb', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 16, 'created': '2014-10-09 00:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f21b47b020a1bc07e3b486481e90e50d28e9f50', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 17, 'created': '2014-10-09 17:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/30a5eb051c9cdb504e964473bb6ba0b1cf8a08fe', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 18, 'created': '2014-10-14 21:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0e2cc8301d8029ab74b1ec6b34c34cb7e604362e', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 19, 'created': '2014-10-20 20:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e68e9b5f25f1708497602abecefd4bc837881102', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 20, 'created': '2014-10-29 21:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e64cc2767fd0122c548174aed423dfd06a540c8c', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nNote: if user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 21, 'created': '2014-10-31 21:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/75fe38671d202f239aea6ffec9f7f986cf0f423e', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 22, 'created': '2014-11-12 02:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1791f54602cd3316f90c3db30512f1c91040697b', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 23, 'created': '2014-11-14 19:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8c2d6c95ff9c33ec1fbf06b7dbf15de4eba97994', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 24, 'created': '2014-11-20 00:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6cdd724d2e93c48bf32e42ffb37a08c369940660', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 25, 'created': '2014-12-01 23:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f0f389ec124cc492c764d185a14fc734a112f132', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 26, 'created': '2014-12-08 22:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aab48e261171ad6a46c804fab1282f6f1ba8cb3f', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 27, 'created': '2014-12-09 01:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/47b7d0a4fa40a4fb34f12482127315d7bfd8abbc', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 28, 'created': '2014-12-09 19:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4c50ad7c7f5f0337a83fd8af6f0278785c1ee755', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 29, 'created': '2014-12-09 22:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/409eac37d97906d84dd055ff2665cb5963ef294c', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 30, 'created': '2014-12-10 00:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/90945955c36ca6877b493c50505547b36ed58b90', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}, {'number': 31, 'created': '2014-12-10 03:20:00.000000000', 'files': ['horizon/static/horizon/js/horizon.quota.js', 'openstack_dashboard/dashboards/project/instances/workflows/resize_instance.py', 'openstack_dashboard/dashboards/project/instances/templates/instances/_flavors_and_quotas.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d433b9157672e3854d9e5cf2996da819320096d9', 'message': ""Fixed issue of progress bars in resize instance\n\nWhen user resizes instance there are 4 issues for the progress\n(graphic) bars:\n\n1.It adds 1 instance even there is no new instance to add.\n2.It adds the vcpu of the selected flavor when it should have\nused the difference between the old flavor and new flavor.\n3. It adds the ram of the selected flavor when it should have\nused the difference of the old flavor and new flavor.\n4. When select no falvor, the new flavor detail doesn't get updated.\n\nAdded logics to deal with flavor quota for instance_resize:\n\n1. Set a flag resize_instance in resize_instance.py where it passes\nthe context back to _flavors_and_quotas.html.\n2. Seperate the instance progress bars using different ids based\non the resize_instance flag.\n3. Updated horizon.quota.js to capture the old_flavor. When old_flavor\nand selected_flavor are both available, use the difference to caculate\nthe update_amount for vcpu and ram.\n4. Instance update_amount is always 0 for resize instance case.\n5. When nothing selected in flavor choice, update the flavor detail to\nreflect that.\n\nWhat to expect now:\n\nWhen change to the flavor of size bigger, the instance bar should not\nchange. The vCPU bar will be updated based on the new flavor. The RAM\nbar will be updated based on the new flavor.\n\nWhen change to the same flavor, the progress bars should not be updated.\n\nWhen user tries to resize to be smaller size, the progress bars\nwill not change.\n\nCloses-Bug: #1288954\nChange-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49\n""}]",35,117053,d433b9157672e3854d9e5cf2996da819320096d9,132,13,31,11880,,,0,"Fixed issue of progress bars in resize instance

When user resizes instance there are 4 issues for the progress
(graphic) bars:

1.It adds 1 instance even there is no new instance to add.
2.It adds the vcpu of the selected flavor when it should have
used the difference between the old flavor and new flavor.
3. It adds the ram of the selected flavor when it should have
used the difference of the old flavor and new flavor.
4. When select no falvor, the new flavor detail doesn't get updated.

Added logics to deal with flavor quota for instance_resize:

1. Set a flag resize_instance in resize_instance.py where it passes
the context back to _flavors_and_quotas.html.
2. Seperate the instance progress bars using different ids based
on the resize_instance flag.
3. Updated horizon.quota.js to capture the old_flavor. When old_flavor
and selected_flavor are both available, use the difference to caculate
the update_amount for vcpu and ram.
4. Instance update_amount is always 0 for resize instance case.
5. When nothing selected in flavor choice, update the flavor detail to
reflect that.

What to expect now:

When change to the flavor of size bigger, the instance bar should not
change. The vCPU bar will be updated based on the new flavor. The RAM
bar will be updated based on the new flavor.

When change to the same flavor, the progress bars should not be updated.

When user tries to resize to be smaller size, the progress bars
will not change.

Closes-Bug: #1288954
Change-Id: Ie5bb47a4ea416864ed88b80b1c1c539c76f4bc49
",git fetch https://review.opendev.org/openstack/horizon refs/changes/53/117053/27 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.quota.js', 'openstack_dashboard/dashboards/project/instances/workflows/resize_instance.py', 'openstack_dashboard/dashboards/project/instances/templates/instances/_flavors_and_quotas.html']",3,13c97a45a853e7b2dd6e89c0838955002a081776,bug/1288954," {% if resize_instance %} <div id=""quota_resize_instance"" class=""quota_bar"" data-progress-indicator-flavor data-quota-limit=""{{ usages.maxTotalInstances }}"" data-quota-used=""{{usages.totalInstancesUsed}}""> </div> {% else %} <div id=""quota_instances"" class=""quota_bar"" data-progress-indicator-flavor data-quota-limit=""{{ usages.maxTotalInstances }}"" data-quota-used=""{{usages.totalInstancesUsed}}""> </div> {% endif %}"," <div id=""quota_instances"" class=""quota_bar"" data-progress-indicator-flavor data-quota-limit=""{{ usages.maxTotalInstances }}"" data-quota-used=""{{ usages.totalInstancesUsed }}""> </div>",50,5
openstack%2Fmistral~master~I1859742cabaa404e25354c036e555109e045c8da,openstack/mistral,master,I1859742cabaa404e25354c036e555109e045c8da,Add docs on task-affinity and configuring MySQL,MERGED,2014-12-08 14:15:14.000000000,2014-12-10 09:29:03.000000000,2014-12-10 09:29:03.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}]","[{'number': 1, 'created': '2014-12-08 14:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/cd53bf87cea4d4c5da942f730d147777ff34e1ae', 'message': 'Add docs on task-affinity\n\nPartially implements blueprint mistral-install-docs\n\nChange-Id: I1859742cabaa404e25354c036e555109e045c8da\n'}, {'number': 2, 'created': '2014-12-08 14:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c6fa07657d188753f93c9f8cb1da158380752bac', 'message': 'Add docs on task-affinity and configuring MySQL\n\nPartially implements blueprint mistral-install-docs\n\nChange-Id: I1859742cabaa404e25354c036e555109e045c8da\n'}, {'number': 3, 'created': '2014-12-08 14:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/04fa1e9ca3e146f5fb60174bb2d3451b12f3003b', 'message': 'Add docs on task-affinity and configuring MySQL\n\nPartially implements blueprint mistral-install-docs\n\nChange-Id: I1859742cabaa404e25354c036e555109e045c8da\n'}, {'number': 4, 'created': '2014-12-09 10:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/87700801c7ee07ffc0abbb9e11a95f67ae8ca214', 'message': 'Add docs on task-affinity and configuring MySQL\n\nPartially implements blueprint mistral-install-docs\n\nChange-Id: I1859742cabaa404e25354c036e555109e045c8da\n'}, {'number': 5, 'created': '2014-12-09 11:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/965fac67bf668bf89b4a1bf335bc330a66992970', 'message': 'Add docs on task-affinity and configuring MySQL\n\nPartially implements blueprint mistral-install-docs\n\nChange-Id: I1859742cabaa404e25354c036e555109e045c8da\n'}, {'number': 6, 'created': '2014-12-09 12:21:38.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/mistral/commit/1b1353ecc8add2927a76d98c2dbd2caa7eb8641d', 'message': 'Add docs on task-affinity and configuring MySQL\n\nPartially implements blueprint mistral-install-docs\n\nChange-Id: I1859742cabaa404e25354c036e555109e045c8da\n'}]",13,140012,1b1353ecc8add2927a76d98c2dbd2caa7eb8641d,23,4,6,7700,,,0,"Add docs on task-affinity and configuring MySQL

Partially implements blueprint mistral-install-docs

Change-Id: I1859742cabaa404e25354c036e555109e045c8da
",git fetch https://review.opendev.org/openstack/mistral refs/changes/12/140012/6 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cd53bf87cea4d4c5da942f730d147777ff34e1ae,bp/mistral-install-docs,"If it is needed to run some tasks on specific executor then feature *task-affinity* can be used to send these tasks directly on this executor. In config-file, edit section ""executor"", *host* property: [executor] host = my_favorite_executor Then start (restart) executor. Use *targets* task property to specify this executor: ... Workflow YAML ... task1: ... targets: [my_favorite_executor] ... Workflow YAML ... ",,13,0
openstack%2Fironic-inspector~master~Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885,openstack/ironic-inspector,master,Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885,Refactoring: split test.py and rewrite tests for process,MERGED,2014-12-09 14:16:11.000000000,2014-12-10 09:22:07.000000000,2014-12-10 09:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-09 14:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/872914ba8bd0871e8d35adf87010ec589ec9746e', 'message': 'Refactoring: split test.py\n\nTo simplify migration, prevent Python from writing bytecode\nduring testing.\n\nChange-Id: Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885\n'}, {'number': 2, 'created': '2014-12-09 14:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/dc2424b1adec8d7510bb5eebdfd7793d6a359370', 'message': 'Refactoring: split test.py\n\nTo simplify migration, prevent Python from writing bytecode\nduring testing.\n\nChange-Id: Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885\n'}, {'number': 3, 'created': '2014-12-09 14:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/672f8adcd436d387dbe6fc3101efd30f5799388d', 'message': 'Refactoring: split test.py\n\nMoved one function from utils that does not belong there.\n\nTo simplify migration, prevent Python from writing bytecode\nduring testing.\n\nChange-Id: Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885\n'}, {'number': 4, 'created': '2014-12-09 19:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ebd44e72cd18d6e88ee9c4914029fb128c1e6b20', 'message': ""Refactoring: split test.py and rewrite tests for process\n\nTests for process.py completely rewritten to be more 'unit'.\n\nMoved one function from utils that does not belong there\nand fixed small issues uncovered by the new tests.\n\nTo simplify migration, prevent Python from writing bytecode\nduring testing.\n\nChange-Id: Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885\n""}, {'number': 5, 'created': '2014-12-09 19:51:46.000000000', 'files': ['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/test/test_client.py', 'ironic_discoverd/plugins/standard.py', 'ironic_discoverd/utils.py', 'ironic_discoverd/test/test_node_cache.py', 'ironic_discoverd/test/test_process.py', 'ironic_discoverd/test.py', 'ironic_discoverd/test/test_main.py', 'ironic_discoverd/test/__init__.py', 'ironic_discoverd/main.py', 'ironic_discoverd/test/base.py', 'tox.ini', 'ironic_discoverd/node_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c211e9c1b5b547cfbe2553e5dace40ab21141a02', 'message': ""Refactoring: split test.py and rewrite tests for process\n\nTests for process.py completely rewritten to be more 'unit'.\n\nMoved one function from utils that does not belong there\nand fixed small issues uncovered by the new tests.\n\nTo simplify migration, prevent Python from writing bytecode\nduring testing.\n\nChange-Id: Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885\n""}]",0,140339,c211e9c1b5b547cfbe2553e5dace40ab21141a02,12,2,5,10239,,,0,"Refactoring: split test.py and rewrite tests for process

Tests for process.py completely rewritten to be more 'unit'.

Moved one function from utils that does not belong there
and fixed small issues uncovered by the new tests.

To simplify migration, prevent Python from writing bytecode
during testing.

Change-Id: Ie2c5d9217982620ba62f8105cf8e4b2cfaefe885
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/39/140339/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test.py', 'ironic_discoverd/test/test_discover.py', 'ironic_discoverd/test/test_client.py', 'ironic_discoverd/test/test_main.py', 'ironic_discoverd/test/__init__.py', 'ironic_discoverd/test/base.py', 'tox.ini', 'ironic_discoverd/test/test_node_cache.py', 'ironic_discoverd/test/test_process.py']",9,872914ba8bd0871e8d35adf87010ec589ec9746e,refactoring,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import time import eventlet from ironicclient import exceptions import mock from ironic_discoverd import conf from ironic_discoverd import firewall from ironic_discoverd import node_cache from ironic_discoverd.plugins import example as example_plugin from ironic_discoverd import process from ironic_discoverd.test import base as test_base from ironic_discoverd import utils @mock.patch.object(eventlet.greenthread, 'spawn_n', lambda f, *a: f(*a) and None) @mock.patch.object(eventlet.greenthread, 'sleep', lambda _: None) @mock.patch.object(example_plugin.ExampleProcessingHook, 'post_discover') @mock.patch.object(example_plugin.ExampleProcessingHook, 'pre_discover') @mock.patch.object(firewall, 'update_filters', autospec=True) @mock.patch.object(node_cache, 'pop_node', autospec=True) @mock.patch.object(utils, 'get_client', autospec=True) class TestProcess(test_base.NodeTest): def setUp(self): super(TestProcess, self).setUp() self.node2 = mock.Mock(driver_info={'ipmi_address': '1.2.3.4'}, properties={'cpu_arch': 'i386', 'local_gb': 40}, uuid='uuid', power_state='power off', extra={'on_discovery': 'true'}) self.patch1 = [ {'op': 'add', 'path': '/properties/cpus', 'value': '2'}, {'op': 'add', 'path': '/properties/memory_mb', 'value': '1024'}, ] self.patch2 = [ {'op': 'add', 'path': '/extra/newly_discovered', 'value': 'true'}, {'op': 'remove', 'path': '/extra/on_discovery'}, ] self.data = { 'ipmi_address': '1.2.3.4', 'cpus': 2, 'cpu_arch': 'x86_64', 'memory_mb': 1024, 'local_gb': 20, 'interfaces': { 'em1': {'mac': '11:22:33:44:55:66', 'ip': '1.2.3.4'}, 'em2': {'mac': 'broken', 'ip': '1.2.3.4'}, 'em3': {'mac': '', 'ip': '1.2.3.4'}, 'em4': {'mac': '66:55:44:33:22:11', 'ip': '1.2.3.4'}, 'em5': {'mac': '66:55:44:33:22:11'}, } } self.macs = ['11:22:33:44:55:66', 'broken', '', '66:55:44:33:22:11'] self.port = mock.Mock(uuid='port_uuid') self.attributes = dict(bmc_address='1.2.3.4', mac=mock.ANY) self.good_macs = ['11:22:33:44:55:66', '66:55:44:33:22:11'] self.good_interfaces = ['em1', 'em4'] def _do_test(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): conf.CONF.set('discoverd', 'processing_hooks', 'ramdisk_error,scheduler,validate_interfaces,example') cli = client_mock.return_value def fake_port_create(node_uuid, address): if address == self.good_macs[0]: return self.port else: raise exceptions.Conflict() cli.port.create.side_effect = fake_port_create pop_mock.return_value = node_cache.NodeInfo(uuid=self.node.uuid, started_at=time.time()) cli.node.get.side_effect = [self.node] * 5 + [self.node2] post_mock.return_value = (['fake patch', 'fake patch 2'], {self.good_macs[0]: ['port patch']}) self.node.to_dict.return_value = self.data cli.node.update.return_value = self.node res = process.process(self.data) self.assertEqual({'node': self.data}, res) pop_mock.assert_called_once_with(**self.attributes) cli.node.get.assert_called_with(self.node.uuid) self.assertEqual(6, cli.node.get.call_count) self.assertEqual(self.good_macs, sorted(pop_mock.call_args[1]['mac'])) cli.node.update.assert_any_call(self.node.uuid, self.patch1 + ['fake patch', 'fake patch 2']) cli.node.update.assert_any_call(self.node.uuid, self.patch2) self.assertEqual(2, cli.node.update.call_count) cli.port.create.assert_any_call(node_uuid=self.node.uuid, address=self.good_macs[0]) cli.port.create.assert_any_call(node_uuid=self.node.uuid, address=self.good_macs[1]) self.assertEqual(2, cli.port.create.call_count) filters_mock.assert_called_once_with(cli) cli.port.update.assert_called_once_with(self.port.uuid, ['port patch']) pre_mock.assert_called_once_with(self.data) post_mock.assert_called_once_with(self.node, [self.port], self.data) self.assertEqual(self.good_macs, sorted(self.data['macs'])) self.assertEqual(self.good_interfaces, sorted(self.data['interfaces'])) def test_ok(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): self._do_test(client_mock, pop_mock, filters_mock, pre_mock, post_mock) self.assertFalse(client_mock.return_value.node.set_power_state.called) @mock.patch.object(time, 'time') def test_power_timeout(self, time_mock, client_mock, pop_mock, filters_mock, pre_mock, post_mock): cli = client_mock.return_value conf.CONF.set('discoverd', 'timeout', '3600') time_mock.return_value = 10000 pop_mock.return_value = node_cache.NodeInfo(uuid=self.node.uuid, started_at=1000) cli.node.get.return_value = self.node process.process(self.data) cli.node.update.assert_called_once_with(self.node.uuid, self.patch1) def test_power_failure(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): conf.CONF.set('discoverd', 'power_off_after_discovery', 'true') client_mock.return_value.node.set_power_state.side_effect = ( exceptions.Conflict()) self.assertRaisesRegexp(utils.DiscoveryFailed, 'Failed to power off', self._do_test, client_mock, pop_mock, filters_mock, pre_mock, post_mock) def test_no_ipmi(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): del self.data['ipmi_address'] self.attributes = dict(bmc_address=None, mac=mock.ANY) self._do_test(client_mock, pop_mock, filters_mock, pre_mock, post_mock) self.assertFalse(client_mock.return_value.node.set_power_state.called) def test_force_off(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): conf.CONF.set('discoverd', 'power_off_after_discovery', 'true') self._do_test(client_mock, pop_mock, filters_mock, pre_mock, post_mock) client_mock.return_value.node.set_power_state.assert_called_once_with( self.node.uuid, 'off') def test_deprecated_macs(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): del self.data['interfaces'] self.data['macs'] = self.macs self.good_interfaces = ['dummy0', 'dummy3'] self._do_test(client_mock, pop_mock, filters_mock, pre_mock, post_mock) def test_ports_for_inactive(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): del self.data['interfaces']['em4'] conf.CONF.set('discoverd', 'ports_for_inactive_interfaces', 'true') self.good_interfaces = ['em1', 'em5'] self._do_test(client_mock, pop_mock, filters_mock, pre_mock, post_mock) def test_not_found(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): cli = client_mock.return_value pop_mock.side_effect = utils.DiscoveryFailed('boom') self.assertRaisesRegexp(utils.DiscoveryFailed, 'boom', process.process, self.data) self.assertFalse(cli.node.update.called) self.assertFalse(cli.port.create.called) self.assertFalse(cli.node.set_power_state.called) def test_not_found_in_ironic(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): cli = client_mock.return_value pop_mock.return_value = node_cache.NodeInfo(uuid=self.node.uuid, started_at=time.time()) cli.node.get.side_effect = exceptions.NotFound() self.assertRaisesRegexp(utils.DiscoveryFailed, 'not found in Ironic', process.process, self.data) cli.node.get.assert_called_once_with(self.node.uuid) self.assertFalse(cli.node.update.called) self.assertFalse(cli.port.create.called) self.assertFalse(cli.node.set_power_state.called) def test_error(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): conf.CONF.set('discoverd', 'processing_hooks', 'ramdisk_error,scheduler,validate_interfaces') self.data['error'] = 'BOOM' self.assertRaisesRegexp(utils.DiscoveryFailed, 'BOOM', process.process, self.data) def test_missing(self, client_mock, pop_mock, filters_mock, pre_mock, post_mock): del self.data['cpus'] self.assertRaisesRegexp(utils.DiscoveryFailed, 'missing', process.process, self.data) ",,843,727
openstack%2Fironic-inspector~master~I6e4de72ee6a3ecc825fe959b289d7e7e83e01bb9,openstack/ironic-inspector,master,I6e4de72ee6a3ecc825fe959b289d7e7e83e01bb9,Refactoring: cap complexity at 15 and coverage at 90,MERGED,2014-12-08 20:02:26.000000000,2014-12-10 09:05:47.000000000,2014-12-10 09:05:47.000000000,"[{'_account_id': 3}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-08 20:02:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c8d73c0839895175703948ac47c59ea0e17d43de', 'message': 'Refactoring: cap complexity at 15 and coverage at 90\n\nChange-Id: I6e4de72ee6a3ecc825fe959b289d7e7e83e01bb9\n'}]",0,140136,c8d73c0839895175703948ac47c59ea0e17d43de,7,2,1,10239,,,0,"Refactoring: cap complexity at 15 and coverage at 90

Change-Id: I6e4de72ee6a3ecc825fe959b289d7e7e83e01bb9
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/36/140136/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c8d73c0839895175703948ac47c59ea0e17d43de,refactoring, coverage report -m --fail-under 90max-complexity=15, coverage report -m --fail-under 80max-complexity=20,2,2
openstack%2Fironic-inspector~master~I2d4d4619cb5825422cb2fc684f7cd028f99b991d,openstack/ironic-inspector,master,I2d4d4619cb5825422cb2fc684f7cd028f99b991d,Refactoring: split discoverd.py into 2 modules,MERGED,2014-12-08 17:56:02.000000000,2014-12-10 09:05:41.000000000,2014-12-10 09:05:41.000000000,"[{'_account_id': 3}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-08 17:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/0eaa120acbfcc5bfa57730fe077fcded8f1ba0d0', 'message': 'Refactoring: split discoverd.py into 2 modules\n\nAlso drop or move to plugins some obsolete code.\n\nChange-Id: I2d4d4619cb5825422cb2fc684f7cd028f99b991d\n'}, {'number': 2, 'created': '2014-12-08 19:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e9c86d5ec87f857e0126608b031359ad079a84eb', 'message': 'Refactoring: split discoverd.py into 2 modules\n\nAlso drop or move to plugins some obsolete code and\nincrease code coverage by unit tests.\n\nAlso cap complexity at 15 and coverage at 90%.\nNext step is unit tests refactoring.\n\nChange-Id: I2d4d4619cb5825422cb2fc684f7cd028f99b991d\n'}, {'number': 3, 'created': '2014-12-08 20:02:26.000000000', 'files': ['ironic_discoverd/test.py', 'ironic_discoverd/discoverd.py', 'ironic_discoverd/process.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/main.py', 'ironic_discoverd/firewall.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/b8e1d97e81d45092e4d61a63fbd811c850cd6bbd', 'message': 'Refactoring: split discoverd.py into 2 modules\n\nWrote some missing tests as well.\n\nChange-Id: I2d4d4619cb5825422cb2fc684f7cd028f99b991d\n'}]",0,140102,b8e1d97e81d45092e4d61a63fbd811c850cd6bbd,12,2,3,10239,,,0,"Refactoring: split discoverd.py into 2 modules

Wrote some missing tests as well.

Change-Id: I2d4d4619cb5825422cb2fc684f7cd028f99b991d
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/02/140102/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test.py', 'ironic_discoverd/discoverd.py', 'ironic_discoverd/plugins/ramdisk_error.py', 'ironic_discoverd/process.py', 'setup.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/main.py', 'ironic_discoverd/firewall.py']",8,0eaa120acbfcc5bfa57730fe077fcded8f1ba0d0,refactoring,"LOG = logging.getLogger(""ironic_discoverd.firewall"")","LOG = logging.getLogger(""discoverd"")",315,260
openstack%2Ftripleo-image-elements~master~I8b845e2436465d355183e919f741726c9593b177,openstack/tripleo-image-elements,master,I8b845e2436465d355183e919f741726c9593b177,Add Neutron DVR configuration variables,MERGED,2014-10-13 15:14:16.000000000,2014-12-10 09:01:42.000000000,2014-12-10 09:01:41.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 360}, {'_account_id': 6488}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 8449}, {'_account_id': 8688}, {'_account_id': 9453}, {'_account_id': 10652}]","[{'number': 1, 'created': '2014-10-13 15:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9720f11bc296cf0c1ea05ca271a877fbbbb0e53d', 'message': 'Add Neutron DVR configuration variables\n\nThis change modifies the l3_agent.ini, neutron.conf and ml2_conf.ini image\nfiles to add parameters necessary for configuring Neutron distributed\nvirtual routers.\n\nChange-Id: I8b845e2436465d355183e919f741726c9593b177\nblueprint: support-neutron-dvr\n'}, {'number': 2, 'created': '2014-10-13 15:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ce4ac4bc4f63fddc752e0c147afd0afc6041f339', 'message': 'Add Neutron DVR configuration variables\n\nThis change modifies the l3_agent.ini, neutron.conf and ml2_conf.ini image\nfiles to add parameters necessary for configuring Neutron distributed\nvirtual routers.\n\nChange-Id: I8b845e2436465d355183e919f741726c9593b177\nblueprint: support-neutron-dvr\n'}, {'number': 3, 'created': '2014-10-16 13:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f9e2d2775ee76ebed33aa875b2f33d5d5ded934e', 'message': 'Add Neutron DVR configuration variables\n\nThis change modifies the l3_agent.ini, neutron.conf and ml2_conf.ini image\nfiles to add parameters necessary for configuring Neutron distributed\nvirtual routers.\n\nChange-Id: I8b845e2436465d355183e919f741726c9593b177\nblueprint: support-neutron-dvr\n'}, {'number': 4, 'created': '2014-10-23 13:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/44edf275018d6cebb6e499edd2a426ad40f84a83', 'message': 'Add Neutron DVR configuration variables\n\nThis change modifies the l3_agent.ini, neutron.conf and ml2_conf.ini image\nfiles to add parameters necessary for configuring Neutron distributed\nvirtual routers.\n\nChange-Id: I8b845e2436465d355183e919f741726c9593b177\nblueprint: support-neutron-dvr\n'}, {'number': 5, 'created': '2014-11-17 15:15:37.000000000', 'files': ['elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/neutron/os-apply-config/etc/neutron/plugins/ml2/ml2_conf.ini', 'elements/neutron/os-apply-config/etc/neutron/l3_agent.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fc4d56a0b425f88e803c2ee1313b5f83b252b2ee', 'message': 'Add Neutron DVR configuration variables\n\nThis change modifies the l3_agent.ini, neutron.conf and ml2_conf.ini image\nfiles to add parameters necessary for configuring Neutron distributed\nvirtual routers.\n\nChange-Id: I8b845e2436465d355183e919f741726c9593b177\nblueprint: support-neutron-dvr\n'}]",8,127988,fc4d56a0b425f88e803c2ee1313b5f83b252b2ee,40,11,5,10652,,,0,"Add Neutron DVR configuration variables

This change modifies the l3_agent.ini, neutron.conf and ml2_conf.ini image
files to add parameters necessary for configuring Neutron distributed
virtual routers.

Change-Id: I8b845e2436465d355183e919f741726c9593b177
blueprint: support-neutron-dvr
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/88/127988/5 && git format-patch -1 --stdout FETCH_HEAD,"['elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/neutron/os-apply-config/etc/neutron/plugins/ml2/ml2_conf.ini', 'elements/neutron/os-apply-config/etc/neutron/l3_agent.ini']",3,9720f11bc296cf0c1ea05ca271a877fbbbb0e53d,bp/support-neutron-dvr,{{#neutron.agent_mode}} agent_mode = {{neutron.agent_mode}} {{/neutron.agent_mode}} ,,12,0
openstack%2Fheat~master~I5c45ddc96b17bb1f87188ae3e9aabf74e6e29e1d,openstack/heat,master,I5c45ddc96b17bb1f87188ae3e9aabf74e6e29e1d,Add dependency on Router External Gateway property,MERGED,2014-12-09 09:01:53.000000000,2014-12-10 09:00:52.000000000,2014-12-10 09:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d45fb75e862a9174bd8bd42cf1acd67eac3409da', 'message': 'Add dependency on Router External Gateway property\n\nFIP has dependecy for RouterGateway resource, but it was deperecated in\nfavor of Router property. So we should add corrsponding dependency for\nFIP resource.\n\nChange-Id: I5c45ddc96b17bb1f87188ae3e9aabf74e6e29e1d\nCloses-Bug: #1399699\n'}, {'number': 2, 'created': '2014-12-09 14:30:03.000000000', 'files': ['heat/engine/resources/neutron/floatingip.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/38d1b4fada3bf1f52547103a311f7ac9e27a04b4', 'message': 'Add dependency on Router External Gateway property\n\nFIP has dependecy for RouterGateway resource, but it was deperecated in\nfavor of Router property. So we should add corrsponding dependency for\nFIP resource.\n\nChange-Id: I5c45ddc96b17bb1f87188ae3e9aabf74e6e29e1d\nCloses-Bug: #1399699\n'}]",2,140273,38d1b4fada3bf1f52547103a311f7ac9e27a04b4,20,7,2,6577,,,0,"Add dependency on Router External Gateway property

FIP has dependecy for RouterGateway resource, but it was deperecated in
favor of Router property. So we should add corrsponding dependency for
FIP resource.

Change-Id: I5c45ddc96b17bb1f87188ae3e9aabf74e6e29e1d
Closes-Bug: #1399699
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/140273/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/floatingip.py', 'heat/tests/test_neutron.py']",2,d45fb75e862a9174bd8bd42cf1acd67eac3409da,add_dependencies," ""floating_ip"": { ""Type"": ""OS::Neutron::FloatingIP"", ""Properties"": { ""floating_network"": { ""Ref"": ""net_external"" }, } }, required_by = set(stack.dependencies.required_by(stack['router'])) self.assertIn(stack['floating_ip'], required_by)",,24,0
openstack%2Fheat~master~I0ee15b80627783fc2a4c037060629e3c2f364b82,openstack/heat,master,I0ee15b80627783fc2a4c037060629e3c2f364b82,Use only FIP dependencies from graph,MERGED,2014-12-09 09:01:53.000000000,2014-12-10 08:59:43.000000000,2014-12-10 08:59:42.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-09 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5e1f85a8bc89a36da458058f22300243ae17e3f0', 'message': 'Use only FIP dependencies from graph\n\nThis patch contains follow important changes:\n - Fix wrong parameter passsed in graph method.\n - Now we use only FIP dependencies from graph.\n - Tests were fixed according to correct logic. Previously we try to add\n   router interface to FIP dependecies, when FIPAssociation was defined\n   in template. It was incorrect, because in this case such dependecy\n   should be added to FIPAssociation insteaf of FIP resource.\n\nChange-Id: I0ee15b80627783fc2a4c037060629e3c2f364b82\nCloses-Bug: #1399713\n'}, {'number': 2, 'created': '2014-12-09 14:30:03.000000000', 'files': ['heat/engine/resources/neutron/floatingip.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/64a301c5b2555aa04fb78925ef91321bdfa2e174', 'message': 'Use only FIP dependencies from graph\n\nThis patch contains follow important changes:\n - Fix wrong parameter passsed in graph method.\n - Now we use only FIP dependencies from graph.\n - Tests were fixed according to correct logic. Previously we try to add\n   router interface to FIP dependecies, when FIPAssociation was defined\n   in template. It was incorrect, because in this case such dependecy\n   should be added to FIPAssociation insteaf of FIP resource.\n\nChange-Id: I0ee15b80627783fc2a4c037060629e3c2f364b82\nCloses-Bug: #1399713\n'}]",0,140272,64a301c5b2555aa04fb78925ef91321bdfa2e174,20,5,2,6577,,,0,"Use only FIP dependencies from graph

This patch contains follow important changes:
 - Fix wrong parameter passsed in graph method.
 - Now we use only FIP dependencies from graph.
 - Tests were fixed according to correct logic. Previously we try to add
   router interface to FIP dependecies, when FIPAssociation was defined
   in template. It was incorrect, because in this case such dependecy
   should be added to FIPAssociation insteaf of FIP resource.

Change-Id: I0ee15b80627783fc2a4c037060629e3c2f364b82
Closes-Bug: #1399713
",git fetch https://review.opendev.org/openstack/heat refs/changes/72/140272/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/floatingip.py', 'heat/tests/test_neutron.py']",2,5e1f85a8bc89a36da458058f22300243ae17e3f0,add_dependencies," ""router_interface"": { ""Type"": ""OS::Neutron::RouterInterface"", ""Properties"": { ""router_id"": { ""Ref"" : ""router"" }, ""subnet"": ""sub1234"" } }, # check dependencies for fip resource required_by = set(stack.dependencies.required_by( stack['router_interface'])) self.assertIn(stack['floating_ip'], required_by) "," self.assertIn(stack['floating_ip'], required_by)",13,2
openstack%2Fironic~master~I87eedd716debf2457e3e5394bf815b3d37e1342d,openstack/ironic,master,I87eedd716debf2457e3e5394bf815b3d37e1342d,Add AMT Support with PXE Driver,ABANDONED,2014-12-09 14:57:19.000000000,2014-12-10 08:55:40.000000000,,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-12-09 14:57:19.000000000', 'files': ['ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2d1d7e5f74d0a1ada44582c15e3e023127549e85', 'message': ""Add AMT Support with PXE Driver\n\nNode will reboot after finish deployment. But AMT doesn't support\nsetting boot device persistent, so need to set boot device again.\n\nImplements blueprint amt-pxe-driver\nChange-Id: I87eedd716debf2457e3e5394bf815b3d37e1342d\n""}]",3,140351,2d1d7e5f74d0a1ada44582c15e3e023127549e85,9,4,1,13362,,,0,"Add AMT Support with PXE Driver

Node will reboot after finish deployment. But AMT doesn't support
setting boot device persistent, so need to set boot device again.

Implements blueprint amt-pxe-driver
Change-Id: I87eedd716debf2457e3e5394bf815b3d37e1342d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/51/140351/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py']",2,2d1d7e5f74d0a1ada44582c15e3e023127549e85,bp/amt-pxe-driver," @mock.patch.object(deploy_utils, 'notify_deploy_complete') @mock.patch.object(deploy_utils, 'switch_pxe_config') @mock.patch.object(iscsi_deploy, 'InstanceImageCache') def test_continue_deploy_with_amt_driver(self, mock_image_cache, mock_switch_config, notify_mock): token_path = self._create_token_file() self.node.power_state = states.POWER_ON self.node.provision_state = states.DEPLOYWAIT self.node.save() root_uuid = ""12345678-1234-1234-1234-1234567890abcxyz"" boot_mode = None def fake_deploy(**kwargs): return root_uuid self.useFixture(fixtures.MonkeyPatch( 'ironic.drivers.modules.deploy_utils.deploy', fake_deploy)) with task_manager.acquire(self.context, self.node.uuid) as task: task.node.driver = 'pxe_amt' mock_mgmt_driver = mock.Mock() task.driver.management = mock_mgmt_driver mock_snbd = mock.Mock() mock_mgmt_driver.set_next_boot_device = mock_snbd task.driver.vendor._continue_deploy( task, address='123456', iqn='aaa-bbb', key='fake-56789') mock_snbd.assert_called_once_with(task.node, 'pxe') self.node.refresh() self.assertEqual(states.ACTIVE, self.node.provision_state) self.assertEqual(states.POWER_ON, self.node.power_state) self.assertIsNone(self.node.last_error) self.assertFalse(os.path.exists(token_path)) mock_image_cache.assert_called_once_with() mock_image_cache.return_value.clean_up.assert_called_once_with() pxe_config_path = pxe_utils.get_pxe_config_file_path(self.node.uuid) mock_switch_config.assert_called_once_with(pxe_config_path, root_uuid, boot_mode) notify_mock.assert_called_once_with('123456') ",,45,1
openstack%2Fcongress-specs~master~Ie319c80142bdc706cb849e8870d96f44b2045dcd,openstack/congress-specs,master,Ie319c80142bdc706cb849e8870d96f44b2045dcd,Enhance tox output and fix spec formatting,MERGED,2014-11-22 00:30:54.000000000,2014-12-10 08:55:08.000000000,2014-12-10 08:55:08.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 7187}]","[{'number': 1, 'created': '2014-11-22 00:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/f4e0ececbdf343cfaccb5df6027c2d4727ec88e5', 'message': 'Enhance tox output and fix spec formatting\n\nMake title and subtitle comparisons case-insensitive. Include file name for\nspecs with missing subtitles. Include file name for specs with docutils errors.\nRemoved empty file.\n\nFormatting errors fixed in specs:\n* Line length past 79 characters.\n* Missing subtitle.\n* Unexpected indentation.\n* Title underline length too short.\n\nChange-Id: Ie319c80142bdc706cb849e8870d96f44b2045dcd\n'}, {'number': 2, 'created': '2014-12-10 08:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/0e294888a525167baa59422f9b991d5338d2b13b', 'message': 'Enhance tox output and fix spec formatting\n\nInclude file name for specs with missing subtitles. Include file name for specs\nwith docutils errors. Removed empty file.\n\nFormatting errors fixed in specs:\n* Line length past 79 characters.\n* Consistent capitalization of subtitles (first word only, which was the\n  majority of the existing ones).\n* Missing subtitle.\n* Unexpected indentation.\n* Title underline length too short.\n\nChange-Id: Ie319c80142bdc706cb849e8870d96f44b2045dcd\n'}, {'number': 3, 'created': '2014-12-10 08:27:06.000000000', 'files': ['specs/kilo/congress-gbp-translation.rst', 'specs/kilo/compromised-vm.rst', 'specs/kilo/api-validation.rst', 'tests/test_titles.py', 'specs/juno/datalog-aggregates.rst', 'specs/template.rst', 'specs/kilo/horizon-create-policies.rst', 'specs/kilo/policy-engine-trigger.rst', 'specs/kilo/horizon-integration.rst', 'specs/juno/Plexxi-Driver.rst', 'specs/kilo/dse-dataservices-status.rst', 'specs/kilo/persistent-storage-for-api.rst', 'specs/kilo/multiple-policies.rst', 'specs/kilo/datalog-column-names.rst', 'specs/juno/cinder-datasource-driver.rst', 'specs/kilo/glance-datasource-driver.rst', 'specs/kilo/empty', 'specs/kilo/refactor-drivers.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/7319e304d4372e4de7fa80ea43867f29d3aa772c', 'message': 'Enhance tox output and fix spec formatting\n\nInclude file name for specs with missing subtitles. Include file name for specs\nwith docutils errors. Removed empty file.\n\nFormatting errors fixed in specs:\n* Line length past 79 characters.\n* Consistent capitalization of subtitles (first word only, which was the\n  majority of the existing ones).\n* Missing subtitle.\n* Unexpected indentation.\n* Title underline length too short.\n\nChange-Id: Ie319c80142bdc706cb849e8870d96f44b2045dcd\n'}]",3,136537,7319e304d4372e4de7fa80ea43867f29d3aa772c,13,3,3,7187,,,0,"Enhance tox output and fix spec formatting

Include file name for specs with missing subtitles. Include file name for specs
with docutils errors. Removed empty file.

Formatting errors fixed in specs:
* Line length past 79 characters.
* Consistent capitalization of subtitles (first word only, which was the
  majority of the existing ones).
* Missing subtitle.
* Unexpected indentation.
* Title underline length too short.

Change-Id: Ie319c80142bdc706cb849e8870d96f44b2045dcd
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/37/136537/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/kilo/congress-gbp-translation.rst', 'specs/kilo/compromised-vm.rst', 'specs/kilo/api-validation.rst', 'tests/test_titles.py', 'specs/juno/datalog-aggregates.rst', 'specs/template.rst', 'specs/kilo/horizon-integration.rst', 'specs/juno/Plexxi-Driver.rst', 'specs/kilo/dse-dataservices-status.rst', 'specs/kilo/multiple-policies.rst', 'specs/kilo/datalog-column-names.rst', 'specs/kilo/empty', 'specs/kilo/refactor-drivers.rst']",13,f4e0ececbdf343cfaccb5df6027c2d4727ec88e5,,"Unit tests for superclass, and modify existing test cases for individual drivers.","Unit tests for superclass, and modify existing test cases for individual drivers.",104,89
openstack%2Fheat~master~I58a94318d10721e6c0eb582cdbaf489da85b8a8e,openstack/heat,master,I58a94318d10721e6c0eb582cdbaf489da85b8a8e,Add dependency hidden on router_interface,MERGED,2014-12-09 09:01:53.000000000,2014-12-10 08:51:18.000000000,2014-12-10 08:50:07.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/02c275e4d3e66309da49ef9519b85ed22709fb23', 'message': 'Add dependency hidden on router_interface\n\nThis patch adds hidden dependency for FloatingIPAssocoation resource on\nRouterInterface resource.\n\nChange-Id: I58a94318d10721e6c0eb582cdbaf489da85b8a8e\nCloses-Bug: #1399702\n'}, {'number': 2, 'created': '2014-12-09 14:30:03.000000000', 'files': ['heat/engine/resources/neutron/floatingip.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/85a4cf7df405a120392dd87d055fe0dd2bdef516', 'message': 'Add dependency hidden on router_interface\n\nThis patch adds hidden dependency for FloatingIPAssocoation resource on\nRouterInterface resource.\n\nChange-Id: I58a94318d10721e6c0eb582cdbaf489da85b8a8e\nCloses-Bug: #1399702\n'}]",2,140271,85a4cf7df405a120392dd87d055fe0dd2bdef516,21,7,2,6577,,,0,"Add dependency hidden on router_interface

This patch adds hidden dependency for FloatingIPAssocoation resource on
RouterInterface resource.

Change-Id: I58a94318d10721e6c0eb582cdbaf489da85b8a8e
Closes-Bug: #1399702
",git fetch https://review.opendev.org/openstack/heat refs/changes/71/140271/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/floatingip.py', 'heat/tests/test_neutron.py']",2,02c275e4d3e66309da49ef9519b85ed22709fb23,add_dependencies," required_by = set(stack.dependencies.required_by( stack['router_interface'])) self.assertIn(stack['floating_ip_assoc'], required_by) self.assertIn(stack['floating_ip'], required_by)"," deps = stack.dependencies[stack['router_interface']] self.assertIn(stack['floating_ip'], deps)",30,2
openstack%2Ffuel-web~master~I09dab88eaca583144e68f998283ebce236d728b7,openstack/fuel-web,master,I09dab88eaca583144e68f998283ebce236d728b7,Rename nailgun.test.base.Environment class,MERGED,2014-12-03 18:48:23.000000000,2014-12-10 08:29:57.000000000,2014-12-10 08:29:56.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-03 18:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1a7913a23933a6305c6cada6c0e18bf367c1bbb5', 'message': 'Rename nailgun.test.base.Environment class\n\n  Rename nailgun.test.base.Environment class to EnvironmentManager\n\nChange-Id: I09dab88eaca583144e68f998283ebce236d728b7\nImplements: blueprint code-testing-improvements\n'}, {'number': 2, 'created': '2014-12-04 10:58:36.000000000', 'files': ['nailgun/nailgun/test/performance/base.py', 'nailgun/nailgun/test/base.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c670a1d7062d2f3858dd06b4579f8ceee87f4f54', 'message': 'Rename nailgun.test.base.Environment class\n\n  In Fuel terminology we use ""environment"" term as a synonym for\n  ""cluster"", but in our tests Environment class doesn\'t represent\n  the cluster entity and behaves more like ""Environment Manager"",\n  since it may have more than one cluster.\n\nChange-Id: I09dab88eaca583144e68f998283ebce236d728b7\nImplements: blueprint code-testing-improvements\n'}]",2,138823,c670a1d7062d2f3858dd06b4579f8ceee87f4f54,23,10,2,11577,,,0,"Rename nailgun.test.base.Environment class

  In Fuel terminology we use ""environment"" term as a synonym for
  ""cluster"", but in our tests Environment class doesn't represent
  the cluster entity and behaves more like ""Environment Manager"",
  since it may have more than one cluster.

Change-Id: I09dab88eaca583144e68f998283ebce236d728b7
Implements: blueprint code-testing-improvements
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/23/138823/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/performance/base.py', 'nailgun/nailgun/test/base.py']",2,1a7913a23933a6305c6cada6c0e18bf367c1bbb5,bp/code-testing-improvements,"class EnvironmentManager(object): self.env = EnvironmentManager(app=self.app, session=self.db)","class Environment(object): self.env = Environment(app=self.app, session=self.db)",4,4
openstack%2Fglance~master~I9606f42e1b2be799cdf435ccd9293a1fa1a831d3,openstack/glance,master,I9606f42e1b2be799cdf435ccd9293a1fa1a831d3,Remove jsonutils from openstack-common.conf,ABANDONED,2014-12-09 18:58:07.000000000,2014-12-10 08:19:25.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-09 18:58:07.000000000', 'files': ['glance/openstack/common/jsonutils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/927bbbc72268c93374c12ec79f8d89fe89111562', 'message': ""Remove jsonutils from openstack-common.conf\n\nIt's actually not used anymore\n\nChange-Id: I9606f42e1b2be799cdf435ccd9293a1fa1a831d3\n""}]",0,140435,927bbbc72268c93374c12ec79f8d89fe89111562,5,4,1,1669,,,0,"Remove jsonutils from openstack-common.conf

It's actually not used anymore

Change-Id: I9606f42e1b2be799cdf435ccd9293a1fa1a831d3
",git fetch https://review.opendev.org/openstack/glance refs/changes/35/140435/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/openstack/common/jsonutils.py', 'openstack-common.conf']",2,927bbbc72268c93374c12ec79f8d89fe89111562,jd/update-oslo-inc,,module=jsonutils,0,187
openstack%2Foslo.utils~master~I162a8c79c387c8bc056a76cd4c7423e53bce7fd2,openstack/oslo.utils,master,I162a8c79c387c8bc056a76cd4c7423e53bce7fd2,Imported Translations from Transifex,MERGED,2014-11-22 13:39:46.000000000,2014-12-10 08:16:01.000000000,2014-12-10 08:16:01.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-11-22 13:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4516314d78a6fd79fe88f5e3c5b6a44c7acaec31', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 2, 'created': '2014-11-23 06:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/93209367b8779f59914a0253964dc2abe611ef0a', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 3, 'created': '2014-11-24 06:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4ef574f882f0cffff75ea1b7ec79a304aab8fbfd', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 4, 'created': '2014-11-25 06:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/d145ab04799aa9b4e202d4c5fdd2027fa051b89f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 5, 'created': '2014-11-26 06:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/5f3585d80e0b4afd094875842604779a502b5aa0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 6, 'created': '2014-11-27 06:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/9026474d5eed72099c89f38a9aaefa8d8c576c54', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 7, 'created': '2014-11-28 06:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/0883ab1b6bc0fa8a4f5cb06b2ee34dcf295068e1', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 8, 'created': '2014-11-29 06:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/99719da039bfeb0e332b02eaba881ffbffe88881', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 9, 'created': '2014-11-30 06:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/1070435b5a3c7985280f15d35ccd82fc4b5207fc', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 10, 'created': '2014-12-01 06:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/591652dae52193778dfffde5292f4bf6df77b34f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 11, 'created': '2014-12-02 06:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/efeb4139ff5cb3cb03e5e9fe4e21c44656816eda', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 12, 'created': '2014-12-03 06:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/7f911cf1b57045e98cbd2cd53a857f80438c17e5', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 13, 'created': '2014-12-04 06:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/ebf7c81990eae45644b48089280c4b3dcc0317fa', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 14, 'created': '2014-12-05 06:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/f19048fc4a41ce92f74936ce667c0811bb2cc488', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 15, 'created': '2014-12-08 06:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/06be3e867586216bfc1295316970bd3ffee5f1a3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 16, 'created': '2014-12-09 06:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/519138b9c1962b454378df84e14c0c24ce77e77d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}, {'number': 17, 'created': '2014-12-10 06:12:09.000000000', 'files': ['oslo.utils/locale/de/LC_MESSAGES/oslo.utils-log-info.po', 'oslo.utils/locale/de/LC_MESSAGES/oslo.utils.po', 'oslo.utils/locale/oslo.utils-log-info.pot'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/2081aa9cdeb41b86e0f58556a20c09f46835a82b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2\n'}]",0,136566,2081aa9cdeb41b86e0f58556a20c09f46835a82b,49,4,17,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I162a8c79c387c8bc056a76cd4c7423e53bce7fd2
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/66/136566/16 && git format-patch -1 --stdout FETCH_HEAD,"['oslo.utils/locale/oslo.utils-log-info.pot', 'oslo.utils/locale/fr/LC_MESSAGES/oslo.utils-log-info.po']",2,4516314d78a6fd79fe88f5e3c5b6a44c7acaec31,transifex/translations,"# Translations template for oslo.utils. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the oslo.utils project. # # Translators: # Maxime COQUEREL <max.coquerel@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: oslo.utils\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-11-22 13:39+0000\n"" ""PO-Revision-Date: 2014-11-21 20:47+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n"" ""Language-Team: French (http://www.transifex.com/projects/p/osloutils/"" ""language/fr/)\n"" ""Language: fr\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" #: oslo/utils/netutils.py:144 msgid ""Couldn't get IPv4"" msgstr ""Impossible d'obtenir l'adresse IPv4"" ",,31,2
openstack%2Fcongress-specs~master~I78feeaab14a7718884c10b64c4096eabddb16820,openstack/congress-specs,master,I78feeaab14a7718884c10b64c4096eabddb16820,Add a spec for a heat datasource driver,MERGED,2014-11-18 23:28:48.000000000,2014-12-10 08:11:58.000000000,2014-12-10 08:11:57.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 8246}, {'_account_id': 12875}]","[{'number': 1, 'created': '2014-11-18 23:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/5f0b1cb2cee88f023f50b3200a897ecc119276e0', 'message': 'Add a spec for a heat datasource driver\n\nBlueprint:\n  https://blueprints.launchpad.net/congress/+spec/heat-datasource-driver\n\nChange-Id: I78feeaab14a7718884c10b64c4096eabddb16820\n'}, {'number': 2, 'created': '2014-11-25 00:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/cb996ab465cc75c38e239bce0657ea0ea144f618', 'message': 'Add a spec for a heat datasource driver\n\nBlueprint:\n  https://blueprints.launchpad.net/congress/+spec/heat-datasource-driver\n\nChange-Id: I78feeaab14a7718884c10b64c4096eabddb16820\n'}, {'number': 3, 'created': '2014-12-10 08:04:08.000000000', 'files': ['specs/kilo/heat-datasource-driver.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/bcab90d57cd95c1b26aae20b3a198128a6056cfa', 'message': 'Add a spec for a heat datasource driver\n\nBlueprint:\n  https://blueprints.launchpad.net/congress/+spec/heat-datasource-driver\n\nChange-Id: I78feeaab14a7718884c10b64c4096eabddb16820\n'}]",2,135457,bcab90d57cd95c1b26aae20b3a198128a6056cfa,15,5,3,12875,,,0,"Add a spec for a heat datasource driver

Blueprint:
  https://blueprints.launchpad.net/congress/+spec/heat-datasource-driver

Change-Id: I78feeaab14a7718884c10b64c4096eabddb16820
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/57/135457/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/heat-datasource-driver.rst'],1,5f0b1cb2cee88f023f50b3200a897ecc119276e0,bp/s,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Create a Heat Datasource Driver =============================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/congress/+spec/heat-datasource-driver This Heat driver will allow Congress to interact with the Openstack Heat API for orchestration. The first version will provide data from Heat's read API calls until Congress does has infrastructure to handle writing to drivers. Subsequent versions may be able to send requests and write to the Heat API. Problem description =================== Today, there is no Congress driver for Heat, either for reading or writing. This driver will give Congress eyes into Heat so that a policy writer can inspect Heat state such as details about each stack, stack snapshots, resources, software configurations, software deployments, and perhaps templates themselves. Proposed change =============== This driver will be similar to other existing drivers like neutron_driver.py and nova_driver.py. The Heat driver will read data from the following Heat API calls and convert the responses to Congress tables: * list stacks * show stack detail * list snapshots * list resources * show resource data * show resource metadata * list resource types * show configuration details Alternatives ------------ The alternative is to have no driver for Heat, which is not a good option for those admins that use Heat in their cloud. Policy ------ N/A Policy Actions -------------- N/A Data Sources ------------ Openstack Heat Data model impact ----------------- N/A REST API impact --------------- N/A Security impact --------------- The Heat driver will need to authenticate to the Heat API just like all the other datasource drivers. Notifications impact -------------------- N/A Other end user impact --------------------- N/A Performance Impact ------------------ It is possible that the API calls will be expensive. We will need to measure the impact of the API calls on Heat and Congress performance. Other Deployer Impacts ---------------------- N/A Developer Impact ---------------- N/A Implementation ============== Assignee(s) ----------- Primary assignee: None Other contributors: None Work Items ---------- * Write unit test * Write tempest test * Write API client code * Write translators for tables Dependencies ============ N/A Testing ======= This work must include a unit test and a tempest test. The driver translator infrastructure makes most of the translation code robust, but the driver is still dependent on the Heat API, so the tempest test is particularly important as an integration test. Documentation Impact ==================== N/A References ========== Blueprint: https://blueprints.launchpad.net/congress/+spec/heat-datasource-driver ",,158,0
openstack%2Ftricircle~master~I9bd576add946400cdec19cae466a933f57f80f32,openstack/tricircle,master,I9bd576add946400cdec19cae466a933f57f80f32,Resovle some perfromance issues of nova cascading,MERGED,2014-12-10 07:56:30.000000000,2014-12-10 07:57:29.000000000,2014-12-10 07:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-10 07:56:30.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/75643b324f6340fe18049f25bc6636d954f52a1b', 'message': 'Resovle some perfromance issues of nova cascading\n\nFirstly, we get rid of the unused code in manager_proxy; then adding the\npaging function of query nova instances; finally, the resize func is\nmodified for rollback flavor when cascaded resize failed.\n\nChange-Id: I9bd576add946400cdec19cae466a933f57f80f32\n'}]",0,140599,75643b324f6340fe18049f25bc6636d954f52a1b,6,2,1,9684,,,0,"Resovle some perfromance issues of nova cascading

Firstly, we get rid of the unused code in manager_proxy; then adding the
paging function of query nova instances; finally, the resize func is
modified for rollback flavor when cascaded resize failed.

Change-Id: I9bd576add946400cdec19cae466a933f57f80f32
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/99/140599/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,75643b324f6340fe18049f25bc6636d954f52a1b,," QUERY_PER_PAGE_LIMIT = 30 INSTANCE_UUID_LENGTH = 36 search_opts_args = { 'all_tenants': True } marker = None while True: servers = csd_nova_client.servers.list(search_opts_args, limit=self.QUERY_PER_PAGE_LIMIT, marker=marker) if servers: marker = servers[-1].id else: break for server in servers: csg_instance_uuid = ComputeManager._extract_csg_uuid(server) self._uuid_mapping[csg_instance_uuid] = server.id uuid_len = ComputeManager.INSTANCE_UUID_LENGTH if len(csd_name) > (uuid_len+1) and csd_name[-(uuid_len+1)] == '@': return csd_name[-uuid_len:] def _sync_instance_flavor(self, context, instance): try: flavor_name = instance['system_metadata']['instance_type_name'] # Get the active flavor by flavor_name in the instance. active_flavor = flavor_obj.Flavor.get_by_name(context, flavor_name) if not active_flavor: LOG.info(_('the flavor %s not exists, may be deleted.'), flavor_name) #(todo) Should delete the cascaed flavor accordingly and #remove it from the cache? return instance_type = { 'flavorid': active_flavor.flavorid, 'name': active_flavor.name, 'memory_mb': active_flavor.memory_mb, 'vcpus': active_flavor.vcpus, 'swap': active_flavor.swap, 'rxtx_factor': active_flavor.rxtx_factor, 'ephemeral_gb': active_flavor.ephemeral_gb, 'root_gb': active_flavor.root_gb, 'extra_specs': active_flavor.extra_specs } self._heal_syn_flavor_info(context, instance_type) except KeyError: LOG.error(_('Can not find flavor info in instance %s when reboot.'), instance['uuid']) except Exception: with excutils.save_and_reraise_exception(): LOG.error(_('Fail to get/sync flavor %s when reboot.'), flavor_name) def _heal_syn_flavor_info(self, context, instance_type, check_extra=True): _extra_specs_change_flag = check_extra and \ csd_flavor.get('extra_specs', {}) != instance_type['extra_specs'] # self.update_available_resource(nova.context.get_admin_context()) self._sync_instance_flavor(context, instance) # the instance_type contains no extra_specs. instance_type['extra_specs'] = {} self._heal_syn_flavor_info(context, instance_type, check_extra=False) LOG.error(_('Failed to resize server %s, rollback flavor.'), flavors.delete_flavor_info(sys_meta, 'old_') if resize_instance: self._save_instance_info(instance, old_instance_type, sys_meta) # new_resource_tracker_dict = {} # nodenames = set(self.driver.get_available_nodes()) # for nodename in nodenames: # rt = self._get_resource_tracker(nodename) # rt.update_available_resource(context) # new_resource_tracker_dict[nodename] = rt # # # Delete orphan compute node not reported by driver but still in db # compute_nodes_in_db = self._get_compute_nodes_in_db(context, # use_slave=True) # # for cn in compute_nodes_in_db: # if cn.hypervisor_hostname not in nodenames: # LOG.audit(_(""Deleting orphan compute node %s"") % cn.id) # cn.destroy() # # self._resource_tracker_dict = new_resource_tracker_dict"," search_opts_args = { 'all_tenants': True } servers = csd_nova_client.servers.list(search_opts_args) # def extract_instance_uuid(csd_name): # if len(csd_name) > 37 and csd_name[-37] == '@': # return csd_name[-36:] # return '' for server in servers: csg_instance_uuid = ComputeManager._extract_csg_uuid(server) self._uuid_mapping[csg_instance_uuid] = server.id if len(csd_name) > 37 and csd_name[-37] == '@': return csd_name[-36:] def _heal_syn_flavor_info(self, context, instance_type): _extra_specs_change_flag = csd_flavor.get('extra_specs', {}) \ != instance_type['extra_specs'] self.update_available_resource(nova.context.get_admin_context()) try: flavor_name = instance['system_metadata']['instance_type_name'] # Get the active flavor by flavor_name in the instance. active_flavor = flavor_obj.Flavor.get_by_name(context, flavor_name) instance_type = { 'flavorid': active_flavor.flavorid, 'name': active_flavor.name, 'memory_mb': active_flavor.memory_mb, 'vcpus': active_flavor.vcpus, 'swap': active_flavor.swap, 'rxtx_factor': active_flavor.rxtx_factor, 'ephemeral_gb': active_flavor.ephemeral_gb, 'root_gb': active_flavor.root_gb } self._heal_syn_flavor_info(context, instance_type) except KeyError: LOG.error(_('Can not find flavor info in instance %s when reboot.'), instance['uuid']) except Exception: with excutils.save_and_reraise_exception(): LOG.error(_('Fail to get/sync flavor %s when reboot.'), flavor_name) LOG.error(_('Failed to resize server %s .'), new_resource_tracker_dict = {} nodenames = set(self.driver.get_available_nodes()) for nodename in nodenames: rt = self._get_resource_tracker(nodename) rt.update_available_resource(context) new_resource_tracker_dict[nodename] = rt # Delete orphan compute node not reported by driver but still in db compute_nodes_in_db = self._get_compute_nodes_in_db(context, use_slave=True) for cn in compute_nodes_in_db: if cn.hypervisor_hostname not in nodenames: LOG.audit(_(""Deleting orphan compute node %s"") % cn.id) cn.destroy() self._resource_tracker_dict = new_resource_tracker_dict",81,59
openstack%2Ffuel-web~master~I9f3e02b1cdf635a761583fe58d8ba8116a690a95,openstack/fuel-web,master,I9f3e02b1cdf635a761583fe58d8ba8116a690a95,Add possibility to stop update/rollback proccess,ABANDONED,2014-09-03 16:46:45.000000000,2014-12-10 07:48:38.000000000,,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-09-03 16:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f71985a0ca4d6d2ed14722b5c4ace2f01f15b4e3', 'message': 'Add possibility to stop update/rollback proccess\n\nThis patch requires this one:\n\n    https://review.openstack.org/#/c/118634/\n\nChange-Id: I9f3e02b1cdf635a761583fe58d8ba8116a690a95\nCloses-Bug: #1364907\n'}, {'number': 2, 'created': '2014-09-03 16:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a0f05ea73473bece450224d3ba1c97255061bbe0', 'message': 'Add possibility to stop update/rollback proccess\n\nThis patch requires this one:\n\n    https://review.openstack.org/#/c/118634/\n\nChange-Id: I9f3e02b1cdf635a761583fe58d8ba8116a690a95\nCloses-Bug: #1364907\n'}, {'number': 3, 'created': '2014-09-04 07:51:16.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/task/manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1ab2f32aa3a137343592224f476a69d85555cf66', 'message': 'Add possibility to stop update/rollback proccess\n\nThis patch requires this one:\n\n    https://review.openstack.org/#/c/118634/\n\nChange-Id: I9f3e02b1cdf635a761583fe58d8ba8116a690a95\nCloses-Bug: #1364907\n'}]",0,118688,1ab2f32aa3a137343592224f476a69d85555cf66,18,6,3,10391,,,0,"Add possibility to stop update/rollback proccess

This patch requires this one:

    https://review.openstack.org/#/c/118634/

Change-Id: I9f3e02b1cdf635a761583fe58d8ba8116a690a95
Closes-Bug: #1364907
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/88/118688/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/task.py', 'nailgun/nailgun/task/manager.py']",2,f71985a0ca4d6d2ed14722b5c4ace2f01f15b4e3,bug/1364907," update_task = objects.TaskCollection.filter_by( None, cluster_id=self.cluster.id, name=TASK_NAMES.update, ) update_task = objects.TaskCollection.order_by( update_task, 'id' ).first() if not deployment_task and not provisioning_task and not update_task: provision_task=provisioning_task, update_task=update_task,", if not deployment_task and not provisioning_task: provision_task=provisioning_task,19,3
openstack%2Ffuel-web~master~I44b6f76e5fdaa798bb899fad3c54d8d833df3184,openstack/fuel-web,master,I44b6f76e5fdaa798bb899fad3c54d8d833df3184,Fix node assignment validation,MERGED,2014-12-01 13:04:01.000000000,2014-12-10 07:47:39.000000000,2014-12-10 07:47:38.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-01 13:04:01.000000000', 'files': ['nailgun/nailgun/test/unit/test_assignment_validator.py', 'nailgun/nailgun/api/v1/validators/json_schema/assignment.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2e026bfbee632190f2fe274c54834a2e3139f76b', 'message': 'Fix node assignment validation\n\nBoth ""id"" and ""roles"" fields are required for assignment, but they\nweren\'t marked as required in JSON Schema. Since now it\'s fixed.\n\nChange-Id: I44b6f76e5fdaa798bb899fad3c54d8d833df3184\nCloses-Bug: #1397016\n'}]",1,138057,2e026bfbee632190f2fe274c54834a2e3139f76b,16,10,1,10391,,,0,"Fix node assignment validation

Both ""id"" and ""roles"" fields are required for assignment, but they
weren't marked as required in JSON Schema. Since now it's fixed.

Change-Id: I44b6f76e5fdaa798bb899fad3c54d8d833df3184
Closes-Bug: #1397016
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/57/138057/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_assignment_validator.py', 'nailgun/nailgun/api/v1/validators/json_schema/assignment.py']",2,2e026bfbee632190f2fe274c54834a2e3139f76b,bug/1397016," }, 'required': ['id', 'roles'],", },30,12
openstack%2Ffuel-web~master~Ib2981ceb9769455f0c3fa2e0b0de10b5f083eeef,openstack/fuel-web,master,Ib2981ceb9769455f0c3fa2e0b0de10b5f083eeef,Reset `group_id` during cluster deletion in FakeUI,MERGED,2014-12-05 11:13:43.000000000,2014-12-10 07:47:28.000000000,2014-12-10 07:47:27.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-05 11:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c9f18d434f88830ed2bd2584c1416ff94ff1dc9d', 'message': 'Reset `group_id` during cluster deletion in FakeUI\n\nIf we add some node to some cluster and then remove this cluster, we\nwon\'t be able to add this node to some another cluster. The cause is\nthat we have a ""hack"" that handles cluster removing in Fake UI mode.\n\nChange-Id: Ib2981ceb9769455f0c3fa2e0b0de10b5f083eeef\nCloses-Bug: #1398822\n'}, {'number': 2, 'created': '2014-12-05 14:01:39.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_cluster_handler.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8c8e426cffb4c2b44d915286351747e978bfe831', 'message': 'Reset `group_id` during cluster deletion in FakeUI\n\nIf we add some node to some cluster and then remove this cluster, we\nwon\'t be able to add this node to some another cluster. The cause is\nthat we have a ""hack"" that handles cluster removing in Fake UI mode.\n\nChange-Id: Ib2981ceb9769455f0c3fa2e0b0de10b5f083eeef\nCloses-Bug: #1398822\n'}]",2,139600,8c8e426cffb4c2b44d915286351747e978bfe831,21,9,2,10391,,,0,"Reset `group_id` during cluster deletion in FakeUI

If we add some node to some cluster and then remove this cluster, we
won't be able to add this node to some another cluster. The cause is
that we have a ""hack"" that handles cluster removing in Fake UI mode.

Change-Id: Ib2981ceb9769455f0c3fa2e0b0de10b5f083eeef
Closes-Bug: #1398822
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/00/139600/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/task/task.py'],1,c9f18d434f88830ed2bd2584c1416ff94ff1dc9d,bug/1398822," reset_attrs = ( 'pending_addition', 'group_id', ) and prop.key not in reset_attrs:", keep_attrs = ( 'pending_addition' ) and prop.key not in keep_attrs:,4,3
openstack%2Ffuel-web~master~I401ef74abc95961d5687d12835752b881ef0e7ef,openstack/fuel-web,master,I401ef74abc95961d5687d12835752b881ef0e7ef,"Use build_app from app.py, not from wsgi.py",MERGED,2014-12-05 15:52:18.000000000,2014-12-10 07:46:39.000000000,2014-12-10 07:46:39.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-05 15:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f90bce6bb7dd33df7569dcb76ffe870f59170bc5', 'message': ""Use build_app from app.py, not from wsgi.py\n\nFor tests it's important to use `build_app` from app.py because it doesn't\nuse the `HTTPLoggerMiddleware`. This makes us possible to run tests without\nwrite permissions in `/var/log/nailgun`.\n\nThe commit also removes the obsolete `paste` package from dependencies.\n\nChange-Id: I401ef74abc95961d5687d12835752b881ef0e7ef\nCloses-Bug: #1396685\n""}, {'number': 2, 'created': '2014-12-05 16:28:13.000000000', 'files': ['nailgun/requirements.txt', 'nailgun/nailgun/test/integration/test_db_refresh.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4a276068b966ffef74783fb3138b8d3fb23cd8dd', 'message': ""Use build_app from app.py, not from wsgi.py\n\nFor tests it's important to use `build_app` from app.py because it doesn't\nuse the `HTTPLoggerMiddleware`. This makes us possible to run tests without\nwrite permissions in `/var/log/nailgun`.\n\nThe commit also removes the obsolete `paste` package from dependencies.\n\nChange-Id: I401ef74abc95961d5687d12835752b881ef0e7ef\nCloses-Bug: #1396685\n""}]",0,139664,4a276068b966ffef74783fb3138b8d3fb23cd8dd,22,9,2,10391,,,0,"Use build_app from app.py, not from wsgi.py

For tests it's important to use `build_app` from app.py because it doesn't
use the `HTTPLoggerMiddleware`. This makes us possible to run tests without
write permissions in `/var/log/nailgun`.

The commit also removes the obsolete `paste` package from dependencies.

Change-Id: I401ef74abc95961d5687d12835752b881ef0e7ef
Closes-Bug: #1396685
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/64/139664/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/requirements.txt', 'nailgun/nailgun/test/integration/test_db_refresh.py']",2,f90bce6bb7dd33df7569dcb76ffe870f59170bc5,bug/1396685,from webtest.app import TestAppfrom nailgun.app import build_app,from paste.fixture import TestAppfrom nailgun.wsgi import build_app,2,3
openstack%2Fswift~feature%2Fec~Ic1cb4756bae015bf24402d9feeff88ec91e67e87,openstack/swift,feature/ec,Ic1cb4756bae015bf24402d9feeff88ec91e67e87,EC: GET path in object server,ABANDONED,2014-09-27 13:45:59.000000000,2014-12-10 07:30:12.000000000,,"[{'_account_id': 3}, {'_account_id': 5189}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-09-27 13:45:59.000000000', 'files': ['swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/18dbc830ab7854f6cdaddcc025d7bcceea32f5dd', 'message': 'EC: GET path in object server\n\nGET response should indicate multiple data file were founded\n\nChange-Id: Ic1cb4756bae015bf24402d9feeff88ec91e67e87\n'}]",0,124596,18dbc830ab7854f6cdaddcc025d7bcceea32f5dd,5,3,1,5189,,,0,"EC: GET path in object server

GET response should indicate multiple data file were founded

Change-Id: Ic1cb4756bae015bf24402d9feeff88ec91e67e87
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/124596/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/diskfile.py'],1,18dbc830ab7854f6cdaddcc025d7bcceea32f5dd,bp/swift-ec," data_file_list = [join(datadir, af) for af in files if af.endswith('.data')] return data_file_list, meta_file, ts_file data_file_list, meta_file, ts_file = self._get_ondisk_file() if data_file_list: data_file = data_file_list[0] else: data_file = None if len(data_file_list) > 1: version_list = [path.split('/')[-1].rstrip('.data') for path in data_file_list] self._metadata.update({'X-EC-Multiversion': version_list})"," return data_file, meta_file, ts_file data_file, meta_file, ts_file = self._get_ondisk_file()",10,2
openstack%2Fhorizon~master~I4e46bb4c3a3b1a1958224fc329631bfce5444c80,openstack/horizon,master,I4e46bb4c3a3b1a1958224fc329631bfce5444c80,Imported Translations from Transifex,MERGED,2014-12-10 06:03:41.000000000,2014-12-10 07:25:15.000000000,2014-12-10 07:25:14.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-12-10 06:03:41.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/feea493eba8c8bb6b724070179e2f6712f0890ac', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4e46bb4c3a3b1a1958224fc329631bfce5444c80\n'}]",0,140580,feea493eba8c8bb6b724070179e2f6712f0890ac,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I4e46bb4c3a3b1a1958224fc329631bfce5444c80
",git fetch https://review.opendev.org/openstack/horizon refs/changes/80/140580/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,feea493eba8c8bb6b724070179e2f6712f0890ac,transifex/translations,"""POT-Creation-Date: 2014-12-09 21:09-0600\n"" ""PO-Revision-Date: 2014-12-09 09:39+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: api/neutron.py:859#: api/neutron.py:896#: api/neutron.py:1035#: api/neutron.py:1053#: api/neutron.py:1068msgid ""The container cannot be deleted since it is not empty."" msgstr """" #: api/swift.py:320 msgid ""The pseudo folder cannot be deleted since it is not empty."" msgstr """"#: dashboards/project/instances/tables.py:973#: dashboards/project/images/templates/images/images/_create.html:13 #: dashboards/project/images/templates/images/images/_update.html:11#: dashboards/project/images/templates/images/images/_create.html:33 #: dashboards/project/images/templates/images/images/_update.html:17#: dashboards/project/instances/tables.py:992#: dashboards/project/access_and_security/floating_ips/tables.py:220#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:116#: dashboards/project/data_processing/job_executions/tables.py:143#: dashboards/project/instances/tables.py:934 #: dashboards/project/instances/tables.py:956#: dashboards/project/access_and_security/floating_ips/tables.py:200#: dashboards/project/data_processing/job_executions/tables.py:158#: dashboards/project/instances/tables.py:968#: dashboards/project/stacks/tables.py:117 #: dashboards/project/stacks/tables.py:154 #: dashboards/project/stacks/tables.py:201#: dashboards/project/instances/tables.py:935#: dashboards/project/instances/tables.py:958#: dashboards/project/images/templates/images/images/_create.html:18#: dashboards/project/images/templates/images/images/_create.html:22#: dashboards/project/images/templates/images/images/_create.html:26#: dashboards/project/images/templates/images/images/_create.html:32#: dashboards/project/images/templates/images/images/_update.html:16#: dashboards/project/images/templates/images/images/_update.html:12#: dashboards/project/instances/tables.py:936#: dashboards/project/instances/tables.py:937#: dashboards/project/access_and_security/floating_ips/tables.py:192#: dashboards/project/instances/tables.py:960#: dashboards/project/instances/tables.py:963#: dashboards/project/instances/tables.py:975#: dashboards/project/instances/tables.py:982#: dashboards/project/instances/tables.py:985 usage/tables.py:78#: dashboards/project/instances/views.py:209 #: dashboards/project/instances/views.py:351#: dashboards/project/instances/tables.py:618#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:320#: dashboards/project/stacks/tables.py:108#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:190 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:319#: dashboards/project/access_and_security/floating_ips/tables.py:198#: dashboards/project/access_and_security/floating_ips/tables.py:149#: dashboards/project/access_and_security/floating_ips/tables.py:153 #: dashboards/project/instances/tables.py:612#: dashboards/project/access_and_security/floating_ips/tables.py:159#: dashboards/project/access_and_security/floating_ips/tables.py:163#: dashboards/project/access_and_security/floating_ips/tables.py:179#: dashboards/project/access_and_security/floating_ips/tables.py:180#: dashboards/project/access_and_security/floating_ips/tables.py:181#: dashboards/project/access_and_security/floating_ips/tables.py:196#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:321#: dashboards/project/data_processing/job_executions/tables.py:117#: dashboards/project/data_processing/job_executions/tables.py:167#: dashboards/project/data_processing/job_executions/tables.py:38#: dashboards/project/data_processing/job_executions/tables.py:46#: dashboards/project/data_processing/job_executions/tables.py:59 #: dashboards/project/data_processing/job_executions/tables.py:88#: dashboards/project/data_processing/job_executions/tables.py:67 #: dashboards/project/data_processing/job_executions/tables.py:96#: dashboards/project/data_processing/job_executions/tables.py:73#: dashboards/project/data_processing/job_executions/tables.py:102#: dashboards/project/data_processing/job_executions/tables.py:149#: dashboards/project/data_processing/job_executions/tables.py:153#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:189 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:318#: dashboards/project/data_processing/nodegroup_templates/workflows/copy.py:83#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:118#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:123#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:125#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:150#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:165#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:191#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:299#: dashboards/project/instances/tables.py:803 #: dashboards/project/instances/tables.py:810 #: dashboards/project/instances/views.py:365#: dashboards/project/stacks/tables.py:112#: dashboards/project/instances/views.py:262#: dashboards/project/images/templates/images/images/_create.html:16#: dashboards/project/images/templates/images/images/_create.html:24#: dashboards/project/instances/tables.py:606#: dashboards/project/instances/tables.py:609#: dashboards/project/instances/tables.py:619#: dashboards/project/instances/tables.py:621#: dashboards/project/instances/tables.py:633#: dashboards/project/instances/tables.py:649 #: dashboards/project/instances/views.py:362#: dashboards/project/instances/tables.py:666#: dashboards/project/instances/tables.py:674#: dashboards/project/instances/tables.py:696#: dashboards/project/instances/tables.py:705#: dashboards/project/instances/tables.py:726#: dashboards/project/instances/tables.py:734#: dashboards/project/instances/tables.py:757#: dashboards/project/instances/tables.py:765#: dashboards/project/instances/tables.py:794#: dashboards/project/instances/tables.py:818 #: dashboards/project/instances/tables.py:840#: dashboards/project/instances/tables.py:819#: dashboards/project/instances/tables.py:820#: dashboards/project/instances/tables.py:822#: dashboards/project/instances/tables.py:823#: dashboards/project/instances/tables.py:824#: dashboards/project/instances/tables.py:826#: dashboards/project/instances/tables.py:828#: dashboards/project/instances/tables.py:830#: dashboards/project/instances/tables.py:831#: dashboards/project/instances/tables.py:833#: dashboards/project/instances/tables.py:834#: dashboards/project/instances/tables.py:835#: dashboards/project/instances/tables.py:837#: dashboards/project/instances/tables.py:838#: dashboards/project/instances/tables.py:839#: dashboards/project/instances/tables.py:842#: dashboards/project/instances/tables.py:843#: dashboards/project/instances/tables.py:845#: dashboards/project/instances/tables.py:851#: dashboards/project/instances/tables.py:853#: dashboards/project/instances/tables.py:855#: dashboards/project/instances/tables.py:856#: dashboards/project/instances/tables.py:858#: dashboards/project/instances/tables.py:860#: dashboards/project/instances/tables.py:862#: dashboards/project/instances/tables.py:864#: dashboards/project/instances/tables.py:866#: dashboards/project/instances/tables.py:868#: dashboards/project/instances/tables.py:870#: dashboards/project/instances/tables.py:872#: dashboards/project/instances/tables.py:874#: dashboards/project/instances/tables.py:876#: dashboards/project/instances/tables.py:878#: dashboards/project/instances/tables.py:880#: dashboards/project/instances/tables.py:881#: dashboards/project/instances/tables.py:883#: dashboards/project/instances/tables.py:884#: dashboards/project/instances/tables.py:885 #: dashboards/project/instances/tables.py:888#: dashboards/project/instances/tables.py:887#: dashboards/project/instances/tables.py:890#: dashboards/project/instances/tables.py:892#: dashboards/project/instances/tables.py:893#: dashboards/project/instances/tables.py:895#: dashboards/project/instances/tables.py:897#: dashboards/project/instances/tables.py:899#: dashboards/project/instances/tables.py:901#: dashboards/project/instances/tables.py:902#: dashboards/project/instances/tables.py:903#: dashboards/project/instances/tables.py:905#: dashboards/project/instances/tables.py:906#: dashboards/project/instances/tables.py:907#: dashboards/project/instances/tables.py:909#: dashboards/project/instances/tables.py:911#: dashboards/project/instances/tables.py:913#: dashboards/project/instances/tables.py:915#: dashboards/project/instances/tables.py:919#: dashboards/project/instances/tables.py:920#: dashboards/project/instances/tables.py:921#: dashboards/project/instances/tables.py:922#: dashboards/project/instances/tables.py:923#: dashboards/project/instances/tables.py:924#: dashboards/project/instances/tables.py:925#: dashboards/project/instances/tables.py:926#: dashboards/project/instances/tables.py:927#: dashboards/project/instances/tables.py:928#: dashboards/project/instances/tables.py:965#: dashboards/project/instances/views.py:152#: dashboards/project/instances/views.py:167#: dashboards/project/instances/views.py:178#: dashboards/project/instances/views.py:189#: dashboards/project/instances/views.py:276#: dashboards/project/instances/views.py:297#: dashboards/project/instances/views.py:306#: dashboards/project/instances/views.py:315#: dashboards/project/instances/views.py:323#: dashboards/project/instances/views.py:376#: dashboards/project/stacks/tables.py:105#: dashboards/project/stacks/tables.py:126#: dashboards/project/stacks/tables.py:143 #: dashboards/project/stacks/tables.py:188#: dashboards/project/stacks/tables.py:146 #: dashboards/project/stacks/tables.py:191#: dashboards/project/stacks/tables.py:149#: dashboards/project/stacks/tables.py:157 #: dashboards/project/stacks/tables.py:206#: dashboards/project/stacks/tables.py:161#: dashboards/project/stacks/tables.py:194#: dashboards/project/stacks/tables.py:196#: dashboards/project/stacks/tables.py:219#: dashboards/settings/dashboard.py:22 templates/_header.html:39#: templates/500.html:74 templates/_header.html:46#: templates/_header.html:21#: templates/_header.html:54","""POT-Creation-Date: 2014-12-05 20:04-0600\n"" ""PO-Revision-Date: 2014-12-09 00:51+0000\n"" ""Last-Translator: Tom Fifield <tom@openstack.org>\n""#: api/neutron.py:849#: api/neutron.py:886#: api/neutron.py:1025#: api/neutron.py:1043#: api/neutron.py:1058msgid ""The container cannot be deleted since it's not empty."" msgstr ""The container cannot be deleted since it's not empty.""#: dashboards/project/instances/tables.py:974#: dashboards/project/images/templates/images/images/_create.html:19 #: dashboards/project/images/templates/images/images/_update.html:17#: dashboards/project/images/templates/images/images/_create.html:40 #: dashboards/project/images/templates/images/images/_update.html:24#: dashboards/project/instances/tables.py:993#: dashboards/project/access_and_security/floating_ips/tables.py:221#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:115#: dashboards/project/data_processing/job_executions/tables.py:135#: dashboards/project/instances/tables.py:935 #: dashboards/project/instances/tables.py:957#: dashboards/project/access_and_security/floating_ips/tables.py:201#: dashboards/project/data_processing/job_executions/tables.py:150#: dashboards/project/instances/tables.py:969#: dashboards/project/stacks/tables.py:113 #: dashboards/project/stacks/tables.py:150 #: dashboards/project/stacks/tables.py:197#: dashboards/project/instances/tables.py:936#: dashboards/project/instances/tables.py:959#: dashboards/project/images/templates/images/images/_create.html:24#: dashboards/project/images/templates/images/images/_create.html:28#: dashboards/project/images/templates/images/images/_create.html:32#: dashboards/project/images/templates/images/images/_create.html:39#: dashboards/project/images/templates/images/images/_update.html:23#: dashboards/project/images/templates/images/images/_update.html:18#: dashboards/project/instances/tables.py:937#: dashboards/project/instances/tables.py:938#: dashboards/project/access_and_security/floating_ips/tables.py:193#: dashboards/project/instances/tables.py:961#: dashboards/project/instances/tables.py:964#: dashboards/project/instances/tables.py:976#: dashboards/project/instances/tables.py:983#: dashboards/project/instances/tables.py:986 usage/tables.py:78#: dashboards/project/instances/views.py:208 #: dashboards/project/instances/views.py:350#: dashboards/project/instances/tables.py:619#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:319#: dashboards/project/stacks/tables.py:104#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:189 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:318#: dashboards/project/access_and_security/floating_ips/tables.py:199#: dashboards/project/access_and_security/floating_ips/tables.py:150#: dashboards/project/access_and_security/floating_ips/tables.py:154 #: dashboards/project/instances/tables.py:613#: dashboards/project/access_and_security/floating_ips/tables.py:160#: dashboards/project/access_and_security/floating_ips/tables.py:164#: dashboards/project/access_and_security/floating_ips/tables.py:180#: dashboards/project/access_and_security/floating_ips/tables.py:181#: dashboards/project/access_and_security/floating_ips/tables.py:182#: dashboards/project/access_and_security/floating_ips/tables.py:197#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:320#: dashboards/project/data_processing/job_executions/tables.py:159#: dashboards/project/data_processing/job_executions/tables.py:34#: dashboards/project/data_processing/job_executions/tables.py:42#: dashboards/project/data_processing/job_executions/tables.py:55 #: dashboards/project/data_processing/job_executions/tables.py:84#: dashboards/project/data_processing/job_executions/tables.py:63 #: dashboards/project/data_processing/job_executions/tables.py:92#: dashboards/project/data_processing/job_executions/tables.py:69#: dashboards/project/data_processing/job_executions/tables.py:98#: dashboards/project/data_processing/job_executions/tables.py:141#: dashboards/project/data_processing/job_executions/tables.py:145#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:188 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:317#: dashboards/project/data_processing/nodegroup_templates/workflows/copy.py:78#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:117#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:122#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:124#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:149#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:164#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:190#: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:298#: dashboards/project/instances/tables.py:804 #: dashboards/project/instances/tables.py:811 #: dashboards/project/instances/views.py:364#: dashboards/project/stacks/tables.py:108#: dashboards/project/instances/views.py:261#: dashboards/project/images/templates/images/images/_create.html:22#: dashboards/project/images/templates/images/images/_create.html:30#: dashboards/project/instances/tables.py:607#: dashboards/project/instances/tables.py:610#: dashboards/project/instances/tables.py:620#: dashboards/project/instances/tables.py:622#: dashboards/project/instances/tables.py:634#: dashboards/project/instances/tables.py:650 #: dashboards/project/instances/views.py:361#: dashboards/project/instances/tables.py:667#: dashboards/project/instances/tables.py:675#: dashboards/project/instances/tables.py:697#: dashboards/project/instances/tables.py:706#: dashboards/project/instances/tables.py:727#: dashboards/project/instances/tables.py:735#: dashboards/project/instances/tables.py:758#: dashboards/project/instances/tables.py:766#: dashboards/project/instances/tables.py:795#: dashboards/project/instances/tables.py:819 #: dashboards/project/instances/tables.py:841#: dashboards/project/instances/tables.py:820#: dashboards/project/instances/tables.py:821#: dashboards/project/instances/tables.py:823#: dashboards/project/instances/tables.py:824#: dashboards/project/instances/tables.py:825#: dashboards/project/instances/tables.py:827#: dashboards/project/instances/tables.py:829#: dashboards/project/instances/tables.py:831#: dashboards/project/instances/tables.py:832#: dashboards/project/instances/tables.py:834#: dashboards/project/instances/tables.py:835#: dashboards/project/instances/tables.py:836#: dashboards/project/instances/tables.py:838#: dashboards/project/instances/tables.py:839#: dashboards/project/instances/tables.py:840#: dashboards/project/instances/tables.py:843#: dashboards/project/instances/tables.py:844#: dashboards/project/instances/tables.py:846#: dashboards/project/instances/tables.py:852#: dashboards/project/instances/tables.py:854#: dashboards/project/instances/tables.py:856#: dashboards/project/instances/tables.py:857#: dashboards/project/instances/tables.py:859#: dashboards/project/instances/tables.py:861#: dashboards/project/instances/tables.py:863#: dashboards/project/instances/tables.py:865#: dashboards/project/instances/tables.py:867#: dashboards/project/instances/tables.py:869#: dashboards/project/instances/tables.py:871#: dashboards/project/instances/tables.py:873#: dashboards/project/instances/tables.py:875#: dashboards/project/instances/tables.py:877#: dashboards/project/instances/tables.py:879#: dashboards/project/instances/tables.py:881#: dashboards/project/instances/tables.py:882#: dashboards/project/instances/tables.py:884#: dashboards/project/instances/tables.py:885#: dashboards/project/instances/tables.py:886 #: dashboards/project/instances/tables.py:889#: dashboards/project/instances/tables.py:888#: dashboards/project/instances/tables.py:891#: dashboards/project/instances/tables.py:893#: dashboards/project/instances/tables.py:894#: dashboards/project/instances/tables.py:896#: dashboards/project/instances/tables.py:898#: dashboards/project/instances/tables.py:900#: dashboards/project/instances/tables.py:902#: dashboards/project/instances/tables.py:903#: dashboards/project/instances/tables.py:904#: dashboards/project/instances/tables.py:906#: dashboards/project/instances/tables.py:907#: dashboards/project/instances/tables.py:908#: dashboards/project/instances/tables.py:910#: dashboards/project/instances/tables.py:912#: dashboards/project/instances/tables.py:914#: dashboards/project/instances/tables.py:916#: dashboards/project/instances/tables.py:920#: dashboards/project/instances/tables.py:921#: dashboards/project/instances/tables.py:922#: dashboards/project/instances/tables.py:923#: dashboards/project/instances/tables.py:924#: dashboards/project/instances/tables.py:925#: dashboards/project/instances/tables.py:926#: dashboards/project/instances/tables.py:927#: dashboards/project/instances/tables.py:928#: dashboards/project/instances/tables.py:929#: dashboards/project/instances/tables.py:966#: dashboards/project/instances/views.py:151#: dashboards/project/instances/views.py:166#: dashboards/project/instances/views.py:177#: dashboards/project/instances/views.py:188#: dashboards/project/instances/views.py:275#: dashboards/project/instances/views.py:296#: dashboards/project/instances/views.py:305#: dashboards/project/instances/views.py:314#: dashboards/project/instances/views.py:322#: dashboards/project/instances/views.py:375#: dashboards/project/stacks/tables.py:101#: dashboards/project/stacks/tables.py:122#: dashboards/project/stacks/tables.py:139 #: dashboards/project/stacks/tables.py:184#: dashboards/project/stacks/tables.py:142 #: dashboards/project/stacks/tables.py:187#: dashboards/project/stacks/tables.py:145#: dashboards/project/stacks/tables.py:153 #: dashboards/project/stacks/tables.py:202#: dashboards/project/stacks/tables.py:157#: dashboards/project/stacks/tables.py:190#: dashboards/project/stacks/tables.py:192#: dashboards/project/stacks/tables.py:215#: dashboards/settings/dashboard.py:22 templates/_header.html:37#: templates/500.html:74 templates/_header.html:44#: templates/_header.html:20#: templates/_header.html:52",3505,3420
openstack%2Fproject-config~master~If7244319894784217d133216bd5cd6392d749a8a,openstack/project-config,master,If7244319894784217d133216bd5cd6392d749a8a,Add networking-arisa project to StackForge,MERGED,2014-12-09 20:54:20.000000000,2014-12-10 07:15:14.000000000,2014-12-10 07:15:13.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6558}]","[{'number': 1, 'created': '2014-12-09 20:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a40d4c0ac05d401146874e5b0ff38800db9b3419', 'message': ""Add networking_arisa project to StackForge\n\nThis repo will be used for the development of back-end of ML2 Drivers\nas well L3 Service Plguin for Arista.\n\nThe need for this repo is inline with the spec approval[1] which proposes\nto decouple vendor's back-end code from the Neutron code repository.\n\n[1] https://review.openstack.org/#/c/134680/\n\nChange-Id: If7244319894784217d133216bd5cd6392d749a8a\n""}, {'number': 2, 'created': '2014-12-10 00:49:44.000000000', 'files': ['gerrit/acls/stackforge/networking-arista.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ad7d45260e342fe97232fdcbc87b89a808da7be5', 'message': ""Add networking-arisa project to StackForge\n\nThis repo will be used for the development of back-end of ML2 Drivers\nas well L3 Service Plguin for Arista.\n\nThe need for this repo is inline with the spec approval[1] which proposes\nto decouple vendor's back-end code from the Neutron code repository.\n\n[1] https://review.openstack.org/#/c/134680/\n\nChange-Id: If7244319894784217d133216bd5cd6392d749a8a\n""}]",0,140473,ad7d45260e342fe97232fdcbc87b89a808da7be5,12,4,2,6558,,,0,"Add networking-arisa project to StackForge

This repo will be used for the development of back-end of ML2 Drivers
as well L3 Service Plguin for Arista.

The need for this repo is inline with the spec approval[1] which proposes
to decouple vendor's back-end code from the Neutron code repository.

[1] https://review.openstack.org/#/c/134680/

Change-Id: If7244319894784217d133216bd5cd6392d749a8a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/73/140473/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/stackforge/networking-arista.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",4,a40d4c0ac05d401146874e5b0ff38800db9b3419,, - name: stackforge/networking-arista template: - name: merge-check - name: python-jobs ,,29,0
openstack%2Ftripleo-incubator~master~I07be1301c95c5c994834858c0a20731dc92eb49d,openstack/tripleo-incubator,master,I07be1301c95c5c994834858c0a20731dc92eb49d,Whitespace cleanup,ABANDONED,2014-08-21 22:54:10.000000000,2014-12-10 07:14:48.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 6039}, {'_account_id': 6348}, {'_account_id': 8449}, {'_account_id': 9369}, {'_account_id': 9453}, {'_account_id': 13945}, {'_account_id': 14123}]","[{'number': 1, 'created': '2014-08-21 22:54:10.000000000', 'files': ['scripts/devtest_end.sh', 'scripts/devtest_seed.sh', 'scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_setup.sh', 'scripts/devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f39b8c718f45086a4750545febe948ec25473824', 'message': ""Whitespace cleanup\n\nIn an unrelated changed I noticed that some of our scripts have lines\nwith trailing whitespace after a ##, to avoid unexpected indentation\nerrors from sphinx.\n\nFor the most part this is unnecessary, a pure blank line works just as\nwell (and doesn't have trailing whitespace), so I've removed those\nlines.\n\nChange-Id: I07be1301c95c5c994834858c0a20731dc92eb49d\n""}]",0,116124,f39b8c718f45086a4750545febe948ec25473824,16,10,1,9453,,,0,"Whitespace cleanup

In an unrelated changed I noticed that some of our scripts have lines
with trailing whitespace after a ##, to avoid unexpected indentation
errors from sphinx.

For the most part this is unnecessary, a pure blank line works just as
well (and doesn't have trailing whitespace), so I've removed those
lines.

Change-Id: I07be1301c95c5c994834858c0a20731dc92eb49d
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/24/116124/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_end.sh', 'scripts/devtest_seed.sh', 'scripts/devtest_undercloud.sh', 'scripts/devtest_variables.sh', 'scripts/devtest_setup.sh', 'scripts/devtest.sh']",6,f39b8c718f45086a4750545febe948ec25473824,whitespace_cleanup,,## ## ## ## ## ## ,45,45
openstack%2Fnova~master~I4165b040658c6eb83bc2fa9b7c92de0a644ab502,openstack/nova,master,I4165b040658c6eb83bc2fa9b7c92de0a644ab502,Do not merge: Check microversion deco order,ABANDONED,2014-12-09 10:21:14.000000000,2014-12-10 07:13:44.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 10:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6da6124da7b2e494b59a843c8f1f3b27464d2d82', 'message': 'Do not merge: Check microversion deco order\n\nwsgi.api_version() is necessary to be put as the first decorator\non the TODO. This patch tests it on the gate.\nIf the TODO is true, test_microversions2_later_version should be\nfailed.\n\nChange-Id: I4165b040658c6eb83bc2fa9b7c92de0a644ab502\n'}, {'number': 2, 'created': '2014-12-09 11:20:31.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b9d66706fcb7ced38f22f90e04f9fbe65e7428bb', 'message': 'Do not merge: Check microversion deco order\n\nwsgi.api_version() is necessary to be put as the first decorator\non the TODO. This patch tests it on the gate.\nIf the TODO is true, test_microversions_post_validation_error_with_header\nshould be failed.\n\nChange-Id: I4165b040658c6eb83bc2fa9b7c92de0a644ab502\n'}]",0,140288,b9d66706fcb7ced38f22f90e04f9fbe65e7428bb,15,7,2,6167,,,0,"Do not merge: Check microversion deco order

wsgi.api_version() is necessary to be put as the first decorator
on the TODO. This patch tests it on the gate.
If the TODO is true, test_microversions_post_validation_error_with_header
should be failed.

Change-Id: I4165b040658c6eb83bc2fa9b7c92de0a644ab502
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/140288/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py']",2,6da6124da7b2e494b59a843c8f1f3b27464d2d82,add-unit-test," @wsgi.Controller.api_version(""2.5"", ""3.1"") # noqa"," @wsgi.Controller.api_version(""2.5"", ""3.1"") # noqa",1,3
openstack%2Ftempest~master~Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1,openstack/tempest,master,Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1,Do not merge: Test v2.1 API on the gate,ABANDONED,2014-10-29 05:34:56.000000000,2014-12-10 07:12:52.000000000,,"[{'_account_id': 3}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-29 05:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/38f12cfe456d722f10557e32d644f2c6516c614d', 'message': 'Do not merge: Test v2.1 API on the gate\n\nThis patch makes v2 API tests enable against Nova v2.1 API on the gate.\nThrough these tests, we can know backwards incompatible changes from\nv2.0 API and working items for v2.1 API development.\n\nChange-Id: Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1\n'}, {'number': 2, 'created': '2014-11-28 04:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8b030a0f253cd5d5a81fc75c05fc7247a10ba886', 'message': 'Do not merge: Test v2.1 API on the gate\n\nThis patch makes v2 API tests enable against Nova v2.1 API on the gate.\nThrough these tests, we can know backwards incompatible changes from\nv2.0 API and working items for v2.1 API development.\n\nChange-Id: Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1\n'}, {'number': 3, 'created': '2014-11-28 11:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c8c23aab8ae45c0364b7e12318c3280f3f1f6c1', 'message': 'Do not merge: Test v2.1 API on the gate\n\nThis patch makes v2 API tests enable against Nova v2.1 API on the gate.\nThrough these tests, we can know backwards incompatible changes from\nv2.0 API and working items for v2.1 API development.\n\nChange-Id: Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1\n'}, {'number': 4, 'created': '2014-12-03 13:18:01.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dbf1fa98faf6f9af57882c31096d3562a97af9c0', 'message': 'Do not merge: Test v2.1 API on the gate\n\nThis patch makes v2 API tests enable against Nova v2.1 API on the gate.\nThrough these tests, we can know backwards incompatible changes from\nv2.0 API and working items for v2.1 API development.\n\nChange-Id: Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1\n'}]",0,131639,dbf1fa98faf6f9af57882c31096d3562a97af9c0,49,7,4,6167,,,0,"Do not merge: Test v2.1 API on the gate

This patch makes v2 API tests enable against Nova v2.1 API on the gate.
Through these tests, we can know backwards incompatible changes from
v2.0 API and working items for v2.1 API development.

Change-Id: Ibac6af9aca621ace624fd08ef1070b9e2d0abaf1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/39/131639/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/config.py']",2,38f12cfe456d722f10557e32d644f2c6516c614d,use_compute_service_type," default='computev21', default=False,"," default='compute', default=True,",4,4
openstack%2Fnova-specs~master~If26bd38a1130494015d4d4fbbbd83db7a5ce781f,openstack/nova-specs,master,If26bd38a1130494015d4d4fbbbd83db7a5ce781f,The end goal of Nova API policy improvement,ABANDONED,2014-10-15 05:41:52.000000000,2014-12-10 07:10:53.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 9060}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-10-15 05:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5b0fe2457fa6788bc1926d855609ff38d4f0fdf8', 'message': 'The end goal of Nova API policy improvement\n\nThis spec provide a full view of the end goal for nova API policy\nimprovement.\n\nPart of blueprint v3-api-policy\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: If26bd38a1130494015d4d4fbbbd83db7a5ce781f\n'}, {'number': 2, 'created': '2014-10-15 07:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8ee5081390656a97260b949dffe7502bba3b9b87', 'message': 'The end goal of Nova API policy improvement\n\nThis spec provide a full view of the end goal for nova API policy\nimprovement.\n\nPart of blueprint v3-api-policy\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: If26bd38a1130494015d4d4fbbbd83db7a5ce781f\n'}, {'number': 3, 'created': '2014-10-24 06:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f6a9f63a2a825ad37db3132034622942368c56c1', 'message': 'The end goal of Nova API policy improvement\n\nThis spec provide a full view of the end goal for nova API policy\nimprovement.\n\nPart of blueprint v3-api-policy\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: If26bd38a1130494015d4d4fbbbd83db7a5ce781f\n'}, {'number': 4, 'created': '2014-11-10 07:51:37.000000000', 'files': ['specs/kilo/approved/the-end-goal-of-api-policy.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1ec0c08d1eea8097bee49ed8ef0ad4f53016beea', 'message': 'The end goal of Nova API policy improvement\n\nThis spec provide a full view of the end goal for nova API policy\nimprovement.\n\nPart of blueprint v3-api-policy\nPart of blueprint separated-policy-rule-v3-api\n\nChange-Id: If26bd38a1130494015d4d4fbbbd83db7a5ce781f\n'}]",16,128560,1ec0c08d1eea8097bee49ed8ef0ad4f53016beea,18,7,4,5754,,,0,"The end goal of Nova API policy improvement

This spec provide a full view of the end goal for nova API policy
improvement.

Part of blueprint v3-api-policy
Part of blueprint separated-policy-rule-v3-api

Change-Id: If26bd38a1130494015d4d4fbbbd83db7a5ce781f
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/60/128560/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/the-end-goal-of-api-policy.rst'],1,5b0fe2457fa6788bc1926d855609ff38d4f0fdf8,bp/v3-api-policy,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== The End Goal of Nova API Policy =============================== https://blueprints.launchpad.net/nova/+spec/v3-api-policy https://blueprints.launchpad.net/openstack/?searchtext=separated-policy-rule-v3-api There are some of ideas and requirements from Icehouse summit to improve the current nova API policy. This spec aims to provide a full view for the improvement of nova API policy to ensure the final goal is on the right way. There are two sub-specs for more detail: https://review.openstack.org/127160 https://review.openstack.org/127863 Problem description =================== There are several problems for current API policy. * The permission checking is spread through the various levels of the nova code, also have some hard-code permission checking that make some polcy rules didn't work. * API policy rules need better granularity. Some of extensions just use one rule for all the APIs. Deployer can't get better granularity control for the APIs. * More easy way to override default policy settings for deployer. And Currently all the API(EC2, V2, V2.1) rules mix in one policy.conf file. Use Cases --------- 1. Operator want to specified role can access service API, but it's hard-code as only admin can operator those API. 2. One policy rule for one API at REST API layer. Multiple rules in different layer really confuse the developer and deployer. 3. Deployer can specified separated rule for each API in one extension. 4. Deployer can override the default policy rule easily without mix his own config and default config in one policy.conf file. Project Priority ---------------- The kilo priorities list is currently not defined. However under the currently proposed list of priorities it would fall under ""User Experience"" as it significantly increases the ability for us to improve the Nova API. Proposed change =============== The generic rule for all the improvement is keep V2 API back-compatible. The improvement just for EC2 and V2.1 API. Because V2 API may be depreciated after V2.1 parity with V2. And reduce the risk of broken what we have for now. * Enforcement policy at REST API layer and remove hard-code permission checks. Remove the permission checking from low layers of nova. This make better usability for API policy. The detail describes at: https://review.openstack.org/127160 * Use different prefix in policy rule name for EC2/V2/V2.1 API. After move all the policy into REST API layer, then all the API won't share some policy enforcement in the compute API layer. So it's time group them. We can provide different prefix in rule name for each API. * EC2 API: We name the policy rule as ""ec2_api:[action]"" * Nova V2 API: After we move to V2.1, we needn't spend time to change V2 api rule, and needn't to bother deployer upgrade their policy config. So just keep V2 API poicy rule named as before. * Nova V2.1 API: We name the policy rule as ""os_compute_api:[extension]:[action]"". The core API may be changed in the future, so we needn't name them as ""compute"" or ""compute_extension"" to distinguish the core or extension API. * Port policy.d from oslo-incubator into nova. The policy.d already implement at oslo-incubator: https://review.openstack.org/#/c/105362/ This feature make deployer can override default policy rule easily. And When nova default policy config changed, deployer only need replace default policy config files with new one. It won't affect his own policy config in other files. * Group the policy rules into different policy files. After support policy.d we can separated the policy rules as separated files, then deployer will more clear for which rule he can set for specified API. The rules can be grouped as below: * policy.conf: It only contains the generic rule, like: :: ""context_is_admin"": ""role:admin"", ""admin_or_owner"": ""is_admin:True or project_id:%(project_id)s"", ""default"": ""rule:admin_or_owner"", * policy.d/00-ec2-api.conf: It contains all the policy rules for EC2 API. * policy.d/00-v2-api.conf: It contains all the policy rules for nova V2 API. * policy.d/00-v2.1-api.conf: It contains all the policy rules for nova v2.1 API. * Add separated rule for each API in extension. This is for provider better granularity for policy rules. The detail at: https://review.openstack.org/127863 Alternatives ------------ The alternative is the status quo which is confusing for both deployers as well as developers having to maintain the current implementation Data model impact ----------------- None REST API impact --------------- None Security impact --------------- All of those improvement aims to provide more clear and easier way to config API policy, that reduce the mistake happened when change policy config. There are more detail for separated propose at: https://review.openstack.org/127160 https://review.openstack.org/127863 These improvements will require very rigorous double checking and high quality reviews to ensure that security bugs are not introduced as the nova internal calls can be called from quite a few different code paths (Ec2, V2 API, V2.1 API and other internals). Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ There are more detail for separated propose at: https://review.openstack.org/127160 https://review.openstack.org/127863 Other deployer impact --------------------- The policy config for V2 will keep the same as before(except removing db layer hard-code permission checks). So this won't affect deployer they only running V2 API. For EC2 API, there will be some change for it. The policy rule name will be changed, that need deployer upgrade his config files. But the EC2 API isn't very big, so it isn't too hard thing. For V2.1 will have a lot of changes, but currently the v2.1 is only experimental, so there isn't actually user will running it as production environment. Developer impact ---------------- After those improvement, nova will have more clear way to add permission checks. Implementation ============== Assignee(s) ----------- Primary assignee: Alex Xu <xuhj@linux.vnet.ibm.com> Work Items ---------- * Porting policy.d into nova from oslo-incubator * Policy enforcement at REST API layer: https://review.openstack.org/127160 * Group the policy rules. * Add separated policy rule for each API: https://review.openstack.org/127863 Dependencies ============ None Testing ======= There are more detail for separated propose at: https://review.openstack.org/127160 https://review.openstack.org/127863 Documentation Impact ==================== We should document the new policy config files structs in Cloud Admin Document. And we should doc all the changes for existed policy rule in upgrade document. There are more detail for separated propose at: https://review.openstack.org/127160 https://review.openstack.org/127863 References ========== ",,230,0
openstack%2Fkeystonemiddleware~master~I139c6f0602d3258ac65ffe54bc0e7c3f82d14264,openstack/keystonemiddleware,master,I139c6f0602d3258ac65ffe54bc0e7c3f82d14264,Auth token tests create temp cert directory,MERGED,2014-09-18 00:36:32.000000000,2014-12-10 06:28:58.000000000,2014-12-10 06:28:58.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-09-18 00:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/aca1d08ce95f010311aa9fa99ba36b55c590aaa9', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 2, 'created': '2014-09-25 23:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/189f8a8693e71f07d04561bdbca207ebef082334', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 3, 'created': '2014-10-27 15:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ba3d504da9180824224c3e5cdf0b4c9be7713f32', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 4, 'created': '2014-10-30 01:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/25547ea1610b8af1fd8e53ef4ac94e19e3bc4f77', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 5, 'created': '2014-10-30 12:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d61353514a093f13c664ed7020e51382c182f5a4', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 6, 'created': '2014-11-18 22:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/5d782c914d837984911c9a71bc9ad79b59bf662a', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 7, 'created': '2014-12-02 15:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/e0d13e6004dfe1f38db3b93e60e4a4ac08b0f316', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}, {'number': 8, 'created': '2014-12-09 02:07:37.000000000', 'files': ['keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ee477d461f41ea18889bdf4e907bc7e50d609898', 'message': ""Auth token tests create temp cert directory\n\nThe auth token tests were using the example signing directory as the\ndefault signing directory. This is dangerous because the auth token\nmiddleware may write to the directory in the course of the tests.\nWith this change, a temporary directory is created for each test\nthat's populated with the sample files.\n\nTest this by doing `chmod -w examples/pki/certs` before running the\ntests.\n\nChange-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264\n""}]",2,122280,ee477d461f41ea18889bdf4e907bc7e50d609898,31,6,8,6486,,,0,"Auth token tests create temp cert directory

The auth token tests were using the example signing directory as the
default signing directory. This is dangerous because the auth token
middleware may write to the directory in the course of the tests.
With this change, a temporary directory is created for each test
that's populated with the sample files.

Test this by doing `chmod -w examples/pki/certs` before running the
tests.

Change-Id: I139c6f0602d3258ac65ffe54bc0e7c3f82d14264
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/80/122280/2 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/test_auth_token_middleware.py'],1,aca1d08ce95f010311aa9fa99ba36b55c590aaa9,cleanup," signing_dir = self._setup_signing_directory() 'signing_dir': signing_dir, def _setup_signing_directory(self): directory_name = tempfile.mkdtemp() self.addCleanup(shutil.rmtree, directory_name) # Copy the sample certificate files into the temporary directory. for filename in ['cacert.pem', 'signing_cert.pem', ]: shutil.copy2(os.path.join(client_fixtures.CERTDIR, filename), os.path.join(directory_name, filename)) return directory_name "," 'signing_dir': client_fixtures.CERTDIR, with tempfile.NamedTemporaryFile(dir=self.middleware._signing_dirname, delete=False) as f: pass self.middleware._revoked_file_name = f.name self.addCleanup(cleanup_revoked_file, self.middleware._revoked_file_name) 'signing_dir': client_fixtures.CERTDIR, 'signing_dir': client_fixtures.CERTDIR,",14,11
openstack%2Fopenstack-manuals~master~Ibdb42813bd2dc6f240b08afa0b1cac9ff5be90af,openstack/openstack-manuals,master,Ibdb42813bd2dc6f240b08afa0b1cac9ff5be90af,Imported Translations from Transifex,MERGED,2014-12-10 06:13:37.000000000,2014-12-10 06:27:45.000000000,2014-12-10 06:27:45.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2014-12-10 06:13:37.000000000', 'files': ['doc/image-guide/locale/image-guide.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/image-guide/locale/fr.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dbc0080f10dabf70fdd4123713178ddb9c841d49', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibdb42813bd2dc6f240b08afa0b1cac9ff5be90af\n'}]",0,140582,dbc0080f10dabf70fdd4123713178ddb9c841d49,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibdb42813bd2dc6f240b08afa0b1cac9ff5be90af
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/140582/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/image-guide/locale/image-guide.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/image-guide/locale/fr.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po', 'doc/image-guide/locale/ja.po']",9,dbc0080f10dabf70fdd4123713178ddb9c841d49,transifex/translations,"""POT-Creation-Date: 2014-12-10 04:44+0000\n"" ""PO-Revision-Date: 2014-12-10 04:41+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""""href=\""https://getfedora.org/en/cloud/download/\""/>. The images include the ""msgstr """"","""POT-Creation-Date: 2014-12-07 06:37+0000\n"" ""PO-Revision-Date: 2014-12-08 02:41+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""""href=\""http://cloud.fedoraproject.org/\""/>. The images include the ""msgstr ""Fedora <link href=\""http://cloud.fedoraproject.org/\""/> <systemitem class=\""process\"">cloud-init</systemitem>  <systemitem class=\""username\"">fedora</systemitem> <placeholder-1/>""",590,364
openstack%2Fneutron-lbaas~master~Icd7a614fa62811f990204c38cb5e0029feab9772,openstack/neutron-lbaas,master,Icd7a614fa62811f990204c38cb5e0029feab9772,"Test review, do not merge",ABANDONED,2014-12-03 21:52:22.000000000,2014-12-10 06:27:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-03 21:52:22.000000000', 'files': ['DO_NOT_MERGE'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ff6c65325f96252c19dfc37c7992f129e16672eb', 'message': 'Test review, do not merge\n\nChange-Id: Icd7a614fa62811f990204c38cb5e0029feab9772\n'}]",0,138870,ff6c65325f96252c19dfc37c7992f129e16672eb,7,3,1,10980,,,0,"Test review, do not merge

Change-Id: Icd7a614fa62811f990204c38cb5e0029feab9772
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/70/138870/1 && git format-patch -1 --stdout FETCH_HEAD,['DO_NOT_MERGE'],1,ff6c65325f96252c19dfc37c7992f129e16672eb,,,,0,0
openstack%2Ftaskflow~master~Id27c23d79d7fdbcd677ed959d9d817c796a0828c,openstack/taskflow,master,Id27c23d79d7fdbcd677ed959d9d817c796a0828c,Remove rtype from task clone() doc,MERGED,2014-12-09 08:15:41.000000000,2014-12-10 05:48:26.000000000,2014-12-10 05:48:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-09 08:15:41.000000000', 'files': ['taskflow/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f333e1b2aacd8d5ed8efca76af6fc6d2e4535538', 'message': ""Remove rtype from task clone() doc\n\nThe sphinx docs don't seem to show this parameter\ncorrectly when building the html docs so instead of\nshowing it just remove since the return type should\nbe pretty obvious due to the surronding text.\n\nChange-Id: Id27c23d79d7fdbcd677ed959d9d817c796a0828c\n""}]",0,140264,f333e1b2aacd8d5ed8efca76af6fc6d2e4535538,6,2,1,1297,,,0,"Remove rtype from task clone() doc

The sphinx docs don't seem to show this parameter
correctly when building the html docs so instead of
showing it just remove since the return type should
be pretty obvious due to the surronding text.

Change-Id: Id27c23d79d7fdbcd677ed959d9d817c796a0828c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/64/140264/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/task.py'],1,f333e1b2aacd8d5ed8efca76af6fc6d2e4535538,,, :rtype: task,0,1
openstack%2Fdiskimage-builder~master~I57ea529cf387ab8ec8497d35be19ac64198df47a,openstack/diskimage-builder,master,I57ea529cf387ab8ec8497d35be19ac64198df47a,Improve --ramdisk-element docs,MERGED,2014-12-01 16:22:54.000000000,2014-12-10 05:44:59.000000000,2014-12-10 05:44:58.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 9369}, {'_account_id': 12459}]","[{'number': 1, 'created': '2014-12-01 16:22:54.000000000', 'files': ['bin/disk-image-create'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ff2a89215e79cb326182fb62de0098ea0f70a920', 'message': ""Improve --ramdisk-element docs\n\nUnlike most of the options to disk-image-create, this one didn't\ndocument its default value, and it also didn't have any context for\nwhy one might use it.\n\nChange-Id: I57ea529cf387ab8ec8497d35be19ac64198df47a\nRelated-Bug: 1397073\n""}]",0,138114,ff2a89215e79cb326182fb62de0098ea0f70a920,9,4,1,6928,,,0,"Improve --ramdisk-element docs

Unlike most of the options to disk-image-create, this one didn't
document its default value, and it also didn't have any context for
why one might use it.

Change-Id: I57ea529cf387ab8ec8497d35be19ac64198df47a
Related-Bug: 1397073
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/14/138114/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/disk-image-create'],1,ff2a89215e79cb326182fb62de0098ea0f70a920,bug/1397073," echo "" Defaults to 'ramdisk'. Should be set to 'dracut-ramdisk' for platforms such"" echo "" as RHEL and CentOS that do not package busybox.""",,2,0
openstack%2Fdiskimage-builder~master~I57d4a007efee9624e60c41357cefa627d8c7373f,openstack/diskimage-builder,master,I57d4a007efee9624e60c41357cefa627d8c7373f,Migrate to new package-installs,MERGED,2014-11-26 21:38:56.000000000,2014-12-10 05:44:46.000000000,2014-12-10 05:44:44.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-11-26 21:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/153c2d6d1f436711b37e8641f8f09b2df5d5366d', 'message': 'Migrate to new package-installs\n\nWe have a new package-installs file format. Migrating existing\npackage-installs files to the new format.\n\nChange-Id: I57d4a007efee9624e60c41357cefa627d8c7373f\n'}, {'number': 2, 'created': '2014-11-26 21:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/1ba9145f0351466754a1c7b1c983e10c93b12783', 'message': 'Migrate to new package-installs\n\nWe have a new package-installs file format. Migrating existing\npackage-installs files to the new format.\n\nChange-Id: I57d4a007efee9624e60c41357cefa627d8c7373f\n'}, {'number': 3, 'created': '2014-11-26 21:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b448dd32e1e3e7c7363c38a4f278029d84216c36', 'message': 'Migrate to new package-installs\n\nWe have a new package-installs file format. Migrating existing\npackage-installs files to the new format.\n\nChange-Id: I57d4a007efee9624e60c41357cefa627d8c7373f\n'}, {'number': 4, 'created': '2014-11-27 00:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9aa9ca71d409a7db1c72c227a8c3e25dc78131f9', 'message': 'Migrate to new package-installs\n\nWe have a new package-installs file format. Migrating existing\npackage-installs files to the new format.\n\nChange-Id: I57d4a007efee9624e60c41357cefa627d8c7373f\n'}, {'number': 5, 'created': '2014-12-01 22:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/47a5571049ea83259d08b1a3d5f0c133b8ecc289', 'message': 'Migrate to new package-installs\n\nWe have a new package-installs file format. Migrating existing\npackage-installs files to the new format.\n\nChange-Id: I57d4a007efee9624e60c41357cefa627d8c7373f\n'}, {'number': 6, 'created': '2014-12-02 05:31:15.000000000', 'files': ['elements/fedora/package-installs.yaml', 'elements/redhat-common/install.d/package-installs-redhat-common', 'elements/svc-map/pre-install.d/package-installs-svc-map', 'elements/redhat-common/pre-install.d/package-installs-redhat-common', 'elements/deploy-baremetal/package-installs.yaml', 'elements/deploy-kexec/install.d/package-installs-deploy-kexec', 'elements/deploy-kexec/package-installs.yaml', 'elements/hwdiscovery/package-installs.yaml', 'elements/stable-interface-names/install.d/package-installs-stable-interface-names', 'elements/deploy-baremetal/install.d/package-installs-deploy-baremetal', 'elements/source-repositories/package-installs.yaml', 'elements/deploy-ironic/package-installs.yaml', 'elements/stable-interface-names/package-installs.yaml', 'elements/hwdiscovery/install.d/package-installs-hwdiscovery', 'elements/dracut-network/package-installs.yaml', 'elements/opensuse/package-installs.yaml', 'elements/redhat-common/package-installs.yaml', 'elements/deploy-ironic/install.d/package-installs-deploy-ironic', 'elements/svc-map/package-installs.yaml', 'elements/dracut-network/install.d/package-installs-dracut-network'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/26266069801986a35a07200790bb597b5dffc513', 'message': 'Migrate to new package-installs\n\nWe have a new package-installs file format. Migrating existing\npackage-installs files to the new format.\n\nChange-Id: I57d4a007efee9624e60c41357cefa627d8c7373f\n'}]",0,137478,26266069801986a35a07200790bb597b5dffc513,28,5,6,10035,,,0,"Migrate to new package-installs

We have a new package-installs file format. Migrating existing
package-installs files to the new format.

Change-Id: I57d4a007efee9624e60c41357cefa627d8c7373f
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/78/137478/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/opensuse/install.d/package-installs-opensuse', 'elements/source-repositories/install.d/package-installs-source-repositories', 'elements/redhat-common/pre-install.d/package-installs-redhat-common', 'elements/deploy-kexec/package-installs.yaml', 'elements/fedora/install.d/package-installs-fedora', 'elements/hwdiscovery/package-installs.yaml', 'elements/stable-interface-names/install.d/package-installs-stable-interface-names', 'elements/source-repositories/package-installs.yaml', 'elements/deploy-ironic/package-installs.yaml', 'elements/dracut-network/package-installs.yaml', 'elements/redhat-common/package-installs.yaml', 'elements/deploy-ironic/install.d/package-installs-deploy-ironic', 'elements/svc-map/package-installs.yaml', 'elements/package-installs/bin/package-installs-v2', 'elements/fedora/package-installs.yaml', 'elements/redhat-common/install.d/package-installs-redhat-common', 'elements/svc-map/pre-install.d/package-installs-svc-map', 'elements/deploy-baremetal/package-installs.yaml', 'elements/deploy-kexec/install.d/package-installs-deploy-kexec', 'elements/deploy-baremetal/install.d/package-installs-deploy-baremetal', 'elements/stable-interface-names/package-installs.yaml', 'elements/hwdiscovery/install.d/package-installs-hwdiscovery', 'elements/opensuse/package-installs.yaml', 'elements/dracut-network/install.d/package-installs-dracut-network']",24,153c2d6d1f436711b37e8641f8f09b2df5d5366d,134917,,dracut-network patch ,287,198
openstack%2Fnova~master~Ia499991006fad30f68f06b2cf75e6be33cdfdf51,openstack/nova,master,Ia499991006fad30f68f06b2cf75e6be33cdfdf51,Add more unit test case for microversion,ABANDONED,2014-12-09 07:35:27.000000000,2014-12-10 05:42:28.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 07:35:27.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/073e25a5f8d601a9c7139c0aebc94185a5aed971', 'message': 'Add more unit test case for microversion\n\nAdd new api example and test cases for microversions.\n\nThis test case will prove that no need to let api_version\ndecorator the top decorator(outer one).\n\nPartially implements blueprint api-microversions\nChange-Id: Ia499991006fad30f68f06b2cf75e6be33cdfdf51\n'}]",0,140258,073e25a5f8d601a9c7139c0aebc94185a5aed971,9,7,1,12175,,,0,"Add more unit test case for microversion

Add new api example and test cases for microversions.

This test case will prove that no need to let api_version
decorator the top decorator(outer one).

Partially implements blueprint api-microversions
Change-Id: Ia499991006fad30f68f06b2cf75e6be33cdfdf51
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/140258/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py']",2,073e25a5f8d601a9c7139c0aebc94185a5aed971,bp/api-microversions," @wsgi.response(207) # noqa @wsgi.Controller.api_version(""3.1"", ""3.2"") def index(self, req): data = {'param': 'controller2_val3'} return data ",,21,1
openstack%2Fcinder~master~If82cf0c58d765bf79dbf721ca95c10a468940cab,openstack/cinder,master,If82cf0c58d765bf79dbf721ca95c10a468940cab,Use pbr entry_points to setup the cinder scripts,MERGED,2014-06-20 04:38:55.000000000,2014-12-10 05:33:04.000000000,2014-12-10 05:33:01.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6094}, {'_account_id': 7219}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11047}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12492}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-06-20 04:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bed9010b094a4816660d48a513d8f32b6d4a13a4', 'message': 'WIP: Use pbr entry_points to manage the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 2, 'created': '2014-06-20 04:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e8f1e52b0337180fa0b82b440847bebbe3ee0f7e', 'message': 'WIP: Use pbr entry_points to manage the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 3, 'created': '2014-06-21 19:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/19b56ffd033b08cdb20640d48fed6bb8271a74ed', 'message': 'WIP: Use pbr entry_points to setup the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 4, 'created': '2014-06-21 21:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4254afbd3b66dd97e3a9e8fc959830142950272f', 'message': 'WIP: Use pbr entry_points to setup the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 5, 'created': '2014-06-22 03:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/047a3762408e4ba59f95612cdc84f21b503dc059', 'message': 'WIP: Use pbr entry_points to setup the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 6, 'created': '2014-06-22 04:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/428646a958d94731568a3af1c840a627f05d3939', 'message': 'WIP: Use pbr entry_points to setup the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 7, 'created': '2014-06-25 02:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/149efce466bd1bd0293fef272fa01976b37e3829', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following is the first of a few patches that changes\nhow cinder scripts are installed and unit tested. This\npatch moves all the cinder scripts from bin into\ncinder/cmd and creates entry_points for those scripts\nin setup.cfg. When cinder is installed, these scripts\nwill be installed under /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\nThe relevant unit test cases for each script will follow.\nThis patch allows the setup to be in place before actual\nunit tests are written, as well as break up the code\ncommit into more reviewable patches.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 8, 'created': '2014-07-05 02:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b00437613e2741b72445d8868ea2a77e41bfb0b1', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 9, 'created': '2014-07-05 02:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0aefc94f50066a90486cf41d52e8942bca74972c', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 10, 'created': '2014-07-05 16:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c9d2cdec831f53951be5045ef9b5a596337507db', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 11, 'created': '2014-07-05 16:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e689c028a88999b641cc1cf7c9e751aefd95294', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The requirements for rtslib-fb was set to versions\n2.1.39 or 2.1.40. Otherwise, python 2.6 would throw a\nSyntaxError at rtslib/fabric.py line 120.\n\n6. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 12, 'created': '2014-07-07 20:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ecd6d0bd6f84a0fb512a53f9d0534aef447e21a6', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 13, 'created': '2014-07-07 22:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d2618afbdeb074e2befea809ca1898dca8655178', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 14, 'created': '2014-07-07 22:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1670b3e37b327771f6f9add5b3079654f6b959f7', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 15, 'created': '2014-07-07 23:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f7c5959530096840c0ffc612a2ec4179ab5dd354', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. Disable check_uptodate.sh in run_tests.sh and tox pep8\nso that the gate-cinder-pep8 job can pass. This change was\nmade in nova and heat projects. The mailing list discussion\nsurrounding this can be found at:\nhttp://lists.openstack.org/pipermail/openstack-dev/\n2014-February/026253.html\n\n5. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 16, 'created': '2014-07-15 02:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc174f80a4a30ce3994de1a71b162d19606a7b2a', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 17, 'created': '2014-07-15 03:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6c4df58eef92a01dc84249d61bab43abb267fb0', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 18, 'created': '2014-07-15 03:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d6df3589aabcf6988482df0e472a76c3da738dea', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 19, 'created': '2014-07-15 18:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9aa5c1f22851410cca96560c9dd404a9437d3b40', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 20, 'created': '2014-07-15 18:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f50601f4ff2e91cb12da02b3e03809b27eaf8099', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 21, 'created': '2014-07-15 23:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71aec43d4e47c9500a34cd053beffc04bd8a584b', 'message': 'Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n'}, {'number': 22, 'created': '2014-07-16 00:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15b5d5a3e7922f0d8e29bf3e158fa1338366bcc6', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\n5. Renamed 'host' config option in cinder-volume, which\noverrides the host value for multiple-storage backends, with\n'backend_host' because it conflicted with another 'host'\nconfig option.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host'\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 23, 'created': '2014-07-16 13:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b4b82222da6a0d3c13ec56afdff8c063b1488e5b', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\n5. Renamed 'host' config option in cinder-volume, which\noverrides the host value for multiple-storage backends, with\n'backend_host' because it conflicted with another 'host'\nconfig option.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host'\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 24, 'created': '2014-07-16 15:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ee6fff6982de37aa55129b40293798263a827726', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\n5. Renamed 'host' config option in cinder-volume, which\noverrides the host value for multiple-storage backends, with\n'backend_host' because it conflicted with another 'host'\nconfig option.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host'\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 25, 'created': '2014-07-19 18:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/870a77fcad8e792218b748124a05e4ce78e3e85f', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\n5. Renamed 'host' config option in cinder-volume, which\noverrides the host value for multiple-storage backends, with\n'backend_host' because it conflicted with another 'host'\nconfig option.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host'\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 26, 'created': '2014-07-20 05:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8dc42ef235d8dbd3ba371e12f6e7446b05f4a92a', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\n5. Renamed 'host' config option in cinder-volume, which\noverrides the host value for multiple-storage backends, with\n'backend_host' because it conflicted with another 'host'\nconfig option.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host'\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 27, 'created': '2014-07-22 03:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f03f7579a454be58346e6e6d3b2ee03f4b8d046', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nIn this patch:\n\n1. cinder-clear-rabbit-queues is removed because it does\nnot appear to be widely used and there is no user\ndocumentation for it. Also, RabbitMQ now includes a\nmanagement plugin and CLI that allows you to delete\nqueues and exchanges:\n  $> rabbitmqadmin delete queue name=$topic\n  $> rabbitmqadmin delete queue name=$topic.$host\n  $> rabbitmqadmin delete exchange name=nova\nThis script was also removed in nova as part of\nhttps://review.openstack.org/#/c/40355/.\n\n2. reattach function in cinder-manage is removed because\nit should be in nova-manage. This is noted in bug #1167931.\n\n3. cinder-rpc-zmq-receiver is removed as part of the\nswitch to oslo.messaging. It is now replaced with\noslo-messaging-zmq-receiver.\n\n4. The relevant unit test cases for each script are created.\n\n5. Renamed 'host' config option in cinder-volume, which\noverrides the host value for multiple-storage backends, with\n'backend_host' because it conflicted with another 'host'\nconfig option.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host'\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 28, 'created': '2014-07-29 20:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/64ea5935a071bcc6d66976a7499ced66d55b2660', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 29, 'created': '2014-08-07 19:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1d39e516580f6ccb71bc8c1c0287b5b02a22bd97', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 30, 'created': '2014-08-08 02:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/774f637b2565a79516b334b4a450ce7319fe6bc4', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 31, 'created': '2014-08-08 03:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/037da14bd9497d8923783e842f7e1800752a8e47', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 32, 'created': '2014-08-13 04:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6a94ec0367d9e07b1bc4e23d02ce413623c240b4', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 33, 'created': '2014-08-18 23:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f29d3bc6ee9956797a0cbc79ed4bfc7fb69bfb0', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 34, 'created': '2014-08-19 00:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/196b08ad27b16afbcfef0c948188fd57cd07f4d7', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 35, 'created': '2014-08-19 14:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/159266f37f11757f22c660626afd78a2de3d1140', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for mutliple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 36, 'created': '2014-08-29 20:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e584739aff15f7ee189faa7ea7cc30319efb771e', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 37, 'created': '2014-09-23 19:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74455f4c5fe2a94aebeff4bcb9c04d49222b5a0c', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 38, 'created': '2014-10-10 04:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb2277604530ac2f39c8d63e10f33d788dbf8f3f', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 39, 'created': '2014-10-29 01:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22d949a15714d567cee75c312c9c57cc40906505', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 40, 'created': '2014-11-10 14:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a1d8272999d7ae3bc1f8c3e452439b51d25fbb33', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 41, 'created': '2014-12-01 17:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba51945fc0697211042f9e24551c4c9ca68a4631', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 42, 'created': '2014-12-05 20:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/efeff57fc6754e00ec94ca237917fcbd228aeb53', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}, {'number': 43, 'created': '2014-12-08 14:54:01.000000000', 'files': ['cinder/cmd/volume_usage_audit.py', 'cinder/cmd/volume.py', 'cinder/cmd/api.py', 'cinder/cmd/scheduler.py', 'cinder/cmd/manage.py', 'cinder/test.py', 'cinder/tests/test_cmd.py', 'run_tests.sh', 'cinder/cmd/all.py', 'cinder/cmd/__init__.py', 'setup.cfg', 'cinder/cmd/rtstool.py', 'tox.ini', 'cinder/cmd/backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5fb266a0dac0c4c6538ee2661cb186a5c0fe6d6a', 'message': ""Use pbr entry_points to setup the cinder scripts\n\nThe following patch changes how cinder scripts are\ninstalled and unit tested. This patch moves all the\ncinder scripts from bin into cinder/cmd and creates\nentry_points for those scripts in setup.cfg. When\ncinder is installed, these scripts will be installed\nunder /usr/local/bin by pbr.\n\nDocImpact: 'host' config option for multiple-storage backends\nin cinder.conf is renamed to 'backend_host' in order to avoid\na naming conflict with the 'host' to locate redis\nChange-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab\nImplements: blueprint unit-test-cases-for-cinder-scripts\n""}]",36,101412,5fb266a0dac0c4c6538ee2661cb186a5c0fe6d6a,289,26,43,8247,,,0,"Use pbr entry_points to setup the cinder scripts

The following patch changes how cinder scripts are
installed and unit tested. This patch moves all the
cinder scripts from bin into cinder/cmd and creates
entry_points for those scripts in setup.cfg. When
cinder is installed, these scripts will be installed
under /usr/local/bin by pbr.

DocImpact: 'host' config option for multiple-storage backends
in cinder.conf is renamed to 'backend_host' in order to avoid
a naming conflict with the 'host' to locate redis
Change-Id: If82cf0c58d765bf79dbf721ca95c10a468940cab
Implements: blueprint unit-test-cases-for-cinder-scripts
",git fetch https://review.opendev.org/openstack/cinder refs/changes/12/101412/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/cmd/volume_usage_audit.py', 'cinder/cmd/volume.py', 'cinder/cmd/api.py', 'cinder/cmd/scheduler.py', 'cinder/cmd/manage.py', 'cinder/cmd/rpc_zmq_receiver.py', 'cinder/cmd/clear_rabbit_queues.py', 'cinder/cmd/cinder_all.py', 'cinder/cmd/__init__.py', 'setup.cfg', 'cinder/cmd/rtstool.py', 'cinder/cmd/backup.py']",12,bed9010b094a4816660d48a513d8f32b6d4a13a4,bp/unit-test-cases-for-cinder-scripts,def main(): if __name__ == '__main__': main()," # If ../cinder/__init__.py exists, add ../ to Python search path, so that # it will override what happens to be installed in /usr/(local/)lib/python... possible_topdir = os.path.normpath(os.path.join(os.path.abspath(sys.argv[0]), os.pardir, os.pardir)) if os.path.exists(os.path.join(possible_topdir, 'cinder', '__init__.py')): sys.path.insert(0, possible_topdir) if __name__ == '__main__':",52,95
openstack%2Fcinder~master~I51808f3c468cc0d3e0227569c26ecf761d51abba,openstack/cinder,master,I51808f3c468cc0d3e0227569c26ecf761d51abba,Add Nimbus-iSCSI support for Cinder volume driver,ABANDONED,2014-07-10 13:36:03.000000000,2014-12-10 04:57:15.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 6043}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11496}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12499}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-07-10 13:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e53964a9cd4075217b6c5c3589dfea68beb2238e', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 2, 'created': '2014-07-15 12:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1207d09b6f4f3cdbe067b2c5c88b120670da76d8', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 3, 'created': '2014-07-16 09:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbb7d8537402b14c38ff96b0f06cd56f564bc3b7', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 4, 'created': '2014-07-18 14:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/56ae24276f2e3f0f683b5685e55eb8a58a489414', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 5, 'created': '2014-07-22 10:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8020bb53ac88a5ef5bf623c6e2f558d061139d6d', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 6, 'created': '2014-08-05 14:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a67686dadb191495cbafbe7186492910f37d705f', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 7, 'created': '2014-08-06 07:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/76d1919eb15131103d5a031ff478dc78c5eddfc5', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 8, 'created': '2014-08-08 12:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e7a546bb6d142ad7491cddfc55630ae41cd9fa5b', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 9, 'created': '2014-08-11 08:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3c170675db3de7d979da0e8c181ccd796de32026', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 10, 'created': '2014-08-12 09:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e91e1f22a7c426515b28bc68ad41e66551778c6', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 11, 'created': '2014-08-19 07:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/09e25f91b827b88468d6dada6617e309230cbc76', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 12, 'created': '2014-08-22 06:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2db5df8ec057b843eab72018f2f823e01b6e0179', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}, {'number': 13, 'created': '2014-09-03 10:53:51.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/nimbus/iscsi.py', 'cinder/volume/drivers/nimbus/haloapi.py', 'cinder/volume/drivers/nimbus/utils.py', 'cinder/tests/test_nimbus_iscsi.py', 'cinder/volume/drivers/nimbus/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6b3518922975cc612c975833e77800b49bd1c5bd', 'message': ""Add Nimbus-iSCSI support for Cinder volume driver\n\nThe set of changes introduces the cinder iSCSI volume driver support for\nNimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a\nbackend store. It implements the minimum set of features required by the\nicehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for\nmore information.\nImplements: blueprint nimbus-iscsi-cinder-driver\n\nChange-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba\n""}]",13,106056,6b3518922975cc612c975833e77800b49bd1c5bd,91,15,13,11496,,,0,"Add Nimbus-iSCSI support for Cinder volume driver

The set of changes introduces the cinder iSCSI volume driver support for
NimbusData's HALO Flash Storage Array (Gemini All-Flash Arrays) as a
backend store. It implements the minimum set of features required by the
icehouse release. Please see the blueprint nimbus-iscsi-cinder-driver for
more information.
Implements: blueprint nimbus-iscsi-cinder-driver

Change-Id: I51808f3c468cc0d3e0227569c26ecf761d51abba
",git fetch https://review.opendev.org/openstack/cinder refs/changes/56/106056/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/nimbus/options.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/nimbus/iscsi.py', 'cinder/volume/drivers/nimbus/haloapi.py', 'cinder/volume/drivers/nimbus/utils.py', 'cinder/tests/test_nimbus_iscsi.py', 'cinder/volume/drivers/nimbus/__init__.py']",7,e53964a9cd4075217b6c5c3589dfea68beb2238e,bp/nimbus-iscsi-cinder-driver,,,1706,0
openstack%2Fopenstack-manuals~master~I09379f5cdf90ef8ccfa88468b961b10a966c9412,openstack/openstack-manuals,master,I09379f5cdf90ef8ccfa88468b961b10a966c9412,"Removal of passive voice from chap 1, arch guide",MERGED,2014-12-09 03:06:45.000000000,2014-12-10 04:43:51.000000000,2014-12-10 04:43:50.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 9162}, {'_account_id': 10897}]","[{'number': 1, 'created': '2014-12-09 03:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a1fb6f73e605c23973c6a7511d931a31041651bb', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from ch_generalpurpose\n\nChange-Id: I09379f5cdf90ef8ccfa88468b961b10a966c9412\nPartial-bug: #1400550\n'}, {'number': 2, 'created': '2014-12-09 03:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d84cddb9aac189eb3abf92b05e0c68a5f811788', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from ch_generalpurpose\n\nChange-Id: I09379f5cdf90ef8ccfa88468b961b10a966c9412\nPartial-bug: #1400550\n'}, {'number': 3, 'created': '2014-12-09 21:39:34.000000000', 'files': ['doc/arch-design/ch_generalpurpose.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2b3659ab774ac395c176b4a4f25db26b42ba2c80', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from ch_generalpurpose\n\nChange-Id: I09379f5cdf90ef8ccfa88468b961b10a966c9412\nPartial-bug: #1400550\n'}]",1,140213,2b3659ab774ac395c176b4a4f25db26b42ba2c80,13,4,3,10607,,,0,"Removal of passive voice from chap 1, arch guide

Removal of passive voice from ch_generalpurpose

Change-Id: I09379f5cdf90ef8ccfa88468b961b10a966c9412
Partial-bug: #1400550
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/140213/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/ch_generalpurpose.xml'],1,a1fb6f73e605c23973c6a7511d931a31041651bb,asettle/bug1400550," starting point for building a cloud deployment. They are designed to balance the components and do not emphasize any particular aspect of the overall computing environment. Compute, network, and storage components are expected to be given equal weight in the design. General purpose clouds are found in private, public, and hybrid environments, lending themselves to many different use cases. </para> <note> <para> General purpose clouds are homogeneous deployments and are not suited to specialized environments or edge case situations. </para> </note> <para> Common uses of a general purpose cloud include: </para> <itemizedlist> <listitem> <para> Providing a simple database </para> </listitem> <listitem> <para> A web application runtime environment </para> </listitem> <listitem> <para> A shared application development platform </para> </listitem> <listitem> <para> Lab test bed </para> </listitem> </itemizedlist> <para>Use cases that benefit from scale-out rather than scale-up approaches are good candidates for general purpose cloud architecture. </para> <para>A general purpose cloud is designed to have a range of potential uses or functions; not specialized for specific use cases. General purpose architecture is designed to address 80% of potential use cases available. The infrastructure, in itself, is a specific use case, enabling it to be used as a base model for the design process. General purpose clouds are designed to be platforms that are suited for general purpose applications.</para>"," starting point for building a cloud deployment. General purpose clouds, by their nature, balance the components and do not emphasize (or heavily emphasize) any particular aspect of the overall computing environment. The expectation is that the compute, network, and storage components will be given equal weight in the design. General purpose clouds can be found in private, public, and hybrid environments. They lend themselves to many different use cases but, since they are homogeneous deployments, they are not suited to specialized environments or edge case situations. Common uses to consider for a general purpose cloud could be, but are not limited to, providing a simple database, a web application runtime environment, a shared application development platform, or lab test bed. In other words, any use case that would benefit from a scale-out rather than a scale-up approach is a good candidate for a general purpose cloud architecture.</para> <para>A general purpose cloud, by definition, is something that is designed to have a range of potential uses or functions; not specialized for a specific use. General purpose architecture is largely considered a scenario that would address 80% of the potential use cases. The infrastructure, in itself, is a specific use case. It is also a good place to start the design process. As the most basic cloud service model, general purpose clouds are designed to be platforms suited for general purpose applications.</para>",50,26
openstack%2Fopenstack-manuals~master~I24a1021ce68803e73f97bd0ec81dfd67cb15195d,openstack/openstack-manuals,master,I24a1021ce68803e73f97bd0ec81dfd67cb15195d,Use new download URL for Fedora cloud images,MERGED,2014-12-09 15:24:04.000000000,2014-12-10 04:39:26.000000000,2014-12-10 04:39:25.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-09 15:24:04.000000000', 'files': ['doc/image-guide/ch_obtaining_images.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/36caa7fea3247d1bf155f4c0941f5c8c7ccbb11e', 'message': 'Use new download URL for Fedora cloud images\n\nWith the release of Fedora 21 the cloud images are now available at\nhttps://getfedora.org/en/cloud/download/.\n\nChange-Id: I24a1021ce68803e73f97bd0ec81dfd67cb15195d\n'}]",0,140367,36caa7fea3247d1bf155f4c0941f5c8c7ccbb11e,7,4,1,167,,,0,"Use new download URL for Fedora cloud images

With the release of Fedora 21 the cloud images are now available at
https://getfedora.org/en/cloud/download/.

Change-Id: I24a1021ce68803e73f97bd0ec81dfd67cb15195d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/140367/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/ch_obtaining_images.xml'],1,36caa7fea3247d1bf155f4c0941f5c8c7ccbb11e,download_url_fedora_image," <link xlink:href=""https://getfedora.org/en/cloud/download/"" />. The images"," <link xlink:href=""http://cloud.fedoraproject.org/"" />. The images",1,1
openstack%2Fneutron-specs~master~Ice535cb335d276af62246daa3c41e1c6d7e23029,openstack/neutron-specs,master,Ice535cb335d276af62246daa3c41e1c6d7e23029,L7 rules support for LBaaS v2,ABANDONED,2014-12-07 09:05:43.000000000,2014-12-10 04:27:29.000000000,,"[{'_account_id': 3}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-07 09:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a72191ccb6cc6a034adfb01abd5e0ab41ea66428', 'message': 'L7 rules support for LBaaS v2\n\nL7 rules capabilities support for LBaaS v2\n\nChange-Id: Ice535cb335d276af62246daa3c41e1c6d7e23029\nImplements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-l7-rules\n'}, {'number': 2, 'created': '2014-12-07 10:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/31ec3055509c522cc3657fda35d8d1f96452fe25', 'message': 'L7 rules support for LBaaS v2\n\nL7 rules capabilities support for LBaaS v2\n\nChange-Id: Ice535cb335d276af62246daa3c41e1c6d7e23029\nImplements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-l7-rules\n'}, {'number': 3, 'created': '2014-12-07 10:19:34.000000000', 'files': ['specs/kilo/lbaas-l7-rules.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/fd61e882108c8765ea5c5e54ea5a76079613cfa6', 'message': 'L7 rules support for LBaaS v2\n\nL7 rules capabilities support for LBaaS v2\n\nChange-Id: Ice535cb335d276af62246daa3c41e1c6d7e23029\nImplements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-l7-rules\n'}]",0,139853,fd61e882108c8765ea5c5e54ea5a76079613cfa6,10,3,3,8446,,,0,"L7 rules support for LBaaS v2

L7 rules capabilities support for LBaaS v2

Change-Id: Ice535cb335d276af62246daa3c41e1c6d7e23029
Implements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-l7-rules
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/53/139853/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/lbaas-l7-rules.rst'],1,a72191ccb6cc6a034adfb01abd5e0ab41ea66428,bp/https,"========================================== LBaaS Layer 7 rules ========================================== Launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/lbaas-l7-rules Layer 7 switching takes its name from the OSI model, indicating that the device switches requests based on layer 7 (application) data. Layer 7 switching is also known as ""request switching"", ""application switching"", and ""content based routing"". A layer 7 switch presents to the outside world a ""virtual server"" that accepts requests on behalf of a number of servers and distributes those requests based on policies that use application data to determine which server should service which request. This allows for the application infrastructure to be specifically tuned/optimized to serve specific types of content. For example, one server can be tuned to serve only images, another for execution of server-side scripting languages like PHP and ASP, and another for static content such as HTML, CSS and JavaScript. Problem description =================== Use Cases: 1. Redirect traffic to a Pool that supports static content (HTML, CSS) 2. Redirect traffic to a Pool that serves images (jpg, png, etc) Proposed change =============== Extend the LBaaS API and support Layer 7 switching. L7 Entities: 1. L7Rule - Set of attributes that defines which part of the request should be matched and how it should be matched. 2. L7Policy - A collection of L7Rules. Holds the action that should be performed when the rules are matched.(Redirect to Pool, Redirect to URL, Reject). L7Policy holds a Listener id, so a Listner can evaluate a collection of L7Policies. L7Policy will return 'true' when all of the L7Rules that belong to this L7Policy are matched. L7Policies under a specific Listener are ordered and the first l7Policy that returns a match will be executed. When none of the policies match the request gets forwarded to listener.default_pool_id Alternatives ------------ None. Data model impact ----------------- Model:: +--------------------+ +--------------------+ | Listener | | L7Policy | +--------------------+ +--------------------+ | | | | | id | | id | | other attributes +--------+ action | | | | pool id | | | | redirect url | | | | listener id | +--------------------+ | index | | | | | +-----------------+--+ | | +------------------+--+ | L7Rule | +---------------------+ | | | id | | l7 policy id | | type | | compare type | | key | | value | | | +---------------------+ Two new entities are introduced: L7Rule and L7Policy The L7Policy is a container of L7Rules. The L7Policy contains a reference to a Listener 1. L7Rule object Data Model. +----------------+--------------+------+-----+---------+ | Field | Type | Null | Key | Default | +================+==============+======+=====+=========+ | id | string(36) | NO | PRI | | +----------------+--------------+------+-----+---------+ | l7_policy_id | string(36) | NO | FK | | +----------------+--------------+------+-----+---------+ | type | Enum (*) | NO | | | +----------------+--------------+------+-----+---------+ | compare_type | Enum (*) | NO | | | +----------------+--------------+------+-----+---------+ | key | string(36) | NO | | | +----------------+--------------+------+-----+---------+ | value | string(36) | YES | | | +----------------+--------------+------+-----+---------+ * type values - Hostname - Path - FileType: This is the file extension. Examples: txt, jpg, png, xls A rule that is looking for text files will look like: type = FileType, compare_type=EqualTo, value = txt - Header - Cookie: This is the value of a specific cookie A rule that is looking for a cookie named 'department' with the value starting with 'finance-' will look like: type = Cookie, compare_type=StartsWith, key = department value = finance- * compare_type values - Regexp - StartsWith - EndsWith - Contains - EqualTo - GreaterThan - LessThan 2. L7Policy object Data Model. +----------------+--------------+------+-----+---------+ | Field | Type | Null | Key | Default | +================+==============+======+=====+=========+ | id | string(36) | NO | PRI | | +----------------+--------------+------+-----+---------+ | listener_id | string(36) | NO | FK | | +----------------+--------------+------+-----+---------+ | action | Enum (*) | NO | | | +----------------+--------------+------+-----+---------+ | pool_id | string(36) | YES | | | +----------------+--------------+------+-----+---------+ | redirect_url | string(256) | YES | | | +----------------+--------------+------+-----+---------+ | index | int | NO | | | +----------------+--------------+------+-----+---------+ * action: [Reject,RedirectToURL,RedirectToPool] * If action is RedirectToURL redirect_url can not be null * If action is RedirectToPool pool_id can not be null * Index - If total policies for this listener is less than index, append to end of list. - Index numbering starts with 0 - If policy with same index number exists, insert the new policy at that index number and increment all policy indexes for this listener with an equal or higher index value. - Not specifying an index appends the policy to the list. REST API impact --------------- l7rule-create Create a L7Rule for a given tenant. Request POST /v2.0/l7rules Accept: application/json .. code-block:: javascript { ""l7rule"":{ ""l7_policy_id"": ""6b96ff0cb17a4b859e1e575d221683c5"", ""type"":""Header"", ""compare_type"":""StartsWith"", ""key"":'department', ""value"":""HR"" } } Response .. code-block:: javascript { ""l7rule"":{ ""id"": ""6b96ff0cb17a4b859e1e575d221683d7"", ""l7_policy_id"": ""6b96ff0cb17a4b859e1e575d221683c5"", ""type"":""Header"", ""compare_type"":""StartsWith"", ""key"":'department', ""value"":""HR"", ""tenant_id"":""6b96ff0cb17a4b859e1e575d2216845"" } } l7rule-show Show information of a given L7Rule. Request GET /v2.0/l7rules/6b96ff0cb17a4b859e1e575d221683d7 Accept: application/json Response .. code-block:: javascript { ""l7rule"":{ ""id"": ""6b96ff0cb17a4b859e1e575d221683d7"", ""l7_policy_id"": ""6b96ff0cb17a4b859e1e575d221683c5"", ""type"":""Header"", ""compare_type"":""StartsWith"", ""key"":'department', ""value"":""HR"" ""tenant_id"":""6b96ff0cb17a4b859e1e575d2216845"" } } l7rule-delete Delete a given L7Rule. Request DELETE /v2.0/l7rules/6b96ff0cb17a4b859e1e575d221683d7 Accept: application/json l7policy-create Create a L7Policy for a given tenant. POST /v2.0/l7policies Accept: application/json .. code-block:: javascript { ""l7policy"":{ ""listener_id"": ""6b96ff0cb17a4b859e1e575d221683c5"", ""action"":""RedirectToPool"", ""pool_id"":6b96ff0cb17a4b859e1e575d22168399, ""index"": 2 } } Response .. code-block:: javascript { ""l7policy"":{ ""id"": ""6b96ff0cb17a4b859e1e575d221683d7"", ""listener_id"": ""6b96ff0cb17a4b859e1e575d221683c5"", ""action"":""RedirectToPool"", ""pool_id"":6b96ff0cb17a4b859e1e575d22168399, ""tenant_id"":""6b96ff0cb17a4b859e1e575d2216845"", ""index"": 2 } } l7policy-show Show information of a given L7Policy. Request GET /v2.0/l7policies/6b96ff0cb17a4b859e1e575d221683d7 Accept: application/json Response .. code-block:: javascript { ""l7policy"":{ ""id"": ""6b96ff0cb17a4b859e1e575d221683d7"", ""listener_id"": ""6b96ff0cb17a4b859e1e575d221683c5"", ""action"":""RedirectToPool"", ""pool_id"":6b96ff0cb17a4b859e1e575d22168399, ""tenant_id"":""6b96ff0cb17a4b859e1e575d2216845"", ""index"": 2 } } l7policy-delete Delete a given L7Policy. Request DELETE /v2.0/l7policies/6b96ff0cb17a4b859e1e575d221683d7 Accept: application/json Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~avishayb Other contributors: **TBD** Work Items ---------- * REST API * DB Schema * LBaaS plugin and driver API * CLI update Dependencies ============ * Depends on the new LBaaS model https://review.openstack.org/#/c/89903/ Testing ======= * REST API and attributes validation tests * DB mixin and schema tests * LBaaS Plugin with mocked driver end-to-end tests * Specific driver tests for each existing driver supporting L7 switching * Tempest tests * CLI tests Documentation Impact ==================== * Neutron API should be modified with L7Rule and L7Policy entities * Neutron CLI should be modified with L7Rule and L7Policy entities References ========== https://wiki.openstack.org/wiki/Neutron/LBaaS/l7",,376,0
openstack%2Fneutron-specs~master~Ic4d53bbec2e99529b9823ad114a0f44e2b5e8752,openstack/neutron-specs,master,Ic4d53bbec2e99529b9823ad114a0f44e2b5e8752,TLS support for LBaaS v2,ABANDONED,2014-12-07 08:51:58.000000000,2014-12-10 04:27:22.000000000,,"[{'_account_id': 3}, {'_account_id': 8446}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-07 08:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/96f4769227a424f9e0803c11a70c10d41dbb422c', 'message': 'TLS support for LBaaS v2\n\nTLS capabilities support specification for LBaaS v2\n\nImplements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination\n\nTLS termination\n\nChange-Id: Ic4d53bbec2e99529b9823ad114a0f44e2b5e8752\n'}, {'number': 2, 'created': '2014-12-07 09:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/37d9e7f1aaf2a7a55ee760067f5c071e2f199d78', 'message': 'TLS support for LBaaS v2\n\nTLS capabilities support specification for LBaaS v2\n\nImplements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination\n\nTLS termination\n\nChange-Id: Ic4d53bbec2e99529b9823ad114a0f44e2b5e8752\n'}, {'number': 3, 'created': '2014-12-07 09:47:26.000000000', 'files': ['specs/kilo/lbaas-tls.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8cf12ccf55330f3d8cb2b7b1feaf6fb7e64261ba', 'message': 'TLS support for LBaaS v2\n\nTLS capabilities support specification for LBaaS v2\n\nImplements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination\n\nTLS termination\n\nChange-Id: Ic4d53bbec2e99529b9823ad114a0f44e2b5e8752\n'}]",0,139852,8cf12ccf55330f3d8cb2b7b1feaf6fb7e64261ba,11,4,3,8446,,,0,"TLS support for LBaaS v2

TLS capabilities support specification for LBaaS v2

Implements: blueprint https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination

TLS termination

Change-Id: Ic4d53bbec2e99529b9823ad114a0f44e2b5e8752
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/52/139852/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/lbaas-tls.rst'],1,96f4769227a424f9e0803c11a70c10d41dbb422c,bp/https,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================== Neutron LBaaS TLS - Specification ================================== BP https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination Terminating TLS connections on the load balancer is a capability expected from modern load balancers and incorporated into many applications. This capability enables better certificate management and improved application based load balancing e.g. cookie-based persistency, L7 Policies appliance, etc. Problem description =================== No TLS offloading capability is available for Neutron LBaaS Proposed change =============== *Note: This document is referencing to the new LBaaS objects model proposed at https://review.openstack.org/#/c/89903* *Note: This document does not consider flavors framework proposed at https://review.openstack.org/#/c/90070 Before the flavors framework is in place, specific back-end driver which does not support TLS capabilities should throw an exception stating a lack of TLS support once it gets request for listener with TLS configuration. This document specifies a ""core"" feature set that every back-end implementing TLS capabilities must comply. TLS capabilities of various back-end implementations may differ in future releases, thus flavors aspect should definitely be part of TLS capabilities specification* *Note: Horizon project aspect is not a part of this specification.* * Tenant will manage his TLS certificates using Barbican. Certificates will be stored in Barbican secure containers. * Barbican is in charge of containers life cycle management, containers classification and validation. LBaaS TLS requires a specific container type (TLS). Only container of this type will be listed to the tenant for selection while configuring listener's TLS containers to use. Any invalid container usage will raise an error. * Barbican will also manage list of interested consumers for each container. See spec at https://review.openstack.org/#/c/99516 Neutron LBaaS (a consumer, according to Barbican's terminology) will not use a regular GET request for container resource in order to get the container. Instead, it will use a POST request to container's consumers resource (http://admin-api/v1/containers/{container-uuid}/consumers) with following info: { ""type"": ""LBaaS"", ""URL"": ""https://lbaas.myurl.net/loadbalancers/<lb_id>/"" } **Note:** We might want to use specific Listener URL instead of Loadbalancer's one, like ""https://lbaas.myurl.net/lbaas/listeners/<listener_id>"" As a response, it will get containers data like container's resource GET request was used. Barbican, in its turn will store consumer's (LBaaS instance URL) data in its database so this info can be used for getting all consumers of a specific TLS container. As a result, Neutron LBaaS TLS implementation is required to: * Use only POST request to container's consumers resource in order to get the container's data. * Perform DELETE request to container's consumers resource when stop using a container. * Barbican TLS container will contain PEM encoded data. Specific back-end implementation might convert the certificates data to other format such as DER, if needed. * In addition to existing HTTP, HTTPS and TCP, new protocol, TERMINATED_HTTPS will be added for listener creation * For tenant, creating listener with TERMINATED_HTTPS as a protocol means desire to offload incoming encrypted traffic. New configuration options will be available for listener's configuration including: * Default TLS container id for TLS termination * TLS containers list for SNI * In case when specific back-end is not able to support TLS capabilities, its driver should throw an exception. The exception message should state that this specific back-end (provider) does not support listeners with TLS offloading. The clear sign of listener's requirement for TLS offloading capabilities is its TERMINATED_HTTPS protocol. * New module will be developed in Neutron LBaaS for Barbican TLS containers interactions. The module will be used by Neutron LBaaS front-end API code and providers' driver code. The module will be used for validation and data extraction from default TLS container and SNI containers. This module represents the only legitimate API for Barbican TLS containers interactions. See 'SNI certificates list management' section for detailed module specification. * When creating listener with TERMINATED_HTTPS protocol: * Front-end TLS offloading is always enabled - hard coded as a default behaviour for listener with TERMINATED_HTTPS protocol * Tenant must supply default TLS container for front-end offloading. Not supplying a container is an invalid configuration. * TLS supported protocols and cipher suites for termination will be set to sane values by each back-end's specific code * SNI certificates list is optional and not mandatory to specify * SNI certificates list specifying is described in ""SNI certificates list management"" section * Certificate intermediate chain will be stored as a part of Barbican's TLS container * Back-end re-encryption will not be supported in first phase * Front-end client authentication and back-end server authentication will not be supported in first phase * When updating listener with TERMINATED_HTTPS protocol: * In TLS configuration domain, default TLS container ID for front-end offloading and SNI container IDs list are values that may be changed * In case when defaut TLS container ID is replaced for the listener, back-end implementation should ensure a lack of a downtime on LB appliance. * Same for changing SNI container IDs list, back-end should avoid LB downtime. * HA-Proxy LBaaS implementaion and other LBaaS implementations should be modified to support this specification. **With stated above, following is a description of a basic tenant use case - creating listener with TLS offloading:** * Tenant cteates Barbican TLS container with a certificate. * Tenant creates listener with TERMINATED_HTTPS as a listener protocol and specifies the Barbican TLS container ID as a default TLS container for front-end offloading * As a result, listener created, offloading encrypted traffic on front-end with default tenant's TLS certificate, not re-encrypting traffic to the back-end. Requirements from Barbican -------------------------- * Tenant should be able to create and delete TLS containers using Barbican * Ability to store TLS certificates in Barbican containers that contain the TLS certificate itself, its private key and optionaly, intermediate chain * Creating TLS container with: * Certificate : PEM text field * Private_key: PEM text_field * (extracted) Private_key_pass_phrase : text field * Intermediates: PEM text field (optional) This field is a concatination of PEM encoded certificate blocks in specific order * Delete TLS certificate **optional:** Check if certificate is in use by any consumer and warn before deleting. Barbican's BP discussing this feature: https://review.openstack.org/#/c/99516/ * Get TLS container, including private key in PEM encoded PKCS1 or PKCS7 formats, by container id * Get TLS certificate in pem encoded x509 format, by container id Alternatives ------------ None Restrictions ------------ * TLS settings are only available for listeners having TERMINATED_HTTPS as a protocol. In other cases TLS settings will be disabled and have None or empty values. There should be a meaningfull error message to a user explaining the exact reason of a failure in case of an invalid configuration. * Listener protocol is immutable. Changing the protocol will require radical re-configuration of provider's back-end system, which seems to be not justified for this use case. Tenant should create new listener. * While updating existing TLS certificate, name and description are only values allowed to be modified. Creating new TLS container and using it instead of the old one will be easier option than re-configuring LBaaS back-end with modified container, at least in first phase. SNI certificates list management -------------------------------- For SNI functionality, tenant will supply list of TLS containers in specific order. In case when specific back-end is not able to support SNI capabilities, its driver should throw an exception. The exception message should state that this specific back-end (provider) does not support SNI capability. The clear sign of listener's requirement for SNI capability is a none empty SNI container ids list. However, reference implementation must support SNI capability. New separate module will be developed in Neutron LBaaS for Barbican TLS containers interactions. The module will use service account for Barbican API interation. The module will have API for: * Ensuring Barbican TLS container existence (used by LBaaS front-end API) * Validating Barbican TLS container (used by LBaaS front-end API) This API will also ""register"" LBaaS as a container's consumer in Barbican's repository. * Extracting SubjectCommonName and SubjectAltName information from certificates X509 (used by LBaaS front-end API) As for now, only dNSName and directoryName types will be extracted from SubjectAltName sequence, while directoryName type usage is an issue for further discussion. * Extracting certificates data from Barbican TLS container (used by provider/driver code) * Unregistering LBaaS as a consumer of the container when container is not used by any listener any more (used by LBaaS front-end API) The module will use pyOpenSSL and PyASN1 packages. Only this new common module should be used by Neutron LBaaS code for Barbican containers interactions. Front-end LBaaS API (plugin) code will use a new developed module for validating Barbican TLS containers. Driver, in its turn, can extract SubjectCommonName and SubjectAltName information from certificates X509 via the common module API and use it for its specific SNI implementation. **Note:** **Specific back-end driver does not have to use SubjectAltName information. Furthermore, specific driver may throw an exception saying SubjectAltName is not supported by its provider** Any specific driver implementation may extract host names info from certificates using the mentioned above common module API only, if needed. **SNI conflicts** Employing the order of certificates list is not a common requirement for all back-end implementations. The order of SNI containers list may be used by specific back-end code, like Radware's, for specifying priorities among certificates. Order is meant to be a hint to resolve conflicts when 2 or more certificates match the DNS name requested in the SNI client hello. Specific backends might choose to ignore this order and might employ their own mechanisms to choose one among the clashing certificates. For ex. NetScaler employs the best match algorithm and does not require order for conflict resolution. It's also possible that specific driver throws an exception saying there is a collision and this specific SNI setup will not be supported by the back-end. Data model impact ----------------- **Data model changes** * *lbaas_listeners* table will be modified with new * default_tls_container_id (nullable string 36) - Barbican's TLS container id * New *lbaas_sni* table will be created for storing ordered list of TLS containers associated to a listener for SNI capabilities. Association objects is composed of: * id (immutable string 36) - generated object id * listener_id (string 36) - associated listener id * tls_container_id (string 36) - associated Barbican TLS container id * position - (integer) index for preserving the order **Required database migration** * add new columns to *lbaas_isteners* table * create new *lbaas_sni* table **New data initial set** * New columns for *lbaas_listeners* table's existing entries will be set to defaults REST API impact --------------- **Listener Attributes** +-------------+-------+---------+---------+------------+----------------------+ |Attribute |Type |Access |Default |Validation/ |Description | |Name | | |Value |Conversion | | +=============+=======+=========+=========+============+======================+ |default-tls- |UUID |RW,tenant|NULL |UUID |default TLS cert id | |container-id | | | | |to use for offloading | +-------------+-------+---------+---------+------------+----------------------+ |sni_container|UUID |RW,tenant|NULL |UUID list |ordered list of | |_ids |list | | | |TLS containers to use | | | | | | |for SNI .| +-------------+-------+---------+---------+------------+----------------------+ **Functions** * create_listener * Creates new listener * Request *POST /v2.0/lbaas/listeners Accept: application/json { ""listener"":{ <...usual listener parameters>, ""protocol"": ""TERMINATED_HTTPS"" ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4j"", ""sni_container_ids"": None } }* * Response *{ ""listener"":{ ""id"": ""8604a0de-7f6b-409a-a47c-a1cc7bc77b2e"" <...usual listener parameters>, ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"": None ""tenant_id"":""6b96ff0cb17a4b859e1e575d221683d3"" } }* * create_listener (with SNI list) * Creates new listener * Request *POST /v2.0/lbaas/listeners Accept: application/json { ""listener"":{ <...usual listener parameters>, ""protocol"": ""TERMINATED_HTTPS"" ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4j"", ""sni_container_ids"": [5404a0de-7f6b-409a-a47c-a1ccgbc77b3j, 1206a0de-7f6b-409a-a47c-a1ccgbc7bgf3] } }* * Response *{ ""listener"":{ ""id"": ""8604a0de-7f6b-409a-a47c-a1cc7bc77b2e"" <...usual listener parameters>, ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"":[5404a0de-7f6b-409a-a47c-a1ccgbc77b3j, 1206a0de-7f6b-409a-a47c-a1ccgbc7bgf3] ""tenant_id"":""6b96ff0cb17a4b859e1e575d221683d3"" } }* * update_listener * Updates VIP listener * Request *PUT /v2.0/lbaas/listeners/<listener-id> Accept: application/json { ""listener"":{ <...usual listener parameters>, ""protocol"": ""TERMINATED_HTTPS"" ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"": None } }* * Response *{ ""listener"":{ ""id"": ""8604a0de-7f6b-409a-a47c-a1cc7bc77b2e"" <...usual listener parameters>, ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"": None ""tenant_id"":""6b96ff0cb17a4b859e1e575d221683d3"" } }* Security impact --------------- Following are security requirements: * Retrieving TLS container from Barbican to LBaaS plugin/driver must be secured * Sending TLS container contents from driver to back-end system must be secured * Storing secrets on neutron server is prohibited * Back-end systems may need to ensure secured store for secrets to meet certain security compliance requirements Notifications impact -------------------- None CLI impact --------------------- * Listener creation with TERMINATED_HTTPS protocol (default behavior) *lb-listener-create* **--protocol TERMINATED_HTTPS** *--protocol-port 443* **--default_tls_container_id 9a96ff0cb17a4b859e1e575d2216cd23** *...<usual CLI options>* * Listener creation with TERMINATED_HTTPS protocol and SNI certificates list *lb-listener-create* **--protocol TERMINATED_HTTPS** *--protocol-port 443* **--default_tls_container_id 9a96ff0cb17a4b859e1e575d2216cd23 --sni_container_ids list=true 6b96ff0cb17a4b859e1e575d221683d3 4596ff0cb17a4b859e1e575d22168ba1** *...<usual CLI options>* Other end user impact --------------------- None Performance Impact ------------------ * When updating listener without modifying TLS settings (default container id or SNI list) - Barbican API should not be used for retrieving container content which was not actually changed. This will prevent unnecessary resources consumption when, for example, members are added to the pool used by listener. It means that each Barbican TLS container will be validated only once for a listener while it's still in use by this listener. Other deployer impact --------------------- * Barbican is required to be deployed and functional in order this feature to work. * New dependencies are added for neutron, pyOpenSSL and PyASN1. These are required by new module for Barbican TLS containers interactions. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~evgenyf Other contributors: Barbican TLS containers interactions module - https://launchpad.net/~carlos-garza Work Items ---------- * Develop new module for BArbican TLS containers interactions using pyOpenSSL and PyASN1 packages. * Implement changes in LBaaS DB schema v2 * Implement changes in LBaaS extension v2 * Implement all required CLI changes * Implement all required unit testing * Implement all required tempest testing * Make integration with Barbican certificates storage API Detailed specificatio of how Barbican's API for containers should be used is at https://review.openstack.org/#/c/99516 * Modifying LBaaS HA-Proxy driver to support TLS capability Detailed specification of this work item is at https://review.openstack.org/#/c/100931 * Use HA-Proxy version 1.5 * Implement horizon part of this spec, not as part of Juno release. Dependencies ============ * Barbican API requirements * Neutron LBaaS API v2 with new listener object implemented * New dependencies will be added for neutron, pyOpenSSL and PyASN1. These are required by new module for Barbican TLS containers interactions. Testing ======= **listener unit testing domains** * REST API and attributes validation tests * DB mixin and schema tests * LBaaS Plugin with mocked driver end-to-end tests * Specific driver tests for each existing driver supporting TLS offloading * Tempest tests * CLI tests Unit testing scenarios * New listener creation with TERMINATED_HTTPS as a protocol * No default TLS container for termination supplied. Check error generation * Default TLS container for termination supplied. Test expected default configuration took place. * Default TLS container supplied. SNI TLS containers list was supplied Test expected configuration took place * Update existing listener with TERMINATED_HTTPS as a protocole * Change default TLS container. Test expected configuration * Add/Modify SNI containers list. Test expected configuration CLI tests should test inconsistency issues such as: * No default offloading TLS container specified when creating listener with TERMINATES_HTTPS protocole Documentation Impact ==================== * Neutron API should be modified with new listener TLS attributes * Neutron CLI should be modified with updated listener commands with TLS options References ========== * TLS RFC http://tools.ietf.org/html/rfc2818 ",,568,0
openstack%2Fneutron~stable%2Fjuno~Id702f2bd737e380308cf6a254c3b25f9f87c058e,openstack/neutron,stable/juno,Id702f2bd737e380308cf6a254c3b25f9f87c058e,iaaaa,ABANDONED,2014-12-10 02:12:22.000000000,2014-12-10 04:17:25.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-10 02:12:22.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6971570f54bcd88c1c9962d2af847b49676c5786', 'message': 'iaaaa\n\nChange-Id: Id702f2bd737e380308cf6a254c3b25f9f87c058e\n'}]",0,140555,6971570f54bcd88c1c9962d2af847b49676c5786,12,10,1,10612,,,0,"iaaaa

Change-Id: Id702f2bd737e380308cf6a254c3b25f9f87c058e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/140555/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,6971570f54bcd88c1c9962d2af847b49676c5786,juno, ,,2,0
openstack%2Fneutron-specs~master~I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e,openstack/neutron-specs,master,I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e,Add Spec for Extra DHCP Options for IPv4 and IPv6,MERGED,2014-10-17 03:13:00.000000000,2014-12-10 04:10:53.000000000,2014-12-10 04:10:53.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1923}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5572}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 7183}, {'_account_id': 10257}]","[{'number': 1, 'created': '2014-10-17 03:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/44014fd2beb7ff2f85e6a40fd07c6bc1438280a2', 'message': 'Add Spec for Extra DHCP Options for IPv4 and IPv6\n\nBP extra-dhcp-opts-ipv4-ipv6\n\nChange-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e\n'}, {'number': 2, 'created': '2014-10-17 03:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d982865c5dd1855a1d3422c540169e9976f32b8a', 'message': 'Add Spec for Extra DHCP Options for IPv4 and IPv6\n\nBP extra-dhcp-opts-ipv4-ipv6\n\nChange-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e\n'}, {'number': 3, 'created': '2014-10-17 06:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3724958a763eb8e98c8b72387608e9888b18ebde', 'message': 'Add Spec for Extra DHCP Options for IPv4 and IPv6\n\nBP extra-dhcp-opts-ipv4-ipv6\n\nChange-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e\n'}, {'number': 4, 'created': '2014-11-11 06:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5f9bfc04f2d9c4f66f0cb0471de78ba6ddfeba05', 'message': 'Add Spec for Extra DHCP Options for IPv4 and IPv6\n\nBP extra-dhcp-opts-ipv4-ipv6\n\nDocImpact\nAPIImpact\n\nChange-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e\n'}, {'number': 5, 'created': '2014-11-12 03:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/15a5c2f73ca0f2b1d5e65b234b5778bb8d84f5ee', 'message': 'Add Spec for Extra DHCP Options for IPv4 and IPv6\n\nBP extra-dhcp-opts-ipv4-ipv6\n\nDocImpact\nAPIImpact\n\nChange-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e\n'}, {'number': 6, 'created': '2014-12-10 02:18:42.000000000', 'files': ['specs/kilo/extra-dhcp-opts-ipv4-ipv6.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/87a641dc9b189b89537984884c1c29c01cbc4319', 'message': 'Add Spec for Extra DHCP Options for IPv4 and IPv6\n\nBP extra-dhcp-opts-ipv4-ipv6\n\nDocImpact\nAPIImpact\n\nChange-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e\n'}]",17,129118,87a641dc9b189b89537984884c1c29c01cbc4319,43,10,6,7183,,,0,"Add Spec for Extra DHCP Options for IPv4 and IPv6

BP extra-dhcp-opts-ipv4-ipv6

DocImpact
APIImpact

Change-Id: I114f6bd63a6cb3edb589f16b3f2e65105c4a1f5e
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/18/129118/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/extra-dhcp-opts-ipv4-ipv6.rst'],1,44014fd2beb7ff2f85e6a40fd07c6bc1438280a2,bp/extra-dhcp-opts-ipv4-ipv6,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Extra DHCP Options for IPv4 and IPv6 ==================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/extra-dhcp-opts-ipv4-ipv6.rst Problem Description =================== A detailed description of the problem: * Currently extra_dhcp_opts only works for DHCPv4 or DHCPv6 address on a port. Since a port can have both IPv4 and IPv6 address, we need to find a new way to specify extra dhcp options for DHCPv4 and DHCPv6, respectively. * There is no validation of DHCP options, therefore any option name and value can be specified for a port. Proposed Change =============== * A new attribute ""ip_version"" will be used in Neutron port create/update extra_dhcp_opts API to specify the IP version of a given DHCP option. * ""ip_version"" will be used to differentiate the option for DHCPv4 or DHCPv6 when processing the DHCP options for a given port. * How to deal with the case that ip_version is not specified: If ""ip_version"" is not specified for a DHCP option, and the port only has IPv4 address, ip_version=4 will be used and the option will be used for DHCPv4 option. If ""ip_version"" is not specified for a DHCP option, and the port only has IPv6 address, ip_version=6 will be used and the option will be used for DHCPv6 option. If the port has both IPv4 and IPv6 address, and ""ip_version"" is not specified, the option will be used for both DHCPv4 and DHCPv6. * Validation of DHCP option: The validation of a DHCP option for a given port will be based on the port's address, allowed option name and allowed option values. Unknow DHCP option names, improper option values (for example, IPv6 dns server for IPv4 port), and wrong ip_version should not be applied with clear error messages. Data Model Impact ----------------- * A new column ""ip_version"" will be added to Neutron extradhcpopts table with Integer type and nullable=True. * Upgrade database migration requires adding this new column and downgrade database migration requires dropping this new column. * The defult value of this column if not specified and the value after upgrade is null. :: +-----------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-----------+--------------+------+-----+---------+-------+ | id | varchar(36) | NO | PRI | NULL | | | port_id | varchar(36) | NO | MUL | NULL | | | opt_name | varchar(64) | NO | | NULL | | | opt_value | varchar(255) | NO | | NULL | | | ip_version| int(11) | YES | | NULL | | +-----------+--------------+------+-----+---------+-------+ REST API Impact --------------- The modified extra_dhcp_opts attribute map is described as follows: :: POST /v2.0/ports Accept: application/json { ""port"": { ... ""extra_dhcp_opts"": [ {""opt_value"": ""pxelinux.0"", ""opt_name"": ""bootfile-name"", ""ip_version"": 4}, {""opt_value"": ""123.123.123.123"", ""opt_name"": ""tftp-server"", ""ip_version"": 4}, {""opt_value"": ""123.123.123.45"", ""opt_name"": ""server-ip-address"", ""ip_version"": 4} ], ... } } The added attribute ""ip_version"" is not required. The allowed value of ""ip_version"" is 4 or 6. Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- Neutron client change: neutron port-create and neutron port-update needs following changes: :: neutron port-create Network --extra-dhcp-opt opt_name=<dhcp_option_name>,opt_value=<value>,ip_version={4,6} neutron port-update Network --extra-dhcp-opt opt_name=<dhcp_option_name>,opt_value=<value>,ip_version={4,6} Performance Impact ------------------ None Other Deployer Impact --------------------- None Developer Impact ---------------- None Community Impact ---------------- This proposed change has been discussed in Neutron IPv6 sub-team meeting and community development mail list: http://lists.openstack.org/pipermail/openstack-dev/2014-September/047222.html Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: xuhanp Other contributors: TBD Work Items ---------- * Add new API attribute and change current linux dhcp implementation by dnsmasq to treat IPv4 and IPv6 dhcp option separately. * DB migration script to add ""ip_version"" column in Neutron extradhcpopts table. * Add validation of extra dhcp options. * Add ""ip_version"" attribute to Neutron client port create and port update CLI. Dependencies ============ None Testing ======= Tempest Tests ------------- Add tempest API test for Neutron port creation and update using the new ""ip_version"" attribute of extra_dhcp_opts. Functional Tests ---------------- Functional tests towards DHCPv4 and DHCPv6 option name, value and the ip version. API Tests --------- API test to the added ""ip_version"" attribute of Port extra_dhcp_opts. Documentation Impact ==================== Neutron API documation should be modified to add the new attribute. User Documentation ------------------ The allowed DHCP option name and values should be documented in User Documentation. Examples for frequently used options should be provided. Developer Documentation ----------------------- Developer API documentation should be updated with the new attribute. References ========== * Mail list discussion: http://lists.openstack.org/pipermail/openstack-dev/2014-September/047222.html * DHCP options in DNSMASQ: http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq-man.html ",,221,0
openstack%2Fneutron-specs~master~I99ffc106714c03608c985e87156510d1569b455d,openstack/neutron-specs,master,I99ffc106714c03608c985e87156510d1569b455d,Re-propose LBaaS v2 specs for Kilo,MERGED,2014-12-06 01:41:19.000000000,2014-12-10 04:07:44.000000000,2014-12-10 04:07:43.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-06 01:41:19.000000000', 'files': ['specs/kilo/lbaas-l7-rules.rst', 'specs/kilo/lbaas-ref-driver-impl-tls.rst', 'specs/kilo/lbaas-refactor-haproxy-namespace-driver-to-new-driver-interface.rst', 'specs/kilo/lbaas-tls.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/192004752abbd3c780ee17ec85f2a10cfe1d7cdd', 'message': 'Re-propose LBaaS v2 specs for Kilo\n\nChange-Id: I99ffc106714c03608c985e87156510d1569b455d\n'}]",15,139773,192004752abbd3c780ee17ec85f2a10cfe1d7cdd,10,6,1,10980,,,0,"Re-propose LBaaS v2 specs for Kilo

Change-Id: I99ffc106714c03608c985e87156510d1569b455d
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/73/139773/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/kilo/lbaas-l7-rules.rst', 'specs/kilo/lbaas-ref-driver-impl-tls.rst', 'specs/kilo/lbaas-refactor-haproxy-namespace-driver-to-new-driver-interface.rst', 'specs/kilo/lbaas-tls.rst']",4,192004752abbd3c780ee17ec85f2a10cfe1d7cdd,kilo_specs_lbaasv2,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================== Neutron LBaaS TLS - Specification ================================== BP https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination Terminating TLS connections on the load balancer is a capability expected from modern load balancers and incorporated into many applications. This capability enables better certificate management and improved application based load balancing e.g. cookie-based persistency, L7 Policies appliance, etc. Problem Description =================== No TLS offloading capability is available for Neutron LBaaS Proposed Change =============== *Note: This document is referencing to the new LBaaS objects model proposed at https://review.openstack.org/#/c/89903* *Note: This document does not consider flavors framework proposed at https://review.openstack.org/#/c/90070 Before the flavors framework is in place, specific back-end driver which does not support TLS capabilities should throw an exception stating a lack of TLS support once it gets request for listener with TLS configuration. This document specifies a ""core"" feature set that every back-end implementing TLS capabilities must comply. TLS capabilities of various back-end implementations may differ in future releases, thus flavors aspect should definitely be part of TLS capabilities specification* *Note: Horizon project aspect is not a part of this specification.* * Tenant will manage his TLS certificates using Barbican. Certificates will be stored in Barbican secure containers. * Barbican is in charge of containers life cycle management, containers classification and validation. LBaaS TLS requires a specific container type (TLS). Only container of this type will be listed to the tenant for selection while configuring listener's TLS containers to use. Any invalid container usage will raise an error. * Barbican will also manage list of interested consumers for each container. See spec at https://review.openstack.org/#/c/99516 Neutron LBaaS (a consumer, according to Barbican's terminology) will not use a regular GET request for container resource in order to get the container. Instead, it will use a POST request to container's consumers resource (http://admin-api/v1/containers/{container-uuid}/consumers) with following info: { ""type"": ""LBaaS"", ""URL"": ""https://lbaas.myurl.net/loadbalancers/<lb_id>/"" } **Note:** We might want to use specific Listener URL instead of Loadbalancer's one, like ""https://lbaas.myurl.net/lbaas/listeners/<listener_id>"" As a response, it will get containers data like container's resource GET request was used. Barbican, in its turn will store consumer's (LBaaS instance URL) data in its database so this info can be used for getting all consumers of a specific TLS container. As a result, Neutron LBaaS TLS implementation is required to: * Use only POST request to container's consumers resource in order to get the container's data. * Perform DELETE request to container's consumers resource when stop using a container. * Barbican TLS container will contain PEM encoded data. Specific back-end implementation might convert the certificates data to other format such as DER, if needed. * In addition to existing HTTP, HTTPS and TCP, new protocol, TERMINATED_HTTPS will be added for listener creation * For tenant, creating listener with TERMINATED_HTTPS as a protocol means desire to offload incoming encrypted traffic. New configuration options will be available for listener's configuration including: * Default TLS container id for TLS termination * TLS containers list for SNI * In case when specific back-end is not able to support TLS capabilities, its driver should throw an exception. The exception message should state that this specific back-end (provider) does not support listeners with TLS offloading. The clear sign of listener's requirement for TLS offloading capabilities is its TERMINATED_HTTPS protocol. * New module will be developed in Neutron LBaaS for Barbican TLS containers interactions. The module will be used by Neutron LBaaS front-end API code and providers' driver code. The module will be used for validation and data extraction from default TLS container and SNI containers. This module represents the only legitimate API for Barbican TLS containers interactions. See 'SNI certificates list management' section for detailed module specification. * When creating listener with TERMINATED_HTTPS protocol: * Front-end TLS offloading is always enabled - hard coded as a default behaviour for listener with TERMINATED_HTTPS protocol * Tenant must supply default TLS container for front-end offloading. Not supplying a container is an invalid configuration. * TLS supported protocols and cipher suites for termination will be set to sane values by each back-end's specific code * SNI certificates list is optional and not mandatory to specify * SNI certificates list specifying is described in ""SNI certificates list management"" section * Certificate intermediate chain will be stored as a part of Barbican's TLS container * Back-end re-encryption will not be supported in first phase * Front-end client authentication and back-end server authentication will not be supported in first phase * When updating listener with TERMINATED_HTTPS protocol: * In TLS configuration domain, default TLS container ID for front-end offloading and SNI container IDs list are values that may be changed * In case when defaut TLS container ID is replaced for the listener, back-end implementation should ensure a lack of a downtime on LB appliance. * Same for changing SNI container IDs list, back-end should avoid LB downtime. * HA-Proxy LBaaS implementaion and other LBaaS implementations should be modified to support this specification. **With stated above, following is a description of a basic tenant use case - creating listener with TLS offloading:** * Tenant cteates Barbican TLS container with a certificate. * Tenant creates listener with TERMINATED_HTTPS as a listener protocol and specifies the Barbican TLS container ID as a default TLS container for front-end offloading * As a result, listener created, offloading encrypted traffic on front-end with default tenant's TLS certificate, not re-encrypting traffic to the back-end. Requirements from Barbican -------------------------- * Tenant should be able to create and delete TLS containers using Barbican * Ability to store TLS certificates in Barbican containers that contain the TLS certificate itself, its private key and optionaly, intermediate chain * Creating TLS container with: * Certificate : PEM text field * Private_key: PEM text_field * (extracted) Private_key_pass_phrase : text field * Intermediates: PEM text field (optional) This field is a concatination of PEM encoded certificate blocks in specific order * Delete TLS certificate **optional:** Check if certificate is in use by any consumer and warn before deleting. Barbican's BP discussing this feature: https://review.openstack.org/#/c/99516/ * Get TLS container, including private key in PEM encoded PKCS1 or PKCS7 formats, by container id * Get TLS certificate in pem encoded x509 format, by container id Restrictions ------------ * TLS settings are only available for listeners having TERMINATED_HTTPS as a protocol. In other cases TLS settings will be disabled and have None or empty values. There should be a meaningfull error message to a user explaining the exact reason of a failure in case of an invalid configuration. * Listener protocol is immutable. Changing the protocol will require radical re-configuration of provider's back-end system, which seems to be not justified for this use case. Tenant should create new listener. * While updating existing TLS certificate, name and description are only values allowed to be modified. Creating new TLS container and using it instead of the old one will be easier option than re-configuring LBaaS back-end with modified container, at least in first phase. SNI certificates list management -------------------------------- For SNI functionality, tenant will supply list of TLS containers in specific order. In case when specific back-end is not able to support SNI capabilities, its driver should throw an exception. The exception message should state that this specific back-end (provider) does not support SNI capability. The clear sign of listener's requirement for SNI capability is a none empty SNI container ids list. However, reference implementation must support SNI capability. New separate module will be developed in Neutron LBaaS for Barbican TLS containers interactions. The module will use service account for Barbican API interation. The module will have API for: * Ensuring Barbican TLS container existence (used by LBaaS front-end API) * Validating Barbican TLS container (used by LBaaS front-end API) This API will also ""register"" LBaaS as a container's consumer in Barbican's repository. * Extracting SubjectCommonName and SubjectAltName information from certificates X509 (used by LBaaS front-end API) As for now, only dNSName and directoryName types will be extracted from SubjectAltName sequence, while directoryName type usage is an issue for further discussion. * Extracting certificates data from Barbican TLS container (used by provider/driver code) * Unregistering LBaaS as a consumer of the container when container is not used by any listener any more (used by LBaaS front-end API) The module will use pyOpenSSL and PyASN1 packages. Only this new common module should be used by Neutron LBaaS code for Barbican containers interactions. Front-end LBaaS API (plugin) code will use a new developed module for validating Barbican TLS containers. Driver, in its turn, can extract SubjectCommonName and SubjectAltName information from certificates X509 via the common module API and use it for its specific SNI implementation. **Note:** **Specific back-end driver does not have to use SubjectAltName information. Furthermore, specific driver may throw an exception saying SubjectAltName is not supported by its provider** Any specific driver implementation may extract host names info from certificates using the mentioned above common module API only, if needed. **SNI conflicts** Employing the order of certificates list is not a common requirement for all back-end implementations. The order of SNI containers list may be used by specific back-end code, like Radware's, for specifying priorities among certificates. Order is meant to be a hint to resolve conflicts when 2 or more certificates match the DNS name requested in the SNI client hello. Specific backends might choose to ignore this order and might employ their own mechanisms to choose one among the clashing certificates. For ex. NetScaler employs the best match algorithm and does not require order for conflict resolution. It's also possible that specific driver throws an exception saying there is a collision and this specific SNI setup will not be supported by the back-end. Data Model Impact ----------------- **Data model changes** * *lbaas_listeners* table will be modified with new * default_tls_container_id (nullable string 36) - Barbican's TLS container id * New *lbaas_sni* table will be created for storing ordered list of TLS containers associated to a listener for SNI capabilities. Association objects is composed of: * id (immutable string 36) - generated object id * listener_id (string 36) - associated listener id * tls_container_id (string 36) - associated Barbican TLS container id * position - (integer) index for preserving the order **Required database migration** * add new columns to *lbaas_isteners* table * create new *lbaas_sni* table **New data initial set** * New columns for *lbaas_listeners* table's existing entries will be set to defaults REST API Impact --------------- **Listener Attributes** +-------------+-------+---------+---------+------------+----------------------+ |Attribute |Type |Access |Default |Validation/ |Description | |Name | | |Value |Conversion | | +=============+=======+=========+=========+============+======================+ |default-tls- |UUID |RW,tenant|NULL |UUID |default TLS cert id | |container-id | | | | |to use for offloading | +-------------+-------+---------+---------+------------+----------------------+ |sni_container|UUID |RW,tenant|NULL |UUID list |ordered list of | |_ids |list | | | |TLS containers to use | | | | | | |for SNI .| +-------------+-------+---------+---------+------------+----------------------+ **Functions** * create_listener * Creates new listener * Request *POST /v2.0/lbaas/listeners Accept: application/json { ""listener"":{ <...usual listener parameters>, ""protocol"": ""TERMINATED_HTTPS"" ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4j"", ""sni_container_ids"": None } }* * Response *{ ""listener"":{ ""id"": ""8604a0de-7f6b-409a-a47c-a1cc7bc77b2e"" <...usual listener parameters>, ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"": None ""tenant_id"":""6b96ff0cb17a4b859e1e575d221683d3"" } }* * create_listener (with SNI list) * Creates new listener * Request *POST /v2.0/lbaas/listeners Accept: application/json { ""listener"":{ <...usual listener parameters>, ""protocol"": ""TERMINATED_HTTPS"" ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4j"", ""sni_container_ids"": [5404a0de-7f6b-409a-a47c-a1ccgbc77b3j, 1206a0de-7f6b-409a-a47c-a1ccgbc7bgf3] } }* * Response *{ ""listener"":{ ""id"": ""8604a0de-7f6b-409a-a47c-a1cc7bc77b2e"" <...usual listener parameters>, ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"":[5404a0de-7f6b-409a-a47c-a1ccgbc77b3j, 1206a0de-7f6b-409a-a47c-a1ccgbc7bgf3] ""tenant_id"":""6b96ff0cb17a4b859e1e575d221683d3"" } }* * update_listener * Updates VIP listener * Request *PUT /v2.0/lbaas/listeners/<listener-id> Accept: application/json { ""listener"":{ <...usual listener parameters>, ""protocol"": ""TERMINATED_HTTPS"" ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"": None } }* * Response *{ ""listener"":{ ""id"": ""8604a0de-7f6b-409a-a47c-a1cc7bc77b2e"" <...usual listener parameters>, ""default_tls_container_id"": ""7804a0de-7f6b-409a-a47c-a1cc7bc77b4c"", ""sni_container_ids"": None ""tenant_id"":""6b96ff0cb17a4b859e1e575d221683d3"" } }* Security Impact --------------- Following are security requirements: * Retrieving TLS container from Barbican to LBaaS plugin/driver must be secured * Sending TLS container contents from driver to back-end system must be secured * Storing secrets on neutron server is prohibited * Back-end systems may need to ensure secured store for secrets to meet certain security compliance requirements Notifications Impact -------------------- None CLI Impact --------------------- * Listener creation with TERMINATED_HTTPS protocol (default behavior) *lb-listener-create* **--protocol TERMINATED_HTTPS** *--protocol-port 443* **--default_tls_container_id 9a96ff0cb17a4b859e1e575d2216cd23** *...<usual CLI options>* * Listener creation with TERMINATED_HTTPS protocol and SNI certificates list *lb-listener-create* **--protocol TERMINATED_HTTPS** *--protocol-port 443* **--default_tls_container_id 9a96ff0cb17a4b859e1e575d2216cd23 --sni_container_ids list=true 6b96ff0cb17a4b859e1e575d221683d3 4596ff0cb17a4b859e1e575d22168ba1** *...<usual CLI options>* Other End User Impact --------------------- None Performance Impact ------------------ * When updating listener without modifying TLS settings (default container id or SNI list) - Barbican API should not be used for retrieving container content which was not actually changed. This will prevent unnecessary resources consumption when, for example, members are added to the pool used by listener. It means that each Barbican TLS container will be validated only once for a listener while it's still in use by this listener. IPv6 Impact ----------- None Other Deployer Impact --------------------- * Barbican is required to be deployed and functional in order this feature to work. * New dependencies are added for neutron, pyOpenSSL and PyASN1. These are required by new module for Barbican TLS containers interactions. Developer Impact ---------------- None Community Impact ---------------- This change has been in review since Juno. Much discussion has taken place over IRC and the mailing list. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~evgenyf Other contributors: Barbican TLS containers interactions module - https://launchpad.net/~carlos-garza Work Items ---------- * Develop new module for BArbican TLS containers interactions using pyOpenSSL and PyASN1 packages. * Implement changes in LBaaS DB schema v2 * Implement changes in LBaaS extension v2 * Implement all required CLI changes * Implement all required unit testing * Implement all required tempest testing * Make integration with Barbican certificates storage API Detailed specificatio of how Barbican's API for containers should be used is at https://review.openstack.org/#/c/99516 * Modifying LBaaS HA-Proxy driver to support TLS capability Detailed specification of this work item is at https://review.openstack.org/#/c/100931 * Use HA-Proxy version 1.5 * Implement horizon part of this spec, not as part of Juno release. Dependencies ============ * Barbican API requirements * Neutron LBaaS API v2 with new listener object implemented * New dependencies will be added for neutron, pyOpenSSL and PyASN1. These are required by new module for Barbican TLS containers interactions. Testing ======= Tempest Tests ------------- **listener unit testing domains** * REST API and attributes validation tests * DB mixin and schema tests * LBaaS Plugin with mocked driver end-to-end tests * Specific driver tests for each existing driver supporting TLS offloading * Tempest tests * CLI tests * New listener creation with TERMINATED_HTTPS as a protocol * No default TLS container for termination supplied. Check error generation * Default TLS container for termination supplied. Test expected default configuration took place. * Default TLS container supplied. SNI TLS containers list was supplied Test expected configuration took place * Update existing listener with TERMINATED_HTTPS as a protocole * Change default TLS container. Test expected configuration * Add/Modify SNI containers list. Test expected configuration CLI tests should test inconsistency issues such as: * No default offloading TLS container specified when creating listener with TERMINATES_HTTPS protocole Functional Tests ---------------- As above. API Tests ---------- As above. Documentation Impact ==================== User Documentation ------------------ * Neutron CLI should be modified with updated listener commands with TLS options Developer Documentation ----------------------- * Neutron API should be modified with new listener TLS attributes References ========== * TLS RFC http://tools.ietf.org/html/rfc2818 ",,1402,0
openstack%2Fneutron-specs~master~I45b4875080ffa835817b2512948f3b039bf8b20c,openstack/neutron-specs,master,I45b4875080ffa835817b2512948f3b039bf8b20c,LBaaS V2 API and object model definition,MERGED,2014-12-01 23:50:40.000000000,2014-12-10 04:06:37.000000000,2014-12-10 04:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-01 23:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c3157897d21a29677b52d75afce22f1171f4e848', 'message': 'LBaaS V2 API and object model definition\n\nReproposing and repurposing the lbaas object model refactor into what\ncurrently exists in the LBaaS v2 feature branch without the TLS and L7\nrules.\n\nChange-Id: I45b4875080ffa835817b2512948f3b039bf8b20c\n'}, {'number': 2, 'created': '2014-12-02 20:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9bb8cde1bc4180d693e6d2647ae5c4831eda04e9', 'message': 'LBaaS V2 API and object model definition\n\nReproposing and repurposing the lbaas object model refactor into what\ncurrently exists in the LBaaS v2 feature branch without the TLS and L7\nrules.\n\nAPIImpact\n\nChange-Id: I45b4875080ffa835817b2512948f3b039bf8b20c\n'}, {'number': 3, 'created': '2014-12-02 22:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ff95f01285b23baa8c847a9593d33d2f17d573ff', 'message': 'LBaaS V2 API and object model definition\n\nReproposing and repurposing the lbaas object model refactor into what\ncurrently exists in the LBaaS v2 feature branch without the TLS and L7\nrules.\n\nAPIImpact\nDocImpact\n\nChange-Id: I45b4875080ffa835817b2512948f3b039bf8b20c\n'}, {'number': 4, 'created': '2014-12-04 23:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/40d8606b919d4035b9da37d69a37311987dd7870', 'message': 'LBaaS V2 API and object model definition\n\nReproposing and repurposing the lbaas object model refactor into what\ncurrently exists in the LBaaS v2 feature branch without the TLS and L7\nrules.\n\nAPIImpact\nDocImpact\n\nChange-Id: I45b4875080ffa835817b2512948f3b039bf8b20c\n'}, {'number': 5, 'created': '2014-12-05 23:41:25.000000000', 'files': ['specs/kilo/lbaas-api-and-objmodel-improvement.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2283d6caaecc613f11a0b237399edfc4488919b0', 'message': 'LBaaS V2 API and object model definition\n\nReproposing and repurposing the lbaas object model refactor into what\ncurrently exists in the LBaaS v2 feature branch without the TLS and L7\nrules.\n\nAPIImpact\nDocImpact\n\nChange-Id: I45b4875080ffa835817b2512948f3b039bf8b20c\n'}]",4,138205,2283d6caaecc613f11a0b237399edfc4488919b0,22,6,5,6951,,,0,"LBaaS V2 API and object model definition

Reproposing and repurposing the lbaas object model refactor into what
currently exists in the LBaaS v2 feature branch without the TLS and L7
rules.

APIImpact
DocImpact

Change-Id: I45b4875080ffa835817b2512948f3b039bf8b20c
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/05/138205/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/lbaas-v2.rst'],1,c3157897d21a29677b52d75afce22f1171f4e848,bp/lbaas-api-and-objmodel-improvement,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================== LBaaS API and Object Model improvement ====================================== https://blueprints.launchpad.net/neutron/+spec/lbaas-api-and-objmodel-improvement LBaaS needs improved API and object model to provide base line for new API parts that provide advanced use cases such as L7, TLS, HA, etc. This blueprint describes the changes that should be made to object model so that further design and implementation of L7 switching, TLS and HA feature is possible. The new API that exposes the new entities will be done in an separate extension. This blueprint is not describing design of L7, TLS API parts but may briefly assume some aspects of possible design of those features. Nor does it describe the changes to the API that will fit with this object model. Problem description =================== The ""advanced"" LB configuration which is supported by all LB vendors, both hw and sw, may consist of multiple service endpoints on one ip address, and multiple pools. Here, 'service endpoint' means IP address + port. The problem with existing API/object model is that it only accounts for single VIP and single pool per loadbalancer. One of the biggest issue of the existing API and object model is that Pool is playing 'root object' role and this solely prevents multiple pools per single configuration. Proposed change =============== There are a few things that needs to be done in order to make LBaaS API suitable for addition of TLS, L7 and HA features. 1. This will entirely be a new extension and service plugin. LBaaS V1 code should not be affected, but there may be exceptions. 2. Currently Pool object is the root object(*), which is logically incorrect and confusing. From API perspective that means that creating Pool object will not be a starting point of the workflow. 3. Member object will add subnet_id as an optional attribute. 4. VIP object will not be used. Its attributes will be added to the LoadBalancer object and the Listener object. 5. LoadBalancer object becomes the root object(*) of the LBaaS object model. It will hold the attributes that pertain to the vip and will be the parent of one or many listeners. 6. Additional object Listener is introduced, which is a placeholder for former VIP parameters such as protocol_port, and protocol, see detailed description below LoadBalancer and Listener relate as 1:M. Listener will initially only be a child of a LoadBalancer, so its life-cycle is limited to a LoadBalancer. Deleting a LoadBalancer will not be alllowed when it has children Listeners. In the future, this relationship may become M:N if it is decided it is needed. The M:N change will be an additive change so it will not break contract, however, this blueprint will not attempt this. 7. To prevent entities in the database being out of sync with the backend due to concurrent requests, no operations will be allowed if an entity is in a transient state (PENDING_CREATE, PENDING_UPDATE, PENDING_DELETE). 8. Pool to Health Monitor relationship will change from M:N to 1:1 for now. 9. Attributes of health monitor and member will stay nearly identical except for references to parents. 10. A new synchronous haproxy driver will be created to easily test out the API and DB changes. It will not be meant for production use. Refactoring the agent haproxy driver will be left to another blueprint. (*) Root object is an object that represents 'service instance'. It could be deployed/undeployed, turned on/off, or capability requirements may be applied to it. It also is a starting point of configuration workflow. Alternatives ------------ * https://docs.google.com/a/mirantis.com/document/d/1mTfkkdnPAd4tWOMZAdwHEx7IuFZDULjG9bTmWyXe-zo/edit The documents describes differently structured API that uses 'single-call' approach. * https://etherpad.openstack.org/p/neutron-lbaas-api-proposals Brief description of how other APIs for other object models look like Data model impact ----------------- LBaaS v1 tables will remain unchanged and the following tables will be added for LBaaS v2 use: * neutron.lbaas_loadbalancers * neutron.lbaas_listeners * neutron.lbaas_pools * neutron.lbaas_members * neutron.lbaas_healthmonitors * neutron.lbaas_sessionpersistences * neutron.lbaas_loadbalancer_statistics 1. lbaas_loadbalancers * id - unique identifier * tenant_id * name * description * vip_port_id - the neutron port tied to the vip (this can be used to get the vip_subnet, and vip_address). This will be stored in the database but not exposed through the API. * vip_subnet_id - the subnet a neutron port should be created on * vip_address - the address of the subnet * status - provisioning status (ACTIVE, PENDING_CREATE, PENDING_DELETE, etc) * admin_state_up * listeners - a list of back-references child listener ids * provider - provider in which this load balancer should be provisioned 2. lbaas_listeners * id - identity * tenant_id * loadbalancer_id * default_pool_id - ID of default pool. Must have compatible protocol with listener. * protocol - Protocol to load balancer: HTTP, HTTPS, TCP, UDP * protocol_port - port number to listen * admin_state_up - admin state (True or False) * status - provisioning status (ACTIVE, PENDING_CREATE, PENDING_DELETE, etc) Listener model will later be amended with L7 and TLS-related attributes which are out of scope of this blueprint. 3. lbaas_pools * id - identity * tenant_id * name * description * protocol - Protocol to load balance * lb_method - load balancing method * healthmonitor_id - id of health monitor * admin_state_up - admin state (True/False). That attribute defines administrative state of the pool on all of the backends where it is actually deployed. * status - operational status (ONLINE, OFFLINE) 4. lbaas_members * id - identity * tenant_id * address - ip address * pool_id - required parent pool * subnet_id - optional subnet this member is on * protocol_port * weight * status - operational status (ONLINE, OFFLINE) * admin_state_up 5. lbaas_healthmonitors * id - id * tenant_id * type - (TCP, HTTP) * delay * timeout * max_retries * http_method * url_path * expected_codes * admin_state_up REST API impact --------------- A separate extension will be created exposing the following resources: * /lbaas/loadbalancers * /lbaas/listeners * /lbaas/pools * /lbaas/pools/{pool_id}/members * /lbaas/healthmonitors Resource Attributes /lbaas/loadbalancers +----------------+----------------+-----------------------+ | POST | PUT | GET (List and Single) | +----------------+----------------+-----------------------+ | tenant_id | name | id | | name | description | tenant_id | | description | admin_state_up | name | | vip_subnet_id* | | description | | vip_address | | vip_subnet_id | | admin_state_up | | vip_address | | | | admin_state_up | | | | status | +----------------+----------------+-----------------------+ Deleting a load balancer will only succeed if it is not a parent of any listeners. /lbaas/listeners +------------------+------------------+-----------------------+ | POST | PUT | GET (List and Single) | +------------------+------------------+-----------------------+ | tenant_id | name | id | | name | description | tenant_id | | description | connection_limit | name | | loadbalancer_id* | admin_state_up | description | | connection_limit | | loadbalancer_id | | protocol* | | connection_limit | | protocol_port* | | protocol | | admin_state_up | | protocol_port | | | | admin_state_up | | | | status | +------------------+------------------+-----------------------+ Note that loadbalancer_id is required for now. This will not preclude later implementations that may want to allow M:N loadbalancer to listeners as this is only an API attribute and thus can be changed from required to optional. Note that default_pool_id is not specified here as the pool will define its parent listener. Deleting a Listener will only succeed if it is not the parent of a pool. /lbaas/pools +---------------------+---------------------+-----------------------+ | POST | PUT | GET (List and Single) | +---------------------+---------------------+-----------------------+ | tenant_id | name | id | | name | description | tenant_id | | description | lb_algorithm | name | | listener_id* | session_persistence | description | | protocol* | admin_state_up | listener_id | | lb_algorithm* | | protocol | | session_persistence | | lb_algorithm | | admin_state_up | | session_persistence | | | | members | | | | admin_state_up | | | | status | +---------------------+---------------------+-----------------------+ Note that listener_id is required for now. There will be validation that the listener has only one pool as a child. This should not preclude a later implementation of M:N listener to pools. Deleting a pool will not succeed if it is the parent of a health monitor. It will however succeed if it is the parent of any children, and those children will be deleted as well. /lbaas/healthmonitors +----------------+----------------+-----------------------+ | POST | PUT | GET (List and Single) | +----------------+----------------+-----------------------+ | tenant_id | delay | id | | type* | timeout | tenant_id | | delay* | max_retries | type | | timeout* | http_method | delay | | max_retries* | url_path | timeout | | http_method | expected_codes | max_retries | | url_path | admin_state_up | http_method | | expected_codes | | url_path | | admin_state_up | | expected_codes | | pool_id* | | admin_state_up | | | | status | | | | pool_id | +----------------+----------------+-----------------------+ Note that pool_id is a required attribute. Similar to listener_id on the pool object, this does not preclude later implementations of 1:M pool to health monitor relationship. /lbaas/pools/{pool_id}/members +----------------+----------------+-----------------------+ | POST | PUT | GET (List and Single) | +----------------+----------------+-----------------------+ | tenant_id | weight | id | | address* | admin_state_up | tenant_id | | protocol_port* | | address | | weight | | protocol_port | | admin_state_up | | weight | | subnet_id | | admin_state_up | | | | status | | | | subnet_id | +----------------+----------------+-----------------------+ (*) denotes a required attribute Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- None Notifications will be impacted because the payload will change and other notifications will go away. New notifications: - loadbalancer - listener - pool - healthmonitor - member Other end user impact --------------------- Users may have access to a new lbaas extension. Performance Impact ------------------ None Other deployer impact --------------------- LBaaS V1 and LBaaS V2 can coexist in the codebase, but should not be run at the same time. This will have to be enforced in the code. No migration path from LBaaS V1 to V2 will be done for this blueprint, however another blueprint should do this as it will be a complicated effort. Developer impact ---------------- A new extension and service plugin. Implementation ============== Assignee(s) ----------- Primary assignees: brandon-logan Work Items ---------- * object model change * new loadbalancer extension for new API * unit tests Dependencies ============ None Testing ======= No change to LBaaS V1 tests. New tests for all of the new resources for LBaaS V2. - Tempest API tests - Tempest scenario tests - Neutron functional tests Documentation Impact ==================== LBaaS V2 should be added to the neutron documentation. References ========== * https://etherpad.openstack.org/p/juno-lbaas-design-session ",,392,0
openstack%2Fheat~master~I88b43874bbccf1510b0dff0cdae7ab4bd3422769,openstack/heat,master,I88b43874bbccf1510b0dff0cdae7ab4bd3422769,Set resource id for OS::Neutron::LoadBalancer,ABANDONED,2014-12-08 07:57:28.000000000,2014-12-10 03:35:10.000000000,,"[{'_account_id': 3}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-08 07:57:28.000000000', 'files': ['heat/engine/resources/neutron/loadbalancer.py', 'heat/tests/test_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f91be6739d781189c159a7031e40839e31008967', 'message': 'Set resource id for OS::Neutron::LoadBalancer\n\nAdd resource id for OS::Neutron::LoadBalancer\n\nCloses-Bug: #1400227\nChange-Id: I88b43874bbccf1510b0dff0cdae7ab4bd3422769\n'}]",0,139934,f91be6739d781189c159a7031e40839e31008967,7,3,1,7404,,,0,"Set resource id for OS::Neutron::LoadBalancer

Add resource id for OS::Neutron::LoadBalancer

Closes-Bug: #1400227
Change-Id: I88b43874bbccf1510b0dff0cdae7ab4bd3422769
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/139934/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/loadbalancer.py', 'heat/tests/test_loadbalancer.py']",2,f91be6739d781189c159a7031e40839e31008967,bug/1400227, self.assertIsNotNone(rsrc.resource_id),,2,0
openstack%2Fneutron~master~Ib8e75bca41dbcd9dbb188ba8ee03ef51a479d9cc,openstack/neutron,master,Ib8e75bca41dbcd9dbb188ba8ee03ef51a479d9cc,Remove TODO for H404,MERGED,2014-12-09 20:06:48.000000000,2014-12-10 03:21:35.000000000,2014-12-09 22:15:49.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-09 20:06:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/acde1b60dd87713aed5c84408460917d65d530aa', 'message': ""Remove TODO for H404\n\nThere is no timeline or intention to fix this - it's a non-functional\nformatting change.\n\nChange-Id: Ib8e75bca41dbcd9dbb188ba8ee03ef51a479d9cc\n""}]",0,140463,acde1b60dd87713aed5c84408460917d65d530aa,24,20,1,2035,,,0,"Remove TODO for H404

There is no timeline or intention to fix this - it's a non-functional
formatting change.

Change-Id: Ib8e75bca41dbcd9dbb188ba8ee03ef51a479d9cc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/140463/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,acde1b60dd87713aed5c84408460917d65d530aa,,# H404 multi line docstring should start with a summary,# TODO(marun) H404 multi line docstring should start with a summary,1,1
openstack%2Fhorizon~master~Ie711bc441ce689c385034edc1d703c8a9f067d80,openstack/horizon,master,Ie711bc441ce689c385034edc1d703c8a9f067d80,rename project to project_id for underlying api,ABANDONED,2014-12-10 02:35:30.000000000,2014-12-10 03:09:26.000000000,,[],"[{'number': 1, 'created': '2014-12-10 02:35:30.000000000', 'files': ['openstack_dashboard/api/rest/keystone.py', 'openstack_dashboard/test/api_tests/keystone_rest_tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/11af9f99d1b6b17a3f28110d75c5d93826a0946b', 'message': 'rename project to project_id for underlying api\n\nChange-Id: Ie711bc441ce689c385034edc1d703c8a9f067d80\n'}]",0,140557,11af9f99d1b6b17a3f28110d75c5d93826a0946b,2,0,1,12071,,,0,"rename project to project_id for underlying api

Change-Id: Ie711bc441ce689c385034edc1d703c8a9f067d80
",git fetch https://review.opendev.org/openstack/horizon refs/changes/57/140557/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/rest/keystone.py', 'openstack_dashboard/test/api_tests/keystone_rest_tests.py']",2,11af9f99d1b6b17a3f28110d75c5d93826a0946b,rest-api-keystone," request = self._construct_request(body=''' {""name"": ""spam"", ""project_id"": ""other123""} ''') name='spam', project='other123')"," request = self._construct_request(body='{""name"": ""spam""}') name='spam')",7,2
openstack%2Fhorizon~master~I10d50c202c7fd156455a97c6a5451225154ae0bc,openstack/horizon,master,I10d50c202c7fd156455a97c6a5451225154ae0bc,Provide tenant_id in Neutron create requests,MERGED,2014-11-12 04:33:51.000000000,2014-12-10 03:06:32.000000000,2014-12-10 03:06:31.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 7787}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-11-12 04:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/442ea4c78a7c8f6cbc210faa2afa43b5ac994005', 'message': 'test neutron api\n\nChange-Id: I10d50c202c7fd156455a97c6a5451225154ae0bc\n'}, {'number': 2, 'created': '2014-12-08 17:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3af2c9f1331e7064eb5e955984c8a6159b205371', 'message': 'Provide tenant_id in Neutron create requests\n\nInclude the tenant_id explicitly in the Neutron object creation\nrequests rather than assuming that all of the information can\nbe derived from Keystone. This fixes deployments that only pass\ntokens to Neutron.\n\nCloses-Bug: #1400418\nChange-Id: I10d50c202c7fd156455a97c6a5451225154ae0bc\n'}, {'number': 3, 'created': '2014-12-09 00:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dcf1db9718ac7d6f8f41f77c61a5f7a254bebce4', 'message': 'Provide tenant_id in Neutron create requests\n\nInclude the tenant_id explicitly in the Neutron object creation\nrequests rather than assuming that all of the information can\nbe derived from Keystone. This fixes deployments that only pass\ntokens to Neutron.\n\nCloses-Bug: #1400418\nChange-Id: I10d50c202c7fd156455a97c6a5451225154ae0bc\n'}, {'number': 4, 'created': '2014-12-09 16:12:56.000000000', 'files': ['openstack_dashboard/test/api_tests/neutron_tests.py', 'openstack_dashboard/test/api_tests/network_tests.py', 'openstack_dashboard/api/neutron.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b29a5eff1b62b418159aa4689adeac8f396e56c9', 'message': 'Provide tenant_id in Neutron create requests\n\nInclude the tenant_id explicitly in the Neutron object creation\nrequests rather than assuming that all of the information can\nbe derived from Keystone. This fixes deployments that only pass\ntokens to Neutron.\n\nCloses-Bug: #1400418\nChange-Id: I10d50c202c7fd156455a97c6a5451225154ae0bc\n'}]",4,133884,b29a5eff1b62b418159aa4689adeac8f396e56c9,20,5,4,7787,,,0,"Provide tenant_id in Neutron create requests

Include the tenant_id explicitly in the Neutron object creation
requests rather than assuming that all of the information can
be derived from Keystone. This fixes deployments that only pass
tokens to Neutron.

Closes-Bug: #1400418
Change-Id: I10d50c202c7fd156455a97c6a5451225154ae0bc
",git fetch https://review.opendev.org/openstack/horizon refs/changes/84/133884/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/api/neutron.py'],1,442ea4c78a7c8f6cbc210faa2afa43b5ac994005,bug/1400418," tenant_id=request.user.tenant_id,",,1,0
openstack%2Fheat~master~Id203478dbd067743d36623e99332ac32c6f96d42,openstack/heat,master,Id203478dbd067743d36623e99332ac32c6f96d42,Expose resource attributes in the API,MERGED,2014-11-17 23:11:57.000000000,2014-12-10 02:59:28.000000000,2014-12-10 02:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-11-17 23:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5f162324bd284731662f96a69217b77c3a895519', 'message': ""Show resource attributes on resource-show\n\nThis adds the necessary API changes to allow the user to view\nresource's attributes when making calls to resource show.\n\nImplements: blueprint detailed-resource-show\nChange-Id: Id203478dbd067743d36623e99332ac32c6f96d42\n""}, {'number': 2, 'created': '2014-11-18 14:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb8f124d9e7a1f83f074a56757d1bbdbd6bbf48c', 'message': ""Show resource attributes on resource-show\n\nThis adds the necessary API changes to allow the user to view\nresource's attributes when making calls to resource show.\n\nImplements: blueprint detailed-resource-show\nChange-Id: Id203478dbd067743d36623e99332ac32c6f96d42\n""}, {'number': 3, 'created': '2014-11-20 17:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5ce8d4ccdad2d14005c6bf4c317cbcc11347ad8b', 'message': ""Show resource attributes on resource-show\n\nThis adds the necessary API changes to allow the user to view\nresource's attributes when making calls to resource show.\n\nImplements: blueprint detailed-resource-show\nChange-Id: Id203478dbd067743d36623e99332ac32c6f96d42\n""}, {'number': 4, 'created': '2014-12-04 17:52:41.000000000', 'files': ['heat/tests/test_rpc_client.py', 'heat/rpc/client.py', 'heat/api/openstack/v1/resources.py', 'heat/tests/test_api_openstack_v1.py', 'heat/tests/test_api_cfn_v1.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e9c24bbd85256887df54f1db375d5486617f52d8', 'message': ""Expose resource attributes in the API\n\nThis adds the necessary API changes to allow the user to view\nresource's attributes when making calls to resource show.\n\nImplements: blueprint detailed-resource-show\nChange-Id: Id203478dbd067743d36623e99332ac32c6f96d42\n""}]",0,135111,e9c24bbd85256887df54f1db375d5486617f52d8,20,5,4,9189,,,0,"Expose resource attributes in the API

This adds the necessary API changes to allow the user to view
resource's attributes when making calls to resource show.

Implements: blueprint detailed-resource-show
Change-Id: Id203478dbd067743d36623e99332ac32c6f96d42
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/135111/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_rpc_client.py', 'heat/rpc/client.py', 'heat/api/openstack/v1/resources.py', 'heat/tests/test_api_cfn_v1.py', 'heat/tests/test_api_openstack_v1.py']",5,5f162324bd284731662f96a69217b77c3a895519,bp/detailed-resource-show," {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) def test_show_with_single_attribute(self, mock_enforce): self._mock_enforce_setup(mock_enforce, 'show', True) res_name = 'WikiDatabase' stack_identity = identifier.HeatIdentifier(self.tenant, 'foo', '1') res_identity = identifier.ResourceIdentifier(resource_name=res_name, **stack_identity) mock_describe = mock.Mock(return_value={'foo': 'bar'}) self.controller.rpc_client.describe_stack_resource = mock_describe req = self._get(res_identity._tenant_path(), {'with_attr': 'baz'}) resp = self.controller.show(req, tenant_id=self.tenant, stack_name=stack_identity.stack_name, stack_id=stack_identity.stack_id, resource_name=res_name) self.assertEqual({'resource': {'foo': 'bar'}}, resp) args, kwargs = mock_describe.call_args self.assertIn('baz', kwargs['with_attr']) def test_show_with_multiple_attributes(self, mock_enforce): self._mock_enforce_setup(mock_enforce, 'show', True) res_name = 'WikiDatabase' stack_identity = identifier.HeatIdentifier(self.tenant, 'foo', '1') res_identity = identifier.ResourceIdentifier(resource_name=res_name, **stack_identity) mock_describe = mock.Mock(return_value={'foo': 'bar'}) self.controller.rpc_client.describe_stack_resource = mock_describe req = self._get(res_identity._tenant_path()) req.environ['QUERY_STRING'] = 'with_attr=a1&with_attr=a2&with_attr=a3' resp = self.controller.show(req, tenant_id=self.tenant, stack_name=stack_identity.stack_name, stack_id=stack_identity.stack_id, resource_name=res_name) self.assertEqual({'resource': {'foo': 'bar'}}, resp) args, kwargs = mock_describe.call_args self.assertIn('a1', kwargs['with_attr']) self.assertIn('a2', kwargs['with_attr']) self.assertIn('a3', kwargs['with_attr']) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None}) {'stack_identity': stack_identity, 'resource_name': res_name, 'with_attr': None})"," {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name}) {'stack_identity': stack_identity, 'resource_name': res_name})",69,12
openstack%2Fceilometer~master~Id30b74fd9d52d0d2db6a0a05b047ed1f11d19e8c,openstack/ceilometer,master,Id30b74fd9d52d0d2db6a0a05b047ed1f11d19e8c,"Use ""rss"" of domain.memoryStats() to get memory usage",ABANDONED,2014-12-08 03:16:43.000000000,2014-12-10 02:54:22.000000000,,"[{'_account_id': 3}, {'_account_id': 7052}, {'_account_id': 9562}, {'_account_id': 12927}, {'_account_id': 14118}]","[{'number': 1, 'created': '2014-12-08 03:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4dea97ad6f5b69fe83817d15409dca7eb70b8966', 'message': 'Use ""rss"" of domain.memoryStats() to get memory usage\n\ndomain.memoryStats() seems not consist ""available"" and ""unused"",\nbut consist ""rss"" and ""actual"". So it is necessary to use ""rss""\nas memory usage, otherwise libvirt inspector can\'t get momory\nusage info at all for most circumstances.\n\nChange-Id: Id30b74fd9d52d0d2db6a0a05b047ed1f11d19e8c\nCloses-bug: #1399559\n'}, {'number': 2, 'created': '2014-12-08 03:59:46.000000000', 'files': ['ceilometer/compute/virt/libvirt/inspector.py', 'ceilometer/tests/compute/virt/libvirt/test_inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5298ddc031d37e2fcb6917e9ac0c998a8fd86d39', 'message': 'Use ""rss"" of domain.memoryStats() to get memory usage\n\ndomain.memoryStats() seems not consist ""available"" and ""unused"",\nbut consist ""rss"" and ""actual"". So it is necessary to use ""rss""\nas memory usage, otherwise libvirt inspector can\'t get momory\nusage info at all for most circumstances.\n\nChange-Id: Id30b74fd9d52d0d2db6a0a05b047ed1f11d19e8c\nCloses-bug: #1399559\n'}]",0,139899,5298ddc031d37e2fcb6917e9ac0c998a8fd86d39,15,5,2,14118,,,0,"Use ""rss"" of domain.memoryStats() to get memory usage

domain.memoryStats() seems not consist ""available"" and ""unused"",
but consist ""rss"" and ""actual"". So it is necessary to use ""rss""
as memory usage, otherwise libvirt inspector can't get momory
usage info at all for most circumstances.

Change-Id: Id30b74fd9d52d0d2db6a0a05b047ed1f11d19e8c
Closes-bug: #1399559
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/99/139899/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/compute/virt/libvirt/inspector.py'],1,4dea97ad6f5b69fe83817d15409dca7eb70b8966,bug/1399559, memory_stats.get('rss')): memory_used = memory_stats.get('rss'), memory_stats.get('available') and memory_stats.get('unused')): memory_used = (memory_stats.get('available') - memory_stats.get('unused')),2,4
openstack%2Fpython-heatclient~master~Idba76cc145aaf7636b68ece14598ef67b811275c,openstack/python-heatclient,master,Idba76cc145aaf7636b68ece14598ef67b811275c,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:51:09.000000000,2014-12-10 02:52:23.000000000,2014-12-10 02:52:22.000000000,"[{'_account_id': 3}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-12-05 03:51:09.000000000', 'files': ['CONTRIBUTING.rst', 'doc/source/index.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/39c1846b1feb0e724ecf2f69b9c7207bd83e55e2', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: Idba76cc145aaf7636b68ece14598ef67b811275c\n'}]",0,139373,39c1846b1feb0e724ecf2f69b9c7207bd83e55e2,6,2,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: Idba76cc145aaf7636b68ece14598ef67b811275c
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/73/139373/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'doc/source/index.rst', 'README.rst']",3,39c1846b1feb0e724ecf2f69b9c7207bd83e55e2,infra-manual,`developer guide <http://docs.openstack.org/infra/manual/developers.html>`_. The master repository is in `Git <http://git.openstack.org/cgit/heat-api/python-heatclient>`_.,`OpenStack wiki <http://wiki.openstack.org/HowToContribute>`_. The master repository is on `GitHub <http://github.com/heat-api/python-heatclient>`_.,5,5
openstack%2Fopenstack-ansible~stable%2Ficehouse~I63fd9b48cec07bf533dc62850b287c8b08a6fec4,openstack/openstack-ansible,stable/icehouse,I63fd9b48cec07bf533dc62850b287c8b08a6fec4,Remove Changelog.md,MERGED,2014-12-09 20:56:44.000000000,2014-12-10 02:51:57.000000000,2014-12-09 21:34:06.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-09 20:56:44.000000000', 'files': ['Changelog.md'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/03a084ded5656168db24c418c9db002201b2dfe4', 'message': 'Remove Changelog.md\n\nRemove Changelog.md from the source now that changelogs will be recorded\nin the Launchpad release pages.\n\nChange-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4\nCloses-Bug: #1400808\n'}]",0,140475,03a084ded5656168db24c418c9db002201b2dfe4,7,3,1,6714,,,0,"Remove Changelog.md

Remove Changelog.md from the source now that changelogs will be recorded
in the Launchpad release pages.

Change-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4
Closes-Bug: #1400808
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/75/140475/1 && git format-patch -1 --stdout FETCH_HEAD,['Changelog.md'],1,03a084ded5656168db24c418c9db002201b2dfe4,bug/1400808,,"# Changelog ## 9.0.3 - 2014-11-18 - Do not recursively chown {{ install_lib_dir }} [#367] - Create alarms for discovered devices [$430] - This commit adds a check to the dynamic inventory script when parsing extra values [#458] - Increase galera startup timeout [#411,#413] - Specialize galera client config [#411,#413] - Use local socket for mysql client connection [#411,#413] - Use root pass for galera init script [#411,#413] ## 9.0.2 - 2014-11-06 - Increase delay and retries for lxc cache download [#449] - Updated cinder.conf to allow for AZ setup [#458] - Create empty 'authorized_keys' file [#478] - Fix limit_container_types typo [#480] - Use {{ ansible_fqdn }} for service checks [#452] - Allow for more galera/mysql tuning [#410,#429] - Increase ssh timeout in ansible.cfg [#358] - Updated pip installation/wheel building process - Created lxc-system-manage script for common operational tasks [#434] - Added missing comma which caused Kibana dashboard to not load - Updated rpc_release/maas_repo_version versions [#370] - Ensure that rsyslog state files are unique [#205] - Changed release version to match the branch [#421] - Changed maas_notification_plan to npManaged [#402] - Added galera alarms [#403] - Added repo_package variable file to nova-spice-console [#347] - Resolved issue with neutron HA failover cron clobbering other crons [#383,#378] ## 9.0.1 - 2014-10-17 - Ensure temptest installs a bootable cirros image [#333] - Reference updated rpc-maas repo tag - Templated out iscsi options in the cinder.conf [#328] - AggregateDiskFilter should not be included in Icehouse default filters [#326] - HAproxy memcached acl line too long on big cluster [#142] - Set holland backup to minute based on container IP [#136] - Idempotency for LXC cloning [#312] - No time units for haproxy timeouts [#320] - Allow maas agent to create agent token [#263] - Ensure nova_virt_type default is used [#242] - Change default threading for logstash [#207] - Horizon logs not being parsed [#204] - Swap default/fallback repo urls [#188] - Add appropriate aggregate filters [#315] - Adds a simple to use and cron script for python packages [#252] - Add CDM checks and alarms [#306] - Change the help URL in Horizon so that it can be overriden [#105] - Increase haproxy client/server timeouts for galera service [#259] - Updates to remove uses of "">"" that cause errors [#192] - Fixed an issue where a lookup would fail due to recursive children [#300] - Create users within tempest tenants [#253] - Install Tempest in utility container [#227] - Make container networking timeout slightly less aggressive [#208] - Add missing dependency [#261] - Unnecessary rackspace_cloudfiles_tenant_id variable [#281] - Disable query_cache to reduce deadlocks in Galera [#290] - Removed unused FWaaS plugin [#196] - Fix template name ircbalance -> irqbalance [#199] - IRQbalance needs to have hints ignored [#161] - Galera Needs to have limits set [#160] - RabbitMQ needs to have the ulimit set [#159] - Rabbitmq not clustering correctly when 'rpc' in hostname [#256] - Add a better check to see if the cinder api is actually up [#261] - Remove verbose logging from logstash [#206] - Missing logs on logging server [#130] - Add limits config to galera [#285] - Added sane Nova scheduler settings [#156] - Removed duplicate scheduler_driver from nova.conf - Changed default hypervisor to KVM [#147] - Fix heat domain configuration [#195] - Added check to make sure that the volume group variable exists [#231] - Changed ansible install from the package name to a URL as a tarball [#148] - Offline compress CSS and JS files [#176] - Added heat template for use with RPC9.0.0 and RAX - Added heat template for use with RPC9.0.0 and OpenStack ## 9.0.0 - 2014-09-25 - Initial Release ",0,83
openstack%2Fheat~master~I572ded640582419e0888e4b9f8eed3a3432d6121,openstack/heat,master,I572ded640582419e0888e4b9f8eed3a3432d6121,Do static template validation for nested stacks,MERGED,2014-11-04 06:52:54.000000000,2014-12-10 02:49:32.000000000,2014-12-10 02:49:30.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9189}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-11-04 06:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db9e67c1ebf01b93412f8be17bc905d4575afc1a', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\n""}, {'number': 2, 'created': '2014-11-05 09:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/469b83b0cb5a344c95d9a49ae6c906f64f1bbae9', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\n""}, {'number': 3, 'created': '2014-11-07 03:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cdd6d4cb3d3ebf68dde6e8f83d03cb3fe142d310', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\n""}, {'number': 4, 'created': '2014-11-07 03:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3625711f22ea30d1b1d82e859b0bceb991a9ad4', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\n""}, {'number': 5, 'created': '2014-11-07 06:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cd367b0c566e72def12ded1f832db3b31dae6314', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 6, 'created': '2014-11-13 07:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/649f4ac9a4f172eaa1627f18a50e605603a3d9cb', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 7, 'created': '2014-11-13 09:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6a3aeedfb22668f240d945ce3a7e3f234c1f272e', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 8, 'created': '2014-11-14 10:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dcfe18b7d71c2b13cd07b614c99625edcc58ca66', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nwhen validate the parent stack for create_stack and\npreview_stack.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 9, 'created': '2014-11-18 04:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c9dbea08c6d42343389a50714a4f9d2d311457e2', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 10, 'created': '2014-11-20 10:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51d3fc857a2634a2486b67f26e3078d6fa0e3828', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 11, 'created': '2014-11-20 10:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/38ecb3dc18c4b0110b2b63cea73a3b64bb94c5bb', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 12, 'created': '2014-11-21 02:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fcd26cd9d82060a48ce81b92b12ba9446dce9787', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 13, 'created': '2014-11-24 04:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/57c82f587b8194521aa7d98494d628e787788a65', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 14, 'created': '2014-11-24 07:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f879485f659501071eeb22000ef266d765091353', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 15, 'created': '2014-11-27 06:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c432585368fb456608b0c3f805f38282a6cf4795', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 16, 'created': '2014-11-27 07:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/265ad4492ca36e6d06a298798cfaa03061259116', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 17, 'created': '2014-12-02 02:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c2fe7c4c1b42dd9ad5d5d90a5d292c95d43e124a', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 18, 'created': '2014-12-03 01:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0e7f2785b01457415f75d566e9b81b5d0c8eb207', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 19, 'created': '2014-12-04 01:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f097a9f991f6e4144918728b1a90f1791e875856', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 20, 'created': '2014-12-04 03:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f247292b75aefa16eace58c0aec3fcb5b9e8a5c', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 21, 'created': '2014-12-04 07:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/be04b9ba1a2b0bc1ea4a5f1cd6aa8f0db442ab71', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 22, 'created': '2014-12-05 07:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1acd3e9600ff17f02ae217c2e13c2b55d6137a5c', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 23, 'created': '2014-12-05 08:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/afaf0ecbf1989c8287ab0349e1b2caa82c0bb6cb', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}, {'number': 24, 'created': '2014-12-09 05:00:39.000000000', 'files': ['heat/tests/test_nested_stack.py', 'heat/tests/test_autoscaling.py', 'heat/engine/stack_resource.py', 'heat/tests/test_resource_group.py', 'heat/tests/autoscaling/test_scaling_group.py', 'heat/tests/test_stack_resource.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c31c34f8dfd0919bf46a975701c139073115debc', 'message': ""Do static template validation for nested stacks\n\nCurrently we don't fail fast, even if there is an error\nin the nested template which should fail validation.\nThis change to recurse and do static template validation\nfor nested stack resources.\n\nChange-Id: I572ded640582419e0888e4b9f8eed3a3432d6121\nCloses-Bug: #1388140\nCloses-Bug: #1389104\n""}]",14,132625,c31c34f8dfd0919bf46a975701c139073115debc,129,15,24,8289,,,0,"Do static template validation for nested stacks

Currently we don't fail fast, even if there is an error
in the nested template which should fail validation.
This change to recurse and do static template validation
for nested stack resources.

Change-Id: I572ded640582419e0888e4b9f8eed3a3432d6121
Closes-Bug: #1388140
Closes-Bug: #1389104
",git fetch https://review.opendev.org/openstack/heat refs/changes/25/132625/5 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,db9e67c1ebf01b93412f8be17bc905d4575afc1a,bug/1388140," def _parse_and_validate_nested_stack(self, parent_stack): def validate_template_resource(res): if issubclass(res.__class__, resources.template_resource.TemplateResource): nested_stack = res._parse_nested_stack( res.name, res.child_template(), res.child_params()) return self._parse_and_validate_nested_stack(nested_stack) for res in parent_stack.resources.itervalues(): validate_template_resource(res) self._parse_and_validate_nested_stack(stack)",,54,0
openstack%2Fnova~master~Id32385df5b20903d7a019c3590432f3fb1133f90,openstack/nova,master,Id32385df5b20903d7a019c3590432f3fb1133f90,Clean bdms and networks after deleting shelved VM,MERGED,2014-04-21 03:26:44.000000000,2014-12-10 02:47:54.000000000,2014-12-10 02:28:37.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1011}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 8021}, {'_account_id': 8289}, {'_account_id': 8290}, {'_account_id': 8412}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 8874}, {'_account_id': 8922}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10614}, {'_account_id': 11531}, {'_account_id': 12175}, {'_account_id': 12287}]","[{'number': 1, 'created': '2014-04-21 03:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e532cb2e638fbd7685080b7e47954caa1a78bf55', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 2, 'created': '2014-05-09 06:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/700dce8f83e96602941601fdbd8df16276b77b36', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 3, 'created': '2014-05-09 08:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bfd241a531faee55f308fbc8abb0bc8e558abdf', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 4, 'created': '2014-05-10 02:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65bc90bd3eb9f967a5b44a5e0e496abdd77e8014', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 5, 'created': '2014-05-12 04:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b3f5a0afdffea8a218fb7808127017c5e597f4c', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 6, 'created': '2014-05-12 07:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/443e8f1099da4f06a6af4fbf7ce5e6f442a2e949', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 7, 'created': '2014-05-19 03:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fe4459fc2ab9599c64d110883d1fb655d98b23f', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 8, 'created': '2014-05-19 11:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/407cda2ec7d1f2bbf8399eeec11de183e1bcebd8', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 9, 'created': '2014-05-28 02:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/924c0176a9212427bbe765e20c3a4682eaa6c2d0', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 10, 'created': '2014-05-29 03:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3075bb7427685ef873e7100eb888cda495da9fd', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 11, 'created': '2014-06-16 09:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff4dedba12315e8d22d4378153fbc9877211cd1c', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 12, 'created': '2014-06-25 02:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/698ee25e7e1d4d9d26dcb8affa0c81e079a78392', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 13, 'created': '2014-06-25 08:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2df80f95dc2cea0f605a61e80b99916ecd7ff226', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 14, 'created': '2014-07-01 09:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f606f00315a3266217a696413c335ce09479f95c', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 15, 'created': '2014-07-02 01:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66545886375c589e57646e00ed9305f5dda1c708', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 16, 'created': '2014-07-03 06:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3570609890bc28534856c796c05b89f21b73618e', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 17, 'created': '2014-07-28 11:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93f8089c70424eb3f43b9fcc7558292b1f982c0a', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 18, 'created': '2014-09-04 03:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80843e187f1584d21e92029a7ee3093ea29f72a7', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 19, 'created': '2014-09-16 02:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/535d82e3dd20fc26fb99034cc2272cdfdaf69a7c', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 20, 'created': '2014-09-17 01:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c4d323e817abbc01e3f5cde6970dd369170de2d', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 21, 'created': '2014-09-18 07:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a698cfeb1ece70d6c59256227bb95fcdf53e7ac9', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 22, 'created': '2014-09-25 06:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc46485a0b97f0708f6ec9f4133e1523b25d23d0', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 23, 'created': '2014-10-10 03:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c05151d694b7dd610fb7a6001165a6a94b57e157', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 24, 'created': '2014-10-15 01:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f40c125eb52386cd2e310fba1e33043be21a2d2', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 25, 'created': '2014-10-15 08:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/087ed5a7f1a74f1a3ff4434ef5c1f45000e6ce17', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 26, 'created': '2014-10-23 07:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12c538c7b17377346e72fa5c3b69215f9c4dd7c1', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 27, 'created': '2014-10-30 08:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b85b5e350acb9df1e89140dcd4879761f1f97683', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 28, 'created': '2014-12-03 02:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d58765062182cf454cb63ca8f3b9469186a664f', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}, {'number': 29, 'created': '2014-12-09 02:34:07.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/54f4600c82241ad6ae6768d3dcd1e1755dac4ddc', 'message': 'Clean bdms and networks after deleting shelved VM\n\nAfter deleting the shelved offloaded instance with user volumes,\nthe bdms and networks info should be cleanup. This patch use local\ndeleting to cleanup the instance info.\n\nChange-Id: Id32385df5b20903d7a019c3590432f3fb1133f90\nCloses-bug: #1307791\n'}]",91,89298,54f4600c82241ad6ae6768d3dcd1e1755dac4ddc,372,27,29,8290,,,0,"Clean bdms and networks after deleting shelved VM

After deleting the shelved offloaded instance with user volumes,
the bdms and networks info should be cleanup. This patch use local
deleting to cleanup the instance info.

Change-Id: Id32385df5b20903d7a019c3590432f3fb1133f90
Closes-bug: #1307791
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/89298/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/compute/api.py']",2,e532cb2e638fbd7685080b7e47954caa1a78bf55,bug/1307791," if instance['vm_state'] == vm_states.SHELVED_OFFLOADED: #If instance state is SHELVED_OFFLOADED, instance['host'] is #None, use local_delete to clean up its bdms and network info. self._local_delete(context, instance, bdms, delete_type, cb) if reservations: QUOTAS.commit(context, reservations, project_id=project_id, user_id=user_id) reservations = None return if instance['vm_state'] == vm_states.SHELVED_OFFLOADED: LOG.debug(_(""instance is in SHELVED_OFFLOADED state, cleanup"" "" the instance's info from datebase.""), instance=instance) else: LOG.warning(_(""instance's host %s is down, deleting from "" ""database"") % instance['host'], instance=instance)"," LOG.warning(_(""instance's host %s is down, deleting from "" ""database"") % instance['host'], instance=instance)",23,6
openstack%2Fdevstack~master~I79aafb6a86032c7ab04937c9e9bec08661ecdefa,openstack/devstack,master,I79aafb6a86032c7ab04937c9e9bec08661ecdefa,XenAPI: Add another plugin directory,MERGED,2014-12-09 17:38:34.000000000,2014-12-10 02:41:51.000000000,2014-12-10 02:41:50.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 11444}]","[{'number': 1, 'created': '2014-12-09 17:38:34.000000000', 'files': ['tools/xen/functions'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f3b49e23b04878a2a4d37bbb1884c677b6b56c2a', 'message': 'XenAPI: Add another plugin directory\n\nBuildroot on 64-bit systems may use /usr/lib64 to store the XAPI plugins\nAdd this as an option to search for.\n\nThe list is getting of acceptable paths is getting longer but some work is going\non in XAPI to allow us to query for this path, which will mean we can get\nrid of this list in future.\n\nChange-Id: I79aafb6a86032c7ab04937c9e9bec08661ecdefa\n'}]",0,140413,f3b49e23b04878a2a4d37bbb1884c677b6b56c2a,16,6,1,6735,,,0,"XenAPI: Add another plugin directory

Buildroot on 64-bit systems may use /usr/lib64 to store the XAPI plugins
Add this as an option to search for.

The list is getting of acceptable paths is getting longer but some work is going
on in XAPI to allow us to query for this path, which will mean we can get
rid of this list in future.

Change-Id: I79aafb6a86032c7ab04937c9e9bec08661ecdefa
",git fetch https://review.opendev.org/openstack/devstack refs/changes/13/140413/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/xen/functions'],1,f3b49e23b04878a2a4d37bbb1884c677b6b56c2a,," for PLUGIN_DIR in ""/etc/xapi.d/plugins/"" ""/usr/lib/xcp/plugins/"" ""/usr/lib/xapi/plugins"" ""/usr/lib64/xapi/plugins""; do"," for PLUGIN_DIR in ""/etc/xapi.d/plugins/"" ""/usr/lib/xcp/plugins/"" ""/usr/lib/xapi/plugins""; do",1,1
openstack%2Fopenstack-ansible~stable%2Fjuno~I63fd9b48cec07bf533dc62850b287c8b08a6fec4,openstack/openstack-ansible,stable/juno,I63fd9b48cec07bf533dc62850b287c8b08a6fec4,Remove Changelog.md,MERGED,2014-12-09 20:24:16.000000000,2014-12-10 02:35:58.000000000,2014-12-09 21:33:57.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-09 20:24:16.000000000', 'files': ['Changelog.md'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1370d5f0c2aad5751ef4acac82bc1b83a3cce1c7', 'message': 'Remove Changelog.md\n\nRemove Changelog.md from the source now that changelogs will be recorded\nin the Launchpad release pages.\n\nChange-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4\nCloses-Bug: #1400808\n'}]",0,140467,1370d5f0c2aad5751ef4acac82bc1b83a3cce1c7,6,3,1,6714,,,0,"Remove Changelog.md

Remove Changelog.md from the source now that changelogs will be recorded
in the Launchpad release pages.

Change-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4
Closes-Bug: #1400808
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/67/140467/1 && git format-patch -1 --stdout FETCH_HEAD,['Changelog.md'],1,1370d5f0c2aad5751ef4acac82bc1b83a3cce1c7,,,# Changelog ## 9.0.0 - 2014-09-25 - Initial Release ,0,5
openstack%2Ftricircle~master~Ib230efaba7ba09862668c8c5d8d7fa158112d54f,openstack/tricircle,master,Ib230efaba7ba09862668c8c5d8d7fa158112d54f,Config paging query for cinder,MERGED,2014-12-10 02:03:17.000000000,2014-12-10 02:06:09.000000000,2014-12-10 02:06:09.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-10 02:03:17.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/72a648dd8537ba0462cc8daec88f40f5131912bb', 'message': 'Config paging query for cinder\n\nConfig paging query for cinder.\n\nChange-Id: Ib230efaba7ba09862668c8c5d8d7fa158112d54f\n'}]",0,140552,72a648dd8537ba0462cc8daec88f40f5131912bb,6,2,1,9684,,,0,"Config paging query for cinder

Config paging query for cinder.

Change-Id: Ib230efaba7ba09862668c8c5d8d7fa158112d54f
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/52/140552/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,72a648dd8537ba0462cc8daec88f40f5131912bb,," search_opt = {'all_tenants': True, 'sort_key': 'updated_at', 'sort_dir': 'desc', 'limit': '50', } if instance_uuid is not None: self.db.volume_update(context, volume_id, {""instance_uuid"": instance_uuid, ""mountpoint"": mountpoint }) elif host_name is not None: self.db.volume_update(context, volume_id, {""attached_host"": host_name, ""mountpoint"": mountpoint, })"," search_opt = {'all_tenants': True} self.db.volume_update(context, volume_id, {""instance_uuid"": instance_uuid, ""mountpoint"": mountpoint, ""attached_host"": host_name })",15,6
openstack%2Fironic-specs~master~I9f09dd2890932f0a7670cd8e4e39fe342511addb,openstack/ironic-specs,master,I9f09dd2890932f0a7670cd8e4e39fe342511addb,New Ironic provisioner state machine.,MERGED,2014-11-11 20:34:47.000000000,2014-12-10 02:03:22.000000000,2014-12-10 02:03:22.000000000,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 4573}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7623}, {'_account_id': 8125}, {'_account_id': 10202}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10380}, {'_account_id': 11297}, {'_account_id': 12315}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-11-11 20:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d5ca3f26aa79ff647ee69b1ecc950ed8174e0586', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 2, 'created': '2014-11-12 15:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0d0fff9b20007d27448ff360b119aae6fb145499', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 3, 'created': '2014-11-17 18:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/1e7ce81205bdb7aa2a83d0f8e19824e9cc361e77', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 4, 'created': '2014-11-24 21:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a987f32d8e1f0f8b0d3b3cee4b605aff0864a95a', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 5, 'created': '2014-12-01 16:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6394d6f8722972ea46955809e7b3258ed773ba71', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 6, 'created': '2014-12-01 21:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c5651f7ccaef829899301c2172f632844051a775', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 7, 'created': '2014-12-01 21:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9c3ba671aa0cbe07d2fa92e4f65ca61a6886c56d', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 8, 'created': '2014-12-02 16:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/050f9ed79091a29acf9e4613f7a33198673929ca', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 9, 'created': '2014-12-02 23:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/cd77c7deaddfc5c118552a3e45b5d796b2c6e796', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 10, 'created': '2014-12-04 16:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/305c70fbce7ac88d3cb40ec1eec6bcca9f3c838b', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 11, 'created': '2014-12-08 15:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c133cc13bd8cf8603ca27c913015ff604d752dda', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 12, 'created': '2014-12-09 16:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c7dd5d00aadb6f8912d7d4fd2fe80bc6293e05c9', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nexternal tooling.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 13, 'created': '2014-12-09 17:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e5d5f59d9365ff51b61e780f9bccb5da4589f25c', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nphysical machine lifecycle concerns.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}, {'number': 14, 'created': '2014-12-09 17:55:06.000000000', 'files': ['specs/kilo/new-ironic-state-machine.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e84effb5749f575e112d230404a403f49b177221', 'message': ""New Ironic provisioner state machine.\n\nThe Ironic state machine needs some enhancement to better deal with\nphysical machine lifecycle concerns.  Let's add more states.\n\nChange-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb\n""}]",387,133828,e84effb5749f575e112d230404a403f49b177221,167,18,14,114,,,0,"New Ironic provisioner state machine.

The Ironic state machine needs some enhancement to better deal with
physical machine lifecycle concerns.  Let's add more states.

Change-Id: I9f09dd2890932f0a7670cd8e4e39fe342511addb
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/28/133828/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/new-ironic-state-machine.rst'],1,d5ca3f26aa79ff647ee69b1ecc950ed8174e0586,I9f09dd2890932f0a7670cd8e4e39fe342511addb,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== A proposal for the new Ironic system lifecycle state machine. ========================================== https://blueprints.launchpad.net/ironic/+spec/new-ironic-state-machine This blueprint suggests reworking the Ironic provisioning state machine to fix some current shortcomings and to make it easier for drivers and external orchestration agents to manage nodes in Ironic. Problem description =================== The current Ironic state machine has a few shortcomings: * NOSTATE is a state that indicates we have no state information about a node. This may be fine for talking about the node's power state, but we should always know what provisioning state a node is in. * Ironic has no notion of a node discovery phase, and it will need one when we start making node drivers composable to alleviate the current combinatorial explosion of driver combinations. * We also need a state to put nodes in when they are performing configuration tasks that can reasonably be expected to take hours to complete, such as RAID configuration and burnin. It is unreasonable to force upstream consumers of Ironic managed nodes to wait hours between the time they request a node and get it, so running these tasks as part of DEPLOYING or DEPLOYWAIT is nonviable. * We also need a place to handle node decomissioning tasks. The current decomissioning blueprints handle this in DELETING, but it would also be useful to perform decomissioning tasks on freshly-added nodes. * We also need to let external orchestration systems hook into parts of the state machine for each node to let them manage parts of the node lifecycle without having to import that functionality into Ironic. Proposed change =============== We will rewrite the Ironic state machine to include the following states: ENROLL This is the state that all nodes start off in. When a node is in ENROLL, the only thing Ironic knows about it is that it exists, and Ironic cannot take any further action by itself. From ENROLL, the only allowed provisioner state transitions are to DISCOVERING (if the node was enrolled as a side effect of booting to a discovery image that knows how to talk to Ironic), and INIT (if the node is being created via the API without a discovery image). DISCOVERING When a node is being enrolled as a side effect being booted to via a discovery image, it should immediately transition from ENROLL to DISCOVERING. It is expected that the discovery image will populate some basic information about the node and pick the appropriate set of drivers to manage the node. Any actions the discovery image takes MUST be nondestructive to prevent Ironic from accidentaly blowing away a node that it should not manage, but that got discovered by mistake. INIT Once a node has an initial set of drivers and enough configuration information to allow Ironic to manage the power state of the node, it should be placed into INIT and (optionally) powered off. Nodes must be transitioned out of INIT by an API call -- Ironic should not do this by itself. In the INIT state, an API caller can either transition the node to AVAILABLE, or queue up destructive and/or long-running tasks and then transition the node to ZAPPING. ZAPPING Nodes in the ZAPPING state are performing (potentially) long-running and destructive tasks, such as: * securely erasing disks * changing RAID levels, * updating firmware, * going through burnin. Tasks for ZAPPING should have been enqueued during either the INIT or the DELETED states, and the failure of any task will cause the node to transition to ZAPFAIL. Once all tasks have completed successfully, Ironic will transition the node to AVAILABLE. ZAPFAIL If zapping a node fails for some reason, Ironic will transition the node to ZAPFAIL, and operator intervention will be required to resolve the situation. AVAILABLE Nodes in the AVAILABLE state are cleaned and ready to be provisioned. From AVAILABLE, nodes can transition to PREBOOTING (if you need a running OS to make node config changes), or DEPLOYING (if all your changes can be made out of band). In the AVAILABLE state, short-lived and nondestructive tasks can be queued up to handled when the node transitions to DEPLOYING. PREBOOTING Nodes in PREBOOTING are in the process of booting into a pre-deploy enviromnent such as IPA or a similar (potentially long-running) ramdisk. Nodes in PREBOOTING should transition to PREBOOT when they are ready to perform useful work, and Ironic should transition the node to PREBOOTFAIL if the node does not transition to PREBOOT within a specified amount of time. PREBOOTFAIL If prebooting a node fails for some reason, Ironic will transition the node to PREBOOTFAIL, and operator intervention will be required to resolve the situation. PREBOOT Nodes in PREBOOT have booted into a suitable pre-deploy environment (such as IPA) or a long-running ramdisk. Nodes that were booted to PREBOOT for maintenance purposes should transition back to AVAILABLE when finished, otherwise they should transition to DEPLOYING. Tasks for DEPLOYING can also be enqueued on the node from this state. DEPLOYING Nodes in DEPLOYING are being actively prepared to run a workload on them. This should mainly consist of running a series of short-lived tasks, such as: * Setting appropriate BIOS configurations * Partitioning drives and laying down filesystems. * Creating any additional resources (node-specific network config, etc.) that may be required by additional subsystems. Tasks for DEPLOYING should have been enqueued during either AVAILABLE or PREBOOT, and the failure of any task will cause the node to transition to DEPLOYFAIL. Once all the tasks are finished, Ironic should transition the node to DEPLOYED. DEPLOYFAIL If deploying a node fails for some reason, Ironic will transition the node to DEPLOYFAIL, and operator intervention will be required to resolve the situation. DEPLOYED Nodes in DEPLOYED are ready to be handed over to a workload. Ironic should do so, and then transition the node to ACTIVE once the handoff is complete. ACTIVE Nodes in ACTIVE have a workload running on them. Ironic will check their power state on a regular basis, but will otherwise leave them alone. Nodes in ACTIVE can transition to RESCUE and to DELETING. RESCUE RESCUE exists to allow Ironic to be aware of a node that would be otherwise running a workload, but that has been booted into a different environment for some other (usually troubleshooting or maintenance related) reason. Nodes in RESCUE can transition back to ACTIVE or to DELETING. DELETING Nodes in DELETING state are being torn down from running an active workload. In DELETING, Ironic should tear down or remove any configuration or resources it added in DEPLOYING. Nodes in DELETING should transition to DELETED if teardown was successful, or to DELETEFAIL if it was not. DELETEFAIL If deleting a node fails for some reason, Ironic will transition the node to DELETEFAIL, and operator intervention will be required to resolve the situation. DELETED Nodes in DELETED have been torn down, but have not necessarily been scrubbed or had certian persistent configuration (such as RAID config) erased. Nodes in DELETED can transition back to AVAILABLE (if there is no need to scrub the system), or can have tasks enqueued on them and then transition to ZAPPING (if there is a need to scrub the system, run it through burnin again, or perform some other long-running task). In ascii art, the state machine will look like this (ignoring error states): ENROLL +-> DISCOVERING +-> INIT /-> ZAPPING +-> AVAILABLE -\ \-------->------/ | ^ ^ | | \->+-----------+ v | ^ | PREBOOTING v | ^ | | DELETING -----------> DELETED | v | ^ \- PREBOOT | | | | +-<- ACTIVE <- DEPLOYED <- DEPLOYING <---+---<----/ | ^ ^ | | v \--- RESCUE In addition to state machine changes, Ironic needs a mechanism for signalling that an external tool (such as Chef, Puppet, Ansible, Crowbar, etc.) is handling part of the transition for any given state -- at the summt we talked in terms of a wait flag, but that area still needs to be hashed out. Alternatives ------------ No reasonable ones that we could think of at the summit. Data model impact ----------------- Probably. REST API impact --------------- Definitly. RPC API impact -------------- Yup. Driver API impact ----------------- Yes. Nova driver impact ------------------ Maybe not. Security impact --------------- Probably not, assuming perfect coding. Other end user impact --------------------- Yes. Scalability impact ------------------ Probably nothing significant. Performance Impact ------------------ Ditto. Other deployer impact --------------------- Hopefully not. Developer impact ---------------- This exists to get developer feedback ind impact assesment. Implementation ============== Assignee(s) ----------- None yet. Work Items ---------- Lots of discussion in comments to be done. Dependencies ============ Most every blueprint that touches on the Ironic drivers will be affected, but this blueprint is vendor-agnostic. Testing ======= We have alot of talking to do about this. Upgrades and Backwards Compatibility ==================================== Plenty of backwards compatibility issues to be discussed. Documentation Impact ==================== The new state machine code will need to be thuroughly documented. References ========== Anyone have a link to some developer session notes? I was sorta busy being a whiteboard monkey. ",,301,0
openstack%2Fopenstack-ansible~master~I63fd9b48cec07bf533dc62850b287c8b08a6fec4,openstack/openstack-ansible,master,I63fd9b48cec07bf533dc62850b287c8b08a6fec4,Remove Changelog.md,MERGED,2014-12-09 18:58:06.000000000,2014-12-10 01:54:36.000000000,2014-12-10 00:34:53.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-09 18:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e0af13d7a7f526eabcd25dbe450707329ca0233a', 'message': 'Remove Changelog.md\n\nRemove Changelog.md from the source now that changelogs will be recorded\nin the Launchpad release pages.\n\nChange-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4\nCloses-Bug: #1400808\n'}, {'number': 2, 'created': '2014-12-09 19:28:29.000000000', 'files': ['Changelog.md'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9ff921ce346317861110be6e1555ec6c9de172d8', 'message': 'Remove Changelog.md\n\nRemove Changelog.md from the source now that changelogs will be recorded\nin the Launchpad release pages.\n\nChange-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4\nCloses-Bug: #1400808\n'}]",0,140434,9ff921ce346317861110be6e1555ec6c9de172d8,12,3,2,6714,,,0,"Remove Changelog.md

Remove Changelog.md from the source now that changelogs will be recorded
in the Launchpad release pages.

Change-Id: I63fd9b48cec07bf533dc62850b287c8b08a6fec4
Closes-Bug: #1400808
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/140434/1 && git format-patch -1 --stdout FETCH_HEAD,['Changelog.md'],1,e0af13d7a7f526eabcd25dbe450707329ca0233a,bug/1400808,,# Changelog ## 9.0.0 - 2014-09-25 - Initial Release ,0,5
openstack%2Fnova~master~Ibde9763071c9bfcc1d7631cbf3452ed0948b4a62,openstack/nova,master,Ibde9763071c9bfcc1d7631cbf3452ed0948b4a62,Fix cells RPC version 1.30 compatibility with dict-based Flavors,MERGED,2014-12-08 19:36:25.000000000,2014-12-10 01:44:19.000000000,2014-12-10 00:31:52.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 19:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e323d84d860e98db2deca1aa0c7c807573df54a7', 'message': 'Fix cells RPC version 1.30 compatibility with dict-based Flavors\n\nVersion 1.30 of the cells RPC API changed the client to send Flavor\nobjects instead of dicts. This patch fixes the manager-side compatibility\nfor <=1.29 clients.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ibde9763071c9bfcc1d7631cbf3452ed0948b4a62\n'}, {'number': 2, 'created': '2014-12-08 21:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edefefa1987ad6ee4cafd785e40f4d7c276156cd', 'message': 'Fix cells RPC version 1.30 compatibility with dict-based Flavors\n\nVersion 1.30 of the cells RPC API changed the client to send Flavor\nobjects instead of dicts. This patch fixes the manager-side compatibility\nfor <=1.29 clients.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ibde9763071c9bfcc1d7631cbf3452ed0948b4a62\n'}, {'number': 3, 'created': '2014-12-09 17:30:37.000000000', 'files': ['nova/cells/manager.py', 'nova/tests/unit/cells/test_cells_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ea2cb6514bbb71f8c7e242adef38ed6512eb9ab7', 'message': 'Fix cells RPC version 1.30 compatibility with dict-based Flavors\n\nVersion 1.30 of the cells RPC API changed the client to send Flavor\nobjects instead of dicts. This patch fixes the manager-side compatibility\nfor <=1.29 clients.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ibde9763071c9bfcc1d7631cbf3452ed0948b4a62\n'}]",0,140127,ea2cb6514bbb71f8c7e242adef38ed6512eb9ab7,32,11,3,4393,,,0,"Fix cells RPC version 1.30 compatibility with dict-based Flavors

Version 1.30 of the cells RPC API changed the client to send Flavor
objects instead of dicts. This patch fixes the manager-side compatibility
for <=1.29 clients.

Related to blueprint kilo-objects

Change-Id: Ibde9763071c9bfcc1d7631cbf3452ed0948b4a62
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/140127/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/cells/manager.py', 'nova/tests/unit/cells/test_cells_manager.py']",2,e323d84d860e98db2deca1aa0c7c807573df54a7,bp/kilo-objects,"from nova import objectsfrom nova.tests.unit.objects import test_flavor def test_build_instances_old_flavor(self): flavor_dict = test_flavor.fake_flavor args = {'filter_properties': {'instance_type': flavor_dict}} with mock.patch.object(self.msg_runner, 'build_instances') as mock_bi: self.cells_manager.build_instances(self.ctxt, build_inst_kwargs=args) filter_properties = mock_bi.call_args[0][2]['filter_properties'] self.assertIsInstance(filter_properties['instance_type'], objects.Flavor) ",,21,0
openstack%2Fproject-config~master~Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f,openstack/project-config,master,Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f,Add new project packstack-vagrant to stackforge,MERGED,2014-12-05 15:20:22.000000000,2014-12-10 01:28:36.000000000,2014-12-10 01:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 11491}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-12-05 15:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2e73271fac2d841d392fc4e28a87b435143a8053', 'message': 'Add new project packstack-vagrant to stackforge\n\nChange-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f\n'}, {'number': 2, 'created': '2014-12-05 15:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cd9506efd2f34df7ea73caef55d2d39815cb56ef', 'message': 'Add new project packstack-vagrant to stackforge\n\npackstack-vagrant is a Vagrant environment providing a Packstack installation on top of CentOS.\n\nChange-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f\n'}, {'number': 3, 'created': '2014-12-05 15:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cc3c2c6337be247ab723c1cbd8d9bf451daf7744', 'message': 'Add new project packstack-vagrant to stackforge\n\npackstack-vagrant is a Vagrant environment providing a\nPackstack installation on top of CentOS.\n\nChange-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f\n'}, {'number': 4, 'created': '2014-12-05 22:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4252f7dc6184bf451fc420edb7c6091730c96a9d', 'message': 'Add new project packstack-vagrant to stackforge\n\nChange-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f\n'}, {'number': 5, 'created': '2014-12-06 07:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/43b00e3706eff9520eee7ba786b211a212e9350d', 'message': 'Add new project packstack-vagrant to stackforge\n\nChange-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f\n'}, {'number': 6, 'created': '2014-12-06 11:16:42.000000000', 'files': ['gerrit/acls/stackforge/packstack-vagrant.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ba85fe8e878bac6198b5eae7dee677b14d384706', 'message': 'Add new project packstack-vagrant to stackforge\n\nChange-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f\n'}]",1,139660,ba85fe8e878bac6198b5eae7dee677b14d384706,22,6,6,167,,,0,"Add new project packstack-vagrant to stackforge

Change-Id: Icbabc1e3a2d27f95114bdbe7fb796b7177e3b47f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/139660/4 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/stackforge/packstack-vagrant.config', 'gerrit/projects.yaml']",2,2e73271fac2d841d392fc4e28a87b435143a8053,packstack-vagrant,- project: stackforge/packstack-vagrant description: Vagrant environment providing a Packstack installation. upstream: git://github.com/b1-systems/packstack-vagrant.git,,17,0
openstack%2Ftempest~master~I6bff9747fdf60de72295f823f16953abc0d73158,openstack/tempest,master,I6bff9747fdf60de72295f823f16953abc0d73158,Test disabling lbaas/fwaas/vpnaas temporarily for services repo split,ABANDONED,2014-12-08 17:24:30.000000000,2014-12-10 01:25:42.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-08 17:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a4e4f6e83e7f0a3bdcea8ce332c90e27a4eed30a', 'message': 'Test disabling lbaas/fwaas/vpnaas temporarily for services repo split.\n\nChange-Id: I6bff9747fdf60de72295f823f16953abc0d73158\n'}, {'number': 2, 'created': '2014-12-08 18:10:57.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/30bfe99e2f1696ab923cb5754e0b9d4126d8d0d1', 'message': 'Test disabling lbaas/fwaas/vpnaas temporarily for services repo split\n\nChange-Id: I6bff9747fdf60de72295f823f16953abc0d73158\n'}]",0,140091,30bfe99e2f1696ab923cb5754e0b9d4126d8d0d1,9,6,2,10980,,,0,"Test disabling lbaas/fwaas/vpnaas temporarily for services repo split

Change-Id: I6bff9747fdf60de72295f823f16953abc0d73158
",git fetch https://review.opendev.org/openstack/tempest refs/changes/91/140091/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,a4e4f6e83e7f0a3bdcea8ce332c90e27a4eed30a,," if extension_name in ['lbaas', 'fwaas', 'vpnaas']: return False",,2,0
openstack%2Ftempest~master~Ie7203054b52cd3d5ef288ef2b3da6cdac8414b37,openstack/tempest,master,Ie7203054b52cd3d5ef288ef2b3da6cdac8414b37,Nuke flawed load balancer scenario test,ABANDONED,2014-12-09 00:59:26.000000000,2014-12-10 01:25:10.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 00:59:26.000000000', 'files': ['tempest/scenario/test_load_balancer_basic.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/663f2a82d691d31b78b0983a6d61561928305a97', 'message': 'Nuke flawed load balancer scenario test\n\nChange-Id: Ie7203054b52cd3d5ef288ef2b3da6cdac8414b37\n'}]",1,140192,663f2a82d691d31b78b0983a6d61561928305a97,5,3,1,10980,,,0,"Nuke flawed load balancer scenario test

Change-Id: Ie7203054b52cd3d5ef288ef2b3da6cdac8414b37
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/140192/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_load_balancer_basic.py'],1,663f2a82d691d31b78b0983a6d61561928305a97,,,"# Copyright 2014 Mirantis.inc # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import tempfile import time import urllib2 from tempest.common import commands from tempest import config from tempest import exceptions from tempest.scenario import manager from tempest.services.network import resources as net_resources from tempest import test config = config.CONF class TestLoadBalancerBasic(manager.NetworkScenarioTest): """""" This test checks basic load balancing. The following is the scenario outline: 1. Create an instance 2. SSH to the instance and start two servers 3. Create a load balancer with two members and with ROUND_ROBIN algorithm associate the VIP with a floating ip 4. Send NUM requests to the floating ip and check that they are shared between the two servers. """""" @classmethod def check_preconditions(cls): super(TestLoadBalancerBasic, cls).check_preconditions() cfg = config.network if not test.is_extension_enabled('lbaas', 'network'): msg = 'LBaaS Extension is not enabled' cls.enabled = False raise cls.skipException(msg) if not (cfg.tenant_networks_reachable or cfg.public_network_id): msg = ('Either tenant_networks_reachable must be ""true"", or ' 'public_network_id must be defined.') cls.enabled = False raise cls.skipException(msg) @classmethod def resource_setup(cls): super(TestLoadBalancerBasic, cls).resource_setup() cls.check_preconditions() cls.servers_keypairs = {} cls.members = [] cls.floating_ips = {} cls.server_ips = {} cls.port1 = 80 cls.port2 = 88 cls.num = 50 def setUp(self): super(TestLoadBalancerBasic, self).setUp() self.server_ips = {} self.server_fixed_ips = {} self._create_security_group_for_test() self._set_net_and_subnet() def _set_net_and_subnet(self): """""" Query and set appropriate network and subnet attributes to be used for the test. Existing tenant networks are used if they are found. The configured private network and associated subnet is used as a fallback in absence of tenant networking. """""" try: tenant_net = self._list_networks(tenant_id=self.tenant_id)[0] except IndexError: tenant_net = None if tenant_net: tenant_subnet = self._list_subnets(tenant_id=self.tenant_id)[0] self.subnet = net_resources.DeletableSubnet( client=self.network_client, **tenant_subnet) self.network = tenant_net else: self.network = self._get_network_by_name( config.compute.fixed_network_name) # TODO(adam_g): We are assuming that the first subnet associated # with the fixed network is the one we want. In the future, we # should instead pull a subnet id from config, which is set by # devstack/admin/etc. subnet = self._list_subnets(network_id=self.network['id'])[0] self.subnet = net_resources.AttributeDict(subnet) def _create_security_group_for_test(self): self.security_group = self._create_security_group( tenant_id=self.tenant_id) self._create_security_group_rules_for_port(self.port1) self._create_security_group_rules_for_port(self.port2) def _create_security_group_rules_for_port(self, port): rule = { 'direction': 'ingress', 'protocol': 'tcp', 'port_range_min': port, 'port_range_max': port, } self._create_security_group_rule( secgroup=self.security_group, tenant_id=self.tenant_id, **rule) def _create_server(self, name): keypair = self.create_keypair() security_groups = [{'name': self.security_group['name']}] create_kwargs = { 'networks': [ {'uuid': self.network['id']}, ], 'key_name': keypair['name'], 'security_groups': security_groups, } net_name = self.network['name'] server = self.create_server(name=name, create_kwargs=create_kwargs) self.servers_keypairs[server['id']] = keypair if (config.network.public_network_id and not config.network.tenant_networks_reachable): public_network_id = config.network.public_network_id floating_ip = self.create_floating_ip( server, public_network_id) self.floating_ips[floating_ip] = server self.server_ips[server['id']] = floating_ip.floating_ip_address else: self.server_ips[server['id']] =\ server['addresses'][net_name][0]['addr'] self.server_fixed_ips[server['id']] =\ server['addresses'][net_name][0]['addr'] self.assertTrue(self.servers_keypairs) return server def _create_servers(self): for count in range(2): self._create_server(name=(""server%s"" % (count + 1))) self.assertEqual(len(self.servers_keypairs), 2) def _start_servers(self): """""" Start two backends 1. SSH to the instance 2. Start two http backends listening on ports 80 and 88 respectively """""" for server_id, ip in self.server_ips.iteritems(): private_key = self.servers_keypairs[server_id]['private_key'] server_name = self.servers_client.get_server(server_id)[1]['name'] username = config.scenario.ssh_user ssh_client = self.get_remote_client( server_or_ip=ip, private_key=private_key) # Write a backend's response into a file resp = ('echo -ne ""HTTP/1.1 200 OK\r\nContent-Length: 7\r\n' 'Connection: close\r\nContent-Type: text/html; ' 'charset=UTF-8\r\n\r\n%s""; cat >/dev/null') with tempfile.NamedTemporaryFile() as script: script.write(resp % server_name) script.flush() with tempfile.NamedTemporaryFile() as key: key.write(private_key) key.flush() commands.copy_file_to_host(script.name, ""/tmp/script1"", ip, username, key.name) # Start netcat start_server = ('while true; do ' 'sudo nc -l -p %(port)s -e sh /tmp/%(script)s; ' 'done &') cmd = start_server % {'port': self.port1, 'script': 'script1'} ssh_client.exec_command(cmd) if len(self.server_ips) == 1: with tempfile.NamedTemporaryFile() as script: script.write(resp % 'server2') script.flush() with tempfile.NamedTemporaryFile() as key: key.write(private_key) key.flush() commands.copy_file_to_host(script.name, ""/tmp/script2"", ip, username, key.name) cmd = start_server % {'port': self.port2, 'script': 'script2'} ssh_client.exec_command(cmd) def _check_connection(self, check_ip, port=80): def try_connect(ip, port): try: resp = urllib2.urlopen(""http://{0}:{1}/"".format(ip, port)) if resp.getcode() == 200: return True return False except IOError: return False except urllib2.HTTPError: return False timeout = config.compute.ping_timeout start = time.time() while not try_connect(check_ip, port): if (time.time() - start) > timeout: message = ""Timed out trying to connect to %s"" % check_ip raise exceptions.TimeoutException(message) def _create_pool(self): """"""Create a pool with ROUND_ROBIN algorithm."""""" self.pool = super(TestLoadBalancerBasic, self)._create_pool( lb_method='ROUND_ROBIN', protocol='HTTP', subnet_id=self.subnet.id) self.assertTrue(self.pool) def _create_members(self): """""" Create two members. In case there is only one server, create both members with the same ip but with different ports to listen on. """""" for server_id, ip in self.server_fixed_ips.iteritems(): if len(self.server_fixed_ips) == 1: member1 = self._create_member(address=ip, protocol_port=self.port1, pool_id=self.pool.id) member2 = self._create_member(address=ip, protocol_port=self.port2, pool_id=self.pool.id) self.members.extend([member1, member2]) else: member = self._create_member(address=ip, protocol_port=self.port1, pool_id=self.pool.id) self.members.append(member) self.assertTrue(self.members) def _assign_floating_ip_to_vip(self, vip): public_network_id = config.network.public_network_id port_id = vip.port_id floating_ip = self.create_floating_ip(vip, public_network_id, port_id=port_id) self.floating_ips.setdefault(vip.id, []) self.floating_ips[vip.id].append(floating_ip) def _create_load_balancer(self): self._create_pool() self._create_members() self.vip = self._create_vip(protocol='HTTP', protocol_port=80, subnet_id=self.subnet.id, pool_id=self.pool.id) self.vip.wait_for_status('ACTIVE') if (config.network.public_network_id and not config.network.tenant_networks_reachable): self._assign_floating_ip_to_vip(self.vip) self.vip_ip = self.floating_ips[ self.vip.id][0]['floating_ip_address'] else: self.vip_ip = self.vip.address # Currently the ovs-agent is not enforcing security groups on the # vip port - see https://bugs.launchpad.net/neutron/+bug/1163569 # However the linuxbridge-agent does, and it is necessary to add a # security group with a rule that allows tcp port 80 to the vip port. self.network_client.update_port( self.vip.port_id, security_groups=[self.security_group.id]) def _check_load_balancing(self): """""" 1. Send NUM requests on the floating ip associated with the VIP 2. Check that the requests are shared between the two servers """""" self._check_connection(self.vip_ip) self._send_requests(self.vip_ip, [""server1"", ""server2""]) def _send_requests(self, vip_ip, servers): counters = dict.fromkeys(servers, 0) for i in range(self.num): try: server = urllib2.urlopen(""http://{0}/"".format(vip_ip)).read() counters[server] += 1 # HTTP exception means fail of server, so don't increase counter # of success and continue connection tries except urllib2.HTTPError: continue # Assert that each member of the pool gets balanced at least once for member, counter in counters.iteritems(): self.assertGreater(counter, 0, 'Member %s never balanced' % member) @test.services('compute', 'network') def test_load_balancer_basic(self): self._create_server('server1') self._start_servers() self._create_load_balancer() self._check_load_balancing() ",0,319
openstack%2Fcue~master~Ibfdeabc3164d34f9c6696661f43a1d8627df7b2d,openstack/cue,master,Ibfdeabc3164d34f9c6696661f43a1d8627df7b2d,Add base API Test,MERGED,2014-12-09 00:40:53.000000000,2014-12-10 00:52:18.000000000,2014-12-10 00:52:18.000000000,"[{'_account_id': 3}, {'_account_id': 1925}]","[{'number': 1, 'created': '2014-12-09 00:40:53.000000000', 'files': ['cue/tests/api/test_base.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/21de80cedc70c4532176b224303aa29f8c688ecc', 'message': 'Add base API Test\n\nChange-Id: Ibfdeabc3164d34f9c6696661f43a1d8627df7b2d\n'}]",0,140187,21de80cedc70c4532176b224303aa29f8c688ecc,6,2,1,1925,,,0,"Add base API Test

Change-Id: Ibfdeabc3164d34f9c6696661f43a1d8627df7b2d
",git fetch https://review.opendev.org/openstack/cue refs/changes/87/140187/1 && git format-patch -1 --stdout FETCH_HEAD,['cue/tests/api/test_base.py'],1,21de80cedc70c4532176b224303aa29f8c688ecc,,"# Copyright 2014 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import cue.tests.api as api_base class TestBase(api_base.FunctionalTest): def test_api_setup(self): pass def test_bad_uri(self): response = self.get_json('/bad/path', expect_errors=True, headers={""Accept"": ""application/json""}) self.assertEqual(404, response.status_int) self.assertEqual(""application/json"", response.content_type) self.assertTrue(response.json['error_message']) ",,30,0
openstack%2Freviewstats~master~I4e8921467fb462d381ac9491a9bacbb43bfbe87e,openstack/reviewstats,master,I4e8921467fb462d381ac9491a9bacbb43bfbe87e,Update neutron core,MERGED,2014-12-08 21:50:54.000000000,2014-12-10 00:23:33.000000000,2014-12-10 00:23:32.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 6316}, {'_account_id': 6609}]","[{'number': 1, 'created': '2014-12-08 21:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/c2e9b170b5e630e87015015e33513b4df09d25b9', 'message': ""Update neutron core\n\nWe've removed to folks (rkukura and nati_ueno) and added two new cores\n(HenryG and kevinbenton).\n\nChange-Id: I4e8921467fb462d381ac9491a9bacbb43bfbe87e\n""}, {'number': 2, 'created': '2014-12-08 23:42:46.000000000', 'files': ['projects/neutron.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/b0c9b630bbae30e5a22deda980a9470c4b5b3d34', 'message': ""Update neutron core\n\nWe've removed two folks (rkukura and nati_ueno) and added two new core\nreviewers (HenryG and kevinbenton).\n\nChange-Id: I4e8921467fb462d381ac9491a9bacbb43bfbe87e\n""}]",0,140159,b0c9b630bbae30e5a22deda980a9470c4b5b3d34,10,4,2,105,,,0,"Update neutron core

We've removed two folks (rkukura and nati_ueno) and added two new core
reviewers (HenryG and kevinbenton).

Change-Id: I4e8921467fb462d381ac9491a9bacbb43bfbe87e
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/59/140159/2 && git format-patch -1 --stdout FETCH_HEAD,['projects/neutron.json'],1,c2e9b170b5e630e87015015e33513b4df09d25b9,neutron/new-cores," ""HenryG"", ""kevinbenton"","," ""nati-ueno"", ""rkukura"",",2,2
openstack%2Ftempest~master~I39e3df635f24bbe0f288bb6ccf1300ee5132725e,openstack/tempest,master,I39e3df635f24bbe0f288bb6ccf1300ee5132725e,Test to create bulk port,MERGED,2014-11-25 12:42:09.000000000,2014-12-10 00:12:02.000000000,2014-12-10 00:12:01.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5174}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7249}, {'_account_id': 8576}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 13342}]","[{'number': 1, 'created': '2014-11-25 12:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/28f73b6d4302e2986b39dd9dd5ba6a7e99a00cb0', 'message': 'Test to create bulk port\n\nAdd test to create bulk port for two different network\n  -Create two different networks\n  -Create a network_list\n  -Call a bulk port function to create a ports\n  -Verify the port network_id with the network id used\n  -Verify the admin_state_up of the port\n\nChange-Id: I39e3df635f24bbe0f288bb6ccf1300ee5132725e\n'}, {'number': 2, 'created': '2014-12-03 14:23:39.000000000', 'files': ['tempest/api/network/test_ports.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/073731025290a6161b27fa224ba7a0e17d2dffe9', 'message': 'Test to create bulk port\n\nAdd test to create bulk port for two different network\n  -Create two different networks\n  -Create a network_list\n  -Call a bulk port function to create a ports\n  -Verify the port network_id with the network id used\n  -Verify the admin_state_up of the port\n\nChange-Id: I39e3df635f24bbe0f288bb6ccf1300ee5132725e\n'}]",6,137038,073731025290a6161b27fa224ba7a0e17d2dffe9,23,11,2,13342,,,0,"Test to create bulk port

Add test to create bulk port for two different network
  -Create two different networks
  -Create a network_list
  -Call a bulk port function to create a ports
  -Verify the port network_id with the network id used
  -Verify the admin_state_up of the port

Change-Id: I39e3df635f24bbe0f288bb6ccf1300ee5132725e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/38/137038/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_ports.py'],1,28f73b6d4302e2986b39dd9dd5ba6a7e99a00cb0,bulk_port," def test_create_bulk_port(self): network1 = self.network name = data_utils.rand_name('network-') network2 = self.create_network(network_name=name) network_list = [network1['id'], network2['id']] port_list = [{'network_id': net_id} for net_id in network_list] _, body = self.client.create_bulk_port(port_list) created_ports = body['ports'] port1 = created_ports[0] port2 = created_ports[1] self.addCleanup(self._delete_port, port1['id']) self.addCleanup(self._delete_port, port2['id']) self.assertEqual(port1['network_id'], network1['id']) self.assertEqual(port2['network_id'], network2['id']) self.assertTrue(port1['admin_state_up']) self.assertTrue(port2['admin_state_up']) """""" """"""",,19,1
openstack%2Fhorizon~master~Ifcbf6deac4f7f66b54d139d6487b0b668f1a26fc,openstack/horizon,master,Ifcbf6deac4f7f66b54d139d6487b0b668f1a26fc,[Sahara] Fixed job execution update for deleted row,MERGED,2014-11-24 23:42:43.000000000,2014-12-10 00:10:54.000000000,2014-12-10 00:10:53.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 2750}, {'_account_id': 5623}, {'_account_id': 7132}]","[{'number': 1, 'created': '2014-11-24 23:42:43.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/job_executions/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/38beb1f1bd4c609debc6b8cb2075c1842d3a66a0', 'message': '[Sahara] Fixed job execution update for deleted row\n\nRaise Http404 to have row deleted from the table.\n\nChange-Id: Ifcbf6deac4f7f66b54d139d6487b0b668f1a26fc\nCloses-Bug: #1395931\n'}]",0,136927,38beb1f1bd4c609debc6b8cb2075c1842d3a66a0,9,5,1,8411,,,0,"[Sahara] Fixed job execution update for deleted row

Raise Http404 to have row deleted from the table.

Change-Id: Ifcbf6deac4f7f66b54d139d6487b0b668f1a26fc
Closes-Bug: #1395931
",git fetch https://review.opendev.org/openstack/horizon refs/changes/27/136927/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/data_processing/job_executions/tables.py'],1,38beb1f1bd4c609debc6b8cb2075c1842d3a66a0,bug/1395931,"from django.http import Http404 # noqafrom saharaclient.api import base as api_base from horizon import messages try: return saharaclient.job_execution_get(request, job_execution_id) except api_base.APIException as e: if e.error_code == 404: raise Http404 else: messages.error(request, _(""Unable to update row""))"," job_execution = saharaclient.job_execution_get(request, job_execution_id) return job_execution",11,3
